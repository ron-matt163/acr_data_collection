[
    {
        "pr_title": "feat: added annotations samples for SM",
        "pr_number": 4432,
        "file_name": "firestore/vector_search_distance_threshold.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage firestore\n \n-// [START firestore_vector_search_basic]\n+// [START firestore_vector_search_distance_threshold]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into sm-annotations",
        "commit_id": "74dcad54cb0fce545c7cd60facda6f3896491994"
    },
    {
        "pr_title": "feat: added annotations samples for SM",
        "pr_number": 4432,
        "file_name": "firestore/vector_search_result_field_masked.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage firestore\n \n-// [START firestore_vector_search_distance_result_field]\n+// [START firestore_vector_search_distance_result_field_masked]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into sm-annotations",
        "commit_id": "74dcad54cb0fce545c7cd60facda6f3896491994"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage ingestion topic",
        "pr_number": 4428,
        "file_name": "firestore/vector_search_distance_threshold.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage firestore\n \n-// [START firestore_vector_search_basic]\n+// [START firestore_vector_search_distance_threshold]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-cloud-storage",
        "commit_id": "de474bcfca11881a18c5bde85148c5fcccf2cb8d"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage ingestion topic",
        "pr_number": 4428,
        "file_name": "firestore/vector_search_result_field_masked.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage firestore\n \n-// [START firestore_vector_search_distance_result_field]\n+// [START firestore_vector_search_distance_result_field_masked]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-cloud-storage",
        "commit_id": "de474bcfca11881a18c5bde85148c5fcccf2cb8d"
    },
    {
        "pr_title": "feat(securitycenter): add sample for creating v2 clients with regional and default endpoints",
        "pr_number": 4419,
        "file_name": "compute/reservations/reservations_test.go",
        "code_diff": "@@ -98,6 +98,47 @@\nfunc deleteTemplate(project, templateName string) error {\n \treturn op.Wait(ctx)\n }\n \n+func deleteInstance(project, zone, instance string) error {\n+\tctx := context.Background()\n+\tclient, err := compute.NewInstancesRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\treq := &computepb.DeleteInstanceRequest{\n+\t\tInstance: instance,\n+\t\tProject:  project,\n+\t\tZone:     zone,\n+\t}\n+\top, err := client.Delete(ctx, req)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"unable to delete instance: %w\", err)\n+\t}\n+\n+\treturn op.Wait(ctx)\n+}\n+\n+func deleteInstanceTemplate(project, templateName string) error {\n+\tctx := context.Background()\n+\tinstanceTemplatesClient, err := compute.NewInstanceTemplatesRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer instanceTemplatesClient.Close()\n+\n+\treq := &computepb.DeleteInstanceTemplateRequest{\n+\t\tProject:          project,\n+\t\tInstanceTemplate: templateName,\n+\t}\n+\n+\top, err := instanceTemplatesClient.Delete(ctx, req)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"unable to delete instance template: %w\", err)\n+\t}\n+\n+\treturn op.Wait(ctx)\n+}\n+\n func TestReservations(t *testing.T) {\n \tvar r *rand.Rand = rand.New(\n \t\trand.NewSource(time.Now().UnixNano()))",
        "comments": [],
        "commit_message": "Merge branch 'main' into scc-client",
        "commit_id": "bd2a61bf2f54e7aba655407226db15a24e927682"
    },
    {
        "pr_title": "feat(securitycenter): add sample for creating v2 clients with regional and default endpoints",
        "pr_number": 4419,
        "file_name": "compute/reservations/reservations_test.go",
        "code_diff": "@@ -106,7 +147,6 @@\nfunc TestReservations(t *testing.T) {\n \ttemplateName := fmt.Sprintf(\"test-template-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \n \tvar buf bytes.Buffer\n-\n \terr := createTemplate(tc.ProjectID, templateName)\n \tif err != nil {\n \t\tt.Errorf(\"createTemplate got err: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'main' into scc-client",
        "commit_id": "bd2a61bf2f54e7aba655407226db15a24e927682"
    },
    {
        "pr_title": "feat(securitycenter): add sample for creating v2 clients with regional and default endpoints",
        "pr_number": 4419,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -297,7 +297,7 @@\nfunc TestDelete(t *testing.T) {\n \t}\n }\n \n-func TestTopicKinesis(t *testing.T) {\n+func TestTopicKinesisIngestion(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'main' into scc-client",
        "commit_id": "bd2a61bf2f54e7aba655407226db15a24e927682"
    },
    {
        "pr_title": "feat: create shared reservation",
        "pr_number": 4378,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -297,7 +297,7 @@\nfunc TestDelete(t *testing.T) {\n \t}\n }\n \n-func TestTopicKinesis(t *testing.T) {\n+func TestTopicKinesisIngestion(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat_compute_reservation_create_shared",
        "commit_id": "52ce7d7df01996d7c7ad15eb9511fa2026f34e03"
    },
    {
        "pr_title": "feat(firestore): Vector search",
        "pr_number": 4358,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -577,6 +577,7 @@\nfunc TestCreateDisksStoragePool(t *testing.T) {\n \tstoragePoolName := fmt.Sprintf(\"test-storage-pool-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tstoragePoolType := fmt.Sprintf(\"projects/%s/zones/%s/storagePoolTypes/hyperdisk-balanced\", tc.ProjectID, zone)\n \tstoragePoolLink := fmt.Sprintf(\"https://www.googleapis.com/compute/v1/projects/%s/zones/%s/storagePools/%s\", tc.ProjectID, zone, storagePoolName)\n+\tperformanceProvisioningType := \"ADVANCED\"\n \tprovisionedCapacity := int64(10240)\n \tprovisionedIops := int64(10000)\n \tprovisionedThroughput := int64(1024)",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/fs-vector-search",
        "commit_id": "423e3436088e8b983d17634321729ee106dba3d0"
    },
    {
        "pr_title": "feat(bigqueryv2): Add Big Query v2 client libraries/ samples",
        "pr_number": 4343,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -29,7 +29,10 @@\nimport (\n \t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n+\t\"cloud.google.com/go/pubsub/pstest\"\n \t\"cloud.google.com/go/storage\"\n+\ttrace \"cloud.google.com/go/trace/apiv1\"\n+\t\"cloud.google.com/go/trace/apiv1/tracepb\"\n \t\"google.golang.org/api/iterator\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'big-query-export-samples-v2' of github.com:vijaykanthm/golang-samples into big-query-export-samples-v2\nMerge remote into local",
        "commit_id": "9a3c0d0c7bbd43e298bc93033fe936f0ad28b49c"
    },
    {
        "pr_title": "feat(bigqueryv2): Add Big Query v2 client libraries/ samples",
        "pr_number": 4343,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -30,6 +30,8 @@\nimport (\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"cloud.google.com/go/pubsub/pstest\"\n+\ttrace \"cloud.google.com/go/trace/apiv1\"\n+\t\"cloud.google.com/go/trace/apiv1/tracepb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"google.golang.org/api/iterator\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'big-query-export-samples-v2' of github.com:vijaykanthm/golang-samples into big-query-export-samples-v2\nMerge remote into local",
        "commit_id": "9a3c0d0c7bbd43e298bc93033fe936f0ad28b49c"
    },
    {
        "pr_title": "fix: refactoring aiplatform samples",
        "pr_number": 4326,
        "file_name": "vertexai/multimodal-video-with-audio/multimodalvideoaudio.go",
        "code_diff": "@@ -27,14 +27,9 @@\nimport (\n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-// generateMultimodalContent shows how to send video and text prompts to a model, writing the response to\n-// the provided io.Writer.\n+// generateMultimodalContent shows how to send video to a model, writing the response to the provided io.Writer.\n // video is a Google Cloud Storage path starting with \"gs://\"\n-func generateMultimodalContent(w io.Writer, prompt, video, projectID, location, modelName string) error {\n-\t// prompt := `\n-\t// \t\tProvide a description of the video.\n-\t// \t\tThe description should also contain anything important which people say in the video.\n-\t// `\n+func generateMultimodalContent(w io.Writer, video, projectID, location, modelName string) error {\n \t// video := \"gs://cloud-samples-data/generative-ai/video/pixel8.mp4\"\n \t// location := \"us-central1\"\n \t// modelName := \"gemini-1.5-flash-001\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_aiplatform_hidden_variables",
        "commit_id": "93c421ad3d013e0fda7f098a11494e72b89553fc"
    },
    {
        "pr_title": "fix: refactoring aiplatform samples",
        "pr_number": 4326,
        "file_name": "vertexai/system-instruction/systeminstruction.go",
        "code_diff": "@@ -29,13 +29,7 @@\nimport (\n )\n \n // systemInstruction shows how to provide a system instruction to the generative model.\n-func systemInstruction(w io.Writer, instruction, prompt, projectID, location, modelName string) error {\n-\t// instruction := `\n-\t// \t\tYou are a helpful language translator.\n-\t// \t\tYour mission is to translate text in English to French.`\n-\t// prompt := `\n-\t//\t\tUser input: I like bagels.\n-\t//\t\tAnswer:`\n+func systemInstruction(w io.Writer, projectID, location, modelName string) error {\n \t// location := \"us-central1\"\n \t// modelName := \"gemini-1.5-flash-001\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_aiplatform_hidden_variables",
        "commit_id": "93c421ad3d013e0fda7f098a11494e72b89553fc"
    },
    {
        "pr_title": "Fix: moving function attributes inside samples, to make them self-descriptive",
        "pr_number": 4325,
        "file_name": "vertexai/multimodal-multiple/multiple-multimodal.go",
        "code_diff": "@@ -12,55 +12,40 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n // multiple-multimodal shows how to generate content from mixed image and text content\n-package main\n+package multiplemultimodal\n \n // [START generativeaionvertexai_gemini_single_turn_multi_image]\n // [START aiplatform_gemini_single_turn_multi_image]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\t\"net/http\"\n-\t\"net/url\"\n-\t\"os\"\n-\t\"strings\"\n+\t\"mime\"\n+\t\"path/filepath\"\n \n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-func main() {\n-\tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n-\tlocation := \"us-central1\"\n-\tmodelName := \"gemini-1.5-flash-001\"\n-\ttemperature := 0.4\n-\n-\tif projectID == \"\" {\n-\t\tlog.Fatal(\"require environment variable GOOGLE_CLOUD_PROJECT\")\n-\t}\n-\n-\t// construct this multimodal prompt:\n-\t// [image of colosseum] city: Rome, Landmark: the Colosseum\n-\t// [image of forbidden city]  city: Beijing, Landmark: the Forbidden City\n-\t// [new image]\n+// generateMultimodalContent shows how to generate a text from a multimodal prompt using the Gemini model,\n+// writing the response to the provided io.Writer.\n+func generateMultimodalContent(w io.Writer, projectID, location, modelName string) error {\n+\t// location := \"us-central1\"\n+\t// modelName := \"gemini-1.5-flash-001\"\n+\tctx := context.Background()\n \n \t// create prompt image parts\n-\t// colosseum\n-\tcolosseum, err := partFromImageURL(\"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark1.png\")\n-\tif err != nil {\n-\t\tlog.Fatalf(\"unable to read image: %v\", err)\n+\tcolosseum := genai.FileData{\n+\t\tMIMEType: mime.TypeByExtension(filepath.Ext(\"landmark1.png\")),\n+\t\tFileURI:  \"gs://cloud-samples-data/vertex-ai/llm/prompts/landmark1.png\",\n \t}\n-\t// forbidden city\n-\tforbiddenCity, err := partFromImageURL(\"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark2.png\")\n-\tif err != nil {\n-\t\tlog.Fatalf(\"unable to read image: %v\", err)\n+\tforbiddenCity := genai.FileData{\n+\t\tMIMEType: mime.TypeByExtension(filepath.Ext(\"landmark2.png\")),\n+\t\tFileURI:  \"gs://cloud-samples-data/vertex-ai/llm/prompts/landmark2.png\",\n \t}\n-\t// new image\n-\tnewImage, err := partFromImageURL(\"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark3.png\")\n-\tif err != nil {\n-\t\tlog.Fatalf(\"unable to read image: %v\", err)\n+\tnewImage := genai.FileData{\n+\t\tMIMEType: mime.TypeByExtension(filepath.Ext(\"landmark3.png\")),\n+\t\tFileURI:  \"gs://cloud-samples-data/vertex-ai/llm/prompts/landmark3.png\",\n \t}\n-\n \t// create a multimodal (multipart) prompt\n \tprompt := []genai.Part{\n \t\tcolosseum,",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_vertexai_unclear_attributes",
        "commit_id": "a5eec03f8305855faccb02fcf9dc86f2b866c363"
    },
    {
        "pr_title": "fix: moved attributes inside sample",
        "pr_number": 4315,
        "file_name": "aiplatform/snippets/embeddings_preview.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage snippets\n \n-// [START generativeaionvertexai_sdk_embedding]\n+// [START generativeaionvertexai_text_predictions]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pro_example",
        "commit_id": "12caac81be12ef0f819e9e68e5ced6695f82b1ce"
    },
    {
        "pr_title": "fix: moved attributes inside sample",
        "pr_number": 4315,
        "file_name": "aiplatform/snippets/embeddings_preview.go",
        "code_diff": "@@ -27,6 +27,8 @@\nimport (\n \t\"google.golang.org/protobuf/types/known/structpb\"\n )\n \n+// Embeds code query with a pre-trained, foundational model by specifying the task type as 'CODE_RETRIEVAL_QUERY'. e.g. 'Retrieve a function that adds two numbers'.\n+// Embeds code block with a pre-trained, foundational model by specifying the task type as 'RETRIEVAL_DOCUMENT'. e.g. 'texts := []string{\"def func(a, b): return a + b\", \"def func(a, b): return a - b\", \"def func(a, b): return (a ** 2 + b ** 2) ** 0.5\"}'.\n func embedTextsPreview(\n \tapiEndpoint, project, model string, texts []string,\n \ttask string, dimensionality *int) ([][]float32, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pro_example",
        "commit_id": "12caac81be12ef0f819e9e68e5ced6695f82b1ce"
    },
    {
        "pr_title": "fix: moved attributes inside sample",
        "pr_number": 4315,
        "file_name": "datastore/snippets/query_test.go",
        "code_diff": "@@ -21,10 +21,14 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"log\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"cloud.google.com/go/datastore\"\n+\tadmin \"cloud.google.com/go/datastore/admin/apiv1\"\n+\t\"cloud.google.com/go/datastore/admin/apiv1/adminpb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n )\n \n var projectID string",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pro_example",
        "commit_id": "12caac81be12ef0f819e9e68e5ced6695f82b1ce"
    },
    {
        "pr_title": "fix: moved attributes inside sample",
        "pr_number": 4315,
        "file_name": "pubsub/subscriptions/pull_exactly_once_delivery.go",
        "code_diff": "@@ -22,6 +22,7 @@\nimport (\n \t\"time\"\n \n \t\"cloud.google.com/go/pubsub\"\n+\t\"google.golang.org/api/option\"\n )\n \n // receiveMessagesWithExactlyOnceDeliveryEnabled instantiates a subscriber client.",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pro_example",
        "commit_id": "12caac81be12ef0f819e9e68e5ced6695f82b1ce"
    },
    {
        "pr_title": "fix: moved attributes inside sample",
        "pr_number": 4315,
        "file_name": "securitycenter/muteconfig/mute_config_test.go",
        "code_diff": "@@ -252,6 +252,9 @@\nfunc TestSetMuteFinding(t *testing.T) {\n \n func TestSetUnmuteFinding(t *testing.T) {\n \tt.Skip(\"see https://github.com/GoogleCloudPlatform/golang-samples/issues/3793\")\n+\t// Needs more investigation (doesn't match on missing `locations/global`)\n+\t// got:       Mute value for the finding: organizations/688851828130/sources/14743348522722609714/locations/global/findings/updated is UNDEFINED\n+\t// expected:  Mute value for the finding: organizations/688851828130/sources/14743348522722609714/findings/updated is UNDEFINED\n \ttestutil.SystemTest(t)\n \n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pro_example",
        "commit_id": "12caac81be12ef0f819e9e68e5ced6695f82b1ce"
    },
    {
        "pr_title": "feat(datastore): Multiple inequalities",
        "pr_number": 4311,
        "file_name": "vertexai/function-calling/functioncalling_basic.go",
        "code_diff": "@@ -34,7 +34,8 @@\nimport (\n \n // functionCallsBasic opens a chat session and sends 2 messages to the model:\n // - first, to convert a text into a structured function call request\n-// - second, to convert a structured function call response into natural language\n+// - second, to convert a structured function call response into natural language.\n+// Writes output of second call to w.\n func functionCallsBasic(w io.Writer, prompt, projectID, location, modelName string) error {\n \t// prompt := \"What's the weather like in Boston?\"\n \t// location := \"us-central1\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/ds-mieq",
        "commit_id": "ecdb56d65473e97a92c3395cd36769846f384240"
    },
    {
        "pr_title": "feat(datastore): Multiple inequalities",
        "pr_number": 4311,
        "file_name": "vertexai/function-calling/functioncalling_basic.go",
        "code_diff": "@@ -69,7 +70,6 @@\nfunc functionCallsBasic(w io.Writer, prompt, projectID, location, modelName stri\n \n \tchat := model.StartChat()\n \n-\tfmt.Fprintf(w, \"Question: %s\\n\", prompt)\n \tresp, err := chat.SendMessage(ctx, genai.Text(prompt))\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/ds-mieq",
        "commit_id": "ecdb56d65473e97a92c3395cd36769846f384240"
    },
    {
        "pr_title": "feat(datastore): Multiple inequalities",
        "pr_number": 4311,
        "file_name": "vertexai/function-calling/functioncalling_basic.go",
        "code_diff": "@@ -81,25 +81,34 @@\nfunc functionCallsBasic(w io.Writer, prompt, projectID, location, modelName stri\n \n \t// The model has returned a function call to the declared function `getCurrentWeather`\n \t// with a value for the argument `location`.\n-\tjsondata, err := json.MarshalIndent(resp.Candidates[0].Content.Parts[0], \"\", \"  \")\n+\t_, err = json.MarshalIndent(resp.Candidates[0].Content.Parts[0], \"\", \"  \")\n \tif err != nil {\n \t\treturn fmt.Errorf(\"json.MarshalIndent: %w\", err)\n \t}\n-\tfmt.Fprintf(w, \"function call generated by the model:\\n%s\\n\\n\", string(jsondata))\n+\n+\t// In this example, we'll use synthetic data to simulate a response payload from an external API\n+\tweather := map[string]string{\n+\t\t\"location\":    \"Boston\",\n+\t\t\"temperature\": \"38\",\n+\t\t\"description\": \"Partly Cloudy\",\n+\t\t\"icon\":        \"partly-cloudy\",\n+\t\t\"humidity\":    \"65\",\n+\t\t\"wind\":        \"{\\\"speed\\\": \\\"10\\\", \\\"direction\\\": \\\"NW\\\"}\",\n+\t}\n+\tweather_json, _ := json.Marshal(weather)\n \n \t// Create a function call response, to simulate the result of a call to a\n \t// real service\n \tfunresp := &genai.FunctionResponse{\n \t\tName: \"getCurrentWeather\",\n \t\tResponse: map[string]any{\n-\t\t\t\"currentWeather\": \"sunny\",\n+\t\t\t\"currentWeather\": weather_json,\n \t\t},\n \t}\n-\tjsondata, err = json.MarshalIndent(funresp, \"\", \"  \")\n+\t_, err = json.MarshalIndent(funresp, \"\", \"  \")\n \tif err != nil {\n \t\treturn fmt.Errorf(\"json.MarshalIndent: %w\", err)\n \t}\n-\tfmt.Fprintf(w, \"function call response sent to the model:\\n%s\\n\\n\", string(jsondata))\n \n \t// And provide the function call response to the model\n \tresp, err = chat.SendMessage(ctx, funresp)",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/ds-mieq",
        "commit_id": "ecdb56d65473e97a92c3395cd36769846f384240"
    },
    {
        "pr_title": "feat(datastore): Multiple inequalities",
        "pr_number": 4311,
        "file_name": "vertexai/function-calling/functioncalling_test.go",
        "code_diff": "@@ -15,7 +15,8 @@\npackage functioncalling\n \n import (\n-\t\"io\"\n+\t\"bytes\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/ds-mieq",
        "commit_id": "ecdb56d65473e97a92c3395cd36769846f384240"
    },
    {
        "pr_title": "feat(datastore): Multiple inequalities",
        "pr_number": 4311,
        "file_name": "vertexai/safety-settings-multimodal/safety-settings-multimodal.go",
        "code_diff": "@@ -26,10 +26,8 @@\nimport (\n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-// generateMultimodalContent generates a response into w, based upon the prompt\n-// and image provided.\n-func generateMultimodalContent(w io.Writer, prompt, image, projectID, location, modelName string) error {\n-\t// prompt := \"describe this image.\"\n+// generateMultimodalContent generates a response into w, based upon the  provided image.\n+func generateMultimodalContent(w io.Writer, image, projectID, location, modelName string) error {\n \t// location := \"us-central1\"\n \t// model := \"gemini-1.5-flash-001\"\n \t// image := \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/ds-mieq",
        "commit_id": "ecdb56d65473e97a92c3395cd36769846f384240"
    },
    {
        "pr_title": "feat(firestore): Multiple inequalities",
        "pr_number": 4310,
        "file_name": "vertexai/multimodal-multiple/multiple-multimodal.go",
        "code_diff": "@@ -12,55 +12,40 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n // multiple-multimodal shows how to generate content from mixed image and text content\n-package main\n+package multiplemultimodal\n \n // [START generativeaionvertexai_gemini_single_turn_multi_image]\n // [START aiplatform_gemini_single_turn_multi_image]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\t\"net/http\"\n-\t\"net/url\"\n-\t\"os\"\n-\t\"strings\"\n+\t\"mime\"\n+\t\"path/filepath\"\n \n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-func main() {\n-\tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n-\tlocation := \"us-central1\"\n-\tmodelName := \"gemini-1.5-flash-001\"\n-\ttemperature := 0.4\n-\n-\tif projectID == \"\" {\n-\t\tlog.Fatal(\"require environment variable GOOGLE_CLOUD_PROJECT\")\n-\t}\n-\n-\t// construct this multimodal prompt:\n-\t// [image of colosseum] city: Rome, Landmark: the Colosseum\n-\t// [image of forbidden city]  city: Beijing, Landmark: the Forbidden City\n-\t// [new image]\n+// generateMultimodalContent shows how to generate a text from a multimodal prompt using the Gemini model,\n+// writing the response to the provided io.Writer.\n+func generateMultimodalContent(w io.Writer, projectID, location, modelName string) error {\n+\t// location := \"us-central1\"\n+\t// modelName := \"gemini-1.5-flash-001\"\n+\tctx := context.Background()\n \n \t// create prompt image parts\n-\t// colosseum\n-\tcolosseum, err := partFromImageURL(\"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark1.png\")\n-\tif err != nil {\n-\t\tlog.Fatalf(\"unable to read image: %v\", err)\n+\tcolosseum := genai.FileData{\n+\t\tMIMEType: mime.TypeByExtension(filepath.Ext(\"landmark1.png\")),\n+\t\tFileURI:  \"gs://cloud-samples-data/vertex-ai/llm/prompts/landmark1.png\",\n \t}\n-\t// forbidden city\n-\tforbiddenCity, err := partFromImageURL(\"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark2.png\")\n-\tif err != nil {\n-\t\tlog.Fatalf(\"unable to read image: %v\", err)\n+\tforbiddenCity := genai.FileData{\n+\t\tMIMEType: mime.TypeByExtension(filepath.Ext(\"landmark2.png\")),\n+\t\tFileURI:  \"gs://cloud-samples-data/vertex-ai/llm/prompts/landmark2.png\",\n \t}\n-\t// new image\n-\tnewImage, err := partFromImageURL(\"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark3.png\")\n-\tif err != nil {\n-\t\tlog.Fatalf(\"unable to read image: %v\", err)\n+\tnewImage := genai.FileData{\n+\t\tMIMEType: mime.TypeByExtension(filepath.Ext(\"landmark3.png\")),\n+\t\tFileURI:  \"gs://cloud-samples-data/vertex-ai/llm/prompts/landmark3.png\",\n \t}\n-\n \t// create a multimodal (multipart) prompt\n \tprompt := []genai.Part{\n \t\tcolosseum,",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/fs-mieq",
        "commit_id": "b594a8b2ff33e4b448391f5a0f5d06b8dec635ea"
    },
    {
        "pr_title": "docs: Create set_mute_undefined_finding sample",
        "pr_number": 4309,
        "file_name": "securitycenter/muteconfig/mute_config_test.go",
        "code_diff": "@@ -252,6 +252,9 @@\nfunc TestSetMuteFinding(t *testing.T) {\n \n func TestSetUnmuteFinding(t *testing.T) {\n \tt.Skip(\"see https://github.com/GoogleCloudPlatform/golang-samples/issues/3793\")\n+\t// Needs more investigation (doesn't match on missing `locations/global`)\n+\t// got:       Mute value for the finding: organizations/688851828130/sources/14743348522722609714/locations/global/findings/updated is UNDEFINED\n+\t// expected:  Mute value for the finding: organizations/688851828130/sources/14743348522722609714/findings/updated is UNDEFINED\n \ttestutil.SystemTest(t)\n \n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_message": "chore: skip test possibly related to #3793",
        "commit_id": "1b927c69578b52763bd5c32afb0f06dbfdee73a0"
    },
    {
        "pr_title": "fix: moving prompt inside sample",
        "pr_number": 4305,
        "file_name": "aiplatform/snippets/embeddings.go",
        "code_diff": "@@ -19,7 +19,7 @@\npackage snippets\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"regexp\"\n+\t\"io\"\n \n \taiplatform \"cloud.google.com/go/aiplatform/apiv1\"\n \t\"cloud.google.com/go/aiplatform/apiv1/aiplatformpb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_token_count",
        "commit_id": "2f6557fa55bee99b74b66a49acdc3d6264d7e07f"
    },
    {
        "pr_title": "fix: moving prompt inside sample",
        "pr_number": 4305,
        "file_name": "aiplatform/snippets/embeddings.go",
        "code_diff": "@@ -28,40 +28,37 @@\nimport (\n \t\"google.golang.org/protobuf/types/known/structpb\"\n )\n \n-func embedTexts(\n-\tproject, location string, texts []string) ([][]float32, error) {\n+// embedTexts shows how embeddings are set for text-embedding-preview-0409 model\n+func embedTexts(w io.Writer, project, location string) error {\n+\t// location := \"us-central1\"\n \tctx := context.Background()\n \n \tapiEndpoint := fmt.Sprintf(\"%s-aiplatform.googleapis.com:443\", location)\n+\tdimensionality := 5\n \tmodel := \"text-embedding-004\"\n-\ttask := \"QUESTION_ANSWERING\"\n-\tcustomOutputDimensionality := 5\n+\ttexts := []string{\"banana muffins? \", \"banana bread? banana muffins?\"}\n \n \tclient, err := aiplatform.NewPredictionClient(ctx, option.WithEndpoint(apiEndpoint))\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn err\n \t}\n \tdefer client.Close()\n \n-\tmatch := regexp.MustCompile(`^(\\w+-\\w+)`).FindStringSubmatch(apiEndpoint)\n-\tif match != nil {\n-\t\tlocation = match[1]\n-\t}\n \tendpoint := fmt.Sprintf(\"projects/%s/locations/%s/publishers/google/models/%s\", project, location, model)\n \tinstances := make([]*structpb.Value, len(texts))\n \tfor i, text := range texts {\n \t\tinstances[i] = structpb.NewStructValue(&structpb.Struct{\n \t\t\tFields: map[string]*structpb.Value{\n \t\t\t\t\"content\":   structpb.NewStringValue(text),\n-\t\t\t\t\"task_type\": structpb.NewStringValue(task),\n+\t\t\t\t\"task_type\": structpb.NewStringValue(\"QUESTION_ANSWERING\"),\n \t\t\t},\n \t\t})\n \t}\n-\toutputDimensionality := structpb.NewNullValue()\n-\toutputDimensionality = structpb.NewNumberValue(float64(customOutputDimensionality))\n \n \tparams := structpb.NewStructValue(&structpb.Struct{\n-\t\tFields: map[string]*structpb.Value{\"outputDimensionality\": outputDimensionality},\n+\t\tFields: map[string]*structpb.Value{\n+\t\t\t\"outputDimensionality\": structpb.NewNumberValue(float64(dimensionality)),\n+\t\t},\n \t})\n \n \treq := &aiplatformpb.PredictRequest{",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_token_count",
        "commit_id": "2f6557fa55bee99b74b66a49acdc3d6264d7e07f"
    },
    {
        "pr_title": "fix: moving prompt inside sample",
        "pr_number": 4305,
        "file_name": "aiplatform/snippets/embeddings.go",
        "code_diff": "@@ -71,7 +68,7 @@\nfunc embedTexts(\n \t}\n \tresp, err := client.Predict(ctx, req)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn err\n \t}\n \tembeddings := make([][]float32, len(resp.Predictions))\n \tfor i, prediction := range resp.Predictions {",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_token_count",
        "commit_id": "2f6557fa55bee99b74b66a49acdc3d6264d7e07f"
    },
    {
        "pr_title": "fix: moving prompt inside sample",
        "pr_number": 4305,
        "file_name": "aiplatform/snippets/embeddings_preview.go",
        "code_diff": "@@ -18,7 +18,7 @@\npackage snippets\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"regexp\"\n+\t\"io\"\n \n \taiplatform \"cloud.google.com/go/aiplatform/apiv1\"\n \t\"cloud.google.com/go/aiplatform/apiv1/aiplatformpb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_token_count",
        "commit_id": "2f6557fa55bee99b74b66a49acdc3d6264d7e07f"
    },
    {
        "pr_title": "fix: moving prompt inside sample",
        "pr_number": 4305,
        "file_name": "aiplatform/snippets/embeddings_preview.go",
        "code_diff": "@@ -29,38 +29,37 @@\nimport (\n \n // Embeds code query with a pre-trained, foundational model by specifying the task type as 'CODE_RETRIEVAL_QUERY'. e.g. 'Retrieve a function that adds two numbers'.\n // Embeds code block with a pre-trained, foundational model by specifying the task type as 'RETRIEVAL_DOCUMENT'. e.g. 'texts := []string{\"def func(a, b): return a + b\", \"def func(a, b): return a - b\", \"def func(a, b): return (a ** 2 + b ** 2) ** 0.5\"}'.\n-func embedTextsPreview(\n-\tapiEndpoint, project, model string, texts []string,\n-\ttask string, dimensionality *int) ([][]float32, error) {\n+// embedTextsPreview shows how embeddings are set for text-embedding-preview-0815 model\n+func embedTextsPreview(w io.Writer, projectID, location string) error {\n+\t// location := \"us-central1\"\n \tctx := context.Background()\n \n+\tapiEndpoint := fmt.Sprintf(\"%s-aiplatform.googleapis.com:443\", location)\n+\tdimensionality := 5\n+\tmodel := \"text-embedding-preview-0815\"\n+\ttexts := []string{\"banana muffins? \", \"banana bread? banana muffins?\"}\n+\n \tclient, err := aiplatform.NewPredictionClient(ctx, option.WithEndpoint(apiEndpoint))\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn err\n \t}\n \tdefer client.Close()\n \n-\tmatch := regexp.MustCompile(`^(\\w+-\\w+)`).FindStringSubmatch(apiEndpoint)\n-\tlocation := \"us-central1\"\n-\tif match != nil {\n-\t\tlocation = match[1]\n-\t}\n-\tendpoint := fmt.Sprintf(\"projects/%s/locations/%s/publishers/google/models/%s\", project, location, model)\n+\tendpoint := fmt.Sprintf(\"projects/%s/locations/%s/publishers/google/models/%s\", projectID, location, model)\n \tinstances := make([]*structpb.Value, len(texts))\n \tfor i, text := range texts {\n \t\tinstances[i] = structpb.NewStructValue(&structpb.Struct{\n \t\t\tFields: map[string]*structpb.Value{\n \t\t\t\t\"content\":   structpb.NewStringValue(text),\n-\t\t\t\t\"task_type\": structpb.NewStringValue(task),\n+\t\t\t\t\"task_type\": structpb.NewStringValue(\"CODE_RETRIEVAL_QUERY\"),\n \t\t\t},\n \t\t})\n \t}\n-\toutputDimensionality := structpb.NewNullValue()\n-\tif dimensionality != nil {\n-\t\toutputDimensionality = structpb.NewNumberValue(float64(*dimensionality))\n-\t}\n+\n \tparams := structpb.NewStructValue(&structpb.Struct{\n-\t\tFields: map[string]*structpb.Value{\"outputDimensionality\": outputDimensionality},\n+\t\tFields: map[string]*structpb.Value{\n+\t\t\t\"outputDimensionality\": structpb.NewNumberValue(float64(dimensionality)),\n+\t\t},\n \t})\n \n \treq := &aiplatformpb.PredictRequest{",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_token_count",
        "commit_id": "2f6557fa55bee99b74b66a49acdc3d6264d7e07f"
    },
    {
        "pr_title": "fix: moving prompt inside sample",
        "pr_number": 4305,
        "file_name": "aiplatform/snippets/embeddings_preview.go",
        "code_diff": "@@ -70,7 +69,7 @@\nfunc embedTextsPreview(\n \t}\n \tresp, err := client.Predict(ctx, req)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn err\n \t}\n \tembeddings := make([][]float32, len(resp.Predictions))\n \tfor i, prediction := range resp.Predictions {",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_token_count",
        "commit_id": "2f6557fa55bee99b74b66a49acdc3d6264d7e07f"
    },
    {
        "pr_title": "fix: moving prompt inside sample",
        "pr_number": 4305,
        "file_name": "aiplatform/snippets/embeddings_test.go",
        "code_diff": "@@ -15,6 +15,8 @@\npackage snippets\n \n import (\n+\t\"bytes\"\n+\t\"fmt\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_token_count",
        "commit_id": "2f6557fa55bee99b74b66a49acdc3d6264d7e07f"
    },
    {
        "pr_title": "fix: moving prompt inside sample",
        "pr_number": 4305,
        "file_name": "run/testing/system_package.e2e_test.go",
        "code_diff": "@@ -15,10 +15,8 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_token_count",
        "commit_id": "2f6557fa55bee99b74b66a49acdc3d6264d7e07f"
    },
    {
        "pr_title": "fix: Adding more complex context for weather and corresponding test",
        "pr_number": 4300,
        "file_name": "vertexai/multimodal-pdf/pdf.go",
        "code_diff": "@@ -25,26 +25,11 @@\nimport (\n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-// pdfPrompt is a sample prompt type consisting of one PDF asset, and a text question.\n-type pdfPrompt struct {\n-\t// pdfPath is a Google Cloud Storage path starting with \"gs://\"\n-\tpdfPath string\n-\t// question asked to the model\n-\tquestion string\n-}\n-\n // generateContentFromPDF generates a response into the provided io.Writer, based upon the PDF\n-// asset and the question provided in the multimodal prompt.\n-func generateContentFromPDF(w io.Writer, prompt pdfPrompt, projectID, location, modelName string) error {\n-\t// prompt := pdfPrompt{\n-\t// \tpdfPath: \"gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf\",\n-\t// \tquestion: `\n-\t// \t\tYou are a very professional document summarization specialist.\n-\t// \t\tPlease summarize the given document.\n-\t// \t`,\n-\t// }\n+func generateContentFromPDF(w io.Writer, projectID, location, modelName string) error {\n \t// location := \"us-central1\"\n \t// modelName := \"gemini-1.5-flash-001\"\n+\n \tctx := context.Background()\n \n \tclient, err := genai.NewClient(ctx, projectID, location)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_function_calling",
        "commit_id": "7523ab3fc9bdbf1701b3f97c5ecc45b25f066161"
    },
    {
        "pr_title": "fix: Adding more complex context for weather and corresponding test",
        "pr_number": 4300,
        "file_name": "vertexai/multimodal-pdf/pdf_test.go",
        "code_diff": "@@ -25,18 +25,11 @@\nimport (\n func Test_generateContentFromPDF(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n-\tprompt := pdfPrompt{\n-\t\tpdfPath: \"gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf\",\n-\t\tquestion: `\n-\t\t\tYou are a very professional document summarization specialist.\n-    \t\tPlease summarize the given document.\n-\t\t`,\n-\t}\n+\tvar buf bytes.Buffer\n \tlocation := \"us-central1\"\n \tmodelName := \"gemini-1.5-flash-001\"\n \n-\terr := generateContentFromPDF(buf, prompt, tc.ProjectID, location, modelName)\n+\terr := generateContentFromPDF(&buf, tc.ProjectID, location, modelName)\n \tif err != nil {\n \t\tt.Errorf(\"Test_generateContentFromPDF: %v\", err.Error())\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_function_calling",
        "commit_id": "7523ab3fc9bdbf1701b3f97c5ecc45b25f066161"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -21,16 +21,30 @@\nimport (\n \t\"os\"\n \t\"reflect\"\n \t\"strings\"\n+\n \t\"testing\"\n \n \tsecretmanager \"cloud.google.com/go/secretmanager/apiv1\"\n \t\"cloud.google.com/go/secretmanager/apiv1/secretmanagerpb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\tregional_secretmanager \"github.com/GoogleCloudPlatform/golang-samples/secretmanager/regional_samples\"\n \t\"github.com/gofrs/uuid\"\n+\t\"google.golang.org/api/option\"\n \tgrpccodes \"google.golang.org/grpc/codes\"\n \tgrpcstatus \"google.golang.org/grpc/status\"\n )\n \n+func testLocation(tb testing.TB) string {\n+\ttb.Helper()\n+\n+\tv := os.Getenv(\"GOLANG_REGIONAL_SAMPLES_LOCATION\")\n+\tif v == \"\" {\n+\t\ttb.Skip(\"testIamUser: missing GOLANG_REGIONAL_SAMPLES_LOCATION\")\n+\t}\n+\n+\treturn v\n+}\n+\n func testClient(tb testing.TB) (*secretmanager.Client, context.Context) {\n \ttb.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -42,6 +56,23 @@\nfunc testClient(tb testing.TB) (*secretmanager.Client, context.Context) {\n \treturn client, ctx\n }\n \n+func testRegionalClient(tb testing.TB) (*secretmanager.Client, context.Context) {\n+\ttb.Helper()\n+\n+\tctx := context.Background()\n+\n+\tlocationId := testLocation(tb)\n+\n+\t//Endpoint to send the request to regional server\n+\tendpoint := fmt.Sprintf(\"secretmanager.%s.rep.googleapis.com:443\", locationId)\n+\tclient, err := secretmanager.NewClient(ctx, option.WithEndpoint(endpoint))\n+\n+\tif err != nil {\n+\t\ttb.Fatalf(\"testRegionalClient: failed to create regional client: %v\", err)\n+\t}\n+\treturn client, ctx\n+}\n+\n func testName(tb testing.TB) string {\n \ttb.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -76,6 +107,24 @@\nfunc testSecret(tb testing.TB, projectID string) *secretmanagerpb.Secret {\n \treturn secret\n }\n \n+func testRegionalSecret(tb testing.TB, projectID string) (*secretmanagerpb.Secret, string) {\n+\ttb.Helper()\n+\n+\tsecretID := testName(tb)\n+\n+\tlocationID := testLocation(tb)\n+\tclient, ctx := testRegionalClient(tb)\n+\tsecret, err := client.CreateSecret(ctx, &secretmanagerpb.CreateSecretRequest{\n+\t\tParent:   fmt.Sprintf(\"projects/%s/locations/%s\", projectID, locationID),\n+\t\tSecretId: secretID,\n+\t})\n+\tif err != nil {\n+\t\ttb.Fatalf(\"testSecret: failed to create secret: %v\", err)\n+\t}\n+\n+\treturn secret, secretID\n+}\n+\n func testSecretVersion(tb testing.TB, parent string, payload []byte) *secretmanagerpb.SecretVersion {\n \ttb.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -93,6 +142,23 @@\nfunc testSecretVersion(tb testing.TB, parent string, payload []byte) *secretmana\n \treturn version\n }\n \n+func testRegionalSecretVersion(tb testing.TB, parent string, payload []byte) *secretmanagerpb.SecretVersion {\n+\ttb.Helper()\n+\n+\tclient, ctx := testRegionalClient(tb)\n+\n+\tversion, err := client.AddSecretVersion(ctx, &secretmanagerpb.AddSecretVersionRequest{\n+\t\tParent: parent,\n+\t\tPayload: &secretmanagerpb.SecretPayload{\n+\t\t\tData: payload,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\ttb.Fatalf(\"testSecretVersion: failed to create regional secret version: %v\", err)\n+\t}\n+\treturn version\n+}\n+\n func testCleanupSecret(tb testing.TB, name string) {\n \ttb.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -107,6 +173,20 @@\nfunc testCleanupSecret(tb testing.TB, name string) {\n \t}\n }\n \n+func testCleanupRegionalSecret(tb testing.TB, name string) {\n+\ttb.Helper()\n+\n+\tclient, ctx := testRegionalClient(tb)\n+\n+\tif err := client.DeleteSecret(ctx, &secretmanagerpb.DeleteSecretRequest{\n+\t\tName: name,\n+\t}); err != nil {\n+\t\tif terr, ok := grpcstatus.FromError(err); !ok || terr.Code() != grpccodes.NotFound {\n+\t\t\ttb.Fatalf(\"testCleanupSecret: failed to delete regional secret: %v\", err)\n+\t\t}\n+\t}\n+}\n+\n func testIamUser(tb testing.TB) string {\n \ttb.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -137,6 +217,27 @@\nfunc TestAccessSecretVersion(t *testing.T) {\n \t}\n }\n \n+func TestAccessRegionalSecretVersion(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tpayload := []byte(\"my-secret\")\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\ttestRegionalSecretVersion(t, secret.Name, payload)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.AccessRegionalSecretVersion(&b, tc.ProjectID, locationID, secretID, \"1\"); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), string(payload); !strings.Contains(got, want) {\n+\t\tt.Errorf(\"accessRegionalSecretVersion: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestAddSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -153,6 +254,24 @@\nfunc TestAddSecretVersion(t *testing.T) {\n \t}\n }\n \n+func TestAddRegionalSecretVersion(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.AddRegionalSecretVersion(&b, tc.ProjectID, locationID, secretID); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Added regional secret version:\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"addSecretVersion: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestConsumeEventNotification(t *testing.T) {\n \tv, err := ConsumeEventNotification(context.Background(), PubSubMessage{\n \t\tAttributes: PubSubAttributes{",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -188,6 +307,24 @@\nfunc TestCreateSecret(t *testing.T) {\n \t}\n }\n \n+func TestCreateRegionalSecret(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecretID := \"createRegionalSecret\"\n+\tlocationID := testLocation(t)\n+\n+\tdefer testCleanupRegionalSecret(t, fmt.Sprintf(\"projects/%s/locations/%s/secrets/%s\", tc.ProjectID, locationID, secretID))\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.CreateRegionalSecret(&b, tc.ProjectID, locationID, secretID); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Created regional secret:\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"createSecret: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestCreateUserManagedReplicationSecret(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -226,6 +363,27 @@\nfunc TestDeleteSecret(t *testing.T) {\n \t}\n }\n \n+func TestDeleteRegionalSecret(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret, secretId := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tif err := regional_secretmanager.DeleteRegionalSecret(tc.ProjectID, locationID, secretId); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testRegionalClient(t)\n+\t_, err := client.GetSecret(ctx, &secretmanagerpb.GetSecretRequest{\n+\t\tName: secret.Name,\n+\t})\n+\tif terr, ok := grpcstatus.FromError(err); !ok || terr.Code() != grpccodes.NotFound {\n+\t\tt.Errorf(\"deleteRegionalSecret: expected %v to be not found\", err)\n+\t}\n+}\n+\n func TestDeleteSecretWithEtag(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -245,6 +403,27 @@\nfunc TestDeleteSecretWithEtag(t *testing.T) {\n \t}\n }\n \n+func TestDeleteRegionalSecretWithEtag(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret, secretId := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tif err := regional_secretmanager.DeleteRegionalSecretWithEtag(tc.ProjectID, locationID, secretId, secret.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testRegionalClient(t)\n+\t_, err := client.GetSecret(ctx, &secretmanagerpb.GetSecretRequest{\n+\t\tName: secret.Name,\n+\t})\n+\tif terr, ok := grpcstatus.FromError(err); !ok || terr.Code() != grpccodes.NotFound {\n+\t\tt.Errorf(\"deleteRegionalSecret: expected %v to be not found\", err)\n+\t}\n+}\n+\n func TestDestroySecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -270,6 +449,33 @@\nfunc TestDestroySecretVersion(t *testing.T) {\n \t}\n }\n \n+func TestDestroyRegionalSecretVersion(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tpayload := []byte(\"my-secret\")\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tversion := testRegionalSecretVersion(t, secret.Name, payload)\n+\n+\tif err := regional_secretmanager.DestroyRegionalSecretVersion(tc.ProjectID, locationID, secretID, \"1\"); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testRegionalClient(t)\n+\tv, err := client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_DESTROYED; got != want {\n+\t\tt.Errorf(\"testRegionalSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+}\n+\n func TestDestroySecretVersionWithEtag(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tpayload := []byte(\"my-secret\")",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -294,6 +500,32 @@\nfunc TestDestroySecretVersionWithEtag(t *testing.T) {\n \t}\n }\n \n+func TestDestroyRegionalSecretVersionWithEtag(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tpayload := []byte(\"my-secret\")\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tversion := testRegionalSecretVersion(t, secret.Name, payload)\n+\n+\tif err := regional_secretmanager.DestroyRegionalSecretVersionWithEtag(tc.ProjectID, locationID, secretID, \"1\", version.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testRegionalClient(t)\n+\tv, err := client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_DESTROYED; got != want {\n+\t\tt.Errorf(\"testRegionalSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+}\n+\n func TestDisableEnableSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -333,6 +565,47 @@\nfunc TestDisableEnableSecretVersion(t *testing.T) {\n \t}\n }\n \n+func TestDisableEnableRegionalSecretVersion(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tpayload := []byte(\"my-secret\")\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tversion := testRegionalSecretVersion(t, secret.Name, payload)\n+\n+\tif err := regional_secretmanager.DisableRegionalSecretVersion(tc.ProjectID, locationID, secretID, \"1\"); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testRegionalClient(t)\n+\tv, err := client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_DISABLED; got != want {\n+\t\tt.Errorf(\"testRegionalSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+\n+\tif err := regional_secretmanager.EnableRegionalSecretVersion(tc.ProjectID, locationID, secretID, \"1\"); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tv, err = client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_ENABLED; got != want {\n+\t\tt.Errorf(\"testRegionalSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+}\n+\n func TestDisableEnableSecretVersionWithEtag(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -372,6 +645,47 @@\nfunc TestDisableEnableSecretVersionWithEtag(t *testing.T) {\n \t}\n }\n \n+func TestDisableEnableRegionalSecretVersionWithEtag(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tpayload := []byte(\"my-secret\")\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationId := testLocation(t)\n+\n+\tversion := testRegionalSecretVersion(t, secret.Name, payload)\n+\n+\tif err := regional_secretmanager.DisableRegionalSecretVersionWithEtag(tc.ProjectID, locationId, secretID, \"1\", version.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testRegionalClient(t)\n+\tv, err := client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_DISABLED; got != want {\n+\t\tt.Errorf(\"testRegionalSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+\n+\tif err := regional_secretmanager.EnableRegionalSecretVersionWithEtag(tc.ProjectID, locationId, secretID, \"1\", v.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tv, err = client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_ENABLED; got != want {\n+\t\tt.Errorf(\"testRegionalSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+}\n+\n func TestGetSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -391,6 +705,27 @@\nfunc TestGetSecretVersion(t *testing.T) {\n \t}\n }\n \n+func TestGetRegionalSecretVersion(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tpayload := []byte(\"my-secret\")\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\ttestRegionalSecretVersion(t, secret.Name, payload)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.GetRegionalSecretVersion(&b, tc.ProjectID, locationID, secretID, \"1\"); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Found regional secret version\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"testRegionalSecretVersion: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestGetSecret(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -407,6 +742,24 @@\nfunc TestGetSecret(t *testing.T) {\n \t}\n }\n \n+func TestGetRegionalSecret(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret, secretdID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.GetRegionalSecret(&b, tc.ProjectID, locationID, secretdID); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Found regional secret\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"getRegionalSecret: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestIamGrantAccess(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -443,6 +796,44 @@\nfunc TestIamGrantAccess(t *testing.T) {\n \t}\n }\n \n+func TestIamGrantAccessWithRegionalSecret(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tiamUser := testIamUser(t)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.IamGrantAccessWithRegionalSecret(&b, tc.ProjectID, locationID, secretID, iamUser); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Updated IAM policy\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"getRegionalSecret: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tclient, ctx := testRegionalClient(t)\n+\tpolicy, err := client.IAM(secret.Name).Policy(ctx)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tfound := false\n+\tmembers := policy.Members(\"roles/secretmanager.secretAccessor\")\n+\tfor _, m := range members {\n+\t\tif m == iamUser {\n+\t\t\tfound = true\n+\t\t}\n+\t}\n+\n+\tif !found {\n+\t\tt.Errorf(\"expected %q to include %q\", members, iamUser)\n+\t}\n+}\n+\n func TestIamRevokeAccess(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -474,6 +865,39 @@\nfunc TestIamRevokeAccess(t *testing.T) {\n \t}\n }\n \n+func TestIamRevokeAccessWithRegionalSecret(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tiamUser := testIamUser(t)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.IamRevokeAccessWithRegionalSecret(&b, tc.ProjectID, locationID, secretID, iamUser); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Updated IAM policy\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"getRegionalSecret: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tclient, ctx := testRegionalClient(t)\n+\tpolicy, err := client.IAM(secret.Name).Policy(ctx)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tmembers := policy.Members(\"roles/secretmanager.secretAccessor\")\n+\tfor _, m := range members {\n+\t\tif m == iamUser {\n+\t\t\tt.Errorf(\"expected %q to not include %q\", members, iamUser)\n+\t\t}\n+\t}\n+}\n+\n func TestListSecretVersions(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -498,6 +922,32 @@\nfunc TestListSecretVersions(t *testing.T) {\n \t}\n }\n \n+func TestListRegionalSecretVersions(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tpayload := []byte(\"my-secret\")\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tversion1 := testRegionalSecretVersion(t, secret.Name, payload)\n+\tversion2 := testRegionalSecretVersion(t, secret.Name, payload)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.ListRegionalSecretVersions(&b, tc.ProjectID, locationID, secretID); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), fmt.Sprintf(\"%s with state ENABLED\", version1.Name); !strings.Contains(got, want) {\n+\t\tt.Errorf(\"listSecretVersions: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tif got, want := b.String(), fmt.Sprintf(\"%s with state ENABLED\", version2.Name); !strings.Contains(got, want) {\n+\t\tt.Errorf(\"listSecretVersions: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestListSecretVersionsWithFilter(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -522,6 +972,32 @@\nfunc TestListSecretVersionsWithFilter(t *testing.T) {\n \t}\n }\n \n+func TestListRegionalSecretVersionsWithFilter(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tpayload := []byte(\"my-secret\")\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tversion1 := testRegionalSecretVersion(t, secret.Name, payload)\n+\tversion2 := testRegionalSecretVersion(t, secret.Name, payload)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.ListRegionalSecretVersionsWithFilter(&b, tc.ProjectID, locationID, secretID, fmt.Sprintf(\"name:%s\", version1.Name)); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), fmt.Sprintf(\"%s with state ENABLED\", version1.Name); !strings.Contains(got, want) {\n+\t\tt.Errorf(\"listSecretVersions: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tif got, lacked := b.String(), fmt.Sprintf(\"%s with state ENABLED\", version2.Name); strings.Contains(got, lacked) {\n+\t\tt.Errorf(\"listSecretVersions: expected %q to not contain %q\", got, lacked)\n+\t}\n+}\n+\n func TestListSecrets(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -545,6 +1021,31 @@\nfunc TestListSecrets(t *testing.T) {\n \t}\n }\n \n+func TestListRegionalSecrets(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret1, _ := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret1.Name)\n+\n+\tsecret2, _ := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret2.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.ListRegionalSecrets(&b, tc.ProjectID, locationID); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), secret1.Name; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"listRegionalSecrets: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tif got, want := b.String(), secret2.Name; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"listRegionalSecrets: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestListSecretsWithFilter(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -568,6 +1069,31 @@\nfunc TestListSecretsWithFilter(t *testing.T) {\n \t}\n }\n \n+func TestListRegionalSecretsWithFilter(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret1, _ := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret1.Name)\n+\n+\tsecret2, _ := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret2.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.ListRegionalSecretsWithFilter(&b, tc.ProjectID, locationID, fmt.Sprintf(\"name:%s\", secret1.Name)); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), secret1.Name; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"listRegionalSecrets: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tif got, lacked := b.String(), secret2.Name; strings.Contains(got, lacked) {\n+\t\tt.Errorf(\"listRegionalSecrets: expected %q to not contain %q\", got, lacked)\n+\t}\n+}\n+\n func TestUpdateSecret(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -596,6 +1122,36 @@\nfunc TestUpdateSecret(t *testing.T) {\n \t}\n }\n \n+func TestRegionalUpdateSecret(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.UpdateRegionalSecret(&b, tc.ProjectID, locationID, secretID); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Updated regional secret\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"updateRegionalSecret: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tclient, ctx := testRegionalClient(t)\n+\ts, err := client.GetSecret(ctx, &secretmanagerpb.GetSecretRequest{\n+\t\tName: secret.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := s.Labels, map[string]string{\"secretmanager\": \"rocks\"}; !reflect.DeepEqual(got, want) {\n+\t\tt.Errorf(\"updateRegionalSecret: expected %q to be %q\", got, want)\n+\t}\n+}\n+\n func TestUpdateSecretWithEtag(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -624,6 +1180,36 @@\nfunc TestUpdateSecretWithEtag(t *testing.T) {\n \t}\n }\n \n+func TestUpdateRegionalSecretWithEtag(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret, secretID := testRegionalSecret(t, tc.ProjectID)\n+\tdefer testCleanupRegionalSecret(t, secret.Name)\n+\n+\tlocationID := testLocation(t)\n+\n+\tvar b bytes.Buffer\n+\tif err := regional_secretmanager.UpdateRegionalSecretWithEtag(&b, tc.ProjectID, locationID, secretID, secret.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Updated regional secret\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"updateRegionalSecret: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tclient, ctx := testRegionalClient(t)\n+\ts, err := client.GetSecret(ctx, &secretmanagerpb.GetSecretRequest{\n+\t\tName: secret.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := s.Labels, map[string]string{\"secretmanager\": \"rocks\"}; !reflect.DeepEqual(got, want) {\n+\t\tt.Errorf(\"updateRegionalSecret: expected %q to be %q\", got, want)\n+\t}\n+}\n+\n func TestUpdateSecretWithAlias(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_generativeaionvertexai_gemini_pdf",
        "commit_id": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "media/videostitcher/create_vod_session.go",
        "code_diff": "@@ -26,18 +26,9 @@\nimport (\n \n // createVodSession creates a video on demand (VOD) session in which to insert ads.\n // VOD sessions are ephemeral resources that expire after a few hours.\n-func createVodSession(w io.Writer, projectID, sourceURI string) error {\n+func createVodSession(w io.Writer, projectID, vodConfigID string) error {\n \t// projectID := \"my-project-id\"\n-\n-\t// Uri of the media to stitch; this URI must reference either an MPEG-DASH\n-\t// manifest (.mpd) file or an M3U playlist manifest (.m3u8) file.\n-\t// sourceURI := \"https://storage.googleapis.com/my-bucket/main.mpd\"\n-\n-\t// See https://cloud.google.com/video-stitcher/docs/concepts for information\n-\t// on ad tags and ad metadata. This sample uses an ad tag URL that displays\n-\t// a VMAP Pre-roll ad\n-\t// (https://developers.google.com/interactive-media-ads/docs/sdks/html5/client-side/tags).\n-\tadTagURI := \"https://pubads.g.doubleclick.net/gampad/ads?iu=/21775744923/external/vmap_ad_samples&sz=640x480&cust_params=sample_ar%3Dpreonly&ciu_szs=300x250%2C728x90&gdfp_req=1&ad_rule=1&output=vmap&unviewed_position_start=1&env=vp&impl=s&correlator=\"\n+\t// vodConfigID := \"my-vod-config-id\"\n \tlocation := \"us-central1\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -49,8 +49,11 @@\nconst (\n \tupdatedHostname      = \"updated.cdn.example.com\"\n \tkeyName              = \"my-key\"\n \n-\tvodURI      = \"https://storage.googleapis.com/cloud-samples-data/media/hls-vod/manifest.m3u8\"\n-\tvodAdTagURI = \"https://pubads.g.doubleclick.net/gampad/ads?iu=/21775744923/external/vmap_ad_samples&sz=640x480&cust_params=sample_ar%3Dpreonly&ciu_szs=300x250%2C728x90&gdfp_req=1&ad_rule=1&output=vmap&unviewed_position_start=1&env=vp&impl=s&correlator=\"\n+\tvodConfigIDPrefix       = \"go-test-vod-config\"\n+\tdeleteVodConfigResponse = \"Deleted VOD config\"\n+\tvodURI                  = \"https://storage.googleapis.com/cloud-samples-data/media/hls-vod/manifest.m3u8\"\n+\tupdatedVodURI           = \"https://storage.googleapis.com/cloud-samples-data/media/hls-vod/manifest.mpd\"\n+\tvodAdTagURI             = \"https://pubads.g.doubleclick.net/gampad/ads?iu=/21775744923/external/vmap_ad_samples&sz=640x480&cust_params=sample_ar%3Dpreonly&ciu_szs=300x250%2C728x90&gdfp_req=1&ad_rule=1&output=vmap&unviewed_position_start=1&env=vp&impl=s&correlator=\"\n \n \tliveConfigIDPrefix       = \"go-test-live-config\"\n \tdeleteLiveConfigResponse = \"Deleted live config\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -196,6 +199,43 @@\nfunc cleanStaleResources(projectID string) {\n \t\t\t}\n \t\t}\n \t}\n+\n+\t// VOD configs\n+\treq4 := &stitcherstreampb.ListVodConfigsRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n+\t}\n+\n+\tit4 := client.ListVodConfigs(ctx, req4)\n+\n+\tfor {\n+\t\tresponse, err := it4.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tlog.Printf(\"Can't find next VOD config: %s\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\tif strings.Contains(response.GetName(), vodConfigIDPrefix) {\n+\n+\t\t\tarr := strings.Split(response.GetName(), \"-\")\n+\t\t\tt := arr[len(arr)-1]\n+\t\t\tif isResourceStale(t) == true {\n+\t\t\t\treq := &stitcherstreampb.DeleteVodConfigRequest{\n+\t\t\t\t\tName: response.GetName(),\n+\t\t\t\t}\n+\t\t\t\t// Deletes the VOD config.\n+\t\t\t\top, err := client.DeleteVodConfig(ctx, req)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tlog.Printf(\"cleanStaleResources DeleteVodConfig: %s\", err)\n+\t\t\t\t}\n+\t\t\t\terr = op.Wait(ctx)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tlog.Printf(\"cleanStaleResources Wait: %s\", err)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n }\n \n func isResourceStale(timestamp string) bool {",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -314,6 +354,58 @@\nfunc deleteTestSlate(slateName string, t *testing.T) {\n \t}\n }\n \n+func createTestVodConfig(vodConfigID string, t *testing.T) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\n+\tclient, err := stitcher.NewVideoStitcherClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"stitcher.NewVideoStitcherClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\ttc := testutil.SystemTest(t)\n+\treq := &stitcherstreampb.CreateVodConfigRequest{\n+\t\tParent:      fmt.Sprintf(\"projects/%s/locations/%s\", tc.ProjectID, location),\n+\t\tVodConfigId: vodConfigID,\n+\t\tVodConfig: &stitcherstreampb.VodConfig{\n+\t\t\tSourceUri: vodURI,\n+\t\t\tAdTagUri:  vodAdTagURI,\n+\t\t},\n+\t}\n+\top, err := client.CreateVodConfig(ctx, req)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\t_, err = op.Wait(ctx)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+}\n+\n+func deleteTestVodConfig(vodConfigName string, t *testing.T) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := stitcher.NewVideoStitcherClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"stitcher.NewVideoStitcherClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\t// Delete the VOD config.\n+\treq := &stitcherstreampb.DeleteVodConfigRequest{\n+\t\tName: vodConfigName,\n+\t}\n+\top, err := client.DeleteVodConfig(ctx, req)\n+\tif err != nil {\n+\t\tt.Errorf(\"client.DeleteVodConfig: %v\", err)\n+\t}\n+\terr = op.Wait(ctx)\n+\tif err != nil {\n+\t\tt.Error(err)\n+\t}\n+}\n+\n func createTestLiveConfig(slateID, liveConfigID string, t *testing.T) {\n \tt.Helper()\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -469,7 +561,7 @@\nfunc createTestLiveSession(liveConfigID string, t *testing.T) (string, string) {\n \treturn sessionID, playURI\n }\n \n-func createTestVodSession(t *testing.T) string {\n+func createTestVodSession(vodConfigID string, t *testing.T) string {\n \tt.Helper()\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -48,6 +48,7 @@\ntype instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string) error\n type backupSampleFuncWithoutContext func(w io.Writer, dbName, backupID string) error\n type createBackupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string, versionTime time.Time) error\n+type instancePartitionSampleFunc func(w io.Writer, projectID, instanceID, instancePartitionID string) error\n \n var (\n \tvalidInstancePattern = regexp.MustCompile(\"^projects/(?P<project>[^/]+)/instances/(?P<instance>[^/]+)$\")",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -60,7 +61,8 @@\nfunc initTest(t *testing.T, id string) (instName, dbName string, cleanup func())\n \t\tconfigName = \"regional-us-central1\"\n \t}\n \tlog.Printf(\"Running test by using the instance config: %s\\n\", configName)\n-\tinstName, cleanup = createTestInstance(t, projectID, configName)\n+\tinstanceID, cleanup := createTestInstance(t, projectID, configName)\n+\tinstName = fmt.Sprintf(\"projects/%s/instances/%s\", projectID, instanceID)\n \tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n \tdbName = fmt.Sprintf(\"%s/databases/%s\", instName, dbID)",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -69,7 +71,8 @@\nfunc initTest(t *testing.T, id string) (instName, dbName string, cleanup func())\n \n func initTestWithConfig(t *testing.T, id string, instanceConfigName string) (instName, dbName string, cleanup func()) {\n \tprojectID := getSampleProjectId(t)\n-\tinstName, cleanup = createTestInstance(t, projectID, instanceConfigName)\n+\tinstanceID, cleanup := createTestInstance(t, projectID, instanceConfigName)\n+\tinstName = fmt.Sprintf(\"projects/%s/instances/%s\", projectID, instanceID)\n \tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n \tdbName = fmt.Sprintf(\"%s/databases/%s\", instName, dbID)",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -109,6 +112,14 @@\nfunc initBackupTest(t *testing.T, id, instName string) (restoreDBName, backupID,\n \treturn\n }\n \n+func initInstancePartitionTest(t *testing.T, id string) (string, string, string, func()) {\n+\tprojectID := getSampleProjectId(t)\n+\tinstancePartitionID := fmt.Sprintf(\"instance-partition-%s\", id)\n+\tinstanceID, cleanup := createTestInstance(t, projectID, \"regional-us-central1\")\n+\n+\treturn projectID, instanceID, instancePartitionID, cleanup\n+}\n+\n func TestCreateInstances(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n \tt.Parallel()",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -465,6 +476,19 @@\nfunc TestBackupSample(t *testing.T) {\n \tassertContains(t, out, fmt.Sprintf(\"Deleted backup %s\", backupID))\n }\n \n+func TestInstancePartitionSample(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\tid := randomID()\n+\tprojectID, instanceID, instancePartitionID, cleanup := initInstancePartitionTest(t, id)\n+\tdefer cleanup()\n+\n+\tvar out string\n+\tout = runInstancePartitionSample(t, createInstancePartition, projectID, instanceID, instancePartitionID, \"failed to create an instance partition\")\n+\tassertContains(t, out, fmt.Sprintf(\"Created instance partition [%s]\", instancePartitionID))\n+}\n+\n func TestCreateDatabaseWithRetentionPeriodSample(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n \tt.Parallel()",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -1204,6 +1228,14 @@\nfunc runBackupSampleWithRetry(ctx context.Context, t *testing.T, f backupSampleF\n \treturn b.String()\n }\n \n+func runInstancePartitionSample(t *testing.T, f instancePartitionSampleFunc, projectID, instanceID, instancePartitionID, errMsg string) string {\n+\tvar b bytes.Buffer\n+\tif err := f(&b, projectID, instanceID, instancePartitionID); err != nil {\n+\t\tt.Errorf(\"%s: %v\", errMsg, err)\n+\t}\n+\treturn b.String()\n+}\n+\n func runInstanceSample(t *testing.T, f instanceSampleFunc, projectID, instanceID, errMsg string) string {\n \tvar b bytes.Buffer",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(securitymarksv2): Add Security Marks v2 Go Client Libraries/ Samples",
        "pr_number": 4273,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -1233,10 +1265,10 @@\nfunc mustRunSample(t *testing.T, f sampleFuncWithContext, dbName, errMsg string)\n \treturn b.String()\n }\n \n-func createTestInstance(t *testing.T, projectID string, instanceConfigName string) (instanceName string, cleanup func()) {\n+func createTestInstance(t *testing.T, projectID string, instanceConfigName string) (instanceID string, cleanup func()) {\n \tctx := context.Background()\n-\tinstanceID := fmt.Sprintf(\"go-sample-%s\", uuid.New().String()[:16])\n-\tinstanceName = fmt.Sprintf(\"projects/%s/instances/%s\", projectID, instanceID)\n+\tinstanceID = fmt.Sprintf(\"go-sample-%s\", uuid.New().String()[:16])\n+\tinstanceName := fmt.Sprintf(\"projects/%s/instances/%s\", projectID, instanceID)\n \tinstanceAdmin, err := instance.NewInstanceAdminClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create InstanceAdminClient: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'main' into security-marks-v2",
        "commit_id": "d8aecde4c544af01540dd209b9380d8883547cb2"
    },
    {
        "pr_title": "feat(findings): Add findings v2 resources",
        "pr_number": 4270,
        "file_name": "securitycenter/findingsv2/findings_test.go",
        "code_diff": "@@ -71,7 +71,7 @@\nfunc createTestFinding(ctx context.Context, client *securitycenter.Client, findi\n \t\t},\n \t}\n \n-  finding, err := client.CreateFinding(ctx, req)\n+\tfinding, err := client.CreateFinding(ctx, req)\n \n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"CreateFinding: %w\", err)",
        "comments": [
            {
                "comment": "this PR includes the `createSource` function, which does this work. can we use it here to avoid code duplication?",
                "position": null
            },
            {
                "comment": "I suggest using buf.Reset() here. while the effect is the same, a \"Reset\" is more readable.",
                "position": null
            },
            {
                "comment": "Addressed",
                "position": null
            },
            {
                "comment": "Addressed.",
                "position": null
            },
            {
                "comment": "Hi @vijaykanthm, in an effort to be more idiomatic and consistent with other samples, please refactor to `var buf bytes.Buffer` (and update usages appropriately, like line 273). Rather than comment on all the instances, please just search and replace all of them in the PR. Thanks!",
                "position": null
            },
            {
                "comment": "Thank you, addressed.",
                "position": null
            }
        ],
        "commit_message": "Fix lint issue",
        "commit_id": "a0ff30c5a5484683b5dd91cfe8f0804aa487b1d0"
    },
    {
        "pr_title": "feat(findings): Add findings v2 resources",
        "pr_number": 4270,
        "file_name": "securitycenter/findingsv2/findings_test.go",
        "code_diff": "@@ -321,9 +321,9 @@\nfunc TestCreateFinding(t *testing.T) {\n \n \t\tif err != nil {\n \t\t\tr.Errorf(\"createFinding(%s) had error: %v\", sourceName, err)\n-      \treturn\n+\t\t\treturn\n \t\t}\n-    got := buf.String()\n+\t\tgot := buf.String()\n \t\tif want := fmt.Sprintf(\"%s/locations/global/findings/samplefindingid\", sourceName); !strings.Contains(got, want) {\n \t\t\tr.Errorf(\"createFinding(%s) got: %s want %s\", sourceName, got, want)\n \t\t}",
        "comments": [
            {
                "comment": "this PR includes the `createSource` function, which does this work. can we use it here to avoid code duplication?",
                "position": null
            },
            {
                "comment": "I suggest using buf.Reset() here. while the effect is the same, a \"Reset\" is more readable.",
                "position": null
            },
            {
                "comment": "Addressed",
                "position": null
            },
            {
                "comment": "Addressed.",
                "position": null
            },
            {
                "comment": "Hi @vijaykanthm, in an effort to be more idiomatic and consistent with other samples, please refactor to `var buf bytes.Buffer` (and update usages appropriately, like line 273). Rather than comment on all the instances, please just search and replace all of them in the PR. Thanks!",
                "position": null
            },
            {
                "comment": "Thank you, addressed.",
                "position": null
            }
        ],
        "commit_message": "Fix lint issue",
        "commit_id": "a0ff30c5a5484683b5dd91cfe8f0804aa487b1d0"
    },
    {
        "pr_title": "feat(findings): Add findings v2 resources",
        "pr_number": 4270,
        "file_name": "securitycenter/findingsv2/findings_test.go",
        "code_diff": "@@ -353,8 +353,8 @@\nfunc TestUpdateFindingSourceProperties(t *testing.T) {\n \t\t\tr.Errorf(\"updateFindingSourceProperties(%s) had error: %v\", finding.Name, err)\n \t\t\treturn\n \t\t}\n-    \n-    got := buf.String()\n+\n+\t\tgot := buf.String()\n \t\tif want := \"s_value\"; !strings.Contains(got, want) {\n \t\t\tr.Errorf(\"updateFindingSourceProperties(%s) got: %s want %s\", finding.Name, got, want)\n \t\t}",
        "comments": [
            {
                "comment": "this PR includes the `createSource` function, which does this work. can we use it here to avoid code duplication?",
                "position": null
            },
            {
                "comment": "I suggest using buf.Reset() here. while the effect is the same, a \"Reset\" is more readable.",
                "position": null
            },
            {
                "comment": "Addressed",
                "position": null
            },
            {
                "comment": "Addressed.",
                "position": null
            },
            {
                "comment": "Hi @vijaykanthm, in an effort to be more idiomatic and consistent with other samples, please refactor to `var buf bytes.Buffer` (and update usages appropriately, like line 273). Rather than comment on all the instances, please just search and replace all of them in the PR. Thanks!",
                "position": null
            },
            {
                "comment": "Thank you, addressed.",
                "position": null
            }
        ],
        "commit_message": "Fix lint issue",
        "commit_id": "a0ff30c5a5484683b5dd91cfe8f0804aa487b1d0"
    },
    {
        "pr_title": "feat(findings): Add findings v2 resources",
        "pr_number": 4270,
        "file_name": "securitycenter/findingsv2/findings_test.go",
        "code_diff": "@@ -363,7 +363,7 @@\nfunc TestUpdateFindingSourceProperties(t *testing.T) {\n \t\t}\n \t})\n }\n-    \n+\n func TestListFilteredFindings(t *testing.T) {\n \tsetup(t)\n \ttestutil.Retry(t, 5, 20*time.Second, func(r *testutil.R) {",
        "comments": [
            {
                "comment": "this PR includes the `createSource` function, which does this work. can we use it here to avoid code duplication?",
                "position": null
            },
            {
                "comment": "I suggest using buf.Reset() here. while the effect is the same, a \"Reset\" is more readable.",
                "position": null
            },
            {
                "comment": "Addressed",
                "position": null
            },
            {
                "comment": "Addressed.",
                "position": null
            },
            {
                "comment": "Hi @vijaykanthm, in an effort to be more idiomatic and consistent with other samples, please refactor to `var buf bytes.Buffer` (and update usages appropriately, like line 273). Rather than comment on all the instances, please just search and replace all of them in the PR. Thanks!",
                "position": null
            },
            {
                "comment": "Thank you, addressed.",
                "position": null
            }
        ],
        "commit_message": "Fix lint issue",
        "commit_id": "a0ff30c5a5484683b5dd91cfe8f0804aa487b1d0"
    },
    {
        "pr_title": "feat(findings): Add findings v2 resources",
        "pr_number": 4270,
        "file_name": "securitycenter/findingsv2/findings_test.go",
        "code_diff": "@@ -373,7 +373,7 @@\nfunc TestListFilteredFindings(t *testing.T) {\n \n \t\tif err != nil {\n \t\t\tr.Errorf(\"listFilteredFindings(%s) had error: %v\", sourceName, err)\n-      return\n+\t\t\treturn\n \t\t}\n \t\tgot := buf.String()\n \t\tif !strings.Contains(got, findingName) {",
        "comments": [
            {
                "comment": "this PR includes the `createSource` function, which does this work. can we use it here to avoid code duplication?",
                "position": null
            },
            {
                "comment": "I suggest using buf.Reset() here. while the effect is the same, a \"Reset\" is more readable.",
                "position": null
            },
            {
                "comment": "Addressed",
                "position": null
            },
            {
                "comment": "Addressed.",
                "position": null
            },
            {
                "comment": "Hi @vijaykanthm, in an effort to be more idiomatic and consistent with other samples, please refactor to `var buf bytes.Buffer` (and update usages appropriately, like line 273). Rather than comment on all the instances, please just search and replace all of them in the PR. Thanks!",
                "position": null
            },
            {
                "comment": "Thank you, addressed.",
                "position": null
            }
        ],
        "commit_message": "Fix lint issue",
        "commit_id": "a0ff30c5a5484683b5dd91cfe8f0804aa487b1d0"
    },
    {
        "pr_title": "feat(findings): Add findings v2 resources",
        "pr_number": 4270,
        "file_name": "securitycenter/findingsv2/findings_test.go",
        "code_diff": "@@ -459,8 +459,6 @@\nfunc TestGroupFindings(t *testing.T) {\n \t})\n }\n \n-\n-\n func TestSetFindingState(t *testing.T) {\n \tsetup(t)\n \ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {",
        "comments": [
            {
                "comment": "this PR includes the `createSource` function, which does this work. can we use it here to avoid code duplication?",
                "position": null
            },
            {
                "comment": "I suggest using buf.Reset() here. while the effect is the same, a \"Reset\" is more readable.",
                "position": null
            },
            {
                "comment": "Addressed",
                "position": null
            },
            {
                "comment": "Addressed.",
                "position": null
            },
            {
                "comment": "Hi @vijaykanthm, in an effort to be more idiomatic and consistent with other samples, please refactor to `var buf bytes.Buffer` (and update usages appropriately, like line 273). Rather than comment on all the instances, please just search and replace all of them in the PR. Thanks!",
                "position": null
            },
            {
                "comment": "Thank you, addressed.",
                "position": null
            }
        ],
        "commit_message": "Fix lint issue",
        "commit_id": "a0ff30c5a5484683b5dd91cfe8f0804aa487b1d0"
    },
    {
        "pr_title": "feat(findings): Add findings v2 resources",
        "pr_number": 4270,
        "file_name": "securitycenter/findingsv2/findings_test.go",
        "code_diff": "@@ -483,8 +481,8 @@\nfunc TestSetFindingState(t *testing.T) {\n \t\t\tr.Errorf(\"setFindingState(%s) had error: %v\", finding.Name, err)\n \t\t\treturn\n \t\t}\n-    \n-    got := buf.String()\n+\n+\t\tgot := buf.String()\n \t\tif want := \"INACTIVE\"; !strings.Contains(got, want) {\n \t\t\tr.Errorf(\"setFindingState(%s) got: %s want %s\", finding.Name, got, want)\n \t\t}",
        "comments": [
            {
                "comment": "this PR includes the `createSource` function, which does this work. can we use it here to avoid code duplication?",
                "position": null
            },
            {
                "comment": "I suggest using buf.Reset() here. while the effect is the same, a \"Reset\" is more readable.",
                "position": null
            },
            {
                "comment": "Addressed",
                "position": null
            },
            {
                "comment": "Addressed.",
                "position": null
            },
            {
                "comment": "Hi @vijaykanthm, in an effort to be more idiomatic and consistent with other samples, please refactor to `var buf bytes.Buffer` (and update usages appropriately, like line 273). Rather than comment on all the instances, please just search and replace all of them in the PR. Thanks!",
                "position": null
            },
            {
                "comment": "Thank you, addressed.",
                "position": null
            }
        ],
        "commit_message": "Fix lint issue",
        "commit_id": "a0ff30c5a5484683b5dd91cfe8f0804aa487b1d0"
    },
    {
        "pr_title": "feat: add v2 API for muteconfig Go client libraries or samples",
        "pr_number": 4268,
        "file_name": "securitycenter/muteconfigv2/mute_config_test.go",
        "code_diff": "@@ -106,6 +106,7 @@\ntype muteconfigFixture struct {\n \tclient        *securitycenter.Client\n \torgId         string\n \tprojectId     string\n+\tlocationId    string\n \tparent        string\n \tsourceName    string\n \tfinding1Name  string",
        "comments": [
            {
                "comment": "Nit: I think `fmt.Errorf` is always better with the verb `%w` for an error, even in a test file  (this is different from `t.Errorf`)\r\n\r\n4 occurrences",
                "position": null
            },
            {
                "comment": "Addressed.",
                "position": null
            }
        ],
        "commit_message": "Remove bulk mute sample due to server side issue",
        "commit_id": "eb274b0d1db8f7c8f293765d19ff264d66ab906e"
    },
    {
        "pr_title": "feat: add v2 API for muteconfig Go client libraries or samples",
        "pr_number": 4268,
        "file_name": "securitycenter/muteconfigv2/mute_config_test.go",
        "code_diff": "@@ -133,7 +134,7 @@\nfunc newMuteConfigFixture() (*muteconfigFixture, error) {\n \t}\n \tmc.orgId = orgId\n \tmc.projectId = projectId\n-\n+\tmc.locationId = locationId\n \t// Create source.\n \tbuf := &bytes.Buffer{}\n \tif err := createSource(buf, orgId); err != nil {",
        "comments": [
            {
                "comment": "Nit: I think `fmt.Errorf` is always better with the verb `%w` for an error, even in a test file  (this is different from `t.Errorf`)\r\n\r\n4 occurrences",
                "position": null
            },
            {
                "comment": "Addressed.",
                "position": null
            }
        ],
        "commit_message": "Remove bulk mute sample due to server side issue",
        "commit_id": "eb274b0d1db8f7c8f293765d19ff264d66ab906e"
    },
    {
        "pr_title": "feat(vertexai): Context caching",
        "pr_number": 4267,
        "file_name": "batch/job_basics_test.go",
        "code_diff": "@@ -22,6 +22,7 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/batch/apiv1/batchpb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into context-caching",
        "commit_id": "144233d4dc81ab54d1bb8bda3813c020758e135b"
    },
    {
        "pr_title": "feat: added labels samples for secret manager",
        "pr_number": 4253,
        "file_name": "firestore/query_multiple_inequality_test.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage firestore\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into labels-SM",
        "commit_id": "34880db369ef13be7a10500e59bc08ac470ab402"
    },
    {
        "pr_title": "feat: added labels samples for secret manager",
        "pr_number": 4253,
        "file_name": "firestore/query_multiple_inequality_test.go",
        "code_diff": "@@ -26,21 +27,12 @@\nimport (\n \t\"cloud.google.com/go/firestore/apiv1/admin/adminpb\"\n )\n \n-func TestMultipleInequalitiesQuery(t *testing.T) {\n-\tprojectID := os.Getenv(\"GOLANG_SAMPLES_FIRESTORE_PROJECT\")\n-\tif projectID == \"\" {\n-\t\tt.Skip(\"Skipping firestore test. Set GOLANG_SAMPLES_FIRESTORE_PROJECT.\")\n-\t}\n-\n+func setupClientAndCities(t *testing.T, projectID string) (*firestore.Client, func()) {\n \tctx := context.Background()\n \tclient, err := firestore.NewClient(ctx, projectID)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n-\tt.Cleanup(func() {\n-\t\tclient.Close()\n-\t})\n-\n \tcities := []City{\n \t\t{\n \t\t\tName:       \"San Francisco\",",
        "comments": [],
        "commit_message": "Merge branch 'main' into labels-SM",
        "commit_id": "34880db369ef13be7a10500e59bc08ac470ab402"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -25,7 +25,6 @@\nimport (\n )\n \n // [START job_custom_attribute_job]\n-// [START custom_attribute_job]\n \n // constructJobWithCustomAttributes constructs a job with custom attributes.\n func constructJobWithCustomAttributes(companyName string, jobTitle string) *talent.Job {",
        "comments": [],
        "commit_message": "fix: migrate to new region tag in custom_attribute_sample.go",
        "commit_id": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -54,11 +53,9 @@\nfunc constructJobWithCustomAttributes(companyName string, jobTitle string) *tale\n \treturn job\n }\n \n-// [END custom_attribute_job]\n // [END job_custom_attribute_job]\n \n // [START job_custom_attribute_filter_string_value]\n-// [START custom_attribute_filter_string_value]\n \n // filterOnStringValueCustomAttribute searches for jobs on a string value custom\n // atrribute.",
        "comments": [],
        "commit_message": "fix: migrate to new region tag in custom_attribute_sample.go",
        "commit_id": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -105,11 +102,9 @@\nfunc filterOnStringValueCustomAttribute(w io.Writer, projectID string) (*talent.\n \treturn resp, nil\n }\n \n-// [END custom_attribute_filter_string_value]\n // [END job_custom_attribute_filter_string_value]\n \n // [START job_custom_attribute_filter_long_value]\n-// [START custom_attribute_filter_long_value]\n \n // filterOnLongValueCustomAttribute searches for jobs on a long value custom\n // atrribute.",
        "comments": [],
        "commit_message": "fix: migrate to new region tag in custom_attribute_sample.go",
        "commit_id": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -156,12 +151,9 @@\nfunc filterOnLongValueCustomAttribute(w io.Writer, projectID string) (*talent.Se\n \treturn resp, nil\n }\n \n-// [END job_custom_attribute_filter_long_value]\n-// [END custom_attribute_filter_long_value]\n // [END job_custom_attribute_filter_long_value]\n \n // [START job_custom_attribute_filter_multi_attributes]\n-// [START custom_attribute_filter_multi_attributes]\n \n // filterOnLongValueCustomAttribute searches for jobs on multiple custom\n // atrributes.",
        "comments": [],
        "commit_message": "fix: migrate to new region tag in custom_attribute_sample.go",
        "commit_id": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "feat: add v2 API findings samples for create, update",
        "pr_number": 4226,
        "file_name": "aiplatform/snippets/embeddings_preview.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage snippets\n \n-// [START generativeaionvertexai_sdk_embedding]\n+// [START generativeaionvertexai_text_predictions]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into findings-samples-v2",
        "commit_id": "9fca1c92786ff1d390197cc9706f884bd83a73c7"
    },
    {
        "pr_title": "feat: add v2 API findings samples for create, update",
        "pr_number": 4226,
        "file_name": "aiplatform/snippets/embeddings_preview.go",
        "code_diff": "@@ -27,6 +27,8 @@\nimport (\n \t\"google.golang.org/protobuf/types/known/structpb\"\n )\n \n+// Embeds code query with a pre-trained, foundational model by specifying the task type as 'CODE_RETRIEVAL_QUERY'. e.g. 'Retrieve a function that adds two numbers'.\n+// Embeds code block with a pre-trained, foundational model by specifying the task type as 'RETRIEVAL_DOCUMENT'. e.g. 'texts := []string{\"def func(a, b): return a + b\", \"def func(a, b): return a - b\", \"def func(a, b): return (a ** 2 + b ** 2) ** 0.5\"}'.\n func embedTextsPreview(\n \tapiEndpoint, project, model string, texts []string,\n \ttask string, dimensionality *int) ([][]float32, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into findings-samples-v2",
        "commit_id": "9fca1c92786ff1d390197cc9706f884bd83a73c7"
    },
    {
        "pr_title": "feat(storage): add object retention samples",
        "pr_number": 4220,
        "file_name": "bigquery/snippets/querying/integration_test.go",
        "code_diff": "@@ -18,7 +18,7 @@\npackage querying\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n+\t\"io\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into obj-retention",
        "commit_id": "34668b7cfa629e386a985af3b041dc80a0afca37"
    },
    {
        "pr_title": "feat(storage): add object retention samples",
        "pr_number": 4220,
        "file_name": "bigquery/snippets/querying/integration_test.go",
        "code_diff": "@@ -55,40 +55,40 @@\nfunc TestQueries(t *testing.T) {\n \tt.Run(\"group\", func(t *testing.T) {\n \t\tt.Run(\"queryBasic\", func(t *testing.T) {\n \t\t\tt.Parallel()\n-\t\t\tif err := queryBasic(ioutil.Discard, tc.ProjectID); err != nil {\n+\t\t\tif err := queryBasic(io.Discard, tc.ProjectID); err != nil {\n \t\t\t\tt.Errorf(\"queryBasic: %v\", err)\n \t\t\t}\n \t\t})\n \t\tt.Run(\"queryBatch\", func(t *testing.T) {\n \t\t\tt.Parallel()\n \t\t\ttableID := \"bigquery_query_batch\"\n-\t\t\tif err := queryBatch(ioutil.Discard, tc.ProjectID, testDatasetID, tableID); err != nil {\n+\t\t\tif err := queryBatch(io.Discard, tc.ProjectID, testDatasetID, tableID); err != nil {\n \t\t\t\tt.Errorf(\"queryBatch(%q): %v\", testDatasetID, err)\n \t\t\t}\n \t\t})\n \t\tt.Run(\"queryDisableCache\", func(t *testing.T) {\n \t\t\tt.Parallel()\n-\t\t\tif err := queryDisableCache(ioutil.Discard, tc.ProjectID); err != nil {\n+\t\t\tif err := queryDisableCache(io.Discard, tc.ProjectID); err != nil {\n \t\t\t\tt.Errorf(\"queryDisableCache: %v\", err)\n \t\t\t}\n \t\t})\n \t\tt.Run(\"queryDryRun\", func(t *testing.T) {\n \t\t\tt.Parallel()\n-\t\t\tif err := queryDryRun(ioutil.Discard, tc.ProjectID); err != nil {\n+\t\t\tif err := queryDryRun(io.Discard, tc.ProjectID); err != nil {\n \t\t\t\tt.Errorf(\"queryDryRun: %v\", err)\n \t\t\t}\n \t\t})\n \t\tt.Run(\"queryLegacy\", func(t *testing.T) {\n \t\t\tt.Parallel()\n \t\t\tsql := \"SELECT 17 as foo\"\n-\t\t\tif err := queryLegacy(ioutil.Discard, tc.ProjectID, sql); err != nil {\n+\t\t\tif err := queryLegacy(io.Discard, tc.ProjectID, sql); err != nil {\n \t\t\t\tt.Errorf(\"queryLegacy: %v\", err)\n \t\t\t}\n \t\t})\n \t\tt.Run(\"queryLegacyLargeResults\", func(t *testing.T) {\n \t\t\tt.Parallel()\n \t\t\ttableID := \"bigquery_query_legacy_large_results\"\n-\t\t\tif err := queryLegacyLargeResults(ioutil.Discard, tc.ProjectID, testDatasetID, tableID); err != nil {\n+\t\t\tif err := queryLegacyLargeResults(io.Discard, tc.ProjectID, testDatasetID, tableID); err != nil {\n \t\t\t\tt.Errorf(\"queryLegacyLargeResults: %v\", err)\n \t\t\t}\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into obj-retention",
        "commit_id": "34668b7cfa629e386a985af3b041dc80a0afca37"
    },
    {
        "pr_title": "feat(storage): add object retention samples",
        "pr_number": 4220,
        "file_name": "bigquery/snippets/querying/integration_test.go",
        "code_diff": "@@ -102,7 +102,7 @@\nfunc TestQueries(t *testing.T) {\n \t\tt.Run(\"queryWithDestination\", func(t *testing.T) {\n \t\t\tt.Parallel()\n \t\t\ttableID := \"bigquery_query_destination_table\"\n-\t\t\tif err := queryWithDestination(ioutil.Discard, tc.ProjectID, testDatasetID, tableID); err != nil {\n+\t\t\tif err := queryWithDestination(io.Discard, tc.ProjectID, testDatasetID, tableID); err != nil {\n \t\t\t\tt.Errorf(\"queryWithDestination: %v\", err)\n \t\t\t}\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into obj-retention",
        "commit_id": "34668b7cfa629e386a985af3b041dc80a0afca37"
    },
    {
        "pr_title": "feat(storage): add object retention samples",
        "pr_number": 4220,
        "file_name": "bigquery/snippets/querying/integration_test.go",
        "code_diff": "@@ -112,37 +112,37 @@\nfunc TestQueries(t *testing.T) {\n \t\t\t}\n \t\t\tt.Parallel()\n \t\t\ttableID := \"bigquery_query_destination_table_cmek\"\n-\t\t\tif err := queryWithDestinationCMEK(ioutil.Discard, tc.ProjectID, testDatasetID, tableID); err != nil {\n+\t\t\tif err := queryWithDestinationCMEK(io.Discard, tc.ProjectID, testDatasetID, tableID); err != nil {\n \t\t\t\tt.Errorf(\"queryWithDestinationCMEK: %v\", err)\n \t\t\t}\n \t\t})\n \t\tt.Run(\"queryWithArrayParams\", func(t *testing.T) {\n \t\t\tt.Parallel()\n-\t\t\tif err := queryWithArrayParams(ioutil.Discard, tc.ProjectID); err != nil {\n+\t\t\tif err := queryWithArrayParams(io.Discard, tc.ProjectID); err != nil {\n \t\t\t\tt.Errorf(\"queryWithArrayParams: %v\", err)\n \t\t\t}\n \t\t})\n \t\tt.Run(\"queryWithNamedParams\", func(t *testing.T) {\n \t\t\tt.Parallel()\n-\t\t\tif err := queryWithNamedParams(ioutil.Discard, tc.ProjectID); err != nil {\n+\t\t\tif err := queryWithNamedParams(io.Discard, tc.ProjectID); err != nil {\n \t\t\t\tt.Errorf(\"queryWithNamedParams: %v\", err)\n \t\t\t}\n \t\t})\n \t\tt.Run(\"queryWithPositionalParams\", func(t *testing.T) {\n \t\t\tt.Parallel()\n-\t\t\tif err := queryWithPositionalParams(ioutil.Discard, tc.ProjectID); err != nil {\n+\t\t\tif err := queryWithPositionalParams(io.Discard, tc.ProjectID); err != nil {\n \t\t\t\tt.Errorf(\"queryWithPositionalParams: %v\", err)\n \t\t\t}\n \t\t})\n \t\tt.Run(\"queryWithStructParam\", func(t *testing.T) {\n \t\t\tt.Parallel()\n-\t\t\tif err := queryWithStructParam(ioutil.Discard, tc.ProjectID); err != nil {\n+\t\t\tif err := queryWithStructParam(io.Discard, tc.ProjectID); err != nil {\n \t\t\t\tt.Errorf(\"queryWithStructParam: %v\", err)\n \t\t\t}\n \t\t})\n \t\tt.Run(\"queryWithTimestampParam\", func(t *testing.T) {\n \t\t\tt.Parallel()\n-\t\t\tif err := queryWithTimestampParam(ioutil.Discard, tc.ProjectID); err != nil {\n+\t\t\tif err := queryWithTimestampParam(io.Discard, tc.ProjectID); err != nil {\n \t\t\t\tt.Errorf(\"queryWithTimestampParam: %v\", err)\n \t\t\t}\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into obj-retention",
        "commit_id": "34668b7cfa629e386a985af3b041dc80a0afca37"
    },
    {
        "pr_title": "feat(storage): add object retention samples",
        "pr_number": 4220,
        "file_name": "bigquery/snippets/querying/integration_test.go",
        "code_diff": "@@ -152,7 +152,7 @@\nfunc TestQueries(t *testing.T) {\n \t\t\tif err := preparePartitionedData(tc.ProjectID, testDatasetID, tableID); err != nil {\n \t\t\t\tt.Fatalf(\"couldn't setup clustered table: %v\", err)\n \t\t\t}\n-\t\t\tif err := queryPartitionedTable(ioutil.Discard, tc.ProjectID, testDatasetID, tableID); err != nil {\n+\t\t\tif err := queryPartitionedTable(io.Discard, tc.ProjectID, testDatasetID, tableID); err != nil {\n \t\t\t\tt.Errorf(\"queryPartitionedTable: %v\", err)\n \t\t\t}\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into obj-retention",
        "commit_id": "34668b7cfa629e386a985af3b041dc80a0afca37"
    },
    {
        "pr_title": "feat(testing): run tests in modified packages only",
        "pr_number": 4214,
        "file_name": "batch/job_basics_test.go",
        "code_diff": "@@ -26,13 +26,12 @@\nimport (\n )\n \n func TestBatchJobCRUD(t *testing.T) {\n-\tt.Skip(\"Skipped while investigating https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \tt.Parallel()\n \tvar r *rand.Rand = rand.New(\n \t\trand.NewSource(time.Now().UnixNano()))\n \ttc := testutil.SystemTest(t)\n \tregion := \"us-central1\"\n-\tjobName := fmt.Sprintf(\"test-job-go-script-%v-%v\", time.Now().Format(\"2006-12-25\"), r.Int())\n+\tjobName := fmt.Sprintf(\"test-job-go-script-%v-%v\", time.Now().Format(\"2006-01-02\"), r.Int())\n \n \tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_message": "Merge branch 'main' into smoltest",
        "commit_id": "65eb28a920ac7fd773f3a93f30b94f5606bd51b2"
    },
    {
        "pr_title": "feat(testing): run tests in modified packages only",
        "pr_number": 4214,
        "file_name": "bigquery/snippets/bqtestutil/bqtestutil.go",
        "code_diff": "@@ -18,6 +18,7 @@\nimport (\n \t\"fmt\"\n \t\"os\"\n \t\"regexp\"\n+\t\"strings\"\n \n \t\"github.com/gofrs/uuid\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into smoltest",
        "commit_id": "65eb28a920ac7fd773f3a93f30b94f5606bd51b2"
    },
    {
        "pr_title": "feat(compute): compute_ip_address_promote_ephemeral sample",
        "pr_number": 4195,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \t\"errors\"\n \t\"flag\"\n \t\"fmt\"\n+\t\"log\"\n \t\"os\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_ip_address_promote_ephemeral",
        "commit_id": "e689f1b2f142cce954ce4770163546f95ee97bfb"
    },
    {
        "pr_title": "feat(compute): compute_ip_address_promote_ephemeral sample",
        "pr_number": 4195,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -33,10 +34,12 @@\nimport (\n var (\n \tmetaProject = flag.String(\"project\", \"\", \"Meta-project that manages the pool.\")\n \tformat      = flag.String(\"output\", \"\", \"Output format for selected operations. Options include: list\")\n+\twaitTime    = flag.Duration(\"timeout\", 30*time.Minute, \"maximum wait time for leasing a project\")\n \tdatastore   *ds.Client\n \n-\tversion   = \"dev\"\n-\tbuildDate = \"unknown\"\n+\tversion       = \"dev\"\n+\tbuildDate     = \"unknown\"\n+\tErrNoProjects = errors.New(\"could not find a free project\")\n )\n \n type Pool struct {",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_ip_address_promote_ephemeral",
        "commit_id": "e689f1b2f142cce954ce4770163546f95ee97bfb"
    },
    {
        "pr_title": "feat(compute): compute_ip_address_promote_ephemeral sample",
        "pr_number": 4195,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -142,7 +145,21 @@\nAdministrative commands:\n \t\tfmt.Fprintln(os.Stderr, usage.Error())\n \t\treturn nil\n \tcase \"lease\":\n-\t\treturn lease(ctx, flag.Arg(1))\n+\t\t// When leasing, keep trying until we reach our configured timeout\n+\t\tctx, cancel := context.WithTimeout(ctx, *waitTime)\n+\t\tdefer cancel()\n+\t\tfor ctx.Err() == nil {\n+\t\t\terr := lease(ctx, flag.Arg(1))\n+\t\t\tif err == nil {\n+\t\t\t\treturn err\n+\t\t\t} else if errors.Is(err, ErrNoProjects) {\n+\t\t\t\tlog.Printf(\"Temporary error: %v\\n\", err)\n+\t\t\t\ttime.Sleep(30 * time.Second)\n+\t\t\t} else {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t}\n+\t\treturn ctx.Err()\n \tcase \"pool-add\":\n \t\treturn addToPool(ctx, flag.Arg(1))\n \tcase \"pool-rm\":",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_ip_address_promote_ephemeral",
        "commit_id": "e689f1b2f142cce954ce4770163546f95ee97bfb"
    },
    {
        "pr_title": "feat(compute): compute_ip_address_promote_ephemeral sample",
        "pr_number": 4195,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -199,7 +216,7 @@\nfunc lease(ctx context.Context, duration string) error {\n \t\tvar ok bool\n \t\tproj, ok = pool.Lease(d)\n \t\tif !ok {\n-\t\t\treturn errors.New(\"Could not find a free project. Try again soon.\")\n+\t\t\treturn ErrNoProjects\n \t\t}\n \t\treturn nil\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_ip_address_promote_ephemeral",
        "commit_id": "e689f1b2f142cce954ce4770163546f95ee97bfb"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n-// [START create_company]\n+// [START job_create_company]\n \n // createCompany creates a company as given.\n func createCompany(w io.Writer, projectID string, companyToCreate *talent.Company) (*talent.Company, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -51,9 +51,9 @@\nfunc createCompany(w io.Writer, projectID string, companyToCreate *talent.Compan\n \treturn company, nil\n }\n \n-// [END create_company]\n+// [END job_create_company]\n \n-// [START get_company]\n+// [START job_get_company]\n \n // getCompany gets an existing company by name.\n func getCompany(w io.Writer, name string) (*talent.Company, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -79,9 +79,9 @@\nfunc getCompany(w io.Writer, name string) (*talent.Company, error) {\n \treturn company, nil\n }\n \n-// [END get_company]\n+// [END job_get_company]\n \n-// [START update_company]\n+// [START job_update_company]\n \n // updateCompany update a company with all fields.\n func updateCompany(w io.Writer, name string, companyToUpdate *talent.Company) (*talent.Company, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -108,9 +108,9 @@\nfunc updateCompany(w io.Writer, name string, companyToUpdate *talent.Company) (*\n \treturn company, nil\n }\n \n-// [END update_company]\n+// [END job_update_company]\n \n-// [START update_company_with_field_mask]\n+// [START job_update_company_with_field_mask]\n \n // updateCompanyWithMask updates a company with specific fields.\n // mask is a comma separated list of top-level fields of talent.Company.",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -139,9 +139,9 @@\nfunc updateCompanyWithMask(w io.Writer, name string, mask string, companyToUpdat\n \treturn company, nil\n }\n \n-// [END update_company_with_field_mask]\n+// [END job_update_company_with_field_mask]\n \n-// [START delete_company]\n+// [START job_delete_company]\n \n // deleteCompany deletes an existing company by name.\n func deleteCompany(w io.Writer, name string) error {",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -164,9 +164,9 @@\nfunc deleteCompany(w io.Writer, name string) error {\n \treturn nil\n }\n \n-// [END delete_company]\n+// [END job_delete_company]\n \n-// [START list_companies]\n+// [START job_list_companies]\n \n // listCompanies lists all companies in the project.\n func listCompanies(w io.Writer, projectID string) (*talent.ListCompaniesResponse, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -84,7 +84,6 @@\nfunc getJob(w io.Writer, jobName string) (*talent.Job, error) {\n // [END job_get_job]\n \n // [START job_update_job]\n-// [START update_job]\n \n // updateJob update a job with all fields except name.\n func updateJob(w io.Writer, jobName string, jobToUpdate *talent.Job) (*talent.Job, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -111,11 +110,9 @@\nfunc updateJob(w io.Writer, jobName string, jobToUpdate *talent.Job) (*talent.Jo\n \treturn job, err\n }\n \n-// [END update_job]\n // [END job_update_job]\n \n // [START job_update_job_with_field_mask]\n-// [START update_job_with_field_mask]\n \n // updateJobWithMask updates a job by name with specific fields.\n // mask is a comma separated list top-level fields of talent.Job.",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -144,11 +141,9 @@\nfunc updateJobWithMask(w io.Writer, jobName string, mask string, jobToUpdate *ta\n \treturn job, err\n }\n \n-// [END update_job_with_field_mask]\n // [END job_update_job_with_field_mask]\n \n // [START job_delete_job]\n-// [START delete_job]\n \n // deleteJob deletes an existing job by name.\n func deleteJob(w io.Writer, jobName string) error {",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -171,11 +166,9 @@\nfunc deleteJob(w io.Writer, jobName string) error {\n \treturn err\n }\n \n-// [END delete_job]\n // [END job_delete_job]\n \n // [START job_list_jobs]\n-// [START list_jobs]\n \n // listJobs lists jobs with a filter, for example\n // `companyName=\"projects/my-project/companies/123\"`.",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -24,7 +24,7 @@\nimport (\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n-// [START custom_attribute_job]\n+// [START job_custom_attribute_job]\n \n // constructJobWithCustomAttributes constructs a job with custom attributes.\n func constructJobWithCustomAttributes(companyName string, jobTitle string) *talent.Job {",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -53,9 +53,9 @@\nfunc constructJobWithCustomAttributes(companyName string, jobTitle string) *tale\n \treturn job\n }\n \n-// [END custom_attribute_job]\n+// [END job_custom_attribute_job]\n \n-// [START custom_attribute_filter_string_value]\n+// [START job_custom_attribute_filter_string_value]\n \n // filterOnStringValueCustomAttribute searches for jobs on a string value custom\n // atrribute.",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -102,9 +102,9 @@\nfunc filterOnStringValueCustomAttribute(w io.Writer, projectID string) (*talent.\n \treturn resp, nil\n }\n \n-// [END custom_attribute_filter_string_value]\n+// [END job_custom_attribute_filter_string_value]\n \n-// [START custom_attribute_filter_long_value]\n+// [START job_custom_attribute_filter_long_value]\n \n // filterOnLongValueCustomAttribute searches for jobs on a long value custom\n // atrribute.",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -151,9 +151,9 @@\nfunc filterOnLongValueCustomAttribute(w io.Writer, projectID string) (*talent.Se\n \treturn resp, nil\n }\n \n-// [END custom_attribute_filter_long_value]\n+// [END job_custom_attribute_filter_long_value]\n \n-// [START custom_attribute_filter_multi_attributes]\n+// [START job_custom_attribute_filter_multi_attributes]\n \n // filterOnLongValueCustomAttribute searches for jobs on multiple custom\n // atrributes.",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/histogram_search_sample.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n+// [START job_histogram_search]\n // [START histogram_search]\n \n // histogramSearch searches for jobs with histogram facets.",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n-// [START basic_location_search]\n+// [START job_basic_location_search]\n \n // basicLocationSearch searches for jobs within distance of location.\n func basicLocationSearch(w io.Writer, projectID, companyName, location string, distance float64) (*talent.SearchJobsResponse, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -82,8 +82,9 @@\nfunc basicLocationSearch(w io.Writer, projectID, companyName, location string, d\n \treturn resp, nil\n }\n \n-// [END basic_location_search]\n+// [END job_basic_location_search]\n \n+// [START job_city_location_search]\n // [START city_location_search]\n \n // cityLocationSearch searches for jobs in the same city of given location.",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -143,7 +144,9 @@\nfunc cityLocationSearch(w io.Writer, projectID, companyName, location string) (*\n }\n \n // [END city_location_search]\n+// [END job_city_location_search]\n \n+// [START job_broadening_location_search]\n // [START broadening_location_search]\n \n // broadeningLocationSearch searches for jobs with a broadening area of given",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -205,8 +208,9 @@\nfunc broadeningLocationSearch(w io.Writer, projectID, companyName, location stri\n }\n \n // [END broadening_location_search]\n+// [END job_broadening_location_search]\n \n-// [START keyword_location_search]\n+// [START job_keyword_location_search]\n \n // keywordLocationSearch searches for jobs with given keyword and within the\n // distance of given location.",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -267,9 +271,9 @@\nfunc keywordLocationSearch(w io.Writer, projectID, companyName, location string,\n \treturn resp, nil\n }\n \n-// [END keyword_location_search]\n+// [END job_keyword_location_search]\n \n-// [START multi_locations_search]\n+// [START job_multi_locations_search]\n \n // multiLocationsSearch searches for jobs that fall in the distance of any given\n // locations.",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_snapsht",
        "commit_id": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Compute images create from image",
        "pr_number": 4180,
        "file_name": "jobs/v3/howto/commute_search_sample.go",
        "code_diff": "@@ -24,7 +24,6 @@\nimport (\n )\n \n // [START job_discovery_commute_search]\n-// [START commute_search]\n \n // commuteSearch searches for jobs within commute filter.\n func commuteSearch(w io.Writer, projectID, companyName string) (*talent.SearchJobsResponse, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute_images_create_from_image",
        "commit_id": "365b5cb5c195b2faf688d181b95b4c4c2ed9de78"
    },
    {
        "pr_title": "feat(compute): samples/compute_instances_bulk_insert",
        "pr_number": 4179,
        "file_name": "compute/address/address_test.go",
        "code_diff": "@@ -551,7 +551,7 @@\nfunc TestGetRegionalExternal(t *testing.T) {\n \n }\n \n-func TestAssignStaticAddressToExistingVM(t *testing.T) {\n+func TestAssignUnassignStaticAddressToExistingVM(t *testing.T) {\n \tctx := context.Background()\n \tvar seededRand = rand.New(\n \t\trand.NewSource(time.Now().UnixNano()))",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_instances_bulk_insert",
        "commit_id": "74df862379ce95ac382b3e2a3c4bcf4b66d3b092"
    },
    {
        "pr_title": "feat(compute): samples/compute_instances_bulk_insert",
        "pr_number": 4179,
        "file_name": "compute/disk-images/disk_image_test.go",
        "code_diff": "@@ -81,6 +81,8 @@\nfunc TestComputeDiskImageSnippets(t *testing.T) {\n \timageName := fmt.Sprintf(\"test-image-go-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tdiskName := fmt.Sprintf(\"test-disk-go-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tsourceImage := \"projects/debian-cloud/global/images/family/debian-11\"\n+\tsourceProjectId := \"debian-cloud\"\n+\tsourceImageName := \"debian-11\"\n \n \tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_instances_bulk_insert",
        "commit_id": "74df862379ce95ac382b3e2a3c4bcf4b66d3b092"
    },
    {
        "pr_title": "feat(compute): samples/compute_instances_bulk_insert",
        "pr_number": 4179,
        "file_name": "compute/disk-images/disk_image_test.go",
        "code_diff": "@@ -123,7 +125,7 @@\nfunc TestComputeDiskImageSnippets(t *testing.T) {\n \t\tbuf.Reset()\n \t\twant = \"Newest disk image was found\"\n \n-\t\terr = getDiskImageFromFamily(buf, \"debian-cloud\", \"debian-11\")\n+\t\t_, err = getDiskImageFromFamily(buf, \"debian-cloud\", \"debian-11\")\n \t\tif err != nil {\n \t\t\tt.Errorf(\"getDiskImageFromFamily got err: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_instances_bulk_insert",
        "commit_id": "74df862379ce95ac382b3e2a3c4bcf4b66d3b092"
    },
    {
        "pr_title": "feat(compute): samples/compute_instances_bulk_insert",
        "pr_number": 4179,
        "file_name": "compute/disk-images/get_disk_image_from_family.go",
        "code_diff": "@@ -28,14 +28,14 @@\nimport (\n func getDiskImageFromFamily(\n \tw io.Writer,\n \tprojectID, family string,\n-) error {\n+) (*computepb.Image, error) {\n \t// projectID := \"your_project_id\"\n \t// family := \"my_family\"\n \n \tctx := context.Background()\n \timagesClient, err := compute.NewImagesRESTClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewImagesRESTClient: %w\", err)\n+\t\treturn nil, fmt.Errorf(\"NewImagesRESTClient: %w\", err)\n \t}\n \tdefer imagesClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_instances_bulk_insert",
        "commit_id": "74df862379ce95ac382b3e2a3c4bcf4b66d3b092"
    },
    {
        "pr_title": "feat(compute): samples/compute_instances_bulk_insert",
        "pr_number": 4179,
        "file_name": "jobs/v3/howto/commute_search_sample.go",
        "code_diff": "@@ -24,7 +24,6 @@\nimport (\n )\n \n // [START job_discovery_commute_search]\n-// [START commute_search]\n \n // commuteSearch searches for jobs within commute filter.\n func commuteSearch(w io.Writer, projectID, companyName string) (*talent.SearchJobsResponse, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_instances_bulk_insert",
        "commit_id": "74df862379ce95ac382b3e2a3c4bcf4b66d3b092"
    },
    {
        "pr_title": "samples(storage): add folder samples",
        "pr_number": 4178,
        "file_name": "vertexai/chat/chat.go",
        "code_diff": "@@ -24,11 +24,8 @@\nimport (\n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-func makeChatRequests(w io.Writer, projectID string, location string, modelName string) error {\n-\t// location := \"us-central1\"\n-\t// modelName := \"gemini-1.0-pro-002\"\n-\tctx := context.Background()\n-\tclient, err := genai.NewClient(ctx, projectID, location)\n+func makeChatRequests(ctx context.Context, w io.Writer, projectID, region, modelName string) error {\n+\tclient, err := genai.NewClient(ctx, projectID, region)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"error creating client: %w\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into folder-samples",
        "commit_id": "2e0d7a361de5c8638a22d1b837269cec7ae35d62"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "aiplatform/snippets/import_data_image_classification.go",
        "code_diff": "@@ -41,7 +41,7 @@\nfunc importDataImageClassification(w io.Writer, projectID, location, datasetID,\n \tctx := context.Background()\n \taiplatformClient, err := aiplatform.NewDatasetClient(ctx, clientOption)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"aiplatform.NewDatasetClient: %v\", err)\n+\t\treturn fmt.Errorf(\"aiplatform.NewDatasetClient: %w\", err)\n \t}\n \tdefer aiplatformClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "auth/id_token_from_service_account.go",
        "code_diff": "@@ -19,7 +19,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n+\t\"os\"\n \n \t\"google.golang.org/api/idtoken\"\n \t\"google.golang.org/api/option\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "bigtable/writes/writes_test.go",
        "code_diff": "@@ -65,6 +65,21 @@\nfunc TestWrites(t *testing.T) {\n \t\tt.Fatalf(\"CreateColumnFamily(%s): %v\", columnFamilyName, err)\n \t}\n \n+\tcolumnFamilyName = \"view_count\"\n+\tif err = adminClient.CreateColumnFamilyWithConfig(\n+\t\tctx,\n+\t\ttableName,\n+\t\tcolumnFamilyName,\n+\t\tbigtable.Family{\n+\t\t\tValueType: bigtable.AggregateType{\n+\t\t\t\tInput:      bigtable.Int64Type{},\n+\t\t\t\tAggregator: bigtable.SumAggregator{},\n+\t\t\t},\n+\t\t}); err != nil {\n+\t\tadminClient.DeleteTable(ctx, tableName)\n+\t\tt.Fatalf(\"CreateColumnFamily(%s): %v\", columnFamilyName, err)\n+\t}\n+\n \tbuf := new(bytes.Buffer)\n \tif err = writeSimple(buf, project, instance, tableName); err != nil {\n \t\tt.Errorf(\"TestWriteSimple: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "dataproc/quickstart/quickstart.go",
        "code_diff": "@@ -29,7 +29,7 @@\nimport (\n \t\"context\"\n \t\"flag\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n+\t\"io\"\n \t\"log\"\n \t\"regexp\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "documentai/documentai_quickstart/main.go",
        "code_diff": "@@ -20,7 +20,7 @@\nimport (\n \t\"context\"\n \t\"flag\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n+\t\"os\"\n \n \tdocumentai \"cloud.google.com/go/documentai/apiv1\"\n \t\"cloud.google.com/go/documentai/apiv1/documentaipb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n+// [START job_create_job]\n // [START create_job]\n \n // createJob create a job as given.",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -52,7 +53,9 @@\nfunc createJob(w io.Writer, projectID string, jobToCreate *talent.Job) (*talent.\n }\n \n // [END create_job]\n+// [END job_create_job]\n \n+// [START job_get_job]\n // [START get_job]\n \n // getJob gets a job by name.",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -80,7 +83,9 @@\nfunc getJob(w io.Writer, jobName string) (*talent.Job, error) {\n }\n \n // [END get_job]\n+// [END job_get_job]\n \n+// [START job_update_job]\n // [START update_job]\n \n // updateJob update a job with all fields except name.",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -109,7 +114,9 @@\nfunc updateJob(w io.Writer, jobName string, jobToUpdate *talent.Job) (*talent.Jo\n }\n \n // [END update_job]\n+// [END job_update_job]\n \n+// [START job_update_job_with_field_mask]\n // [START update_job_with_field_mask]\n \n // updateJobWithMask updates a job by name with specific fields.",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -140,7 +147,9 @@\nfunc updateJobWithMask(w io.Writer, jobName string, mask string, jobToUpdate *ta\n }\n \n // [END update_job_with_field_mask]\n+// [END job_update_job_with_field_mask]\n \n+// [START job_delete_job]\n // [START delete_job]\n \n // deleteJob deletes an existing job by name.",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -165,7 +174,9 @@\nfunc deleteJob(w io.Writer, jobName string) error {\n }\n \n // [END delete_job]\n+// [END job_delete_job]\n \n+// [START job_list_jobs]\n // [START list_jobs]\n \n // listJobs lists jobs with a filter, for example",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "jobs/v3/howto/commute_search_sample.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n+// [START job_discovery_commute_search]\n // [START commute_search]\n \n // commuteSearch searches for jobs within commute filter.",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "jobs/v3/quickstart/main.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START quick_start]\n+// [START job_search_quick_start]\n \n // Command quickstart is an example of using the Google Cloud Talent Solution API.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "spanner/spanner_snippets/spanner/spanner_update_database.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc updateDatabase(ctx context.Context, w io.Writer, db string) error {\n \t// Instantiate database admin client.\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"updateDatabase.NewDatabaseAdminClient: %v\", err)\n+\t\treturn fmt.Errorf(\"updateDatabase.NewDatabaseAdminClient: %w\", err)\n \t}\n \tdefer adminClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "speech/snippets/transcribe_diarization_beta.go",
        "code_diff": "@@ -54,7 +54,7 @@\nfunc transcribe_diarization(w io.Writer, filename string) error {\n \t// Get the contents of the local audio file\n \tcontent, err := os.ReadFile(filename)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"error reading file %v\", err)\n+\t\treturn fmt.Errorf(\"error reading file %w\", err)\n \t}\n \taudio := &speechpb.RecognitionAudio{\n \t\tAudioSource: &speechpb.RecognitionAudio_Content{Content: content},",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "speech/snippets/transcribe_streaming_v2.go",
        "code_diff": "@@ -89,7 +89,7 @@\nfunc transcribeStreamingV2(w io.Writer, projectID string, path string) error {\n \t\t\t\t\t\tAudio: buf[:n],\n \t\t\t\t\t},\n \t\t\t\t}); err != nil {\n-\t\t\t\t\treturn fmt.Errorf(\"could not send audio: %v\", err)\n+\t\t\t\t\treturn fmt.Errorf(\"could not send audio: %w\", err)\n \t\t\t\t}\n \t\t\t}\n \t\t\tif err == io.EOF {",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "speech/snippets/transcribe_streaming_v2_explicit_decoding.go",
        "code_diff": "@@ -96,7 +96,7 @@\nfunc transcribeStreamingSpecificDecodingV2(w io.Writer, projectID string, path s\n \t\t\t\t\t\tAudio: buf[:n],\n \t\t\t\t\t},\n \t\t\t\t}); err != nil {\n-\t\t\t\t\treturn fmt.Errorf(\"could not send audio: %v\", err)\n+\t\t\t\t\treturn fmt.Errorf(\"could not send audio: %w\", err)\n \t\t\t\t}\n \t\t\t}\n \t\t\tif err == io.EOF {",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "vertexai/multimodal-multiple/multiple-multimodal.go",
        "code_diff": "@@ -92,7 +92,7 @@\nfunc generateMultimodalContent(w io.Writer, parts []genai.Part, projectID, locat\n \n \tres, err := model.GenerateContent(ctx, parts...)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"unable to generate contents: %v\", err)\n+\t\treturn fmt.Errorf(\"unable to generate contents: %w\", err)\n \t}\n \n \tfmt.Fprintf(w, \"generated response: %s\\n\", res.Candidates[0].Content.Parts[0])",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): samples/compute_disk_list sample",
        "pr_number": 4171,
        "file_name": "vertexai/multimodal-video/multimodalvideo.go",
        "code_diff": "@@ -40,7 +40,7 @@\nfunc generateMultimodalContent(w io.Writer, prompt, video, projectID, location,\n \n \tclient, err := genai.NewClient(ctx, projectID, location)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"unable to create client: %v\", err)\n+\t\treturn fmt.Errorf(\"unable to create client: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_disk_list",
        "commit_id": "8185a72ff2205fb05a41dfbd786f5be8119e9a56"
    },
    {
        "pr_title": "feat(compute): compute_ip_address_assign_static_existing_vm sample",
        "pr_number": 4166,
        "file_name": "videointelligence/annotate/logo_detection.go",
        "code_diff": "@@ -20,7 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n+\t\"os\"\n \t\"time\"\n \n \tvideo \"cloud.google.com/go/videointelligence/apiv1\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into samples/compute_ip_address_assign_static_existing_vm",
        "commit_id": "21b9257faef0f2743161fdac719a318da5311347"
    },
    {
        "pr_title": "feat(vertexai): Add token count multimodal",
        "pr_number": 4157,
        "file_name": "vertexai/multimodal/multimodal.go",
        "code_diff": "@@ -15,6 +15,7 @@\n// multimodal shows an example of understanding multimodal input\n package multimodal\n \n+// [START generativeaionvertexai_gemini_pro_example]\n import (\n \t\"context\"\n \t\"errors\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into token-count-multimodal",
        "commit_id": "2d25a14c71e885279aa718d2472404d71682e77d"
    },
    {
        "pr_title": "feat(compute): compute_ip_address_get_static_address sample",
        "pr_number": 4154,
        "file_name": "compute/address/address_test.go",
        "code_diff": "@@ -159,8 +159,6 @@\nfunc _deleteRegionalIPAddress(ctx context.Context, projectID, region, addressNam\n \treturn nil\n }\n \n-// end helper functions\n-\n func TestReserveNewRegionalExternal(t *testing.T) {\n \tctx := context.Background()\n \tvar seededRand = rand.New(",
        "comments": [],
        "commit_message": "feat(compute): compute_ip_address_get_static_external sample",
        "commit_id": "993c48e1be7848422487d2aac443e77284dc55e9"
    },
    {
        "pr_title": "feat(otel-instrumentation): Add custom instrumentation ",
        "pr_number": 4149,
        "file_name": "aiplatform/snippets/embeddings.go",
        "code_diff": "@@ -28,17 +28,21 @@\nimport (\n )\n \n func embedTexts(\n-\tapiEndpoint, project, model string, texts []string, task string) ([][]float32, error) {\n+\tproject, location string, texts []string) ([][]float32, error) {\n \tctx := context.Background()\n \n+\tapiEndpoint := fmt.Sprintf(\"%s-aiplatform.googleapis.com:443\", location)\n+\tmodel := \"text-embedding-004\"\n+\ttask := \"QUESTION_ANSWERING\"\n+\tcustomOutputDimensionality := 5\n+\n \tclient, err := aiplatform.NewPredictionClient(ctx, option.WithEndpoint(apiEndpoint))\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \tdefer client.Close()\n \n \tmatch := regexp.MustCompile(`^(\\w+-\\w+)`).FindStringSubmatch(apiEndpoint)\n-\tlocation := \"us-central1\"\n \tif match != nil {\n \t\tlocation = match[1]\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into add-exemplars",
        "commit_id": "2ad16542a974e9c4aedca133c34141e74682343d"
    },
    {
        "pr_title": "feat(otel-instrumentation): Add custom instrumentation ",
        "pr_number": 4149,
        "file_name": "vertexai/multimodal-audio/multimodalaudio_test.go",
        "code_diff": "@@ -39,7 +39,7 @@\nfunc Test_summarizeAudio(t *testing.T) {\n \n \terr := summarizeAudio(buf, prompt, tc.ProjectID, location, modelName)\n \tif err != nil {\n-\t\tt.Errorf(\"Test_generateMultimodalContent: %v\", err.Error())\n+\t\tt.Errorf(\"Test_summarizeAudio: %v\", err.Error())\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into add-exemplars",
        "commit_id": "2ad16542a974e9c4aedca133c34141e74682343d"
    },
    {
        "pr_title": "feat(vertexai): Add stream multimodality basic",
        "pr_number": 4148,
        "file_name": "aiplatform/snippets/embeddings.go",
        "code_diff": "@@ -28,17 +28,21 @@\nimport (\n )\n \n func embedTexts(\n-\tapiEndpoint, project, model string, texts []string, task string) ([][]float32, error) {\n+\tproject, location string, texts []string) ([][]float32, error) {\n \tctx := context.Background()\n \n+\tapiEndpoint := fmt.Sprintf(\"%s-aiplatform.googleapis.com:443\", location)\n+\tmodel := \"text-embedding-004\"\n+\ttask := \"QUESTION_ANSWERING\"\n+\tcustomOutputDimensionality := 5\n+\n \tclient, err := aiplatform.NewPredictionClient(ctx, option.WithEndpoint(apiEndpoint))\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \tdefer client.Close()\n \n \tmatch := regexp.MustCompile(`^(\\w+-\\w+)`).FindStringSubmatch(apiEndpoint)\n-\tlocation := \"us-central1\"\n \tif match != nil {\n \t\tlocation = match[1]\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into stream-multimodality-basic",
        "commit_id": "a243a1578e2e511d1b2c73e29edda2d596576c61"
    },
    {
        "pr_title": "feat(vertexai): Add stream text sample",
        "pr_number": 4147,
        "file_name": "aiplatform/snippets/embeddings.go",
        "code_diff": "@@ -28,17 +28,21 @@\nimport (\n )\n \n func embedTexts(\n-\tapiEndpoint, project, model string, texts []string, task string) ([][]float32, error) {\n+\tproject, location string, texts []string) ([][]float32, error) {\n \tctx := context.Background()\n \n+\tapiEndpoint := fmt.Sprintf(\"%s-aiplatform.googleapis.com:443\", location)\n+\tmodel := \"text-embedding-004\"\n+\ttask := \"QUESTION_ANSWERING\"\n+\tcustomOutputDimensionality := 5\n+\n \tclient, err := aiplatform.NewPredictionClient(ctx, option.WithEndpoint(apiEndpoint))\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \tdefer client.Close()\n \n \tmatch := regexp.MustCompile(`^(\\w+-\\w+)`).FindStringSubmatch(apiEndpoint)\n-\tlocation := \"us-central1\"\n \tif match != nil {\n \t\tlocation = match[1]\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into stream-text-basic",
        "commit_id": "ba60916e16d101a58efed3c7901c954ad49971f0"
    },
    {
        "pr_title": "feat(vertexai): add gemini code sample and test for text-only input",
        "pr_number": 4130,
        "file_name": "vertexai/snippets/text_input_test.go",
        "code_diff": "@@ -15,7 +15,7 @@\npackage snippets\n \n import (\n \t\"bytes\"\n-\t\"fmt\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [
            {
                "comment": "Can we deterministically expect this string to be found in the output?",
                "position": null
            },
            {
                "comment": "Refactored",
                "position": null
            },
            {
                "comment": "Replace \"unexpected error\" with the name of the function you called.",
                "position": null
            },
            {
                "comment": "The test shouldn't print output if it succeeds.\r\n\r\nPerhaps you can check that one or more of the expected response field names (e.g. `Candidates`) shows up in the buffer? That seems like a reasonable thing to check to validate that you got a well formed response.",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            },
            {
                "comment": "Added a check here",
                "position": null
            }
        ],
        "commit_message": "fix test",
        "commit_id": "bdcbe94fd4cab8d10d8328a6f256dc406e7f6927"
    },
    {
        "pr_title": "feat(vertexai): Elastic Text-Embedding Model demo.",
        "pr_number": 4127,
        "file_name": "vertexai/function-calling/functioncalling.go",
        "code_diff": "@@ -23,6 +23,7 @@\npackage functioncalling\n \n // [START aiplatform_gemini_function_calling]\n // [START aiplatform_gemini_function_calling_chat]\n+// [START generativeaionvertexai_function_calling_advanced]\n import (\n \t\"context\"\n \t\"encoding/json\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into text-embedding-google_io_2024_new_model",
        "commit_id": "b73ded9238e7affe8350cc30e0ffdf5b07dc06d8"
    },
    {
        "pr_title": "feat(vertexai): Elastic Text-Embedding Model demo.",
        "pr_number": 4127,
        "file_name": "vertexai/multimodal-audio/multimodalaudio_test.go",
        "code_diff": "@@ -39,7 +39,7 @@\nfunc Test_summarizeAudio(t *testing.T) {\n \n \terr := summarizeAudio(buf, prompt, tc.ProjectID, location, modelName)\n \tif err != nil {\n-\t\tt.Errorf(\"Test_generateMultimodalContent: %v\", err.Error())\n+\t\tt.Errorf(\"Test_summarizeAudio: %v\", err.Error())\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into text-embedding-google_io_2024_new_model",
        "commit_id": "b73ded9238e7affe8350cc30e0ffdf5b07dc06d8"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "functions/tips/lazy.go",
        "code_diff": "@@ -14,7 +14,6 @@\n// [START functions_tips_lazy_globals]\n // [START cloudrun_tips_global_lazy]\n-// [START run_tips_global_lazy]\n \n // Package tips contains tips for writing Cloud Functions in Go.\n package tips",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "functions/tips/scope.go",
        "code_diff": "@@ -24,7 +24,6 @@\nimport (\n \n // [START functions_tips_scopes]\n // [START cloudrun_tips_global_scope]\n-// [START run_tips_global_scope]\n \n // h is in the global (instance-wide) scope.\n var h string",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -28,15 +28,43 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n-// CreateTestBucket creates a new bucket with the given prefix\n-func CreateTestBucket(ctx context.Context, t *testing.T, client *storage.Client, projectID, prefix string) (string, error) {\n+// TestBucket creates a new bucket with the given prefix and registers a cleanup\n+// function to delete the bucket and any objects it contains when the test finishes.\n+// TestBucket returns the bucket name. It fails the test if bucket creation fails.\n+func TestBucket(ctx context.Context, t *testing.T, projectID, prefix string) string {\n+\tt.Helper()\n+\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tt.Cleanup(func() { client.Close() })\n+\treturn CreateTestBucket(ctx, t, client, projectID, prefix)\n+}\n+\n+// CreateTestBucket creates a new bucket with the given prefix and registers a\n+// cleanup function to delete the bucket and any objects it contains.\n+// It is equivalent to TestBucket but allows Storage Client re-use.\n+func CreateTestBucket(ctx context.Context, t *testing.T, client *storage.Client, projectID, prefix string) string {\n \tt.Helper()\n \tbucketName := UniqueBucketName(prefix)\n-\treturn bucketName, cleanBucketWithClient(ctx, t, client, projectID, bucketName)\n+\n+\tb := client.Bucket(bucketName)\n+\tif err := b.Create(ctx, projectID, nil); err != nil {\n+\t\tt.Fatalf(\"Bucket.Create(%q): %v\", bucketName, err)\n+\t}\n+\n+\tt.Cleanup(func() {\n+\t\tif err := DeleteBucketIfExists(ctx, client, bucketName); err != nil {\n+\t\t\tlog.Printf(\"Bucket.Delete(%q): %v\", bucketName, err)\n+\t\t}\n+\t})\n+\treturn bucketName\n }\n \n // CleanBucket creates a new bucket. If the bucket already exists, it will be\n // deleted and recreated.\n+// Deprecated: use TestBucket or CreateTestBucket instead.\n func CleanBucket(ctx context.Context, t *testing.T, projectID, bucket string) error {\n \tt.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -78,7 +106,7 @@\nfunc cleanBucketWithClient(ctx context.Context, t *testing.T, client *storage.Cl\n \treturn nil\n }\n \n-// DeleteBucketIfExists deletes a bucket and all its objects\n+// DeleteBucketIfExists deletes a bucket and all its objects.\n func DeleteBucketIfExists(ctx context.Context, client *storage.Client, bucket string) error {\n \tb := client.Bucket(bucket)",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/authentication/auth.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage authentication\n \n // [START cloudrun_service_to_service_auth]\n-// [START run_service_to_service_auth]\n import (\n \t\"fmt\"\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/grpc-ping/connection.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage main\n \n // [START cloudrun_grpc_conn]\n-// [START run_grpc_conn]\n \n import (\n \t\"crypto/tls\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/grpc-ping/main.go",
        "code_diff": "@@ -26,7 +26,6 @@\nimport (\n )\n \n // [START cloudrun_grpc_server]\n-// [START run_grpc_server]\n func main() {\n \tlog.Printf(\"grpc-ping: starting server...\")",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/grpc-ping/request.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage main\n \n // [START cloudrun_grpc_request]\n-// [START run_grpc_request]\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/grpc-ping/request_auth.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage main\n \n // [START cloudrun_grpc_request_auth]\n-// [START run_grpc_request_auth]\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/hello-broken/main.go",
        "code_diff": "@@ -13,7 +13,6 @@\n// limitations under the License.\n \n // [START cloudrun_broken_service]\n-// [START run_broken_service]\n \n // Sample hello demonstrates a difficult to troubleshoot service.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/hello-broken/main.go",
        "code_diff": "@@ -30,11 +29,9 @@\nfunc main() {\n \n \thttp.HandleFunc(\"/\", helloHandler)\n \n-\t// [END run_broken_service]\n \t// [END cloudrun_broken_service]\n \thttp.HandleFunc(\"/improved\", improvedHandler)\n \t// [START cloudrun_broken_service]\n-\t// [START run_broken_service]\n \n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/helloworld/main.go",
        "code_diff": "@@ -13,7 +13,6 @@\n// limitations under the License.\n \n // [START cloudrun_helloworld_service]\n-// [START run_helloworld_service]\n \n // Sample run-helloworld is a minimal Cloud Run service.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/image-processing/imagemagick/imagemagick.go",
        "code_diff": "@@ -13,7 +13,6 @@\n// limitations under the License.\n \n // [START cloudrun_imageproc_handler_setup]\n-// [START run_imageproc_handler_setup]\n \n // Package imagemagick contains an example of using ImageMagick to process a\n // file uploaded to Cloud Storage.",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/image-processing/imagemagick/imagemagick.go",
        "code_diff": "@@ -53,11 +52,9 @@\nfunc init() {\n \t}\n }\n \n-// [END run_imageproc_handler_setup]\n // [END cloudrun_imageproc_handler_setup]\n \n // [START cloudrun_imageproc_handler_analyze]\n-// [START run_imageproc_handler_analyze]\n \n // GCSEvent is the payload of a GCS event.\n type GCSEvent struct {",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/image-processing/imagemagick/imagemagick.go",
        "code_diff": "@@ -87,11 +84,9 @@\nfunc BlurOffensiveImages(ctx context.Context, e GCSEvent) error {\n \treturn nil\n }\n \n-// [END run_imageproc_handler_analyze]\n // [END cloudrun_imageproc_handler_analyze]\n \n // [START cloudrun_imageproc_handler_blur]\n-// [START run_imageproc_handler_blur]\n \n // blur blurs the image stored at gs://inputBucket/name and stores the result in\n // gs://outputBucket/name.",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/image-processing/main.go",
        "code_diff": "@@ -13,7 +13,6 @@\n// limitations under the License.\n \n // [START cloudrun_imageproc_controller]\n-// [START run_imageproc_controller]\n \n // Sample image-processing is a Cloud Run service which performs asynchronous processing on images.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/logging-manual/main.go",
        "code_diff": "@@ -52,7 +52,6 @@\nfunc main() {\n }\n \n // [START cloudrun_manual_logging_object]\n-// [START run_manual_logging_object]\n \n // Entry defines a log entry.\n type Entry struct {",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/logging-manual/main.go",
        "code_diff": "@@ -76,11 +75,9 @@\nfunc (e Entry) String() string {\n \treturn string(out)\n }\n \n-// [END run_manual_logging_object]\n // [END cloudrun_manual_logging_object]\n \n // [START cloudrun_manual_logging]\n-// [START run_manual_logging]\n \n func init() {\n \t// Disable log prefixes such as the default timestamp.",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage main\n \n // [START cloudrun_secure_request]\n-// [START run_secure_request]\n import (\n \t\"bytes\"\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -65,11 +64,9 @@\nfunc (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \treturn req, nil\n }\n \n-// [END run_secure_request]\n // [END cloudrun_secure_request]\n \n // [START cloudrun_secure_request_do]\n-// [START run_secure_request_do]\n \n var renderClient = &http.Client{Timeout: 30 * time.Second}",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/pubsub/main.go",
        "code_diff": "@@ -13,7 +13,6 @@\n// limitations under the License.\n \n // [START cloudrun_pubsub_server]\n-// [START run_pubsub_server]\n \n // Sample run-pubsub is a Cloud Run service which handles Pub/Sub messages.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/pubsub/main.go",
        "code_diff": "@@ -41,11 +40,9 @@\nfunc main() {\n \t}\n }\n \n-// [END run_pubsub_server]\n // [END cloudrun_pubsub_server]\n \n // [START cloudrun_pubsub_handler]\n-// [START run_pubsub_handler]\n \n // PubSubMessage is the payload of a Pub/Sub event.\n // See the documentation for more details:",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/system_package/graphviz.go",
        "code_diff": "@@ -54,7 +54,6 @@\nfunc main() {\n }\n \n // [START cloudrun_system_package_handler]\n-// [START run_system_package_handler]\n \n // diagramHandler renders a diagram using HTTP request parameters and the dot command.\n func diagramHandler(w http.ResponseWriter, r *http.Request) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "feat(vertexai): system instruction",
        "pr_number": 4121,
        "file_name": "run/system_package/graphviz.go",
        "code_diff": "@@ -88,11 +87,9 @@\nfunc diagramHandler(w http.ResponseWriter, r *http.Request) {\n \t}\n }\n \n-// [END run_system_package_handler]\n // [END cloudrun_system_package_handler]\n \n // [START cloudrun_system_package_exec]\n-// [START run_system_package_exec]\n \n // createDiagram generates a diagram image from the provided io.Reader written to the io.Writer.\n func createDiagram(w io.Writer, r io.Reader) error {",
        "comments": [],
        "commit_message": "Merge branch 'main' into system-instruction",
        "commit_id": "eaf9b96e762c8b29f98d5ba6ee14c22ac5800abc"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -1072,6 +1072,46 @@\nfunc TestPgOrderNulls(t *testing.T) {\n \tassertContains(t, out, \"Singers ORDER BY Name DESC NULLS LAST\\n\\tBruce\\n\\tAlice\\n\\t<null>\")\n }\n \n+func TestProtoColumnSample(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\n+\tctx, cancel := context.WithTimeout(context.Background(), time.Hour)\n+\tdefer cancel()\n+\n+\tstatements := []string{\n+\t\t`CREATE TABLE Singers (\n+\t\t\t\tSingerId   INT64 NOT NULL,\n+\t\t\t\tFirstName  STRING(1024),\n+\t\t\t\tLastName   STRING(1024),\n+\t\t\t) PRIMARY KEY (SingerId)`,\n+\t\t`CREATE TABLE Albums (\n+\t\t\t\tSingerId     INT64 NOT NULL,\n+\t\t\t\tAlbumId      INT64 NOT NULL,\n+\t\t\t\tAlbumTitle   STRING(MAX)\n+\t\t\t) PRIMARY KEY (SingerId, AlbumId),\n+\t\t\tINTERLEAVE IN PARENT Singers ON DELETE CASCADE`,\n+\t}\n+\tdbCleanup, err := createTestDatabase(dbName, statements...)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tvar out string\n+\trunSample(t, write, dbName, \"failed to insert data\")\n+\trunSampleWithContext(ctx, t, addProtoColumn, dbName, \"failed to update db for proto columns\")\n+\tout = runSample(t, updateDataWithProtoColumn, dbName, \"failed to update data with proto columns\")\n+\tassertContains(t, out, \"Data updated\\n\")\n+\tout = runSample(t, updateDataWithProtoColumnWithDml, dbName, \"failed to update data with proto columns using dml\")\n+\tassertContains(t, out, \"record(s) updated.\")\n+\tout = runSample(t, queryWithProtoParameter, dbName, \"failed to query with proto parameter\")\n+\tassertContains(t, out, \"2 singer_id:2\")\n+}\n+\n func maybeCreateKey(projectId, locationId, keyRingId, keyId string) error {\n \tclient, err := kms.NewKeyManagementClient(context.Background())\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into randombuckets",
        "commit_id": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(storagetransfer): add retries to all storagetransfer tests",
        "pr_number": 3972,
        "file_name": "compute/create_instance_from_template_with_overrides.go",
        "code_diff": "@@ -21,7 +21,8 @@\nimport (\n \t\"io\"\n \n \tcompute \"cloud.google.com/go/compute/apiv1\"\n-\tcomputepb \"google.golang.org/genproto/googleapis/cloud/compute/v1\"\n+\tcomputepb \"cloud.google.com/go/compute/apiv1/computepb\"\n+\n \t\"google.golang.org/protobuf/proto\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into stssampleretries",
        "commit_id": "dfd69ed611c69003d870e123eb1b41b56c19ef10"
    },
    {
        "pr_title": "test(storagetransfer): add retries to all storagetransfer tests",
        "pr_number": 3972,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n+\t\"cloud.google.com/go/pubsub/pstest\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"google.golang.org/api/iterator\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into stssampleretries",
        "commit_id": "dfd69ed611c69003d870e123eb1b41b56c19ef10"
    },
    {
        "pr_title": "feat(spanner): add a sample for max commit delays",
        "pr_number": 3846,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -26,7 +26,7 @@\nimport (\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"github.com/googleapis/gax-go/v2/apierror\"\n+\t\"google.golang.org/api/googleapi\"\n \t\"google.golang.org/api/iterator\"\n )",
        "comments": [],
        "commit_message": "Merge remote-tracking branch 'origin' into sample",
        "commit_id": "3b6876e8927f36a544958dfa016677eeece30433"
    },
    {
        "pr_title": "feat(spanner): add transaction timeout sample",
        "pr_number": 3808,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -24,10 +24,10 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/googleapis/gax-go/v2/apierror\"\n \t\"google.golang.org/api/iterator\"\n-\n-\t\"cloud.google.com/go/storage\"\n )\n \n var serviceAccountEmail = os.Getenv(\"GOLANG_SAMPLES_SERVICE_ACCOUNT_EMAIL\")",
        "comments": [],
        "commit_message": "Merge branch 'main' into spanner-transaction-timeout",
        "commit_id": "763006f01f17af83cb369e0619a5bbbdb6914583"
    },
    {
        "pr_title": "feat(pubsub): add create kinesis topic and update samples",
        "pr_number": 3800,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -85,9 +85,8 @@\nfunc setup(t *testing.T) *pubsub.Client {\n \t\t\t\t}\n \t\t\t\ttimeTCreated := time.Unix(0, timestamp)\n \t\t\t\tif time.Since(timeTCreated) > expireAge {\n-\t\t\t\t\tif err := t.Delete(ctx); err != nil {\n-\t\t\t\t\t\tfmt.Printf(\"Delete topic err: %v: %v\", t.String(), err)\n-\t\t\t\t\t}\n+\t\t\t\t\t// Topic deletion can be fire and forget\n+\t\t\t\t\tt.Delete(ctx)\n \t\t\t\t}\n \t\t\t}\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into pubsub-kinesis-ingestion",
        "commit_id": "e0a339ad6c2ab7c336e3d94c3593c3282511624b"
    },
    {
        "pr_title": "feat(vertexai): function calling",
        "pr_number": 3779,
        "file_name": "vertexai/function-calling/functioncalling.go",
        "code_diff": "@@ -45,6 +45,7 @@\nfunc functionCalls(w io.Writer, prompt, projectID, location, modelName string) e\n \n \tmodel := client.GenerativeModel(modelName)\n \n+\t// Build an OpenAPI schema, in memory\n \tparams := &genai.Schema{\n \t\tType: genai.TypeObject,\n \t\tProperties: map[string]*genai.Schema{",
        "comments": [
            {
                "comment": "Don't declare a `main()` in golang-samples. Provide a meaningful function name with a docstring.\r\n\r\n",
                "position": null
            },
            {
                "comment": "Pass `projectID` into the function.",
                "position": null
            },
            {
                "comment": "Pass in `io.Writer`, write console output to it.\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/main/CONTRIBUTING.md#print-to-an-iowriter-for-snippets",
                "position": null
            },
            {
                "comment": "Remove this check.",
                "position": null
            },
            {
                "comment": "Don't hardcode location unless you have too.",
                "position": null
            },
            {
                "comment": "Replace with call to `fmt.Fprintf(writer)`",
                "position": null
            },
            {
                "comment": "Lower case \"function call\" unless this is a proper noun.",
                "position": null
            },
            {
                "comment": "Pass in a writer instead of stdout. We can't read from stdout in tests (unless we do some awkward pipe-ing).",
                "position": null
            },
            {
                "comment": "If \"Function Call\" is a proper noun -- that is, if it is a unique feature of Vertex -- provide a link to the documentation on cloud.google.com.",
                "position": null
            },
            {
                "comment": "NIT: pass in prompt to function. That way we can configure inputs/outputs in the tests.",
                "position": null
            },
            {
                "comment": "Why are we creating a schema in memory? AIUI, developers would open an OpenAPI Swagger file that defines the schema. Opening a schema file from the internet makes more sense here.",
                "position": 49
            },
            {
                "comment": "Insert line break before `||`.",
                "position": null
            },
            {
                "comment": "Why is has the actual sample (the calls to Gemini) been abstracted out of the main body? I recommend moving the entire sample into a single function.",
                "position": null
            },
            {
                "comment": "Check whether \"Function Call\" should be a proper noun. Is this a feature of Vertex? If it is, ",
                "position": null
            },
            {
                "comment": "Use more descriptive variable names in samples. I don't know what 'rb' is unless I look at the ref docs for `json.MarshalIndent()`.",
                "position": null
            },
            {
                "comment": "Insert line break before `||`.",
                "position": null
            },
            {
                "comment": "According to [this doc page](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling), lower case should be prefered.",
                "position": null
            },
            {
                "comment": "After `||` ?",
                "position": null
            },
            {
                "comment": "Unfortunately, I'm not aware of an existing ready-to-use parser from bytes to `genai.Schema`",
                "position": 49
            },
            {
                "comment": "Fair enough. I would put a comment before this block that explicitly states that you're creating an OpenAPI schema in memory.\r\n\r\nI do believe that there are a few Go libraries that can parse this -- for example, libopenapi -- but it's reasonable to skip that step for demonstration purposes.",
                "position": 49
            },
            {
                "comment": "Don't throw away the error here. ",
                "position": null
            },
            {
                "comment": "Same as above. Be sure to handle the error.",
                "position": null
            }
        ],
        "commit_message": "fix(vertexai): in function-calling, do not ignore error from json.MarshalIndent",
        "commit_id": "7a90bb56bb5c442a7c8210b3a23a40af0085122f"
    },
    {
        "pr_title": "feat(vertexai): function calling",
        "pr_number": 3779,
        "file_name": "vertexai/function-calling/functioncalling.go",
        "code_diff": "@@ -54,13 +55,11 @@\nfunc functionCalls(w io.Writer, prompt, projectID, location, modelName string) e\n \t\t\t},\n \t\t},\n \t}\n-\n \tfundecl := &genai.FunctionDeclaration{\n \t\tName:        \"getCurrentWeather\",\n \t\tDescription: \"Get the current weather in a given location\",\n \t\tParameters:  params,\n \t}\n-\n \tmodel.Tools = []*genai.Tool{\n \t\t{FunctionDeclarations: []*genai.FunctionDeclaration{fundecl}},\n \t}",
        "comments": [
            {
                "comment": "Don't declare a `main()` in golang-samples. Provide a meaningful function name with a docstring.\r\n\r\n",
                "position": null
            },
            {
                "comment": "Pass `projectID` into the function.",
                "position": null
            },
            {
                "comment": "Pass in `io.Writer`, write console output to it.\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/main/CONTRIBUTING.md#print-to-an-iowriter-for-snippets",
                "position": null
            },
            {
                "comment": "Remove this check.",
                "position": null
            },
            {
                "comment": "Don't hardcode location unless you have too.",
                "position": null
            },
            {
                "comment": "Replace with call to `fmt.Fprintf(writer)`",
                "position": null
            },
            {
                "comment": "Lower case \"function call\" unless this is a proper noun.",
                "position": null
            },
            {
                "comment": "Pass in a writer instead of stdout. We can't read from stdout in tests (unless we do some awkward pipe-ing).",
                "position": null
            },
            {
                "comment": "If \"Function Call\" is a proper noun -- that is, if it is a unique feature of Vertex -- provide a link to the documentation on cloud.google.com.",
                "position": null
            },
            {
                "comment": "NIT: pass in prompt to function. That way we can configure inputs/outputs in the tests.",
                "position": null
            },
            {
                "comment": "Insert line break before `||`.",
                "position": null
            },
            {
                "comment": "Why is has the actual sample (the calls to Gemini) been abstracted out of the main body? I recommend moving the entire sample into a single function.",
                "position": null
            },
            {
                "comment": "Check whether \"Function Call\" should be a proper noun. Is this a feature of Vertex? If it is, ",
                "position": null
            },
            {
                "comment": "Use more descriptive variable names in samples. I don't know what 'rb' is unless I look at the ref docs for `json.MarshalIndent()`.",
                "position": null
            },
            {
                "comment": "Insert line break before `||`.",
                "position": null
            },
            {
                "comment": "According to [this doc page](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling), lower case should be prefered.",
                "position": null
            },
            {
                "comment": "After `||` ?",
                "position": null
            },
            {
                "comment": "Don't throw away the error here. ",
                "position": null
            },
            {
                "comment": "Same as above. Be sure to handle the error.",
                "position": null
            }
        ],
        "commit_message": "fix(vertexai): in function-calling, do not ignore error from json.MarshalIndent",
        "commit_id": "7a90bb56bb5c442a7c8210b3a23a40af0085122f"
    },
    {
        "pr_title": "feat(vertexai): function calling",
        "pr_number": 3779,
        "file_name": "vertexai/function-calling/functioncalling.go",
        "code_diff": "@@ -79,7 +78,10 @@\nfunc functionCalls(w io.Writer, prompt, projectID, location, modelName string) e\n \n \t// The model has returned a function call to the declared function `getCurrentWeather`\n \t// with a value for the argument `location`.\n-\tjsondata, _ := json.MarshalIndent(resp.Candidates[0].Content.Parts[0], \"\", \"  \")\n+\tjsondata, err := json.MarshalIndent(resp.Candidates[0].Content.Parts[0], \"\", \"  \")\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"json.Marshal: %w\", err)\n+\t}\n \tfmt.Fprintf(w, \"function call generated by the model:\\n%s\\n\\n\", string(jsondata))\n \n \t// Create a function call response, to simulate the result of a call to a",
        "comments": [
            {
                "comment": "Don't declare a `main()` in golang-samples. Provide a meaningful function name with a docstring.\r\n\r\n",
                "position": null
            },
            {
                "comment": "Pass `projectID` into the function.",
                "position": null
            },
            {
                "comment": "Pass in `io.Writer`, write console output to it.\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/main/CONTRIBUTING.md#print-to-an-iowriter-for-snippets",
                "position": null
            },
            {
                "comment": "Remove this check.",
                "position": null
            },
            {
                "comment": "Don't hardcode location unless you have too.",
                "position": null
            },
            {
                "comment": "Replace with call to `fmt.Fprintf(writer)`",
                "position": null
            },
            {
                "comment": "Lower case \"function call\" unless this is a proper noun.",
                "position": null
            },
            {
                "comment": "Pass in a writer instead of stdout. We can't read from stdout in tests (unless we do some awkward pipe-ing).",
                "position": null
            },
            {
                "comment": "If \"Function Call\" is a proper noun -- that is, if it is a unique feature of Vertex -- provide a link to the documentation on cloud.google.com.",
                "position": null
            },
            {
                "comment": "NIT: pass in prompt to function. That way we can configure inputs/outputs in the tests.",
                "position": null
            },
            {
                "comment": "Insert line break before `||`.",
                "position": null
            },
            {
                "comment": "Why is has the actual sample (the calls to Gemini) been abstracted out of the main body? I recommend moving the entire sample into a single function.",
                "position": null
            },
            {
                "comment": "Check whether \"Function Call\" should be a proper noun. Is this a feature of Vertex? If it is, ",
                "position": null
            },
            {
                "comment": "Use more descriptive variable names in samples. I don't know what 'rb' is unless I look at the ref docs for `json.MarshalIndent()`.",
                "position": null
            },
            {
                "comment": "Insert line break before `||`.",
                "position": null
            },
            {
                "comment": "According to [this doc page](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling), lower case should be prefered.",
                "position": null
            },
            {
                "comment": "After `||` ?",
                "position": null
            },
            {
                "comment": "Don't throw away the error here. ",
                "position": null
            },
            {
                "comment": "Same as above. Be sure to handle the error.",
                "position": null
            }
        ],
        "commit_message": "fix(vertexai): in function-calling, do not ignore error from json.MarshalIndent",
        "commit_id": "7a90bb56bb5c442a7c8210b3a23a40af0085122f"
    },
    {
        "pr_title": "feat(vertexai): function calling",
        "pr_number": 3779,
        "file_name": "vertexai/function-calling/functioncalling.go",
        "code_diff": "@@ -90,7 +92,10 @@\nfunc functionCalls(w io.Writer, prompt, projectID, location, modelName string) e\n \t\t\t\"currentWeather\": \"sunny\",\n \t\t},\n \t}\n-\tjsondata, _ = json.MarshalIndent(funresp, \"\", \"  \")\n+\tjsondata, err = json.MarshalIndent(funresp, \"\", \"  \")\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"json.Marshal: %w\", err)\n+\t}\n \tfmt.Fprintf(w, \"function call response sent to the model:\\n%s\\n\\n\", string(jsondata))\n \n \t// And provide the function call response to the model",
        "comments": [
            {
                "comment": "Don't declare a `main()` in golang-samples. Provide a meaningful function name with a docstring.\r\n\r\n",
                "position": null
            },
            {
                "comment": "Pass `projectID` into the function.",
                "position": null
            },
            {
                "comment": "Pass in `io.Writer`, write console output to it.\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/main/CONTRIBUTING.md#print-to-an-iowriter-for-snippets",
                "position": null
            },
            {
                "comment": "Remove this check.",
                "position": null
            },
            {
                "comment": "Don't hardcode location unless you have too.",
                "position": null
            },
            {
                "comment": "Replace with call to `fmt.Fprintf(writer)`",
                "position": null
            },
            {
                "comment": "Lower case \"function call\" unless this is a proper noun.",
                "position": null
            },
            {
                "comment": "Pass in a writer instead of stdout. We can't read from stdout in tests (unless we do some awkward pipe-ing).",
                "position": null
            },
            {
                "comment": "If \"Function Call\" is a proper noun -- that is, if it is a unique feature of Vertex -- provide a link to the documentation on cloud.google.com.",
                "position": null
            },
            {
                "comment": "NIT: pass in prompt to function. That way we can configure inputs/outputs in the tests.",
                "position": null
            },
            {
                "comment": "Insert line break before `||`.",
                "position": null
            },
            {
                "comment": "Why is has the actual sample (the calls to Gemini) been abstracted out of the main body? I recommend moving the entire sample into a single function.",
                "position": null
            },
            {
                "comment": "Check whether \"Function Call\" should be a proper noun. Is this a feature of Vertex? If it is, ",
                "position": null
            },
            {
                "comment": "Use more descriptive variable names in samples. I don't know what 'rb' is unless I look at the ref docs for `json.MarshalIndent()`.",
                "position": null
            },
            {
                "comment": "Insert line break before `||`.",
                "position": null
            },
            {
                "comment": "According to [this doc page](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling), lower case should be prefered.",
                "position": null
            },
            {
                "comment": "After `||` ?",
                "position": null
            },
            {
                "comment": "Don't throw away the error here. ",
                "position": null
            },
            {
                "comment": "Same as above. Be sure to handle the error.",
                "position": null
            }
        ],
        "commit_message": "fix(vertexai): in function-calling, do not ignore error from json.MarshalIndent",
        "commit_id": "7a90bb56bb5c442a7c8210b3a23a40af0085122f"
    },
    {
        "pr_title": "feat(vertexai): token count",
        "pr_number": 3778,
        "file_name": "vertexai/safety-settings-multimodal/safety-settings-multimodal_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package safetysettingsmultimodal\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into token-count",
        "commit_id": "42db7fb6e67fc2d989d831ba0439d425530c7b19"
    },
    {
        "pr_title": "feat(vertexai): token count",
        "pr_number": 3778,
        "file_name": "vertexai/safety-settings/safety-settings.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2023 Google LLC\n+// Copyright 2024 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'main' into token-count",
        "commit_id": "42db7fb6e67fc2d989d831ba0439d425530c7b19"
    },
    {
        "pr_title": "feat(vertexai): token count",
        "pr_number": 3778,
        "file_name": "vertexai/safety-settings/safety-settings_test.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2023 Google LLC\n+// Copyright 2024 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'main' into token-count",
        "commit_id": "42db7fb6e67fc2d989d831ba0439d425530c7b19"
    },
    {
        "pr_title": "feat(vertexai): token count",
        "pr_number": 3778,
        "file_name": "vertexai/safety-settings/safety-settings_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package safetysettings\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into token-count",
        "commit_id": "42db7fb6e67fc2d989d831ba0439d425530c7b19"
    },
    {
        "pr_title": "test(storage): add retry to HMAC key deletion",
        "pr_number": 3759,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -391,16 +391,13 @@\nfunc TestKMSObjects(t *testing.T) {\n func TestV4SignedURL(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n-\t}\n-\tdefer client.Close()\n \n \tbucketName := tc.ProjectID + \"-signed-url-bucket-name\"\n \tobjectName := \"foo.txt\"\n \n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n+\n+\t// Generate PUT URL.\n \tputBuf := new(bytes.Buffer)\n \tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix-flaky-hmac",
        "commit_id": "705ca7c6c578bc328873239a29e3b233a77d5ad4"
    },
    {
        "pr_title": "test(storage): add retry to HMAC key deletion",
        "pr_number": 3759,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -411,17 +408,7 @@\nfunc TestV4SignedURL(t *testing.T) {\n \t\tt.Errorf(\"got %q, want %q\", got, want)\n \t}\n \n-\thttpClient := &http.Client{}\n-\trequest, err := http.NewRequest(\"PUT\", putURL, strings.NewReader(\"hello world\"))\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to compose HTTP request: %v\", err)\n-\t}\n-\trequest.ContentLength = 11\n-\trequest.Header.Set(\"Content-Type\", \"application/octet-stream\")\n-\t_, err = httpClient.Do(request)\n-\tif err != nil {\n-\t\tt.Errorf(\"httpClient.Do: %v\", err)\n-\t}\n+\t// Generate GET URL.\n \tgetBuf := new(bytes.Buffer)\n \tgetURL, err := generateV4GetObjectSignedURL(getBuf, bucketName, objectName)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix-flaky-hmac",
        "commit_id": "705ca7c6c578bc328873239a29e3b233a77d5ad4"
    },
    {
        "pr_title": "test(profiler): add tests for ListProfiles sample",
        "pr_number": 3707,
        "file_name": "profiler/export/main_test.go",
        "code_diff": "@@ -17,7 +17,6 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n-\t\"os\"\n \t\"runtime\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [
            {
                "comment": "```suggestion\r\n\ttc := testutil.EndToEndTest(t)\r\n\tprojectID := tc.ProjectID\r\n```\r\nThis is the typical pattern for tests, and will fail the test if the projectID is unspecified, so you can safely delete 32-35.",
                "position": null
            }
        ],
        "commit_message": "update projectID retrieval for running tests",
        "commit_id": "952811f05f80b56c096e78a44847eb8ff3f55e8a"
    },
    {
        "pr_title": "feat(vertexai): adds a Gemini video example",
        "pr_number": 3612,
        "file_name": "vertexai/multimodal-video/multimodal-video.go",
        "code_diff": "@@ -34,7 +34,6 @@\nfunc main() {\n \tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tlocation := \"us-central1\"\n \tmodelName := \"gemini-pro-vision\"\n-\ttemperature := 0.4\n \n \tif projectID == \"\" {\n \t\tlog.Fatal(\"require environment variable GOOGLE_CLOUD_PROJECT\")",
        "comments": [
            {
                "comment": "nit: this should take a context",
                "position": null
            },
            {
                "comment": "Why single out temperature as the one config setting that is passed in? Maybe it's better to leave out all config for clarity?",
                "position": null
            },
            {
                "comment": "nit: if you're taking an arbitrary io.Writer, you should check for errors:\r\n```\r\n_, err := fmt.Fprintf(...)\r\nreturn err\r\n```",
                "position": null
            },
            {
                "comment": "Take ctx as arg.",
                "position": null
            },
            {
                "comment": "Try `path.Ext`\r\nhttps://pkg.go.dev/path#Ext\r\nNote that it returns the empty string if missing.",
                "position": null
            },
            {
                "comment": "ack, although we're not doing this in any of the other snippet samples - can you please advise if this is ok for now or should we refactor the others to include context?",
                "position": null
            },
            {
                "comment": "Given that both of these methods require a context, I will uplift for this example; thank you for pointing this out!",
                "position": null
            },
            {
                "comment": "Not urgent, but you should indeed change the others.",
                "position": null
            },
            {
                "comment": "Useful, thank you!",
                "position": null
            },
            {
                "comment": "added path pkg",
                "position": null
            },
            {
                "comment": "Agree we should go for consistency here and determine what configurations are worth explicitly calling out as useful ones. Will adjust here and review others.",
                "position": null
            }
        ],
        "commit_message": "model temperature in method",
        "commit_id": "516b7f001dfd57fd4dfecc45398dcf5f28217f75"
    },
    {
        "pr_title": "feat(vertexai): adds a Gemini video example",
        "pr_number": 3612,
        "file_name": "vertexai/multimodal-video/multimodal-video_test.go",
        "code_diff": "@@ -32,7 +32,6 @@\nfunc TestGenerateMultimodalContent(t *testing.T) {\n \tlocation := \"us-central1\"\n \n \tmodelName := \"gemini-pro-vision\"\n-\ttemperature := 0.8\n \n \tctx := context.Background()",
        "comments": [],
        "commit_message": "model temperature in method",
        "commit_id": "516b7f001dfd57fd4dfecc45398dcf5f28217f75"
    },
    {
        "pr_title": "feat(otel): use Cloud Logging structured log conventions",
        "pr_number": 3590,
        "file_name": "opentelemetry/instrumentation/app/logger.go",
        "code_diff": "@@ -16,11 +16,15 @@\npackage main\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"log/slog\"\n+\t\"os\"\n \n \t\"go.opentelemetry.io/otel/trace\"\n )\n \n+var projectId = os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n+\n // handerWithSpanContext adds attributes from the span context\n // [START opentelemetry_instrumentation_spancontext_logger]\n func handerWithSpanContext(handler slog.Handler) *spanContextLogHandler {",
        "comments": [],
        "commit_message": "feat(otel): use Cloud Logging structured log conventions",
        "commit_id": "4d2ab3693db87978a792803cf0b2c4922b78fc74"
    },
    {
        "pr_title": "feat(otel): use Cloud Logging structured log conventions",
        "pr_number": 3590,
        "file_name": "opentelemetry/instrumentation/app/main_test.go",
        "code_diff": "@@ -132,13 +132,13 @@\nfunc TestWriteTelemetry(t *testing.T) {\n }\n \n type expectedLogFormat struct {\n-\tTime        string `json:\"time\"`\n-\tLevel       string `json:\"level\"`\n-\tMsg         string `json:\"msg\"`\n-\tSubRequests int    `json:\"subRequests\"`\n-\tTraceID     string `json:\"trace_id\"`\n-\tSpanID      string `json:\"span_id\"`\n-\tTraceFlags  string `json:\"trace_flags\"`\n+\tTimestamp    string `json:\"timestamp\"`\n+\tSeverity     string `json:\"severity\"`\n+\tMessage      string `json:\"message\"`\n+\tSubRequests  int    `json:\"subRequests\"`\n+\tTraceID      string `json:\"logging.googleapis.com/trace\"`\n+\tSpanID       string `json:\"logging.googleapis.com/spanId\"`\n+\tTraceSampled bool   `json:\"logging.googleapis.com/trace_sampled\"`\n }\n \n const expectedLogMessage = \"handle /multi request\"",
        "comments": [],
        "commit_message": "feat(otel): use Cloud Logging structured log conventions",
        "commit_id": "4d2ab3693db87978a792803cf0b2c4922b78fc74"
    },
    {
        "pr_title": "chore: Update App Engine samples to the go121 runtime",
        "pr_number": 3585,
        "file_name": "opentelemetry/instrumentation/app/logger.go",
        "code_diff": "@@ -16,11 +16,15 @@\npackage main\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"log/slog\"\n+\t\"os\"\n \n \t\"go.opentelemetry.io/otel/trace\"\n )\n \n+var projectId = os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n+\n // handerWithSpanContext adds attributes from the span context\n // [START opentelemetry_instrumentation_spancontext_logger]\n func handerWithSpanContext(handler slog.Handler) *spanContextLogHandler {",
        "comments": [],
        "commit_message": "Merge branch 'main' into chore-appengine-samples",
        "commit_id": "f3ca4f733491e48d889c3b7759e3bcea5a1b5994"
    },
    {
        "pr_title": "chore: Update App Engine samples to the go121 runtime",
        "pr_number": 3585,
        "file_name": "opentelemetry/instrumentation/app/main_test.go",
        "code_diff": "@@ -132,13 +132,13 @@\nfunc TestWriteTelemetry(t *testing.T) {\n }\n \n type expectedLogFormat struct {\n-\tTime        string `json:\"time\"`\n-\tLevel       string `json:\"level\"`\n-\tMsg         string `json:\"msg\"`\n-\tSubRequests int    `json:\"subRequests\"`\n-\tTraceID     string `json:\"trace_id\"`\n-\tSpanID      string `json:\"span_id\"`\n-\tTraceFlags  string `json:\"trace_flags\"`\n+\tTimestamp    string `json:\"timestamp\"`\n+\tSeverity     string `json:\"severity\"`\n+\tMessage      string `json:\"message\"`\n+\tSubRequests  int    `json:\"subRequests\"`\n+\tTraceID      string `json:\"logging.googleapis.com/trace\"`\n+\tSpanID       string `json:\"logging.googleapis.com/spanId\"`\n+\tTraceSampled bool   `json:\"logging.googleapis.com/trace_sampled\"`\n }\n \n const expectedLogMessage = \"handle /multi request\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into chore-appengine-samples",
        "commit_id": "f3ca4f733491e48d889c3b7759e3bcea5a1b5994"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "vertexai/safety-settings-multimodal/safety-settings-multimodal.go",
        "code_diff": "@@ -20,10 +20,9 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"log\"\n-\t\"net/http\"\n-\t\"net/url\"\n+\t\"mime\"\n \t\"os\"\n-\t\"strings\"\n+\t\"path/filepath\"\n \n \t\"cloud.google.com/go/vertexai/genai\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "vertexai/safety-settings-multimodal/safety-settings-multimodal.go",
        "code_diff": "@@ -32,39 +31,33 @@\nfunc main() {\n \tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tlocation := \"us-central1\"\n \tmodelName := \"gemini-pro-vision\"\n-\ttemperature := 0.4\n+\n+\tprompt := \"describe what is in this picture\"\n+\timage := \"gs://generativeai-downloads/images/scones.jpg\"\n \n \tif projectID == \"\" {\n \t\tlog.Fatal(\"require environment variable GOOGLE_CLOUD_PROJECT\")\n \t}\n \n-\tcat, _ := partFromImageURL(\"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\")\n-\n-\t// create a multipart (multimodal) prompt\n-\tprompt := []genai.Part{\n-\t\tgenai.Text(\"say something nice about this \"),\n-\t\tcat,\n-\t}\n-\n-\terr := generateContent(os.Stdout, prompt, projectID, location, modelName, float32(temperature))\n+\terr := generateMultimodalContent(os.Stdout, prompt, image, projectID, location, modelName)\n \tif err != nil {\n-\t\tfmt.Printf(\"unable to generate: %v\\n\", err)\n+\t\tlog.Fatalf(\"unable to generate: %v\", err)\n \t}\n }\n \n-// generateContent generates text from prompt and configurations provided.\n-func generateContent(w io.Writer, prompt []genai.Part, projectID, location, modelName string, temperature float32) error {\n+// generateMultimodalContent generates a response into w, based upon the prompt\n+// and image provided.\n+func generateMultimodalContent(w io.Writer, prompt, image, projectID, location, modelName string) error {\n \tctx := context.Background()\n \n \tclient, err := genai.NewClient(ctx, projectID, location)\n \tif err != nil {\n-\t\treturn err\n+\t\treturn fmt.Errorf(\"unable to create client: %v\", err)\n \t}\n \tdefer client.Close()\n \n \tmodel := client.GenerativeModel(modelName)\n-\tmodel.Temperature = temperature\n-\n+\tmodel.Temperature = 0.4\n \t// configure the safety settings thresholds\n \tmodel.SafetySettings = []*genai.SafetySetting{\n \t\t{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat(testing): convert Kokoro to use new Makefile-based testing",
        "pr_number": 3574,
        "file_name": "bigquery/bigquery_migration_quickstart/main.go",
        "code_diff": "@@ -27,7 +27,7 @@\nimport (\n \t\"time\"\n \n \tmigration \"cloud.google.com/go/bigquery/migration/apiv2\"\n-\tmigrationpb \"google.golang.org/genproto/googleapis/cloud/bigquery/migration/v2\"\n+\t\"cloud.google.com/go/bigquery/migration/apiv2/migrationpb\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'main' into kokoro-make",
        "commit_id": "4b10288712c1b40bc670f767f55b12a576c755ea"
    },
    {
        "pr_title": "feat(testing): convert Kokoro to use new Makefile-based testing",
        "pr_number": 3574,
        "file_name": "bigquery/bigquery_migration_quickstart/main.go",
        "code_diff": "@@ -56,7 +56,7 @@\nfunc main() {\n \n \tworkflow, err := executeTranslationWorkflow(ctx, migClient, *projectID, *location, *outputPath)\n \tif err != nil {\n-\t\tlog.Fatalf(\"workflow execution failed: %v\", err)\n+\t\tlog.Fatalf(\"workflow execution failed: %v\\n\", err)\n \t}\n \n \treportWorkflowStatus(workflow)",
        "comments": [],
        "commit_message": "Merge branch 'main' into kokoro-make",
        "commit_id": "4b10288712c1b40bc670f767f55b12a576c755ea"
    },
    {
        "pr_title": "feat(testing): convert Kokoro to use new Makefile-based testing",
        "pr_number": 3574,
        "file_name": "aiplatform/snippets/import_data_image_classification_test.go",
        "code_diff": "@@ -64,12 +64,12 @@\nfunc setupImportDatasetImageClassification(t *testing.T) func() {\n \n \top, err := client.CreateDataset(ctx, req)\n \tif err != nil {\n-\t\tt.Fatal(err)\n+\t\tt.Fatalf(\"CreateDataset: %v\", err)\n \t}\n \n \tresp, err := op.Wait(ctx)\n \tif err != nil {\n-\t\tt.Fatal(err)\n+\t\tt.Fatalf(\"Wait: %v\", err)\n \t}\n \n \tdatasetName = resp.GetName()",
        "comments": [],
        "commit_message": "Merge branch 'main' into kokoro-make",
        "commit_id": "273ff25201532fc0658d7c768973a77684eecee1"
    },
    {
        "pr_title": "feat(testing): convert Kokoro to use new Makefile-based testing",
        "pr_number": 3574,
        "file_name": "opentelemetry/instrumentation/app/logger.go",
        "code_diff": "@@ -16,11 +16,15 @@\npackage main\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"log/slog\"\n+\t\"os\"\n \n \t\"go.opentelemetry.io/otel/trace\"\n )\n \n+var projectId = os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n+\n // handerWithSpanContext adds attributes from the span context\n // [START opentelemetry_instrumentation_spancontext_logger]\n func handerWithSpanContext(handler slog.Handler) *spanContextLogHandler {",
        "comments": [],
        "commit_message": "Merge branch 'main' into kokoro-make",
        "commit_id": "273ff25201532fc0658d7c768973a77684eecee1"
    },
    {
        "pr_title": "feat(testing): convert Kokoro to use new Makefile-based testing",
        "pr_number": 3574,
        "file_name": "opentelemetry/instrumentation/app/main_test.go",
        "code_diff": "@@ -132,13 +132,13 @@\nfunc TestWriteTelemetry(t *testing.T) {\n }\n \n type expectedLogFormat struct {\n-\tTime        string `json:\"time\"`\n-\tLevel       string `json:\"level\"`\n-\tMsg         string `json:\"msg\"`\n-\tSubRequests int    `json:\"subRequests\"`\n-\tTraceID     string `json:\"trace_id\"`\n-\tSpanID      string `json:\"span_id\"`\n-\tTraceFlags  string `json:\"trace_flags\"`\n+\tTimestamp    string `json:\"timestamp\"`\n+\tSeverity     string `json:\"severity\"`\n+\tMessage      string `json:\"message\"`\n+\tSubRequests  int    `json:\"subRequests\"`\n+\tTraceID      string `json:\"logging.googleapis.com/trace\"`\n+\tSpanID       string `json:\"logging.googleapis.com/spanId\"`\n+\tTraceSampled bool   `json:\"logging.googleapis.com/trace_sampled\"`\n }\n \n const expectedLogMessage = \"handle /multi request\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into kokoro-make",
        "commit_id": "273ff25201532fc0658d7c768973a77684eecee1"
    },
    {
        "pr_title": "feat: add sample and test for getting an access token from an imperso\u2026",
        "pr_number": 3450,
        "file_name": "bigquery/bigquery_migration_quickstart/main_test.go",
        "code_diff": "@@ -26,6 +26,8 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n+var appTimeout = 60 * time.Second\n+\n func TestApp(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tm := testutil.BuildMain(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into auth",
        "commit_id": "133e131986f263fae31d327a9f22b08e6c2b3467"
    },
    {
        "pr_title": "feat: add sample and test for getting an access token from an imperso\u2026",
        "pr_number": 3450,
        "file_name": "run/testing/h2c.e2e_test.go",
        "code_diff": "@@ -15,7 +15,7 @@\npackage cloudruntests\n \n import (\n-\t\"io/ioutil\"\n+\t\"io\"\n \t\"net/http\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into auth",
        "commit_id": "133e131986f263fae31d327a9f22b08e6c2b3467"
    },
    {
        "pr_title": "feat: add sample and test for getting an access token from an imperso\u2026",
        "pr_number": 3450,
        "file_name": "run/testing/helloworld.e2e_test.go",
        "code_diff": "@@ -15,7 +15,7 @@\npackage cloudruntests\n \n import (\n-\t\"io/ioutil\"\n+\t\"io\"\n \t\"net/http\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into auth",
        "commit_id": "133e131986f263fae31d327a9f22b08e6c2b3467"
    },
    {
        "pr_title": "feat: add sample and test for getting an access token from an imperso\u2026",
        "pr_number": 3450,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -17,7 +17,7 @@\npackage cloudruntests\n import (\n \t\"bytes\"\n \t\"encoding/json\"\n-\t\"io/ioutil\"\n+\t\"io\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into auth",
        "commit_id": "133e131986f263fae31d327a9f22b08e6c2b3467"
    },
    {
        "pr_title": "feat: add sample and test for getting an access token from an imperso\u2026",
        "pr_number": 3450,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -90,7 +90,7 @@\nfunc caseEditorServiceRender(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"json.Marshall: %v\", err)\n \t}\n-\treq.Body = ioutil.NopCloser(bytes.NewReader(b))\n+\treq.Body = io.NopCloser(bytes.NewReader(b))\n \n \tresp, err := editorService.Do(req)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into auth",
        "commit_id": "133e131986f263fae31d327a9f22b08e6c2b3467"
    },
    {
        "pr_title": "feat: add sample and test for getting an access token from an imperso\u2026",
        "pr_number": 3450,
        "file_name": "run/testing/markdown_preview_renderer.e2e_test.go",
        "code_diff": "@@ -15,7 +15,7 @@\npackage cloudruntests\n \n import (\n-\t\"io/ioutil\"\n+\t\"io\"\n \t\"net/http\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into auth",
        "commit_id": "133e131986f263fae31d327a9f22b08e6c2b3467"
    },
    {
        "pr_title": "feat: add sample and test for getting an access token from an imperso\u2026",
        "pr_number": 3450,
        "file_name": "run/testing/markdown_preview_renderer.e2e_test.go",
        "code_diff": "@@ -55,7 +55,7 @@\nfunc TestRendererService(t *testing.T) {\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"service.NewRequest: %q\", err)\n \t\t}\n-\t\treq.Body = ioutil.NopCloser(strings.NewReader(test.input))\n+\t\treq.Body = io.NopCloser(strings.NewReader(test.input))\n \n \t\tresp, err := service.Do(req)\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into auth",
        "commit_id": "133e131986f263fae31d327a9f22b08e6c2b3467"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -48,348 +48,6 @@\nconst (\n \tredactImageTemplate            = \"redact-image-template-go\"\n )\n \n-func TestMask(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\ttests := []struct {\n-\t\tinput            string\n-\t\tmaskingCharacter string\n-\t\tnumberToMask     int32\n-\t\twant             string\n-\t}{\n-\t\t{\n-\t\t\tinput:            \"My SSN is 111222333\",\n-\t\t\tmaskingCharacter: \"+\",\n-\t\t\twant:             \"My SSN is +++++++++\",\n-\t\t},\n-\t\t{\n-\t\t\tinput: \"My SSN is 111222333\",\n-\t\t\twant:  \"My SSN is *********\",\n-\t\t},\n-\t\t{\n-\t\t\tinput:            \"My SSN is 111222333\",\n-\t\t\tmaskingCharacter: \"+\",\n-\t\t\tnumberToMask:     6,\n-\t\t\twant:             \"My SSN is ++++++333\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.input, func(t *testing.T) {\n-\t\t\ttest := test\n-\t\t\tt.Parallel()\n-\t\t\tbuf := new(bytes.Buffer)\n-\t\t\terr := mask(buf, tc.ProjectID, test.input, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, test.maskingCharacter, test.numberToMask)\n-\t\t\tif err != nil {\n-\t\t\t\tt.Errorf(\"mask(%q, %s, %v) = error %q, want %q\", test.input, test.maskingCharacter, test.numberToMask, err, test.want)\n-\t\t\t}\n-\t\t\tif got := buf.String(); got != test.want {\n-\t\t\t\tt.Errorf(\"mask(%q, %s, %v) = %q, want %q\", test.input, test.maskingCharacter, test.numberToMask, got, test.want)\n-\t\t\t}\n-\t\t})\n-\t}\n-}\n-\n-func TestDeidentifyDateShift(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\ttests := []struct {\n-\t\tinput      string\n-\t\twant       string\n-\t\tlowerBound int32\n-\t\tupperBound int32\n-\t}{\n-\t\t{\n-\t\t\tinput:      \"2016-01-10\",\n-\t\t\tlowerBound: 1,\n-\t\t\tupperBound: 1,\n-\t\t\twant:       \"2016-01-11\",\n-\t\t},\n-\t\t{\n-\t\t\tinput:      \"2016-01-10\",\n-\t\t\tlowerBound: -1,\n-\t\t\tupperBound: -1,\n-\t\t\twant:       \"2016-01-09\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.input, func(t *testing.T) {\n-\t\t\ttest := test\n-\t\t\tt.Parallel()\n-\t\t\tbuf := new(bytes.Buffer)\n-\t\t\terr := deidentifyDateShift(buf, tc.ProjectID, test.lowerBound, test.upperBound, test.input)\n-\t\t\tif err != nil {\n-\t\t\t\tt.Errorf(\"deidentifyDateShift(%v, %v, %q) = error '%q', want %q\", test.lowerBound, test.upperBound, err, test.input, test.want)\n-\t\t\t}\n-\t\t\tif got := buf.String(); got != test.want {\n-\t\t\t\tt.Errorf(\"deidentifyDateShift(%v, %v, %q) = %q, want %q\", test.lowerBound, test.upperBound, got, test.input, test.want)\n-\t\t\t}\n-\t\t})\n-\t}\n-}\n-\n-func TestDeidentifyTableRowSuppress(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tvar buf bytes.Buffer\n-\tif err := deidentifyTableRowSuppress(&buf, tc.ProjectID); err != nil {\n-\t\tt.Errorf(\"deidentifyTableRowSuppress: %v\", err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Table after de-identification\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableRowSuppress got %q, want %q\", got, want)\n-\t}\n-\tif want := \"values:{string_value:\\\"Charles Dickens\\\"} \"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableRowSuppress got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestDeidentifyTableInfoTypes(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyTableInfotypes(&buf, tc.ProjectID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Table after de-identification\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n-\t}\n-\n-\tif want := \"[PERSON_NAME]\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n-\t}\n-\n-\tif want := \"Charles Dickens\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Mark Twain\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Jane Austen\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n-\t}\n-\n-}\n-\n-func TestDeIdentifyWithRedact(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tinput := \"My name is Alicia Abernathy, and my email address is aabernathy@example.com.\"\n-\tinfoTypeNames := []string{\"EMAIL_ADDRESS\"}\n-\twant := \"output: My name is Alicia Abernathy, and my email address is .\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyWithRedact(&buf, tc.ProjectID, input, infoTypeNames); err != nil {\n-\t\tt.Errorf(\"deidentifyWithRedact(%q) = error '%q', want %q\", err, input, want)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyWithRedact(%q) = %q, want %q\", got, input, want)\n-\t}\n-}\n-\n-func TestDeidentifyExceptionList(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tinput := \"jack@example.org accessed customer record of user5@example.com\"\n-\twant := \"output : jack@example.org accessed customer record of [EMAIL_ADDRESS]\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyExceptionList(&buf, tc.ProjectID, input); err != nil {\n-\t\tt.Errorf(\"deidentifyExceptionList(%q) = error '%q', want %q\", input, err, want)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyExceptionList(%q) = %q, want %q\", input, got, want)\n-\t}\n-\n-}\n-\n-func TestDeIdentifyWithReplacement(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tinput := \"My name is Alicia Abernathy, and my email address is aabernathy@example.com.\"\n-\tinfoType := []string{\"EMAIL_ADDRESS\"}\n-\treplaceVal := \"[email-address]\"\n-\twant := \"output : My name is Alicia Abernathy, and my email address is [email-address].\"\n-\n-\tvar buf bytes.Buffer\n-\terr := deidentifyWithReplacement(&buf, tc.ProjectID, input, infoType, replaceVal)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyWithReplacement(%q) = %q, want %q\", input, got, want)\n-\t}\n-}\n-\n-func TestDeidentifyTableBucketing(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := deIdentifyTableBucketing(&buf, tc.ProjectID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"values:{string_value:\\\"70:80\\\"}}\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deIdentifyTableBucketing got %q, want %q\", got, want)\n-\t}\n-\tif want := \"values:{string_value:\\\"75\\\"}}\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"deIdentifyTableBucketing got %q, want %q\", got, want)\n-\t}\n-\n-}\n-\n-func TestDeidentifyTableMaskingCondition(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tif err := deidentifyTableMaskingCondition(&buf, tc.ProjectID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Table after de-identification :\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableMaskingCondition got (%q) =%q \", got, want)\n-\t}\n-\tif want := \"values:{string_value:\\\"**\\\"}\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableMaskingCondition got (%q) =%q \", got, want)\n-\t}\n-}\n-\n-func TestDeidentifyTableConditionInfoTypes(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyTableConditionInfoTypes(&buf, tc.ProjectID, []string{\"PATIENT\", \"FACTOID\"}); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Table after de-identification\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableConditionInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"values:{string_value:\\\"[PERSON_NAME] name was a curse invented by [PERSON_NAME].\\\"}}\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableConditionInfoTypes got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestDeIdentifyWithWordList(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tinput := \"Patient was seen in RM-YELLOW then transferred to rm green.\"\n-\tinfoType := \"CUSTOM_ROOM_ID\"\n-\twordList := []string{\"RM-GREEN\", \"RM-YELLOW\", \"RM-ORANGE\"}\n-\twant := \"output : Patient was seen in [CUSTOM_ROOM_ID] then transferred to [CUSTOM_ROOM_ID].\"\n-\n-\tif err := deidentifyWithWordList(&buf, tc.ProjectID, input, infoType, wordList); err != nil {\n-\t\tt.Errorf(\"deidentifyWithWordList(%q) = error '%q', want %q\", input, err, want)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyWithWordList(%q) = %q, want %q\", input, got, want)\n-\t}\n-}\n-\n-func TestDeIdentifyWithInfotype(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tinput := \"My email is test@example.com\"\n-\tinfoType := []string{\"EMAIL_ADDRESS\"}\n-\twant := \"output : My email is [EMAIL_ADDRESS]\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyWithInfotype(&buf, tc.ProjectID, input, infoType); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyFreeTextWithFPEUsingSurrogate(%q) = %q, want %q\", input, got, want)\n-\t}\n-\n-}\n-\n-func TestDeidentifyTableFPE(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tkmsKeyName, wrappedAesKey, keyVersion, err := createKey(t, tc.ProjectID, keyRingName)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tdefer destroyKey(t, tc.ProjectID, keyVersion)\n-\n-\tcontains := \"De-identify Table after format-preserving encryption\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyTableFPE(&buf, tc.ProjectID, kmsKeyName, wrappedAesKey); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tif got := buf.String(); !strings.Contains(got, contains) {\n-\t\tt.Errorf(\"deidentifyTableFPE() = %q,%q \", got, contains)\n-\t}\n-}\n-func TestDeIdentifyDeterministic(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tinput := \"Jack's phone number is 5555551212\"\n-\tinfoTypeNames := []string{\"PHONE_NUMBER\"}\n-\tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tkeyFileName, cryptoKeyName, keyVersion, err := createKey(t, tc.ProjectID, keyRingName)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tdefer destroyKey(t, tc.ProjectID, keyVersion)\n-\n-\tsurrogateInfoType := \"PHONE_TOKEN\"\n-\twant := \"output : Jack's phone number is PHONE_TOKEN(36):\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deIdentifyDeterministicEncryption(&buf, tc.ProjectID, input, infoTypeNames, keyFileName, cryptoKeyName, surrogateInfoType); err != nil {\n-\t\tt.Errorf(\"deIdentifyDeterministicEncryption(%q) = error '%q', want %q\", err, input, want)\n-\t}\n-\n-\tif got := buf.String(); !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deIdentifyDeterministicEncryption(%q) = %q, want %q\", input, got, want)\n-\t}\n-\n-}\n-\n-func TestReidentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tinputStr := \"My phone number is 1234567890\"\n-\tinfoType := \"PHONE_NUMBER\"\n-\tsurrogateType := \"PHONE_TOKEN\"\n-\tunwrappedKey := \"hu4O2y0RsY9qrVt1d2xAWEmqVqAc1P8Vk7D6peashag=\"\n-\n-\tif err := deidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputStr, infoType, surrogateType, unwrappedKey); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tinputForReid := \"My phone number is PHONE_TOKEN(10):4169075971\"\n-\n-\tbuf.Reset()\n-\tif err := reidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputForReid, surrogateType, unwrappedKey); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"output: My phone number is 1234567890\"; got != want {\n-\t\tt.Errorf(\"reidentifyFreeTextWithFPEUsingSurrogate got %q, want %q\", got, want)\n-\t}\n-\n-}\n-\n func TestDeIdentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -425,44 +83,6 @@\nfunc getUnwrappedKey(t *testing.T) (string, error) {\n \n }\n \n-func TestReidentifyWithDeterministic(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tinputStr := \"My SSN is 372819127\"\n-\tinfoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n-\tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tkeyFileName, cryptoKeyName, keyVersion, err := createKey(t, tc.ProjectID, keyRingName)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tdefer destroyKey(t, tc.ProjectID, keyVersion)\n-\n-\tsurrogateInfoType := \"SSN_TOKEN\"\n-\n-\tif err := deIdentifyDeterministicEncryption(&buf, tc.ProjectID, inputStr, infoTypeNames, keyFileName, cryptoKeyName, surrogateInfoType); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tdeidContent := buf.String()\n-\n-\tinputForReid := strings.TrimPrefix(deidContent, \"output : \")\n-\n-\tbuf.Reset()\n-\tif err := reidentifyWithDeterministic(&buf, tc.ProjectID, inputForReid, surrogateInfoType, keyFileName, cryptoKeyName); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"output: My SSN is 372819127\"; got != want {\n-\t\tt.Errorf(\"reidentifyWithDeterministic got %q, want %q\", got, want)\n-\t}\n-\n-}\n-\n func createKeyRing(t *testing.T, projectID string) (string, error) {\n \tt.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/deid/reid_fpe.go",
        "code_diff": "@@ -17,9 +17,9 @@\npackage deid\n // [START dlp_reidentify_fpe]\n import (\n \t\"context\"\n+\t\"encoding/base64\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/deid/reid_fpe.go",
        "code_diff": "@@ -30,7 +30,7 @@\nimport (\n // full KMS key resource name used to wrap the key. surrogateInfoType is an\n // the identifier used during deidentification.\n // Info types can be found with the infoTypes.list method or on https://cloud.google.com/dlp/docs/infotypes-reference\n-func reidentifyFPE(w io.Writer, projectID, input, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n+func reidentifyFPE(w io.Writer, projectID, input, kmsKeyName, wrappedAesKey, surrogateInfoType string) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 123456789\"\n \t// keyFileName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/deid/reid_fpe.go",
        "code_diff": "@@ -42,11 +42,24 @@\nfunc reidentifyFPE(w io.Writer, projectID, input, keyFileName, cryptoKeyName, su\n \t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()\n-\t// Read the key file.\n-\tkeyBytes, err := ioutil.ReadFile(keyFileName)\n+\n+\t// Specify an encrypted AES-256 key and the name of the Cloud KMS key that encrypted it.\n+\tkmsWrappedCryptoKey, err := base64.StdEncoding.DecodeString(wrappedAesKey)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"ReadFile: %w\", err)\n+\t\tfmt.Fprintf(w, \"error %v\", err)\n+\t\treturn err\n \t}\n+\n+\t// Specify the crypto key configuration that will used for encryption.\n+\tcryptoKey := &dlppb.CryptoKey{\n+\t\tSource: &dlppb.CryptoKey_KmsWrapped{\n+\t\t\tKmsWrapped: &dlppb.KmsWrappedCryptoKey{\n+\t\t\t\tWrappedKey:    kmsWrappedCryptoKey,\n+\t\t\t\tCryptoKeyName: kmsKeyName,\n+\t\t\t},\n+\t\t},\n+\t}\n+\n \t// Create a configured request.\n \treq := &dlppb.ReidentifyContentRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/global\", projectID),",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage inspect\n \n import (\n-\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -50,37 +49,6 @@\nconst (\n \tbucketnameForInspectGCSFileWithSampling = \"dlp-job-go-lang-test-inspect-gcs-file-with-sampling\"\n )\n \n-func TestInspectDatastore(t *testing.T) {\n-\ttc := testutil.EndToEndTest(t)\n-\twriteTestDatastoreFiles(t, tc.ProjectID)\n-\ttests := []struct {\n-\t\tkind string\n-\t\twant string\n-\t}{\n-\t\t{\n-\t\t\tkind: \"SSNTask\",\n-\t\t\twant: \"Created job\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.kind, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\ttestutil.Retry(t, 5, 15*time.Second, func(r *testutil.R) {\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, \"\", test.kind); err != nil {\n-\t\t\t\t\tr.Errorf(\"inspectDatastore(%s) got err: %v\", test.kind, err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\t\tr.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n-\t\t\t\t}\n-\t\t\t})\n-\t\t})\n-\t}\n-}\n-\n type SSNTask struct {\n \tDescription string\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -103,37 +71,6 @@\nfunc writeTestDatastoreFiles(t *testing.T, projectID string) {\n \t}\n }\n \n-func TestInspectGCS(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\twriteTestGCSFiles(t, tc.ProjectID)\n-\ttests := []struct {\n-\t\tfileName string\n-\t\twant     string\n-\t}{\n-\t\t{\n-\t\t\tfileName: ssnFileName,\n-\t\t\twant:     \"Created job\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.fileName, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\ttestutil.Retry(t, 5, 15*time.Second, func(r *testutil.R) {\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, bucketName, test.fileName); err != nil {\n-\t\t\t\t\tr.Errorf(\"inspectGCSFile(%s) got err: %v\", test.fileName, err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\t\tr.Errorf(\"inspectGCSFile(%s) = %q, want %q substring\", test.fileName, got, test.want)\n-\t\t\t\t}\n-\t\t\t})\n-\t\t})\n-\t}\n-}\n-\n func writeTestGCSFiles(t *testing.T, projectID string) {\n \tt.Helper()\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -176,37 +113,6 @@\nfunc writeObject(ctx context.Context, bucket *storage.BucketHandle, fileName, co\n \treturn nil\n }\n \n-func TestInspectString(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n-\n-\tif err := inspectString(buf, tc.ProjectID, \"I'm Gary and my email is gary@example.com\"); err != nil {\n-\t\tt.Errorf(\"TestInspectFile: %v\", err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectString got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectTextFile(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n-\n-\tif err := inspectTextFile(buf, tc.ProjectID, \"testdata/test.txt\"); err != nil {\n-\t\tt.Errorf(\"TestInspectTextFile: %v\", err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectTextFile got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectTextFile got %q, want %q\", got, want)\n-\t}\n-}\n-\n type Item struct {\n \tDescription string\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -261,396 +167,6 @@\nfunc uploadBigQuery(ctx context.Context, d *bigquery.Dataset, schema bigquery.Sc\n \treturn status.Err()\n }\n \n-func TestInspectBigquery(t *testing.T) {\n-\ttc := testutil.EndToEndTest(t)\n-\n-\tmustCreateBigqueryTestFiles(t, tc.ProjectID, bqDatasetID)\n-\n-\ttests := []struct {\n-\t\ttable string\n-\t\twant  string\n-\t}{\n-\t\t{\n-\t\t\ttable: harmfulTable,\n-\t\t\twant:  \"Created job\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.table, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\tu := uuid.New().String()[:8]\n-\t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectBigquery(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, bqDatasetID, test.table); err != nil {\n-\t\t\t\tt.Errorf(\"inspectBigquery(%s) got err: %v\", test.table, err)\n-\t\t\t}\n-\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\tt.Errorf(\"inspectBigquery(%s) = %q, want %q substring\", test.table, got, test.want)\n-\t\t\t}\n-\t\t})\n-\t}\n-}\n-\n-func TestInspectTable(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tif err := inspectTable(&buf, tc.ProjectID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectTable got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Likelihood: VERY_LIKELY\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectTable got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringWithExclusionRegex(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tif err := inspectStringWithExclusionRegex(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, bob@example.org\", \".+@example.com\"); err != nil {\n-\t\tt.Errorf(\"inspectStringWithExclusionRegex: %v\", err)\n-\t}\n-\n-\tgot := buf.String()\n-\n-\tif want := \"Quote: bob@example.org\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionRegex got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: gary@example.com\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionRegex got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringCustomExcludingSubstring(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringCustomExcludingSubstring(&buf, tc.ProjectID, \"Name: Doe, John. Name: Example, Jimmy\", \"[A-Z][a-z]{1,15}, [A-Z][a-z]{1,15}\", []string{\"Jimmy\"}); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\n-\tif want := \"Infotype Name: CUSTOM_NAME_DETECTOR\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomExcludingSubstring got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: Doe, John\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomExcludingSubstring got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Jimmy\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomExcludingSubstring got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringMultipleRules(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringMultipleRules(&buf, tc.ProjectID, \"patient: Jane Doe\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringMultipleRules got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectWithHotWordRules(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectWithHotWordRules(&buf, tc.ProjectID, \"Patient's MRN 444-5-22222 and just a number 333-2-33333\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"InfoType Name: C_MRN\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectWithHotWordRules got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Findings: 2\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectWithHotWordRules got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectPhoneNumber(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectPhoneNumber(&buf, tc.ProjectID, \"I'm Gary and my phone number is (415) 555-0890\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectPhoneNumber got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringWithoutOverlap(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringWithoutOverlap(&buf, tc.ProjectID, \"example.com is a domain, james@example.org is an email.\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: DOMAIN_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithoutOverlap got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: example.com\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithoutOverlap got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: example.org\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithoutOverlap got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringCustomHotWord(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringCustomHotWord(&buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomHotWord got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringWithExclusionDictSubstring(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringWithExclusionDictSubstring(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, TEST@example.com\", []string{\"TEST\"}); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Infotype Name: DOMAIN_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: TEST\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringOmitOverlap(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringOmitOverlap(&buf, tc.ProjectID, \"gary@example.com\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringOmitOverlap got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringCustomOmitOverlap(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringCustomHotWord(&buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomOmitOverlap got %q, want %q\", got, want)\n-\t}\n-\n-\tif want := \"Quote: John Doe\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomOmitOverlap got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: Larry Page\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomOmitOverlap got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectWithCustomRegex(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tvar buf bytes.Buffer\n-\tif err := inspectWithCustomRegex(&buf, tc.ProjectID, \"Patients MRN 444-5-22222\", \"[1-9]{3}-[1-9]{1}-[1-9]{5}\", \"C_MRN\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: C_MRN\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectWithCustomRegex got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Likelihood: POSSIBLE\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectWithCustomRegex got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringWithExclusionDictionary(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tif err := inspectStringWithExclusionDictionary(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, example@example.com\", []string{\"example@example.com\"}); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictionary got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectImageFile(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tpathToImage := \"testdata/test.png\"\n-\tif err := inspectImageFile(&buf, tc.ProjectID, pathToImage); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectImageFile got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectImageFile got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectImageFileAllInfoTypes(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tinputPath := \"testdata/image.jpg\"\n-\n-\tvar buf bytes.Buffer\n-\tif err := inspectImageFileAllInfoTypes(&buf, tc.ProjectID, inputPath); err != nil {\n-\t\tt.Errorf(\"inspectImageFileAllInfoTypes: %v\", err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Info type: DATE\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileAllInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileAllInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: US_SOCIAL_SECURITY_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileAllInfoTypes got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectImageFileListedInfoTypes(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tpathToImage := \"testdata/sensitive-data-image.jpg\"\n-\n-\tif err := inspectImageFileListedInfoTypes(&buf, tc.ProjectID, pathToImage); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileListedInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileListedInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: US_SOCIAL_SECURITY_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileListedInfoTypes got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectGcsFileWithSampling(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\ttopicID := \"go-lang-dlp-test-bigquery-with-sampling-topic\"\n-\tsubscriptionID := \"go-lang-dlp-test-bigquery-with-sampling-subscription\"\n-\tctx := context.Background()\n-\tsc, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tlog.Fatalf(\"storage.NewClient: %v\", err)\n-\t}\n-\tdefer sc.Close()\n-\n-\tbucketnameForInspectGCSFileWithSampling, err := testutil.CreateTestBucket(ctx, t, sc, tc.ProjectID, \"dlp-test-inspect-prefix\")\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tGCSUri := \"gs://\" + bucketnameForInspectGCSFileWithSampling + \"/\"\n-\n-\tvar buf bytes.Buffer\n-\tif err := inspectGcsFileWithSampling(&buf, tc.ProjectID, GCSUri, topicID, subscriptionID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Job Created\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectGcsFileWithSampling got %q, want %q\", got, want)\n-\t}\n-\terr = testutil.DeleteBucketIfExists(ctx, sc, bucketnameForInspectGCSFileWithSampling)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-}\n-\n-func TestInspectBigQueryTableWithSampling(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\ttopicID := \"go-lang-dlp-test-bigquery-with-sampling-topic\"\n-\tsubscriptionID := \"go-lang-dlp-test-bigquery-with-sampling-subscription\"\n-\n-\tvar buf bytes.Buffer\n-\tif err := inspectBigQueryTableWithSampling(&buf, tc.ProjectID, topicID, subscriptionID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Job Created\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectBigQueryTableWithSampling got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Found\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectBigQueryTableWithSampling got %q, want %q\", got, want)\n-\t}\n-\n-}\n-\n-func TestInspectAugmentInfoTypes(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\ttextToInspect := \"The patient's name is Quasimodo\"\n-\twordList := []string{\"quasimodo\"}\n-\n-\tif err := inspectAugmentInfoTypes(&buf, tc.ProjectID, textToInspect, wordList); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Quote: Quasimodo\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectAugmentInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectAugmentInfoTypes got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectTableWithCustomHotword(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\thotwordRegexPattern := \"(Fake Social Security Number)\"\n-\tif err := inspectTableWithCustomHotword(&buf, tc.ProjectID, hotwordRegexPattern); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\n-\tif want := \"Quote: 222-22-2222\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectTableWithCustomHotword got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Infotype Name: US_SOCIAL_SECURITY_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectTableWithCustomHotword got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: 111-11-1111\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectTableWithCustomHotword got %q, want %q\", got, want)\n-\t}\n-}\n-\n func createBigQueryDataSetId(projectID string) error {\n \n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -802,23 +318,6 @@\nfunc deleteJob(projectID, jobName string) error {\n \treturn nil\n }\n \n-func TestInspectDataStoreSendToScc(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tu := uuid.New().String()[:8]\n-\tdatastoreNamespace := fmt.Sprint(\"golang-samples\" + u)\n-\tdatastoreKind := \"task\"\n-\n-\tif err := inspectDataStoreSendToScc(&buf, tc.ProjectID, datastoreNamespace, datastoreKind); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Job created successfully:\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectBigQuerySendToScc got %q, want %q\", got, want)\n-\t}\n-}\n-\n var (\n \tprojectID                  string\n \tjobTriggerForInspectSample string",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -881,43 +380,6 @@\nfunc createStoredInfoTypeForTesting(t *testing.T, projectID, outputPath string)\n \treturn resp.Name, nil\n }\n \n-func TestInspectGCSFileSendToScc(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tctx := context.Background()\n-\tsc, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tlog.Fatalf(\"storage.NewClient: %v\", err)\n-\t}\n-\tdefer sc.Close()\n-\n-\t// Creates a bucket using a function available in testutil.\n-\tbucketNameForInspectGCSSendToScc, err := testutil.CreateTestBucket(ctx, t, sc, tc.ProjectID, \"dlp-test-inspect-prefix\")\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\t// Uploads a file on created bucket.\n-\tfilePathtoGCS(t, tc.ProjectID, bucketNameForInspectGCSSendToScc, dirPathForInspectGCSSendToScc)\n-\n-\tgcsPath := fmt.Sprint(\"gs://\" + bucketNameForInspectGCSSendToScc + \"/\" + dirPathForInspectGCSSendToScc + \"/test.txt\")\n-\n-\tif err := inspectGCSFileSendToScc(&buf, tc.ProjectID, gcsPath); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Job created successfully:\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectGCSFileSendToScc got %q, want %q\", got, want)\n-\t}\n-\n-\t// Delete a bucket that has just been created.\n-\terr = testutil.DeleteBucketIfExists(ctx, sc, bucketNameForInspectGCSSendToScc)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-}\n-\n // filePathtoGCS uploads a file test.txt in given path from the testdata directory.\n func filePathtoGCS(t *testing.T, projectID, bucketNameForInspectGCSSendToScc, dirPathForInspectGCSSendToScc string) error {\n \tt.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -943,9 +405,9 @@\nfunc filePathtoGCS(t *testing.T, projectID, bucketNameForInspectGCSSendToScc, di\n \t\t}); err != nil {\n \t\t\treturn err\n \t\t}\n-\t\tfmt.Printf(\"Bucket '%s' created successfully.\\n\", bucketNameForInspectGCSSendToScc)\n+\t\tlog.Printf(\"[INFO] [filePathtoGCS] Bucket '%s' created successfully.\\n\", bucketNameForInspectGCSSendToScc)\n \t} else {\n-\t\tfmt.Printf(\"Bucket '%s' already exists.\\n\", bucketNameForInspectGCSSendToScc)\n+\t\tlog.Printf(\"[INFO] [filePathtoGCS] Bucket '%s' already exists.\\n\", bucketNameForInspectGCSSendToScc)\n \t}\n \n \t// Check if the directory already exists in the bucket.",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -963,17 +425,17 @@\nfunc filePathtoGCS(t *testing.T, projectID, bucketNameForInspectGCSSendToScc, di\n \t\tif _, err := obj.NewWriter(ctx).Write([]byte(\"\")); err != nil {\n \t\t\tlog.Fatalf(\"Failed to create directory: %v\", err)\n \t\t}\n-\t\tfmt.Printf(\"Directory '%s' created successfully in bucket '%s'.\\n\", dirPathForInspectGCSSendToScc, bucketNameForInspectGCSSendToScc)\n+\t\tlog.Printf(\"[INFO] [filePathtoGCS] Directory '%s' created successfully in bucket '%s'.\\n\", dirPathForInspectGCSSendToScc, bucketNameForInspectGCSSendToScc)\n \t} else {\n-\t\tfmt.Printf(\"Directory '%s' already exists in bucket '%s'.\\n\", dirPathForInspectGCSSendToScc, bucketNameForInspectGCSSendToScc)\n+\t\tlog.Printf(\"[INFO] [filePathtoGCS] Directory '%s' already exists in bucket '%s'.\\n\", dirPathForInspectGCSSendToScc, bucketNameForInspectGCSSendToScc)\n \t}\n \n \t// file upload code\n \n \t// Open local file.\n \tfile, err := ioutil.ReadFile(filePathToUpload)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to read file: %v\", err)\n+\t\tlog.Fatalf(\"[INFO] [filePathtoGCS] Failed to read file: %v\", err)\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -985,29 +447,29 @@\nfunc filePathtoGCS(t *testing.T, projectID, bucketNameForInspectGCSSendToScc, di\n \twriter := object.NewWriter(ctx)\n \t_, err = writer.Write(file)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to write file: %v\", err)\n+\t\tlog.Fatalf(\"[INFO] [filePathtoGCS] Failed to write file: %v\", err)\n \t\treturn err\n \t}\n \terr = writer.Close()\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to close writer: %v\", err)\n+\t\tlog.Fatalf(\"[INFO] [filePathtoGCS] Failed to close writer: %v\", err)\n \t\treturn err\n \t}\n-\tfmt.Printf(\"File uploaded successfully: %v\\n\", inspectsGCSTestFileName)\n+\tlog.Printf(\"[INFO] [filePathtoGCS] File uploaded successfully: %v\\n\", inspectsGCSTestFileName)\n \n \t// Check if the file exists in the bucket\n \t_, err = bucket.Object(inspectsGCSTestFileName).Attrs(ctx)\n \tif err != nil {\n \t\tif err == storage.ErrObjectNotExist {\n-\t\t\tfmt.Printf(\"File %v does not exist in bucket %v\\n\", inspectsGCSTestFileName, bucketNameForInspectGCSSendToScc)\n+\t\t\tlog.Printf(\"[INFO] [filePathtoGCS] File %v does not exist in bucket %v\\n\", inspectsGCSTestFileName, bucketNameForInspectGCSSendToScc)\n \t\t} else {\n-\t\t\tlog.Fatalf(\"Failed to check file existence: %v\", err)\n+\t\t\tlog.Fatalf(\"[INFO] [filePathtoGCS] Failed to check file existence: %v\", err)\n \t\t}\n \t} else {\n-\t\tfmt.Printf(\"File %v exists in bucket %v\\n\", inspectsGCSTestFileName, bucketNameForInspectGCSSendToScc)\n+\t\tlog.Printf(\"[INFO] [filePathtoGCS] File %v exists in bucket %v\\n\", inspectsGCSTestFileName, bucketNameForInspectGCSSendToScc)\n \t}\n \n-\tfmt.Println(\"filePathtoGCS function is executed-------\")\n+\tlog.Println(\"[INFO] [filePathtoGCS] filePathtoGCS function is executed-------\")\n \treturn nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -1058,35 +520,8 @@\nfunc TestMain(m *testing.M) {\n \tdeleteJobTriggerForInspectDataToHybridJobTrigger(tc.ProjectID, jobTriggerForInspectSample)\n \tif err := testutil.DeleteExpiredBuckets(c, tc.ProjectID, testPrefix, bucketExpiryAge); err != nil {\n \t\t// Don't fail the test if cleanup fails\n-\t\tlog.Printf(\"Post-test cleanup failed: %v\", err)\n-\t}\n-}\n-\n-func TestInspectDataToHybridJobTrigger(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\ttrigger := jobTriggerForInspectSample\n-\tfmt.Print(\"Name:\" + trigger)\n-\tif err := inspectDataToHybridJobTrigger(&buf, tc.ProjectID, \"My email is test@example.org and my name is Gary.\", trigger); err != nil {\n-\t\tt.Fatal(err)\n+\t\tlog.Printf(\"[INFO] [TestMain] Post-test cleanup failed: %v\", err)\n \t}\n-\tgot := buf.String()\n-\tif want := \"successfully inspected data using hybrid job trigger\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectDataToHybridJobTrigger got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Findings\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectDataToHybridJobTrigger got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Job State: ACTIVE\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectDataToHybridJobTrigger got %q, want %q\", got, want)\n-\t}\n-\tif want := \"EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectDataToHybridJobTrigger got %q, want %q\", got, want)\n-\t}\n-\tif want := \"PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectDataToHybridJobTrigger got %q, want %q\", got, want)\n-\t}\n-\n }\n \n func deleteActiveJob(project, trigger string) error {",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -16,20 +16,17 @@\npackage jobs\n \n import (\n-\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"regexp\"\n-\t\"strings\"\n \t\"testing\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"cloud.google.com/go/storage\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/gofrs/uuid\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -144,72 +141,8 @@\nfunc riskNumerical(projectID, dataProject, pubSubTopic, pubSubSub, datasetID, ta\n \treturn nil\n }\n \n-func TestListJobs(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n-\tlistJobs(buf, tc.ProjectID, \"\", \"RISK_ANALYSIS_JOB\")\n-\ts := buf.String()\n-\tif len(s) == 0 {\n-\t\t// Create job.\n-\t\triskNumerical(tc.ProjectID, \"bigquery-public-data\", \"risk-topic\", \"risk-sub\", \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\tbuf.Reset()\n-\t\terr := listJobs(buf, tc.ProjectID, \"\", \"RISK_ANALYSIS_JOB\")\n-\t\tif err != nil {\n-\t\t\tt.Errorf(\"listJobs(%s, %s, %s) = error %q, want nil\", buf, tc.ProjectID, \"\", err)\n-\t\t}\n-\t\ts = buf.String()\n-\t}\n-\tif !strings.Contains(buf.String(), \"Job\") {\n-\t\tt.Errorf(\"%q not found in listJobs output: %q\", \"Job\", s)\n-\t}\n-}\n-\n var jobIDRegexp = regexp.MustCompile(`Job ([^ ]+) status.*`)\n \n-func TestDeleteJob(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n-\tlistJobs(buf, tc.ProjectID, \"\", \"RISK_ANALYSIS_JOB\")\n-\ts := buf.String()\n-\tif len(s) == 0 {\n-\t\t// Create job.\n-\t\triskNumerical(tc.ProjectID, \"bigquery-public-data\", \"risk-topic\", \"risk-sub\", \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\tbuf.Reset()\n-\t\tlistJobs(buf, tc.ProjectID, \"\", \"RISK_ANALYSIS_JOB\")\n-\t\ts = buf.String()\n-\t}\n-\tjobName := string(jobIDRegexp.FindSubmatch([]byte(s))[1])\n-\tbuf.Reset()\n-\tdeleteJob(buf, jobName)\n-\tif got := buf.String(); got != \"Successfully deleted job\" {\n-\t\tt.Errorf(\"unable to delete job: %s\", s)\n-\t}\n-}\n-\n-func TestCreateJob(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tvar buf bytes.Buffer\n-\t// createBucketForCreatJob will create a bucket and upload a txt file\n-\tbucketName, fileName, err := createBucketForCreatJob(t, tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgcsPath := \"gs://\" + bucketName + \"/\" + fileName\n-\tinfoTypeNames := []string{\"EMAIL_ADDRESS\", \"PERSON_NAME\", \"LOCATION\", \"PHONE_NUMBER\"}\n-\n-\tif err := createJob(&buf, tc.ProjectID, gcsPath, infoTypeNames); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Created a Dlp Job \"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectWithCustomRegex got %q, want %q\", got, want)\n-\t}\n-\n-\tdefer deleteAssetsOfCreateJobTest(t, tc.ProjectID, bucketName, fileName)\n-}\n-\n func createBucketForCreatJob(t *testing.T, projectID string) (string, string, error) {\n \tt.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -16,19 +16,15 @@\npackage metadata\n \n import (\n-\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"log\"\n \t\"os\"\n-\t\"strings\"\n \t\"testing\"\n-\t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"cloud.google.com/go/storage\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -38,80 +34,6 @@\nconst (\n \tbucket_prefix    = \"test\"\n )\n \n-func TestInfoTypes(t *testing.T) {\n-\ttestutil.SystemTest(t)\n-\ttests := []struct {\n-\t\tlanguage string\n-\t\tfilter   string\n-\t\twant     string\n-\t}{\n-\t\t{\n-\t\t\twant: \"TIME\",\n-\t\t},\n-\t\t{\n-\t\t\tlanguage: \"en-US\",\n-\t\t\twant:     \"TIME\",\n-\t\t},\n-\t\t{\n-\t\t\tlanguage: \"es\",\n-\t\t\twant:     \"DATE\",\n-\t\t},\n-\t\t{\n-\t\t\tfilter: \"supported_by=INSPECT\",\n-\t\t\twant:   \"GENDER\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.language, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\tbuf := new(bytes.Buffer)\n-\t\t\terr := infoTypes(buf, test.language, test.filter)\n-\t\t\tif err != nil {\n-\t\t\t\tt.Errorf(\"infoTypes(%s, %s) = error %q, want substring %q\", test.language, test.filter, err, test.want)\n-\t\t\t}\n-\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\tt.Errorf(\"infoTypes(%s, %s) = %s, want substring %q\", test.language, test.filter, got, test.want)\n-\t\t\t}\n-\t\t})\n-\t}\n-}\n-\n-func TestCreateStoredInfoType(t *testing.T) {\n-\n-\ttc := testutil.SystemTest(t)\n-\tctx := context.Background()\n-\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tdefer client.Close()\n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\toutputPath := fmt.Sprintf(\"gs://\" + bucketName + \"/\")\n-\tvar buf bytes.Buffer\n-\n-\tif err := createStoredInfoType(&buf, tc.ProjectID, outputPath); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"output: \"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"error from create stored infoType %q\", got)\n-\t}\n-\n-\tif want := \"github-usernames\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"error from create stored infoType %q\", got)\n-\t}\n-\n-\tname := strings.TrimPrefix(got, \"output: \")\n-\n-\tdefer deleteStoredInfoTypeAfterTest(t, name)\n-}\n-\n func deleteStoredInfoTypeAfterTest(t *testing.T, name string) error {\n \tt.Helper()\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -131,57 +53,6 @@\nfunc deleteStoredInfoTypeAfterTest(t *testing.T, name string) error {\n \treturn nil\n }\n \n-func TestUpdateStoredInfoType(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tvar buf bytes.Buffer\n-\tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tdefer client.Close()\n-\toutputBucket, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\toutputPath := fmt.Sprintf(\"gs://\" + outputBucket + \"/\")\n-\n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tfileSetUrl, gcsUri, err := filesForUpdateStoredInfoType(t, tc.ProjectID, bucketName)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tinfoTypeId, err := createStoredInfoTypeForTesting(t, tc.ProjectID, outputPath)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tinfoTypeId = strings.TrimPrefix(infoTypeId, fmt.Sprint(\"projects/\"+tc.ProjectID+\"/locations/global/storedInfoTypes/\"))\n-\n-\tduration := time.Duration(30) * time.Second\n-\ttime.Sleep(duration)\n-\n-\tif err := updateStoredInfoType(&buf, tc.ProjectID, gcsUri, fileSetUrl, infoTypeId); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\n-\tif want := \"output: \"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"error from create stored infoType %q\", got)\n-\t}\n-\n-\tname := strings.TrimPrefix(got, \"output: \")\n-\n-\tdefer deleteStoredInfoTypeAfterTest(t, name)\n-}\n-\n func filesForUpdateStoredInfoType(t *testing.T, projectID, bucketName string) (string, string, error) {\n \tt.Helper()\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -206,19 +77,19 @@\nfunc filesForUpdateStoredInfoType(t *testing.T, projectID, bucketName string) (s\n \tif !dirExists {\n \t\tobj := client.Bucket(bucketName).Object(dirPath)\n \t\tif _, err := obj.NewWriter(ctx).Write([]byte(\"\")); err != nil {\n-\t\t\tlog.Fatalf(\"Failed to create directory: %v\", err)\n+\t\t\tlog.Fatalf(\"[INFO] [filesForUpdateStoredInfoType] Failed to create directory: %v\", err)\n \t\t}\n-\t\tfmt.Printf(\"Directory '%s' created successfully in bucket '%s'.\\n\", dirPath, bucketName)\n+\t\tlog.Printf(\"[INFO] [filesForUpdateStoredInfoType] Directory '%s' created successfully in bucket '%s'.\\n\", dirPath, bucketName)\n \t} else {\n-\t\tfmt.Printf(\"Directory '%s' already exists in bucket '%s'.\\n\", dirPath, bucketName)\n+\t\tlog.Printf(\"[INFO] [filesForUpdateStoredInfoType] Directory '%s' already exists in bucket '%s'.\\n\", dirPath, bucketName)\n \t}\n \n \t// file upload code\n \n \t// Open local file.\n \tfile, err := os.ReadFile(filePathToUpload)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to read file: %v\", err)\n+\t\tlog.Fatalf(\"[INFO] [filesForUpdateStoredInfoType] Failed to read file: %v\", err)\n \t}\n \n \t// Get a reference to the bucket",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -229,24 +100,24 @@\nfunc filesForUpdateStoredInfoType(t *testing.T, projectID, bucketName string) (s\n \twriter := object.NewWriter(ctx)\n \t_, err = writer.Write(file)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to write file: %v\", err)\n+\t\tlog.Fatalf(\"[INFO] [filesForUpdateStoredInfoType] Failed to write file: %v\", err)\n \t}\n \terr = writer.Close()\n \tif err != nil {\n \t\tlog.Fatalf(\"Failed to close writer: %v\", err)\n \t}\n-\tfmt.Printf(\"File uploaded successfully: %v\\n\", termListFileName)\n+\tlog.Printf(\"[INFO] [filesForUpdateStoredInfoType] File uploaded successfully: %v\\n\", termListFileName)\n \n \t// Check if the file exists in the bucket\n \t_, err = bucket.Object(termListFileName).Attrs(ctx)\n \tif err != nil {\n \t\tif err == storage.ErrObjectNotExist {\n-\t\t\tfmt.Printf(\"File %v does not exist in bucket %v\\n\", termListFileName, bucketName)\n+\t\t\tlog.Printf(\"[INFO] [filesForUpdateStoredInfoType] File %v does not exist in bucket %v\\n\", termListFileName, bucketName)\n \t\t} else {\n-\t\t\tlog.Fatalf(\"Failed to check file existence: %v\", err)\n+\t\t\tlog.Fatalf(\"[INFO] [filesForUpdateStoredInfoType] Failed to check file existence: %v\", err)\n \t\t}\n \t} else {\n-\t\tfmt.Printf(\"File %v exists in bucket %v\\n\", termListFileName, bucketName)\n+\t\tlog.Printf(\"[INFO] [filesForUpdateStoredInfoType] File %v exists in bucket %v\\n\", termListFileName, bucketName)\n \t}\n \n \tfileSetUrl := fmt.Sprint(\"gs://\" + bucketName + \"/\" + termListFileName)",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -16,11 +16,9 @@\npackage risk\n \n import (\n-\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"log\"\n-\t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -35,103 +33,6 @@\nconst (\n \triskSubscriptionName = \"dlp-risk-test-sub-\"\n )\n \n-func TestRisk(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tclient, err := pubsub.NewClient(context.Background(), tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"pubsub.NewClient: %v\", err)\n-\t}\n-\ttests := []struct {\n-\t\tname string\n-\t\tfn   func(r *testutil.R)\n-\t}{\n-\t\t{\n-\t\t\tname: \"Numerical\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskNumerical got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tt.Errorf(\"riskNumerical got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"Categorical\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskCategorical got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskCategorical got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"K Anonymity\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskKAnonymity got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskKAnonymity got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"L Diversity\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskLDiversity got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskLDiversity got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"K Map\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskKMap got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t}\n-\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.name, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\ttestutil.Retry(t, 20, 2*time.Second, test.fn)\n-\t\t})\n-\t}\n-}\n-\n func cleanupPubsub(t *testing.T, client *pubsub.Client, topicName, subName string) {\n \tctx := context.Background()\n \ttopic := client.Topic(topicName)",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "dlp/snippets/template/template_test.go",
        "code_diff": "@@ -16,9 +16,13 @@\npackage template\n \n import (\n \t\"bytes\"\n+\t\"context\"\n+\t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n \n+\tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "functions/helloworld/hello_world.go",
        "code_diff": "@@ -12,7 +12,6 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START functions_helloworld_get_gen1]\n // [START functions_helloworld_get]\n \n // Package helloworld provides a set of Cloud Functions samples.",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -123,7 +123,7 @@\nfunc Accept2xx(r *http.Response) bool {\n \n // AcceptNonServerError returns true for any non-500 http response\n func AcceptNonServerError(r *http.Response) bool {\n-\treturn r.StatusCode > 500\n+\treturn r.StatusCode < 500\n }\n \n func WithAttempts(n int) func(*RetryOptions) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -142,8 +142,8 @@\nfunc WithAcceptFunc(f func(*http.Response) bool) func(*RetryOptions) {\n \t}\n }\n \n-// Request issues an HTTP request to the deployed service.\n-func (s *Service) Request(method string, path string, opts ...func(*RetryOptions)) (*http.Response, error) {\n+// Do executes the provided http.Request using the default http client\n+func (s *Service) Do(req *http.Request, opts ...func(*RetryOptions)) (*http.Response, error) {\n \tif !s.deployed {\n \t\treturn nil, errors.New(\"Request called before Deploy\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "media/videostitcher/get_cdn_key.go",
        "code_diff": "@@ -22,7 +22,7 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // getCDNKey gets a CDN key by ID.",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "media/videostitcher/list_cdn_keys.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // listCDNKeys gets all of the CDN keys for a given location.",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -40,11 +40,11 @@\nconst (\n \tdeleteSlateResponse = \"Deleted slate\"\n \n \tdeleteCDNKeyResponse = \"Deleted CDN key\"\n-\tmediaCDNKeyID        = \"my-go-test-media-cdn\"\n-\tcloudCDNKeyID        = \"my-go-test-cloud-cdn\"\n-\takamaiCDNKeyID       = \"my-go-test-akamai-cdn\"\n+\tmediaCDNKeyID        = \"go-test-media-cdn\"\n+\tcloudCDNKeyID        = \"go-test-cloud-cdn\"\n+\takamaiCDNKeyID       = \"go-test-akamai-cdn\"\n \thostname             = \"cdn.example.com\"\n-\tupdatedHostname      = \"updated.example.com\"\n+\tupdatedHostname      = \"updated.cdn.example.com\"\n \tkeyName              = \"my-key\"\n \n \tvodURI = \"https://storage.googleapis.com/cloud-samples-data/media/hls-vod/manifest.m3u8\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -80,6 +80,7 @@\nfunc cleanStaleResources(projectID string) {\n \t}\n \tdefer client.Close()\n \n+\t// Slates\n \treq := &stitcherstreampb.ListSlatesRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -115,6 +116,45 @@\nfunc cleanStaleResources(projectID string) {\n \t\t\t}\n \t\t}\n \t}\n+\n+\t// CDN keys\n+\treq2 := &stitcherstreampb.ListCdnKeysRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n+\t}\n+\n+\tit2 := client.ListCdnKeys(ctx, req2)\n+\n+\tfor {\n+\t\tresponse, err := it2.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tlog.Printf(\"Can't find next CDN key: %s\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\tif strings.Contains(response.GetName(), mediaCDNKeyID) ||\n+\t\t\tstrings.Contains(response.GetName(), cloudCDNKeyID) ||\n+\t\t\tstrings.Contains(response.GetName(), akamaiCDNKeyID) {\n+\n+\t\t\tarr := strings.Split(response.GetName(), \"-\")\n+\t\t\tt := arr[len(arr)-1]\n+\t\t\tif isResourceStale(t) == true {\n+\t\t\t\treq := &stitcherstreampb.DeleteCdnKeyRequest{\n+\t\t\t\t\tName: response.GetName(),\n+\t\t\t\t}\n+\t\t\t\t// Deletes the CDN key.\n+\t\t\t\top, err := client.DeleteCdnKey(ctx, req)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tlog.Printf(\"cleanStaleResources DeleteCdnKey: %s\", err)\n+\t\t\t\t}\n+\t\t\t\terr = op.Wait(ctx)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tlog.Printf(\"cleanStaleResources Wait: %s\", err)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n }\n \n func isResourceStale(timestamp string) bool {",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "media/videostitcher/update_cdn_key.go",
        "code_diff": "@@ -21,35 +21,35 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n \t\"google.golang.org/protobuf/types/known/fieldmaskpb\"\n )\n \n // updateCDNKey updates a CDN key. A CDN key is used to retrieve protected media.\n // If isMediaCDN is true, update a Media CDN key. If false, update a Cloud\n // CDN key. To create an updated privateKey value for Media CDN, see\n // https://cloud.google.com/video-stitcher/docs/how-to/managing-cdn-keys#create-private-key-media-cdn.\n-func updateCDNKey(w io.Writer, projectID, keyID, hostname, keyName, privateKey string, isMediaCDN bool) error {\n+func updateCDNKey(w io.Writer, projectID, keyID, privateKey string, isMediaCDN bool) error {\n \t// projectID := \"my-project-id\"\n \t// keyID := \"my-cdn-key\"\n-\t// hostname := \"updated.cdn.example.com\"\n-\t// keyName := \"cdn-key\"\n \t// privateKey := \"my-updated-private-key\"\n \t// isMediaCDN := true\n \tlocation := \"us-central1\"\n+\thostname := \"updated.cdn.example.com\"\n+\tkeyName := \"cdn-key\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"stitcher.NewVideoStitcherClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n-\tvar req *stitcherpb.UpdateCdnKeyRequest\n+\tvar req *stitcherstreampb.UpdateCdnKeyRequest\n \tif isMediaCDN {\n-\t\treq = &stitcherpb.UpdateCdnKeyRequest{\n-\t\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_MediaCdnKey{\n-\t\t\t\t\tMediaCdnKey: &stitcherpb.MediaCdnKey{\n+\t\treq = &stitcherstreampb.UpdateCdnKeyRequest{\n+\t\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_MediaCdnKey{\n+\t\t\t\t\tMediaCdnKey: &stitcherstreampb.MediaCdnKey{\n \t\t\t\t\t\tKeyName:    keyName,\n \t\t\t\t\t\tPrivateKey: []byte(privateKey),\n \t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "media/videostitcher/update_cdn_key.go",
        "code_diff": "@@ -64,10 +64,10 @@\nfunc updateCDNKey(w io.Writer, projectID, keyID, hostname, keyName, privateKey s\n \t\t\t},\n \t\t}\n \t} else {\n-\t\treq = &stitcherpb.UpdateCdnKeyRequest{\n-\t\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_GoogleCdnKey{\n-\t\t\t\t\tGoogleCdnKey: &stitcherpb.GoogleCdnKey{\n+\t\treq = &stitcherstreampb.UpdateCdnKeyRequest{\n+\t\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_GoogleCdnKey{\n+\t\t\t\t\tGoogleCdnKey: &stitcherstreampb.GoogleCdnKey{\n \t\t\t\t\t\tKeyName:    keyName,\n \t\t\t\t\t\tPrivateKey: []byte(privateKey),\n \t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "media/videostitcher/update_cdn_key_akamai.go",
        "code_diff": "@@ -21,29 +21,29 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n \t\"google.golang.org/protobuf/types/known/fieldmaskpb\"\n )\n \n // updateCDNKeyAkamai updates an Akamai CDN key. A CDN key is used to retrieve\n // protected media.\n-func updateCDNKeyAkamai(w io.Writer, projectID, keyID, hostname, akamaiTokenKey string) error {\n+func updateCDNKeyAkamai(w io.Writer, projectID, keyID, akamaiTokenKey string) error {\n \t// projectID := \"my-project-id\"\n \t// keyID := \"my-cdn-key\"\n-\t// hostname := \"updated.cdn.example.com\"\n \t// akamaiTokenKey := \"my-updated-token-key\"\n \tlocation := \"us-central1\"\n+\thostname := \"updated.cdn.example.com\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"stitcher.NewVideoStitcherClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n-\treq := &stitcherpb.UpdateCdnKeyRequest{\n-\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_AkamaiCdnKey{\n-\t\t\t\tAkamaiCdnKey: &stitcherpb.AkamaiCdnKey{\n+\treq := &stitcherstreampb.UpdateCdnKeyRequest{\n+\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_AkamaiCdnKey{\n+\t\t\t\tAkamaiCdnKey: &stitcherstreampb.AkamaiCdnKey{\n \t\t\t\t\tTokenKey: []byte(akamaiTokenKey),\n \t\t\t\t},\n \t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "opentelemetry/instrumentation/app/setup.go",
        "code_diff": "@@ -19,12 +19,10 @@\nimport (\n \t\"errors\"\n \t\"log/slog\"\n \t\"os\"\n-\t\"time\"\n \n \t\"go.opentelemetry.io/contrib/exporters/autoexport\"\n \t\"go.opentelemetry.io/contrib/propagators/autoprop\"\n \t\"go.opentelemetry.io/otel\"\n-\t\"go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetrichttp\"\n \t\"go.opentelemetry.io/otel/sdk/metric\"\n \t\"go.opentelemetry.io/otel/sdk/trace\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "run/testing/logging_manual.e2e_test.go",
        "code_diff": "@@ -15,10 +15,8 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -67,7 +67,7 @@\nfunc caseEditorServiceUI(t *testing.T) {\n \t\tt.Fatalf(\"service.NewRequest: %q\", err)\n \t}\n \n-\tresp, err := client.Do(req)\n+\tresp, err := editorService.Do(req)\n \tif err != nil {\n \t\tt.Fatalf(\"client.Do: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -92,7 +92,7 @@\nfunc caseEditorServiceRender(t *testing.T) {\n \t}\n \treq.Body = ioutil.NopCloser(bytes.NewReader(b))\n \n-\tresp, err := client.Do(req)\n+\tresp, err := editorService.Do(req)\n \tif err != nil {\n \t\tt.Fatalf(\"client.Do: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "run/testing/markdown_preview_renderer.e2e_test.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"net/http\"\n \t\"strings\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "run/testing/markdown_preview_renderer.e2e_test.go",
        "code_diff": "@@ -58,8 +57,7 @@\nfunc TestRendererService(t *testing.T) {\n \t\t}\n \t\treq.Body = ioutil.NopCloser(strings.NewReader(test.input))\n \n-\t\tclient := http.Client{Timeout: 10 * time.Second}\n-\t\tresp, err := client.Do(req)\n+\t\tresp, err := service.Do(req)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"client.Do: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage-ac21",
        "commit_id": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "fix(dlp): Separated a tests files of samples for `deid` package (PR-1 for deid)",
        "pr_number": 3340,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -123,7 +123,7 @@\nfunc Accept2xx(r *http.Response) bool {\n \n // AcceptNonServerError returns true for any non-500 http response\n func AcceptNonServerError(r *http.Response) bool {\n-\treturn r.StatusCode > 500\n+\treturn r.StatusCode < 500\n }\n \n func WithAttempts(n int) func(*RetryOptions) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_PR_for_issue_3289_deid_1",
        "commit_id": "cb443fce77f82ec35a2abdb5928700999f5b2930"
    },
    {
        "pr_title": "fix(dlp): Separated a tests files of samples for `deid` package (PR-1 for deid)",
        "pr_number": 3340,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -142,8 +142,8 @@\nfunc WithAcceptFunc(f func(*http.Response) bool) func(*RetryOptions) {\n \t}\n }\n \n-// Request issues an HTTP request to the deployed service.\n-func (s *Service) Request(method string, path string, opts ...func(*RetryOptions)) (*http.Response, error) {\n+// Do executes the provided http.Request using the default http client\n+func (s *Service) Do(req *http.Request, opts ...func(*RetryOptions)) (*http.Response, error) {\n \tif !s.deployed {\n \t\treturn nil, errors.New(\"Request called before Deploy\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_PR_for_issue_3289_deid_1",
        "commit_id": "cb443fce77f82ec35a2abdb5928700999f5b2930"
    },
    {
        "pr_title": "fix(dlp): Separated a tests files of samples for `deid` package (PR-1 for deid)",
        "pr_number": 3340,
        "file_name": "run/testing/logging_manual.e2e_test.go",
        "code_diff": "@@ -15,10 +15,8 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_PR_for_issue_3289_deid_1",
        "commit_id": "cb443fce77f82ec35a2abdb5928700999f5b2930"
    },
    {
        "pr_title": "fix(dlp): Separated a tests files of samples for `deid` package (PR-1 for deid)",
        "pr_number": 3340,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -17,7 +17,7 @@\npackage cloudruntests\n import (\n \t\"bytes\"\n \t\"encoding/json\"\n-\t\"io\"\n+\t\"io/ioutil\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_PR_for_issue_3289_deid_1",
        "commit_id": "cb443fce77f82ec35a2abdb5928700999f5b2930"
    },
    {
        "pr_title": "fix(dlp): Separated a tests files of samples for `deid` package (PR-1 for deid)",
        "pr_number": 3340,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -67,19 +67,17 @@\nfunc caseEditorServiceUI(t *testing.T) {\n \t\tt.Fatalf(\"service.NewRequest: %q\", err)\n \t}\n \n-\ttestutil.Retry(t, 10, 20*time.Second, func(r *testutil.R) {\n-\t\tresp, err := client.Do(req)\n-\t\tif err != nil {\n-\t\t\tr.Errorf(\"client.Do: %v\", err)\n-\t\t}\n-\t\tdefer resp.Body.Close()\n-\t\tr.Logf(\"client.Do: %s %s\\n\", req.Method, req.URL)\n-\n-\t\twantStatus := http.StatusOK\n-\t\tif got := resp.StatusCode; got != wantStatus {\n-\t\t\tr.Errorf(\"response status: got %d, want %d\", got, wantStatus)\n-\t\t}\n-\t})\n+\tresp, err := editorService.Do(req)\n+\tif err != nil {\n+\t\tt.Fatalf(\"client.Do: %v\", err)\n+\t}\n+\tdefer resp.Body.Close()\n+\tt.Logf(\"client.Do: %s %s\\n\", req.Method, req.URL)\n+\n+\twantStatus := http.StatusOK\n+\tif got := resp.StatusCode; got != wantStatus {\n+\t\tt.Errorf(\"response status: got %d, want %d\", got, wantStatus)\n+\t}\n }\n \n func caseEditorServiceRender(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_PR_for_issue_3289_deid_1",
        "commit_id": "cb443fce77f82ec35a2abdb5928700999f5b2930"
    },
    {
        "pr_title": "fix(dlp): Separated a tests files of samples for `deid` package (PR-1 for deid)",
        "pr_number": 3340,
        "file_name": "run/testing/markdown_preview_renderer.e2e_test.go",
        "code_diff": "@@ -15,11 +15,10 @@\npackage cloudruntests\n \n import (\n-\t\"io\"\n+\t\"io/ioutil\"\n \t\"net/http\"\n \t\"strings\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_PR_for_issue_3289_deid_1",
        "commit_id": "cb443fce77f82ec35a2abdb5928700999f5b2930"
    },
    {
        "pr_title": "fix(dlp): Separated a tests files of samples for `trigger` package",
        "pr_number": 3334,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -16,11 +16,9 @@\npackage risk\n \n import (\n-\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"log\"\n-\t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_PR_for_issue_3289_trigger",
        "commit_id": "cb750099534c738009005c107352412b877f5380"
    },
    {
        "pr_title": "fix(dlp): Separated a tests files of samples for `trigger` package",
        "pr_number": 3334,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -35,103 +33,6 @@\nconst (\n \triskSubscriptionName = \"dlp-risk-test-sub-\"\n )\n \n-func TestRisk(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tclient, err := pubsub.NewClient(context.Background(), tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"pubsub.NewClient: %v\", err)\n-\t}\n-\ttests := []struct {\n-\t\tname string\n-\t\tfn   func(r *testutil.R)\n-\t}{\n-\t\t{\n-\t\t\tname: \"Numerical\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskNumerical got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tt.Errorf(\"riskNumerical got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"Categorical\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskCategorical got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskCategorical got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"K Anonymity\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskKAnonymity got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskKAnonymity got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"L Diversity\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskLDiversity got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskLDiversity got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"K Map\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskKMap got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t}\n-\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.name, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\ttestutil.Retry(t, 20, 2*time.Second, test.fn)\n-\t\t})\n-\t}\n-}\n-\n func cleanupPubsub(t *testing.T, client *pubsub.Client, topicName, subName string) {\n \tctx := context.Background()\n \ttopic := client.Topic(topicName)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_PR_for_issue_3289_trigger",
        "commit_id": "cb750099534c738009005c107352412b877f5380"
    },
    {
        "pr_title": "fix(dlp): Separated a tests files of samples for `trigger` package",
        "pr_number": 3334,
        "file_name": "dlp/snippets/template/template_test.go",
        "code_diff": "@@ -16,9 +16,13 @@\npackage template\n \n import (\n \t\"bytes\"\n+\t\"context\"\n+\t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n \n+\tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_PR_for_issue_3289_trigger",
        "commit_id": "cb750099534c738009005c107352412b877f5380"
    },
    {
        "pr_title": "feat(trace): add opentelemetry instrumentation example",
        "pr_number": 3312,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -15,25 +15,28 @@\npackage videostitcher\n \n import (\n-\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n-\t\"net/http\"\n-\t\"regexp\"\n+\t\"log\"\n+\n \t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n-\tcloudresourcemanager \"google.golang.org/api/cloudresourcemanager/v1\"\n+\t\"google.golang.org/api/iterator\"\n+\n+\tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n const (\n \tlocation            = \"us-central1\" // All samples use this location\n-\tslateID             = \"my-go-test-slate\"\n+\tslateID             = \"go-test-slate\"\n+\tslateURI            = \"https://storage.googleapis.com/cloud-samples-data/media/ForBiggerEscapes.mp4\"\n+\tupdatedSlateURI     = \"https://storage.googleapis.com/cloud-samples-data/media/ForBiggerJoyrides.mp4\"\n \tdeleteSlateResponse = \"Deleted slate\"\n \n \tdeleteCDNKeyResponse = \"Deleted CDN key\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into otel-go-example",
        "commit_id": "6e075452998a36a9e462cb7c137dd8c81c150230"
    },
    {
        "pr_title": "feat(cloudrunci): Service.Do() method, to support automatic retries in more tests",
        "pr_number": 3307,
        "file_name": "run/testing/markdown_preview_renderer.e2e_test.go",
        "code_diff": "@@ -15,7 +15,7 @@\npackage cloudruntests\n \n import (\n-\t\"io\"\n+\t\"io/ioutil\"\n \t\"net/http\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "fix(merge): fix inconsistent merge.",
        "commit_id": "e08a3350cba9be2e81b6f21396cf8618cb2775e9"
    },
    {
        "pr_title": "feat: convert slates to LROs and add separate tests for each slate sa\u2026",
        "pr_number": 3305,
        "file_name": "pubsub/subscriptions/create_cloud_storage_subscription.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage subscriptions\n \n-// [START pubsub_cloudstorage_subscription]\n+// [START pubsub_create_cloud_storage_subscription]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "b25354f9a6ab846e0acb056535206bbeb4a34be1"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "aiplatform/snippets/import_data_image_classification_test.go",
        "code_diff": "@@ -37,7 +37,7 @@\nvar (\n \tgcsURI      string\n )\n \n-func setup(t *testing.T) func() {\n+func setupImportDatasetImageClassification(t *testing.T) func() {\n \tt.Helper()\n \tif testing.Short() {\n \t\tt.Skip(\"skipping integration test\")",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -48,348 +48,6 @@\nconst (\n \tredactImageTemplate            = \"redact-image-template-go\"\n )\n \n-func TestMask(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\ttests := []struct {\n-\t\tinput            string\n-\t\tmaskingCharacter string\n-\t\tnumberToMask     int32\n-\t\twant             string\n-\t}{\n-\t\t{\n-\t\t\tinput:            \"My SSN is 111222333\",\n-\t\t\tmaskingCharacter: \"+\",\n-\t\t\twant:             \"My SSN is +++++++++\",\n-\t\t},\n-\t\t{\n-\t\t\tinput: \"My SSN is 111222333\",\n-\t\t\twant:  \"My SSN is *********\",\n-\t\t},\n-\t\t{\n-\t\t\tinput:            \"My SSN is 111222333\",\n-\t\t\tmaskingCharacter: \"+\",\n-\t\t\tnumberToMask:     6,\n-\t\t\twant:             \"My SSN is ++++++333\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.input, func(t *testing.T) {\n-\t\t\ttest := test\n-\t\t\tt.Parallel()\n-\t\t\tbuf := new(bytes.Buffer)\n-\t\t\terr := mask(buf, tc.ProjectID, test.input, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, test.maskingCharacter, test.numberToMask)\n-\t\t\tif err != nil {\n-\t\t\t\tt.Errorf(\"mask(%q, %s, %v) = error %q, want %q\", test.input, test.maskingCharacter, test.numberToMask, err, test.want)\n-\t\t\t}\n-\t\t\tif got := buf.String(); got != test.want {\n-\t\t\t\tt.Errorf(\"mask(%q, %s, %v) = %q, want %q\", test.input, test.maskingCharacter, test.numberToMask, got, test.want)\n-\t\t\t}\n-\t\t})\n-\t}\n-}\n-\n-func TestDeidentifyDateShift(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\ttests := []struct {\n-\t\tinput      string\n-\t\twant       string\n-\t\tlowerBound int32\n-\t\tupperBound int32\n-\t}{\n-\t\t{\n-\t\t\tinput:      \"2016-01-10\",\n-\t\t\tlowerBound: 1,\n-\t\t\tupperBound: 1,\n-\t\t\twant:       \"2016-01-11\",\n-\t\t},\n-\t\t{\n-\t\t\tinput:      \"2016-01-10\",\n-\t\t\tlowerBound: -1,\n-\t\t\tupperBound: -1,\n-\t\t\twant:       \"2016-01-09\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.input, func(t *testing.T) {\n-\t\t\ttest := test\n-\t\t\tt.Parallel()\n-\t\t\tbuf := new(bytes.Buffer)\n-\t\t\terr := deidentifyDateShift(buf, tc.ProjectID, test.lowerBound, test.upperBound, test.input)\n-\t\t\tif err != nil {\n-\t\t\t\tt.Errorf(\"deidentifyDateShift(%v, %v, %q) = error '%q', want %q\", test.lowerBound, test.upperBound, err, test.input, test.want)\n-\t\t\t}\n-\t\t\tif got := buf.String(); got != test.want {\n-\t\t\t\tt.Errorf(\"deidentifyDateShift(%v, %v, %q) = %q, want %q\", test.lowerBound, test.upperBound, got, test.input, test.want)\n-\t\t\t}\n-\t\t})\n-\t}\n-}\n-\n-func TestDeidentifyTableRowSuppress(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tvar buf bytes.Buffer\n-\tif err := deidentifyTableRowSuppress(&buf, tc.ProjectID); err != nil {\n-\t\tt.Errorf(\"deidentifyTableRowSuppress: %v\", err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Table after de-identification\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableRowSuppress got %q, want %q\", got, want)\n-\t}\n-\tif want := \"values:{string_value:\\\"Charles Dickens\\\"} \"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableRowSuppress got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestDeidentifyTableInfoTypes(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyTableInfotypes(&buf, tc.ProjectID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Table after de-identification\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n-\t}\n-\n-\tif want := \"[PERSON_NAME]\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n-\t}\n-\n-\tif want := \"Charles Dickens\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Mark Twain\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Jane Austen\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n-\t}\n-\n-}\n-\n-func TestDeIdentifyWithRedact(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tinput := \"My name is Alicia Abernathy, and my email address is aabernathy@example.com.\"\n-\tinfoTypeNames := []string{\"EMAIL_ADDRESS\"}\n-\twant := \"output: My name is Alicia Abernathy, and my email address is .\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyWithRedact(&buf, tc.ProjectID, input, infoTypeNames); err != nil {\n-\t\tt.Errorf(\"deidentifyWithRedact(%q) = error '%q', want %q\", err, input, want)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyWithRedact(%q) = %q, want %q\", got, input, want)\n-\t}\n-}\n-\n-func TestDeidentifyExceptionList(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tinput := \"jack@example.org accessed customer record of user5@example.com\"\n-\twant := \"output : jack@example.org accessed customer record of [EMAIL_ADDRESS]\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyExceptionList(&buf, tc.ProjectID, input); err != nil {\n-\t\tt.Errorf(\"deidentifyExceptionList(%q) = error '%q', want %q\", input, err, want)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyExceptionList(%q) = %q, want %q\", input, got, want)\n-\t}\n-\n-}\n-\n-func TestDeIdentifyWithReplacement(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tinput := \"My name is Alicia Abernathy, and my email address is aabernathy@example.com.\"\n-\tinfoType := []string{\"EMAIL_ADDRESS\"}\n-\treplaceVal := \"[email-address]\"\n-\twant := \"output : My name is Alicia Abernathy, and my email address is [email-address].\"\n-\n-\tvar buf bytes.Buffer\n-\terr := deidentifyWithReplacement(&buf, tc.ProjectID, input, infoType, replaceVal)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyWithReplacement(%q) = %q, want %q\", input, got, want)\n-\t}\n-}\n-\n-func TestDeidentifyTableBucketing(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := deIdentifyTableBucketing(&buf, tc.ProjectID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"values:{string_value:\\\"70:80\\\"}}\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deIdentifyTableBucketing got %q, want %q\", got, want)\n-\t}\n-\tif want := \"values:{string_value:\\\"75\\\"}}\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"deIdentifyTableBucketing got %q, want %q\", got, want)\n-\t}\n-\n-}\n-\n-func TestDeidentifyTableMaskingCondition(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tif err := deidentifyTableMaskingCondition(&buf, tc.ProjectID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Table after de-identification :\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableMaskingCondition got (%q) =%q \", got, want)\n-\t}\n-\tif want := \"values:{string_value:\\\"**\\\"}\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableMaskingCondition got (%q) =%q \", got, want)\n-\t}\n-}\n-\n-func TestDeidentifyTableConditionInfoTypes(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyTableConditionInfoTypes(&buf, tc.ProjectID, []string{\"PATIENT\", \"FACTOID\"}); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Table after de-identification\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableConditionInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"values:{string_value:\\\"[PERSON_NAME] name was a curse invented by [PERSON_NAME].\\\"}}\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deidentifyTableConditionInfoTypes got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestDeIdentifyWithWordList(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tinput := \"Patient was seen in RM-YELLOW then transferred to rm green.\"\n-\tinfoType := \"CUSTOM_ROOM_ID\"\n-\twordList := []string{\"RM-GREEN\", \"RM-YELLOW\", \"RM-ORANGE\"}\n-\twant := \"output : Patient was seen in [CUSTOM_ROOM_ID] then transferred to [CUSTOM_ROOM_ID].\"\n-\n-\tif err := deidentifyWithWordList(&buf, tc.ProjectID, input, infoType, wordList); err != nil {\n-\t\tt.Errorf(\"deidentifyWithWordList(%q) = error '%q', want %q\", input, err, want)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyWithWordList(%q) = %q, want %q\", input, got, want)\n-\t}\n-}\n-\n-func TestDeIdentifyWithInfotype(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tinput := \"My email is test@example.com\"\n-\tinfoType := []string{\"EMAIL_ADDRESS\"}\n-\twant := \"output : My email is [EMAIL_ADDRESS]\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyWithInfotype(&buf, tc.ProjectID, input, infoType); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyFreeTextWithFPEUsingSurrogate(%q) = %q, want %q\", input, got, want)\n-\t}\n-\n-}\n-\n-func TestDeidentifyTableFPE(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tkmsKeyName, wrappedAesKey, keyVersion, err := createKey(t, tc.ProjectID, keyRingName)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tdefer destroyKey(t, tc.ProjectID, keyVersion)\n-\n-\tcontains := \"De-identify Table after format-preserving encryption\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyTableFPE(&buf, tc.ProjectID, kmsKeyName, wrappedAesKey); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tif got := buf.String(); !strings.Contains(got, contains) {\n-\t\tt.Errorf(\"deidentifyTableFPE() = %q,%q \", got, contains)\n-\t}\n-}\n-func TestDeIdentifyDeterministic(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tinput := \"Jack's phone number is 5555551212\"\n-\tinfoTypeNames := []string{\"PHONE_NUMBER\"}\n-\tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tkeyFileName, cryptoKeyName, keyVersion, err := createKey(t, tc.ProjectID, keyRingName)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tdefer destroyKey(t, tc.ProjectID, keyVersion)\n-\n-\tsurrogateInfoType := \"PHONE_TOKEN\"\n-\twant := \"output : Jack's phone number is PHONE_TOKEN(36):\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deIdentifyDeterministicEncryption(&buf, tc.ProjectID, input, infoTypeNames, keyFileName, cryptoKeyName, surrogateInfoType); err != nil {\n-\t\tt.Errorf(\"deIdentifyDeterministicEncryption(%q) = error '%q', want %q\", err, input, want)\n-\t}\n-\n-\tif got := buf.String(); !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deIdentifyDeterministicEncryption(%q) = %q, want %q\", input, got, want)\n-\t}\n-\n-}\n-\n-func TestReidentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tinputStr := \"My phone number is 1234567890\"\n-\tinfoType := \"PHONE_NUMBER\"\n-\tsurrogateType := \"PHONE_TOKEN\"\n-\tunwrappedKey := \"hu4O2y0RsY9qrVt1d2xAWEmqVqAc1P8Vk7D6peashag=\"\n-\n-\tif err := deidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputStr, infoType, surrogateType, unwrappedKey); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tinputForReid := \"My phone number is PHONE_TOKEN(10):4169075971\"\n-\n-\tbuf.Reset()\n-\tif err := reidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputForReid, surrogateType, unwrappedKey); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"output: My phone number is 1234567890\"; got != want {\n-\t\tt.Errorf(\"reidentifyFreeTextWithFPEUsingSurrogate got %q, want %q\", got, want)\n-\t}\n-\n-}\n-\n func TestDeIdentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -425,44 +83,6 @@\nfunc getUnwrappedKey(t *testing.T) (string, error) {\n \n }\n \n-func TestReidentifyWithDeterministic(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tinputStr := \"My SSN is 372819127\"\n-\tinfoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n-\tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tkeyFileName, cryptoKeyName, keyVersion, err := createKey(t, tc.ProjectID, keyRingName)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tdefer destroyKey(t, tc.ProjectID, keyVersion)\n-\n-\tsurrogateInfoType := \"SSN_TOKEN\"\n-\n-\tif err := deIdentifyDeterministicEncryption(&buf, tc.ProjectID, inputStr, infoTypeNames, keyFileName, cryptoKeyName, surrogateInfoType); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tdeidContent := buf.String()\n-\n-\tinputForReid := strings.TrimPrefix(deidContent, \"output : \")\n-\n-\tbuf.Reset()\n-\tif err := reidentifyWithDeterministic(&buf, tc.ProjectID, inputForReid, surrogateInfoType, keyFileName, cryptoKeyName); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"output: My SSN is 372819127\"; got != want {\n-\t\tt.Errorf(\"reidentifyWithDeterministic got %q, want %q\", got, want)\n-\t}\n-\n-}\n-\n func createKeyRing(t *testing.T, projectID string) (string, error) {\n \tt.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/deid/reid_fpe.go",
        "code_diff": "@@ -17,9 +17,9 @@\npackage deid\n // [START dlp_reidentify_fpe]\n import (\n \t\"context\"\n+\t\"encoding/base64\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/deid/reid_fpe.go",
        "code_diff": "@@ -30,7 +30,7 @@\nimport (\n // full KMS key resource name used to wrap the key. surrogateInfoType is an\n // the identifier used during deidentification.\n // Info types can be found with the infoTypes.list method or on https://cloud.google.com/dlp/docs/infotypes-reference\n-func reidentifyFPE(w io.Writer, projectID, input, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n+func reidentifyFPE(w io.Writer, projectID, input, kmsKeyName, wrappedAesKey, surrogateInfoType string) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 123456789\"\n \t// keyFileName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/deid/reid_fpe.go",
        "code_diff": "@@ -42,11 +42,24 @@\nfunc reidentifyFPE(w io.Writer, projectID, input, keyFileName, cryptoKeyName, su\n \t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()\n-\t// Read the key file.\n-\tkeyBytes, err := ioutil.ReadFile(keyFileName)\n+\n+\t// Specify an encrypted AES-256 key and the name of the Cloud KMS key that encrypted it.\n+\tkmsWrappedCryptoKey, err := base64.StdEncoding.DecodeString(wrappedAesKey)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"ReadFile: %w\", err)\n+\t\tfmt.Fprintf(w, \"error %v\", err)\n+\t\treturn err\n \t}\n+\n+\t// Specify the crypto key configuration that will used for encryption.\n+\tcryptoKey := &dlppb.CryptoKey{\n+\t\tSource: &dlppb.CryptoKey_KmsWrapped{\n+\t\t\tKmsWrapped: &dlppb.KmsWrappedCryptoKey{\n+\t\t\t\tWrappedKey:    kmsWrappedCryptoKey,\n+\t\t\t\tCryptoKeyName: kmsKeyName,\n+\t\t\t},\n+\t\t},\n+\t}\n+\n \t// Create a configured request.\n \treq := &dlppb.ReidentifyContentRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/global\", projectID),",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage inspect\n \n import (\n-\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -50,37 +49,6 @@\nconst (\n \tbucketnameForInspectGCSFileWithSampling = \"dlp-job-go-lang-test-inspect-gcs-file-with-sampling\"\n )\n \n-func TestInspectDatastore(t *testing.T) {\n-\ttc := testutil.EndToEndTest(t)\n-\twriteTestDatastoreFiles(t, tc.ProjectID)\n-\ttests := []struct {\n-\t\tkind string\n-\t\twant string\n-\t}{\n-\t\t{\n-\t\t\tkind: \"SSNTask\",\n-\t\t\twant: \"Created job\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.kind, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\ttestutil.Retry(t, 5, 15*time.Second, func(r *testutil.R) {\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, \"\", test.kind); err != nil {\n-\t\t\t\t\tr.Errorf(\"inspectDatastore(%s) got err: %v\", test.kind, err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\t\tr.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n-\t\t\t\t}\n-\t\t\t})\n-\t\t})\n-\t}\n-}\n-\n type SSNTask struct {\n \tDescription string\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -103,37 +71,6 @@\nfunc writeTestDatastoreFiles(t *testing.T, projectID string) {\n \t}\n }\n \n-func TestInspectGCS(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\twriteTestGCSFiles(t, tc.ProjectID)\n-\ttests := []struct {\n-\t\tfileName string\n-\t\twant     string\n-\t}{\n-\t\t{\n-\t\t\tfileName: ssnFileName,\n-\t\t\twant:     \"Created job\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.fileName, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\ttestutil.Retry(t, 5, 15*time.Second, func(r *testutil.R) {\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, bucketName, test.fileName); err != nil {\n-\t\t\t\t\tr.Errorf(\"inspectGCSFile(%s) got err: %v\", test.fileName, err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\t\tr.Errorf(\"inspectGCSFile(%s) = %q, want %q substring\", test.fileName, got, test.want)\n-\t\t\t\t}\n-\t\t\t})\n-\t\t})\n-\t}\n-}\n-\n func writeTestGCSFiles(t *testing.T, projectID string) {\n \tt.Helper()\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -176,37 +113,6 @@\nfunc writeObject(ctx context.Context, bucket *storage.BucketHandle, fileName, co\n \treturn nil\n }\n \n-func TestInspectString(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n-\n-\tif err := inspectString(buf, tc.ProjectID, \"I'm Gary and my email is gary@example.com\"); err != nil {\n-\t\tt.Errorf(\"TestInspectFile: %v\", err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectString got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectTextFile(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n-\n-\tif err := inspectTextFile(buf, tc.ProjectID, \"testdata/test.txt\"); err != nil {\n-\t\tt.Errorf(\"TestInspectTextFile: %v\", err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectTextFile got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectTextFile got %q, want %q\", got, want)\n-\t}\n-}\n-\n type Item struct {\n \tDescription string\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -261,396 +167,6 @@\nfunc uploadBigQuery(ctx context.Context, d *bigquery.Dataset, schema bigquery.Sc\n \treturn status.Err()\n }\n \n-func TestInspectBigquery(t *testing.T) {\n-\ttc := testutil.EndToEndTest(t)\n-\n-\tmustCreateBigqueryTestFiles(t, tc.ProjectID, bqDatasetID)\n-\n-\ttests := []struct {\n-\t\ttable string\n-\t\twant  string\n-\t}{\n-\t\t{\n-\t\t\ttable: harmfulTable,\n-\t\t\twant:  \"Created job\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.table, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\tu := uuid.New().String()[:8]\n-\t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectBigquery(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, bqDatasetID, test.table); err != nil {\n-\t\t\t\tt.Errorf(\"inspectBigquery(%s) got err: %v\", test.table, err)\n-\t\t\t}\n-\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\tt.Errorf(\"inspectBigquery(%s) = %q, want %q substring\", test.table, got, test.want)\n-\t\t\t}\n-\t\t})\n-\t}\n-}\n-\n-func TestInspectTable(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tif err := inspectTable(&buf, tc.ProjectID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectTable got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Likelihood: VERY_LIKELY\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectTable got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringWithExclusionRegex(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tif err := inspectStringWithExclusionRegex(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, bob@example.org\", \".+@example.com\"); err != nil {\n-\t\tt.Errorf(\"inspectStringWithExclusionRegex: %v\", err)\n-\t}\n-\n-\tgot := buf.String()\n-\n-\tif want := \"Quote: bob@example.org\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionRegex got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: gary@example.com\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionRegex got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringCustomExcludingSubstring(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringCustomExcludingSubstring(&buf, tc.ProjectID, \"Name: Doe, John. Name: Example, Jimmy\", \"[A-Z][a-z]{1,15}, [A-Z][a-z]{1,15}\", []string{\"Jimmy\"}); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\n-\tif want := \"Infotype Name: CUSTOM_NAME_DETECTOR\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomExcludingSubstring got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: Doe, John\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomExcludingSubstring got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Jimmy\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomExcludingSubstring got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringMultipleRules(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringMultipleRules(&buf, tc.ProjectID, \"patient: Jane Doe\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringMultipleRules got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectWithHotWordRules(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectWithHotWordRules(&buf, tc.ProjectID, \"Patient's MRN 444-5-22222 and just a number 333-2-33333\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"InfoType Name: C_MRN\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectWithHotWordRules got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Findings: 2\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectWithHotWordRules got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectPhoneNumber(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectPhoneNumber(&buf, tc.ProjectID, \"I'm Gary and my phone number is (415) 555-0890\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectPhoneNumber got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringWithoutOverlap(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringWithoutOverlap(&buf, tc.ProjectID, \"example.com is a domain, james@example.org is an email.\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: DOMAIN_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithoutOverlap got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: example.com\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithoutOverlap got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: example.org\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithoutOverlap got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringCustomHotWord(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringCustomHotWord(&buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomHotWord got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringWithExclusionDictSubstring(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringWithExclusionDictSubstring(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, TEST@example.com\", []string{\"TEST\"}); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Infotype Name: DOMAIN_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: TEST\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringOmitOverlap(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringOmitOverlap(&buf, tc.ProjectID, \"gary@example.com\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringOmitOverlap got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringCustomOmitOverlap(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringCustomHotWord(&buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomOmitOverlap got %q, want %q\", got, want)\n-\t}\n-\n-\tif want := \"Quote: John Doe\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomOmitOverlap got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: Larry Page\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomOmitOverlap got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectWithCustomRegex(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tvar buf bytes.Buffer\n-\tif err := inspectWithCustomRegex(&buf, tc.ProjectID, \"Patients MRN 444-5-22222\", \"[1-9]{3}-[1-9]{1}-[1-9]{5}\", \"C_MRN\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: C_MRN\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectWithCustomRegex got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Likelihood: POSSIBLE\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectWithCustomRegex got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringWithExclusionDictionary(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tif err := inspectStringWithExclusionDictionary(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, example@example.com\", []string{\"example@example.com\"}); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictionary got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectImageFile(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tpathToImage := \"testdata/test.png\"\n-\tif err := inspectImageFile(&buf, tc.ProjectID, pathToImage); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectImageFile got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectImageFile got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectImageFileAllInfoTypes(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tinputPath := \"testdata/image.jpg\"\n-\n-\tvar buf bytes.Buffer\n-\tif err := inspectImageFileAllInfoTypes(&buf, tc.ProjectID, inputPath); err != nil {\n-\t\tt.Errorf(\"inspectImageFileAllInfoTypes: %v\", err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Info type: DATE\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileAllInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileAllInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: US_SOCIAL_SECURITY_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileAllInfoTypes got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectImageFileListedInfoTypes(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tpathToImage := \"testdata/sensitive-data-image.jpg\"\n-\n-\tif err := inspectImageFileListedInfoTypes(&buf, tc.ProjectID, pathToImage); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileListedInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileListedInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: US_SOCIAL_SECURITY_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectImageFileListedInfoTypes got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectGcsFileWithSampling(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\ttopicID := \"go-lang-dlp-test-bigquery-with-sampling-topic\"\n-\tsubscriptionID := \"go-lang-dlp-test-bigquery-with-sampling-subscription\"\n-\tctx := context.Background()\n-\tsc, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tlog.Fatalf(\"storage.NewClient: %v\", err)\n-\t}\n-\tdefer sc.Close()\n-\n-\tbucketnameForInspectGCSFileWithSampling, err := testutil.CreateTestBucket(ctx, t, sc, tc.ProjectID, \"dlp-test-inspect-prefix\")\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tGCSUri := \"gs://\" + bucketnameForInspectGCSFileWithSampling + \"/\"\n-\n-\tvar buf bytes.Buffer\n-\tif err := inspectGcsFileWithSampling(&buf, tc.ProjectID, GCSUri, topicID, subscriptionID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Job Created\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectGcsFileWithSampling got %q, want %q\", got, want)\n-\t}\n-\terr = testutil.DeleteBucketIfExists(ctx, sc, bucketnameForInspectGCSFileWithSampling)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-}\n-\n-func TestInspectBigQueryTableWithSampling(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\ttopicID := \"go-lang-dlp-test-bigquery-with-sampling-topic\"\n-\tsubscriptionID := \"go-lang-dlp-test-bigquery-with-sampling-subscription\"\n-\n-\tvar buf bytes.Buffer\n-\tif err := inspectBigQueryTableWithSampling(&buf, tc.ProjectID, topicID, subscriptionID); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Job Created\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectBigQueryTableWithSampling got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Found\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectBigQueryTableWithSampling got %q, want %q\", got, want)\n-\t}\n-\n-}\n-\n-func TestInspectAugmentInfoTypes(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\ttextToInspect := \"The patient's name is Quasimodo\"\n-\twordList := []string{\"quasimodo\"}\n-\n-\tif err := inspectAugmentInfoTypes(&buf, tc.ProjectID, textToInspect, wordList); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Quote: Quasimodo\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectAugmentInfoTypes got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectAugmentInfoTypes got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectTableWithCustomHotword(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\thotwordRegexPattern := \"(Fake Social Security Number)\"\n-\tif err := inspectTableWithCustomHotword(&buf, tc.ProjectID, hotwordRegexPattern); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := buf.String()\n-\n-\tif want := \"Quote: 222-22-2222\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectTableWithCustomHotword got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Infotype Name: US_SOCIAL_SECURITY_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectTableWithCustomHotword got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: 111-11-1111\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectTableWithCustomHotword got %q, want %q\", got, want)\n-\t}\n-}\n-\n func createBigQueryDataSetId(projectID string) error {\n \n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -802,23 +318,6 @@\nfunc deleteJob(projectID, jobName string) error {\n \treturn nil\n }\n \n-func TestInspectDataStoreSendToScc(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tu := uuid.New().String()[:8]\n-\tdatastoreNamespace := fmt.Sprint(\"golang-samples\" + u)\n-\tdatastoreKind := \"task\"\n-\n-\tif err := inspectDataStoreSendToScc(&buf, tc.ProjectID, datastoreNamespace, datastoreKind); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Job created successfully:\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectBigQuerySendToScc got %q, want %q\", got, want)\n-\t}\n-}\n-\n var (\n \tprojectID                  string\n \tjobTriggerForInspectSample string",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -881,43 +380,6 @@\nfunc createStoredInfoTypeForTesting(t *testing.T, projectID, outputPath string)\n \treturn resp.Name, nil\n }\n \n-func TestInspectGCSFileSendToScc(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tctx := context.Background()\n-\tsc, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tlog.Fatalf(\"storage.NewClient: %v\", err)\n-\t}\n-\tdefer sc.Close()\n-\n-\t// Creates a bucket using a function available in testutil.\n-\tbucketNameForInspectGCSSendToScc, err := testutil.CreateTestBucket(ctx, t, sc, tc.ProjectID, \"dlp-test-inspect-prefix\")\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\t// Uploads a file on created bucket.\n-\tfilePathtoGCS(t, tc.ProjectID, bucketNameForInspectGCSSendToScc, dirPathForInspectGCSSendToScc)\n-\n-\tgcsPath := fmt.Sprint(\"gs://\" + bucketNameForInspectGCSSendToScc + \"/\" + dirPathForInspectGCSSendToScc + \"/test.txt\")\n-\n-\tif err := inspectGCSFileSendToScc(&buf, tc.ProjectID, gcsPath); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Job created successfully:\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectGCSFileSendToScc got %q, want %q\", got, want)\n-\t}\n-\n-\t// Delete a bucket that has just been created.\n-\terr = testutil.DeleteBucketIfExists(ctx, sc, bucketNameForInspectGCSSendToScc)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-}\n-\n // filePathtoGCS uploads a file test.txt in given path from the testdata directory.\n func filePathtoGCS(t *testing.T, projectID, bucketNameForInspectGCSSendToScc, dirPathForInspectGCSSendToScc string) error {\n \tt.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -943,9 +405,9 @@\nfunc filePathtoGCS(t *testing.T, projectID, bucketNameForInspectGCSSendToScc, di\n \t\t}); err != nil {\n \t\t\treturn err\n \t\t}\n-\t\tfmt.Printf(\"Bucket '%s' created successfully.\\n\", bucketNameForInspectGCSSendToScc)\n+\t\tlog.Printf(\"[INFO] [filePathtoGCS] Bucket '%s' created successfully.\\n\", bucketNameForInspectGCSSendToScc)\n \t} else {\n-\t\tfmt.Printf(\"Bucket '%s' already exists.\\n\", bucketNameForInspectGCSSendToScc)\n+\t\tlog.Printf(\"[INFO] [filePathtoGCS] Bucket '%s' already exists.\\n\", bucketNameForInspectGCSSendToScc)\n \t}\n \n \t// Check if the directory already exists in the bucket.",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -963,17 +425,17 @@\nfunc filePathtoGCS(t *testing.T, projectID, bucketNameForInspectGCSSendToScc, di\n \t\tif _, err := obj.NewWriter(ctx).Write([]byte(\"\")); err != nil {\n \t\t\tlog.Fatalf(\"Failed to create directory: %v\", err)\n \t\t}\n-\t\tfmt.Printf(\"Directory '%s' created successfully in bucket '%s'.\\n\", dirPathForInspectGCSSendToScc, bucketNameForInspectGCSSendToScc)\n+\t\tlog.Printf(\"[INFO] [filePathtoGCS] Directory '%s' created successfully in bucket '%s'.\\n\", dirPathForInspectGCSSendToScc, bucketNameForInspectGCSSendToScc)\n \t} else {\n-\t\tfmt.Printf(\"Directory '%s' already exists in bucket '%s'.\\n\", dirPathForInspectGCSSendToScc, bucketNameForInspectGCSSendToScc)\n+\t\tlog.Printf(\"[INFO] [filePathtoGCS] Directory '%s' already exists in bucket '%s'.\\n\", dirPathForInspectGCSSendToScc, bucketNameForInspectGCSSendToScc)\n \t}\n \n \t// file upload code\n \n \t// Open local file.\n \tfile, err := ioutil.ReadFile(filePathToUpload)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to read file: %v\", err)\n+\t\tlog.Fatalf(\"[INFO] [filePathtoGCS] Failed to read file: %v\", err)\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -985,29 +447,29 @@\nfunc filePathtoGCS(t *testing.T, projectID, bucketNameForInspectGCSSendToScc, di\n \twriter := object.NewWriter(ctx)\n \t_, err = writer.Write(file)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to write file: %v\", err)\n+\t\tlog.Fatalf(\"[INFO] [filePathtoGCS] Failed to write file: %v\", err)\n \t\treturn err\n \t}\n \terr = writer.Close()\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to close writer: %v\", err)\n+\t\tlog.Fatalf(\"[INFO] [filePathtoGCS] Failed to close writer: %v\", err)\n \t\treturn err\n \t}\n-\tfmt.Printf(\"File uploaded successfully: %v\\n\", inspectsGCSTestFileName)\n+\tlog.Printf(\"[INFO] [filePathtoGCS] File uploaded successfully: %v\\n\", inspectsGCSTestFileName)\n \n \t// Check if the file exists in the bucket\n \t_, err = bucket.Object(inspectsGCSTestFileName).Attrs(ctx)\n \tif err != nil {\n \t\tif err == storage.ErrObjectNotExist {\n-\t\t\tfmt.Printf(\"File %v does not exist in bucket %v\\n\", inspectsGCSTestFileName, bucketNameForInspectGCSSendToScc)\n+\t\t\tlog.Printf(\"[INFO] [filePathtoGCS] File %v does not exist in bucket %v\\n\", inspectsGCSTestFileName, bucketNameForInspectGCSSendToScc)\n \t\t} else {\n-\t\t\tlog.Fatalf(\"Failed to check file existence: %v\", err)\n+\t\t\tlog.Fatalf(\"[INFO] [filePathtoGCS] Failed to check file existence: %v\", err)\n \t\t}\n \t} else {\n-\t\tfmt.Printf(\"File %v exists in bucket %v\\n\", inspectsGCSTestFileName, bucketNameForInspectGCSSendToScc)\n+\t\tlog.Printf(\"[INFO] [filePathtoGCS] File %v exists in bucket %v\\n\", inspectsGCSTestFileName, bucketNameForInspectGCSSendToScc)\n \t}\n \n-\tfmt.Println(\"filePathtoGCS function is executed-------\")\n+\tlog.Println(\"[INFO] [filePathtoGCS] filePathtoGCS function is executed-------\")\n \treturn nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -1058,35 +520,8 @@\nfunc TestMain(m *testing.M) {\n \tdeleteJobTriggerForInspectDataToHybridJobTrigger(tc.ProjectID, jobTriggerForInspectSample)\n \tif err := testutil.DeleteExpiredBuckets(c, tc.ProjectID, testPrefix, bucketExpiryAge); err != nil {\n \t\t// Don't fail the test if cleanup fails\n-\t\tlog.Printf(\"Post-test cleanup failed: %v\", err)\n-\t}\n-}\n-\n-func TestInspectDataToHybridJobTrigger(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\ttrigger := jobTriggerForInspectSample\n-\tfmt.Print(\"Name:\" + trigger)\n-\tif err := inspectDataToHybridJobTrigger(&buf, tc.ProjectID, \"My email is test@example.org and my name is Gary.\", trigger); err != nil {\n-\t\tt.Fatal(err)\n+\t\tlog.Printf(\"[INFO] [TestMain] Post-test cleanup failed: %v\", err)\n \t}\n-\tgot := buf.String()\n-\tif want := \"successfully inspected data using hybrid job trigger\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectDataToHybridJobTrigger got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Findings\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectDataToHybridJobTrigger got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Job State: ACTIVE\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectDataToHybridJobTrigger got %q, want %q\", got, want)\n-\t}\n-\tif want := \"EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectDataToHybridJobTrigger got %q, want %q\", got, want)\n-\t}\n-\tif want := \"PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectDataToHybridJobTrigger got %q, want %q\", got, want)\n-\t}\n-\n }\n \n func deleteActiveJob(project, trigger string) error {",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -16,20 +16,17 @@\npackage jobs\n \n import (\n-\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"regexp\"\n-\t\"strings\"\n \t\"testing\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"cloud.google.com/go/storage\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/gofrs/uuid\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -144,72 +141,8 @@\nfunc riskNumerical(projectID, dataProject, pubSubTopic, pubSubSub, datasetID, ta\n \treturn nil\n }\n \n-func TestListJobs(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n-\tlistJobs(buf, tc.ProjectID, \"\", \"RISK_ANALYSIS_JOB\")\n-\ts := buf.String()\n-\tif len(s) == 0 {\n-\t\t// Create job.\n-\t\triskNumerical(tc.ProjectID, \"bigquery-public-data\", \"risk-topic\", \"risk-sub\", \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\tbuf.Reset()\n-\t\terr := listJobs(buf, tc.ProjectID, \"\", \"RISK_ANALYSIS_JOB\")\n-\t\tif err != nil {\n-\t\t\tt.Errorf(\"listJobs(%s, %s, %s) = error %q, want nil\", buf, tc.ProjectID, \"\", err)\n-\t\t}\n-\t\ts = buf.String()\n-\t}\n-\tif !strings.Contains(buf.String(), \"Job\") {\n-\t\tt.Errorf(\"%q not found in listJobs output: %q\", \"Job\", s)\n-\t}\n-}\n-\n var jobIDRegexp = regexp.MustCompile(`Job ([^ ]+) status.*`)\n \n-func TestDeleteJob(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n-\tlistJobs(buf, tc.ProjectID, \"\", \"RISK_ANALYSIS_JOB\")\n-\ts := buf.String()\n-\tif len(s) == 0 {\n-\t\t// Create job.\n-\t\triskNumerical(tc.ProjectID, \"bigquery-public-data\", \"risk-topic\", \"risk-sub\", \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\tbuf.Reset()\n-\t\tlistJobs(buf, tc.ProjectID, \"\", \"RISK_ANALYSIS_JOB\")\n-\t\ts = buf.String()\n-\t}\n-\tjobName := string(jobIDRegexp.FindSubmatch([]byte(s))[1])\n-\tbuf.Reset()\n-\tdeleteJob(buf, jobName)\n-\tif got := buf.String(); got != \"Successfully deleted job\" {\n-\t\tt.Errorf(\"unable to delete job: %s\", s)\n-\t}\n-}\n-\n-func TestCreateJob(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tvar buf bytes.Buffer\n-\t// createBucketForCreatJob will create a bucket and upload a txt file\n-\tbucketName, fileName, err := createBucketForCreatJob(t, tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgcsPath := \"gs://\" + bucketName + \"/\" + fileName\n-\tinfoTypeNames := []string{\"EMAIL_ADDRESS\", \"PERSON_NAME\", \"LOCATION\", \"PHONE_NUMBER\"}\n-\n-\tif err := createJob(&buf, tc.ProjectID, gcsPath, infoTypeNames); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Created a Dlp Job \"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"TestInspectWithCustomRegex got %q, want %q\", got, want)\n-\t}\n-\n-\tdefer deleteAssetsOfCreateJobTest(t, tc.ProjectID, bucketName, fileName)\n-}\n-\n func createBucketForCreatJob(t *testing.T, projectID string) (string, string, error) {\n \tt.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -16,19 +16,15 @@\npackage metadata\n \n import (\n-\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"log\"\n \t\"os\"\n-\t\"strings\"\n \t\"testing\"\n-\t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"cloud.google.com/go/storage\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -38,80 +34,6 @@\nconst (\n \tbucket_prefix    = \"test\"\n )\n \n-func TestInfoTypes(t *testing.T) {\n-\ttestutil.SystemTest(t)\n-\ttests := []struct {\n-\t\tlanguage string\n-\t\tfilter   string\n-\t\twant     string\n-\t}{\n-\t\t{\n-\t\t\twant: \"TIME\",\n-\t\t},\n-\t\t{\n-\t\t\tlanguage: \"en-US\",\n-\t\t\twant:     \"TIME\",\n-\t\t},\n-\t\t{\n-\t\t\tlanguage: \"es\",\n-\t\t\twant:     \"DATE\",\n-\t\t},\n-\t\t{\n-\t\t\tfilter: \"supported_by=INSPECT\",\n-\t\t\twant:   \"GENDER\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.language, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\tbuf := new(bytes.Buffer)\n-\t\t\terr := infoTypes(buf, test.language, test.filter)\n-\t\t\tif err != nil {\n-\t\t\t\tt.Errorf(\"infoTypes(%s, %s) = error %q, want substring %q\", test.language, test.filter, err, test.want)\n-\t\t\t}\n-\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\tt.Errorf(\"infoTypes(%s, %s) = %s, want substring %q\", test.language, test.filter, got, test.want)\n-\t\t\t}\n-\t\t})\n-\t}\n-}\n-\n-func TestCreateStoredInfoType(t *testing.T) {\n-\n-\ttc := testutil.SystemTest(t)\n-\tctx := context.Background()\n-\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tdefer client.Close()\n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\toutputPath := fmt.Sprintf(\"gs://\" + bucketName + \"/\")\n-\tvar buf bytes.Buffer\n-\n-\tif err := createStoredInfoType(&buf, tc.ProjectID, outputPath); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"output: \"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"error from create stored infoType %q\", got)\n-\t}\n-\n-\tif want := \"github-usernames\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"error from create stored infoType %q\", got)\n-\t}\n-\n-\tname := strings.TrimPrefix(got, \"output: \")\n-\n-\tdefer deleteStoredInfoTypeAfterTest(t, name)\n-}\n-\n func deleteStoredInfoTypeAfterTest(t *testing.T, name string) error {\n \tt.Helper()\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -131,57 +53,6 @@\nfunc deleteStoredInfoTypeAfterTest(t *testing.T, name string) error {\n \treturn nil\n }\n \n-func TestUpdateStoredInfoType(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tvar buf bytes.Buffer\n-\tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tdefer client.Close()\n-\toutputBucket, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\toutputPath := fmt.Sprintf(\"gs://\" + outputBucket + \"/\")\n-\n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tfileSetUrl, gcsUri, err := filesForUpdateStoredInfoType(t, tc.ProjectID, bucketName)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tinfoTypeId, err := createStoredInfoTypeForTesting(t, tc.ProjectID, outputPath)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tinfoTypeId = strings.TrimPrefix(infoTypeId, fmt.Sprint(\"projects/\"+tc.ProjectID+\"/locations/global/storedInfoTypes/\"))\n-\n-\tduration := time.Duration(30) * time.Second\n-\ttime.Sleep(duration)\n-\n-\tif err := updateStoredInfoType(&buf, tc.ProjectID, gcsUri, fileSetUrl, infoTypeId); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\n-\tif want := \"output: \"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"error from create stored infoType %q\", got)\n-\t}\n-\n-\tname := strings.TrimPrefix(got, \"output: \")\n-\n-\tdefer deleteStoredInfoTypeAfterTest(t, name)\n-}\n-\n func filesForUpdateStoredInfoType(t *testing.T, projectID, bucketName string) (string, string, error) {\n \tt.Helper()\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -206,19 +77,19 @@\nfunc filesForUpdateStoredInfoType(t *testing.T, projectID, bucketName string) (s\n \tif !dirExists {\n \t\tobj := client.Bucket(bucketName).Object(dirPath)\n \t\tif _, err := obj.NewWriter(ctx).Write([]byte(\"\")); err != nil {\n-\t\t\tlog.Fatalf(\"Failed to create directory: %v\", err)\n+\t\t\tlog.Fatalf(\"[INFO] [filesForUpdateStoredInfoType] Failed to create directory: %v\", err)\n \t\t}\n-\t\tfmt.Printf(\"Directory '%s' created successfully in bucket '%s'.\\n\", dirPath, bucketName)\n+\t\tlog.Printf(\"[INFO] [filesForUpdateStoredInfoType] Directory '%s' created successfully in bucket '%s'.\\n\", dirPath, bucketName)\n \t} else {\n-\t\tfmt.Printf(\"Directory '%s' already exists in bucket '%s'.\\n\", dirPath, bucketName)\n+\t\tlog.Printf(\"[INFO] [filesForUpdateStoredInfoType] Directory '%s' already exists in bucket '%s'.\\n\", dirPath, bucketName)\n \t}\n \n \t// file upload code\n \n \t// Open local file.\n \tfile, err := os.ReadFile(filePathToUpload)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to read file: %v\", err)\n+\t\tlog.Fatalf(\"[INFO] [filesForUpdateStoredInfoType] Failed to read file: %v\", err)\n \t}\n \n \t// Get a reference to the bucket",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -229,24 +100,24 @@\nfunc filesForUpdateStoredInfoType(t *testing.T, projectID, bucketName string) (s\n \twriter := object.NewWriter(ctx)\n \t_, err = writer.Write(file)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to write file: %v\", err)\n+\t\tlog.Fatalf(\"[INFO] [filesForUpdateStoredInfoType] Failed to write file: %v\", err)\n \t}\n \terr = writer.Close()\n \tif err != nil {\n \t\tlog.Fatalf(\"Failed to close writer: %v\", err)\n \t}\n-\tfmt.Printf(\"File uploaded successfully: %v\\n\", termListFileName)\n+\tlog.Printf(\"[INFO] [filesForUpdateStoredInfoType] File uploaded successfully: %v\\n\", termListFileName)\n \n \t// Check if the file exists in the bucket\n \t_, err = bucket.Object(termListFileName).Attrs(ctx)\n \tif err != nil {\n \t\tif err == storage.ErrObjectNotExist {\n-\t\t\tfmt.Printf(\"File %v does not exist in bucket %v\\n\", termListFileName, bucketName)\n+\t\t\tlog.Printf(\"[INFO] [filesForUpdateStoredInfoType] File %v does not exist in bucket %v\\n\", termListFileName, bucketName)\n \t\t} else {\n-\t\t\tlog.Fatalf(\"Failed to check file existence: %v\", err)\n+\t\t\tlog.Fatalf(\"[INFO] [filesForUpdateStoredInfoType] Failed to check file existence: %v\", err)\n \t\t}\n \t} else {\n-\t\tfmt.Printf(\"File %v exists in bucket %v\\n\", termListFileName, bucketName)\n+\t\tlog.Printf(\"[INFO] [filesForUpdateStoredInfoType] File %v exists in bucket %v\\n\", termListFileName, bucketName)\n \t}\n \n \tfileSetUrl := fmt.Sprint(\"gs://\" + bucketName + \"/\" + termListFileName)",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -16,11 +16,9 @@\npackage risk\n \n import (\n-\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"log\"\n-\t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -35,103 +33,6 @@\nconst (\n \triskSubscriptionName = \"dlp-risk-test-sub-\"\n )\n \n-func TestRisk(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tclient, err := pubsub.NewClient(context.Background(), tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"pubsub.NewClient: %v\", err)\n-\t}\n-\ttests := []struct {\n-\t\tname string\n-\t\tfn   func(r *testutil.R)\n-\t}{\n-\t\t{\n-\t\t\tname: \"Numerical\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskNumerical got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tt.Errorf(\"riskNumerical got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"Categorical\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskCategorical got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskCategorical got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"K Anonymity\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskKAnonymity got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskKAnonymity got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"L Diversity\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tr.Errorf(\"riskLDiversity got err: %v\", err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskLDiversity got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t\t{\n-\t\t\tname: \"K Map\",\n-\t\t\tfn: func(r *testutil.R) {\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.New().String()[:8]\n-\t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n-\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n-\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n-\t\t\t\t\tr.Errorf(\"riskKMap got %s, want substring %q\", got, want)\n-\t\t\t\t}\n-\t\t\t},\n-\t\t},\n-\t}\n-\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.name, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\ttestutil.Retry(t, 20, 2*time.Second, test.fn)\n-\t\t})\n-\t}\n-}\n-\n func cleanupPubsub(t *testing.T, client *pubsub.Client, topicName, subName string) {\n \tctx := context.Background()\n \ttopic := client.Topic(topicName)",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "dlp/snippets/template/template_test.go",
        "code_diff": "@@ -16,9 +16,13 @@\npackage template\n \n import (\n \t\"bytes\"\n+\t\"context\"\n+\t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n \n+\tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -123,7 +123,7 @@\nfunc Accept2xx(r *http.Response) bool {\n \n // AcceptNonServerError returns true for any non-500 http response\n func AcceptNonServerError(r *http.Response) bool {\n-\treturn r.StatusCode > 500\n+\treturn r.StatusCode < 500\n }\n \n func WithAttempts(n int) func(*RetryOptions) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -142,8 +142,8 @@\nfunc WithAcceptFunc(f func(*http.Response) bool) func(*RetryOptions) {\n \t}\n }\n \n-// Request issues an HTTP request to the deployed service.\n-func (s *Service) Request(method string, path string, opts ...func(*RetryOptions)) (*http.Response, error) {\n+// Do executes the provided http.Request using the default http client\n+func (s *Service) Do(req *http.Request, opts ...func(*RetryOptions)) (*http.Response, error) {\n \tif !s.deployed {\n \t\treturn nil, errors.New(\"Request called before Deploy\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/create_cdn_key.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2022 Google LLC\n+// Copyright 2023 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/create_cdn_key.go",
        "code_diff": "@@ -21,36 +21,36 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // createCDNKey creates a CDN key. A CDN key is used to retrieve protected media.\n // If isMediaCDN is true, create a Media CDN key. If false, create a Cloud\n // CDN key. To create a privateKey value for Media CDN, see\n // https://cloud.google.com/video-stitcher/docs/how-to/managing-cdn-keys#create-private-key-media-cdn.\n-func createCDNKey(w io.Writer, projectID, keyID, hostname, keyName, privateKey string, isMediaCDN bool) error {\n+func createCDNKey(w io.Writer, projectID, keyID, privateKey string, isMediaCDN bool) error {\n \t// projectID := \"my-project-id\"\n \t// keyID := \"my-cdn-key\"\n-\t// hostname := \"cdn.example.com\"\n-\t// keyName := \"cdn-key\"\n \t// privateKey := \"my-private-key\"\n \t// isMediaCDN := true\n \tlocation := \"us-central1\"\n+\thostname := \"cdn.example.com\"\n+\tkeyName := \"cdn-key\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"stitcher.NewVideoStitcherClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n-\tvar req *stitcherpb.CreateCdnKeyRequest\n+\tvar req *stitcherstreampb.CreateCdnKeyRequest\n \tif isMediaCDN {\n-\t\treq = &stitcherpb.CreateCdnKeyRequest{\n+\t\treq = &stitcherstreampb.CreateCdnKeyRequest{\n \t\t\tParent:   fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n \t\t\tCdnKeyId: keyID,\n-\t\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_MediaCdnKey{\n-\t\t\t\t\tMediaCdnKey: &stitcherpb.MediaCdnKey{\n+\t\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_MediaCdnKey{\n+\t\t\t\t\tMediaCdnKey: &stitcherstreampb.MediaCdnKey{\n \t\t\t\t\t\tKeyName:    keyName,\n \t\t\t\t\t\tPrivateKey: []byte(privateKey),\n \t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/create_cdn_key.go",
        "code_diff": "@@ -59,12 +59,12 @@\nfunc createCDNKey(w io.Writer, projectID, keyID, hostname, keyName, privateKey s\n \t\t\t},\n \t\t}\n \t} else {\n-\t\treq = &stitcherpb.CreateCdnKeyRequest{\n+\t\treq = &stitcherstreampb.CreateCdnKeyRequest{\n \t\t\tParent:   fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n \t\t\tCdnKeyId: keyID,\n-\t\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_GoogleCdnKey{\n-\t\t\t\t\tGoogleCdnKey: &stitcherpb.GoogleCdnKey{\n+\t\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_GoogleCdnKey{\n+\t\t\t\t\tGoogleCdnKey: &stitcherstreampb.GoogleCdnKey{\n \t\t\t\t\t\tKeyName:    keyName,\n \t\t\t\t\t\tPrivateKey: []byte(privateKey),\n \t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/create_cdn_key_akamai.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2022 Google LLC\n+// Copyright 2023 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/create_cdn_key_akamai.go",
        "code_diff": "@@ -21,30 +21,30 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // createCDNKeyAkamai creates an Akamai CDN key. A CDN key is used to retrieve\n // protected media.\n-func createCDNKeyAkamai(w io.Writer, projectID, keyID, hostname, akamaiTokenKey string) error {\n+func createCDNKeyAkamai(w io.Writer, projectID, keyID, akamaiTokenKey string) error {\n \t// projectID := \"my-project-id\"\n \t// keyID := \"my-cdn-key\"\n-\t// hostname := \"cdn.example.com\"\n \t// akamaiTokenKey := \"my-private-token-key\"\n \tlocation := \"us-central1\"\n+\thostname := \"cdn.example.com\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"stitcher.NewVideoStitcherClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n-\treq := &stitcherpb.CreateCdnKeyRequest{\n+\treq := &stitcherstreampb.CreateCdnKeyRequest{\n \t\tParent:   fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n \t\tCdnKeyId: keyID,\n-\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_AkamaiCdnKey{\n-\t\t\t\tAkamaiCdnKey: &stitcherpb.AkamaiCdnKey{\n+\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_AkamaiCdnKey{\n+\t\t\t\tAkamaiCdnKey: &stitcherstreampb.AkamaiCdnKey{\n \t\t\t\t\tTokenKey: []byte(akamaiTokenKey),\n \t\t\t\t},\n \t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/delete_cdn_key.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2022 Google LLC\n+// Copyright 2023 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/delete_cdn_key.go",
        "code_diff": "@@ -21,7 +21,7 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // deleteCDNKey deletes a CDN key.",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/get_cdn_key.go",
        "code_diff": "@@ -22,7 +22,7 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // getCDNKey gets a CDN key by ID.",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/list_cdn_keys.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // listCDNKeys gets all of the CDN keys for a given location.",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/update_cdn_key.go",
        "code_diff": "@@ -21,35 +21,35 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n \t\"google.golang.org/protobuf/types/known/fieldmaskpb\"\n )\n \n // updateCDNKey updates a CDN key. A CDN key is used to retrieve protected media.\n // If isMediaCDN is true, update a Media CDN key. If false, update a Cloud\n // CDN key. To create an updated privateKey value for Media CDN, see\n // https://cloud.google.com/video-stitcher/docs/how-to/managing-cdn-keys#create-private-key-media-cdn.\n-func updateCDNKey(w io.Writer, projectID, keyID, hostname, keyName, privateKey string, isMediaCDN bool) error {\n+func updateCDNKey(w io.Writer, projectID, keyID, privateKey string, isMediaCDN bool) error {\n \t// projectID := \"my-project-id\"\n \t// keyID := \"my-cdn-key\"\n-\t// hostname := \"updated.cdn.example.com\"\n-\t// keyName := \"cdn-key\"\n \t// privateKey := \"my-updated-private-key\"\n \t// isMediaCDN := true\n \tlocation := \"us-central1\"\n+\thostname := \"updated.cdn.example.com\"\n+\tkeyName := \"cdn-key\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"stitcher.NewVideoStitcherClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n-\tvar req *stitcherpb.UpdateCdnKeyRequest\n+\tvar req *stitcherstreampb.UpdateCdnKeyRequest\n \tif isMediaCDN {\n-\t\treq = &stitcherpb.UpdateCdnKeyRequest{\n-\t\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_MediaCdnKey{\n-\t\t\t\t\tMediaCdnKey: &stitcherpb.MediaCdnKey{\n+\t\treq = &stitcherstreampb.UpdateCdnKeyRequest{\n+\t\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_MediaCdnKey{\n+\t\t\t\t\tMediaCdnKey: &stitcherstreampb.MediaCdnKey{\n \t\t\t\t\t\tKeyName:    keyName,\n \t\t\t\t\t\tPrivateKey: []byte(privateKey),\n \t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/update_cdn_key.go",
        "code_diff": "@@ -64,10 +64,10 @@\nfunc updateCDNKey(w io.Writer, projectID, keyID, hostname, keyName, privateKey s\n \t\t\t},\n \t\t}\n \t} else {\n-\t\treq = &stitcherpb.UpdateCdnKeyRequest{\n-\t\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_GoogleCdnKey{\n-\t\t\t\t\tGoogleCdnKey: &stitcherpb.GoogleCdnKey{\n+\t\treq = &stitcherstreampb.UpdateCdnKeyRequest{\n+\t\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_GoogleCdnKey{\n+\t\t\t\t\tGoogleCdnKey: &stitcherstreampb.GoogleCdnKey{\n \t\t\t\t\t\tKeyName:    keyName,\n \t\t\t\t\t\tPrivateKey: []byte(privateKey),\n \t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "media/videostitcher/update_cdn_key_akamai.go",
        "code_diff": "@@ -21,29 +21,29 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n \t\"google.golang.org/protobuf/types/known/fieldmaskpb\"\n )\n \n // updateCDNKeyAkamai updates an Akamai CDN key. A CDN key is used to retrieve\n // protected media.\n-func updateCDNKeyAkamai(w io.Writer, projectID, keyID, hostname, akamaiTokenKey string) error {\n+func updateCDNKeyAkamai(w io.Writer, projectID, keyID, akamaiTokenKey string) error {\n \t// projectID := \"my-project-id\"\n \t// keyID := \"my-cdn-key\"\n-\t// hostname := \"updated.cdn.example.com\"\n \t// akamaiTokenKey := \"my-updated-token-key\"\n \tlocation := \"us-central1\"\n+\thostname := \"updated.cdn.example.com\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"stitcher.NewVideoStitcherClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n-\treq := &stitcherpb.UpdateCdnKeyRequest{\n-\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_AkamaiCdnKey{\n-\t\t\t\tAkamaiCdnKey: &stitcherpb.AkamaiCdnKey{\n+\treq := &stitcherstreampb.UpdateCdnKeyRequest{\n+\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_AkamaiCdnKey{\n+\t\t\t\tAkamaiCdnKey: &stitcherstreampb.AkamaiCdnKey{\n \t\t\t\t\tTokenKey: []byte(akamaiTokenKey),\n \t\t\t\t},\n \t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "pubsub/subscriptions/create_cloud_storage_subscription.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage subscriptions\n \n-// [START pubsub_cloudstorage_subscription]\n+// [START pubsub_create_cloud_storage_subscription]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "run/testing/logging_manual.e2e_test.go",
        "code_diff": "@@ -15,10 +15,8 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -67,7 +67,7 @@\nfunc caseEditorServiceUI(t *testing.T) {\n \t\tt.Fatalf(\"service.NewRequest: %q\", err)\n \t}\n \n-\tresp, err := client.Do(req)\n+\tresp, err := editorService.Do(req)\n \tif err != nil {\n \t\tt.Fatalf(\"client.Do: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -92,7 +92,7 @@\nfunc caseEditorServiceRender(t *testing.T) {\n \t}\n \treq.Body = ioutil.NopCloser(bytes.NewReader(b))\n \n-\tresp, err := client.Do(req)\n+\tresp, err := editorService.Do(req)\n \tif err != nil {\n \t\tt.Fatalf(\"client.Do: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "run/testing/markdown_preview_renderer.e2e_test.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"net/http\"\n \t\"strings\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "run/testing/markdown_preview_renderer.e2e_test.go",
        "code_diff": "@@ -58,8 +57,7 @@\nfunc TestRendererService(t *testing.T) {\n \t\t}\n \t\treq.Body = ioutil.NopCloser(strings.NewReader(test.input))\n \n-\t\tclient := http.Client{Timeout: 10 * time.Second}\n-\t\tresp, err := client.Do(req)\n+\t\tresp, err := service.Do(req)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"client.Do: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "testing(run): add test retries to Cloud Run grpc-ping and grpc-streaming",
        "pr_number": 3298,
        "file_name": "storage/buckets/set_autoclass.go",
        "code_diff": "@@ -29,9 +29,12 @@\nimport (\n \n // Note: Only update requests that disable Autoclass are currently supported.\n // To enable Autoclass, you must set it at bucket creation time.\n-func setAutoclass(w io.Writer, bucketName string, value bool) error {\n+func setAutoclass(w io.Writer, bucketName string) error {\n \t// bucketName := \"bucket-name\"\n-\t// value := false\n+\t// Enable Autoclass for a bucket. Set enabled to false to disable Autoclass.\n+\t// Set Autoclass.TerminalStorageClass, valid values are NEARLINE and ARCHIVE.\n+\tenabled := true\n+\tterminalStorageClass := \"ARCHIVE\"\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into testing-retries-run-grpc",
        "commit_id": "9c60bce7ff0cc7cdf9e9a9d6726a2fbc9e285f3c"
    },
    {
        "pr_title": "fix(dlp): remove the function call of setupPubSub and added a inline code in samples",
        "pr_number": 3288,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -651,6 +651,157 @@\nfunc TestInspectTableWithCustomHotword(t *testing.T) {\n \t}\n }\n \n+func createBigQueryDataSetId(projectID string) error {\n+\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tmeta := &bigquery.DatasetMetadata{\n+\t\tLocation: \"US\", // See https://cloud.google.com/bigquery/docs/locations\n+\t}\n+\n+\tif err := client.Dataset(dataSetID).Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n+func createTableInsideDataset(projectID, dataSetID string) error {\n+\tctx := context.Background()\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"user_id\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType},\n+\t\t{Name: \"title\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"score\", Type: bigquery.StringFieldType},\n+\t}\n+\n+\tmetaData := &bigquery.TableMetadata{\n+\t\tSchema:         sampleSchema,\n+\t\tExpirationTime: time.Now().AddDate(1, 0, 0), // Table will be automatically deleted in 1 year.\n+\t}\n+\n+\ttableRef := client.Dataset(dataSetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, metaData); err != nil {\n+\t\tlog.Printf(\"[INFO] createBigQueryDataSetId Error while table creation: %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tduration := time.Duration(90) * time.Second\n+\ttime.Sleep(duration)\n+\n+\tinserter := client.Dataset(dataSetID).Table(tableID).Inserter()\n+\titems := []*BigQueryTableItem{\n+\t\t// Item implements the ValueSaver interface.\n+\t\t{UserId: \"602-61-8588\", Age: 32, Title: \"Biostatistician III\", Score: \"A\"},\n+\t\t{UserId: \"618-96-2322\", Age: 69, Title: \"Programmer I\", Score: \"C\"},\n+\t\t{UserId: \"618-96-2322\", Age: 69, Title: \"Executive Secretary\", Score: \"C\"},\n+\t}\n+\tif err := inserter.Put(ctx, items); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n+type BigQueryTableItem struct {\n+\tUserId string\n+\tAge    int\n+\tTitle  string\n+\tScore  string\n+}\n+\n+func (i *BigQueryTableItem) Save() (map[string]bigquery.Value, string, error) {\n+\treturn map[string]bigquery.Value{\n+\t\t\"user_id\": i.UserId,\n+\t\t\"age\":     i.Age,\n+\t\t\"title\":   i.Title,\n+\t\t\"score\":   i.Score,\n+\t}, bigquery.NoDedupeID, nil\n+}\n+\n+func deleteBigQueryAssets(projectID string) error {\n+\n+\tlog.Printf(\"[START] deleteBigQueryAssets: projectID %v and \", projectID)\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tlog.Printf(\"[INFO] deleteBigQueryAssets: delete dataset err %v\", err)\n+\n+\tif err := client.Dataset(\"dlp_test_dataset\").DeleteWithContents(ctx); err != nil {\n+\t\tlog.Printf(\"[INFO] deleteBigQueryAssets: delete dataset err %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tduration := time.Duration(30) * time.Second\n+\ttime.Sleep(duration)\n+\n+\tlog.Printf(\"[END] deleteBigQueryAssets:\")\n+\treturn nil\n+}\n+\n+func deleteJob(projectID, jobName string) error {\n+\tctx := context.Background()\n+\n+\tlog.Printf(\"[START] deleteJob: projectID %v\", projectID)\n+\t// delete job\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\treturn err\n+\t}\n+\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\n+\treq := &dlppb.DeleteDlpJobRequest{\n+\t\tName: jobName,\n+\t}\n+\tfor {\n+\t\tct, cancel := context.WithTimeout(ctx, 300000)\n+\t\tdefer cancel()\n+\t\tabc, err := client.GetDlpJob(ct, &dlppb.GetDlpJobRequest{\n+\t\t\tName: jobName,\n+\t\t})\n+\t\tif err != nil {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\t\treturn err\n+\t\t}\n+\t\tif abc.State == dlppb.DlpJob_DONE {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job done\")\n+\t\t\tbreak\n+\t\t} else if abc.State == dlppb.DlpJob_FAILED {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job failed\")\n+\t\t\treturn err\n+\t\t} else {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job continue\")\n+\t\t\tcontinue\n+\t\t}\n+\t}\n+\terr = client.DeleteDlpJob(ctx, req)\n+\tif err != nil {\n+\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tlog.Printf(\"[END] deleteJob\")\n+\treturn nil\n+}\n+\n func TestInspectDataStoreSendToScc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_message": "Merge branch 'main' into fix_PR_for_issue_3281",
        "commit_id": "945e501557b594e898a21c8b19614554535b984e"
    },
    {
        "pr_title": "feat(cloudrunci): Add retry by default to Service.Request",
        "pr_number": 3283,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -42,7 +42,8 @@\nimport (\n const (\n \tbucketForDeidCloudStorageForInput  = \"dlp-test-deid-input\"\n \tbucketForDeidCloudStorageForOutput = \"dlp-test-deid-go-lang-output\"\n-\tfilePathToGCSForDeidTest           = \"./testdata/dlp_sample.csv\"\n+\tfilePathToGCSUploadForDeidTest     = \"./testdata/dlp_sample.csv\"\n+\tfilePathToGCSForDeidTest           = \"/testdata/dlp_sample.csv\"\n \ttableID                            = \"dlp_test_deid_table\"\n \tdataSetID                          = \"dlp_test_deid_dataset\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into retries-for-all",
        "commit_id": "72ca024961997989542980f40e1c8b60977187ff"
    },
    {
        "pr_title": "feat(cloudrunci): Add retry by default to Service.Request",
        "pr_number": 3283,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -26,9 +26,12 @@\nimport (\n \n \t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/datastore\"\n+\tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n const (",
        "comments": [],
        "commit_message": "Merge branch 'main' into retries-for-all",
        "commit_id": "72ca024961997989542980f40e1c8b60977187ff"
    },
    {
        "pr_title": "feat(cloudrunci): Add retry by default to Service.Request",
        "pr_number": 3283,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -38,6 +41,9 @@\nconst (\n \tssnFileName = \"fake_ssn.txt\"\n \tbucketName  = \"golang-samples-dlp-test2\"\n \n+\tjobTriggerIdPrefix                      = \"dlp-job-trigger-unit-test-case-12345678\"\n+\tdataSetIDForHybridJob                   = \"dlp_test_dataset\"\n+\ttableIDForHybridJob                     = \"dlp_inspect_test_table_table_id\"\n \tinspectsGCSTestFileName                 = \"test.txt\"\n \tfilePathToUpload                        = \"./testdata/test.txt\"\n \tdirPathForInspectGCSSendToScc           = \"dlp-go-lang-test-for-inspect-gcs-send-to-scc/\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into retries-for-all",
        "commit_id": "72ca024961997989542980f40e1c8b60977187ff"
    },
    {
        "pr_title": "feat(cloudrunci): Add retry by default to Service.Request",
        "pr_number": 3283,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -649,7 +655,7 @@\nfunc TestInspectDataStoreSendToScc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n \tu := uuid.New().String()[:8]\n-\tdatastoreNamespace := \"golang-samples\" + u\n+\tdatastoreNamespace := fmt.Sprint(\"golang-samples\" + u)\n \tdatastoreKind := \"task\"\n \n \tif err := inspectDataStoreSendToScc(&buf, tc.ProjectID, datastoreNamespace, datastoreKind); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into retries-for-all",
        "commit_id": "72ca024961997989542980f40e1c8b60977187ff"
    },
    {
        "pr_title": "feat(cloudrunci): Add retry by default to Service.Request",
        "pr_number": 3283,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage risk\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"log\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into retries-for-all",
        "commit_id": "72ca024961997989542980f40e1c8b60977187ff"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -40,12 +40,9 @@\nimport (\n )\n \n const (\n-\tbucketForDeidCloudStorageForInput  = \"dlp-test-deid-input\"\n-\tbucketForDeidCloudStorageForOutput = \"dlp-test-deid-go-lang-output\"\n-\tfilePathToGCSForDeidTest           = \"./testdata/dlp_sample.csv\"\n-\ttableID                            = \"dlp_test_deid_table\"\n-\tdataSetID                          = \"dlp_test_deid_dataset\"\n-\n+\tfilePathToGCSForDeidTest       = \"./testdata/dlp_sample.csv\"\n+\ttableID                        = \"dlp_test_deid_table\"\n+\tdataSetID                      = \"dlp_test_deid_dataset\"\n \tdeidentifyTemplateID           = \"deidentified-templat-test-go\"\n \tdeidentifyStructuredTemplateID = \"deidentified-structured-template-go\"\n \tredactImageTemplate            = \"redact-image-template-go\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -710,7 +707,7 @@\nfunc TestDeidentifyDataReplaceWithDictionary(t *testing.T) {\n func TestDeidentifyCloudStorage(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n-\t// \"gs://dlp-crest-test/dlp_sample.csv\"\n+\n \tgcsURI := fmt.Sprint(\"gs://\" + bucketForDeidCloudStorageForInput + \"/\" + filePathToGCSForDeidTest)\n \toutputBucket := fmt.Sprint(\"gs://\" + bucketForDeidCloudStorageForOutput)",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -26,9 +26,12 @@\nimport (\n \n \t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/datastore\"\n+\tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n const (",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -38,6 +41,9 @@\nconst (\n \tssnFileName = \"fake_ssn.txt\"\n \tbucketName  = \"golang-samples-dlp-test2\"\n \n+\tjobTriggerIdPrefix                      = \"dlp-job-trigger-unit-test-case-12345678\"\n+\tdataSetIDForHybridJob                   = \"dlp_test_dataset\"\n+\ttableIDForHybridJob                     = \"dlp_inspect_test_table_table_id\"\n \tinspectsGCSTestFileName                 = \"test.txt\"\n \tfilePathToUpload                        = \"./testdata/test.txt\"\n \tdirPathForInspectGCSSendToScc           = \"dlp-go-lang-test-for-inspect-gcs-send-to-scc/\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -617,7 +623,7 @@\nfunc TestInspectAugmentInfoTypes(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \tgot := buf.String()\n-\tif want := \"Qoute: Quasimodo\"; !strings.Contains(got, want) {\n+\tif want := \"Quote: Quasimodo\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"TestInspectAugmentInfoTypes got %q, want %q\", got, want)\n \t}\n \tif want := \"Info type: PERSON_NAME\"; !strings.Contains(got, want) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -645,11 +651,162 @@\nfunc TestInspectTableWithCustomHotword(t *testing.T) {\n \t}\n }\n \n+func createBigQueryDataSetId(projectID string) error {\n+\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tmeta := &bigquery.DatasetMetadata{\n+\t\tLocation: \"US\", // See https://cloud.google.com/bigquery/docs/locations\n+\t}\n+\n+\tif err := client.Dataset(dataSetID).Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n+func createTableInsideDataset(projectID, dataSetID string) error {\n+\tctx := context.Background()\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"user_id\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType},\n+\t\t{Name: \"title\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"score\", Type: bigquery.StringFieldType},\n+\t}\n+\n+\tmetaData := &bigquery.TableMetadata{\n+\t\tSchema:         sampleSchema,\n+\t\tExpirationTime: time.Now().AddDate(1, 0, 0), // Table will be automatically deleted in 1 year.\n+\t}\n+\n+\ttableRef := client.Dataset(dataSetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, metaData); err != nil {\n+\t\tlog.Printf(\"[INFO] createBigQueryDataSetId Error while table creation: %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tduration := time.Duration(90) * time.Second\n+\ttime.Sleep(duration)\n+\n+\tinserter := client.Dataset(dataSetID).Table(tableID).Inserter()\n+\titems := []*BigQueryTableItem{\n+\t\t// Item implements the ValueSaver interface.\n+\t\t{UserId: \"602-61-8588\", Age: 32, Title: \"Biostatistician III\", Score: \"A\"},\n+\t\t{UserId: \"618-96-2322\", Age: 69, Title: \"Programmer I\", Score: \"C\"},\n+\t\t{UserId: \"618-96-2322\", Age: 69, Title: \"Executive Secretary\", Score: \"C\"},\n+\t}\n+\tif err := inserter.Put(ctx, items); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n+type BigQueryTableItem struct {\n+\tUserId string\n+\tAge    int\n+\tTitle  string\n+\tScore  string\n+}\n+\n+func (i *BigQueryTableItem) Save() (map[string]bigquery.Value, string, error) {\n+\treturn map[string]bigquery.Value{\n+\t\t\"user_id\": i.UserId,\n+\t\t\"age\":     i.Age,\n+\t\t\"title\":   i.Title,\n+\t\t\"score\":   i.Score,\n+\t}, bigquery.NoDedupeID, nil\n+}\n+\n+func deleteBigQueryAssets(projectID string) error {\n+\n+\tlog.Printf(\"[START] deleteBigQueryAssets: projectID %v and \", projectID)\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tlog.Printf(\"[INFO] deleteBigQueryAssets: delete dataset err %v\", err)\n+\n+\tif err := client.Dataset(\"dlp_test_dataset\").DeleteWithContents(ctx); err != nil {\n+\t\tlog.Printf(\"[INFO] deleteBigQueryAssets: delete dataset err %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tduration := time.Duration(30) * time.Second\n+\ttime.Sleep(duration)\n+\n+\tlog.Printf(\"[END] deleteBigQueryAssets:\")\n+\treturn nil\n+}\n+\n+func deleteJob(projectID, jobName string) error {\n+\tctx := context.Background()\n+\n+\tlog.Printf(\"[START] deleteJob: projectID %v\", projectID)\n+\t// delete job\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\treturn err\n+\t}\n+\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\n+\treq := &dlppb.DeleteDlpJobRequest{\n+\t\tName: jobName,\n+\t}\n+\tfor {\n+\t\tct, cancel := context.WithTimeout(ctx, 300000)\n+\t\tdefer cancel()\n+\t\tabc, err := client.GetDlpJob(ct, &dlppb.GetDlpJobRequest{\n+\t\t\tName: jobName,\n+\t\t})\n+\t\tif err != nil {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\t\treturn err\n+\t\t}\n+\t\tif abc.State == dlppb.DlpJob_DONE {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job done\")\n+\t\t\tbreak\n+\t\t} else if abc.State == dlppb.DlpJob_FAILED {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job failed\")\n+\t\t\treturn err\n+\t\t} else {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job continue\")\n+\t\t\tcontinue\n+\t\t}\n+\t}\n+\terr = client.DeleteDlpJob(ctx, req)\n+\tif err != nil {\n+\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tlog.Printf(\"[END] deleteJob\")\n+\treturn nil\n+}\n+\n func TestInspectDataStoreSendToScc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n \tu := uuid.New().String()[:8]\n-\tdatastoreNamespace := \"golang-samples\" + u\n+\tdatastoreNamespace := fmt.Sprint(\"golang-samples\" + u)\n \tdatastoreKind := \"task\"\n \n \tif err := inspectDataStoreSendToScc(&buf, tc.ProjectID, datastoreNamespace, datastoreKind); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -662,6 +819,68 @@\nfunc TestInspectDataStoreSendToScc(t *testing.T) {\n \t}\n }\n \n+var (\n+\tprojectID                  string\n+\tjobTriggerForInspectSample string\n+\tbucketExpiryAge            = time.Minute * 2\n+\ttestPrefix                 = \"dlp-test-inspect-prefix\"\n+)\n+\n+func createStoredInfoTypeForTesting(t *testing.T, projectID, outputPath string) (string, error) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\tdefer client.Close()\n+\tu := uuid.New().String()[:8]\n+\tdisplayName := \"stored-info-type-for-inspect-test\" + u\n+\tdescription := \"Dictionary of GitHub usernames used in commits\"\n+\n+\tcloudStoragePath := &dlppb.CloudStoragePath{\n+\t\tPath: outputPath,\n+\t}\n+\n+\tbigQueryField := &dlppb.BigQueryField{\n+\t\tTable: &dlppb.BigQueryTable{\n+\t\t\tProjectId: \"bigquery-public-data\",\n+\t\t\tDatasetId: \"samples\",\n+\t\t\tTableId:   \"github_nested\",\n+\t\t},\n+\t\tField: &dlppb.FieldId{\n+\t\t\tName: \"actor\",\n+\t\t},\n+\t}\n+\n+\tlargeCustomDictionaryConfig := &dlppb.LargeCustomDictionaryConfig{\n+\t\tOutputPath: cloudStoragePath,\n+\t\tSource: &dlppb.LargeCustomDictionaryConfig_BigQueryField{\n+\t\t\tBigQueryField: bigQueryField,\n+\t\t},\n+\t}\n+\n+\tstoredInfoTypeConfig := &dlppb.StoredInfoTypeConfig{\n+\t\tDisplayName: displayName,\n+\t\tDescription: description,\n+\t\tType: &dlppb.StoredInfoTypeConfig_LargeCustomDictionary{\n+\t\t\tLargeCustomDictionary: largeCustomDictionaryConfig,\n+\t\t},\n+\t}\n+\n+\treq := &dlppb.CreateStoredInfoTypeRequest{\n+\t\tParent:           fmt.Sprintf(\"projects/%s/locations/global\", projectID),\n+\t\tConfig:           storedInfoTypeConfig,\n+\t\tStoredInfoTypeId: \"go-sample-test-stored-infoType\" + u,\n+\t}\n+\tresp, err := client.CreateStoredInfoType(ctx, req)\n+\tif err != nil {\n+\t\treturn \"nil\", err\n+\t}\n+\n+\treturn resp.Name, nil\n+}\n+\n func TestInspectGCSFileSendToScc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -18,13 +18,16 @@\npackage risk\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n+\t\"log\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"github.com/gofrs/uuid\"\n+\t\"github.com/google/uuid\"\n )\n \n const (",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -46,7 +49,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Numerical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -62,7 +65,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Categorical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -78,7 +81,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Anonymity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -94,7 +97,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"L Diversity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -110,7 +113,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Map\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "run/testing/hello_broken.e2e_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "run/testing/helloworld.e2e_test.go",
        "code_diff": "@@ -15,11 +15,9 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"io/ioutil\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "run/testing/image_processing.e2e_test.go",
        "code_diff": "@@ -15,10 +15,8 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-import-dataset",
        "commit_id": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "fix(dlp): fixes DLP Risk snippet tests #2897",
        "pr_number": 3272,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -18,7 +18,6 @@\npackage risk\n import (\n \t\"bytes\"\n \t\"context\"\n-\t\"log\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "minor changes",
        "commit_id": "40d83b29ec5859d96999fa3f642416492e81a224"
    },
    {
        "pr_title": "feat(aiplatform): adds delete dataset sample",
        "pr_number": 3269,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -119,7 +119,7 @@\nfunc cleanupNotificationConfig(t *testing.T, notificationConfigID string) error\n }\n \n func TestCreateNotificationConfig(t *testing.T) {\n-\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\ttestutil.Retry(t, 5, 30*time.Second, func(r *testutil.R) {\n \t\tbuf := new(bytes.Buffer)\n \t\trand, err := uuid.NewUUID()\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-delete-dataset",
        "commit_id": "4623f2295f14e44341fb4fb0f287291cc47bd54d"
    },
    {
        "pr_title": "feat(aiplatform): adds delete dataset sample",
        "pr_number": 3269,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -142,7 +142,7 @@\nfunc TestCreateNotificationConfig(t *testing.T) {\n }\n \n func TestDeleteNotificationConfig(t *testing.T) {\n-\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\ttestutil.Retry(t, 5, 30*time.Second, func(r *testutil.R) {\n \t\tbuf := new(bytes.Buffer)\n \t\trand, err := uuid.NewUUID()\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-delete-dataset",
        "commit_id": "4623f2295f14e44341fb4fb0f287291cc47bd54d"
    },
    {
        "pr_title": "feat(aiplatform): adds delete dataset sample",
        "pr_number": 3269,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -168,7 +168,7 @@\nfunc TestDeleteNotificationConfig(t *testing.T) {\n }\n \n func TestGetNotificationConfig(t *testing.T) {\n-\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\ttestutil.Retry(t, 5, 30*time.Second, func(r *testutil.R) {\n \t\tbuf := new(bytes.Buffer)\n \t\trand, err := uuid.NewUUID()\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-delete-dataset",
        "commit_id": "4623f2295f14e44341fb4fb0f287291cc47bd54d"
    },
    {
        "pr_title": "feat(aiplatform): adds delete dataset sample",
        "pr_number": 3269,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -196,7 +196,7 @@\nfunc TestGetNotificationConfig(t *testing.T) {\n }\n \n func TestListNotificationConfigs(t *testing.T) {\n-\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\ttestutil.Retry(t, 5, 30*time.Second, func(r *testutil.R) {\n \t\tbuf := new(bytes.Buffer)\n \t\trand, err := uuid.NewUUID()\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-delete-dataset",
        "commit_id": "4623f2295f14e44341fb4fb0f287291cc47bd54d"
    },
    {
        "pr_title": "feat(aiplatform): adds delete dataset sample",
        "pr_number": 3269,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -224,7 +224,7 @@\nfunc TestListNotificationConfigs(t *testing.T) {\n }\n \n func TestUpdateNotificationConfig(t *testing.T) {\n-\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\ttestutil.Retry(t, 5, 30*time.Second, func(r *testutil.R) {\n \t\tbuf := new(bytes.Buffer)\n \t\trand, err := uuid.NewUUID()\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into aip-delete-dataset",
        "commit_id": "4623f2295f14e44341fb4fb0f287291cc47bd54d"
    },
    {
        "pr_title": "feat(aiplatform): adds create dataset sample for Vertex",
        "pr_number": 3266,
        "file_name": "aiplatform/snippets/create_dataset.go",
        "code_diff": "@@ -28,10 +28,9 @@\nimport (\n )\n \n // createDataset creates a dataset in Vertex AI\n-func createDataset(w io.Writer, projectID, location, datasetID string) error {\n+func createDataset(w io.Writer, projectID, location string) error {\n \t// projectID := \"my-project\"\n \t// location := \"us-central1\"\n-\t// datasetID := \"my-dataset\"\n \n \tapiEndpoint := fmt.Sprintf(\"%s-aiplatform.googleapis.com:443\", location)\n \tclientOption := option.WithEndpoint(apiEndpoint)",
        "comments": [],
        "commit_message": "Per reviewer",
        "commit_id": "4088b71e8143d2cd8cb6a6cedcc422ffb63d4e85"
    },
    {
        "pr_title": "feat(aiplatform): adds create dataset sample for Vertex",
        "pr_number": 3266,
        "file_name": "aiplatform/snippets/create_dataset.go",
        "code_diff": "@@ -44,6 +43,7 @@\nfunc createDataset(w io.Writer, projectID, location, datasetID string) error {\n \tdefer client.Close()\n \n \t// Create a new, empty image dataset\n+\t// Vertex AI automatically assigns an ID for the dataset resource\n \treq := &aiplatformpb.CreateDatasetRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n \t\tDataset: &aiplatformpb.Dataset{",
        "comments": [],
        "commit_message": "Per reviewer",
        "commit_id": "4088b71e8143d2cd8cb6a6cedcc422ffb63d4e85"
    },
    {
        "pr_title": "feat(aiplatform): adds create dataset sample for Vertex",
        "pr_number": 3266,
        "file_name": "aiplatform/snippets/create_dataset_test.go",
        "code_diff": "@@ -31,7 +31,6 @@\nimport (\n )\n \n var (\n-\tdatasetID string\n \toutput    string\n \tprojectID string\n \tregion    string = \"us-central1\"",
        "comments": [
            {
                "comment": "Can we add a dynamic component to this dataset, like some UUID or something? It will help reduce resource contention.",
                "position": null
            },
            {
                "comment": "That is a reasonable request ... unfortunately, the developer doesn't control the actual dataset ID. It is automatically assigned by the service. I will rename this variable to reflect that behavior.",
                "position": null
            }
        ],
        "commit_message": "Per reviewer",
        "commit_id": "4088b71e8143d2cd8cb6a6cedcc422ffb63d4e85"
    },
    {
        "pr_title": "feat(aiplatform): adds create dataset sample for Vertex",
        "pr_number": 3266,
        "file_name": "aiplatform/snippets/create_dataset_test.go",
        "code_diff": "@@ -54,10 +53,9 @@\nfunc TestMain(m *testing.M) {\n \n func TestCreateDataset(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tdatasetID = \"my-image-dataset\"\n \tvar buf bytes.Buffer\n \n-\tif err := createDataset(&buf, tc.ProjectID, region, datasetID); err != nil {\n+\tif err := createDataset(&buf, tc.ProjectID, region); err != nil {\n \t\tt.Fatalf(\"createDataset: %v\", err)\n \t}",
        "comments": [
            {
                "comment": "Can we add a dynamic component to this dataset, like some UUID or something? It will help reduce resource contention.",
                "position": null
            },
            {
                "comment": "That is a reasonable request ... unfortunately, the developer doesn't control the actual dataset ID. It is automatically assigned by the service. I will rename this variable to reflect that behavior.",
                "position": null
            }
        ],
        "commit_message": "Per reviewer",
        "commit_id": "4088b71e8143d2cd8cb6a6cedcc422ffb63d4e85"
    },
    {
        "pr_title": "feat(aiplatform): adds create dataset sample for Vertex",
        "pr_number": 3266,
        "file_name": "aiplatform/snippets/create_dataset_test.go",
        "code_diff": "@@ -71,7 +69,7 @@\nfunc TestCreateDataset(t *testing.T) {\n }\n \n func deleteDataset() {\n-\t// parse dataset name\n+\t// parse dataset name--we cannot predict the dataset ID at creation time.\n \ttmp := strings.Split(output, \"\\n\")\n \tif len(tmp) < 1 {\n \t\tlog.Println(\"couldn't parse dataset resource name\")",
        "comments": [
            {
                "comment": "Can we add a dynamic component to this dataset, like some UUID or something? It will help reduce resource contention.",
                "position": null
            },
            {
                "comment": "That is a reasonable request ... unfortunately, the developer doesn't control the actual dataset ID. It is automatically assigned by the service. I will rename this variable to reflect that behavior.",
                "position": null
            }
        ],
        "commit_message": "Per reviewer",
        "commit_id": "4088b71e8143d2cd8cb6a6cedcc422ffb63d4e85"
    },
    {
        "pr_title": "feat(language): update code example for Cloud NL v2",
        "pr_number": 3256,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -52,7 +52,7 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n-\ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)\n+\ts, err := setupPubSub(ctx, pubsubClient, projectID, pubSubTopic, pubSubSub)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"setupPubSub: %w\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into nl-v2",
        "commit_id": "b24f64231323070cb0f4ab31de01db608ceef603"
    },
    {
        "pr_title": "feat(language): update code example for Cloud NL v2",
        "pr_number": 3256,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -112,14 +112,14 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \t\treturn fmt.Errorf(\"CreateDlpJob: %w\", err)\n \t}\n \tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())\n-\n \t// Wait for the risk job to finish by waiting for a PubSub message.\n \t// This only waits for 10 minutes. For long jobs, consider using a truly\n \t// asynchronous execution model such as Cloud Functions.\n \tctx, cancel := context.WithTimeout(ctx, 10*time.Minute)\n \tdefer cancel()\n \terr = s.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\t// If this is the wrong job, do not process the result.\n+\n \t\tif msg.Attributes[\"DlpJobName\"] != j.GetName() {\n \t\t\tmsg.Nack()\n \t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'main' into nl-v2",
        "commit_id": "b24f64231323070cb0f4ab31de01db608ceef603"
    },
    {
        "pr_title": "feat(language): update code example for Cloud NL v2",
        "pr_number": 3256,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -42,6 +42,7 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \tif err != nil {\n \t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n+\tdefer client.Close()\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)",
        "comments": [],
        "commit_message": "Merge branch 'main' into nl-v2",
        "commit_id": "b24f64231323070cb0f4ab31de01db608ceef603"
    },
    {
        "pr_title": "feat(language): update code example for Cloud NL v2",
        "pr_number": 3256,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -51,7 +52,7 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n-\ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)\n+\ts, err := setupPubSub(ctx, pubsubClient, projectID, pubSubTopic, pubSubSub)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"setupPubSub: %w\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into nl-v2",
        "commit_id": "b24f64231323070cb0f4ab31de01db608ceef603"
    },
    {
        "pr_title": "feat(iam): sample for receiving Cloud Audit Logs from Service Accout Key creation",
        "pr_number": 3255,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -22,14 +22,33 @@\nimport (\n \t\"encoding/base64\"\n \t\"fmt\"\n \t\"log\"\n+\t\"os\"\n \t\"strings\"\n+\t\"time\"\n \n \t\"testing\"\n \n+\t\"cloud.google.com/go/bigquery\"\n+\tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \tkms \"cloud.google.com/go/kms/apiv1\"\n \t\"cloud.google.com/go/kms/apiv1/kmspb\"\n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n+\t\"google.golang.org/api/iterator\"\n+)\n+\n+const (\n+\tbucketForDeidCloudStorageForInput  = \"dlp-test-deid-input\"\n+\tbucketForDeidCloudStorageForOutput = \"dlp-test-deid-go-lang-output\"\n+\tfilePathToGCSForDeidTest           = \"./testdata/dlp_sample.csv\"\n+\ttableID                            = \"dlp_test_deid_table\"\n+\tdataSetID                          = \"dlp_test_deid_dataset\"\n+\n+\tdeidentifyTemplateID           = \"deidentified-templat-test-go\"\n+\tdeidentifyStructuredTemplateID = \"deidentified-structured-template-go\"\n+\tredactImageTemplate            = \"redact-image-template-go\"\n )\n \n func TestMask(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into audit-iam-sample",
        "commit_id": "ddb87da2e3a3eb5bf537eff87c4622a4a025eb79"
    },
    {
        "pr_title": "feat(iam): sample for receiving Cloud Audit Logs from Service Accout Key creation",
        "pr_number": 3255,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -16,56 +16,111 @@\npackage livestream\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"fmt\"\n+\t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\tlivestream \"cloud.google.com/go/video/livestream/apiv1\"\n+\t\"cloud.google.com/go/video/livestream/apiv1/livestreampb\"\n+\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n const (\n \tdeleteChannelEventResponse = \"Deleted channel event\"\n \tdeleteChannelResponse      = \"Deleted channel\"\n \tdeleteInputResponse        = \"Deleted input\"\n+\tdeleteAssetResponse        = \"Deleted asset\"\n \tstartChannelResponse       = \"Started channel\"\n \tstopChannelResponse        = \"Stopped channel\"\n \tlocation                   = \"us-central1\"\n \tinputID                    = \"my-go-test-input\"\n \tbackupInputID              = \"my-go-test-backup-input\"\n \tchannelID                  = \"my-go-test-channel\"\n \teventID                    = \"my-go-test-channel-event\"\n+\tassetID                    = \"my-go-test-asset\"\n+\tpoolID                     = \"default\" // only 1 pool supported per location\n )\n \n+var bucketName string\n+var outputURI string\n+var assetURI string\n+\n // To run the tests, do the following:\n // Export the following env vars:\n // *   GOOGLE_APPLICATION_CREDENTIALS\n // *   GOLANG_SAMPLES_PROJECT_ID\n // Enable the following API on the test project:\n // *   Live Stream API\n \n-// TestLiveStream tests major operations on inputs, channels, and channel\n-// events.\n-func TestLiveStream(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+// TestMain tests major operations on inputs, channels, channel\n+// events, assets, and pools.\n+func TestMain(m *testing.M) {\n+\ttc, _ := testutil.ContextMain(m)\n+\tbucketName = tc.ProjectID + \"-golang-samples-livestream-test\"\n+\toutputURI = \"gs://\" + bucketName + \"/test-output-channel/\"\n+\tassetURI = \"gs://cloud-samples-data/media/ForBiggerEscapes.mp4\"\n+\tm.Run()\n+\tcleanStaleAssets(tc)\n+}\n \n-\tbucketName := tc.ProjectID + \"-golang-samples-livestream-test\"\n-\toutputURI := \"gs://\" + bucketName + \"/test-output-channel/\"\n+func cleanStaleAssets(tc testutil.Context) {\n+\tctx := context.Background()\n+\tvar threeHoursInSec int64 = 60 * 60 * 3\n+\ttimeNowSec := time.Now().Unix()\n \n-\ttestInputs(t)\n-\tt.Logf(\"\\ntestInputs() completed\\n\")\n+\tclient, err := livestream.NewClient(ctx)\n+\tif err != nil {\n+\t\tfmt.Printf(\"NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n \n-\ttestChannels(t, outputURI)\n-\tt.Logf(\"\\ntestChannels() completed\\n\")\n+\treq := &livestreampb.ListAssetsRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", tc.ProjectID, location),\n+\t}\n \n-\ttestChannelEvents(t, outputURI)\n-\tt.Logf(\"\\ntestChannelEvents() completed\\n\")\n+\tit := client.ListAssets(ctx, req)\n+\tfor {\n+\t\tresponse, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tfmt.Printf(\"ListAssets: %v\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\treq := &livestreampb.GetAssetRequest{\n+\t\t\tName: response.Name,\n+\t\t}\n+\t\tasset, err := client.GetAsset(ctx, req)\n+\t\tif err != nil {\n+\t\t\tfmt.Printf(\"GetAsset: %v\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\tif asset.GetCreateTime().GetSeconds() < timeNowSec-threeHoursInSec {\n+\t\t\tfmt.Printf(\"%v - delete asset\", asset.GetCreateTime().GetSeconds())\n+\t\t\treq := &livestreampb.DeleteAssetRequest{\n+\t\t\t\tName: asset.GetName(),\n+\t\t\t}\n+\t\t\t// No need to wait for delete ops to finish, as this is a background\n+\t\t\t// cleanup.\n+\t\t\t_, err := client.DeleteAsset(ctx, req)\n+\t\t\tif err != nil {\n+\t\t\t\tfmt.Printf(\"DeleteAsset: %v\", err)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t}\n+\t}\n }\n \n-// testInputs tests major operations on inputs. Create, list, update,\n+// TestInputs tests major operations on inputs. Create, list, update,\n // and get operations check if the input resource name is returned. The\n // delete operation checks for a hard-coded string response.\n-func testInputs(t *testing.T) {\n+func TestInputs(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_message": "Merge branch 'main' into audit-iam-sample",
        "commit_id": "ddb87da2e3a3eb5bf537eff87c4622a4a025eb79"
    },
    {
        "pr_title": "feat(iam): sample for receiving Cloud Audit Logs from Service Accout Key creation",
        "pr_number": 3255,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -169,12 +224,13 @@\nfunc testInputs(t *testing.T) {\n \t\t\tr.Errorf(\"deleteInput got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteInputResponse)\n \t\t}\n \t})\n+\tt.Logf(\"\\nTestInputs() completed\\n\")\n }\n \n-// testChannels tests major operations on channels. Create, list, update,\n+// TestChannels tests major operations on channels. Create, list, update,\n // and get operations check if the channel resource name is returned. The\n // delete operation checks for a hard-coded string response.\n-func testChannels(t *testing.T, outputURI string) {\n+func TestChannels(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_message": "Merge branch 'main' into audit-iam-sample",
        "commit_id": "ddb87da2e3a3eb5bf537eff87c4622a4a025eb79"
    },
    {
        "pr_title": "feat(iam): sample for receiving Cloud Audit Logs from Service Accout Key creation",
        "pr_number": 3255,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -343,12 +399,13 @@\nfunc testChannels(t *testing.T, outputURI string) {\n \t\t\tr.Errorf(\"deleteInput got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteInputResponse)\n \t\t}\n \t})\n+\tt.Logf(\"\\nTestChannels() completed\\n\")\n }\n \n-// testChannelEvents tests event operations on channels. Create, list, and get\n+// TestChannelEvents tests event operations on channels. Create, list, and get\n // operations check if the channel event resource name is returned. The delete\n // operation checks for a hard-coded string response.\n-func testChannelEvents(t *testing.T, outputURI string) {\n+func TestChannelEvents(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_message": "Merge branch 'main' into audit-iam-sample",
        "commit_id": "ddb87da2e3a3eb5bf537eff87c4622a4a025eb79"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "aiplatform/snippets/create_dataset_test.go",
        "code_diff": "@@ -30,27 +30,6 @@\nimport (\n \t\"google.golang.org/api/option\"\n )\n \n-var (\n-\toutput    string\n-\tprojectID string\n-\tregion    string = \"us-central1\"\n-)\n-\n-func TestMain(m *testing.M) {\n-\ttc, ok := testutil.ContextMain(m)\n-\n-\tprojectID = tc.ProjectID\n-\n-\tif !ok {\n-\t\tlog.Fatal(\"couldn't initialize test\")\n-\t\treturn\n-\t}\n-\n-\tm.Run()\n-\n-\tdeleteDataset()\n-}\n-\n func TestCreateDataset(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -40,12 +40,9 @@\nimport (\n )\n \n const (\n-\tbucketForDeidCloudStorageForInput  = \"dlp-test-deid-input\"\n-\tbucketForDeidCloudStorageForOutput = \"dlp-test-deid-go-lang-output\"\n-\tfilePathToGCSForDeidTest           = \"./testdata/dlp_sample.csv\"\n-\ttableID                            = \"dlp_test_deid_table\"\n-\tdataSetID                          = \"dlp_test_deid_dataset\"\n-\n+\tfilePathToGCSForDeidTest       = \"./testdata/dlp_sample.csv\"\n+\ttableID                        = \"dlp_test_deid_table\"\n+\tdataSetID                      = \"dlp_test_deid_dataset\"\n \tdeidentifyTemplateID           = \"deidentified-templat-test-go\"\n \tdeidentifyStructuredTemplateID = \"deidentified-structured-template-go\"\n \tredactImageTemplate            = \"redact-image-template-go\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -710,7 +707,7 @@\nfunc TestDeidentifyDataReplaceWithDictionary(t *testing.T) {\n func TestDeidentifyCloudStorage(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n-\t// \"gs://dlp-crest-test/dlp_sample.csv\"\n+\n \tgcsURI := fmt.Sprint(\"gs://\" + bucketForDeidCloudStorageForInput + \"/\" + filePathToGCSForDeidTest)\n \toutputBucket := fmt.Sprint(\"gs://\" + bucketForDeidCloudStorageForOutput)",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -26,9 +26,12 @@\nimport (\n \n \t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/datastore\"\n+\tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n const (",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -38,6 +41,9 @@\nconst (\n \tssnFileName = \"fake_ssn.txt\"\n \tbucketName  = \"golang-samples-dlp-test2\"\n \n+\tjobTriggerIdPrefix                      = \"dlp-job-trigger-unit-test-case-12345678\"\n+\tdataSetIDForHybridJob                   = \"dlp_test_dataset\"\n+\ttableIDForHybridJob                     = \"dlp_inspect_test_table_table_id\"\n \tinspectsGCSTestFileName                 = \"test.txt\"\n \tfilePathToUpload                        = \"./testdata/test.txt\"\n \tdirPathForInspectGCSSendToScc           = \"dlp-go-lang-test-for-inspect-gcs-send-to-scc/\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -617,7 +623,7 @@\nfunc TestInspectAugmentInfoTypes(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \tgot := buf.String()\n-\tif want := \"Qoute: Quasimodo\"; !strings.Contains(got, want) {\n+\tif want := \"Quote: Quasimodo\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"TestInspectAugmentInfoTypes got %q, want %q\", got, want)\n \t}\n \tif want := \"Info type: PERSON_NAME\"; !strings.Contains(got, want) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -645,11 +651,162 @@\nfunc TestInspectTableWithCustomHotword(t *testing.T) {\n \t}\n }\n \n+func createBigQueryDataSetId(projectID string) error {\n+\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tmeta := &bigquery.DatasetMetadata{\n+\t\tLocation: \"US\", // See https://cloud.google.com/bigquery/docs/locations\n+\t}\n+\n+\tif err := client.Dataset(dataSetID).Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n+func createTableInsideDataset(projectID, dataSetID string) error {\n+\tctx := context.Background()\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"user_id\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType},\n+\t\t{Name: \"title\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"score\", Type: bigquery.StringFieldType},\n+\t}\n+\n+\tmetaData := &bigquery.TableMetadata{\n+\t\tSchema:         sampleSchema,\n+\t\tExpirationTime: time.Now().AddDate(1, 0, 0), // Table will be automatically deleted in 1 year.\n+\t}\n+\n+\ttableRef := client.Dataset(dataSetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, metaData); err != nil {\n+\t\tlog.Printf(\"[INFO] createBigQueryDataSetId Error while table creation: %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tduration := time.Duration(90) * time.Second\n+\ttime.Sleep(duration)\n+\n+\tinserter := client.Dataset(dataSetID).Table(tableID).Inserter()\n+\titems := []*BigQueryTableItem{\n+\t\t// Item implements the ValueSaver interface.\n+\t\t{UserId: \"602-61-8588\", Age: 32, Title: \"Biostatistician III\", Score: \"A\"},\n+\t\t{UserId: \"618-96-2322\", Age: 69, Title: \"Programmer I\", Score: \"C\"},\n+\t\t{UserId: \"618-96-2322\", Age: 69, Title: \"Executive Secretary\", Score: \"C\"},\n+\t}\n+\tif err := inserter.Put(ctx, items); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n+type BigQueryTableItem struct {\n+\tUserId string\n+\tAge    int\n+\tTitle  string\n+\tScore  string\n+}\n+\n+func (i *BigQueryTableItem) Save() (map[string]bigquery.Value, string, error) {\n+\treturn map[string]bigquery.Value{\n+\t\t\"user_id\": i.UserId,\n+\t\t\"age\":     i.Age,\n+\t\t\"title\":   i.Title,\n+\t\t\"score\":   i.Score,\n+\t}, bigquery.NoDedupeID, nil\n+}\n+\n+func deleteBigQueryAssets(projectID string) error {\n+\n+\tlog.Printf(\"[START] deleteBigQueryAssets: projectID %v and \", projectID)\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tlog.Printf(\"[INFO] deleteBigQueryAssets: delete dataset err %v\", err)\n+\n+\tif err := client.Dataset(\"dlp_test_dataset\").DeleteWithContents(ctx); err != nil {\n+\t\tlog.Printf(\"[INFO] deleteBigQueryAssets: delete dataset err %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tduration := time.Duration(30) * time.Second\n+\ttime.Sleep(duration)\n+\n+\tlog.Printf(\"[END] deleteBigQueryAssets:\")\n+\treturn nil\n+}\n+\n+func deleteJob(projectID, jobName string) error {\n+\tctx := context.Background()\n+\n+\tlog.Printf(\"[START] deleteJob: projectID %v\", projectID)\n+\t// delete job\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\treturn err\n+\t}\n+\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\n+\treq := &dlppb.DeleteDlpJobRequest{\n+\t\tName: jobName,\n+\t}\n+\tfor {\n+\t\tct, cancel := context.WithTimeout(ctx, 300000)\n+\t\tdefer cancel()\n+\t\tabc, err := client.GetDlpJob(ct, &dlppb.GetDlpJobRequest{\n+\t\t\tName: jobName,\n+\t\t})\n+\t\tif err != nil {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\t\treturn err\n+\t\t}\n+\t\tif abc.State == dlppb.DlpJob_DONE {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job done\")\n+\t\t\tbreak\n+\t\t} else if abc.State == dlppb.DlpJob_FAILED {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job failed\")\n+\t\t\treturn err\n+\t\t} else {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job continue\")\n+\t\t\tcontinue\n+\t\t}\n+\t}\n+\terr = client.DeleteDlpJob(ctx, req)\n+\tif err != nil {\n+\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tlog.Printf(\"[END] deleteJob\")\n+\treturn nil\n+}\n+\n func TestInspectDataStoreSendToScc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n \tu := uuid.New().String()[:8]\n-\tdatastoreNamespace := \"golang-samples\" + u\n+\tdatastoreNamespace := fmt.Sprint(\"golang-samples\" + u)\n \tdatastoreKind := \"task\"\n \n \tif err := inspectDataStoreSendToScc(&buf, tc.ProjectID, datastoreNamespace, datastoreKind); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -662,6 +819,68 @@\nfunc TestInspectDataStoreSendToScc(t *testing.T) {\n \t}\n }\n \n+var (\n+\tprojectID                  string\n+\tjobTriggerForInspectSample string\n+\tbucketExpiryAge            = time.Minute * 2\n+\ttestPrefix                 = \"dlp-test-inspect-prefix\"\n+)\n+\n+func createStoredInfoTypeForTesting(t *testing.T, projectID, outputPath string) (string, error) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\tdefer client.Close()\n+\tu := uuid.New().String()[:8]\n+\tdisplayName := \"stored-info-type-for-inspect-test\" + u\n+\tdescription := \"Dictionary of GitHub usernames used in commits\"\n+\n+\tcloudStoragePath := &dlppb.CloudStoragePath{\n+\t\tPath: outputPath,\n+\t}\n+\n+\tbigQueryField := &dlppb.BigQueryField{\n+\t\tTable: &dlppb.BigQueryTable{\n+\t\t\tProjectId: \"bigquery-public-data\",\n+\t\t\tDatasetId: \"samples\",\n+\t\t\tTableId:   \"github_nested\",\n+\t\t},\n+\t\tField: &dlppb.FieldId{\n+\t\t\tName: \"actor\",\n+\t\t},\n+\t}\n+\n+\tlargeCustomDictionaryConfig := &dlppb.LargeCustomDictionaryConfig{\n+\t\tOutputPath: cloudStoragePath,\n+\t\tSource: &dlppb.LargeCustomDictionaryConfig_BigQueryField{\n+\t\t\tBigQueryField: bigQueryField,\n+\t\t},\n+\t}\n+\n+\tstoredInfoTypeConfig := &dlppb.StoredInfoTypeConfig{\n+\t\tDisplayName: displayName,\n+\t\tDescription: description,\n+\t\tType: &dlppb.StoredInfoTypeConfig_LargeCustomDictionary{\n+\t\t\tLargeCustomDictionary: largeCustomDictionaryConfig,\n+\t\t},\n+\t}\n+\n+\treq := &dlppb.CreateStoredInfoTypeRequest{\n+\t\tParent:           fmt.Sprintf(\"projects/%s/locations/global\", projectID),\n+\t\tConfig:           storedInfoTypeConfig,\n+\t\tStoredInfoTypeId: \"go-sample-test-stored-infoType\" + u,\n+\t}\n+\tresp, err := client.CreateStoredInfoType(ctx, req)\n+\tif err != nil {\n+\t\treturn \"nil\", err\n+\t}\n+\n+\treturn resp.Name, nil\n+}\n+\n func TestInspectGCSFileSendToScc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -18,13 +18,16 @@\npackage risk\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n+\t\"log\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"github.com/gofrs/uuid\"\n+\t\"github.com/google/uuid\"\n )\n \n const (",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -46,7 +49,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Numerical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -62,7 +65,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Categorical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -78,7 +81,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Anonymity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -94,7 +97,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"L Diversity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -110,7 +113,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Map\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/helloworld.e2e_test.go",
        "code_diff": "@@ -15,12 +15,10 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/image_processing.e2e_test.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"log\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into klogs",
        "commit_id": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp k anonymity with entity id ",
        "pr_number": 3245,
        "file_name": "run/testing/hello_broken.e2e_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_k_anonymity_with_entity_id",
        "commit_id": "8556f616fd1a213dce702e3a050b652767c0e1bf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp k anonymity with entity id ",
        "pr_number": 3245,
        "file_name": "run/testing/helloworld.e2e_test.go",
        "code_diff": "@@ -15,11 +15,9 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"io/ioutil\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_k_anonymity_with_entity_id",
        "commit_id": "8556f616fd1a213dce702e3a050b652767c0e1bf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp k anonymity with entity id ",
        "pr_number": 3245,
        "file_name": "run/testing/image_processing.e2e_test.go",
        "code_diff": "@@ -15,10 +15,8 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_k_anonymity_with_entity_id",
        "commit_id": "8556f616fd1a213dce702e3a050b652767c0e1bf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect with stored infotype",
        "pr_number": 3242,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -40,13 +40,10 @@\nimport (\n )\n \n const (\n-\tbucketForDeidCloudStorageForInput  = \"dlp-test-deid-input\"\n-\tbucketForDeidCloudStorageForOutput = \"dlp-test-deid-go-lang-output\"\n-\tfilePathToGCSUploadForDeidTest     = \"./testdata/dlp_sample.csv\"\n-\tfilePathToGCSForDeidTest           = \"/testdata/dlp_sample.csv\"\n-\ttableID                            = \"dlp_test_deid_table\"\n-\tdataSetID                          = \"dlp_test_deid_dataset\"\n-\n+\tfilePathToGCSUploadForDeidTest = \"./testdata/dlp_sample.csv\"\n+\tfilePathToGCSForDeidTest       = \"/testdata/dlp_sample.csv\"\n+\ttableID                        = \"dlp_test_deid_table\"\n+\tdataSetID                      = \"dlp_test_deid_dataset\"\n \tdeidentifyTemplateID           = \"deidentified-templat-test-go\"\n \tdeidentifyStructuredTemplateID = \"deidentified-structured-template-go\"\n \tredactImageTemplate            = \"redact-image-template-go\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_with_stored_infotype",
        "commit_id": "bbeab494c2adc27a32b04e7ece0e7609908dec83"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect with stored infotype",
        "pr_number": 3242,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -711,7 +708,7 @@\nfunc TestDeidentifyDataReplaceWithDictionary(t *testing.T) {\n func TestDeidentifyCloudStorage(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n-\t// \"gs://dlp-crest-test/dlp_sample.csv\"\n+\n \tgcsURI := fmt.Sprint(\"gs://\" + bucketForDeidCloudStorageForInput + \"/\" + filePathToGCSForDeidTest)\n \toutputBucket := fmt.Sprint(\"gs://\" + bucketForDeidCloudStorageForOutput)",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_with_stored_infotype",
        "commit_id": "bbeab494c2adc27a32b04e7ece0e7609908dec83"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect with stored infotype",
        "pr_number": 3242,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -18,14 +18,16 @@\npackage risk\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n \t\"log\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"github.com/gofrs/uuid\"\n+\t\"github.com/google/uuid\"\n )\n \n const (",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_with_stored_infotype",
        "commit_id": "bbeab494c2adc27a32b04e7ece0e7609908dec83"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect with stored infotype",
        "pr_number": 3242,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -47,7 +49,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Numerical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_with_stored_infotype",
        "commit_id": "bbeab494c2adc27a32b04e7ece0e7609908dec83"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect with stored infotype",
        "pr_number": 3242,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -64,7 +66,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Categorical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_with_stored_infotype",
        "commit_id": "bbeab494c2adc27a32b04e7ece0e7609908dec83"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect with stored infotype",
        "pr_number": 3242,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -80,7 +82,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Anonymity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_with_stored_infotype",
        "commit_id": "bbeab494c2adc27a32b04e7ece0e7609908dec83"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect with stored infotype",
        "pr_number": 3242,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -96,7 +98,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"L Diversity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_with_stored_infotype",
        "commit_id": "bbeab494c2adc27a32b04e7ece0e7609908dec83"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect with stored infotype",
        "pr_number": 3242,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -112,7 +114,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Map\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_with_stored_infotype",
        "commit_id": "bbeab494c2adc27a32b04e7ece0e7609908dec83"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect bigquery send to scc",
        "pr_number": 3241,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -623,7 +623,7 @@\nfunc TestInspectAugmentInfoTypes(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \tgot := buf.String()\n-\tif want := \"Qoute: Quasimodo\"; !strings.Contains(got, want) {\n+\tif want := \"Quote: Quasimodo\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"TestInspectAugmentInfoTypes got %q, want %q\", got, want)\n \t}\n \tif want := \"Info type: PERSON_NAME\"; !strings.Contains(got, want) {",
        "comments": [
            {
                "comment": "Is this for a different sample? ",
                "position": null
            },
            {
                "comment": "Yes, it's for a different sample but I think due to some unwanted commits or branch conflicts I have to add this one to this PR, Sorry for the confusion.",
                "position": null
            },
            {
                "comment": "question: should we put a timeout on this `Context` object? Or do we know that the `GetDlpJob()` method has a _very_ high reliability?",
                "position": null
            },
            {
                "comment": "Added a new context with timeout.",
                "position": null
            },
            {
                "comment": "issue: one test per file, please.\r\n\r\nSee https://googlecloudplatform.github.io/samples-style-guide/#dedicated-testing-per-sample",
                "position": null
            },
            {
                "comment": "Waiting for your reply on https://github.com/GoogleCloudPlatform/golang-samples/pull/3242#discussion_r1313028235",
                "position": null
            },
            {
                "comment": "Hey @telpirion Hi, I have split the test for this particular sample into a separate file. ",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'main' into dlp_inspect_bigquery_send_to_scc",
        "commit_id": "911fe3db1f69f0c6a56f7601ae9585de6eb26b31"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect bigquery send to scc",
        "pr_number": 3241,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -819,6 +819,68 @@\nfunc TestInspectDataStoreSendToScc(t *testing.T) {\n \t}\n }\n \n+var (\n+\tprojectID                  string\n+\tjobTriggerForInspectSample string\n+\tbucketExpiryAge            = time.Minute * 2\n+\ttestPrefix                 = \"dlp-test-inspect-prefix\"\n+)\n+\n+func createStoredInfoTypeForTesting(t *testing.T, projectID, outputPath string) (string, error) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\tdefer client.Close()\n+\tu := uuid.New().String()[:8]\n+\tdisplayName := \"stored-info-type-for-inspect-test\" + u\n+\tdescription := \"Dictionary of GitHub usernames used in commits\"\n+\n+\tcloudStoragePath := &dlppb.CloudStoragePath{\n+\t\tPath: outputPath,\n+\t}\n+\n+\tbigQueryField := &dlppb.BigQueryField{\n+\t\tTable: &dlppb.BigQueryTable{\n+\t\t\tProjectId: \"bigquery-public-data\",\n+\t\t\tDatasetId: \"samples\",\n+\t\t\tTableId:   \"github_nested\",\n+\t\t},\n+\t\tField: &dlppb.FieldId{\n+\t\t\tName: \"actor\",\n+\t\t},\n+\t}\n+\n+\tlargeCustomDictionaryConfig := &dlppb.LargeCustomDictionaryConfig{\n+\t\tOutputPath: cloudStoragePath,\n+\t\tSource: &dlppb.LargeCustomDictionaryConfig_BigQueryField{\n+\t\t\tBigQueryField: bigQueryField,\n+\t\t},\n+\t}\n+\n+\tstoredInfoTypeConfig := &dlppb.StoredInfoTypeConfig{\n+\t\tDisplayName: displayName,\n+\t\tDescription: description,\n+\t\tType: &dlppb.StoredInfoTypeConfig_LargeCustomDictionary{\n+\t\t\tLargeCustomDictionary: largeCustomDictionaryConfig,\n+\t\t},\n+\t}\n+\n+\treq := &dlppb.CreateStoredInfoTypeRequest{\n+\t\tParent:           fmt.Sprintf(\"projects/%s/locations/global\", projectID),\n+\t\tConfig:           storedInfoTypeConfig,\n+\t\tStoredInfoTypeId: \"go-sample-test-stored-infoType\" + u,\n+\t}\n+\tresp, err := client.CreateStoredInfoType(ctx, req)\n+\tif err != nil {\n+\t\treturn \"nil\", err\n+\t}\n+\n+\treturn resp.Name, nil\n+}\n+\n func TestInspectGCSFileSendToScc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [
            {
                "comment": "Is this for a different sample? ",
                "position": null
            },
            {
                "comment": "Yes, it's for a different sample but I think due to some unwanted commits or branch conflicts I have to add this one to this PR, Sorry for the confusion.",
                "position": null
            },
            {
                "comment": "question: should we put a timeout on this `Context` object? Or do we know that the `GetDlpJob()` method has a _very_ high reliability?",
                "position": null
            },
            {
                "comment": "Added a new context with timeout.",
                "position": null
            },
            {
                "comment": "issue: one test per file, please.\r\n\r\nSee https://googlecloudplatform.github.io/samples-style-guide/#dedicated-testing-per-sample",
                "position": null
            },
            {
                "comment": "Waiting for your reply on https://github.com/GoogleCloudPlatform/golang-samples/pull/3242#discussion_r1313028235",
                "position": null
            },
            {
                "comment": "Hey @telpirion Hi, I have split the test for this particular sample into a separate file. ",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'main' into dlp_inspect_bigquery_send_to_scc",
        "commit_id": "911fe3db1f69f0c6a56f7601ae9585de6eb26b31"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect bigquery send to scc",
        "pr_number": 3241,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -949,7 +1011,24 @@\nfunc filePathtoGCS(t *testing.T, projectID, bucketNameForInspectGCSSendToScc, di\n \treturn nil\n }\n \n-var projectID, jobTriggerForInspectSample string\n+func deleteStoredInfoTypeAfterTest(t *testing.T, name string) error {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\treq := &dlppb.DeleteStoredInfoTypeRequest{\n+\t\tName: name,\n+\t}\n+\terr = client.DeleteStoredInfoType(ctx, req)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\treturn nil\n+}\n \n func TestMain(m *testing.M) {\n \ttc, ok := testutil.ContextMain(m)",
        "comments": [
            {
                "comment": "Is this for a different sample? ",
                "position": null
            },
            {
                "comment": "Yes, it's for a different sample but I think due to some unwanted commits or branch conflicts I have to add this one to this PR, Sorry for the confusion.",
                "position": null
            },
            {
                "comment": "question: should we put a timeout on this `Context` object? Or do we know that the `GetDlpJob()` method has a _very_ high reliability?",
                "position": null
            },
            {
                "comment": "Added a new context with timeout.",
                "position": null
            },
            {
                "comment": "issue: one test per file, please.\r\n\r\nSee https://googlecloudplatform.github.io/samples-style-guide/#dedicated-testing-per-sample",
                "position": null
            },
            {
                "comment": "Waiting for your reply on https://github.com/GoogleCloudPlatform/golang-samples/pull/3242#discussion_r1313028235",
                "position": null
            },
            {
                "comment": "Hey @telpirion Hi, I have split the test for this particular sample into a separate file. ",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'main' into dlp_inspect_bigquery_send_to_scc",
        "commit_id": "911fe3db1f69f0c6a56f7601ae9585de6eb26b31"
    },
    {
        "pr_title": "docs(samples): Add assets and pools samples and tests",
        "pr_number": 3240,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -59,23 +59,23 @@\nvar assetURI string\n \n // TestMain tests major operations on inputs, channels, channel\n // events, assets, and pools.\n-func TestMain(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+func TestMain(m *testing.M) {\n+\ttc, _ := testutil.ContextMain(m)\n \tbucketName = tc.ProjectID + \"-golang-samples-livestream-test\"\n \toutputURI = \"gs://\" + bucketName + \"/test-output-channel/\"\n \tassetURI = \"gs://cloud-samples-data/media/ForBiggerEscapes.mp4\"\n-\tcleanStaleAssets(t)\n+\tm.Run()\n+\tcleanStaleAssets(tc)\n }\n \n-func cleanStaleAssets(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+func cleanStaleAssets(tc testutil.Context) {\n \tctx := context.Background()\n \tvar threeHoursInSec int64 = 60 * 60 * 3\n \ttimeNowSec := time.Now().Unix()\n \n \tclient, err := livestream.NewClient(ctx)\n \tif err != nil {\n-\t\tt.Logf(\"NewClient: %v\", err)\n+\t\tfmt.Printf(\"NewClient: %v\", err)\n \t}\n \tdefer client.Close()",
        "comments": [
            {
                "comment": "These tests should probably be in their own test function (e.g. `TestAssets`), if they do not depend on the previous tests in this method. same for `testPools()`.\r\n\r\nThis will make them run faster, and ensure that the Asset tests still run if there are problems with other livestream tests.",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "Remove Wait() call for background deletes, and move TestMain to run first",
        "commit_id": "5f09f43ac7be35eb13845ed9ad858e690f09980f"
    },
    {
        "pr_title": "chore: update images for cloud-profiler samples",
        "pr_number": 3235,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -347,6 +347,33 @@\nfunc TestDeIdentifyDeterministic(t *testing.T) {\n \n }\n \n+func TestReidentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tvar buf bytes.Buffer\n+\n+\tinputStr := \"My phone number is 1234567890\"\n+\tinfoType := \"PHONE_NUMBER\"\n+\tsurrogateType := \"PHONE_TOKEN\"\n+\tunwrappedKey := \"hu4O2y0RsY9qrVt1d2xAWEmqVqAc1P8Vk7D6peashag=\"\n+\n+\tif err := deidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputStr, infoType, surrogateType, unwrappedKey); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tinputForReid := \"My phone number is PHONE_TOKEN(10):4169075971\"\n+\n+\tbuf.Reset()\n+\tif err := reidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputForReid, surrogateType, unwrappedKey); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"output: My phone number is 1234567890\"; got != want {\n+\t\tt.Errorf(\"reidentifyFreeTextWithFPEUsingSurrogate got %q, want %q\", got, want)\n+\t}\n+\n+}\n+\n func TestDeIdentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into update-cloud-profiler-sample",
        "commit_id": "c3096779b312a418e7e49913e0582218b4cda022"
    },
    {
        "pr_title": "feat(spanner): add foreign key delete cascade samples",
        "pr_number": 3232,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -387,6 +387,17 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"Updated data to VenueDetails column\\n\")\n \tout = runSample(t, queryWithJsonParameter, dbName, \"failed to query with json parameter\")\n \tassertContains(t, out, \"The venue details for venue id 19\")\n+\n+\tout = runSample(t, createSequence, dbName, \"failed to create table with bit reverse sequence enabled\")\n+\tassertContains(t, out, \"Created Seq sequence and Customers table, where the key column CustomerId uses the sequence as a default value\\n\")\n+\tassertContains(t, out, \"Inserted customer record with CustomerId\")\n+\tassertContains(t, out, \"Number of customer records inserted is: 3\")\n+\tout = runSample(t, alterSequence, dbName, \"failed to alter table with bit reverse sequence enabled\")\n+\tassertContains(t, out, \"Altered Seq sequence to skip an inclusive range between 1000 and 5000000\\n\")\n+\tassertContains(t, out, \"Inserted customer record with CustomerId\")\n+\tassertContains(t, out, \"Number of customer records inserted is: 3\")\n+\tout = runSample(t, dropSequence, dbName, \"failed to drop bit reverse sequence column\")\n+\tassertContains(t, out, \"Altered Customers table to drop DEFAULT from CustomerId column and dropped the Seq sequence\\n\")\n }\n \n func TestBackupSample(t *testing.T) {",
        "comments": [
            {
                "comment": "issue: create a new test file or method for this sample.\r\n\r\nSee:\r\nhttps://googlecloudplatform.github.io/samples-style-guide/#dedicated-testing-per-sample",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'main' into foreign_key_delete_cascade",
        "commit_id": "323e7a2f4951ced725c3d195ce7a257c2afdba1c"
    },
    {
        "pr_title": "feat(pubsub): add payload unwrap sample",
        "pr_number": 3228,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -753,9 +753,20 @@\nfunc TestCreatePushSubscription(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tclient := setup(t)\n \tdefer client.Close()\n-\tsubID := subID + \"-push\"\n \n \tt.Run(\"default push subscription\", func(t *testing.T) {\n+\t\ttopicID := topicID + \"-default-push\"\n+\t\tsubID := subID + \"-default-push\"\n+\t\tt.Cleanup(func() {\n+\t\t\t// Don't check delete errors since if it doesn't exist\n+\t\t\t// that's fine.\n+\t\t\ttopic := client.Topic(topicID)\n+\t\t\ttopic.Delete(ctx)\n+\n+\t\t\tsub := client.Subscription(subID)\n+\t\t\tsub.Delete(ctx)\n+\t\t})\n+\n \t\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n \t\t\ttopic, err := getOrCreateTopic(ctx, client, topicID)\n \t\t\tif err != nil {",
        "comments": [
            {
                "comment": "unwrapping -> wrapper",
                "position": null
            }
        ],
        "commit_message": "move cleanup function",
        "commit_id": "0b9f81e7eab4715d091a37a3405f3cd1d0418e84"
    },
    {
        "pr_title": "feat(pubsub): add payload unwrap sample",
        "pr_number": 3228,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -773,21 +784,23 @@\nfunc TestCreatePushSubscription(t *testing.T) {\n \t\t\tif !strings.Contains(got, want) {\n \t\t\t\tr.Errorf(\"got %s, want %s\", got, want)\n \t\t\t}\n-\n-\t\t\tt.Cleanup(func() {\n-\t\t\t\tif err := topic.Delete(ctx); err != nil {\n-\t\t\t\t\tt.Errorf(\"topic.Delete: %v\", err)\n-\t\t\t\t}\n-\n-\t\t\t\tsub := client.Subscription(subID)\n-\t\t\t\tif err := sub.Delete(ctx); err != nil {\n-\t\t\t\t\tt.Errorf(\"sub.Delete: %v\", err)\n-\t\t\t\t}\n-\t\t\t})\n \t\t})\n \t})\n \n \tt.Run(\"no wrapper\", func(t *testing.T) {\n+\t\ttopicID := topicID + \"-no-wrapper\"\n+\t\tsubID := subID + \"-no-wrapper\"\n+\n+\t\tt.Cleanup(func() {\n+\t\t\t// Don't check delete errors since if it doesn't exist\n+\t\t\t// that's fine.\n+\t\t\ttopic := client.Topic(topicID)\n+\t\t\ttopic.Delete(ctx)\n+\n+\t\t\tsub := client.Subscription(subID)\n+\t\t\tsub.Delete(ctx)\n+\t\t})\n+\n \t\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n \t\t\ttopic, err := getOrCreateTopic(ctx, client, topicID)\n \t\t\tif err != nil {",
        "comments": [
            {
                "comment": "unwrapping -> wrapper",
                "position": null
            }
        ],
        "commit_message": "move cleanup function",
        "commit_id": "0b9f81e7eab4715d091a37a3405f3cd1d0418e84"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect datastore send to scc",
        "pr_number": 3221,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -347,6 +347,33 @@\nfunc TestDeIdentifyDeterministic(t *testing.T) {\n \n }\n \n+func TestReidentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tvar buf bytes.Buffer\n+\n+\tinputStr := \"My phone number is 1234567890\"\n+\tinfoType := \"PHONE_NUMBER\"\n+\tsurrogateType := \"PHONE_TOKEN\"\n+\tunwrappedKey := \"hu4O2y0RsY9qrVt1d2xAWEmqVqAc1P8Vk7D6peashag=\"\n+\n+\tif err := deidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputStr, infoType, surrogateType, unwrappedKey); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tinputForReid := \"My phone number is PHONE_TOKEN(10):4169075971\"\n+\n+\tbuf.Reset()\n+\tif err := reidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputForReid, surrogateType, unwrappedKey); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"output: My phone number is 1234567890\"; got != want {\n+\t\tt.Errorf(\"reidentifyFreeTextWithFPEUsingSurrogate got %q, want %q\", got, want)\n+\t}\n+\n+}\n+\n func TestDeIdentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_datastore_send_to_scc",
        "commit_id": "35ab9610258c899b9a0bbd3dda7c6e8cf4874044"
    },
    {
        "pr_title": "feat: Memorystore data plane snippet",
        "pr_number": 3210,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n+\t\"cloud.google.com/go/storage\"\n \t\"google.golang.org/api/iterator\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into memorystore",
        "commit_id": "1d6474ec6a4bcdea419cc3e33083fac1bf142c2a"
    },
    {
        "pr_title": "feat: Memorystore data plane snippet",
        "pr_number": 3210,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -779,6 +780,36 @@\nfunc TestCreateBigQuerySubscription(t *testing.T) {\n \t}\n }\n \n+func TestCreateCloudStorageSubscription(t *testing.T) {\n+\tt.Parallel()\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tdefer client.Close()\n+\tstorageSubID := subID + \"-cloud-storage\"\n+\n+\ttopic, err := getOrCreateTopic(ctx, client, topicID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"CreateTopic: %v\", err)\n+\t}\n+\tvar buf bytes.Buffer\n+\n+\t// Use the same bucket across test instances. This\n+\t// is safe since we're not writing to the bucket\n+\t// and this makes us not have to do bucket cleanups.\n+\tbucketID := fmt.Sprintf(\"%s-%s\", tc.ProjectID, \"pubsub-storage-sub-sink\")\n+\tif err := createOrGetStorageBucket(tc.ProjectID, bucketID); err != nil {\n+\t\tt.Fatalf(\"failed to get or create storage bucket: %v\", err)\n+\t}\n+\n+\tif err := createCloudStorageSubscription(&buf, tc.ProjectID, storageSubID, topic, bucketID); err != nil {\n+\t\tt.Fatalf(\"failed to create cloud storage subscription: %v\", err)\n+\t}\n+\n+\tsub := client.Subscription(storageSubID)\n+\tsub.Delete(ctx)\n+}\n+\n func TestCreateSubscriptionWithExactlyOnceDelivery(t *testing.T) {\n \tt.Parallel()\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into memorystore",
        "commit_id": "1d6474ec6a4bcdea419cc3e33083fac1bf142c2a"
    },
    {
        "pr_title": "fix(eventarc): update e2e tests to send proper payload",
        "pr_number": 3207,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -17,9 +17,9 @@\npackage deid\n // [START dlp_deidentify_fpe]\n import (\n \t\"context\"\n+\t\"encoding/base64\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into auditstoragesink",
        "commit_id": "861e2a1043380540bb5b3960a8b501886fa01ddf"
    },
    {
        "pr_title": "fix(eventarc): update e2e tests to send proper payload",
        "pr_number": 3207,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -31,12 +31,12 @@\nimport (\n // optional identifier needed for reidentification. surrogateInfoType can be any\n // value not found in your input.\n // Info types can be found with the infoTypes.list method or on https://cloud.google.com/dlp/docs/infotypes-reference\n-func deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n+func deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string, kmsKeyName, wrappedAESKey, surrogateInfoType string) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 123456789\"\n \t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n-\t// keyFileName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"\n-\t// cryptoKeyName := \"YOUR_ENCRYPTED_AES_256_KEY\"\n+\t// kmsKeyName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"\n+\t// wrappedAESKey := \"YOUR_ENCRYPTED_AES_256_KEY\"\n \t// surrogateInfoType := \"AGE\"\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'main' into auditstoragesink",
        "commit_id": "861e2a1043380540bb5b3960a8b501886fa01ddf"
    },
    {
        "pr_title": "fix(eventarc): update e2e tests to send proper payload",
        "pr_number": 3207,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -49,11 +49,13 @@\nfunc deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string,\n \tfor _, it := range infoTypeNames {\n \t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n-\t// Read the key file.\n-\tkeyBytes, err := ioutil.ReadFile(keyFileName)\n+\n+\t// Specify an encrypted AES-256 key and the name of the Cloud KMS key that encrypted it.\n+\tkmsWrappedCryptoKey, err := base64.StdEncoding.DecodeString(wrappedAESKey)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"ReadFile: %w\", err)\n+\t\treturn err\n \t}\n+\n \t// Create a configured request.\n \treq := &dlppb.DeidentifyContentRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/global\", projectID),",
        "comments": [],
        "commit_message": "Merge branch 'main' into auditstoragesink",
        "commit_id": "861e2a1043380540bb5b3960a8b501886fa01ddf"
    },
    {
        "pr_title": "fix(eventarc): update e2e tests to send proper payload",
        "pr_number": 3207,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -534,9 +534,13 @@\nfunc TestDeIdentifyTimeExtract(t *testing.T) {\n \t}\n }\n \n-func TestReidTableDataWithFPE(t *testing.T) {\n+func TestReidTextDataWithFPE(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n+\n+\tinput := \"My SSN is 123456789\"\n+\tinfoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\tsurrogateInfoType := \"AGE\"\n \n \tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into auditstoragesink",
        "commit_id": "861e2a1043380540bb5b3960a8b501886fa01ddf"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stseventdriven",
        "commit_id": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -31,6 +32,12 @@\nimport (\n \t\"github.com/google/uuid\"\n )\n \n+const (\n+\ttermListFileName = \"term_list.txt\"\n+\tfilePathToUpload = \"./testdata/term_list_storedInfotype.txt\"\n+\tbucket_prefix    = \"test\"\n+)\n+\n func TestInfoTypes(t *testing.T) {\n \ttestutil.SystemTest(t)\n \ttests := []struct {",
        "comments": [],
        "commit_message": "Merge branch 'main' into stseventdriven",
        "commit_id": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -70,22 +77,19 @@\nfunc TestInfoTypes(t *testing.T) {\n \t}\n }\n \n-func skipKOKORO(t *testing.T) {\n-\tif os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\") != \"\" {\n-\t\tt.Skip(\"Skipping testing in KOKORO environment\")\n-\t}\n-}\n-\n func TestCreateStoredInfoType(t *testing.T) {\n-\tskipKOKORO(t)\n-\n \ttc := testutil.SystemTest(t)\n-\n-\toutputPath, err := bucketForStoredInfoType(t, tc.ProjectID)\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n-\n+\tdefer client.Close()\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\toutputPath := fmt.Sprintf(\"gs://\" + bucketName + \"/\")\n \tvar buf bytes.Buffer\n \n \tif err := createStoredInfoType(&buf, tc.ProjectID, outputPath); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into stseventdriven",
        "commit_id": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -106,39 +110,87 @@\nfunc TestCreateStoredInfoType(t *testing.T) {\n \tdefer deleteStoredInfoTypeAfterTest(t, name)\n }\n \n-func bucketForStoredInfoType(t *testing.T, projectID string) (string, error) {\n+func deleteStoredInfoTypeAfterTest(t *testing.T, name string) error {\n \tt.Helper()\n \tctx := context.Background()\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\treq := &dlppb.DeleteStoredInfoTypeRequest{\n+\t\tName: name,\n+\t}\n+\terr = client.DeleteStoredInfoType(ctx, req)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\treturn nil\n+}\n+\n+func TestUpdateStoredInfoType(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tvar buf bytes.Buffer\n+\tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\treturn \"\", err\n+\t\tt.Fatal(err)\n \t}\n \tdefer client.Close()\n+\toutputBucket, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\toutputPath := fmt.Sprintf(\"gs://\" + outputBucket + \"/\")\n \n-\tu := uuid.New().String()[:8]\n-\tbucketName := \"dlp-go-lang-test-metadata\" + u\n-\tdirPath := \"my-directory/\"\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n \n-\t// Check if the bucket already exists.\n-\tbucketExists := false\n-\t_, err = client.Bucket(bucketName).Attrs(ctx)\n-\tif err == nil {\n-\t\tbucketExists = true\n+\tfileSetUrl, gcsUri, err := filesForUpdateStoredInfoType(t, tc.ProjectID, bucketName)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n \t}\n \n-\t// If the bucket doesn't exist, create it.\n-\tif !bucketExists {\n-\t\tif err := client.Bucket(bucketName).Create(ctx, projectID, &storage.BucketAttrs{\n-\t\t\tStorageClass: \"STANDARD\",\n-\t\t\tLocation:     \"us-central1\",\n-\t\t}); err != nil {\n-\t\t\tlog.Fatalf(\"Failed to create bucket: %v\", err)\n-\t\t}\n-\t\tfmt.Printf(\"Bucket '%s' created successfully.\\n\", bucketName)\n-\t} else {\n-\t\tfmt.Printf(\"Bucket '%s' already exists.\\n\", bucketName)\n+\tinfoTypeId, err := createStoredInfoTypeForTesting(t, tc.ProjectID, outputPath)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tinfoTypeId = strings.TrimPrefix(infoTypeId, fmt.Sprint(\"projects/\"+tc.ProjectID+\"/locations/global/storedInfoTypes/\"))\n+\n+\tduration := time.Duration(30) * time.Second\n+\ttime.Sleep(duration)\n+\n+\tif err := updateStoredInfoType(&buf, tc.ProjectID, gcsUri, fileSetUrl, infoTypeId); err != nil {\n+\t\tt.Fatal(err)\n \t}\n \n+\tgot := buf.String()\n+\n+\tif want := \"output: \"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"error from create stored infoType %q\", got)\n+\t}\n+\n+\tname := strings.TrimPrefix(got, \"output: \")\n+\n+\tdefer deleteStoredInfoTypeAfterTest(t, name)\n+}\n+\n+func filesForUpdateStoredInfoType(t *testing.T, projectID, bucketName string) (string, string, error) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn \"\", \"\", err\n+\t}\n+\tdefer client.Close()\n+\n+\tdirPath := \"update-stored-infoType-data/\"\n+\n \t// Check if the directory already exists in the bucket.\n \tdirExists := false\n \tquery := &storage.Query{Prefix: dirPath}",
        "comments": [],
        "commit_message": "Merge branch 'main' into stseventdriven",
        "commit_id": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "fix(kms): waiting for key import to finish",
        "pr_number": 3193,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -547,9 +547,8 @@\nfunc TestImportEndToEnd(t *testing.T) {\n \tcryptoKeyVersionName := fmt.Sprintf(\"%s/cryptoKeyVersions/1\", cryptoKeyName)\n \n \t// Wait for the key to finish importing.\n-\timportInProgress := true\n \timportInProgressStatus := kmspb.CryptoKeyVersion_CryptoKeyVersionState_name[int32(kmspb.CryptoKeyVersion_PENDING_IMPORT)]\n-\tfor importInProgress {\n+\tfor {\n \t\tb.Reset()\n \t\tif err := checkStateImportedKey(&b, cryptoKeyVersionName); err != nil {\n \t\t\tt.Fatal(err)",
        "comments": [
            {
                "comment": "You don't need both of the statements in this `if` block. I would remove the `importInProgress` variable altogether. Change the for loop so that it doesn't have a condition variable:\r\n\r\n```\r\nfor {\r\n    // ...\r\n    if !strings.Contains(got, importInProgressStatus) {\r\n        break\r\n    }\r\n}\r\n```",
                "position": null
            },
            {
                "comment": "Thanks for the suggestion. Updated.",
                "position": null
            }
        ],
        "commit_message": "fix(kms): implemented review suggestion",
        "commit_id": "08e23a26c3d8f18b75b1980f2b61a27c9fbbdc79"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -17,9 +17,9 @@\npackage deid\n // [START dlp_deidentify_fpe]\n import (\n \t\"context\"\n+\t\"encoding/base64\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -31,12 +31,12 @@\nimport (\n // optional identifier needed for reidentification. surrogateInfoType can be any\n // value not found in your input.\n // Info types can be found with the infoTypes.list method or on https://cloud.google.com/dlp/docs/infotypes-reference\n-func deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n+func deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string, kmsKeyName, wrappedAESKey, surrogateInfoType string) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 123456789\"\n \t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n-\t// keyFileName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"\n-\t// cryptoKeyName := \"YOUR_ENCRYPTED_AES_256_KEY\"\n+\t// kmsKeyName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"\n+\t// wrappedAESKey := \"YOUR_ENCRYPTED_AES_256_KEY\"\n \t// surrogateInfoType := \"AGE\"\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -49,11 +49,13 @@\nfunc deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string,\n \tfor _, it := range infoTypeNames {\n \t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n-\t// Read the key file.\n-\tkeyBytes, err := ioutil.ReadFile(keyFileName)\n+\n+\t// Specify an encrypted AES-256 key and the name of the Cloud KMS key that encrypted it.\n+\tkmsWrappedCryptoKey, err := base64.StdEncoding.DecodeString(wrappedAESKey)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"ReadFile: %w\", err)\n+\t\treturn err\n \t}\n+\n \t// Create a configured request.\n \treq := &dlppb.DeidentifyContentRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/global\", projectID),",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -534,9 +534,13 @@\nfunc TestDeIdentifyTimeExtract(t *testing.T) {\n \t}\n }\n \n-func TestReidTableDataWithFPE(t *testing.T) {\n+func TestReidTextDataWithFPE(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n+\n+\tinput := \"My SSN is 123456789\"\n+\tinfoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\tsurrogateInfoType := \"AGE\"\n \n \tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -17,10 +17,18 @@\npackage metadata\n \n import (\n \t\"bytes\"\n+\t\"context\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n \t\"strings\"\n \t\"testing\"\n \n+\tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n )\n \n func TestInfoTypes(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "eventarc/testing/audit_storage.e2e_test.go",
        "code_diff": "@@ -15,13 +15,16 @@\npackage cloudruntests\n \n import (\n+\t\"context\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\tcloudevent \"github.com/cloudevents/sdk-go/v2\"\n )\n \n func TestAuditStorageSinkService(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "eventarc/testing/audit_storage.e2e_test.go",
        "code_diff": "@@ -34,12 +37,26 @@\nfunc TestAuditStorageSinkService(t *testing.T) {\n \t}\n \tdefer service.Clean()\n \n-\trequestPath := \"/\"\n-\treq, err := service.NewRequest(\"POST\", requestPath)\n+\tevent := cloudevent.NewEvent(\"1.0\")\n+\tevent.SetID(\"1\")\n+\tevent.SetSource(\"test\")\n+\tevent.SetSubject(\"storage.googleapis.com/projects/_/buckets/my-bucket\")\n+\tevent.SetType(\"test\")\n+\n+\tservice_url, err := service.URL(\"/\")\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\treq, err := cloudevent.NewHTTPRequestFromEvent(context.Background(),\n+\t\tservice_url, event)\n \tif err != nil {\n-\t\tt.Fatalf(\"service.NewRequest: %v\", err)\n+\t\tt.Fatal(err)\n \t}\n \n+\t// add a valid auth header to the cloudevent request.\n+\tauthreq, _ := service.NewRequest(\"POST\", \"/\")\n+\treq.Header.Set(\"Authorization\", authreq.Header.Get(\"Authorization\"))\n+\n \tclient := http.Client{Timeout: 10 * time.Second}\n \tresp, err := client.Do(req)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "functions/security/security_system_test.go",
        "code_diff": "@@ -22,6 +22,9 @@\nimport (\n \t\"os/exec\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n+\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n const RuntimeVersion = \"go118\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "internal/aeintegrate/aeintegrate.go",
        "code_diff": "@@ -47,7 +47,6 @@\nimport (\n \t\"context\"\n \t\"errors\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "internal/aeintegrate/aeintegrate.go",
        "code_diff": "@@ -192,7 +191,7 @@\nfunc (p *App) envAppYaml() (string, error) {\n \t\treturn p.tempAppYaml, nil\n \t}\n \n-\tb, err := ioutil.ReadFile(filepath.Join(p.Dir, base))\n+\tb, err := os.ReadFile(filepath.Join(p.Dir, base))\n \tif err != nil {\n \t\treturn \"\", err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "internal/aeintegrate/aeintegrate.go",
        "code_diff": "@@ -232,7 +231,7 @@\nfunc (p *App) envAppYaml() (string, error) {\n \tif err != nil {\n \t\treturn \"\", err\n \t}\n-\tif err := ioutil.WriteFile(filepath.Join(p.Dir, tmp), b, 0755); err != nil {\n+\tif err := os.WriteFile(filepath.Join(p.Dir, tmp), b, 0755); err != nil {\n \t\treturn \"\", err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "internal/e2e/standard_test.go",
        "code_diff": "@@ -17,7 +17,7 @@\npackage e2e\n \n import (\n-\t\"io/ioutil\"\n+\t\"io\"\n \t\"log\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "internal/testutil/runmain.go",
        "code_diff": "@@ -18,7 +18,6 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"os\"\n \t\"os/exec\"\n \t\"path/filepath\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \t\"cloud.google.com/go/kms/apiv1/kmspb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -514,6 +515,7 @@\nfunc TestImportEndToEnd(t *testing.T) {\n \tcryptoKeyName := fmt.Sprintf(\"%s/cryptoKeys/%s\", fixture.KeyRingName, cryptoKeyID)\n \n \t// Create import job.\n+\tb.Reset()\n \timportJobID := fixture.RandomID()\n \tif err := createImportJob(&b, fixture.KeyRingName, importJobID); err != nil {\n \t\tt.Fatal(err)",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -524,13 +526,17 @@\nfunc TestImportEndToEnd(t *testing.T) {\n \timportJobName := fmt.Sprintf(\"%s/importJobs/%s\", fixture.KeyRingName, importJobID)\n \n \t// Check import job state (wait for ACTIVE).\n+\tb.Reset()\n \tfor !strings.Contains(b.String(), \"ACTIVE\") {\n \t\tif err := checkStateImportJob(&b, importJobName); err != nil {\n \t\t\tt.Fatal(err)\n \t\t}\n+\n+\t\ttime.Sleep(time.Second * 2)\n \t}\n \n \t// Import the key.\n+\tb.Reset()\n \tif err := importManuallyWrappedKey(&b, importJobName, cryptoKeyName); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-pubsub-storage-subs",
        "commit_id": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp reidentify fpe",
        "pr_number": 3186,
        "file_name": "internal/aeintegrate/aeintegrate.go",
        "code_diff": "@@ -47,7 +47,6 @@\nimport (\n \t\"context\"\n \t\"errors\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_reidentify_text_fpe",
        "commit_id": "7d7f199acf6554ba54135142d2cde8a13aeb8df3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp reidentify fpe",
        "pr_number": 3186,
        "file_name": "internal/aeintegrate/aeintegrate.go",
        "code_diff": "@@ -192,7 +191,7 @@\nfunc (p *App) envAppYaml() (string, error) {\n \t\treturn p.tempAppYaml, nil\n \t}\n \n-\tb, err := ioutil.ReadFile(filepath.Join(p.Dir, base))\n+\tb, err := os.ReadFile(filepath.Join(p.Dir, base))\n \tif err != nil {\n \t\treturn \"\", err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_reidentify_text_fpe",
        "commit_id": "7d7f199acf6554ba54135142d2cde8a13aeb8df3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp reidentify fpe",
        "pr_number": 3186,
        "file_name": "internal/aeintegrate/aeintegrate.go",
        "code_diff": "@@ -232,7 +231,7 @@\nfunc (p *App) envAppYaml() (string, error) {\n \tif err != nil {\n \t\treturn \"\", err\n \t}\n-\tif err := ioutil.WriteFile(filepath.Join(p.Dir, tmp), b, 0755); err != nil {\n+\tif err := os.WriteFile(filepath.Join(p.Dir, tmp), b, 0755); err != nil {\n \t\treturn \"\", err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_reidentify_text_fpe",
        "commit_id": "7d7f199acf6554ba54135142d2cde8a13aeb8df3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp reidentify fpe",
        "pr_number": 3186,
        "file_name": "internal/e2e/standard_test.go",
        "code_diff": "@@ -17,7 +17,7 @@\npackage e2e\n \n import (\n-\t\"io/ioutil\"\n+\t\"io\"\n \t\"log\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_reidentify_text_fpe",
        "commit_id": "7d7f199acf6554ba54135142d2cde8a13aeb8df3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp reidentify fpe",
        "pr_number": 3186,
        "file_name": "internal/testutil/runmain.go",
        "code_diff": "@@ -18,7 +18,6 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"os\"\n \t\"os/exec\"\n \t\"path/filepath\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_reidentify_text_fpe",
        "commit_id": "7d7f199acf6554ba54135142d2cde8a13aeb8df3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp reidentify table fpe",
        "pr_number": 3185,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -347,6 +347,79 @@\nfunc TestDeIdentifyDeterministic(t *testing.T) {\n \n }\n \n+func TestDeIdentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tinput := \"My phone number is 5555551212\"\n+\tinfoType := \"PHONE_NUMBER\"\n+\tsurrogateType := \"PHONE_TOKEN\"\n+\tunWrappedKey, err := getUnwrappedKey(t)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\twant := \"output: My phone number is PHONE_TOKEN(10):\"\n+\n+\tvar buf bytes.Buffer\n+\tif err := deidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, input, infoType, surrogateType, unWrappedKey); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyFreeTextWithFPEUsingSurrogate(%q) = %q, want %q\", input, got, want)\n+\t}\n+}\n+\n+func getUnwrappedKey(t *testing.T) (string, error) {\n+\tt.Helper()\n+\tkey := make([]byte, 32) // 32 bytes for AES-256\n+\t_, err := rand.Read(key)\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\n+\t// Encode the key to base64\n+\tencodedKey := base64.StdEncoding.EncodeToString(key)\n+\treturn string(encodedKey), nil\n+\n+}\n+\n+func TestReidentifyWithDeterministic(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tvar buf bytes.Buffer\n+\n+\tinputStr := \"My SSN is 372819127\"\n+\tinfoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tkeyFileName, cryptoKeyName, keyVersion, err := createKey(t, tc.ProjectID, keyRingName)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tdefer destroyKey(t, tc.ProjectID, keyVersion)\n+\n+\tsurrogateInfoType := \"SSN_TOKEN\"\n+\n+\tif err := deIdentifyDeterministicEncryption(&buf, tc.ProjectID, inputStr, infoTypeNames, keyFileName, cryptoKeyName, surrogateInfoType); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tdeidContent := buf.String()\n+\n+\tinputForReid := strings.TrimPrefix(deidContent, \"output : \")\n+\n+\tbuf.Reset()\n+\tif err := reidentifyWithDeterministic(&buf, tc.ProjectID, inputForReid, surrogateInfoType, keyFileName, cryptoKeyName); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"output: My SSN is 372819127\"; got != want {\n+\t\tt.Errorf(\"reidentifyWithDeterministic got %q, want %q\", got, want)\n+\t}\n+\n+}\n+\n func createKeyRing(t *testing.T, projectID string) (string, error) {\n \tt.Helper()",
        "comments": [],
        "commit_message": "resolve the conflicts",
        "commit_id": "f0df7ae840e0affb6c5f9118bef80ccd12e53359"
    },
    {
        "pr_title": "feat(eventarc): add sample for unmarshalling Cloud Storage event",
        "pr_number": 3183,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -347,6 +347,79 @@\nfunc TestDeIdentifyDeterministic(t *testing.T) {\n \n }\n \n+func TestDeIdentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tinput := \"My phone number is 5555551212\"\n+\tinfoType := \"PHONE_NUMBER\"\n+\tsurrogateType := \"PHONE_TOKEN\"\n+\tunWrappedKey, err := getUnwrappedKey(t)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\twant := \"output: My phone number is PHONE_TOKEN(10):\"\n+\n+\tvar buf bytes.Buffer\n+\tif err := deidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, input, infoType, surrogateType, unWrappedKey); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyFreeTextWithFPEUsingSurrogate(%q) = %q, want %q\", input, got, want)\n+\t}\n+}\n+\n+func getUnwrappedKey(t *testing.T) (string, error) {\n+\tt.Helper()\n+\tkey := make([]byte, 32) // 32 bytes for AES-256\n+\t_, err := rand.Read(key)\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\n+\t// Encode the key to base64\n+\tencodedKey := base64.StdEncoding.EncodeToString(key)\n+\treturn string(encodedKey), nil\n+\n+}\n+\n+func TestReidentifyWithDeterministic(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tvar buf bytes.Buffer\n+\n+\tinputStr := \"My SSN is 372819127\"\n+\tinfoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tkeyFileName, cryptoKeyName, keyVersion, err := createKey(t, tc.ProjectID, keyRingName)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tdefer destroyKey(t, tc.ProjectID, keyVersion)\n+\n+\tsurrogateInfoType := \"SSN_TOKEN\"\n+\n+\tif err := deIdentifyDeterministicEncryption(&buf, tc.ProjectID, inputStr, infoTypeNames, keyFileName, cryptoKeyName, surrogateInfoType); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tdeidContent := buf.String()\n+\n+\tinputForReid := strings.TrimPrefix(deidContent, \"output : \")\n+\n+\tbuf.Reset()\n+\tif err := reidentifyWithDeterministic(&buf, tc.ProjectID, inputForReid, surrogateInfoType, keyFileName, cryptoKeyName); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"output: My SSN is 372819127\"; got != want {\n+\t\tt.Errorf(\"reidentifyWithDeterministic got %q, want %q\", got, want)\n+\t}\n+\n+}\n+\n func createKeyRing(t *testing.T, projectID string) (string, error) {\n \tt.Helper()",
        "comments": [],
        "commit_message": "Merge branch 'main' into eventarc-storage",
        "commit_id": "88456424bda23ccb12317fe1baa4d0df67251e72"
    },
    {
        "pr_title": "feat(eventarc): add sample for unmarshalling Cloud Storage event",
        "pr_number": 3183,
        "file_name": "securitycenter/findings/list_all_findings.go",
        "code_diff": "@@ -25,7 +25,7 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n-// listFindings prints all findings in orgID to w.  orgID is the numeric\n+// listFindings prints all findings in orgID to w. orgID is the numeric\n // identifier of the organization.\n func listFindings(w io.Writer, orgID string) error {\n \t// orgID := \"12321311\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into eventarc-storage",
        "commit_id": "88456424bda23ccb12317fe1baa4d0df67251e72"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect bigquery with sampling",
        "pr_number": 3168,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -273,6 +273,24 @@\nfunc TestDeIdentifyWithWordList(t *testing.T) {\n \t}\n }\n \n+func TestDeIdentifyWithInfotype(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tinput := \"My email is test@example.com\"\n+\tinfoType := []string{\"EMAIL_ADDRESS\"}\n+\twant := \"output : My email is [EMAIL_ADDRESS]\"\n+\n+\tvar buf bytes.Buffer\n+\n+\tif err := deidentifyWithInfotype(&buf, tc.ProjectID, input, infoType); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got := buf.String(); got != want {\n+\t\tt.Errorf(\"deidentifyFreeTextWithFPEUsingSurrogate(%q) = %q, want %q\", input, got, want)\n+\t}\n+\n+}\n+\n func TestDeidentifyTableFPE(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_bigquery_with_sampling",
        "commit_id": "c13370bcfd1135ad1cf58da3cf245ba1e8000ee2"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -62,8 +62,9 @@\nfunc setup(t *testing.T) *pubsub.Client {\n \t}\n \n \tonce.Do(func() {\n-\t\ttopicID = fmt.Sprintf(\"%s-%d\", topicPrefix, time.Now().UnixNano())\n-\t\tsubID = fmt.Sprintf(\"%s-%d\", subPrefix, time.Now().UnixNano())\n+\t\tvar now = time.Now().UnixNano()\n+\t\ttopicID = fmt.Sprintf(\"%s-%d\", topicPrefix, now)\n+\t\tsubID = fmt.Sprintf(\"%s-%d\", subPrefix, now)\n \n \t\t// Cleanup resources from the previous tests.\n \t\tit := client.Topics(ctx)",
        "comments": [
            {
                "comment": "See previous about declaring & initializing a buffer.",
                "position": null
            }
        ],
        "commit_message": "chore: minor cleanup",
        "commit_id": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -17,9 +17,9 @@\npackage deid\n // [START dlp_deidentify_fpe]\n import (\n \t\"context\"\n+\t\"encoding/base64\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -31,12 +31,12 @@\nimport (\n // optional identifier needed for reidentification. surrogateInfoType can be any\n // value not found in your input.\n // Info types can be found with the infoTypes.list method or on https://cloud.google.com/dlp/docs/infotypes-reference\n-func deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n+func deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string, kmsKeyName, wrappedAESKey, surrogateInfoType string) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 123456789\"\n \t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n-\t// keyFileName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"\n-\t// cryptoKeyName := \"YOUR_ENCRYPTED_AES_256_KEY\"\n+\t// kmsKeyName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"\n+\t// wrappedAESKey := \"YOUR_ENCRYPTED_AES_256_KEY\"\n \t// surrogateInfoType := \"AGE\"\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -49,11 +49,13 @@\nfunc deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string,\n \tfor _, it := range infoTypeNames {\n \t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n-\t// Read the key file.\n-\tkeyBytes, err := ioutil.ReadFile(keyFileName)\n+\n+\t// Specify an encrypted AES-256 key and the name of the Cloud KMS key that encrypted it.\n+\tkmsWrappedCryptoKey, err := base64.StdEncoding.DecodeString(wrappedAESKey)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"ReadFile: %w\", err)\n+\t\treturn err\n \t}\n+\n \t// Create a configured request.\n \treq := &dlppb.DeidentifyContentRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/global\", projectID),",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -534,9 +534,13 @@\nfunc TestDeIdentifyTimeExtract(t *testing.T) {\n \t}\n }\n \n-func TestReidTableDataWithFPE(t *testing.T) {\n+func TestReidTextDataWithFPE(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n+\n+\tinput := \"My SSN is 123456789\"\n+\tinfoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\tsurrogateInfoType := \"AGE\"\n \n \tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -17,10 +17,18 @@\npackage metadata\n \n import (\n \t\"bytes\"\n+\t\"context\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n \t\"strings\"\n \t\"testing\"\n \n+\tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n )\n \n func TestInfoTypes(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "eventarc/testing/audit_storage.e2e_test.go",
        "code_diff": "@@ -15,13 +15,16 @@\npackage cloudruntests\n \n import (\n+\t\"context\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\tcloudevent \"github.com/cloudevents/sdk-go/v2\"\n )\n \n func TestAuditStorageSinkService(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "eventarc/testing/audit_storage.e2e_test.go",
        "code_diff": "@@ -34,12 +37,26 @@\nfunc TestAuditStorageSinkService(t *testing.T) {\n \t}\n \tdefer service.Clean()\n \n-\trequestPath := \"/\"\n-\treq, err := service.NewRequest(\"POST\", requestPath)\n+\tevent := cloudevent.NewEvent(\"1.0\")\n+\tevent.SetID(\"1\")\n+\tevent.SetSource(\"test\")\n+\tevent.SetSubject(\"storage.googleapis.com/projects/_/buckets/my-bucket\")\n+\tevent.SetType(\"test\")\n+\n+\tservice_url, err := service.URL(\"/\")\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\treq, err := cloudevent.NewHTTPRequestFromEvent(context.Background(),\n+\t\tservice_url, event)\n \tif err != nil {\n-\t\tt.Fatalf(\"service.NewRequest: %v\", err)\n+\t\tt.Fatal(err)\n \t}\n \n+\t// add a valid auth header to the cloudevent request.\n+\tauthreq, _ := service.NewRequest(\"POST\", \"/\")\n+\treq.Header.Set(\"Authorization\", authreq.Header.Get(\"Authorization\"))\n+\n \tclient := http.Client{Timeout: 10 * time.Second}\n \tresp, err := client.Do(req)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "functions/security/security_system_test.go",
        "code_diff": "@@ -22,6 +22,9 @@\nimport (\n \t\"os/exec\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n+\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n const RuntimeVersion = \"go118\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "internal/aeintegrate/aeintegrate.go",
        "code_diff": "@@ -47,7 +47,6 @@\nimport (\n \t\"context\"\n \t\"errors\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "internal/aeintegrate/aeintegrate.go",
        "code_diff": "@@ -192,7 +191,7 @@\nfunc (p *App) envAppYaml() (string, error) {\n \t\treturn p.tempAppYaml, nil\n \t}\n \n-\tb, err := ioutil.ReadFile(filepath.Join(p.Dir, base))\n+\tb, err := os.ReadFile(filepath.Join(p.Dir, base))\n \tif err != nil {\n \t\treturn \"\", err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "internal/aeintegrate/aeintegrate.go",
        "code_diff": "@@ -232,7 +231,7 @@\nfunc (p *App) envAppYaml() (string, error) {\n \tif err != nil {\n \t\treturn \"\", err\n \t}\n-\tif err := ioutil.WriteFile(filepath.Join(p.Dir, tmp), b, 0755); err != nil {\n+\tif err := os.WriteFile(filepath.Join(p.Dir, tmp), b, 0755); err != nil {\n \t\treturn \"\", err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "internal/e2e/standard_test.go",
        "code_diff": "@@ -17,7 +17,7 @@\npackage e2e\n \n import (\n-\t\"io/ioutil\"\n+\t\"io\"\n \t\"log\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "internal/testutil/runmain.go",
        "code_diff": "@@ -18,7 +18,6 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"os\"\n \t\"os/exec\"\n \t\"path/filepath\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \t\"cloud.google.com/go/kms/apiv1/kmspb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -514,6 +515,7 @@\nfunc TestImportEndToEnd(t *testing.T) {\n \tcryptoKeyName := fmt.Sprintf(\"%s/cryptoKeys/%s\", fixture.KeyRingName, cryptoKeyID)\n \n \t// Create import job.\n+\tb.Reset()\n \timportJobID := fixture.RandomID()\n \tif err := createImportJob(&b, fixture.KeyRingName, importJobID); err != nil {\n \t\tt.Fatal(err)",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "docs(samples): Add Gen App Builder example to discoveryengine",
        "pr_number": 3155,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -524,13 +526,17 @@\nfunc TestImportEndToEnd(t *testing.T) {\n \timportJobName := fmt.Sprintf(\"%s/importJobs/%s\", fixture.KeyRingName, importJobID)\n \n \t// Check import job state (wait for ACTIVE).\n+\tb.Reset()\n \tfor !strings.Contains(b.String(), \"ACTIVE\") {\n \t\tif err := checkStateImportJob(&b, importJobName); err != nil {\n \t\t\tt.Fatal(err)\n \t\t}\n+\n+\t\ttime.Sleep(time.Second * 2)\n \t}\n \n \t// Import the key.\n+\tb.Reset()\n \tif err := importManuallyWrappedKey(&b, importJobName, cryptoKeyName); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "703749be95f1f5d4bcf15b806364c25814617c63"
    },
    {
        "pr_title": "feat(run/receive-auth): add run sample for receive-auth func",
        "pr_number": 3123,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -347,6 +347,33 @@\nfunc TestDeIdentifyDeterministic(t *testing.T) {\n \n }\n \n+func TestReidentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tvar buf bytes.Buffer\n+\n+\tinputStr := \"My phone number is 1234567890\"\n+\tinfoType := \"PHONE_NUMBER\"\n+\tsurrogateType := \"PHONE_TOKEN\"\n+\tunwrappedKey := \"hu4O2y0RsY9qrVt1d2xAWEmqVqAc1P8Vk7D6peashag=\"\n+\n+\tif err := deidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputStr, infoType, surrogateType, unwrappedKey); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tinputForReid := \"My phone number is PHONE_TOKEN(10):4169075971\"\n+\n+\tbuf.Reset()\n+\tif err := reidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputForReid, surrogateType, unwrappedKey); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"output: My phone number is 1234567890\"; got != want {\n+\t\tt.Errorf(\"reidentifyFreeTextWithFPEUsingSurrogate got %q, want %q\", got, want)\n+\t}\n+\n+}\n+\n func TestDeIdentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/add_receive_auth_with_cloudrun",
        "commit_id": "55e7d1e3afac530fcdd1722a6c30d64a1d2fdff9"
    },
    {
        "pr_title": "feat(run/receive-auth): add run sample for receive-auth func",
        "pr_number": 3123,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -567,7 +594,7 @@\nfunc TestReidTextDataWithFPE(t *testing.T) {\n \n \tgot := buf.String()\n \tif want := \"output: My SSN is 123456789\"; got != want {\n-\t\tt.Errorf(\"reidentifyFreeTextWithFPEUsingSurrogate got %q, want %q\", got, want)\n+\t\tt.Errorf(\"reidTextDataWithFPE got %q, want %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/add_receive_auth_with_cloudrun",
        "commit_id": "55e7d1e3afac530fcdd1722a6c30d64a1d2fdff9"
    },
    {
        "pr_title": "feat(run/receive-auth): add run sample for receive-auth func",
        "pr_number": 3123,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -43,7 +43,6 @@\nconst (\n \ttestCaptionsFileName     = \"captions.srt\"\n \ttestSubtitlesFileName1   = \"subtitles-en.srt\"\n \ttestSubtitlesFileName2   = \"subtitles-es.srt\"\n-\tpreset                   = \"preset/web-hd\"\n \tsmallSpriteSheetFileName = \"small-sprite-sheet0000000000.jpeg\"\n \tlargeSpriteSheetFileName = \"large-sprite-sheet0000000000.jpeg\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/add_receive_auth_with_cloudrun",
        "commit_id": "55e7d1e3afac530fcdd1722a6c30d64a1d2fdff9"
    },
    {
        "pr_title": "feat(run/receive-auth): add run sample for receive-auth func",
        "pr_number": 3123,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -70,6 +69,7 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tinputSubtitles1URI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testSubtitlesFileName1\n \tinputSubtitles2URI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testSubtitlesFileName2\n \toutputURIForPreset := \"gs://\" + bucketName + \"/test-output-preset/\"\n+\toutputURIForPresetBatchMode := \"gs://\" + bucketName + \"/test-output-preset-batch-mode/\"\n \toutputURIForTemplate := \"gs://\" + bucketName + \"/test-output-template/\"\n \toutputURIForAdHoc := \"gs://\" + bucketName + \"/test-output-adhoc/\"\n \toutputURIForStaticOverlay := \"gs://\" + bucketName + \"/test-output-static-overlay/\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/add_receive_auth_with_cloudrun",
        "commit_id": "55e7d1e3afac530fcdd1722a6c30d64a1d2fdff9"
    },
    {
        "pr_title": "feat(run/receive-auth): add run sample for receive-auth func",
        "pr_number": 3123,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -99,6 +99,8 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tt.Logf(\"\\nwriteTestGCSFiles() completed\\n\")\n \ttestJobFromPreset(t, projectNumber, inputURI, outputURIForPreset)\n \tt.Logf(\"\\ntestJobFromPreset() completed\\n\")\n+\ttestJobFromPresetBatchMode(t, projectNumber, inputURI, outputURIForPresetBatchMode)\n+\tt.Logf(\"\\ntestJobFromPresetBatchMode() completed\\n\")\n \ttestJobFromTemplate(t, projectNumber, inputURI, outputURIForTemplate)\n \tt.Logf(\"\\ntestJobFromTemplate() completed\\n\")\n \ttestJobFromAdHoc(t, projectNumber, inputURI, outputURIForAdHoc)",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/add_receive_auth_with_cloudrun",
        "commit_id": "55e7d1e3afac530fcdd1722a6c30d64a1d2fdff9"
    },
    {
        "pr_title": "feat(run/receive-auth): add run sample for receive-auth func",
        "pr_number": 3123,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -260,7 +262,7 @@\nfunc testJobFromPreset(t *testing.T, projectNumber string, inputURI string, outp\n \n \t// Create the job.\n \tjobName := fmt.Sprintf(\"projects/%s/locations/%s/jobs/\", projectNumber, location)\n-\tif err := createJobFromPreset(buf, tc.ProjectID, location, inputURI, outputURIForPreset, preset); err != nil {\n+\tif err := createJobFromPreset(buf, tc.ProjectID, location, inputURI, outputURIForPreset); err != nil {\n \t\tt.Errorf(\"createJobFromPreset got err: %v\", err)\n \t}\n \tgot := buf.String()",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/add_receive_auth_with_cloudrun",
        "commit_id": "55e7d1e3afac530fcdd1722a6c30d64a1d2fdff9"
    },
    {
        "pr_title": "feat(run/receive-auth): add run sample for receive-auth func",
        "pr_number": 3123,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n+\t\"cloud.google.com/go/storage\"\n \t\"google.golang.org/api/iterator\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/add_receive_auth_with_cloudrun",
        "commit_id": "55e7d1e3afac530fcdd1722a6c30d64a1d2fdff9"
    },
    {
        "pr_title": "feat(run/receive-auth): add run sample for receive-auth func",
        "pr_number": 3123,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -746,6 +747,81 @@\nfunc TestCreateWithFilter(t *testing.T) {\n \t}\n }\n \n+func TestCreatePushSubscription(t *testing.T) {\n+\tt.Parallel()\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tdefer client.Close()\n+\n+\tt.Run(\"default push subscription\", func(t *testing.T) {\n+\t\ttopicID := topicID + \"-default-push\"\n+\t\tsubID := subID + \"-default-push\"\n+\t\tt.Cleanup(func() {\n+\t\t\t// Don't check delete errors since if it doesn't exist\n+\t\t\t// that's fine.\n+\t\t\ttopic := client.Topic(topicID)\n+\t\t\ttopic.Delete(ctx)\n+\n+\t\t\tsub := client.Subscription(subID)\n+\t\t\tsub.Delete(ctx)\n+\t\t})\n+\n+\t\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\t\ttopic, err := getOrCreateTopic(ctx, client, topicID)\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"CreateTopic: %v\", err)\n+\t\t\t}\n+\n+\t\t\tvar b bytes.Buffer\n+\t\t\tendpoint := \"https://my-test-project.appspot.com/push\"\n+\t\t\tif err := createWithEndpoint(&b, tc.ProjectID, subID, topic, endpoint); err != nil {\n+\t\t\t\tr.Errorf(\"failed to create push subscription: %v\", err)\n+\t\t\t}\n+\n+\t\t\tgot := b.String()\n+\t\t\twant := \"Created push subscription\"\n+\t\t\tif !strings.Contains(got, want) {\n+\t\t\t\tr.Errorf(\"got %s, want %s\", got, want)\n+\t\t\t}\n+\t\t})\n+\t})\n+\n+\tt.Run(\"no wrapper\", func(t *testing.T) {\n+\t\ttopicID := topicID + \"-no-wrapper\"\n+\t\tsubID := subID + \"-no-wrapper\"\n+\n+\t\tt.Cleanup(func() {\n+\t\t\t// Don't check delete errors since if it doesn't exist\n+\t\t\t// that's fine.\n+\t\t\ttopic := client.Topic(topicID)\n+\t\t\ttopic.Delete(ctx)\n+\n+\t\t\tsub := client.Subscription(subID)\n+\t\t\tsub.Delete(ctx)\n+\t\t})\n+\n+\t\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\t\ttopic, err := getOrCreateTopic(ctx, client, topicID)\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"CreateTopic: %v\", err)\n+\t\t\t}\n+\n+\t\t\tvar b bytes.Buffer\n+\t\t\tendpoint := \"https://my-test-project.appspot.com/push\"\n+\t\t\tif err := createPushNoWrapperSubscription(&b, tc.ProjectID, subID, topic, endpoint); err != nil {\n+\t\t\t\tr.Errorf(\"failed to create push subscription: %v\", err)\n+\t\t\t}\n+\n+\t\t\tgot := b.String()\n+\t\t\twant := \"Created push no wrapper subscription\"\n+\t\t\tif !strings.Contains(got, want) {\n+\t\t\t\tr.Errorf(\"got %s, want %s\", got, want)\n+\t\t\t}\n+\t\t})\n+\t})\n+}\n+\n func TestCreateBigQuerySubscription(t *testing.T) {\n \tt.Parallel()\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/add_receive_auth_with_cloudrun",
        "commit_id": "55e7d1e3afac530fcdd1722a6c30d64a1d2fdff9"
    },
    {
        "pr_title": "feat(run/receive-auth): add run sample for receive-auth func",
        "pr_number": 3123,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -779,6 +855,36 @@\nfunc TestCreateBigQuerySubscription(t *testing.T) {\n \t}\n }\n \n+func TestCreateCloudStorageSubscription(t *testing.T) {\n+\tt.Parallel()\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tdefer client.Close()\n+\tstorageSubID := subID + \"-cloud-storage\"\n+\n+\ttopic, err := getOrCreateTopic(ctx, client, topicID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"CreateTopic: %v\", err)\n+\t}\n+\tvar buf bytes.Buffer\n+\n+\t// Use the same bucket across test instances. This\n+\t// is safe since we're not writing to the bucket\n+\t// and this makes us not have to do bucket cleanups.\n+\tbucketID := fmt.Sprintf(\"%s-%s\", tc.ProjectID, \"pubsub-storage-sub-sink\")\n+\tif err := createOrGetStorageBucket(tc.ProjectID, bucketID); err != nil {\n+\t\tt.Fatalf(\"failed to get or create storage bucket: %v\", err)\n+\t}\n+\n+\tif err := createCloudStorageSubscription(&buf, tc.ProjectID, storageSubID, topic, bucketID); err != nil {\n+\t\tt.Fatalf(\"failed to create cloud storage subscription: %v\", err)\n+\t}\n+\n+\tsub := client.Subscription(storageSubID)\n+\tsub.Delete(ctx)\n+}\n+\n func TestCreateSubscriptionWithExactlyOnceDelivery(t *testing.T) {\n \tt.Parallel()\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/add_receive_auth_with_cloudrun",
        "commit_id": "55e7d1e3afac530fcdd1722a6c30d64a1d2fdff9"
    },
    {
        "pr_title": "feat(run/receive-auth): add run sample for receive-auth func",
        "pr_number": 3123,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -387,6 +387,17 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"Updated data to VenueDetails column\\n\")\n \tout = runSample(t, queryWithJsonParameter, dbName, \"failed to query with json parameter\")\n \tassertContains(t, out, \"The venue details for venue id 19\")\n+\n+\tout = runSample(t, createSequence, dbName, \"failed to create table with bit reverse sequence enabled\")\n+\tassertContains(t, out, \"Created Seq sequence and Customers table, where the key column CustomerId uses the sequence as a default value\\n\")\n+\tassertContains(t, out, \"Inserted customer record with CustomerId\")\n+\tassertContains(t, out, \"Number of customer records inserted is: 3\")\n+\tout = runSample(t, alterSequence, dbName, \"failed to alter table with bit reverse sequence enabled\")\n+\tassertContains(t, out, \"Altered Seq sequence to skip an inclusive range between 1000 and 5000000\\n\")\n+\tassertContains(t, out, \"Inserted customer record with CustomerId\")\n+\tassertContains(t, out, \"Number of customer records inserted is: 3\")\n+\tout = runSample(t, dropSequence, dbName, \"failed to drop bit reverse sequence column\")\n+\tassertContains(t, out, \"Altered Customers table to drop DEFAULT from CustomerId column and dropped the Seq sequence\\n\")\n }\n \n func TestBackupSample(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/add_receive_auth_with_cloudrun",
        "commit_id": "55e7d1e3afac530fcdd1722a6c30d64a1d2fdff9"
    },
    {
        "pr_title": "feat(run/receive-auth): add run sample for receive-auth func",
        "pr_number": 3123,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -671,6 +682,25 @@\nfunc TestCustomInstanceConfigSample(t *testing.T) {\n \tassertContains(t, out, \"Deleted instance configuration\")\n }\n \n+func TestForeignKeyDeleteCascadeSample(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\n+\tmustRunSample(t, createDatabase, dbName, \"failed to create a database\")\n+\n+\tvar out string\n+\n+\tout = runSample(t, createTableWithForeignKeyDeleteCascade, dbName, \"failed to create table with foreign key delete constraint\")\n+\tassertContains(t, out, \"Created Customers and ShoppingCarts table with FKShoppingCartsCustomerId foreign key constraint\")\n+\tout = runSample(t, alterTableWithForeignKeyDeleteCascade, dbName, \"failed to alter table with foreign key delete constraint\")\n+\tassertContains(t, out, \"Altered ShoppingCarts table with FKShoppingCartsCustomerName foreign key constraint\")\n+\tout = runSample(t, dropForeignKeyDeleteCascade, dbName, \"failed to drop foreign key delete constraint\")\n+\tassertContains(t, out, \"Altered ShoppingCarts table to drop FKShoppingCartsCustomerName foreign key constraint\")\n+}\n+\n func TestPgSample(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n \tt.Parallel()",
        "comments": [],
        "commit_message": "Merge branch 'main' into feature/add_receive_auth_with_cloudrun",
        "commit_id": "55e7d1e3afac530fcdd1722a6c30d64a1d2fdff9"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -277,375 +277,6 @@\nfunc TestInspectBigquery(t *testing.T) {\n \t}\n }\n \n-func TestInspectImageFileAllInfoTypes(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tinputPath := \"testdata/image.jpg\"\n-\n-\tvar buf bytes.Buffer\n-\tif err := InspectImageFileAllInfoTypes(&buf, tc.ProjectID, inputPath); err != nil {\n-\t\tt.Errorf(\"InspectBigQueryTableWithSampling: %v\", err)\n-\t}\n-\tgot := buf.String()\n-\tif want := \"Info type: DATE\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectBigQueryTableWithSampling got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectBigQueryTableWithSampling got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: US_SOCIAL_SECURITY_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"InspectBigQueryTableWithSampling got %q, want %q\", got, want)\n-\t}\n-\n-}\n-\n-func TestInspectPhoneNumber(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectPhoneNumber(&buf, tc.ProjectID, \"I'm Gary and my phone number is (415) 555-0890\"); err != nil {\n-\t\tt.Errorf(\"TestInspectFile: %v\", err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectPhoneNumber got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringCustomHotWord(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringCustomHotWord(&buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n-\t\tt.Errorf(\"inspectStringCustomHotWord: %v\", err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomHotWord got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringWithExclusionDictSubstring(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringWithExclusionDictSubstring(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, TEST@example.com\", []string{\"TEST\"}); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n-\n-\tif want := \"Infotype Name: DOMAIN_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n-\n-\tif want := \"Quote: TEST\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectStringOmitOverlap(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\n-\tif err := inspectStringOmitOverlap(&buf, tc.ProjectID, \"gary@example.com\"); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringOmitOverlap got %q, want %q\", got, want)\n-\t}\n-\n-\tif want := \"Infotype Name: PERSON_NAME\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringOmitOverlap got %q, want %q\", got, want)\n-\t}\n-}\n-\n-\n-// Copyright 2019 Google LLC\n-//\n-// Licensed under the Apache License, Version 2.0 (the \"License\");\n-// you may not use this file except in compliance with the License.\n-// You may obtain a copy of the License at\n-//\n-//     https://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing, software\n-// distributed under the License is distributed on an \"AS IS\" BASIS,\n-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-// See the License for the specific language governing permissions and\n-// limitations under the License.\n-\n-package inspect\n-\n-import (\n-\t\"bytes\"\n-\t\"context\"\n-\t\"strings\"\n-\t\"testing\"\n-\t\"time\"\n-\n-\t\"cloud.google.com/go/bigquery\"\n-\t\"cloud.google.com/go/datastore\"\n-\t\"cloud.google.com/go/storage\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"github.com/gofrs/uuid\"\n-)\n-\n-const (\n-\ttopicName        = \"dlp-inspect-test-topic-\"\n-\tsubscriptionName = \"dlp-inspect-test-sub-\"\n-\n-\tssnFileName = \"fake_ssn.txt\"\n-\tbucketName  = \"golang-samples-dlp-test2\"\n-)\n-\n-func TestInspectDatastore(t *testing.T) {\n-\ttc := testutil.EndToEndTest(t)\n-\twriteTestDatastoreFiles(t, tc.ProjectID)\n-\ttests := []struct {\n-\t\tkind string\n-\t\twant string\n-\t}{\n-\t\t{\n-\t\t\tkind: \"SSNTask\",\n-\t\t\twant: \"Created job\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.kind, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\ttestutil.Retry(t, 5, 15*time.Second, func(r *testutil.R) {\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, \"\", test.kind); err != nil {\n-\t\t\t\t\tr.Errorf(\"inspectDatastore(%s) got err: %v\", test.kind, err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\t\tr.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n-\t\t\t\t}\n-\t\t\t})\n-\t\t})\n-\t}\n-}\n-\n-type SSNTask struct {\n-\tDescription string\n-}\n-\n-func writeTestDatastoreFiles(t *testing.T, projectID string) {\n-\tt.Helper()\n-\tctx := context.Background()\n-\tclient, err := datastore.NewClient(ctx, projectID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"datastore.NewClient: %v\", err)\n-\t}\n-\tkind := \"SSNTask\"\n-\tname := \"ssntask1\"\n-\tssnKey := datastore.NameKey(kind, name, nil)\n-\ttask := SSNTask{\n-\t\tDescription: \"My SSN is 111222333\",\n-\t}\n-\tif _, err := client.Put(ctx, ssnKey, &task); err != nil {\n-\t\tt.Fatalf(\"Failed to save task: %v\", err)\n-\t}\n-}\n-\n-func TestInspectGCS(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\twriteTestGCSFiles(t, tc.ProjectID)\n-\ttests := []struct {\n-\t\tfileName string\n-\t\twant     string\n-\t}{\n-\t\t{\n-\t\t\tfileName: ssnFileName,\n-\t\t\twant:     \"Created job\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.fileName, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\ttestutil.Retry(t, 5, 15*time.Second, func(r *testutil.R) {\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n-\t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, bucketName, test.fileName); err != nil {\n-\t\t\t\t\tr.Errorf(\"inspectGCSFile(%s) got err: %v\", test.fileName, err)\n-\t\t\t\t\treturn\n-\t\t\t\t}\n-\t\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\t\tr.Errorf(\"inspectGCSFile(%s) = %q, want %q substring\", test.fileName, got, test.want)\n-\t\t\t\t}\n-\t\t\t})\n-\t\t})\n-\t}\n-}\n-\n-func writeTestGCSFiles(t *testing.T, projectID string) {\n-\tt.Helper()\n-\tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n-\t}\n-\tbucket := client.Bucket(bucketName)\n-\t_, err = bucket.Attrs(ctx)\n-\tif err != nil {\n-\t\tswitch err {\n-\t\tcase storage.ErrObjectNotExist:\n-\t\t\tif err := bucket.Create(ctx, projectID, nil); err != nil {\n-\t\t\t\tt.Fatalf(\"bucket.Create: %v\", err)\n-\t\t\t}\n-\t\tdefault:\n-\t\t\tt.Fatalf(\"error getting bucket attrs: %v\", err)\n-\t\t}\n-\t}\n-\tif err := writeObject(ctx, bucket, ssnFileName, \"My SSN is 111222333\"); err != nil {\n-\t\tt.Fatalf(\"writeObject: %v\", err)\n-\t}\n-}\n-\n-func writeObject(ctx context.Context, bucket *storage.BucketHandle, fileName, content string) error {\n-\tobj := bucket.Object(fileName)\n-\t_, err := obj.Attrs(ctx)\n-\tif err != nil {\n-\t\tswitch err {\n-\t\tcase storage.ErrObjectNotExist:\n-\t\t\tw := obj.NewWriter(ctx)\n-\t\t\tw.Write([]byte(content))\n-\t\t\tif err := w.Close(); err != nil {\n-\t\t\t\treturn err\n-\t\t\t}\n-\t\tdefault:\n-\t\t\treturn err\n-\t\t}\n-\t}\n-\treturn nil\n-}\n-\n-func TestInspectString(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n-\n-\tif err := inspectString(buf, tc.ProjectID, \"I'm Gary and my email is gary@example.com\"); err != nil {\n-\t\tt.Errorf(\"TestInspectFile: %v\", err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectString got %q, want %q\", got, want)\n-\t}\n-}\n-\n-func TestInspectTextFile(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n-\n-\tif err := inspectTextFile(buf, tc.ProjectID, \"testdata/test.txt\"); err != nil {\n-\t\tt.Errorf(\"TestInspectTextFile: %v\", err)\n-\t}\n-\n-\tgot := buf.String()\n-\tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectTextFile got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectTextFile got %q, want %q\", got, want)\n-\t}\n-}\n-\n-type Item struct {\n-\tDescription string\n-}\n-\n-const (\n-\tharmfulTable = \"harmful\"\n-\tbqDatasetID  = \"golang_samples_dlp\"\n-)\n-\n-func mustCreateBigqueryTestFiles(t *testing.T, projectID, datasetID string) {\n-\tt.Helper()\n-\n-\tctx := context.Background()\n-\tclient, err := bigquery.NewClient(ctx, projectID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"bigquery.NewClient: %v\", err)\n-\t}\n-\tdefer client.Close()\n-\td := client.Dataset(datasetID)\n-\tif _, err := d.Metadata(ctx); err != nil {\n-\t\tif err := d.Create(ctx, &bigquery.DatasetMetadata{}); err != nil {\n-\t\t\tt.Fatalf(\"Create: %v\", err)\n-\t\t}\n-\t}\n-\tschema, err := bigquery.InferSchema(Item{})\n-\tif err != nil {\n-\t\tt.Fatalf(\"InferSchema: %v\", err)\n-\t}\n-\tif err := uploadBigQuery(ctx, d, schema, harmfulTable, \"My SSN is 111222333\"); err != nil {\n-\t\tt.Fatalf(\"uploadBigQuery: %v\", err)\n-\t}\n-}\n-\n-func uploadBigQuery(ctx context.Context, d *bigquery.Dataset, schema bigquery.Schema, table, content string) error {\n-\tt := d.Table(table)\n-\tif _, err := t.Metadata(ctx); err == nil {\n-\t\treturn nil\n-\t}\n-\tif err := t.Create(ctx, &bigquery.TableMetadata{Schema: schema}); err != nil {\n-\t\treturn err\n-\t}\n-\tsource := bigquery.NewReaderSource(strings.NewReader(content))\n-\tl := t.LoaderFrom(source)\n-\tjob, err := l.Run(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tstatus, err := job.Wait(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\treturn status.Err()\n-}\n-\n-func TestInspectBigquery(t *testing.T) {\n-\ttc := testutil.EndToEndTest(t)\n-\n-\tmustCreateBigqueryTestFiles(t, tc.ProjectID, bqDatasetID)\n-\n-\ttests := []struct {\n-\t\ttable string\n-\t\twant  string\n-\t}{\n-\t\t{\n-\t\t\ttable: harmfulTable,\n-\t\t\twant:  \"Created job\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.table, func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n-\t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectBigquery(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, bqDatasetID, test.table); err != nil {\n-\t\t\t\tt.Errorf(\"inspectBigquery(%s) got err: %v\", test.table, err)\n-\t\t\t}\n-\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\tt.Errorf(\"inspectBigquery(%s) = %q, want %q substring\", test.table, got, test.want)\n-\t\t\t}\n-\t\t})\n-\t}\n-}\n-\n func TestInspectTable(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "fixing the branch issue",
        "commit_id": "6eb020cefb0bb0a73b4e96fc8b916507c06c7ba5"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "logging/simplelog/simplelog.go",
        "code_diff": "@@ -20,15 +20,6 @@\nimport (\n \t\"log\"\n \t\"os\"\n \t\"time\"\n-\n-\t// [START imports]\n-\t\"context\"\n-\n-\t\"cloud.google.com/go/logging\"\n-\t\"cloud.google.com/go/logging/logadmin\"\n-\n-\t\"google.golang.org/api/iterator\"\n-\t// [END imports]\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "ec5f8d56af4fa29a11b1446923931978da8d22b3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "logging/simplelog/simplelog.go",
        "code_diff": "@@ -42,36 +33,14 @@\nfunc main() {\n \tprojID := os.Args[1]\n \tcommand := os.Args[2]\n \n-\t// [START setup]\n-\tctx := context.Background()\n-\tclient, err := logging.NewClient(ctx, projID)\n-\tif err != nil {\n-\t\tlog.Fatalf(\"Failed to create logging client: %v\", err)\n-\t}\n-\tdefer client.Close()\n-\n-\tadminClient, err := logadmin.NewClient(ctx, projID)\n-\tif err != nil {\n-\t\tlog.Fatalf(\"Failed to create logadmin client: %v\", err)\n-\t}\n-\tdefer adminClient.Close()\n-\n-\tclient.OnError = func(err error) {\n-\t\t// Print an error to the local log.\n-\t\t// For example, if Flush() failed.\n-\t\tlog.Printf(\"client.OnError: %v\", err)\n-\t}\n-\t// [END setup]\n-\n \tswitch command {\n \tcase \"write\":\n-\t\tlog.Print(\"Writing some log entries.\")\n-\t\twriteEntry(client)\n-\t\tstructuredWrite(client)\n+\t\tlog.Print(\"Writing log entries.\")\n+\t\tstructuredWrite(projID)\n \n \tcase \"read\":\n \t\tlog.Print(\"Fetching and printing log entries.\")\n-\t\tentries, err := getEntries(adminClient, projID)\n+\t\tentries, err := getEntries(projID)\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"Could not get entries: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "ec5f8d56af4fa29a11b1446923931978da8d22b3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "logging/simplelog/simplelog.go",
        "code_diff": "@@ -85,7 +54,7 @@\nfunc main() {\n \n \tcase \"delete\":\n \t\tlog.Print(\"Deleting log.\")\n-\t\tif err := deleteLog(adminClient); err != nil {\n+\t\tif err := deleteLog(projID); err != nil {\n \t\t\tlog.Fatalf(\"Could not delete log: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "ec5f8d56af4fa29a11b1446923931978da8d22b3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "logging/simplelog/simplelog_test.go",
        "code_diff": "@@ -22,7 +22,6 @@\nimport (\n \t\"time\"\n \n \t\"cloud.google.com/go/logging\"\n-\t\"cloud.google.com/go/logging/logadmin\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "ec5f8d56af4fa29a11b1446923931978da8d22b3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "logging/simplelog/simplelog_test.go",
        "code_diff": "@@ -35,10 +34,6 @@\nfunc TestSimplelog(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"logging.NewClient: %v\", err)\n \t}\n-\tadminClient, err := logadmin.NewClient(ctx, tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"logadmin.NewClient: %v\", err)\n-\t}\n \tdefer func() {\n \t\tif err := client.Close(); err != nil {\n \t\t\tt.Errorf(\"Close: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "ec5f8d56af4fa29a11b1446923931978da8d22b3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "logging/simplelog/simplelog_test.go",
        "code_diff": "@@ -47,7 +42,7 @@\nfunc TestSimplelog(t *testing.T) {\n \n \tdefer func() {\n \t\ttestutil.Retry(t, 10, 5*time.Second, func(r *testutil.R) {\n-\t\t\tif err := deleteLog(adminClient); err != nil {\n+\t\t\tif err := deleteLog(tc.ProjectID); err != nil {\n \t\t\t\tr.Errorf(\"deleteLog: %v\", err)\n \t\t\t}\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "ec5f8d56af4fa29a11b1446923931978da8d22b3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -279,7 +279,6 @@\nfunc TestInspectBigquery(t *testing.T) {\n \n func TestInspectTable(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\n \tvar buf bytes.Buffer\n \tif err := inspectTable(&buf, tc.ProjectID); err != nil {\n \t\tt.Fatal(err)",
        "comments": [
            {
                "comment": "Please update the test name prefix to **InspectImageFileAllInfoTypes** in this method instead of _InspectBigQueryTableWithSampling_",
                "position": null
            },
            {
                "comment": "Should be inspectImageFileAllInfoTypes not BQ sampling. Please fix.",
                "position": null
            },
            {
                "comment": "Apologies, Updated it. will take care that such things doesn't happen in the future.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "86bc4b6e96da4e7c44d487f92f7293e3088c042d"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -295,9 +294,7 @@\nfunc TestInspectTable(t *testing.T) {\n \n func TestInspectStringWithExclusionRegex(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\n \tvar buf bytes.Buffer\n-\n \tif err := inspectStringWithExclusionRegex(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, bob@example.org\", \".+@example.com\"); err != nil {\n \t\tt.Errorf(\"inspectStringWithExclusionRegex: %v\", err)\n \t}",
        "comments": [
            {
                "comment": "Please update the test name prefix to **InspectImageFileAllInfoTypes** in this method instead of _InspectBigQueryTableWithSampling_",
                "position": null
            },
            {
                "comment": "Should be inspectImageFileAllInfoTypes not BQ sampling. Please fix.",
                "position": null
            },
            {
                "comment": "Apologies, Updated it. will take care that such things doesn't happen in the future.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "86bc4b6e96da4e7c44d487f92f7293e3088c042d"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -338,7 +335,7 @@\nfunc TestInspectStringMultipleRules(t *testing.T) {\n \tvar buf bytes.Buffer\n \n \tif err := inspectStringMultipleRules(&buf, tc.ProjectID, \"patient: Jane Doe\"); err != nil {\n-\t\tt.Errorf(\"inspectStringMultipleRules: %v\", err)\n+\t\tt.Fatal(err)\n \t}\n \tgot := buf.String()\n \tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {",
        "comments": [
            {
                "comment": "Please update the test name prefix to **InspectImageFileAllInfoTypes** in this method instead of _InspectBigQueryTableWithSampling_",
                "position": null
            },
            {
                "comment": "Should be inspectImageFileAllInfoTypes not BQ sampling. Please fix.",
                "position": null
            },
            {
                "comment": "Apologies, Updated it. will take care that such things doesn't happen in the future.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "86bc4b6e96da4e7c44d487f92f7293e3088c042d"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -484,7 +481,6 @@\nfunc TestInspectWithCustomRegex(t *testing.T) {\n func TestInspectStringWithExclusionDictionary(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n-\n \tif err := inspectStringWithExclusionDictionary(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, example@example.com\", []string{\"example@example.com\"}); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [
            {
                "comment": "Please update the test name prefix to **InspectImageFileAllInfoTypes** in this method instead of _InspectBigQueryTableWithSampling_",
                "position": null
            },
            {
                "comment": "Should be inspectImageFileAllInfoTypes not BQ sampling. Please fix.",
                "position": null
            },
            {
                "comment": "Apologies, Updated it. will take care that such things doesn't happen in the future.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "86bc4b6e96da4e7c44d487f92f7293e3088c042d"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -496,15 +492,11 @@\nfunc TestInspectStringWithExclusionDictionary(t *testing.T) {\n \n func TestInspectImageFile(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\n \tvar buf bytes.Buffer\n-\n \tpathToImage := \"testdata/test.png\"\n-\n \tif err := inspectImageFile(&buf, tc.ProjectID, pathToImage); err != nil {\n \t\tt.Fatal(err)\n \t}\n-\n \tgot := buf.String()\n \tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"TestInspectImageFile got %q, want %q\", got, want)",
        "comments": [
            {
                "comment": "Please update the test name prefix to **InspectImageFileAllInfoTypes** in this method instead of _InspectBigQueryTableWithSampling_",
                "position": null
            },
            {
                "comment": "Should be inspectImageFileAllInfoTypes not BQ sampling. Please fix.",
                "position": null
            },
            {
                "comment": "Apologies, Updated it. will take care that such things doesn't happen in the future.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "86bc4b6e96da4e7c44d487f92f7293e3088c042d"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -19,14 +19,18 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n+\t\"log\"\n \t\"regexp\"\n \t\"strings\"\n \t\"testing\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"cloud.google.com/go/pubsub\"\n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n )\n \n // setupPubSub creates a subscription to the given topic.",
        "comments": [
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "86bc4b6e96da4e7c44d487f92f7293e3088c042d"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -182,6 +186,132 @@\nfunc TestDeleteJob(t *testing.T) {\n \t}\n }\n \n+func TestCreateJob(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tvar buf bytes.Buffer\n+\t// createBucketForCreatJob will create a bucket and upload a txt file\n+\tbucketName, fileName, err := createBucketForCreatJob(t, tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tgcsPath := \"gs://\" + bucketName + \"/\" + fileName\n+\tinfoTypeNames := []string{\"EMAIL_ADDRESS\", \"PERSON_NAME\", \"LOCATION\", \"PHONE_NUMBER\"}\n+\n+\tif err := createJob(&buf, tc.ProjectID, gcsPath, infoTypeNames); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"Created a Dlp Job \"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"TestInspectWithCustomRegex got %q, want %q\", got, want)\n+\t}\n+\n+\tdefer deleteAssetsOfCreateJobTest(t, tc.ProjectID, bucketName, fileName)\n+}\n+\n+func createBucketForCreatJob(t *testing.T, projectID string) (string, string, error) {\n+\tt.Helper()\n+\n+\tctx := context.Background()\n+\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn \"\", \"\", err\n+\t}\n+\tdefer client.Close()\n+\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\tbucketName := \"dlp-job-go-lang-test\" + u\n+\n+\t// Check if the bucket already exists.\n+\tbucketExists := false\n+\t_, err = client.Bucket(bucketName).Attrs(ctx)\n+\tif err == nil {\n+\t\tbucketExists = true\n+\t}\n+\n+\t// If the bucket doesn't exist, create it.\n+\tif !bucketExists {\n+\t\tif err := client.Bucket(bucketName).Create(ctx, projectID, &storage.BucketAttrs{\n+\t\t\tStorageClass: \"STANDARD\",\n+\t\t\tLocation:     \"us-central1\",\n+\t\t}); err != nil {\n+\t\t\tlog.Fatalf(\"---Failed to create bucket: %v\", err)\n+\t\t}\n+\t\tfmt.Printf(\"---Bucket '%s' created successfully.\\n\", bucketName)\n+\t} else {\n+\t\tfmt.Printf(\"---Bucket '%s' already exists.\\n\", bucketName)\n+\t}\n+\n+\tfilePathToUpload := \"testdata/test.txt\"\n+\n+\t// Open local file.\n+\tfile, err := ioutil.ReadFile(filePathToUpload)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"Failed to read file: %v\", err)\n+\t}\n+\n+\t// Get a reference to the bucket\n+\tbucket := client.Bucket(bucketName)\n+\n+\t// Upload the file\n+\tu = uuid.Must(uuid.NewV4()).String()[:8]\n+\tfileName := \"test\" + u + \".txt\"\n+\tobject := bucket.Object(fileName)\n+\twriter := object.NewWriter(ctx)\n+\t_, err = writer.Write(file)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"---Failed to write file: %v\", err)\n+\t}\n+\terr = writer.Close()\n+\tif err != nil {\n+\t\tlog.Fatalf(\"---Failed to close writer: %v\", err)\n+\t}\n+\tfmt.Printf(\"---File uploaded successfully: %v\\n\", fileName)\n+\n+\t// Check if the file exists in the bucket\n+\t_, err = bucket.Object(fileName).Attrs(ctx)\n+\tif err != nil {\n+\t\tif err == storage.ErrObjectNotExist {\n+\t\t\tfmt.Printf(\"---File %v does not exist in bucket %v\\n\", fileName, bucketName)\n+\t\t} else {\n+\t\t\tlog.Fatalf(\"---Failed to check file existence: %v\", err)\n+\t\t}\n+\t} else {\n+\t\tfmt.Printf(\"---File %v exists in bucket %v\\n\", fileName, bucketName)\n+\t}\n+\n+\treturn bucketName, fileName, nil\n+}\n+\n+func deleteAssetsOfCreateJobTest(t *testing.T, projectID, bucketName, objectName string) error {\n+\tt.Helper()\n+\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\to := client.Bucket(bucketName).Object(objectName)\n+\tattrs, err := o.Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\to = o.If(storage.Conditions{GenerationMatch: attrs.Generation})\n+\n+\tif err := o.Delete(ctx); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tbucket := client.Bucket(bucketName)\n+\tif err := bucket.Delete(ctx); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\treturn nil\n+}\n+\n func TestJobsGet(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "Revert. `%w` is the correct formatting directive.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            },
            {
                "comment": "fixed it.",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "86bc4b6e96da4e7c44d487f92f7293e3088c042d"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -43,6 +43,7 @@\nvar buf bytes.Buffer\n \n // Setup for all tests\n func setupTests(t *testing.T) {\n+\tt.Helper()\n \tr = rand.New(rand.NewSource(time.Now().UnixNano()))\n \tlocation = \"us-central1\"\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "86bc4b6e96da4e7c44d487f92f7293e3088c042d"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -51,6 +52,7 @@\nfunc setupTests(t *testing.T) {\n \n // Setup and teardown functions for CA Pool\n func setupCaPool(t *testing.T) (string, func(t *testing.T)) {\n+\tt.Helper()\n \tcaPoolId := fmt.Sprintf(\"test-ca-pool-%v-%v\", time.Now().Format(\"2006-01-02\"), r.Int())\n \n \tif err := createCaPool(&buf, projectId, location, caPoolId); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "86bc4b6e96da4e7c44d487f92f7293e3088c042d"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -74,6 +76,7 @@\nfunc setupCaPool(t *testing.T) (string, func(t *testing.T)) {\n \n // Setup and teardown functions for Certificate Authority Tests\n func setupCa(t *testing.T, caPoolId string, autoEnable bool) (string, func(t *testing.T)) {\n+\tt.Helper()\n \tcaId := fmt.Sprintf(\"test-ca-%v-%v\", time.Now().Format(\"2006-01-02\"), r.Int())\n \tcaCommonName := fmt.Sprintf(\"CN - %s\", caId)\n \torg := \"ORGANIZATION\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "86bc4b6e96da4e7c44d487f92f7293e3088c042d"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image all infotypes",
        "pr_number": 3120,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -143,6 +146,7 @@\nfunc deleteCaPerm(projectID string, location string, caPoolId string, caId strin\n \n // Setup and teardown functions for Certifcate tests\n func setupCertificate(t *testing.T, caPoolId string, caId string) (string, func(t *testing.T)) {\n+\tt.Helper()\n \tcertId := fmt.Sprintf(\"test-certificate-%v-%v\", time.Now().Format(\"2006-01-02\"), r.Int())\n \tcommonName := fmt.Sprintf(\"CN - %s\", certId)\n \tdomainName := \"cert2.example.com\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_all_infotypes",
        "commit_id": "86bc4b6e96da4e7c44d487f92f7293e3088c042d"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image listed info types",
        "pr_number": 3119,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -19,14 +19,18 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n+\t\"log\"\n \t\"regexp\"\n \t\"strings\"\n \t\"testing\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"cloud.google.com/go/pubsub\"\n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n )\n \n // setupPubSub creates a subscription to the given topic.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_listed_infotypes",
        "commit_id": "cced9ac0d355be1f322c01d9c06b29f48e94cc38"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image listed info types",
        "pr_number": 3119,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -182,6 +186,132 @@\nfunc TestDeleteJob(t *testing.T) {\n \t}\n }\n \n+func TestCreateJob(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tvar buf bytes.Buffer\n+\t// createBucketForCreatJob will create a bucket and upload a txt file\n+\tbucketName, fileName, err := createBucketForCreatJob(t, tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tgcsPath := \"gs://\" + bucketName + \"/\" + fileName\n+\tinfoTypeNames := []string{\"EMAIL_ADDRESS\", \"PERSON_NAME\", \"LOCATION\", \"PHONE_NUMBER\"}\n+\n+\tif err := createJob(&buf, tc.ProjectID, gcsPath, infoTypeNames); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"Created a Dlp Job \"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"TestInspectWithCustomRegex got %q, want %q\", got, want)\n+\t}\n+\n+\tdefer deleteAssetsOfCreateJobTest(t, tc.ProjectID, bucketName, fileName)\n+}\n+\n+func createBucketForCreatJob(t *testing.T, projectID string) (string, string, error) {\n+\tt.Helper()\n+\n+\tctx := context.Background()\n+\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn \"\", \"\", err\n+\t}\n+\tdefer client.Close()\n+\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\tbucketName := \"dlp-job-go-lang-test\" + u\n+\n+\t// Check if the bucket already exists.\n+\tbucketExists := false\n+\t_, err = client.Bucket(bucketName).Attrs(ctx)\n+\tif err == nil {\n+\t\tbucketExists = true\n+\t}\n+\n+\t// If the bucket doesn't exist, create it.\n+\tif !bucketExists {\n+\t\tif err := client.Bucket(bucketName).Create(ctx, projectID, &storage.BucketAttrs{\n+\t\t\tStorageClass: \"STANDARD\",\n+\t\t\tLocation:     \"us-central1\",\n+\t\t}); err != nil {\n+\t\t\tlog.Fatalf(\"---Failed to create bucket: %v\", err)\n+\t\t}\n+\t\tfmt.Printf(\"---Bucket '%s' created successfully.\\n\", bucketName)\n+\t} else {\n+\t\tfmt.Printf(\"---Bucket '%s' already exists.\\n\", bucketName)\n+\t}\n+\n+\tfilePathToUpload := \"testdata/test.txt\"\n+\n+\t// Open local file.\n+\tfile, err := ioutil.ReadFile(filePathToUpload)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"Failed to read file: %v\", err)\n+\t}\n+\n+\t// Get a reference to the bucket\n+\tbucket := client.Bucket(bucketName)\n+\n+\t// Upload the file\n+\tu = uuid.Must(uuid.NewV4()).String()[:8]\n+\tfileName := \"test\" + u + \".txt\"\n+\tobject := bucket.Object(fileName)\n+\twriter := object.NewWriter(ctx)\n+\t_, err = writer.Write(file)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"---Failed to write file: %v\", err)\n+\t}\n+\terr = writer.Close()\n+\tif err != nil {\n+\t\tlog.Fatalf(\"---Failed to close writer: %v\", err)\n+\t}\n+\tfmt.Printf(\"---File uploaded successfully: %v\\n\", fileName)\n+\n+\t// Check if the file exists in the bucket\n+\t_, err = bucket.Object(fileName).Attrs(ctx)\n+\tif err != nil {\n+\t\tif err == storage.ErrObjectNotExist {\n+\t\t\tfmt.Printf(\"---File %v does not exist in bucket %v\\n\", fileName, bucketName)\n+\t\t} else {\n+\t\t\tlog.Fatalf(\"---Failed to check file existence: %v\", err)\n+\t\t}\n+\t} else {\n+\t\tfmt.Printf(\"---File %v exists in bucket %v\\n\", fileName, bucketName)\n+\t}\n+\n+\treturn bucketName, fileName, nil\n+}\n+\n+func deleteAssetsOfCreateJobTest(t *testing.T, projectID, bucketName, objectName string) error {\n+\tt.Helper()\n+\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\to := client.Bucket(bucketName).Object(objectName)\n+\tattrs, err := o.Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\to = o.If(storage.Conditions{GenerationMatch: attrs.Generation})\n+\n+\tif err := o.Delete(ctx); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tbucket := client.Bucket(bucketName)\n+\tif err := bucket.Delete(ctx); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\treturn nil\n+}\n+\n func TestJobsGet(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_listed_infotypes",
        "commit_id": "cced9ac0d355be1f322c01d9c06b29f48e94cc38"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image listed info types",
        "pr_number": 3119,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -43,6 +43,7 @@\nvar buf bytes.Buffer\n \n // Setup for all tests\n func setupTests(t *testing.T) {\n+\tt.Helper()\n \tr = rand.New(rand.NewSource(time.Now().UnixNano()))\n \tlocation = \"us-central1\"\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_listed_infotypes",
        "commit_id": "cced9ac0d355be1f322c01d9c06b29f48e94cc38"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image listed info types",
        "pr_number": 3119,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -51,6 +52,7 @@\nfunc setupTests(t *testing.T) {\n \n // Setup and teardown functions for CA Pool\n func setupCaPool(t *testing.T) (string, func(t *testing.T)) {\n+\tt.Helper()\n \tcaPoolId := fmt.Sprintf(\"test-ca-pool-%v-%v\", time.Now().Format(\"2006-01-02\"), r.Int())\n \n \tif err := createCaPool(&buf, projectId, location, caPoolId); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_listed_infotypes",
        "commit_id": "cced9ac0d355be1f322c01d9c06b29f48e94cc38"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image listed info types",
        "pr_number": 3119,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -74,6 +76,7 @@\nfunc setupCaPool(t *testing.T) (string, func(t *testing.T)) {\n \n // Setup and teardown functions for Certificate Authority Tests\n func setupCa(t *testing.T, caPoolId string, autoEnable bool) (string, func(t *testing.T)) {\n+\tt.Helper()\n \tcaId := fmt.Sprintf(\"test-ca-%v-%v\", time.Now().Format(\"2006-01-02\"), r.Int())\n \tcaCommonName := fmt.Sprintf(\"CN - %s\", caId)\n \torg := \"ORGANIZATION\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_listed_infotypes",
        "commit_id": "cced9ac0d355be1f322c01d9c06b29f48e94cc38"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image listed info types",
        "pr_number": 3119,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -143,6 +146,7 @@\nfunc deleteCaPerm(projectID string, location string, caPoolId string, caId strin\n \n // Setup and teardown functions for Certifcate tests\n func setupCertificate(t *testing.T, caPoolId string, caId string) (string, func(t *testing.T)) {\n+\tt.Helper()\n \tcertId := fmt.Sprintf(\"test-certificate-%v-%v\", time.Now().Format(\"2006-01-02\"), r.Int())\n \tcommonName := fmt.Sprintf(\"CN - %s\", certId)\n \tdomainName := \"cert2.example.com\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_image_listed_infotypes",
        "commit_id": "cced9ac0d355be1f322c01d9c06b29f48e94cc38"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp create job",
        "pr_number": 3096,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -43,6 +43,7 @@\nvar buf bytes.Buffer\n \n // Setup for all tests\n func setupTests(t *testing.T) {\n+\tt.Helper()\n \tr = rand.New(rand.NewSource(time.Now().UnixNano()))\n \tlocation = \"us-central1\"\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_create_job",
        "commit_id": "a6dafeb83b6c4fffc0e998ce12bfe084bc3835ab"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp create job",
        "pr_number": 3096,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -51,6 +52,7 @@\nfunc setupTests(t *testing.T) {\n \n // Setup and teardown functions for CA Pool\n func setupCaPool(t *testing.T) (string, func(t *testing.T)) {\n+\tt.Helper()\n \tcaPoolId := fmt.Sprintf(\"test-ca-pool-%v-%v\", time.Now().Format(\"2006-01-02\"), r.Int())\n \n \tif err := createCaPool(&buf, projectId, location, caPoolId); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_create_job",
        "commit_id": "a6dafeb83b6c4fffc0e998ce12bfe084bc3835ab"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp create job",
        "pr_number": 3096,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -74,6 +76,7 @@\nfunc setupCaPool(t *testing.T) (string, func(t *testing.T)) {\n \n // Setup and teardown functions for Certificate Authority Tests\n func setupCa(t *testing.T, caPoolId string, autoEnable bool) (string, func(t *testing.T)) {\n+\tt.Helper()\n \tcaId := fmt.Sprintf(\"test-ca-%v-%v\", time.Now().Format(\"2006-01-02\"), r.Int())\n \tcaCommonName := fmt.Sprintf(\"CN - %s\", caId)\n \torg := \"ORGANIZATION\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_create_job",
        "commit_id": "a6dafeb83b6c4fffc0e998ce12bfe084bc3835ab"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp create job",
        "pr_number": 3096,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -143,6 +146,7 @@\nfunc deleteCaPerm(projectID string, location string, caPoolId string, caId strin\n \n // Setup and teardown functions for Certifcate tests\n func setupCertificate(t *testing.T, caPoolId string, caId string) (string, func(t *testing.T)) {\n+\tt.Helper()\n \tcertId := fmt.Sprintf(\"test-certificate-%v-%v\", time.Now().Format(\"2006-01-02\"), r.Int())\n \tcommonName := fmt.Sprintf(\"CN - %s\", certId)\n \tdomainName := \"cert2.example.com\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_create_job",
        "commit_id": "a6dafeb83b6c4fffc0e998ce12bfe084bc3835ab"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "datacatalog/snippets/policytagmanager/create_policytag.go",
        "code_diff": "@@ -35,7 +35,7 @@\nfunc createPolicyTag(w io.Writer, parent, displayName, parentPolicyTag string) (\n \tctx := context.Background()\n \tpolicyClient, err := datacatalog.NewPolicyTagManagerClient(ctx)\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %v\", err)\n+\t\treturn \"\", fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %w\", err)\n \t}\n \tdefer policyClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "datacatalog/snippets/policytagmanager/create_taxonomy.go",
        "code_diff": "@@ -35,7 +35,7 @@\nfunc createTaxonomy(w io.Writer, projectID, location, displayName string) (strin\n \tctx := context.Background()\n \tpolicyClient, err := datacatalog.NewPolicyTagManagerClient(ctx)\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %v\", err)\n+\t\treturn \"\", fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %w\", err)\n \t}\n \tdefer policyClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "datacatalog/snippets/policytagmanager/get_iam_policy.go",
        "code_diff": "@@ -32,7 +32,7 @@\nfunc getIAMPolicy(w io.Writer, resourceID string) error {\n \tctx := context.Background()\n \tpolicyClient, err := datacatalog.NewPolicyTagManagerClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %v\", err)\n+\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %w\", err)\n \t}\n \tdefer policyClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "datacatalog/snippets/policytagmanager/get_policytag.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc getPolicyTag(w io.Writer, policyTagID string) error {\n \tctx := context.Background()\n \tpolicyClient, err := datacatalog.NewPolicyTagManagerClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %v\", err)\n+\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %w\", err)\n \t}\n \tdefer policyClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "datacatalog/snippets/policytagmanager/get_taxonomy.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc getTaxonomy(w io.Writer, taxonomyID string) error {\n \tctx := context.Background()\n \tpolicyClient, err := datacatalog.NewPolicyTagManagerClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %v\", err)\n+\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %w\", err)\n \t}\n \tdefer policyClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "datacatalog/snippets/policytagmanager/list_policytags.go",
        "code_diff": "@@ -32,7 +32,7 @@\nfunc listPolicyTags(w io.Writer, parentTaxonomyID string) error {\n \tctx := context.Background()\n \tpolicyClient, err := datacatalog.NewPolicyTagManagerClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %v\", err)\n+\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %w\", err)\n \t}\n \tdefer policyClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "datacatalog/snippets/policytagmanager/list_taxonomies.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc listTaxonomies(w io.Writer, projectID, location string) error {\n \tctx := context.Background()\n \tpolicyClient, err := datacatalog.NewPolicyTagManagerClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %v\", err)\n+\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %w\", err)\n \t}\n \tdefer policyClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "datacatalog/snippets/policytagmanager/set_iam_policy.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc setIAMPolicy(w io.Writer, resourceID, member string) error {\n \tctx := context.Background()\n \tpolicyClient, err := datacatalog.NewPolicyTagManagerClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %v\", err)\n+\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %w\", err)\n \t}\n \tdefer policyClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "datacatalog/snippets/policytagmanager/set_iam_policy.go",
        "code_diff": "@@ -46,7 +46,7 @@\nfunc setIAMPolicy(w io.Writer, resourceID, member string) error {\n \t}\n \tpolicy, err := policyClient.GetIamPolicy(ctx, req)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"GetIamPolicy: %v\", err)\n+\t\treturn fmt.Errorf(\"GetIamPolicy: %w\", err)\n \t}\n \n \t// Alter the policy to add an additional binding.",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "datacatalog/snippets/policytagmanager/test_iam_permissions.go",
        "code_diff": "@@ -32,7 +32,7 @@\nfunc testIAMPermissions(w io.Writer, resourceID string, permissions []string) er\n \tctx := context.Background()\n \tpolicyClient, err := datacatalog.NewPolicyTagManagerClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %v\", err)\n+\t\treturn fmt.Errorf(\"datacatalog.NewPolicyTagManagerClient: %w\", err)\n \t}\n \tdefer policyClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "storagetransfer/check_latest_transfer_operation.go",
        "code_diff": "@@ -34,7 +34,7 @@\nfunc checkLatestTransferOperation(w io.Writer, projectID string, jobName string)\n \tctx := context.Background()\n \tclient, err := storagetransfer.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "storagetransfer/check_latest_transfer_operation.go",
        "code_diff": "@@ -43,7 +43,7 @@\nfunc checkLatestTransferOperation(w io.Writer, projectID string, jobName string)\n \t\tProjectId: projectID,\n \t})\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"failed to get transfer job: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"failed to get transfer job: %w\", err)\n \t}\n \n \tlatestOpName := job.LatestOperationName",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "storagetransfer/download_to_posix.go",
        "code_diff": "@@ -46,7 +46,7 @@\nfunc downloadToPosix(w io.Writer, projectID string, sinkAgentPoolName string, gc\n \tctx := context.Background()\n \tclient, err := storagetransfer.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "storagetransfer/quickstart.go",
        "code_diff": "@@ -37,7 +37,7 @@\nfunc quickstart(w io.Writer, projectID string, sourceGCSBucket string, sinkGCSBu\n \tctx := context.Background()\n \tclient, err := storagetransfer.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "storagetransfer/transfer_between_posix.go",
        "code_diff": "@@ -47,7 +47,7 @@\nfunc transferBetweenPosix(w io.Writer, projectID string, sourceAgentPoolName str\n \tctx := context.Background()\n \tclient, err := storagetransfer.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "storagetransfer/transfer_from_aws.go",
        "code_diff": "@@ -41,7 +41,7 @@\nfunc transferFromAws(w io.Writer, projectID string, awsSourceBucket string, gcsS\n \tctx := context.Background()\n \tclient, err := storagetransfer.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "storagetransfer/transfer_from_azure.go",
        "code_diff": "@@ -41,7 +41,7 @@\nfunc transferFromAzure(w io.Writer, projectID string, azureStorageAccountName st\n \tctx := context.Background()\n \tclient, err := storagetransfer.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "storagetransfer/transfer_from_posix.go",
        "code_diff": "@@ -41,7 +41,7 @@\nfunc transferFromPosix(w io.Writer, projectID string, sourceAgentPoolName string\n \tctx := context.Background()\n \tclient, err := storagetransfer.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "storagetransfer/transfer_from_s3_compatible_source.go",
        "code_diff": "@@ -62,7 +62,7 @@\nfunc transferFromS3CompatibleSource(w io.Writer, projectID string, sourceAgentPo\n \tctx := context.Background()\n \tclient, err := storagetransfer.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "storagetransfer/transfer_to_nearline.go",
        "code_diff": "@@ -42,7 +42,7 @@\nfunc transferToNearline(w io.Writer, projectID string, gcsSourceBucket string, g\n \tctx := context.Background()\n \tclient, err := storagetransfer.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "refactor(firestore): Split firestore/save.go samples to separate file, widen region tags",
        "pr_number": 3070,
        "file_name": "storagetransfer/transfer_using_manifest.go",
        "code_diff": "@@ -47,7 +47,7 @@\nfunc transferUsingManifest(w io.Writer, projectID string, sourceAgentPoolName st\n \tctx := context.Background()\n \tclient, err := storagetransfer.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"storagetransfer.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into split-firestore-save-pt1",
        "commit_id": "d5e7aadec34dc821a73433b336c27dfc9c873747"
    },
    {
        "pr_title": "feat(fixit): Adding privateca/ca_pool samples",
        "pr_number": 3068,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -36,15 +36,15 @@\nfunc readRow(w io.Writer, projectID, instanceID string, tableName string) error\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n \ttbl := client.Open(tableName)\n \trowKey := \"phone#4c410523#20190501\"\n \trow, err := tbl.ReadRow(ctx, rowKey)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"could not read row with key %s: %v\", rowKey, err)\n+\t\treturn fmt.Errorf(\"could not read row with key %s: %w\", rowKey, err)\n \t}\n \n \tprintRow(w, row)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fixit-newsamples-capool",
        "commit_id": "ef5693a0f0a0519658ebd42e08a7c255b5bc07e4"
    },
    {
        "pr_title": "feat(fixit): Adding privateca/ca_pool samples",
        "pr_number": 3068,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -62,15 +62,15 @@\nfunc readRowPartial(w io.Writer, projectID, instanceID string, tableName string)\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n \ttbl := client.Open(tableName)\n \trowKey := \"phone#4c410523#20190501\"\n \trow, err := tbl.ReadRow(ctx, rowKey, bigtable.RowFilter(bigtable.ColumnFilter(\"os_build\")))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"could not read row with key %s: %v\", rowKey, err)\n+\t\treturn fmt.Errorf(\"could not read row with key %s: %w\", rowKey, err)\n \t}\n \n \tprintRow(w, row)",
        "comments": [],
        "commit_message": "Merge branch 'main' into fixit-newsamples-capool",
        "commit_id": "ef5693a0f0a0519658ebd42e08a7c255b5bc07e4"
    },
    {
        "pr_title": "feat(fixit): Adding privateca/ca_pool samples",
        "pr_number": 3068,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -89,7 +89,7 @@\nfunc readRows(w io.Writer, projectID, instanceID string, tableName string) error\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into fixit-newsamples-capool",
        "commit_id": "ef5693a0f0a0519658ebd42e08a7c255b5bc07e4"
    },
    {
        "pr_title": "feat(fixit): Adding privateca/ca_pool samples",
        "pr_number": 3068,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -101,7 +101,7 @@\nfunc readRows(w io.Writer, projectID, instanceID string, tableName string) error\n \t\t},\n \t)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"tbl.ReadRows: %v\", err)\n+\t\treturn fmt.Errorf(\"tbl.ReadRows: %w\", err)\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'main' into fixit-newsamples-capool",
        "commit_id": "ef5693a0f0a0519658ebd42e08a7c255b5bc07e4"
    },
    {
        "pr_title": "feat(fixit): Adding privateca/ca_pool samples",
        "pr_number": 3068,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -118,7 +118,7 @@\nfunc readRowRange(w io.Writer, projectID, instanceID string, tableName string) e\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into fixit-newsamples-capool",
        "commit_id": "ef5693a0f0a0519658ebd42e08a7c255b5bc07e4"
    },
    {
        "pr_title": "feat(fixit): Adding privateca/ca_pool samples",
        "pr_number": 3068,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -131,7 +131,7 @@\nfunc readRowRange(w io.Writer, projectID, instanceID string, tableName string) e\n \t)\n \n \tif err != nil {\n-\t\treturn fmt.Errorf(\"tbl.ReadRows: %v\", err)\n+\t\treturn fmt.Errorf(\"tbl.ReadRows: %w\", err)\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'main' into fixit-newsamples-capool",
        "commit_id": "ef5693a0f0a0519658ebd42e08a7c255b5bc07e4"
    },
    {
        "pr_title": "feat(fixit): Adding privateca/ca_pool samples",
        "pr_number": 3068,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -148,7 +148,7 @@\nfunc readRowRanges(w io.Writer, projectID, instanceID string, tableName string)\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into fixit-newsamples-capool",
        "commit_id": "ef5693a0f0a0519658ebd42e08a7c255b5bc07e4"
    },
    {
        "pr_title": "feat(fixit): Adding privateca/ca_pool samples",
        "pr_number": 3068,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -163,7 +163,7 @@\nfunc readRowRanges(w io.Writer, projectID, instanceID string, tableName string)\n \t\t},\n \t)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"tbl.ReadRows: %v\", err)\n+\t\treturn fmt.Errorf(\"tbl.ReadRows: %w\", err)\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'main' into fixit-newsamples-capool",
        "commit_id": "ef5693a0f0a0519658ebd42e08a7c255b5bc07e4"
    },
    {
        "pr_title": "feat(fixit): Adding privateca/ca_pool samples",
        "pr_number": 3068,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -180,7 +180,7 @@\nfunc readPrefix(w io.Writer, projectID, instanceID string, tableName string) err\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into fixit-newsamples-capool",
        "commit_id": "ef5693a0f0a0519658ebd42e08a7c255b5bc07e4"
    },
    {
        "pr_title": "feat(fixit): Adding privateca/ca_pool samples",
        "pr_number": 3068,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -192,7 +192,7 @@\nfunc readPrefix(w io.Writer, projectID, instanceID string, tableName string) err\n \t\t},\n \t)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"tbl.ReadRows: %v\", err)\n+\t\treturn fmt.Errorf(\"tbl.ReadRows: %w\", err)\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'main' into fixit-newsamples-capool",
        "commit_id": "ef5693a0f0a0519658ebd42e08a7c255b5bc07e4"
    },
    {
        "pr_title": "feat(fixit): Adding privateca/ca_pool samples",
        "pr_number": 3068,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -209,7 +209,7 @@\nfunc readFilter(w io.Writer, projectID, instanceID string, tableName string) err\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into fixit-newsamples-capool",
        "commit_id": "ef5693a0f0a0519658ebd42e08a7c255b5bc07e4"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -138,7 +138,7 @@\nfunc deleteInstance(t *testing.T, ctx context.Context, projectId, zone, instance\n \tt.Helper()\n \tinstancesClient, err := compute.NewInstancesRESTClient(ctx)\n \tif err != nil {\n-\t\tt.Errorf(\"NewInstancesRESTClient: %v\", err)\n+\t\tt.Fatalf(\"NewInstancesRESTClient: %v\", err)\n \t}\n \tdefer instancesClient.Close()",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -171,12 +171,12 @@\nfunc deleteInstance(t *testing.T, ctx context.Context, projectId, zone, instance\n \n \top, err := instancesClient.Delete(ctx, req)\n \tif err != nil {\n-\t\tt.Error(\"instanceClient.Delete err\", err)\n+\t\tt.Errorf(\"instanceClient.Delete: %v\", err)\n \t}\n \n \terr = op.Wait(ctx)\n \tif err != nil {\n-\t\tt.Error(\"instanceClient.Delete err\", err)\n+\t\tt.Errorf(\"instanceClient.Delete: %v\", err)\n \t}\n }",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -217,12 +217,12 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \tdefer instancesClient.Close()\n \n \t// Create a snapshot before we run the actual tests\n-\tbuf := &bytes.Buffer{}\n-\terr = createDiskFromImage(buf, tc.ProjectID, zone, diskName, diskType, sourceImage, 50)\n+\tvar buf bytes.Buffer\n+\terr = createDiskFromImage(&buf, tc.ProjectID, zone, diskName, diskType, sourceImage, 50)\n \tif err != nil {\n \t\tt.Fatalf(\"createDiskFromImage got err: %v\", err)\n \t}\n-\tdefer deleteDisk(buf, tc.ProjectID, zone, diskName)\n+\tdefer deleteDisk(&buf, tc.ProjectID, zone, diskName)\n \n \terr = createDiskSnapshot(ctx, tc.ProjectID, zone, diskName, snapshotName)\n \tif err != nil {",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -239,10 +239,10 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \n \tt.Run(\"Create and delete zonal disk from a snapshot\", func(t *testing.T) {\n \t\tzonalDiskName := fmt.Sprintf(\"test-zonal-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n-\t\tbuf := &bytes.Buffer{}\n+\t\tvar buf bytes.Buffer\n \t\twant := \"Disk created\"\n \n-\t\tif err := createDiskFromSnapshot(buf, tc.ProjectID, zone, zonalDiskName, diskType, diskSnapshotLink, 50); err != nil {\n+\t\tif err := createDiskFromSnapshot(&buf, tc.ProjectID, zone, zonalDiskName, diskType, diskSnapshotLink, 50); err != nil {\n \t\t\tt.Errorf(\"createDiskFromSnapshot got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -252,7 +252,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\tbuf.Reset()\n \t\twant = \"Disk deleted\"\n \n-\t\tif err := deleteDisk(buf, tc.ProjectID, zone, zonalDiskName); err != nil {\n+\t\tif err := deleteDisk(&buf, tc.ProjectID, zone, zonalDiskName); err != nil {\n \t\t\terrorIfNot404(t, \"deleteDisk\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -262,10 +262,10 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \n \tt.Run(\"Create and delete a regional disk from a snapshot\", func(t *testing.T) {\n \t\tregionalDiskName := fmt.Sprintf(\"test-regional-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n-\t\tbuf := &bytes.Buffer{}\n+\t\tvar buf bytes.Buffer\n \t\twant := \"Disk created\"\n \n-\t\tif err := createRegionalDiskFromSnapshot(buf, tc.ProjectID, region, replicaZones, regionalDiskName, diskType, diskSnapshotLink, 50); err != nil {\n+\t\tif err := createRegionalDiskFromSnapshot(&buf, tc.ProjectID, region, replicaZones, regionalDiskName, diskType, diskSnapshotLink, 50); err != nil {\n \t\t\tt.Errorf(\"createRegionalDiskFromSnapshot got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -275,7 +275,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\tbuf.Reset()\n \t\twant = \"Disk deleted\"\n \n-\t\terr = deleteRegionalDisk(buf, tc.ProjectID, region, regionalDiskName)\n+\t\terr = deleteRegionalDisk(&buf, tc.ProjectID, region, regionalDiskName)\n \t\tif err != nil {\n \t\t\terrorIfNot404(t, \"deleteRegionalDisk\", err)\n \t\t}",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -286,10 +286,10 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \n \tt.Run(\"Create and resize a regional disk\", func(t *testing.T) {\n \t\tregionalDiskName := fmt.Sprintf(\"test-regional-resize-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n-\t\tbuf := &bytes.Buffer{}\n+\t\tvar buf bytes.Buffer\n \t\twant := \"Disk created\"\n \n-\t\tif err := createRegionalDisk(buf, tc.ProjectID, region, replicaZones, regionalDiskName, diskType, 20); err != nil {\n+\t\tif err := createRegionalDisk(&buf, tc.ProjectID, region, replicaZones, regionalDiskName, diskType, 20); err != nil {\n \t\t\tt.Errorf(\"createRegionalDisk got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -299,7 +299,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\tbuf.Reset()\n \t\twant = \"Disk resized\"\n \n-\t\tresizeRegionalDisk(buf, tc.ProjectID, region, regionalDiskName, 50)\n+\t\tresizeRegionalDisk(&buf, tc.ProjectID, region, regionalDiskName, 50)\n \t\tif err != nil {\n \t\t\tt.Errorf(\"resizeRegionalDisk got err: %v\", err)\n \t\t}",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -311,7 +311,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\twant = \"Disk deleted\"\n \n \t\t// clean up\n-\t\terr = deleteRegionalDisk(buf, tc.ProjectID, region, regionalDiskName)\n+\t\terr = deleteRegionalDisk(&buf, tc.ProjectID, region, regionalDiskName)\n \t\tif err != nil {\n \t\t\terrorIfNot404(t, \"deleteRegionalDisk\", err)\n \t\t}",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -321,22 +321,22 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\tzonalDiskName := fmt.Sprintf(\"test-zonal-clone-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \t\tsourceDisk := fmt.Sprintf(\"projects/%s/zones/europe-west2-b/disks/%s\", tc.ProjectID, zonalDiskName)\n \t\tregionalDiskName := fmt.Sprintf(\"test-regional-clone-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n-\t\tbuf := &bytes.Buffer{}\n+\t\tvar buf bytes.Buffer\n \t\twant := \"Disk created\"\n \n-\t\tif err := createEmptyDisk(buf, tc.ProjectID, zone, zonalDiskName, diskType, 20); err != nil {\n+\t\tif err := createEmptyDisk(&buf, tc.ProjectID, zone, zonalDiskName, diskType, 20); err != nil {\n \t\t\tt.Fatalf(\"createEmptyDisk got err: %v\", err)\n \t\t}\n-\t\tdefer deleteDisk(buf, tc.ProjectID, zone, zonalDiskName)\n+\t\tdefer deleteDisk(&buf, tc.ProjectID, zone, zonalDiskName)\n \n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createEmptyDisk got %q, want %q\", got, want)\n \t\t}\n \n-\t\tif err := createRegionalDiskFromDisk(buf, tc.ProjectID, region, replicaZones, regionalDiskName, diskType, sourceDisk, 30); err != nil {\n+\t\tif err := createRegionalDiskFromDisk(&buf, tc.ProjectID, region, replicaZones, regionalDiskName, diskType, sourceDisk, 30); err != nil {\n \t\t\tt.Fatalf(\"createRegionalDiskFromDisk got err: %v\", err)\n \t\t}\n-\t\tdefer deleteRegionalDisk(buf, tc.ProjectID, region, regionalDiskName)\n+\t\tdefer deleteRegionalDisk(&buf, tc.ProjectID, region, regionalDiskName)\n \n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createRegionalDiskFromDisk got %q, want %q\", got, want)",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -347,22 +347,22 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\tencDiskName1 := fmt.Sprintf(\"test-enc-disk1-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \t\tsourceDisk := fmt.Sprintf(\"projects/%s/zones/europe-west2-b/disks/%s\", tc.ProjectID, encDiskName1)\n \t\tencDiskName2 := fmt.Sprintf(\"test-enc-disk2-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n-\t\tbuf := &bytes.Buffer{}\n+\t\tvar buf bytes.Buffer\n \t\twant := \"Disk created\"\n \n-\t\tif err := createEncryptedDisk(buf, tc.ProjectID, zone, encDiskName1, diskType, 20, \"SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=\", \"\", \"\", \"\"); err != nil {\n+\t\tif err := createEncryptedDisk(&buf, tc.ProjectID, zone, encDiskName1, diskType, 20, \"SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=\", \"\", \"\", \"\"); err != nil {\n \t\t\tt.Fatalf(\"createEncryptedDisk got err: %v\", err)\n \t\t}\n-\t\tdefer deleteDisk(buf, tc.ProjectID, zone, encDiskName1)\n+\t\tdefer deleteDisk(&buf, tc.ProjectID, zone, encDiskName1)\n \n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createEncryptedDisk got %q, want %q\", got, want)\n \t\t}\n \n-\t\tif err := createDiskFromCustomerEncryptedDisk(buf, tc.ProjectID, zone, encDiskName2, diskType, 20, sourceDisk, \"SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=\"); err != nil {\n+\t\tif err := createDiskFromCustomerEncryptedDisk(&buf, tc.ProjectID, zone, encDiskName2, diskType, 20, sourceDisk, \"SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=\"); err != nil {\n \t\t\tt.Fatalf(\"createDiskFromCustomerEncryptedDisk got err: %v\", err)\n \t\t}\n-\t\tdefer deleteDisk(buf, tc.ProjectID, zone, encDiskName2)\n+\t\tdefer deleteDisk(&buf, tc.ProjectID, zone, encDiskName2)\n \n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createDiskFromCustomerEncryptedDisk got %q, want %q\", got, want)",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -373,7 +373,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\tbuf.Reset()\n \t\twant := \"disk autoDelete field updated.\"\n \n-\t\tif err := setDiskAutoDelete(buf, tc.ProjectID, zone, instanceName, instanceDiskName, true); err != nil {\n+\t\tif err := setDiskAutoDelete(&buf, tc.ProjectID, zone, instanceName, instanceDiskName, true); err != nil {\n \t\t\tt.Fatalf(\"setDiskAutodelete got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -393,7 +393,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \tt.Run(\"Attach a regional disk to VM\", func(t *testing.T) {\n \t\tinstanceRegionalDiskName := fmt.Sprintf(\"test-attach-rw-instance-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \n-\t\tif err := createRegionalDisk(buf, tc.ProjectID, region, replicaZones, instanceRegionalDiskName, \"regions/us-west3/diskTypes/pd-ssd\", 20); err != nil {\n+\t\tif err := createRegionalDisk(&buf, tc.ProjectID, region, replicaZones, instanceRegionalDiskName, \"regions/us-west3/diskTypes/pd-ssd\", 20); err != nil {\n \t\t\tt.Fatalf(\"createRegionalDisk got err: %v\", err)\n \t\t}",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -402,7 +402,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \n \t\tdiskUrl := fmt.Sprintf(\"projects/%s/regions/%s/disks/%s\", tc.ProjectID, region, instanceRegionalDiskName)\n \n-\t\tif err := attachRegionalDisk(buf, tc.ProjectID, zone, instanceName, diskUrl); err != nil {\n+\t\tif err := attachRegionalDisk(&buf, tc.ProjectID, zone, instanceName, diskUrl); err != nil {\n \t\t\tt.Fatalf(\"attachRegionalDisk got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -424,13 +424,14 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\t\tt.Errorf(\"The disk %s is not attached to the instance!\", instanceRegionalDiskName)\n \t\t}\n \n-\t\t// cannot clean up the disk just yet because it must be done after the VM is terminated - will be done in deleteInstance function\n+\t\t// Cannot clean up the disk just yet because it must be done after the VM is terminated.\n+\t\t// It will be done by deleteInstance function.\n \t})\n \n \tt.Run(\"Attach a read-only regional disk to VM\", func(t *testing.T) {\n \t\tinstanceRegionalDiskName := fmt.Sprintf(\"test-attach-ro-instance-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \n-\t\tif err := createRegionalDisk(buf, tc.ProjectID, region, replicaZones, instanceRegionalDiskName, \"regions/us-west3/diskTypes/pd-ssd\", 20); err != nil {\n+\t\tif err := createRegionalDisk(&buf, tc.ProjectID, region, replicaZones, instanceRegionalDiskName, \"regions/us-west3/diskTypes/pd-ssd\", 20); err != nil {\n \t\t\tt.Fatalf(\"createRegionalDisk got err: %v\", err)\n \t\t}",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -439,7 +440,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \n \t\tdiskUrl := fmt.Sprintf(\"projects/%s/regions/%s/disks/%s\", tc.ProjectID, region, instanceRegionalDiskName)\n \n-\t\tif err := attachRegionalDiskReadOnly(buf, tc.ProjectID, zone, instanceName, diskUrl); err != nil {\n+\t\tif err := attachRegionalDiskReadOnly(&buf, tc.ProjectID, zone, instanceName, diskUrl); err != nil {\n \t\t\tt.Fatalf(\"attachRegionalDisk got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {",
        "comments": [
            {
                "comment": "I would replace with `t.Fatalf()`--if you can't instantiate a client, then all the rest of the samples fail.",
                "position": null
            },
            {
                "comment": "question: did you intend to use a formatting string here? ",
                "position": null
            },
            {
                "comment": "Same as above. I think this will print out the first string then the second string (without any space). Let's explicitly use a formatting string instead.",
                "position": null
            },
            {
                "comment": "issue: declare an empty buffer like so:\r\n\r\n```\r\nvar *bytes.Buffer\r\n```",
                "position": null
            },
            {
                "comment": "issue: insert line break. This comment is too long for a single line.",
                "position": null
            },
            {
                "comment": "Same as above. Split this into two lines.",
                "position": null
            },
            {
                "comment": "It actually has to be:\r\n```\r\nvar buf bytes.Buffer\r\n```\r\n\r\nAnd then whenever I call the function which needs pointer I need to use `&buf`. Let me know if I'm doing something wrong.",
                "position": null
            },
            {
                "comment": "Yep, that's fine.",
                "position": null
            }
        ],
        "commit_message": "Addressing review comments",
        "commit_id": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "feat(asset): Add sample code for Org Policy Analyzer",
        "pr_number": 3021,
        "file_name": "asset/quickstart/analyze-org-policy-governed-assets/analyze_org_policy_governed_assets.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc analyzeOrgPolicyGovernedAssets(w io.Writer, scope string, constraint string\n \tctx := context.Background()\n \tclient, err := asset.NewClient(ctx)\n \tif err != nil {\n-\t\treturn err;\n+\t\treturn err\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "fix lint",
        "commit_id": "db555c3f66b1cf81567dd054eeabf7236f8ba20f"
    },
    {
        "pr_title": "chore(appengine): move region tags to include the full function",
        "pr_number": 3019,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -111,8 +111,8 @@\nfunc TestDeIdentifyWithRedact(t *testing.T) {\n \twant := \"output: My name is Alicia Abernathy, and my email address is .\"\n \n \tvar buf bytes.Buffer\n-\terr := deidentifyWithRedact(&buf, tc.ProjectID, input, infoTypeNames)\n-\tif err != nil {\n+\n+\tif err := deidentifyWithRedact(&buf, tc.ProjectID, input, infoTypeNames); err != nil {\n \t\tt.Errorf(\"deidentifyWithRedact(%q) = error '%q', want %q\", err, input, want)\n \t}\n \tif got := buf.String(); got != want {",
        "comments": [],
        "commit_message": "Merge branch 'main' into iennae-patch-2",
        "commit_id": "eef80649950da4322b9d9850a6d74d44bd5a04f8"
    },
    {
        "pr_title": "chore(appengine): move region tags to include the full function",
        "pr_number": 3019,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -174,9 +174,23 @@\nfunc TestDeidentifyTableBucketing(t *testing.T) {\n \n }\n \n-func TestDeidentifyTableConditionInfoTypes(t *testing.T) {\n+func TestDeidentifyTableMaskingCondition(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n+\tvar buf bytes.Buffer\n+\tif err := deidentifyTableMaskingCondition(&buf, tc.ProjectID); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tgot := buf.String()\n+\tif want := \"Table after de-identification :\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyTableMaskingCondition got (%q) =%q \", got, want)\n+\t}\n+\tif want := \"values:{string_value:\\\"**\\\"}\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyTableMaskingCondition got (%q) =%q \", got, want)\n+\t}\n+}\n \n+func TestDeidentifyTableConditionInfoTypes(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n \n \tif err := deidentifyTableConditionInfoTypes(&buf, tc.ProjectID, []string{\"PATIENT\", \"FACTOID\"}); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into iennae-patch-2",
        "commit_id": "eef80649950da4322b9d9850a6d74d44bd5a04f8"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/deid/date_shift.go",
        "code_diff": "@@ -35,7 +35,7 @@\nfunc deidentifyDateShift(w io.Writer, projectID string, lowerBoundDays, upperBou\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()\n \t// Create a configured request.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -41,7 +41,7 @@\nfunc deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string,\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()\n \t// Convert the info type strings to a list of InfoTypes.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -52,7 +52,7 @@\nfunc deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string,\n \t// Read the key file.\n \tkeyBytes, err := ioutil.ReadFile(keyFileName)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"ReadFile: %v\", err)\n+\t\treturn fmt.Errorf(\"ReadFile: %w\", err)\n \t}\n \t// Create a configured request.\n \treq := &dlppb.DeidentifyContentRequest{",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/deid/mask.go",
        "code_diff": "@@ -37,7 +37,7 @@\nfunc mask(w io.Writer, projectID, input string, infoTypeNames []string, maskingC\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()\n \t// Convert the info type strings to a list of InfoTypes.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/deid/reid_fpe.go",
        "code_diff": "@@ -39,13 +39,13 @@\nfunc reidentifyFPE(w io.Writer, projectID, input, keyFileName, cryptoKeyName, su\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()\n \t// Read the key file.\n \tkeyBytes, err := ioutil.ReadFile(keyFileName)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"ReadFile: %v\", err)\n+\t\treturn fmt.Errorf(\"ReadFile: %w\", err)\n \t}\n \t// Create a configured request.\n \treq := &dlppb.ReidentifyContentRequest{",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/inspect/inspect_bigquery.go",
        "code_diff": "@@ -43,7 +43,7 @@\nfunc inspectBigquery(w io.Writer, projectID string, infoTypeNames []string, cust\n \n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \n \t// Convert the info type strings to a list of InfoTypes.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/inspect/inspect_bigquery.go",
        "code_diff": "@@ -85,28 +85,28 @@\nfunc inspectBigquery(w io.Writer, projectID string, infoTypeNames []string, cust\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"pubsub.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"pubsub.NewClient: %w\", err)\n \t}\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \t// Create the Topic if it doesn't exist.\n \tt := pubsubClient.Topic(pubSubTopic)\n \tif exists, err := t.Exists(ctx); err != nil {\n-\t\treturn fmt.Errorf(\"t.Exists: %v\", err)\n+\t\treturn fmt.Errorf(\"t.Exists: %w\", err)\n \t} else if !exists {\n \t\tif t, err = pubsubClient.CreateTopic(ctx, pubSubTopic); err != nil {\n-\t\t\treturn fmt.Errorf(\"CreateTopic: %v\", err)\n+\t\t\treturn fmt.Errorf(\"CreateTopic: %w\", err)\n \t\t}\n \t}\n \n \t// Create the Subscription if it doesn't exist.\n \ts := pubsubClient.Subscription(pubSubSub)\n \tif exists, err := s.Exists(ctx); err != nil {\n-\t\treturn fmt.Errorf(\"s.Exits: %v\", err)\n+\t\treturn fmt.Errorf(\"s.Exits: %w\", err)\n \t} else if !exists {\n \t\tif s, err = pubsubClient.CreateSubscription(ctx, pubSubSub, pubsub.SubscriptionConfig{Topic: t}); err != nil {\n-\t\t\treturn fmt.Errorf(\"CreateSubscription: %v\", err)\n+\t\t\treturn fmt.Errorf(\"CreateSubscription: %w\", err)\n \t\t}\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/inspect/inspect_bigquery.go",
        "code_diff": "@@ -156,7 +156,7 @@\nfunc inspectBigquery(w io.Writer, projectID string, infoTypeNames []string, cust\n \t// Create the inspect job.\n \tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateDlpJob: %w\", err)\n \t}\n \tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/inspect/inspect_datastore.go",
        "code_diff": "@@ -41,7 +41,7 @@\nfunc inspectDatastore(w io.Writer, projectID string, infoTypeNames []string, cus\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \n \t// Convert the info type strings to a list of InfoTypes.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/inspect/inspect_datastore.go",
        "code_diff": "@@ -83,28 +83,28 @@\nfunc inspectDatastore(w io.Writer, projectID string, infoTypeNames []string, cus\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"pubsub.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"pubsub.NewClient: %w\", err)\n \t}\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \t// Create the Topic if it doesn't exist.\n \tt := pubsubClient.Topic(pubSubTopic)\n \tif exists, err := t.Exists(ctx); err != nil {\n-\t\treturn fmt.Errorf(\"t.Exists: %v\", err)\n+\t\treturn fmt.Errorf(\"t.Exists: %w\", err)\n \t} else if !exists {\n \t\tif t, err = pubsubClient.CreateTopic(ctx, pubSubTopic); err != nil {\n-\t\t\treturn fmt.Errorf(\"CreateTopic: %v\", err)\n+\t\t\treturn fmt.Errorf(\"CreateTopic: %w\", err)\n \t\t}\n \t}\n \n \t// Create the Subscription if it doesn't exist.\n \ts := pubsubClient.Subscription(pubSubSub)\n \tif exists, err := s.Exists(ctx); err != nil {\n-\t\treturn fmt.Errorf(\"s.Exists: %v\", err)\n+\t\treturn fmt.Errorf(\"s.Exists: %w\", err)\n \t} else if !exists {\n \t\tif s, err = pubsubClient.CreateSubscription(ctx, pubSubSub, pubsub.SubscriptionConfig{Topic: t}); err != nil {\n-\t\t\treturn fmt.Errorf(\"CreateSubscription: %v\", err)\n+\t\t\treturn fmt.Errorf(\"CreateSubscription: %w\", err)\n \t\t}\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/inspect/inspect_datastore.go",
        "code_diff": "@@ -156,7 +156,7 @@\nfunc inspectDatastore(w io.Writer, projectID string, infoTypeNames []string, cus\n \t// Create the inspect job.\n \tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateDlpJob: %w\", err)\n \t}\n \tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/inspect/inspect_gcs.go",
        "code_diff": "@@ -41,7 +41,7 @@\nfunc inspectGCSFile(w io.Writer, projectID string, infoTypeNames []string, custo\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \n \t// Convert the info type strings to a list of InfoTypes.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/inspect/inspect_gcs.go",
        "code_diff": "@@ -83,28 +83,28 @@\nfunc inspectGCSFile(w io.Writer, projectID string, infoTypeNames []string, custo\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"pubsub.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"pubsub.NewClient: %w\", err)\n \t}\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \t// Create the Topic if it doesn't exist.\n \tt := pubsubClient.Topic(pubSubTopic)\n \tif exists, err := t.Exists(ctx); err != nil {\n-\t\treturn fmt.Errorf(\"t.Exists: %v\", err)\n+\t\treturn fmt.Errorf(\"t.Exists: %w\", err)\n \t} else if !exists {\n \t\tif t, err = pubsubClient.CreateTopic(ctx, pubSubTopic); err != nil {\n-\t\t\treturn fmt.Errorf(\"CreateTopic: %v\", err)\n+\t\t\treturn fmt.Errorf(\"CreateTopic: %w\", err)\n \t\t}\n \t}\n \n \t// Create the Subscription if it doesn't exist.\n \ts := pubsubClient.Subscription(pubSubSub)\n \tif exists, err := s.Exists(ctx); err != nil {\n-\t\treturn fmt.Errorf(\"s.Exists: %v\", err)\n+\t\treturn fmt.Errorf(\"s.Exists: %w\", err)\n \t} else if !exists {\n \t\tif s, err = pubsubClient.CreateSubscription(ctx, pubSubSub, pubsub.SubscriptionConfig{Topic: t}); err != nil {\n-\t\t\treturn fmt.Errorf(\"CreateSubscription: %v\", err)\n+\t\t\treturn fmt.Errorf(\"CreateSubscription: %w\", err)\n \t\t}\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/inspect/inspect_gcs.go",
        "code_diff": "@@ -152,7 +152,7 @@\nfunc inspectGCSFile(w io.Writer, projectID string, infoTypeNames []string, custo\n \t// Create the inspect job.\n \tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateDlpJob: %w\", err)\n \t}\n \tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -34,25 +34,25 @@\nfunc setupPubSub(projectID, topic, sub string) (*pubsub.Subscription, error) {\n \tctx := context.Background()\n \tclient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"pubsub.NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"pubsub.NewClient: %w\", err)\n \t}\n \t// Create the Topic if it doesn't exist.\n \tt := client.Topic(topic)\n \tif exists, err := t.Exists(ctx); err != nil {\n-\t\treturn nil, fmt.Errorf(\"error checking PubSub topic: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"error checking PubSub topic: %w\", err)\n \t} else if !exists {\n \t\tif t, err = client.CreateTopic(ctx, topic); err != nil {\n-\t\t\treturn nil, fmt.Errorf(\"error creating PubSub topic: %v\", err)\n+\t\t\treturn nil, fmt.Errorf(\"error creating PubSub topic: %w\", err)\n \t\t}\n \t}\n \n \t// Create the Subscription if it doesn't exist.\n \ts := client.Subscription(sub)\n \tif exists, err := s.Exists(ctx); err != nil {\n-\t\treturn nil, fmt.Errorf(\"error checking for subscription: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"error checking for subscription: %w\", err)\n \t} else if !exists {\n \t\tif s, err = client.CreateSubscription(ctx, sub, pubsub.SubscriptionConfig{Topic: t}); err != nil {\n-\t\t\treturn nil, fmt.Errorf(\"failed to create subscription: %v\", err)\n+\t\t\treturn nil, fmt.Errorf(\"failed to create subscription: %w\", err)\n \t\t}\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -64,19 +64,19 @@\nfunc riskNumerical(projectID, dataProject, pubSubTopic, pubSubSub, datasetID, ta\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n+\t\treturn fmt.Errorf(\"Error creating PubSub client: %w\", err)\n \t}\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"setupPubSub: %v\", err)\n+\t\treturn fmt.Errorf(\"setupPubSub: %w\", err)\n \t}\n \n \t// topic is the PubSub topic string where messages should be sent.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -119,7 +119,7 @@\nfunc riskNumerical(projectID, dataProject, pubSubTopic, pubSubSub, datasetID, ta\n \t// Create the risk job.\n \tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateDlpJob: %w\", err)\n \t}\n \n \t// Wait for the risk job to finish by waiting for a PubSub message.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/jobs/list.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc listJobs(w io.Writer, projectID, filter, jobType string) error {\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/metadata/info_types.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc infoTypes(w io.Writer, languageCode, filter string) error {\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/redact/redact.go",
        "code_diff": "@@ -38,7 +38,7 @@\nfunc redactImage(w io.Writer, projectID string, infoTypeNames []string, bytesTyp\n \n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/redact/redact.go",
        "code_diff": "@@ -61,7 +61,7 @@\nfunc redactImage(w io.Writer, projectID string, infoTypeNames []string, bytesTyp\n \t// Read the input file.\n \tb, err := ioutil.ReadFile(inputPath)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"ioutil.ReadFile: %v\", err)\n+\t\treturn fmt.Errorf(\"ioutil.ReadFile: %w\", err)\n \t}\n \n \t// Create a configured request.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -38,19 +38,19 @@\nfunc riskCategorical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n+\t\treturn fmt.Errorf(\"Error creating PubSub client: %w\", err)\n \t}\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"setupPubSub: %v\", err)\n+\t\treturn fmt.Errorf(\"setupPubSub: %w\", err)\n \t}\n \n \t// topic is the PubSub topic string where messages should be sent.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -93,7 +93,7 @@\nfunc riskCategorical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub\n \t// Create the risk job.\n \tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateDlpJob: %w\", err)\n \t}\n \tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/risk/k_anonymity.go",
        "code_diff": "@@ -39,20 +39,20 @@\nfunc riskKAnonymity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n+\t\treturn fmt.Errorf(\"Error creating PubSub client: %w\", err)\n \t}\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"setupPubSub: %v\", err)\n+\t\treturn fmt.Errorf(\"setupPubSub: %w\", err)\n \t}\n \n \t// topic is the PubSub topic string where messages should be sent.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/risk/k_anonymity.go",
        "code_diff": "@@ -99,7 +99,7 @@\nfunc riskKAnonymity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t// Create the risk job.\n \tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateDlpJob: %w\", err)\n \t}\n \tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -41,20 +41,20 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n+\t\treturn fmt.Errorf(\"Error creating PubSub client: %w\", err)\n \t}\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"setupPubSub: %v\", err)\n+\t\treturn fmt.Errorf(\"setupPubSub: %w\", err)\n \t}\n \n \t// topic is the PubSub topic string where messages should be sent.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -109,7 +109,7 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \t// Create the risk job.\n \tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateDlpJob: %w\", err)\n \t}\n \tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -40,20 +40,20 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n+\t\treturn fmt.Errorf(\"Error creating PubSub client: %w\", err)\n \t}\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"setupPubSub: %v\", err)\n+\t\treturn fmt.Errorf(\"setupPubSub: %w\", err)\n \t}\n \n \t// topic is the PubSub topic string where messages should be sent.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -103,7 +103,7 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t// Create the risk job.\n \tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateDlpJob: %w\", err)\n \t}\n \tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/risk/numerical.go",
        "code_diff": "@@ -38,19 +38,19 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n+\t\treturn fmt.Errorf(\"Error creating PubSub client: %w\", err)\n \t}\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"setupPubSub: %v\", err)\n+\t\treturn fmt.Errorf(\"setupPubSub: %w\", err)\n \t}\n \n \t// topic is the PubSub topic string where messages should be sent.",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/risk/numerical.go",
        "code_diff": "@@ -93,7 +93,7 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t// Create the risk job.\n \tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateDlpJob: %w\", err)\n \t}\n \tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/template/create.go",
        "code_diff": "@@ -36,7 +36,7 @@\nfunc createInspectTemplate(w io.Writer, projectID string, templateID, displayNam\n \n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/template/delete.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc deleteInspectTemplate(w io.Writer, templateID string) error {\n \n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/template/list.go",
        "code_diff": "@@ -35,7 +35,7 @@\nfunc listInspectTemplates(w io.Writer, projectID string) error {\n \n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -38,7 +38,7 @@\nfunc createTrigger(w io.Writer, projectID string, triggerID, displayName, descri\n \n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/trigger/delete.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc deleteTrigger(w io.Writer, triggerID string) error {\n \n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/trigger/list.go",
        "code_diff": "@@ -35,7 +35,7 @@\nfunc listTriggers(w io.Writer, projectID string) error {\n \n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_custom_excluding_substring",
        "commit_id": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with multiple rules",
        "pr_number": 3011,
        "file_name": "docs/appengine/capabilities/capability.go",
        "code_diff": "@@ -15,16 +15,16 @@\npackage sample\n \n import (\n-\t\"context\"\n \t\"net/http\"\n \n-\t\"google.golang.org/appengine\"\n-\t\"google.golang.org/appengine/capability\"\n+\t\"google.golang.org/appengine/v2\"\n+\t\"google.golang.org/appengine/v2/capability\"\n )\n \n // [START gae_go_capabilities_lookup]\n func handler(w http.ResponseWriter, r *http.Request) {\n \tctx := appengine.NewContext(r)\n+\t// Check if the Datastore API is available\n \tif !capability.Enabled(ctx, \"datastore_v3\", \"*\") {\n \t\thttp.Error(w, \"This service is currently unavailable.\", 503)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_multiple_rules",
        "commit_id": "36007b41fb4759c3c1f0f64f1abcca31a057302f"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with multiple rules",
        "pr_number": 3011,
        "file_name": "kms/get_public_key_jwk.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage kms\n \n-// [START kms_get_public_key]\n+// [START kms_get_public_key_jwk]\n import (\n \t\"context\"\n \t\"crypto/x509\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_multiple_rules",
        "commit_id": "36007b41fb4759c3c1f0f64f1abcca31a057302f"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table infotypes",
        "pr_number": 3001,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -43,7 +43,7 @@\nfunc TestAnalyzeShotChange(t *testing.T) {\n \t\terr := shotChangeURI(&buf, catVideo)\n \n \t\tif err != nil {\n-\t\t\tt.Error(err)\n+\t\t\tr.Errorf(\"%v\", err)\n \t\t}\n \t\tassert(buf, want, t)\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_table_infotypes",
        "commit_id": "158775728490b004d9b03cbce19fcd8da1b4cc33"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table infotypes",
        "pr_number": 3001,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -57,7 +57,7 @@\nfunc TestAnalyzeLabelURI(t *testing.T) {\n \t\tvar buf bytes.Buffer\n \t\terr := labelURI(&buf, catVideo)\n \t\tif err != nil {\n-\t\t\tt.Error(err)\n+\t\t\tr.Errorf(\"%v\", err)\n \t\t}\n \t\tassert(buf, want, t)\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_table_infotypes",
        "commit_id": "158775728490b004d9b03cbce19fcd8da1b4cc33"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table infotypes",
        "pr_number": 3001,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -71,7 +71,7 @@\nfunc TestAnalyzeExplicitContentURI(t *testing.T) {\n \t\tvar buf bytes.Buffer\n \t\terr := explicitContentURI(&buf, catVideo)\n \t\tif err != nil {\n-\t\t\tt.Error(err)\n+\t\t\tr.Errorf(\"%v\", err)\n \t\t}\n \t\tassert(buf, want, t)\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_table_infotypes",
        "commit_id": "158775728490b004d9b03cbce19fcd8da1b4cc33"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table conditions ",
        "pr_number": 2998,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -110,8 +110,8 @@\nfunc TestDeIdentifyWithRedact(t *testing.T) {\n \tinfoTypeNames := []string{\"EMAIL_ADDRESS\"}\n \twant := \"output: My name is Alicia Abernathy, and my email address is .\"\n \n-\tbuf := new(bytes.Buffer)\n-\terr := deidentifyWithRedact(buf, tc.ProjectID, input, infoTypeNames)\n+\tvar buf bytes.Buffer\n+\terr := deidentifyWithRedact(&buf, tc.ProjectID, input, infoTypeNames)\n \tif err != nil {\n \t\tt.Errorf(\"deidentifyWithRedact(%q) = error '%q', want %q\", err, input, want)\n \t}",
        "comments": [
            {
                "comment": "issue: don't use `new`. Instead write `var buf bytes.Buffer`.",
                "position": null
            },
            {
                "comment": "Resolved.",
                "position": null
            }
        ],
        "commit_message": "addressed review comments",
        "commit_id": "6da03e176d154089128c0267585aecf0787b4f40"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table conditions ",
        "pr_number": 2998,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -126,9 +126,9 @@\nfunc TestDeidentifyExceptionList(t *testing.T) {\n \tinput := \"jack@example.org accessed customer record of user5@example.com\"\n \twant := \"output : jack@example.org accessed customer record of [EMAIL_ADDRESS]\"\n \n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \n-\tif err := deidentifyExceptionList(buf, tc.ProjectID, input); err != nil {\n+\tif err := deidentifyExceptionList(&buf, tc.ProjectID, input); err != nil {\n \t\tt.Errorf(\"deidentifyExceptionList(%q) = error '%q', want %q\", input, err, want)\n \t}\n \tif got := buf.String(); got != want {",
        "comments": [
            {
                "comment": "issue: don't use `new`. Instead write `var buf bytes.Buffer`.",
                "position": null
            },
            {
                "comment": "Resolved.",
                "position": null
            }
        ],
        "commit_message": "addressed review comments",
        "commit_id": "6da03e176d154089128c0267585aecf0787b4f40"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table conditions ",
        "pr_number": 2998,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -138,9 +138,9 @@\nfunc TestDeidentifyExceptionList(t *testing.T) {\n \n func TestDeidentifyTableBucketing(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \n-\tif err := deIdentifyTableBucketing(buf, tc.ProjectID); err != nil {\n+\tif err := deIdentifyTableBucketing(&buf, tc.ProjectID); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [
            {
                "comment": "issue: don't use `new`. Instead write `var buf bytes.Buffer`.",
                "position": null
            },
            {
                "comment": "Resolved.",
                "position": null
            }
        ],
        "commit_message": "addressed review comments",
        "commit_id": "6da03e176d154089128c0267585aecf0787b4f40"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table conditions ",
        "pr_number": 2998,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -160,9 +160,9 @@\nfunc TestDeidentifyTableBucketing(t *testing.T) {\n func TestDeidentifyTableConditionInfoTypes(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \n-\tif err := deidentifyTableConditionInfoTypes(buf, tc.ProjectID, []string{\"PATIENT\", \"FACTOID\"}); err != nil {\n+\tif err := deidentifyTableConditionInfoTypes(&buf, tc.ProjectID, []string{\"PATIENT\", \"FACTOID\"}); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [
            {
                "comment": "issue: don't use `new`. Instead write `var buf bytes.Buffer`.",
                "position": null
            },
            {
                "comment": "Resolved.",
                "position": null
            }
        ],
        "commit_message": "addressed review comments",
        "commit_id": "6da03e176d154089128c0267585aecf0787b4f40"
    },
    {
        "pr_title": "feat(dlp): added a sample for de-identify replace ",
        "pr_number": 2997,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -43,7 +43,7 @@\nfunc TestAnalyzeShotChange(t *testing.T) {\n \t\terr := shotChangeURI(&buf, catVideo)\n \n \t\tif err != nil {\n-\t\t\tt.Fatal(err)\n+\t\t\tt.Error(err)\n \t\t}\n \t\tassert(buf, want, t)\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_replace",
        "commit_id": "7863e34cc884223e2aff18deec7266ef054d219d"
    },
    {
        "pr_title": "feat(dlp): added a sample for de-identify replace ",
        "pr_number": 2997,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -57,7 +57,7 @@\nfunc TestAnalyzeLabelURI(t *testing.T) {\n \t\tvar buf bytes.Buffer\n \t\terr := labelURI(&buf, catVideo)\n \t\tif err != nil {\n-\t\t\tt.Fatal(err)\n+\t\t\tt.Error(err)\n \t\t}\n \t\tassert(buf, want, t)\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_replace",
        "commit_id": "7863e34cc884223e2aff18deec7266ef054d219d"
    },
    {
        "pr_title": "feat(dlp): added a sample for de-identify replace ",
        "pr_number": 2997,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -71,7 +71,7 @@\nfunc TestAnalyzeExplicitContentURI(t *testing.T) {\n \t\tvar buf bytes.Buffer\n \t\terr := explicitContentURI(&buf, catVideo)\n \t\tif err != nil {\n-\t\t\tt.Fatal(err)\n+\t\t\tt.Error(err)\n \t\t}\n \t\tassert(buf, want, t)\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_replace",
        "commit_id": "7863e34cc884223e2aff18deec7266ef054d219d"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table bucketing ",
        "pr_number": 2984,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -312,14 +312,16 @@\nfunc TestInspectStringWithExclusionDictSubstring(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \tgot := buf.String()\n-\n+\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n+\t}\n \tif want := \"Infotype Name: DOMAIN_NAME\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n \t}\n-\n \tif want := \"Quote: TEST\"; strings.Contains(got, want) {\n \t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n \t}\n+\n }\n \n func TestInspectStringOmitOverlap(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_table_bucketing",
        "commit_id": "00d2879b4f2fd55b1ac0b5dd31a55cbab903ec7c"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table bucketing ",
        "pr_number": 2984,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -344,7 +346,7 @@\nfunc TestInspectStringCustomOmitOverlap(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)\n \n-\tif err := inspectStringCustomOmitOverlap(buf, tc.ProjectID, \"Name: Jane Doe. Name: Larry Page.\", \"VIP_DETECTOR\", \"PERSON_NAME\", \"Larry Page|Sergey Brin\"); err != nil {\n+\tif err := inspectStringCustomHotWord(buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_table_bucketing",
        "commit_id": "00d2879b4f2fd55b1ac0b5dd31a55cbab903ec7c"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with exclusion dictionary substring",
        "pr_number": 2958,
        "file_name": "bigquery/snippets/managedwriter/integration_test.go",
        "code_diff": "@@ -24,7 +24,7 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func TestPendingStream(t *testing.T) {\n+func TestAppends(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_string_with_exclusion_dict_substring",
        "commit_id": "1e91d135d1b4df404579a23c1bb849f6b09801b7"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with exclusion dictionary ",
        "pr_number": 2957,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -282,7 +282,7 @@\nfunc TestInspectPhoneNumber(t *testing.T) {\n \tbuf := new(bytes.Buffer)\n \n \tif err := inspectPhoneNumber(buf, tc.ProjectID, \"I'm Gary and my phone number is (415) 555-0890\"); err != nil {\n-\t\tt.Errorf(\"TestInspectFile: %v\", err)\n+\t\tt.Fatal(err)\n \t}\n \n \tgot := buf.String()",
        "comments": [],
        "commit_message": "resolving conflicts",
        "commit_id": "0a61a9ebd3e296cdbeb4016428834a536edee480"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom omit overlap",
        "pr_number": 2955,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -101,6 +101,23 @@\nfunc TestDeidentifyDateShift(t *testing.T) {\n \t}\n }\n \n+func TestDeIdentifyWithRedact(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tinput := \"My name is Alicia Abernathy, and my email address is aabernathy@example.com.\"\n+\tinfoTypeNames := []string{\"EMAIL_ADDRESS\"}\n+\twant := \"output: My name is Alicia Abernathy, and my email address is .\"\n+\n+\tbuf := new(bytes.Buffer)\n+\terr := deidentifyWithRedact(buf, tc.ProjectID, input, infoTypeNames)\n+\tif err != nil {\n+\t\tt.Errorf(\"deidentifyWithRedact(%q) = error '%q', want %q\", err, input, want)\n+\t}\n+\tif got := buf.String(); got != want {\n+\t\tt.Errorf(\"deidentifyWithRedact(%q) = %q, want %q\", got, input, want)\n+\t}\n+}\n+\n func TestDeidentifyExceptionList(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "resolving the conflicts",
        "commit_id": "597c72926fbf53ee836f43ec25e4fe675a840d8e"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom omit overlap",
        "pr_number": 2955,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -282,7 +282,7 @@\nfunc TestInspectPhoneNumber(t *testing.T) {\n \tbuf := new(bytes.Buffer)\n \n \tif err := inspectPhoneNumber(buf, tc.ProjectID, \"I'm Gary and my phone number is (415) 555-0890\"); err != nil {\n-\t\tt.Errorf(\"TestInspectFile: %v\", err)\n+\t\tt.Fatal(err)\n \t}\n \n \tgot := buf.String()",
        "comments": [],
        "commit_message": "resolving the conflicts",
        "commit_id": "597c72926fbf53ee836f43ec25e4fe675a840d8e"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom omit overlap",
        "pr_number": 2955,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -291,24 +291,16 @@\nfunc TestInspectPhoneNumber(t *testing.T) {\n \t}\n }\n \n-func TestInspectStringCustomOmitOverlap(t *testing.T) {\n+func TestInspectStringCustomHotWord(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)\n \n-\tif err := inspectStringCustomOmitOverlap(buf, tc.ProjectID, \"Name: Jane Doe. Name: Larry Page.\", \"VIP_DETECTOR\", \"PERSON_NAME\", \"Larry Page|Sergey Brin\"); err != nil {\n-\t\tt.Fatal(err)\n+\tif err := inspectStringCustomHotWord(buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n+\t\tt.Errorf(\"inspectStringCustomHotWord: %v\", err)\n \t}\n-\n \tgot := buf.String()\n \tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomOmitOverlap got %q, want %q\", got, want)\n-\t}\n-\n-\tif want := \"Quote: Jane Doe\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomOmitOverlap got %q, want %q\", got, want)\n-\t}\n-\tif want := \"Quote: Larry Page\"; strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomOmitOverlap got %q, want %q\", got, want)\n+\t\tt.Errorf(\"inspectStringCustomHotWord got %q, want %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_message": "resolving the conflicts",
        "commit_id": "597c72926fbf53ee836f43ec25e4fe675a840d8e"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom omit overlap",
        "pr_number": 2955,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -319,11 +311,7 @@\nfunc TestInspectStringWithExclusionDictSubstring(t *testing.T) {\n \tif err := inspectStringWithExclusionDictSubstring(buf, tc.ProjectID, \"Some email addresses: gary@example.com, TEST@example.com\", []string{\"TEST\"}); err != nil {\n \t\tt.Fatal(err)\n \t}\n-\n \tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n \n \tif want := \"Infotype Name: DOMAIN_NAME\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)",
        "comments": [],
        "commit_message": "resolving the conflicts",
        "commit_id": "597c72926fbf53ee836f43ec25e4fe675a840d8e"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify redact",
        "pr_number": 2954,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -282,7 +282,7 @@\nfunc TestInspectPhoneNumber(t *testing.T) {\n \tbuf := new(bytes.Buffer)\n \n \tif err := inspectPhoneNumber(buf, tc.ProjectID, \"I'm Gary and my phone number is (415) 555-0890\"); err != nil {\n-\t\tt.Errorf(\"TestInspectFile: %v\", err)\n+\t\tt.Fatal(err)\n \t}\n \n \tgot := buf.String()",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_redact",
        "commit_id": "525660aa894768a40ab37e7e5b56c9843a95411f"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify redact",
        "pr_number": 2954,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -291,17 +291,16 @@\nfunc TestInspectPhoneNumber(t *testing.T) {\n \t}\n }\n \n-func TestInspectStringCustomHotWord(t *testing.T) {\n+func TestInspectStringWithExclusionDictionary(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)\n \n-\tif err := inspectStringCustomHotWord(buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n-\t\tt.Errorf(\"inspectStringCustomHotWord: %v\", err)\n+\tif err := inspectStringWithExclusionDictionary(buf, tc.ProjectID, \"Some email addresses: gary@example.com, example@example.com\", []string{\"example@example.com\"}); err != nil {\n+\t\tt.Fatal(err)\n \t}\n-\n \tgot := buf.String()\n-\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomHotWord got %q, want %q\", got, want)\n+\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringWithExclusionDictionary got %q, want %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_redact",
        "commit_id": "525660aa894768a40ab37e7e5b56c9843a95411f"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify redact",
        "pr_number": 2954,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -312,11 +311,7 @@\nfunc TestInspectStringWithExclusionDictSubstring(t *testing.T) {\n \tif err := inspectStringWithExclusionDictSubstring(buf, tc.ProjectID, \"Some email addresses: gary@example.com, TEST@example.com\", []string{\"TEST\"}); err != nil {\n \t\tt.Fatal(err)\n \t}\n-\n \tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n \n \tif want := \"Infotype Name: DOMAIN_NAME\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_redact",
        "commit_id": "525660aa894768a40ab37e7e5b56c9843a95411f"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect hotword rule ",
        "pr_number": 2953,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -17,6 +17,8 @@\npackage deid\n \n import (\n \t\"bytes\"\n+\t\"strings\"\n+\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_hotword_rule",
        "commit_id": "20852bf581abc44abd68f636f2d5e0ceb460d8cf"
    },
    {
        "pr_title": "feat(dlp): added a sample for de-identify exception list",
        "pr_number": 2951,
        "file_name": "functions/spanner/spanner.go",
        "code_diff": "@@ -25,6 +25,7 @@\nimport (\n \t\"sync\"\n \n \t\"cloud.google.com/go/spanner\"\n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \t\"google.golang.org/api/iterator\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_exception_list",
        "commit_id": "b67e428532d2079af7e97692df881dc6c2e0599e"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect data for phone numbers",
        "pr_number": 2942,
        "file_name": "functions/spanner/spanner.go",
        "code_diff": "@@ -25,6 +25,7 @@\nimport (\n \t\"sync\"\n \n \t\"cloud.google.com/go/spanner\"\n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \t\"google.golang.org/api/iterator\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_inspect_phone_number",
        "commit_id": "5032e61ae491796ce0d1894b350582d5d319c742"
    },
    {
        "pr_title": "feat(dlp): added a sample for de-identify sensitive data with a simple word list ",
        "pr_number": 2941,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -291,16 +291,16 @@\nfunc TestInspectPhoneNumber(t *testing.T) {\n \t}\n }\n \n-func TestInspectStringWithExclusionDictionary(t *testing.T) {\n+func TestInspectStringCustomHotWord(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)\n \n-\tif err := inspectStringWithExclusionDictionary(buf, tc.ProjectID, \"Some email addresses: gary@example.com, example@example.com\", []string{\"example@example.com\"}); err != nil {\n-\t\tt.Fatal(err)\n+\tif err := inspectStringCustomHotWord(buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n+\t\tt.Errorf(\"inspectStringCustomHotWord: %v\", err)\n \t}\n \tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictionary got %q, want %q\", got, want)\n+\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringCustomHotWord got %q, want %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into dlp_deidentify_simple_word_list",
        "commit_id": "be2e35aa00c8e634e8dfbe108f0034e55307664a"
    },
    {
        "pr_title": "chore(all): update CODEOWNERS",
        "pr_number": 2875,
        "file_name": "firestore/save.go",
        "code_diff": "@@ -17,6 +17,8 @@\npackage firestore\n import (\n \t\"context\"\n \t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n \t\"log\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into codeowners-update",
        "commit_id": "743a8ff249f303859910c88ba0a6a80df6edcacc"
    },
    {
        "pr_title": "chore(all): update CODEOWNERS",
        "pr_number": 2875,
        "file_name": "firestore/save.go",
        "code_diff": "@@ -268,18 +270,26 @@\nfunc deleteField(ctx context.Context, client *firestore.Client) error {\n }\n \n // [START firestore_data_delete_collection]\n-func deleteCollection(ctx context.Context, client *firestore.Client,\n-\tref *firestore.CollectionRef, batchSize int) error {\n+func deleteCollection(w io.Writer, projectID, collectionName string,\n+\tbatchSize int) error {\n+\n+\t// Instantiate a client\n+\tctx := context.Background()\n+\tclient, err := firestore.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tcol := client.Collection(collectionName)\n+\tbulkwriter := client.BulkWriter(ctx)\n \n \tfor {\n \t\t// Get a batch of documents\n-\t\titer := ref.Limit(batchSize).Documents(ctx)\n+\t\titer := col.Limit(batchSize).Documents(ctx)\n \t\tnumDeleted := 0\n \n \t\t// Iterate through the documents, adding\n-\t\t// a delete operation for each one to a\n-\t\t// WriteBatch.\n-\t\tbatch := client.Batch()\n+\t\t// a delete operation for each one to the BulkWriter.\n \t\tfor {\n \t\t\tdoc, err := iter.Next()\n \t\t\tif err == iterator.Done {",
        "comments": [],
        "commit_message": "Merge branch 'main' into codeowners-update",
        "commit_id": "743a8ff249f303859910c88ba0a6a80df6edcacc"
    },
    {
        "pr_title": "chore(all): update CODEOWNERS",
        "pr_number": 2875,
        "file_name": "firestore/save_test.go",
        "code_diff": "@@ -15,8 +15,10 @@\npackage firestore\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"os\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"cloud.google.com/go/firestore\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into codeowners-update",
        "commit_id": "743a8ff249f303859910c88ba0a6a80df6edcacc"
    },
    {
        "pr_title": "chore(all): update CODEOWNERS",
        "pr_number": 2875,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -44,7 +44,7 @@\nfunc TestDetect(t *testing.T) {\n \t\t{\"SafeSearch\", detectSafeSearch, detectSafeSearchURI, \"wakeupcat.jpg\", \"Spoofed\"},\n \t\t{\"Text\", detectText, detectTextURI, \"text.jpg\", \"Preparing to install\"},\n \t\t{\"FullText\", detectDocumentText, detectDocumentTextURI, \"text.jpg\", \"Preparing to install\"},\n-\t\t{\"Crop\", detectCropHints, detectCropHintsURI, \"wakeupcat.jpg\", \"(0,0)\"},\n+\t\t{\"Crop\", detectCropHints, detectCropHintsURI, \"wakeupcat.jpg\", \"crop hints:\"},\n \t\t{\"Web\", detectWeb, detectWebURI, \"wakeupcat.jpg\", \"Web properties\"},\n \t\t{\"WebGeo\", nil, detectWebGeoURI, \"city.jpg\", \"Entities\"},\n \t\t{\"Objects\", localizeObjects, localizeObjectsURI, \"puppies.jpg\", \"Dog\"},",
        "comments": [],
        "commit_message": "Merge branch 'main' into codeowners-update",
        "commit_id": "743a8ff249f303859910c88ba0a6a80df6edcacc"
    },
    {
        "pr_title": "chore(all): update CODEOWNERS",
        "pr_number": 2875,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -56,9 +56,6 @@\nfunc TestDetect(t *testing.T) {\n \t\t}\n \t\ttt := tt\n \t\tt.Run(tt.name+\"/local\", func(t *testing.T) {\n-\t\t\tif tt.name == \"Crop\" {\n-\t\t\t\tt.Skip(\"skipped due to googlecloudplatform/golang-samples#2900\")\n-\t\t\t}\n \t\t\tt.Parallel()\n \t\t\tvar buf bytes.Buffer\n \t\t\tif err := tt.local(&buf, \"../testdata/\"+tt.path); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into codeowners-update",
        "commit_id": "743a8ff249f303859910c88ba0a6a80df6edcacc"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "auth/authenticate_explicit_with_adc.go",
        "code_diff": "@@ -37,7 +37,7 @@\nfunc authenticateExplicitWithAdc(w io.Writer) error {\n \t// if you are on a GCE (or other metadata server supported environments).\n \tcredentials, err := google.FindDefaultCredentials(ctx, \"https://www.googleapis.com/auth/cloud-platform\")\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"failed to generate default credentials: %v\", err)\n+\t\treturn fmt.Errorf(\"failed to generate default credentials: %w\", err)\n \t}\n \t// If you are authenticating to a Cloud API, you can let the library include the default scope,\n \t// https://www.googleapis.com/auth/cloud-platform, because IAM is used to provide fine-grained",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "auth/downscoping/token_consumer.go",
        "code_diff": "@@ -52,16 +52,16 @@\nfunc (lts localTokenSource) Token() (*oauth2.Token, error) {\n \t}\n \trootSource, err := google.DefaultTokenSource(lts.ctx, \"https://www.googleapis.com/auth/cloud-platform\")\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"failed to generate rootSource: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"failed to generate rootSource: %w\", err)\n \t}\n \tdts, err := downscope.NewTokenSource(lts.ctx, downscope.DownscopingConfig{RootSource: rootSource, Rules: accessBoundary})\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"failed to generate downscoped token source: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"failed to generate downscoped token source: %w\", err)\n \t}\n \t// Token() uses the previously declared TokenSource to generate a downscoped token.\n \tremoteToken, err = dts.Token()\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"failed to generate token: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"failed to generate token: %w\", err)\n \t}\n \n \treturn remoteToken, nil",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "auth/id_token_from_impersonated_credentials.go",
        "code_diff": "@@ -39,7 +39,7 @@\nfunc getIdTokenFromImpersonatedCredentials(w io.Writer, scope, targetAudience, i\n \t// working environment.\n \tcredentials, err := google.FindDefaultCredentials(ctx, scope)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"failed to generate default credentials: %v\", err)\n+\t\treturn fmt.Errorf(\"failed to generate default credentials: %w\", err)\n \t}\n \n \tts, err := impersonate.IDTokenSource(ctx, impersonate.IDTokenConfig{",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_container_no_mounting.go",
        "code_diff": "@@ -34,7 +34,7 @@\nfunc createContainerJob(w io.Writer, projectID, region, jobName string) error {\n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer batchClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_gcs_bucket.go",
        "code_diff": "@@ -35,7 +35,7 @@\nfunc createScriptJobWithBucket(w io.Writer, projectID, region, jobName, bucketNa\n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer batchClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_gcs_bucket_test.go",
        "code_diff": "@@ -74,7 +74,7 @@\nfunc createBucket(projectID, bucketName string) error {\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"storage.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"storage.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_gcs_bucket_test.go",
        "code_diff": "@@ -83,7 +83,7 @@\nfunc createBucket(projectID, bucketName string) error {\n \n \tbucket := client.Bucket(bucketName)\n \tif err := bucket.Create(ctx, projectID, nil); err != nil {\n-\t\treturn fmt.Errorf(\"Bucket(%q).Create: %v\", bucketName, err)\n+\t\treturn fmt.Errorf(\"Bucket(%q).Create: %w\", bucketName, err)\n \t}\n \treturn nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_gcs_bucket_test.go",
        "code_diff": "@@ -92,7 +92,7 @@\nfunc deleteBucket(bucketName string) error {\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"storage.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"storage.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_gcs_bucket_test.go",
        "code_diff": "@@ -101,7 +101,7 @@\nfunc deleteBucket(bucketName string) error {\n \n \tbucket := client.Bucket(bucketName)\n \tif err := bucket.Delete(ctx); err != nil {\n-\t\treturn fmt.Errorf(\"Bucket(%q).Delete: %v\", bucketName, err)\n+\t\treturn fmt.Errorf(\"Bucket(%q).Delete: %w\", bucketName, err)\n \t}\n \treturn nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_gcs_bucket_test.go",
        "code_diff": "@@ -112,7 +112,7 @@\nfunc deleteFile(bucket, object string) error {\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"storage.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"storage.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_script_no_mounting.go",
        "code_diff": "@@ -34,7 +34,7 @@\nfunc createScriptJob(w io.Writer, projectID, region, jobName string) error {\n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer batchClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_template.go",
        "code_diff": "@@ -39,7 +39,7 @@\nfunc createScriptJobWithTemplate(w io.Writer, projectID, region, jobName, templa\n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer batchClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_template_test.go",
        "code_diff": "@@ -68,13 +68,13 @@\nfunc createTemplate(projectID, templateName string) error {\n \tctx := context.Background()\n \tinstanceTemplatesClient, err := compute.NewInstanceTemplatesRESTClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewInstanceTemplatesRESTClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewInstanceTemplatesRESTClient: %w\", err)\n \t}\n \tdefer instanceTemplatesClient.Close()\n \n \tprojectNumber, err := projectIDtoNumber(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"Could not resolve project ID '%s' to project number: %v\", projectID, err)\n+\t\treturn fmt.Errorf(\"Could not resolve project ID '%s' to project number: %w\", projectID, err)\n \t}\n \n \tserviceAccountAddress := fmt.Sprintf(\"%d-compute@developer.gserviceaccount.com\", projectNumber)",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_template_test.go",
        "code_diff": "@@ -129,11 +129,11 @@\nfunc createTemplate(projectID, templateName string) error {\n \n \top, err := instanceTemplatesClient.Insert(ctx, req)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"unable to create instance template: %v\", err)\n+\t\treturn fmt.Errorf(\"unable to create instance template: %w\", err)\n \t}\n \n \tif err = op.Wait(ctx); err != nil {\n-\t\treturn fmt.Errorf(\"unable to wait for the operation: %v\", err)\n+\t\treturn fmt.Errorf(\"unable to wait for the operation: %w\", err)\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_template_test.go",
        "code_diff": "@@ -143,13 +143,13 @@\nfunc projectIDtoNumber(ctx context.Context, projectID string) (int64, error) {\n \t// Resolve the project ID to project number\n \tresourceManagerClient, err := cloudresourcemanager.NewService(ctx)\n \tif err != nil {\n-\t\treturn 0, fmt.Errorf(\"cloudresourcemanager.NewService: %v\", err)\n+\t\treturn 0, fmt.Errorf(\"cloudresourcemanager.NewService: %w\", err)\n \t}\n \t// resourceManagerClient doesn't have a Close() method\n \tprojectsClient := cloudresourcemanager.NewProjectsService(resourceManagerClient)\n \tprojectData, err := projectsClient.Get(projectID).Do()\n \tif err != nil {\n-\t\treturn 0, fmt.Errorf(\"Could not resolve project ID '%s' to project number: %v\", projectID, err)\n+\t\treturn 0, fmt.Errorf(\"Could not resolve project ID '%s' to project number: %w\", projectID, err)\n \t}\n \treturn projectData.ProjectNumber, nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/create_with_template_test.go",
        "code_diff": "@@ -158,7 +158,7 @@\nfunc deleteInstanceTemplate(projectID, templateName string) error {\n \tctx := context.Background()\n \tinstanceTemplatesClient, err := compute.NewInstanceTemplatesRESTClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewInstanceTemplatesRESTClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewInstanceTemplatesRESTClient: %w\", err)\n \t}\n \tdefer instanceTemplatesClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/delete_job.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc deleteJob(w io.Writer, projectID, region, jobName string) error {\n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer batchClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/get_job.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc getJob(w io.Writer, projectID, region, jobName string) (*batchpb.Job, error\n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer batchClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/get_task.go",
        "code_diff": "@@ -35,7 +35,7 @@\nfunc getTask(w io.Writer, projectID, region, jobName, taskGroup string, taskNumb\n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer batchClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/list_jobs.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc listJobs(w io.Writer, projectID, region string) error {\n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer batchClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/list_tasks.go",
        "code_diff": "@@ -35,7 +35,7 @@\nfunc listTasks(w io.Writer, projectID, region, jobName, taskGroup string) error\n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer batchClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/read_job_logs.go",
        "code_diff": "@@ -34,13 +34,13 @@\nfunc printJobLogs(w io.Writer, projectID string, job *batchpb.Job) error {\n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer batchClient.Close()\n \n \tadminClient, err := logadmin.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"Failed to create logadmin client: %v\", err)\n+\t\treturn fmt.Errorf(\"Failed to create logadmin client: %w\", err)\n \t}\n \tdefer adminClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "batch/testutils.go",
        "code_diff": "@@ -27,7 +27,7 @@\nfunc jobSucceeded(projectID, region, jobName string) (bool, error) {\n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn false, fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn false, fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer batchClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "run/image-processing/imagemagick/imagemagick.go",
        "code_diff": "@@ -76,7 +76,7 @@\nfunc BlurOffensiveImages(ctx context.Context, e GCSEvent) error {\n \n \tresp, err := visionClient.DetectSafeSearch(ctx, img, nil)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"AnnotateImage: %v\", err)\n+\t\treturn fmt.Errorf(\"AnnotateImage: %w\", err)\n \t}\n \n \tif resp.GetAdult() == visionpb.Likelihood_VERY_LIKELY ||",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "run/image-processing/imagemagick/imagemagick.go",
        "code_diff": "@@ -99,7 +99,7 @@\nfunc blur(ctx context.Context, inputBucket, outputBucket, name string) error {\n \tinputBlob := storageClient.Bucket(inputBucket).Object(name)\n \tr, err := inputBlob.NewReader(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewReader: %v\", err)\n+\t\treturn fmt.Errorf(\"NewReader: %w\", err)\n \t}\n \n \toutputBlob := storageClient.Bucket(outputBucket).Object(name)",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "run/testing/grpc_ping.e2e_test.go",
        "code_diff": "@@ -113,7 +113,7 @@\nfunc grpcRequest(host string, audience string, fn func(context.Context, *grpc.Cl\n \topts = append(opts, grpc.WithTransportCredentials(cred))\n \tconn, err := grpc.Dial(host, opts...)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"grpc.Dial: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"grpc.Dial: %w\", err)\n \t}\n \tdefer conn.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "tasks/create_http_task.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc createHTTPTask(projectID, locationID, queueID, url, message string) (*tasks\n \tctx := context.Background()\n \tclient, err := cloudtasks.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "tasks/token/create_http_task_with_token.go",
        "code_diff": "@@ -32,7 +32,7 @@\nfunc createHTTPTaskWithToken(projectID, locationID, queueID, url, email, message\n \tctx := context.Background()\n \tclient, err := cloudtasks.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into drop_database_protection_samples",
        "commit_id": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "chore(cloudsql): split out Postgres Auto IAM AuthN sample",
        "pr_number": 2836,
        "file_name": "cloudsql/postgres/database-sql/connect_connector.go",
        "code_diff": "@@ -55,7 +55,6 @@\nfunc connectWithConnector() (*sql.DB, error) {\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\t// [START cloud_sql_postgres_databasesql_auto_iam_authn]\n \tvar opts []cloudsqlconn.Option\n \tif usePrivate != \"\" {\n \t\topts = append(opts, cloudsqlconn.WithDefaultDialOptions(cloudsqlconn.WithPrivateIP()))",
        "comments": [],
        "commit_message": "chore: remove tag",
        "commit_id": "039b87788d763958711766f6324b0dad2af73b98"
    },
    {
        "pr_title": "feat(compute): resize instance sample",
        "pr_number": 2803,
        "file_name": "functions/tips/contexttip/context_tip.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"os\"\n \n \t\"cloud.google.com/go/pubsub\"\n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n )\n \n // GOOGLE_CLOUD_PROJECT is a user-set environment variable.",
        "comments": [],
        "commit_message": "Merge branch 'main' into resize-instance",
        "commit_id": "7a768760be406b36af3588aae569aaaaa294fce3"
    },
    {
        "pr_title": "feat(compute): resize instance sample",
        "pr_number": 2803,
        "file_name": "functions/tips/scope.go",
        "code_diff": "@@ -18,6 +18,8 @@\npackage tips\n import (\n \t\"fmt\"\n \t\"net/http\"\n+\n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n )\n \n // [START functions_tips_scopes]",
        "comments": [],
        "commit_message": "Merge branch 'main' into resize-instance",
        "commit_id": "7a768760be406b36af3588aae569aaaaa294fce3"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "batch/job_basics_test.go",
        "code_diff": "@@ -26,6 +26,7 @@\nimport (\n )\n \n func TestBatchJobCRUD(t *testing.T) {\n+\tt.Skip(\"Skipped while investigating https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \tt.Parallel()\n \tvar r *rand.Rand = rand.New(\n \t\trand.NewSource(time.Now().UnixNano()))",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "functions/http/cors.go",
        "code_diff": "@@ -20,6 +20,8 @@\npackage http\n import (\n \t\"fmt\"\n \t\"net/http\"\n+\n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n )\n \n // CORSEnabledFunction is an example of setting CORS headers.",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -46,6 +46,11 @@\nvar gcsSinkBucket string\n func TestMain(m *testing.M) {\n \t// Initialize global vars\n \ttc, _ := testutil.ContextMain(m)\n+\tif os.Getenv(\"KOKORO_BUILD_ID\") != \"\" {\n+\t\t// temporarily skip initialization in kokoro\n+\t\t// See https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\n+\t\treturn\n+\t}\n \n \tctx := context.Background()\n \tc, err := storage.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -134,6 +139,7 @@\nfunc TestMain(m *testing.M) {\n }\n \n func TestQuickstart(t *testing.T) {\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -151,6 +157,7 @@\nfunc TestQuickstart(t *testing.T) {\n }\n \n func TestTransferFromAws(t *testing.T) {\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -169,6 +176,7 @@\nfunc TestTransferFromAws(t *testing.T) {\n }\n \n func TestTransferToNearline(t *testing.T) {\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -187,6 +195,7 @@\nfunc TestTransferToNearline(t *testing.T) {\n }\n \n func TestGetLatestTransferOperation(t *testing.T) {\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -210,6 +219,7 @@\nfunc TestGetLatestTransferOperation(t *testing.T) {\n }\n \n func TestDownloadToPosix(t *testing.T) {\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -237,6 +247,7 @@\nfunc TestDownloadToPosix(t *testing.T) {\n }\n \n func TestTransferFromPosix(t *testing.T) {\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -263,6 +274,7 @@\nfunc TestTransferFromPosix(t *testing.T) {\n }\n \n func TestTransferBetweenPosix(t *testing.T) {\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -295,6 +307,7 @@\nfunc TestTransferBetweenPosix(t *testing.T) {\n }\n \n func TestTransferUsingManifest(t *testing.T) {\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -325,6 +338,7 @@\nfunc TestTransferUsingManifest(t *testing.T) {\n }\n \n func TestTransferFromS3CompatibleSource(t *testing.T) {\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'main' into regional-disk-samples",
        "commit_id": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -158,38 +158,38 @@\nfunc TestSlates(t *testing.T) {\n \t})\n }\n \n-// TestCdnKeys tests major operations on CDN keys. Create, list, update,\n+// TestCDNKeys tests major operations on CDN keys. Create, list, update,\n // and get operations check if the CDN key resource name is returned. The\n // delete operation checks for a hard-coded string response.\n-func TestCdnKeys(t *testing.T) {\n+func TestCDNKeys(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := &bytes.Buffer{}\n \n \t// Test setup\n \n \t// Delete the Media CDN key if it exists.\n-\tif err := getCdnKey(buf, tc.ProjectID, mediaCDNKeyID); err == nil {\n+\tif err := getCDNKey(buf, tc.ProjectID, mediaCDNKeyID); err == nil {\n \t\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\t\tif err := deleteCdnKey(buf, tc.ProjectID, mediaCDNKeyID); err != nil {\n-\t\t\t\tr.Errorf(\"deleteCdnKey got err: %v\", err)\n+\t\t\tif err := deleteCDNKey(buf, tc.ProjectID, mediaCDNKeyID); err != nil {\n+\t\t\t\tr.Errorf(\"deleteCDNKey got err: %v\", err)\n \t\t\t}\n \t\t})\n \t}\n \n \t// Delete the Cloud CDN key if it exists.\n-\tif err := getCdnKey(buf, tc.ProjectID, cloudCDNKeyID); err == nil {\n+\tif err := getCDNKey(buf, tc.ProjectID, cloudCDNKeyID); err == nil {\n \t\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\t\tif err := deleteCdnKey(buf, tc.ProjectID, cloudCDNKeyID); err != nil {\n-\t\t\t\tr.Errorf(\"deleteCdnKey got err: %v\", err)\n+\t\t\tif err := deleteCDNKey(buf, tc.ProjectID, cloudCDNKeyID); err != nil {\n+\t\t\t\tr.Errorf(\"deleteCDNKey got err: %v\", err)\n \t\t\t}\n \t\t})\n \t}\n \n \t// Delete the Akamai CDN key if it exists.\n-\tif err := getCdnKey(buf, tc.ProjectID, akamaiCDNKeyID); err == nil {\n+\tif err := getCDNKey(buf, tc.ProjectID, akamaiCDNKeyID); err == nil {\n \t\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\t\tif err := deleteCdnKey(buf, tc.ProjectID, akamaiCDNKeyID); err != nil {\n-\t\t\t\tr.Errorf(\"deleteCdnKey got err: %v\", err)\n+\t\t\tif err := deleteCDNKey(buf, tc.ProjectID, akamaiCDNKeyID); err != nil {\n+\t\t\t\tr.Errorf(\"deleteCDNKey got err: %v\", err)\n \t\t\t}\n \t\t})\n \t}",
        "comments": [
            {
                "comment": "Would it make sense to store these keys in Secret Manager?",
                "position": null
            },
            {
                "comment": "These are random strings used as fake keys and are immediately deleted.",
                "position": null
            },
            {
                "comment": "Then it's probably clearer and safer to generate these on the fly during the test -- you can use a UUID or some other random string right?",
                "position": null
            },
            {
                "comment": "Here and elsewhere, consider using `r.Fatalf` if this operation needs to succeed in order for subsequent steps to work.",
                "position": null
            },
            {
                "comment": "Done - generating UUIDs",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "address feedback",
        "commit_id": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -204,23 +204,23 @@\nfunc TestCdnKeys(t *testing.T) {\n \t// Create a new Media CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectNumber, location, mediaCDNKeyID)\n-\t\tif err := createCdnKey(buf, tc.ProjectID, mediaCDNKeyID, hostname, keyName, mediaCDNPrivateKey, true); err != nil {\n-\t\t\tt.Fatalf(\"createCdnKey (Media CDN) got err: %v\", err)\n+\t\tif err := createCDNKey(buf, tc.ProjectID, mediaCDNKeyID, hostname, keyName, mediaCDNPrivateKey, true); err != nil {\n+\t\t\tt.Fatalf(\"createCDNKey (Media CDN) got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tt.Fatalf(\"createCdnKey (Media CDN) got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tt.Fatalf(\"createCDNKey (Media CDN) got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// List the CDN keys for a given location.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, mediaCDNKeyID)\n-\t\tif err := listCdnKeys(buf, tc.ProjectID); err != nil {\n-\t\t\tr.Errorf(\"listCdnKeys got err: %v\", err)\n+\t\tif err := listCDNKeys(buf, tc.ProjectID); err != nil {\n+\t\t\tr.Errorf(\"listCDNKeys got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"listCdnKeys got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"listCDNKeys got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()",
        "comments": [
            {
                "comment": "Would it make sense to store these keys in Secret Manager?",
                "position": null
            },
            {
                "comment": "These are random strings used as fake keys and are immediately deleted.",
                "position": null
            },
            {
                "comment": "Then it's probably clearer and safer to generate these on the fly during the test -- you can use a UUID or some other random string right?",
                "position": null
            },
            {
                "comment": "Here and elsewhere, consider using `r.Fatalf` if this operation needs to succeed in order for subsequent steps to work.",
                "position": null
            },
            {
                "comment": "Done - generating UUIDs",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "address feedback",
        "commit_id": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -233,33 +233,33 @@\nfunc TestCdnKeys(t *testing.T) {\n \n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, mediaCDNKeyID)\n-\t\tif err := updateCdnKey(buf, tc.ProjectID, mediaCDNKeyID, updatedHostname, keyName, updatedMediaCDNPrivateKey, true); err != nil {\n-\t\t\tr.Errorf(\"updateCdnKey got err: %v\", err)\n+\t\tif err := updateCDNKey(buf, tc.ProjectID, mediaCDNKeyID, updatedHostname, keyName, updatedMediaCDNPrivateKey, true); err != nil {\n+\t\t\tr.Errorf(\"updateCDNKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"updateCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"updateCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// Get the updated CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, mediaCDNKeyID)\n-\t\tif err := getCdnKey(buf, tc.ProjectID, mediaCDNKeyID); err != nil {\n-\t\t\tr.Errorf(\"getCdnKey got err: %v\", err)\n+\t\tif err := getCDNKey(buf, tc.ProjectID, mediaCDNKeyID); err != nil {\n+\t\t\tr.Errorf(\"getCDNKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"getCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"getCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \n \t// Delete the CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tif err := deleteCdnKey(buf, tc.ProjectID, mediaCDNKeyID); err != nil {\n-\t\t\tr.Errorf(\"deleteCdnKey got err: %v\", err)\n+\t\tif err := deleteCDNKey(buf, tc.ProjectID, mediaCDNKeyID); err != nil {\n+\t\t\tr.Errorf(\"deleteCDNKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, deleteCDNKeyResponse) {\n-\t\t\tr.Errorf(\"deleteCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteCDNKeyResponse)\n+\t\t\tr.Errorf(\"deleteCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteCDNKeyResponse)\n \t\t}\n \t})",
        "comments": [
            {
                "comment": "Would it make sense to store these keys in Secret Manager?",
                "position": null
            },
            {
                "comment": "These are random strings used as fake keys and are immediately deleted.",
                "position": null
            },
            {
                "comment": "Then it's probably clearer and safer to generate these on the fly during the test -- you can use a UUID or some other random string right?",
                "position": null
            },
            {
                "comment": "Here and elsewhere, consider using `r.Fatalf` if this operation needs to succeed in order for subsequent steps to work.",
                "position": null
            },
            {
                "comment": "Done - generating UUIDs",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "address feedback",
        "commit_id": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -273,23 +273,23 @@\nfunc TestCdnKeys(t *testing.T) {\n \n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectNumber, location, cloudCDNKeyID)\n-\t\tif err := createCdnKey(buf, tc.ProjectID, cloudCDNKeyID, hostname, keyName, cloudCDNPrivateKey, false); err != nil {\n-\t\t\tt.Fatalf(\"createCdnKey (Cloud CDN) got err: %v\", err)\n+\t\tif err := createCDNKey(buf, tc.ProjectID, cloudCDNKeyID, hostname, keyName, cloudCDNPrivateKey, false); err != nil {\n+\t\t\tt.Fatalf(\"createCDNKey (Cloud CDN) got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tt.Fatalf(\"createCdnKey (Cloud CDN) got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tt.Fatalf(\"createCDNKey (Cloud CDN) got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// List the CDN keys for a given location.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, cloudCDNKeyID)\n-\t\tif err := listCdnKeys(buf, tc.ProjectID); err != nil {\n-\t\t\tr.Errorf(\"listCdnKeys got err: %v\", err)\n+\t\tif err := listCDNKeys(buf, tc.ProjectID); err != nil {\n+\t\t\tr.Errorf(\"listCDNKeys got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"listCdnKeys got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"listCDNKeys got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()",
        "comments": [
            {
                "comment": "Would it make sense to store these keys in Secret Manager?",
                "position": null
            },
            {
                "comment": "These are random strings used as fake keys and are immediately deleted.",
                "position": null
            },
            {
                "comment": "Then it's probably clearer and safer to generate these on the fly during the test -- you can use a UUID or some other random string right?",
                "position": null
            },
            {
                "comment": "Here and elsewhere, consider using `r.Fatalf` if this operation needs to succeed in order for subsequent steps to work.",
                "position": null
            },
            {
                "comment": "Done - generating UUIDs",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "address feedback",
        "commit_id": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -302,33 +302,33 @@\nfunc TestCdnKeys(t *testing.T) {\n \n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, cloudCDNKeyID)\n-\t\tif err := updateCdnKey(buf, tc.ProjectID, cloudCDNKeyID, updatedHostname, keyName, updatedCloudCDNPrivateKey, false); err != nil {\n-\t\t\tr.Errorf(\"updateCdnKey got err: %v\", err)\n+\t\tif err := updateCDNKey(buf, tc.ProjectID, cloudCDNKeyID, updatedHostname, keyName, updatedCloudCDNPrivateKey, false); err != nil {\n+\t\t\tr.Errorf(\"updateCDNKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"updateCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"updateCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// Get the updated CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, cloudCDNKeyID)\n-\t\tif err := getCdnKey(buf, tc.ProjectID, cloudCDNKeyID); err != nil {\n-\t\t\tr.Errorf(\"getCdnKey got err: %v\", err)\n+\t\tif err := getCDNKey(buf, tc.ProjectID, cloudCDNKeyID); err != nil {\n+\t\t\tr.Errorf(\"getCDNKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"getCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"getCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \n \t// Delete the CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tif err := deleteCdnKey(buf, tc.ProjectID, cloudCDNKeyID); err != nil {\n-\t\t\tr.Errorf(\"deleteCdnKey got err: %v\", err)\n+\t\tif err := deleteCDNKey(buf, tc.ProjectID, cloudCDNKeyID); err != nil {\n+\t\t\tr.Errorf(\"deleteCDNKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, deleteCDNKeyResponse) {\n-\t\t\tr.Errorf(\"deleteCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteCDNKeyResponse)\n+\t\t\tr.Errorf(\"deleteCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteCDNKeyResponse)\n \t\t}\n \t})",
        "comments": [
            {
                "comment": "Would it make sense to store these keys in Secret Manager?",
                "position": null
            },
            {
                "comment": "These are random strings used as fake keys and are immediately deleted.",
                "position": null
            },
            {
                "comment": "Then it's probably clearer and safer to generate these on the fly during the test -- you can use a UUID or some other random string right?",
                "position": null
            },
            {
                "comment": "Here and elsewhere, consider using `r.Fatalf` if this operation needs to succeed in order for subsequent steps to work.",
                "position": null
            },
            {
                "comment": "Done - generating UUIDs",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "address feedback",
        "commit_id": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -342,23 +342,23 @@\nfunc TestCdnKeys(t *testing.T) {\n \n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectNumber, location, akamaiCDNKeyID)\n-\t\tif err := createCdnKeyAkamai(buf, tc.ProjectID, akamaiCDNKeyID, hostname, akamaiTokenKey); err != nil {\n-\t\t\tt.Fatalf(\"createCdnKeyAkamai got err: %v\", err)\n+\t\tif err := createCDNKeyAkamai(buf, tc.ProjectID, akamaiCDNKeyID, hostname, akamaiTokenKey); err != nil {\n+\t\t\tt.Fatalf(\"createCDNKeyAkamai got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tt.Fatalf(\"createCdnKeyAkamai got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tt.Fatalf(\"createCDNKeyAkamai got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// List the CDN keys for a given location.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, akamaiCDNKeyID)\n-\t\tif err := listCdnKeys(buf, tc.ProjectID); err != nil {\n-\t\t\tr.Errorf(\"listCdnKeys got err: %v\", err)\n+\t\tif err := listCDNKeys(buf, tc.ProjectID); err != nil {\n+\t\t\tr.Errorf(\"listCDNKeys got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"listCdnKeys got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"listCDNKeys got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()",
        "comments": [
            {
                "comment": "Would it make sense to store these keys in Secret Manager?",
                "position": null
            },
            {
                "comment": "These are random strings used as fake keys and are immediately deleted.",
                "position": null
            },
            {
                "comment": "Then it's probably clearer and safer to generate these on the fly during the test -- you can use a UUID or some other random string right?",
                "position": null
            },
            {
                "comment": "Here and elsewhere, consider using `r.Fatalf` if this operation needs to succeed in order for subsequent steps to work.",
                "position": null
            },
            {
                "comment": "Done - generating UUIDs",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "address feedback",
        "commit_id": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(asset): added sample code for getting a saved query",
        "pr_number": 2783,
        "file_name": "asset/quickstart/get-saved-query/get_saved_query.go",
        "code_diff": "@@ -11,22 +11,22 @@\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n // See the License for the specific language governing permissions and\n // limitations under the License.\n- \n+\n // [START asset_quickstart_get_saved_query]\n- \n+\n package get\n- \n+\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"strconv\"\n- \n+\n \tasset \"cloud.google.com/go/asset/apiv1\"\n \t\"cloud.google.com/go/asset/apiv1/assetpb\"\n \tcloudresourcemanager \"google.golang.org/api/cloudresourcemanager/v1\"\n )\n- \n+\n func getSavedQuery(w io.Writer, projectId, savedQueryID string) error {\n \t// projectID := \"my-project-id\"\n \t// savedQueryID := \"query-ID\"",
        "comments": [],
        "commit_message": "Used goimports to fixed lint errors.",
        "commit_id": "05ab5f3fd61ff612265e73e2e1ffac24ea776504"
    },
    {
        "pr_title": "feat(asset): added sample code for getting a saved query",
        "pr_number": 2783,
        "file_name": "asset/quickstart/get-saved-query/get_saved_query.go",
        "code_diff": "@@ -36,12 +36,12 @@\nfunc getSavedQuery(w io.Writer, projectId, savedQueryID string) error {\n \t\treturn fmt.Errorf(\"asset.NewClient: %v\", err)\n \t}\n \tdefer client.Close()\n- \n+\n \tcloudResourceManagerClient, err := cloudresourcemanager.NewService(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"cloudresourcemanager.NewService: %v\", err)\n \t}\n- \n+\n \tproject, err := cloudResourceManagerClient.Projects.Get(projectId).Do()\n \tif err != nil {\n \t\treturn fmt.Errorf(\"cloudresourcemanagerClient.Projects.Get.Do: %v\", err)",
        "comments": [],
        "commit_message": "Used goimports to fixed lint errors.",
        "commit_id": "05ab5f3fd61ff612265e73e2e1ffac24ea776504"
    },
    {
        "pr_title": "feat(asset): added sample code for getting a saved query",
        "pr_number": 2783,
        "file_name": "asset/quickstart/get-saved-query/main_test.go",
        "code_diff": "@@ -11,9 +11,9 @@\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n // See the License for the specific language governing permissions and\n // limitations under the License.\n- \n+\n package get\n- \n+\n import (\n \t\"bytes\"\n \t\"context\"",
        "comments": [
            {
                "comment": "See previous about package names.",
                "position": null
            },
            {
                "comment": "Since we only really want to check that the sample works, rather than the client, I would move all of the previous code into a `TestMain(m *testing.M)` function.",
                "position": null
            },
            {
                "comment": "TestMain is great! however, in our case, we want to verify the query we just created so we need the projectID and queryID to be used by code above and the get method. \r\n\r\nis there a way to pass info from TestMain to a specific test method? ",
                "position": null
            },
            {
                "comment": "You can set the `projectID` and `queryID` as global variables that are set from within `TestMain`.\r\n\r\n```go\r\nvar (\r\n    projectID string\r\n    queryID string\r\n)\r\n\r\nfunc TestMain(m *testing.M) {\r\n    projectID = //...\r\n    queryID = // ...\r\n\r\n    m.Run()\r\n}\r\n\r\nfunc TestDoingTheSample(t *testing.T) {\r\n   // use the projectID, queryID, etc\r\n}\r\n```",
                "position": null
            },
            {
                "comment": "changed:)",
                "position": null
            },
            {
                "comment": "thanks for the clarification! changed in the new commit:)",
                "position": null
            }
        ],
        "commit_message": "Used goimports to fixed lint errors.",
        "commit_id": "05ab5f3fd61ff612265e73e2e1ffac24ea776504"
    },
    {
        "pr_title": "feat(asset): added sample code for getting a saved query",
        "pr_number": 2783,
        "file_name": "asset/quickstart/get-saved-query/main_test.go",
        "code_diff": "@@ -24,21 +24,21 @@\nimport (\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n- \n+\n \tasset \"cloud.google.com/go/asset/apiv1\"\n \t\"cloud.google.com/go/asset/apiv1/assetpb\"\n \tcloudresourcemanager \"google.golang.org/api/cloudresourcemanager/v1\"\n )\n- \n+\n var (\n \tprojectID     string\n \tsavedQueryID  string\n \tprojectNumber string\n- \n+\n \tctx    context.Context\n \tclient *asset.Client\n )\n- \n+\n func TestMain(m *testing.M) {\n \tprojectID = os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tsavedQueryID = fmt.Sprintf(\"query-%s\", strconv.FormatInt(time.Now().UnixNano(), 10))",
        "comments": [
            {
                "comment": "See previous about package names.",
                "position": null
            },
            {
                "comment": "Since we only really want to check that the sample works, rather than the client, I would move all of the previous code into a `TestMain(m *testing.M)` function.",
                "position": null
            },
            {
                "comment": "TestMain is great! however, in our case, we want to verify the query we just created so we need the projectID and queryID to be used by code above and the get method. \r\n\r\nis there a way to pass info from TestMain to a specific test method? ",
                "position": null
            },
            {
                "comment": "You can set the `projectID` and `queryID` as global variables that are set from within `TestMain`.\r\n\r\n```go\r\nvar (\r\n    projectID string\r\n    queryID string\r\n)\r\n\r\nfunc TestMain(m *testing.M) {\r\n    projectID = //...\r\n    queryID = // ...\r\n\r\n    m.Run()\r\n}\r\n\r\nfunc TestDoingTheSample(t *testing.T) {\r\n   // use the projectID, queryID, etc\r\n}\r\n```",
                "position": null
            },
            {
                "comment": "changed:)",
                "position": null
            },
            {
                "comment": "thanks for the clarification! changed in the new commit:)",
                "position": null
            }
        ],
        "commit_message": "Used goimports to fixed lint errors.",
        "commit_id": "05ab5f3fd61ff612265e73e2e1ffac24ea776504"
    },
    {
        "pr_title": "feat(asset): added sample code for getting a saved query",
        "pr_number": 2783,
        "file_name": "asset/quickstart/get-saved-query/main_test.go",
        "code_diff": "@@ -48,20 +48,20 @@\nfunc TestMain(m *testing.M) {\n \tif err != nil {\n \t\tlog.Fatalf(\"asset.NewClient: %v\", err)\n \t}\n- \n+\n \tcloudResourceManagerClient, err := cloudresourcemanager.NewService(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"cloudresourcemanager.NewService: %v\", err)\n \t}\n- \n+\n \tproject, err := cloudResourceManagerClient.Projects.Get(projectID).Do()\n \tif err != nil {\n \t\tlog.Fatalf(\"cloudResourceManagerClient.Projects.Get.Do: %v\", err)\n \t}\n \tprojectNumber = strconv.FormatInt(project.ProjectNumber, 10)\n \tparent := fmt.Sprintf(\"projects/%s\", projectID)\n \tlog.Printf(\"projectNumber:%s\", projectNumber)\n- \n+\n \treq := &assetpb.CreateSavedQueryRequest{\n \t\tParent:       parent,\n \t\tSavedQueryId: savedQueryID,",
        "comments": [
            {
                "comment": "See previous about package names.",
                "position": null
            },
            {
                "comment": "Since we only really want to check that the sample works, rather than the client, I would move all of the previous code into a `TestMain(m *testing.M)` function.",
                "position": null
            },
            {
                "comment": "TestMain is great! however, in our case, we want to verify the query we just created so we need the projectID and queryID to be used by code above and the get method. \r\n\r\nis there a way to pass info from TestMain to a specific test method? ",
                "position": null
            },
            {
                "comment": "You can set the `projectID` and `queryID` as global variables that are set from within `TestMain`.\r\n\r\n```go\r\nvar (\r\n    projectID string\r\n    queryID string\r\n)\r\n\r\nfunc TestMain(m *testing.M) {\r\n    projectID = //...\r\n    queryID = // ...\r\n\r\n    m.Run()\r\n}\r\n\r\nfunc TestDoingTheSample(t *testing.T) {\r\n   // use the projectID, queryID, etc\r\n}\r\n```",
                "position": null
            },
            {
                "comment": "changed:)",
                "position": null
            },
            {
                "comment": "thanks for the clarification! changed in the new commit:)",
                "position": null
            }
        ],
        "commit_message": "Used goimports to fixed lint errors.",
        "commit_id": "05ab5f3fd61ff612265e73e2e1ffac24ea776504"
    },
    {
        "pr_title": "feat(kms): Add docs samples for KMS key import.",
        "pr_number": 2779,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -28,17 +28,18 @@\nimport (\n \t\"cloud.google.com/go/storage\"\n \tstoragetransfer \"cloud.google.com/go/storagetransfer/apiv1\"\n \t\"cloud.google.com/go/storagetransfer/apiv1/storagetransferpb\"\n+\tazblob \"github.com/Azure/azure-sdk-for-go/sdk/storage/azblob\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/aws/aws-sdk-go/aws\"\n \t\"github.com/aws/aws-sdk-go/aws/session\"\n-\t\"github.com/aws/aws-sdk-go/service/s3/s3manager\"\n-\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/aws/aws-sdk-go/service/s3\"\n+\t\"github.com/aws/aws-sdk-go/service/s3/s3manager\"\n )\n \n var sc *storage.Client\n var sts *storagetransfer.Client\n var s3Bucket string\n+var azureContainer string\n var gcsSourceBucket string\n var gcsSinkBucket string",
        "comments": [],
        "commit_message": "Merge branch 'main' into import",
        "commit_id": "ea36b7fb332218d20a09e4c69d05a5243f50c336"
    },
    {
        "pr_title": "feat(kms): Add docs samples for KMS key import.",
        "pr_number": 2779,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -89,6 +90,19 @@\nfunc TestMain(m *testing.M) {\n \t\tlog.Fatalf(\"couldn't create S3 bucket: %v\", err)\n \t}\n \n+\tconnectionString := os.Getenv(\"AZURE_CONNECTION_STRING\") +\n+\t\t\";\" + \"AccountName=\" + os.Getenv(\"AZURE_STORAGE_ACCOUNT\")\n+\tazClient, err := azblob.NewClientFromConnectionString(connectionString, nil)\n+\tif err != nil {\n+\t\tlog.Fatal(\"Couldn't create Azure client: \" + err.Error())\n+\t}\n+\tazureContainer = testutil.UniqueBucketName(\"azurebucket\")\n+\n+\tazClient.CreateContainer(ctx, azureContainer, nil)\n+\tif err != nil {\n+\t\tlog.Fatal(err)\n+\t}\n+\n \t// Run tests\n \texit := m.Run()",
        "comments": [],
        "commit_message": "Merge branch 'main' into import",
        "commit_id": "ea36b7fb332218d20a09e4c69d05a5243f50c336"
    },
    {
        "pr_title": "feat(kms): Add docs samples for KMS key import.",
        "pr_number": 2779,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -111,6 +125,11 @@\nfunc TestMain(m *testing.M) {\n \t\tlog.Printf(\"couldn't delete S3 bucket: %v\", err)\n \t}\n \n+\t_, err = azClient.DeleteContainer(ctx, azureContainer, nil)\n+\tif err != nil {\n+\t\tlog.Printf(\"couldn't delete Azure bucket: %v\", err)\n+\t}\n+\n \tos.Exit(exit)\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into import",
        "commit_id": "ea36b7fb332218d20a09e4c69d05a5243f50c336"
    },
    {
        "pr_title": "feat(cloudsql): add MySQL Auto IAM AuthN sample",
        "pr_number": 2766,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -260,40 +260,42 @@\nfunc TestPullMsgsAsync(t *testing.T) {\n \tasyncTopicID := topicID + \"-async\"\n \tasyncSubID := subID + \"-async\"\n \n-\ttopic, err := getOrCreateTopic(ctx, client, asyncTopicID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer topic.Delete(ctx)\n-\tdefer topic.Stop()\n+\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\t\ttopic, err := getOrCreateTopic(ctx, client, asyncTopicID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t}\n+\t\tdefer topic.Delete(ctx)\n+\t\tdefer topic.Stop()\n \n-\tcfg := &pubsub.SubscriptionConfig{\n-\t\tTopic: topic,\n-\t}\n-\tsub, err := getOrCreateSub(ctx, client, asyncSubID, cfg)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateSub: %v\", err)\n-\t}\n-\tdefer sub.Delete(ctx)\n+\t\tcfg := &pubsub.SubscriptionConfig{\n+\t\t\tTopic: topic,\n+\t\t}\n+\t\tsub, err := getOrCreateSub(ctx, client, asyncSubID, cfg)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateSub: %v\", err)\n+\t\t}\n+\t\tdefer sub.Delete(ctx)\n \n-\t// Publish 1 message. This avoids race conditions\n-\t// when calling fmt.Fprintf from multiple receive\n-\t// callbacks. This is sufficient for testing since\n-\t// we're not testing client library functionality,\n-\t// and makes the sample more readable.\n-\tconst numMsgs = 1\n-\tpublishMsgs(ctx, topic, numMsgs)\n+\t\t// Publish 1 message. This avoids race conditions\n+\t\t// when calling fmt.Fprintf from multiple receive\n+\t\t// callbacks. This is sufficient for testing since\n+\t\t// we're not testing client library functionality,\n+\t\t// and makes the sample more readable.\n+\t\tconst numMsgs = 1\n+\t\tpublishMsgs(ctx, topic, numMsgs)\n \n-\tbuf := new(bytes.Buffer)\n-\terr = pullMsgs(buf, tc.ProjectID, asyncSubID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to pull messages: %v\", err)\n-\t}\n-\tgot := buf.String()\n-\twant := fmt.Sprintf(\"Received %d messages\\n\", numMsgs)\n-\tif !strings.Contains(got, want) {\n-\t\tt.Fatalf(\"pullMsgs got %s\\nwant %s\", got, want)\n-\t}\n+\t\tbuf := new(bytes.Buffer)\n+\t\terr = pullMsgs(buf, tc.ProjectID, asyncSubID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"failed to pull messages: %v\", err)\n+\t\t}\n+\t\tgot := buf.String()\n+\t\twant := fmt.Sprintf(\"Received %d messages\\n\", numMsgs)\n+\t\tif !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"pullMsgs got %s\\nwant %s\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestPullMsgsSync(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-mysql-iam-authn",
        "commit_id": "afd551517133e354d10019ace14dd0cb220a6dbe"
    },
    {
        "pr_title": "feat(cloudsql): add MySQL Auto IAM AuthN sample",
        "pr_number": 2766,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -304,41 +306,43 @@\nfunc TestPullMsgsSync(t *testing.T) {\n \ttopicIDSync := topicID + \"-sync\"\n \tsubIDSync := subID + \"-sync\"\n \n-\ttopic, err := getOrCreateTopic(ctx, client, topicIDSync)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer topic.Delete(ctx)\n-\tdefer topic.Stop()\n+\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\t\ttopic, err := getOrCreateTopic(ctx, client, topicIDSync)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t}\n+\t\tdefer topic.Delete(ctx)\n+\t\tdefer topic.Stop()\n \n-\tcfg := &pubsub.SubscriptionConfig{\n-\t\tTopic: topic,\n-\t}\n-\tsub, err := getOrCreateSub(ctx, client, subIDSync, cfg)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateSub: %v\", err)\n-\t}\n-\tdefer sub.Delete(ctx)\n+\t\tcfg := &pubsub.SubscriptionConfig{\n+\t\t\tTopic: topic,\n+\t\t}\n+\t\tsub, err := getOrCreateSub(ctx, client, subIDSync, cfg)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateSub: %v\", err)\n+\t\t}\n+\t\tdefer sub.Delete(ctx)\n \n-\t// Publish 1 message. This avoids race conditions\n-\t// when calling fmt.Fprintf from multiple receive\n-\t// callbacks. This is sufficient for testing since\n-\t// we're not testing client library functionality,\n-\t// and makes the sample more readable.\n-\tconst numMsgs = 1\n-\tpublishMsgs(ctx, topic, numMsgs)\n+\t\t// Publish 1 message. This avoids race conditions\n+\t\t// when calling fmt.Fprintf from multiple receive\n+\t\t// callbacks. This is sufficient for testing since\n+\t\t// we're not testing client library functionality,\n+\t\t// and makes the sample more readable.\n+\t\tconst numMsgs = 1\n+\t\tpublishMsgs(ctx, topic, numMsgs)\n \n-\tbuf := new(bytes.Buffer)\n-\terr = pullMsgsSync(buf, tc.ProjectID, subIDSync)\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to pull messages: %v\", err)\n-\t}\n+\t\tbuf := new(bytes.Buffer)\n+\t\terr = pullMsgsSync(buf, tc.ProjectID, subIDSync)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"failed to pull messages: %v\", err)\n+\t\t}\n \n-\tgot := buf.String()\n-\twant := fmt.Sprintf(\"Received %d messages\\n\", numMsgs)\n-\tif !strings.Contains(got, want) {\n-\t\tt.Fatalf(\"pullMsgsSync got %s\\nwant %s\", got, want)\n-\t}\n+\t\tgot := buf.String()\n+\t\twant := fmt.Sprintf(\"Received %d messages\\n\", numMsgs)\n+\t\tif !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"pullMsgsSync got %s\\nwant %s\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestPullMsgsConcurrencyControl(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-mysql-iam-authn",
        "commit_id": "afd551517133e354d10019ace14dd0cb220a6dbe"
    },
    {
        "pr_title": "feat(cloudsql): add MySQL Auto IAM AuthN sample",
        "pr_number": 2766,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -349,7 +353,7 @@\nfunc TestPullMsgsConcurrencyControl(t *testing.T) {\n \ttopicIDConc := topicID + \"-conc\"\n \tsubIDConc := subID + \"-conc\"\n \n-\ttestutil.Retry(t, 3, time.Second, func(r *testutil.R) {\n+\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n \t\ttopic, err := getOrCreateTopic(ctx, client, topicIDConc)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-mysql-iam-authn",
        "commit_id": "afd551517133e354d10019ace14dd0cb220a6dbe"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "batch/get_job.go",
        "code_diff": "@@ -25,15 +25,15 @@\nimport (\n )\n \n // Retrieves the information about the specified job, most importantly its status\n-func getJob(w io.Writer, projectID, region, jobName string) error {\n+func getJob(w io.Writer, projectID, region, jobName string) (*batchpb.Job, error) {\n \t// projectID := \"your_project_id\"\n \t// region := \"us-central1\"\n \t// jobName := \"some-job\"\n \n \tctx := context.Background()\n \tbatchClient, err := batch.NewClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"NewClient: %v\", err)\n \t}\n \tdefer batchClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "batch/job_basics_test.go",
        "code_diff": "@@ -26,6 +26,7 @@\nimport (\n )\n \n func TestBatchJobCRUD(t *testing.T) {\n+\tt.Parallel()\n \tvar r *rand.Rand = rand.New(\n \t\trand.NewSource(time.Now().UnixNano()))\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "batch/job_basics_test.go",
        "code_diff": "@@ -38,9 +39,18 @@\nfunc TestBatchJobCRUD(t *testing.T) {\n \t\tt.Errorf(\"createScriptJob got err: %v\", err)\n \t}\n \n+\tsucceeded, err := jobSucceeded(tc.ProjectID, region, jobName)\n+\tif err != nil {\n+\t\tt.Errorf(\"Could not verify job completion: %v\", err)\n+\t}\n+\tif !succeeded {\n+\t\tt.Errorf(\"The test job has failed: %v\", err)\n+\t}\n+\n \tbuf.Reset()\n \n-\tif err := getJob(buf, tc.ProjectID, region, jobName); err != nil {\n+\tjob, err := getJob(buf, tc.ProjectID, region, jobName)\n+\tif err != nil {\n \t\tt.Errorf(\"getJob got err: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "batch/job_basics_test.go",
        "code_diff": "@@ -56,18 +66,9 @@\nfunc TestBatchJobCRUD(t *testing.T) {\n \tbuf.Reset()\n \n \t// Tasks take a couple of seconds to be created on the server side.\n-\t// We're going to poll until they're created, or give up if the errors are persistent.\n-\tvar attempts uint = 0\n-\tvar loop_err = getTask(buf, tc.ProjectID, region, jobName, \"group0\", 0)\n-\tfor loop_err != nil {\n-\t\tattempts += 1\n-\t\t// tasks usually appear in a couple of seconds, 20 seconds is way more than enough\n-\t\tif attempts > 20 {\n-\t\t\tt.Errorf(\"getTask got err: %v\", loop_err)\n-\t\t\tbreak\n-\t\t}\n-\t\ttime.Sleep(1 * time.Second)\n-\t\tloop_err = getTask(buf, tc.ProjectID, region, jobName, \"group0\", 0)\n+\t// But since we already verified that the job has completed, we don't need to wait any further.\n+\tif err := getTask(buf, tc.ProjectID, region, jobName, \"group0\", 0); err != nil {\n+\t\tt.Errorf(\"getTask got err: %v\", err)\n \t}\n \tif got := buf.String(); !strings.Contains(got, \"status:\") {\n \t\tt.Errorf(\"getTask got %q, expected %q\", got, \"status:\")",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "batch/job_basics_test.go",
        "code_diff": "@@ -84,12 +85,22 @@\nfunc TestBatchJobCRUD(t *testing.T) {\n \n \tbuf.Reset()\n \n+\tif err := printJobLogs(buf, tc.ProjectID, job); err != nil {\n+\t\tt.Errorf(\"printJobLogs got err: %v\", err)\n+\t}\n+\tif got := buf.String(); !strings.Contains(got, \"Hello world!\") {\n+\t\tt.Errorf(\"printJobLogs got %q, expected %q\", got, \"Hello world!\")\n+\t}\n+\n+\tbuf.Reset()\n+\n \tif err := deleteJob(buf, tc.ProjectID, region, jobName); err != nil {\n \t\tt.Errorf(\"deleteJob got err: %v\", err)\n \t}\n }\n \n func TestBatchContainerJob(t *testing.T) {\n+\tt.Parallel()\n \tvar r *rand.Rand = rand.New(\n \t\trand.NewSource(time.Now().UnixNano()))\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "functions/memorystore/redis/visitcount.go",
        "code_diff": "@@ -25,11 +25,17 @@\nimport (\n \t\"net/http\"\n \t\"os\"\n \n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \t\"github.com/gomodule/redigo/redis\"\n )\n \n var redisPool *redis.Pool\n \n+func init() {\n+\t// Register the HTTP handler with the Functions Framework\n+\tfunctions.HTTP(\"VisitCount\", visitCount)\n+}\n+\n // initializeRedis initializes and returns a connection pool\n func initializeRedis() (*redis.Pool, error) {\n \tredisHost := os.Getenv(\"REDISHOST\")",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n-// [START basic_keyword_search]\n+// [START job_discovery_basic_keyword_search]\n \n // basicJobSearch searches for jobs with query.\n func basicJobSearch(w io.Writer, projectID, companyName, query string) (*talent.SearchJobsResponse, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -76,9 +76,9 @@\nfunc basicJobSearch(w io.Writer, projectID, companyName, query string) (*talent.\n \treturn resp, nil\n }\n \n-// [END basic_keyword_search]\n+// [END job_discovery_basic_keyword_search]\n \n-// [START category_filter]\n+// [START job_discovery_category_filter_search]\n \n // categoryFilterSearch searches for jobs on category filter.\n func categoryFilterSearch(w io.Writer, projectID, companyName string, categories []string) (*talent.SearchJobsResponse, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -131,9 +131,9 @@\nfunc categoryFilterSearch(w io.Writer, projectID, companyName string, categories\n \treturn resp, nil\n }\n \n-// [END category_filter]\n+// [END job_discovery_category_filter_search]\n \n-// [START employment_types_filter]\n+// [START job_discovery_employment_types_filter_search]\n \n // employmentTypesSearch searches for jobs on employment types.\n func employmentTypesSearch(w io.Writer, projectID, companyName string, employmentTypes []string) (*talent.SearchJobsResponse, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -186,9 +186,9 @@\nfunc employmentTypesSearch(w io.Writer, projectID, companyName string, employmen\n \treturn resp, nil\n }\n \n-// [END employment_types_filter]\n+// [END job_discovery_employment_types_filter_search]\n \n-// [START date_range_filter]\n+// [START job_discovery_date_range_filter_search]\n \n // /dateRangeSearch searches for jobs on date range.\n // In JSON format, the Timestamp type is encoded as a string in the",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -248,9 +248,9 @@\nfunc dateRangeSearch(w io.Writer, projectID, companyName, startTime, endTime str\n \treturn resp, nil\n }\n \n-// [END date_range_filter]\n+// [END job_discovery_date_range_filter_search]\n \n-// [START language_code_filter]\n+// [START job_discovery_language_code_filter_search]\n \n // languageCodeSearch searches for jobs on language code.\n func languageCodeSearch(w io.Writer, projectID, companyName string, languageCodes []string) (*talent.SearchJobsResponse, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -303,9 +303,9 @@\nfunc languageCodeSearch(w io.Writer, projectID, companyName string, languageCode\n \treturn resp, nil\n }\n \n-// [END language_code_filter]\n+// [END job_discovery_language_code_filter_search]\n \n-// [START company_display_name_filter]\n+// [START job_discovery_company_display_name_search]\n \n // companyDisplayNameSearch searches for job on company display names.\n func companyDisplayNameSearch(w io.Writer, projectID, companyName string, companyDisplayNames []string) (*talent.SearchJobsResponse, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -358,9 +358,9 @@\nfunc companyDisplayNameSearch(w io.Writer, projectID, companyName string, compan\n \treturn resp, nil\n }\n \n-// [END company_display_name_filter]\n+// [END job_discovery_company_display_name_search]\n \n-// [START compensation_filter]\n+// [START job_discovery_compensation_search]\n \n // compensationSearch searches for job on compensation.\n func compensationSearch(w io.Writer, projectID, companyName string) (*talent.SearchJobsResponse, error) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-pg-iam-authn",
        "commit_id": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(storage): add autoclass samples",
        "pr_number": 2737,
        "file_name": "bigquery/snippets/job/bigquery_export_model.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage job\n \n-// [START bigquery_extract_model]\n+// [START bigquery_export_model]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into 2707-autoclass",
        "commit_id": "fb9a0ed39db33ccf5aafe0760737af40153dad33"
    },
    {
        "pr_title": "feat(bigquery): add sample to insert data with complex data types",
        "pr_number": 2731,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -138,6 +138,12 @@\nfunc TestCopiesAndExtracts(t *testing.T) {\n \t\tt.Fatalf(\"cannot create bucket: %v\", err)\n \t}\n \n+\tmodel := client.DatasetInProject(tc.ProjectID, testDatasetID).Model(\"model\")\n+\tif err := generateModel(client, tc.ProjectID, testDatasetID, model.ModelID); err != nil {\n+\t\tt.Fatalf(\"cannot create BQ ML model: %v\", err)\n+\t}\n+\tdefer model.Delete(ctx)\n+\n \t// Run extract job tests in parallel.\n \tt.Run(\"extract\", func(t *testing.T) {\n \t\tt.Run(\"exportTableAsCSV\", func(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into bq-insert-data-types",
        "commit_id": "6e7793bf92663accdf8474b446ff63823c8a3531"
    },
    {
        "pr_title": "feat(bigquery): add sample to insert data with complex data types",
        "pr_number": 2731,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -154,15 +160,20 @@\nfunc TestCopiesAndExtracts(t *testing.T) {\n \t\t\tif err := exportTableAsCompressedCSV(tc.ProjectID, gcsURI); err != nil {\n \t\t\t\tt.Errorf(\"exportTableAsCompressedCSV(%s): %v\", gcsURI, err)\n \t\t\t}\n-\n \t\t})\n \t\tt.Run(\"exportTableAsJSON\", func(t *testing.T) {\n \t\t\tt.Parallel()\n \t\t\tgcsURI := fmt.Sprintf(\"gs://%s/%s\", bucket, \"shakespeare.json\")\n \t\t\tif err := exportTableAsJSON(tc.ProjectID, gcsURI); err != nil {\n \t\t\t\tt.Errorf(\"exportTableAsJSON(%s): %v\", gcsURI, err)\n \t\t\t}\n-\n+\t\t})\n+\t\tt.Run(\"exportModel\", func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tgcsURI := fmt.Sprintf(\"gs://%s/%s\", bucket, \"model\")\n+\t\t\tif err := exportModel(tc.ProjectID, testDatasetID, model.ModelID, gcsURI); err != nil {\n+\t\t\t\tt.Errorf(\"exportModel(%s): %v\", gcsURI, err)\n+\t\t\t}\n \t\t})\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'main' into bq-insert-data-types",
        "commit_id": "6e7793bf92663accdf8474b446ff63823c8a3531"
    },
    {
        "pr_title": "feat(bigquery): add sample to insert data with complex data types",
        "pr_number": 2731,
        "file_name": "pubsub/subscriptions/pull_settings.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n )\n \n-func pullMsgsSettings(w io.Writer, projectID, subID string) error {\n+func pullMsgsFlowControlSettings(w io.Writer, projectID, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// subID := \"my-sub\"\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into bq-insert-data-types",
        "commit_id": "6e7793bf92663accdf8474b446ff63823c8a3531"
    },
    {
        "pr_title": "chore: update go version to 1.19",
        "pr_number": 2726,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -138,6 +138,12 @@\nfunc TestCopiesAndExtracts(t *testing.T) {\n \t\tt.Fatalf(\"cannot create bucket: %v\", err)\n \t}\n \n+\tmodel := client.DatasetInProject(tc.ProjectID, testDatasetID).Model(\"model\")\n+\tif err := generateModel(client, tc.ProjectID, testDatasetID, model.ModelID); err != nil {\n+\t\tt.Fatalf(\"cannot create BQ ML model: %v\", err)\n+\t}\n+\tdefer model.Delete(ctx)\n+\n \t// Run extract job tests in parallel.\n \tt.Run(\"extract\", func(t *testing.T) {\n \t\tt.Run(\"exportTableAsCSV\", func(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'update-go-version' of github.com:LukeSchlangen/golang-samples into update-go-version",
        "commit_id": "2c26fc89f351be42296045b11d55b9d2064d35da"
    },
    {
        "pr_title": "chore: update go version to 1.19",
        "pr_number": 2726,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -154,15 +160,20 @@\nfunc TestCopiesAndExtracts(t *testing.T) {\n \t\t\tif err := exportTableAsCompressedCSV(tc.ProjectID, gcsURI); err != nil {\n \t\t\t\tt.Errorf(\"exportTableAsCompressedCSV(%s): %v\", gcsURI, err)\n \t\t\t}\n-\n \t\t})\n \t\tt.Run(\"exportTableAsJSON\", func(t *testing.T) {\n \t\t\tt.Parallel()\n \t\t\tgcsURI := fmt.Sprintf(\"gs://%s/%s\", bucket, \"shakespeare.json\")\n \t\t\tif err := exportTableAsJSON(tc.ProjectID, gcsURI); err != nil {\n \t\t\t\tt.Errorf(\"exportTableAsJSON(%s): %v\", gcsURI, err)\n \t\t\t}\n-\n+\t\t})\n+\t\tt.Run(\"exportModel\", func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tgcsURI := fmt.Sprintf(\"gs://%s/%s\", bucket, \"model\")\n+\t\t\tif err := exportModel(tc.ProjectID, testDatasetID, model.ModelID, gcsURI); err != nil {\n+\t\t\t\tt.Errorf(\"exportModel(%s): %v\", gcsURI, err)\n+\t\t\t}\n \t\t})\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'update-go-version' of github.com:LukeSchlangen/golang-samples into update-go-version",
        "commit_id": "2c26fc89f351be42296045b11d55b9d2064d35da"
    },
    {
        "pr_title": "chore: update go version to 1.19",
        "pr_number": 2726,
        "file_name": "pubsub/subscriptions/pull_settings.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n )\n \n-func pullMsgsSettings(w io.Writer, projectID, subID string) error {\n+func pullMsgsFlowControlSettings(w io.Writer, projectID, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// subID := \"my-sub\"\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'update-go-version' of github.com:LukeSchlangen/golang-samples into update-go-version",
        "commit_id": "2c26fc89f351be42296045b11d55b9d2064d35da"
    },
    {
        "pr_title": "chore: update go version to 1.19",
        "pr_number": 2726,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -573,6 +573,43 @@\nfunc TestCreateDatabaseWithDefaultLeaderSample(t *testing.T) {\n \tassertContains(t, out, \"The result of the query to get\")\n }\n \n+func TestCustomInstanceConfigSample(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\tprojectID := getSampleProjectId(t)\n+\tdefer cleanupInstanceConfigs(projectID)\n+\n+\tvar b bytes.Buffer\n+\tuserConfigID := fmt.Sprintf(\"custom-golang-samples-config-%v\", randomID())\n+\tif err := createInstanceConfig(&b, projectID, userConfigID, \"nam11\"); err != nil {\n+\t\tt.Fatalf(\"failed to create instance configuration: %v\", err)\n+\t}\n+\tout := b.String()\n+\tassertContains(t, out, \"Created instance configuration\")\n+\n+\tb.Reset()\n+\tif err := updateInstanceConfig(&b, projectID, userConfigID); err != nil {\n+\t\tt.Errorf(\"failed to update instance configuration: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, \"Updated instance configuration\")\n+\n+\tb.Reset()\n+\tif err := listInstanceConfigOperations(&b, projectID); err != nil {\n+\t\tt.Errorf(\"failed to list instance configuration operations: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, \"List instance config operations\")\n+\n+\tb.Reset()\n+\tif err := deleteInstanceConfig(&b, projectID, userConfigID); err != nil {\n+\t\tt.Errorf(\"failed to delete instance configuration: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, \"Deleted instance configuration\")\n+}\n+\n func TestPgSample(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n \tt.Parallel()",
        "comments": [],
        "commit_message": "Merge branch 'update-go-version' of github.com:LukeSchlangen/golang-samples into update-go-version",
        "commit_id": "2c26fc89f351be42296045b11d55b9d2064d35da"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/create_cdn_key.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_create_cdn_key]\n+// [START videostitcher_create_cdn_key]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/create_live_session.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_create_live_session]\n+// [START videostitcher_create_live_session]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/create_slate.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_create_slate]\n+// [START videostitcher_create_slate]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/create_vod_session.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_create_vod_session]\n+// [START videostitcher_create_vod_session]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/delete_cdn_key.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_delete_cdn_key]\n+// [START videostitcher_delete_cdn_key]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/delete_slate.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_delete_slate]\n+// [START videostitcher_delete_slate]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/get_cdn_key.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_get_cdn_key]\n+// [START videostitcher_get_cdn_key]\n import (\n \t\"context\"\n \t\"encoding/json\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/get_live_ad_tag_detail.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_get_live_ad_tag_detail]\n+// [START videostitcher_get_live_ad_tag_detail]\n import (\n \t\"context\"\n \t\"encoding/json\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/get_live_session.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_get_live_session]\n+// [START videostitcher_get_live_session]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/get_slate.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_get_slate]\n+// [START videostitcher_get_slate]\n import (\n \t\"context\"\n \t\"encoding/json\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/get_vod_ad_tag_detail.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_get_vod_ad_tag_detail]\n+// [START videostitcher_get_vod_ad_tag_detail]\n import (\n \t\"context\"\n \t\"encoding/json\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/get_vod_session.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_get_vod_session]\n+// [START videostitcher_get_vod_session]\n import (\n \t\"context\"\n \t\"encoding/json\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/get_vod_stitch_detail.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_get_vod_stitch_detail]\n+// [START videostitcher_get_vod_stitch_detail]\n import (\n \t\"context\"\n \t\"encoding/json\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/list_cdn_keys.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_list_cdn_keys]\n+// [START videostitcher_list_cdn_keys]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/list_live_ad_tag_details.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_list_live_ad_tag_details]\n+// [START videostitcher_list_live_ad_tag_details]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/list_slates.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_list_slates]\n+// [START videostitcher_list_slates]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/list_vod_ad_tag_details.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_list_vod_ad_tag_details]\n+// [START videostitcher_list_vod_ad_tag_details]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/list_vod_stitch_details.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_list_vod_stitch_details]\n+// [START videostitcher_list_vod_stitch_details]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/update_cdn_key.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_update_cdn_key]\n+// [START videostitcher_update_cdn_key]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat(storagetransfer): Add S3 compatible transfer sample",
        "pr_number": 2723,
        "file_name": "media/videostitcher/update_slate.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage videostitcher\n \n-// [START video_stitcher_update_slate]\n+// [START videostitcher_update_slate]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into stss3compatsamples",
        "commit_id": "b36571a6431278f80aef656771934eebc398d339"
    },
    {
        "pr_title": "feat: Add snippets for Spanner DML with returning clause",
        "pr_number": 2713,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -251,6 +251,9 @@\nfunc TestSample(t *testing.T) {\n \tout = runSample(t, insertUsingDML, dbName, \"failed to insert using DML\")\n \tassertContains(t, out, \"record(s) inserted\")\n \n+\tout = runSample(t, insertUsingDMLReturning, dbName, \"failed to insert using DML with returning clause\")\n+\tassertContains(t, out, \"record(s) inserted\")\n+\n \tout = runSample(t, insertUsingDMLRequestPriority, dbName, \"failed to insert using DML with RequestPriority\")\n \tassertContains(t, out, \"record(s) inserted\")",
        "comments": [],
        "commit_message": "feat: Add snippets for Spanner DML with returning clause\n\nSamples are provided for INSERT, DELETE, and UPDATE in both GoogleSQL\nand PostgreSQL dialects. To provide a more compelling example for the\nINSERT case, a generated column has been added in the \"create_database\"\nexample so that the generated value can be returned in the INSERT\nexamples. This changed the number of mutations generated for inserts to\nthe Artists table, and the commitStats test case was updated as a\nresult.",
        "commit_id": "91d495440a75d7d05ceeb48572cba6ee752b6f2d"
    },
    {
        "pr_title": "feat: Add snippets for Spanner DML with returning clause",
        "pr_number": 2713,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -260,9 +263,15 @@\nfunc TestSample(t *testing.T) {\n \tout = runSample(t, updateUsingDML, dbName, \"failed to update using DML\")\n \tassertContains(t, out, \"record(s) updated\")\n \n+\tout = runSample(t, updateUsingDMLReturning, dbName, \"failed to update using DML with returning clause\")\n+\tassertContains(t, out, \"record(s) updated\")\n+\n \tout = runSample(t, deleteUsingDML, dbName, \"failed to delete using DML\")\n \tassertContains(t, out, \"record(s) deleted\")\n \n+\tout = runSample(t, deleteUsingDMLReturning, dbName, \"failed to delete using DML with returning clause\")\n+\tassertContains(t, out, \"record(s) deleted\")\n+\n \tout = runSample(t, updateUsingDMLWithTimestamp, dbName, \"failed to update using DML with timestamp\")\n \tassertContains(t, out, \"record(s) updated\")",
        "comments": [],
        "commit_message": "feat: Add snippets for Spanner DML with returning clause\n\nSamples are provided for INSERT, DELETE, and UPDATE in both GoogleSQL\nand PostgreSQL dialects. To provide a more compelling example for the\nINSERT case, a generated column has been added in the \"create_database\"\nexample so that the generated value can be returned in the INSERT\nexamples. This changed the number of mutations generated for inserts to\nthe Artists table, and the commitStats test case was updated as a\nresult.",
        "commit_id": "91d495440a75d7d05ceeb48572cba6ee752b6f2d"
    },
    {
        "pr_title": "feat: Add snippets for Spanner DML with returning clause",
        "pr_number": 2713,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -276,7 +285,7 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"record(s) inserted\")\n \n \tout = runSample(t, commitStats, dbName, \"failed to request commit stats\")\n-\tassertContains(t, out, \"3 mutations in transaction\")\n+\tassertContains(t, out, \"4 mutations in transaction\")\n \n \tout = runSample(t, queryWithParameter, dbName, \"failed to query with parameter\")\n \tassertContains(t, out, \"12 Melissa Garcia\")",
        "comments": [],
        "commit_message": "feat: Add snippets for Spanner DML with returning clause\n\nSamples are provided for INSERT, DELETE, and UPDATE in both GoogleSQL\nand PostgreSQL dialects. To provide a more compelling example for the\nINSERT case, a generated column has been added in the \"create_database\"\nexample so that the generated value can be returned in the INSERT\nexamples. This changed the number of mutations generated for inserts to\nthe Artists table, and the commitStats test case was updated as a\nresult.",
        "commit_id": "91d495440a75d7d05ceeb48572cba6ee752b6f2d"
    },
    {
        "pr_title": "feat: Add snippets for Spanner DML with returning clause",
        "pr_number": 2713,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -654,8 +663,17 @@\nfunc TestPgDmlSample(t *testing.T) {\n \t\t`CREATE TABLE Singers (\n \t\t   SingerId  bigint NOT NULL PRIMARY KEY,\n \t\t   FirstName varchar(1024),\n-\t\t   LastName  varchar(1024)\n-\t\t )`)\n+\t\t   LastName  varchar(1024),\n+\t\t   FullName  varchar(2048)\n+\t\t     GENERATED ALWAYS AS (FirstName || ' ' || LastName) STORED\n+\t\t )`,\n+\t\t`CREATE TABLE Albums (\n+\t\t\tSingerId         bigint NOT NULL,\n+\t\t\tAlbumId          bigint NOT NULL,\n+\t\t\tAlbumTitle       varchar(1024),\n+\t\t\tMarketingBudget  bigint,\n+\t\t\tPRIMARY KEY (SingerId, AlbumId)\n+\t\t) INTERLEAVE IN PARENT Singers ON DELETE CASCADE`)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create test database: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "feat: Add snippets for Spanner DML with returning clause\n\nSamples are provided for INSERT, DELETE, and UPDATE in both GoogleSQL\nand PostgreSQL dialects. To provide a more compelling example for the\nINSERT case, a generated column has been added in the \"create_database\"\nexample so that the generated value can be returned in the INSERT\nexamples. This changed the number of mutations generated for inserts to\nthe Artists table, and the commitStats test case was updated as a\nresult.",
        "commit_id": "91d495440a75d7d05ceeb48572cba6ee752b6f2d"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -58,13 +58,19 @@\nvar rpcOpts = gax.WithGRPCOptions(\n \tgrpc.MaxCallRecvMsgSize(1024 * 1024 * 129),\n )\n \n+// Available formats\n+const (\n+\tAVRO_FORMAT  = \"avro\"\n+\tARROW_FORMAT = \"arrow\"\n+)\n+\n // Command-line flags.\n var (\n \tprojectID = flag.String(\"project_id\", \"\",\n \t\t\"Cloud Project ID, used for session creation.\")\n \tsnapshotMillis = flag.Int64(\"snapshot_millis\", 0,\n \t\t\"Snapshot time to use for reads, represented in epoch milliseconds format.  Default behavior reads current data.\")\n-\tformat = flag.String(\"format\", \"avro\", \"format to read data from storage API. Default is avro.\")\n+\tformat = flag.String(\"format\", AVRO_FORMAT, \"format to read data from storage API. Default is avro.\")\n )\n \n func main() {",
        "comments": [
            {
                "comment": "nit: This error should be propagated back to the user.",
                "position": null
            },
            {
                "comment": "Does returning `ctx.Err()` make sense in this context and improve it ? \r\n\r\n```\r\ncase <-ctx.Done():\r\n\t// Context was cancelled.  Stop.\r\n\treturn ctx.Err()\r\n```",
                "position": null
            }
        ],
        "commit_message": "fix(bigquery): improve ctx err handling",
        "commit_id": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -101,7 +107,7 @@\nfunc main() {\n \t}\n \n \tdataFormat := bqStoragepb.DataFormat_AVRO\n-\tif *format == \"arrow\" {\n+\tif *format == ARROW_FORMAT {\n \t\tdataFormat = bqStoragepb.DataFormat_ARROW\n \t}\n \tcreateReadSessionRequest := &bqStoragepb.CreateReadSessionRequest{",
        "comments": [
            {
                "comment": "nit: This error should be propagated back to the user.",
                "position": null
            },
            {
                "comment": "Does returning `ctx.Err()` make sense in this context and improve it ? \r\n\r\n```\r\ncase <-ctx.Done():\r\n\t// Context was cancelled.  Stop.\r\n\treturn ctx.Err()\r\n```",
                "position": null
            }
        ],
        "commit_message": "fix(bigquery): improve ctx err handling",
        "commit_id": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -163,13 +169,13 @@\nfunc main() {\n \t\tdefer wg.Done()\n \t\tvar err error\n \t\tswitch *format {\n-\t\tcase \"arrow\":\n+\t\tcase ARROW_FORMAT:\n \t\t\terr = processArrow(ctx, session.GetArrowSchema().GetSerializedSchema(), ch)\n-\t\tcase \"avro\":\n+\t\tcase AVRO_FORMAT:\n \t\t\terr = processAvro(ctx, session.GetAvroSchema().GetSchema(), ch)\n \t\t}\n \t\tif err != nil {\n-\t\t\tlog.Fatalf(\"Error processing %s: %v\", *format, err)\n+\t\t\tlog.Fatalf(\"error processing %s: %v\", *format, err)\n \t\t}\n \t}()",
        "comments": [
            {
                "comment": "nit: This error should be propagated back to the user.",
                "position": null
            },
            {
                "comment": "Does returning `ctx.Err()` make sense in this context and improve it ? \r\n\r\n```\r\ncase <-ctx.Done():\r\n\t// Context was cancelled.  Stop.\r\n\treturn ctx.Err()\r\n```",
                "position": null
            }
        ],
        "commit_message": "fix(bigquery): improve ctx err handling",
        "commit_id": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -336,13 +342,13 @@\nfunc processArrow(ctx context.Context, schema []byte, ch <-chan *bqStoragepb.Rea\n \t\tselect {\n \t\tcase <-ctx.Done():\n \t\t\t// Context was cancelled.  Stop.\n-\t\t\treturn nil\n+\t\t\treturn ctx.Err()\n \t\tcase rows, ok := <-ch:\n \t\t\tif !ok {\n \t\t\t\t// Channel closed, no further arrow messages.  Stop.\n \t\t\t\treturn nil\n \t\t\t}\n-\t\t\tundecoded := rows.GetArrowRecordBatch().SerializedRecordBatch\n+\t\t\tundecoded := rows.GetArrowRecordBatch().GetSerializedRecordBatch()\n \t\t\tif len(undecoded) > 0 {\n \t\t\t\tbuf = bytes.NewBuffer(schema)\n \t\t\t\tbuf.Write(undecoded)",
        "comments": [
            {
                "comment": "nit: This error should be propagated back to the user.",
                "position": null
            },
            {
                "comment": "Does returning `ctx.Err()` make sense in this context and improve it ? \r\n\r\n```\r\ncase <-ctx.Done():\r\n\t// Context was cancelled.  Stop.\r\n\treturn ctx.Err()\r\n```",
                "position": null
            }
        ],
        "commit_message": "fix(bigquery): improve ctx err handling",
        "commit_id": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "docs: clears up difference of go from other languages",
        "pr_number": 2704,
        "file_name": "run/pubsub/main.go",
        "code_diff": "@@ -50,7 +50,6 @@\nfunc main() {\n // PubSubMessage is the payload of a Pub/Sub event.\n // See the documentation for more details:\n // https://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage\n-// byte slice unmarshalling handles base64 decoding\n type PubSubMessage struct {\n \tMessage struct {\n \t\tData []byte `json:\"data,omitempty\"`",
        "comments": [
            {
                "comment": "I understand why the comment is here but should it be on line 71?",
                "position": null
            },
            {
                "comment": "maybe? I contemplated that, but I didn't want to break up the code either. ",
                "position": null
            },
            {
                "comment": "Nit: capitalize/use a period for a sentence comment. go/go-style/decisions#comment-sentences",
                "position": null
            }
        ],
        "commit_message": "docs: moving comment to just before the unmarshal \n\nhandling nits of moving comment to right before the unmarshal (rather than before the struct definition that defines the []byte. Following standard of sentence comments having a \".\"",
        "commit_id": "d281585d6ea319333ae1d09f7dd50ea213bb414b"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/bqtestutil/bqtestutil.go",
        "code_diff": "@@ -26,7 +26,7 @@\nimport (\n func UniqueBQName(prefix string) (string, error) {\n \tu, err := uuid.NewV4()\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"failed to generate bq uuid: %v\", err)\n+\t\treturn \"\", fmt.Errorf(\"failed to generate bq uuid: %w\", err)\n \t}\n \treturn fmt.Sprintf(\"%s_%s\", sanitize(prefix, \"_\"), sanitize(u.String(), \"_\")), nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_clustered.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importClusteredTable(projectID, destDatasetID, destTableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_avro.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc importAvro(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_avro_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importAvroTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_csv.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importCSVExplicitSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_csv_autodetect.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importCSVAutodetectSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_csv_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importCSVTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_hivepartitioning.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importWithHivePartitioning(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONExplicitSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json_autodetect.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONAutodetectSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json_cmek.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONWithCMEK(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_orc.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc importORC(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_orc_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importORCTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_parquet.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc importParquet(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_parquet_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importParquetTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_partitioned.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc importPartitionedTable(projectID, destDatasetID, destTableID string) error\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -93,7 +93,7 @@\nfunc generateExampleMessages(numMessages int) ([][]byte, error) {\n \n \t\tb, err := proto.Marshal(m)\n \t\tif err != nil {\n-\t\t\treturn nil, fmt.Errorf(\"error generating message %d: %v\", i, err)\n+\t\t\treturn nil, fmt.Errorf(\"error generating message %d: %w\", i, err)\n \t\t}\n \t\tmsgs[i] = b\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -111,7 +111,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// Instantiate a managedwriter client to handle interactions with the service.\n \tclient, err := managedwriter.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"managedwriter.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"managedwriter.NewClient: %w\", err)\n \t}\n \t// Close the client when we exit the function.\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -124,7 +124,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t\t},\n \t})\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateWriteStream: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateWriteStream: %w\", err)\n \t}\n \n \t// We need to communicate the descriptor of the protocol buffer message we're using, which",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -134,7 +134,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \tm := &exampleproto.SampleData{}\n \tdescriptorProto, err := adapt.NormalizeDescriptor(m.ProtoReflect().Descriptor())\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NormalizeDescriptor: %v\", err)\n+\t\treturn fmt.Errorf(\"NormalizeDescriptor: %w\", err)\n \t}\n \n \t// Instantiate a ManagedStream, which manages low level details like connection state and provides",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -143,13 +143,13 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \tmanagedStream, err := client.NewManagedStream(ctx, managedwriter.WithStreamName(pendingStream.GetName()),\n \t\tmanagedwriter.WithSchemaDescriptor(descriptorProto))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewManagedStream: %v\", err)\n+\t\treturn fmt.Errorf(\"NewManagedStream: %w\", err)\n \t}\n \n \t// First, we'll append a single row.\n \trows, err := generateExampleMessages(1)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"generateExampleMessages: %v\", err)\n+\t\treturn fmt.Errorf(\"generateExampleMessages: %w\", err)\n \t}\n \n \t// We'll keep track of the current offset in the stream with curOffset.",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -159,7 +159,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \n \tresult, err := managedStream.AppendRows(ctx, rows, managedwriter.WithOffset(0))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"AppendRows first call error: %v\", err)\n+\t\treturn fmt.Errorf(\"AppendRows first call error: %w\", err)\n \t}\n \tresults = append(results, result)",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -169,11 +169,11 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// This time, we'll append three more rows in a single request.\n \trows, err = generateExampleMessages(3)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"generateExampleMessages: %v\", err)\n+\t\treturn fmt.Errorf(\"generateExampleMessages: %w\", err)\n \t}\n \tresult, err = managedStream.AppendRows(ctx, rows, managedwriter.WithOffset(curOffset))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"AppendRows second call error: %v\", err)\n+\t\treturn fmt.Errorf(\"AppendRows second call error: %w\", err)\n \t}\n \tresults = append(results, result)",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -183,11 +183,11 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// Finally, we'll append two more rows.\n \trows, err = generateExampleMessages(2)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"generateExampleMessages: %v\", err)\n+\t\treturn fmt.Errorf(\"generateExampleMessages: %w\", err)\n \t}\n \tresult, err = managedStream.AppendRows(ctx, rows, managedwriter.WithOffset(curOffset))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"AppendRows third call error: %v\", err)\n+\t\treturn fmt.Errorf(\"AppendRows third call error: %w\", err)\n \t}\n \tresults = append(results, result)",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -197,7 +197,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t\t// GetResult blocks until we receive a response from the API.\n \t\trecvOffset, err := v.GetResult(ctx)\n \t\tif err != nil {\n-\t\t\treturn fmt.Errorf(\"append %d returned error: %v\", k, err)\n+\t\t\treturn fmt.Errorf(\"append %d returned error: %w\", k, err)\n \t\t}\n \t\tfmt.Fprintf(w, \"Successfully appended data at offset %d.\\n\", recvOffset)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -206,7 +206,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// further appends.\n \trowCount, err := managedStream.Finalize(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"error during Finalize: %v\", err)\n+\t\treturn fmt.Errorf(\"error during Finalize: %w\", err)\n \t}\n \n \tfmt.Fprintf(w, \"Stream %s finalized with %d rows.\\n\", managedStream.StreamName(), rowCount)",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryBasic(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query_clustered_table.go",
        "code_diff": "@@ -32,7 +32,7 @@\nfunc queryClusteredTable(w io.Writer, projectID, datasetID, tableID string) erro\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query_destination_table.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc queryWithDestination(w io.Writer, projectID, destDatasetID, destTableID str\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query_destination_table_cmek.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc queryWithDestinationCMEK(w io.Writer, projectID, dstDatasetID, dstTableID s\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query_legacy.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryLegacy(w io.Writer, projectID, sqlString string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query_legacy_large_results.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc queryLegacyLargeResults(w io.Writer, projectID, datasetID, tableID string)\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query_no_cache.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryDisableCache(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_arrays.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryWithArrayParams(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_named.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryWithNamedParams(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_positional.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryWithPositionalParams(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_structs.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryWithStructParam(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_timestamps.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryWithTimestampParam(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/routine/bigquery_list_routines.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc listRoutines(w io.Writer, projectID, datasetID string) error {\n \n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/routine/bigquery_update_routine.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc updateRoutine(projectID, datasetID, routineID string) error {\n \n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/routine/bigquery_update_routine.go",
        "code_diff": "@@ -40,7 +40,7 @@\nfunc updateRoutine(projectID, datasetID, routineID string) error {\n \t// fetch existing metadata\n \tmeta, err := routineRef.Metadata(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"couldn't retrieve metadata: %v\", err)\n+\t\treturn fmt.Errorf(\"couldn't retrieve metadata: %w\", err)\n \t}\n \n \t// Due to a limitation in the backend, supply all the properties for update.",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/table/bigquery_create_table_external_hivepartitioned.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc createTableExternalHivePartitioned(projectID, datasetID, tableID string) er\n \n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "bigquery/snippets/table/bigquery_update_materialized_view.go",
        "code_diff": "@@ -31,15 +31,15 @@\nfunc updateMaterializedView(projectID, datasetID, viewID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n \t// Retrieve current view metadata.\n \tviewRef := client.Dataset(datasetID).Table(viewID)\n \tmeta, err := viewRef.Metadata(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"Metadata(): %v\", err)\n+\t\treturn fmt.Errorf(\"couldn't retrieve view metadata: %w\", err)\n \t}\n \n \tif meta.MaterializedView == nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into align-translate-docs",
        "commit_id": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/bqtestutil/bqtestutil.go",
        "code_diff": "@@ -26,7 +26,7 @@\nimport (\n func UniqueBQName(prefix string) (string, error) {\n \tu, err := uuid.NewV4()\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"failed to generate bq uuid: %v\", err)\n+\t\treturn \"\", fmt.Errorf(\"failed to generate bq uuid: %w\", err)\n \t}\n \treturn fmt.Sprintf(\"%s_%s\", sanitize(prefix, \"_\"), sanitize(u.String(), \"_\")), nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_clustered.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importClusteredTable(projectID, destDatasetID, destTableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_avro.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc importAvro(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_avro_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importAvroTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_csv.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importCSVExplicitSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_csv_autodetect.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importCSVAutodetectSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_csv_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importCSVTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_hivepartitioning.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importWithHivePartitioning(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONExplicitSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json_autodetect.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONAutodetectSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json_cmek.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONWithCMEK(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_orc.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc importORC(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_orc_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importORCTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_parquet.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc importParquet(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_parquet_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importParquetTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_partitioned.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc importPartitionedTable(projectID, destDatasetID, destTableID string) error\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -93,7 +93,7 @@\nfunc generateExampleMessages(numMessages int) ([][]byte, error) {\n \n \t\tb, err := proto.Marshal(m)\n \t\tif err != nil {\n-\t\t\treturn nil, fmt.Errorf(\"error generating message %d: %v\", i, err)\n+\t\t\treturn nil, fmt.Errorf(\"error generating message %d: %w\", i, err)\n \t\t}\n \t\tmsgs[i] = b\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -111,7 +111,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// Instantiate a managedwriter client to handle interactions with the service.\n \tclient, err := managedwriter.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"managedwriter.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"managedwriter.NewClient: %w\", err)\n \t}\n \t// Close the client when we exit the function.\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -124,7 +124,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t\t},\n \t})\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateWriteStream: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateWriteStream: %w\", err)\n \t}\n \n \t// We need to communicate the descriptor of the protocol buffer message we're using, which",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -134,7 +134,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \tm := &exampleproto.SampleData{}\n \tdescriptorProto, err := adapt.NormalizeDescriptor(m.ProtoReflect().Descriptor())\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NormalizeDescriptor: %v\", err)\n+\t\treturn fmt.Errorf(\"NormalizeDescriptor: %w\", err)\n \t}\n \n \t// Instantiate a ManagedStream, which manages low level details like connection state and provides",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -143,13 +143,13 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \tmanagedStream, err := client.NewManagedStream(ctx, managedwriter.WithStreamName(pendingStream.GetName()),\n \t\tmanagedwriter.WithSchemaDescriptor(descriptorProto))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewManagedStream: %v\", err)\n+\t\treturn fmt.Errorf(\"NewManagedStream: %w\", err)\n \t}\n \n \t// First, we'll append a single row.\n \trows, err := generateExampleMessages(1)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"generateExampleMessages: %v\", err)\n+\t\treturn fmt.Errorf(\"generateExampleMessages: %w\", err)\n \t}\n \n \t// We'll keep track of the current offset in the stream with curOffset.",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -159,7 +159,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \n \tresult, err := managedStream.AppendRows(ctx, rows, managedwriter.WithOffset(0))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"AppendRows first call error: %v\", err)\n+\t\treturn fmt.Errorf(\"AppendRows first call error: %w\", err)\n \t}\n \tresults = append(results, result)",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -169,11 +169,11 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// This time, we'll append three more rows in a single request.\n \trows, err = generateExampleMessages(3)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"generateExampleMessages: %v\", err)\n+\t\treturn fmt.Errorf(\"generateExampleMessages: %w\", err)\n \t}\n \tresult, err = managedStream.AppendRows(ctx, rows, managedwriter.WithOffset(curOffset))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"AppendRows second call error: %v\", err)\n+\t\treturn fmt.Errorf(\"AppendRows second call error: %w\", err)\n \t}\n \tresults = append(results, result)",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -183,11 +183,11 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// Finally, we'll append two more rows.\n \trows, err = generateExampleMessages(2)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"generateExampleMessages: %v\", err)\n+\t\treturn fmt.Errorf(\"generateExampleMessages: %w\", err)\n \t}\n \tresult, err = managedStream.AppendRows(ctx, rows, managedwriter.WithOffset(curOffset))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"AppendRows third call error: %v\", err)\n+\t\treturn fmt.Errorf(\"AppendRows third call error: %w\", err)\n \t}\n \tresults = append(results, result)",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -197,7 +197,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t\t// GetResult blocks until we receive a response from the API.\n \t\trecvOffset, err := v.GetResult(ctx)\n \t\tif err != nil {\n-\t\t\treturn fmt.Errorf(\"append %d returned error: %v\", k, err)\n+\t\t\treturn fmt.Errorf(\"append %d returned error: %w\", k, err)\n \t\t}\n \t\tfmt.Fprintf(w, \"Successfully appended data at offset %d.\\n\", recvOffset)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -206,7 +206,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// further appends.\n \trowCount, err := managedStream.Finalize(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"error during Finalize: %v\", err)\n+\t\treturn fmt.Errorf(\"error during Finalize: %w\", err)\n \t}\n \n \tfmt.Fprintf(w, \"Stream %s finalized with %d rows.\\n\", managedStream.StreamName(), rowCount)",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryBasic(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query_clustered_table.go",
        "code_diff": "@@ -32,7 +32,7 @@\nfunc queryClusteredTable(w io.Writer, projectID, datasetID, tableID string) erro\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query_destination_table.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc queryWithDestination(w io.Writer, projectID, destDatasetID, destTableID str\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query_destination_table_cmek.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc queryWithDestinationCMEK(w io.Writer, projectID, dstDatasetID, dstTableID s\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query_legacy.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryLegacy(w io.Writer, projectID, sqlString string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query_legacy_large_results.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc queryLegacyLargeResults(w io.Writer, projectID, datasetID, tableID string)\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query_no_cache.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryDisableCache(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_arrays.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryWithArrayParams(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_named.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryWithNamedParams(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_positional.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryWithPositionalParams(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_structs.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryWithStructParam(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_timestamps.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryWithTimestampParam(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/routine/bigquery_list_routines.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc listRoutines(w io.Writer, projectID, datasetID string) error {\n \n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/routine/bigquery_update_routine.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc updateRoutine(projectID, datasetID, routineID string) error {\n \n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/routine/bigquery_update_routine.go",
        "code_diff": "@@ -40,7 +40,7 @@\nfunc updateRoutine(projectID, datasetID, routineID string) error {\n \t// fetch existing metadata\n \tmeta, err := routineRef.Metadata(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"couldn't retrieve metadata: %v\", err)\n+\t\treturn fmt.Errorf(\"couldn't retrieve metadata: %w\", err)\n \t}\n \n \t// Due to a limitation in the backend, supply all the properties for update.",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/table/bigquery_create_table_external_hivepartitioned.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc createTableExternalHivePartitioned(projectID, datasetID, tableID string) er\n \n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "bigquery/snippets/table/bigquery_update_materialized_view.go",
        "code_diff": "@@ -31,15 +31,15 @@\nfunc updateMaterializedView(projectID, datasetID, viewID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n \t// Retrieve current view metadata.\n \tviewRef := client.Dataset(datasetID).Table(viewID)\n \tmeta, err := viewRef.Metadata(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"Metadata(): %v\", err)\n+\t\treturn fmt.Errorf(\"couldn't retrieve view metadata: %w\", err)\n \t}\n \n \tif meta.MaterializedView == nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "media/transcoder/create_job_with_embedded_captions.go",
        "code_diff": "@@ -79,7 +79,7 @@\nfunc createJobWithEmbeddedCaptions(w io.Writer, projectID string, location strin\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(dataflow): Add Go Flex Template example",
        "pr_number": 2692,
        "file_name": "media/transcoder/create_job_with_standalone_captions.go",
        "code_diff": "@@ -81,7 +81,7 @@\nfunc createJobWithStandaloneCaptions(w io.Writer, projectID string, location str\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into flexTemplateExample",
        "commit_id": "14ef887959d5d4c81eafbe1a27eabbe0ce7e458b"
    },
    {
        "pr_title": "feat(pubsub): add exactly once delivery samples",
        "pr_number": 2688,
        "file_name": "media/transcoder/create_job_with_embedded_captions.go",
        "code_diff": "@@ -79,7 +79,7 @@\nfunc createJobWithEmbeddedCaptions(w io.Writer, projectID string, location strin\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-exactly-once-delivery",
        "commit_id": "73384f3c61da812ae9b35d7fd280692f5a1b75b1"
    },
    {
        "pr_title": "feat(pubsub): add exactly once delivery samples",
        "pr_number": 2688,
        "file_name": "media/transcoder/create_job_with_standalone_captions.go",
        "code_diff": "@@ -81,7 +81,7 @@\nfunc createJobWithStandaloneCaptions(w io.Writer, projectID string, location str\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into feat-exactly-once-delivery",
        "commit_id": "73384f3c61da812ae9b35d7fd280692f5a1b75b1"
    },
    {
        "pr_title": "test(storage): add test retry",
        "pr_number": 2684,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -125,21 +125,34 @@\nfunc TestCreate(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \tclient := setup(t)\n-\ttopic, err := client.CreateTopic(ctx, topicID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"CreateTopic: %v\", err)\n-\t}\n-\tbuf := new(bytes.Buffer)\n-\tif err := create(buf, tc.ProjectID, subID, topic); err != nil {\n-\t\tt.Fatalf(\"failed to create a subscription: %v\", err)\n-\t}\n-\tok, err := client.Subscription(subID).Exists(context.Background())\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n-\t}\n-\tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", subID)\n-\t}\n+\n+\tvar topic *pubsub.Topic\n+\tvar err error\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\ttopic, err = client.CreateTopic(ctx, topicID)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"CreateTopic: %v\", err)\n+\t\t}\n+\t})\n+\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif err := create(buf, tc.ProjectID, subID, topic); err != nil {\n+\t\t\tt.Fatalf(\"failed to create a subscription: %v\", err)\n+\t\t}\n+\t\tgot := buf.String()\n+\t\twant := \"Created subscription\"\n+\t\tif !strings.Contains(got, want) {\n+\t\t\tt.Fatalf(\"got: %s, want: %v\", got, want)\n+\t\t}\n+\t\tok, err := client.Subscription(subID).Exists(context.Background())\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n+\t\t}\n+\t\tif !ok {\n+\t\t\tt.Fatalf(\"got none; want sub = %q\", subID)\n+\t\t}\n+\t})\n }\n \n func TestList(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into 2678-timeout",
        "commit_id": "31e2172f76ff79dc04ff98bfdc34d72014e816fb"
    },
    {
        "pr_title": "test(storage): add test retry",
        "pr_number": 2684,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -198,6 +211,7 @@\nfunc TestIAM(t *testing.T) {\n \t\tif role, member := iam.Viewer, iam.AllUsers; !policy.HasRole(member, role) {\n \t\t\tr.Errorf(\"want %q as viewer, policy=%v\", member, policy)\n \t\t}\n+\n \t})\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into 2678-timeout",
        "commit_id": "31e2172f76ff79dc04ff98bfdc34d72014e816fb"
    },
    {
        "pr_title": "test(storage): add test retry",
        "pr_number": 2684,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -357,7 +371,7 @@\nfunc TestPullMsgsConcurrencyControl(t *testing.T) {\n \t\tpublishMsgs(ctx, topic, numMsgs)\n \n \t\tbuf := new(bytes.Buffer)\n-\t\tif err := pullMsgsConcurrenyControl(buf, tc.ProjectID, subIDConc); err != nil {\n+\t\tif err := pullMsgsConcurrencyControl(buf, tc.ProjectID, subIDConc); err != nil {\n \t\t\tr.Errorf(\"failed to pull messages: %v\", err)\n \t\t}\n \t\tgot := buf.String()",
        "comments": [],
        "commit_message": "Merge branch 'main' into 2678-timeout",
        "commit_id": "31e2172f76ff79dc04ff98bfdc34d72014e816fb"
    },
    {
        "pr_title": "chore(cloudsql): add consistent region tags",
        "pr_number": 2679,
        "file_name": "docs/appengine/storage/app.go",
        "code_diff": "@@ -126,7 +126,7 @@\nfunc handler(w http.ResponseWriter, r *http.Request) {\n \t}\n }\n \n-//[START write]\n+// [START write]\n // createFile creates a file in Google Cloud Storage.\n func (d *demo) createFile(fileName string) {\n \tfmt.Fprintf(d.w, \"Creating file /%v/%v\\n\", d.bucketName, fileName)",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-consistent-region-tags",
        "commit_id": "3b7348b6230662e209fd18490d860eb7f28c59a6"
    },
    {
        "pr_title": "chore(cloudsql): add consistent region tags",
        "pr_number": 2679,
        "file_name": "docs/appengine/storage/app.go",
        "code_diff": "@@ -155,7 +155,7 @@\nfunc (d *demo) createFile(fileName string) {\n \n //[END write]\n \n-//[START read]\n+// [START read]\n // readFile reads the named file in Google Cloud Storage.\n func (d *demo) readFile(fileName string) {\n \tio.WriteString(d.w, \"\\nAbbreviated file content (first line and last 1K):\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-consistent-region-tags",
        "commit_id": "3b7348b6230662e209fd18490d860eb7f28c59a6"
    },
    {
        "pr_title": "chore(cloudsql): add consistent region tags",
        "pr_number": 2679,
        "file_name": "docs/appengine/storage/app.go",
        "code_diff": "@@ -182,7 +182,7 @@\nfunc (d *demo) readFile(fileName string) {\n \n //[END read]\n \n-//[START copy]\n+// [START copy]\n // copyFile copies a file in Google Cloud Storage.\n func (d *demo) copyFile(fileName string) {\n \tcopyName := fileName + \"-copy\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-consistent-region-tags",
        "commit_id": "3b7348b6230662e209fd18490d860eb7f28c59a6"
    },
    {
        "pr_title": "chore(cloudsql): add consistent region tags",
        "pr_number": 2679,
        "file_name": "testing/sampletests/main.go",
        "code_diff": "@@ -12,13 +12,15 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-/*The sampletests command adds the region tags tested by each test to the XML\n+/*\n+The sampletests command adds the region tags tested by each test to the XML\n properties of that test case. It reads JUnit XML from stdin and writes JUnit\n XML to stdout.\n \n For example, if TestFoo tests the regions foo_hello_world and\n foo_hello_gopher, the TestFoo element will have the following property:\n-    <property name=\"region_tags\" value=\"foo_hello_world,foo_hello_gopher\"></property>\n+\n+\t<property name=\"region_tags\" value=\"foo_hello_world,foo_hello_gopher\"></property>\n \n sampletests only looks at direct function calls or references by tests. So, if\n you have a map from string -> function reference in the global scope and test",
        "comments": [],
        "commit_message": "Merge branch 'main' into cloudsql-consistent-region-tags",
        "commit_id": "3b7348b6230662e209fd18490d860eb7f28c59a6"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -20,7 +20,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"strings\"\n \n \t\"cloud.google.com/go/bigtable\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -37,17 +36,18 @@\nfunc readRow(w io.Writer, projectID, instanceID string, tableName string) error\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewAdminClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n+\n \ttbl := client.Open(tableName)\n-\trowkey := \"phone#4c410523#20190501\"\n-\trow, err := tbl.ReadRow(ctx, rowkey)\n+\trowKey := \"phone#4c410523#20190501\"\n+\trow, err := tbl.ReadRow(ctx, rowKey)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Could not read row with key %s: %v\", rowkey, err)\n+\t\treturn fmt.Errorf(\"could not read row with key %s: %v\", rowKey, err)\n \t}\n \n \tprintRow(w, row)\n-\n \treturn nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -62,13 +62,15 @@\nfunc readRowPartial(w io.Writer, projectID, instanceID string, tableName string)\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewAdminClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n+\n \ttbl := client.Open(tableName)\n-\trowkey := \"phone#4c410523#20190501\"\n-\trow, err := tbl.ReadRow(ctx, rowkey, bigtable.RowFilter(bigtable.ColumnFilter(\"os_build\")))\n+\trowKey := \"phone#4c410523#20190501\"\n+\trow, err := tbl.ReadRow(ctx, rowKey, bigtable.RowFilter(bigtable.ColumnFilter(\"os_build\")))\n \tif err != nil {\n-\t\tlog.Fatalf(\"Could not read row with key %s: %v\", rowkey, err)\n+\t\treturn fmt.Errorf(\"could not read row with key %s: %v\", rowKey, err)\n \t}\n \n \tprintRow(w, row)",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -87,17 +89,19 @@\nfunc readRows(w io.Writer, projectID, instanceID string, tableName string) error\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewAdminClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n+\n \ttbl := client.Open(tableName)\n \terr = tbl.ReadRows(ctx, bigtable.RowList{\"phone#4c410523#20190501\", \"phone#4c410523#20190502\"},\n \t\tfunc(row bigtable.Row) bool {\n \t\t\tprintRow(w, row)\n \t\t\treturn true\n-\t\t})\n-\n-\tif err = client.Close(); err != nil {\n-\t\treturn fmt.Errorf(\"client.Close(): %v\", err)\n+\t\t},\n+\t)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"tbl.ReadRows: %v\", err)\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -114,17 +118,20 @@\nfunc readRowRange(w io.Writer, projectID, instanceID string, tableName string) e\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewAdminClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n+\n \ttbl := client.Open(tableName)\n \terr = tbl.ReadRows(ctx, bigtable.NewRange(\"phone#4c410523#20190501\", \"phone#4c410523#201906201\"),\n \t\tfunc(row bigtable.Row) bool {\n \t\t\tprintRow(w, row)\n \t\t\treturn true\n-\t\t})\n+\t\t},\n+\t)\n \n-\tif err = client.Close(); err != nil {\n-\t\treturn fmt.Errorf(\"client.Close(): %v\", err)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"tbl.ReadRows: %v\", err)\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -141,8 +148,10 @@\nfunc readRowRanges(w io.Writer, projectID, instanceID string, tableName string)\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewAdminClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n+\n \ttbl := client.Open(tableName)\n \terr = tbl.ReadRows(ctx, bigtable.RowRangeList{\n \t\tbigtable.NewRange(\"phone#4c410523#20190501\", \"phone#4c410523#201906201\"),",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -151,10 +160,10 @@\nfunc readRowRanges(w io.Writer, projectID, instanceID string, tableName string)\n \t\tfunc(row bigtable.Row) bool {\n \t\t\tprintRow(w, row)\n \t\t\treturn true\n-\t\t})\n-\n-\tif err = client.Close(); err != nil {\n-\t\treturn fmt.Errorf(\"client.Close(): %v\", err)\n+\t\t},\n+\t)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"tbl.ReadRows: %v\", err)\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -171,17 +180,19 @@\nfunc readPrefix(w io.Writer, projectID, instanceID string, tableName string) err\n \tctx := context.Background()\n \tclient, err := bigtable.NewClient(ctx, projectID, instanceID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigtable.NewAdminClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigtable.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n+\n \ttbl := client.Open(tableName)\n \terr = tbl.ReadRows(ctx, bigtable.PrefixRange(\"phone#\"),\n \t\tfunc(row bigtable.Row) bool {\n \t\t\tprintRow(w, row)\n \t\t\treturn true\n-\t\t})\n-\n-\tif err = client.Close(); err != nil {\n-\t\treturn fmt.Errorf(\"client.Close(): %v\", err)\n+\t\t},\n+\t)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"tbl.ReadRows: %v\", err)\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "bigtable/reads/reads_test.go",
        "code_diff": "@@ -37,8 +37,14 @@\nfunc TestReads(t *testing.T) {\n \t\tt.Skip(\"Skipping bigtable integration test. Set GOLANG_SAMPLES_BIGTABLE_PROJECT and GOLANG_SAMPLES_BIGTABLE_INSTANCE.\")\n \t}\n \tadminClient, err := bigtable.NewAdminClient(ctx, project, instance)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n \n \tuuid, err := uuid.NewRandom()\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n \ttableName := fmt.Sprintf(\"mobile-time-series-%s\", uuid.String()[:8])\n \tadminClient.DeleteTable(ctx, tableName)",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "bigtable/reads/reads_test.go",
        "code_diff": "@@ -52,7 +58,7 @@\nfunc TestReads(t *testing.T) {\n \t}\n \n \ttimestamp := bigtable.Now().TruncateToMilliseconds()\n-\twriteTestData(err, ctx, project, instance, tableName, timestamp, t)\n+\twriteTestData(ctx, project, instance, tableName, timestamp, t)\n \n \ttests := []struct {\n \t\tname   string",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "internal/mtls_smoketest/smoketest_test.go",
        "code_diff": "@@ -21,13 +21,10 @@\nimport (\n \t\"time\"\n \n \tbqstorage \"cloud.google.com/go/bigquery/storage/apiv1\"\n-\tgaming \"cloud.google.com/go/gaming/apiv1beta\"\n \tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"google.golang.org/api/iterator\"\n \t\"google.golang.org/api/option\"\n \tbqstoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1\"\n-\tgamingpb \"google.golang.org/genproto/googleapis/cloud/gaming/v1beta\"\n )\n \n var shouldFail = os.Getenv(\"GOOGLE_API_USE_MTLS\") == \"always\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "opentelemetry/trace/main.go",
        "code_diff": "@@ -23,8 +23,11 @@\nimport (\n \t\"os\"\n \n \ttexporter \"github.com/GoogleCloudPlatform/opentelemetry-operations-go/exporter/trace\"\n+\t\"go.opentelemetry.io/contrib/detectors/gcp\"\n \t\"go.opentelemetry.io/otel\"\n+\t\"go.opentelemetry.io/otel/sdk/resource\"\n \tsdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n+\tsemconv \"go.opentelemetry.io/otel/semconv/v1.7.0\"\n )\n \n // [END opentelemetry_trace_import]",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "docs(secretmanager): Added sample for creating Secret with UserManaged replication",
        "pr_number": 2658,
        "file_name": "opentelemetry/trace/main.go",
        "code_diff": "@@ -35,7 +38,22 @@\nfunc main() {\n \tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \texporter, err := texporter.New(texporter.WithProjectID(projectID))\n \tif err != nil {\n-\t\tlog.Fatalf(\"texporter.NewExporter: %v\", err)\n+\t\tlog.Fatalf(\"texporter.New: %v\", err)\n+\t}\n+\n+\t// Identify your application using resource detection\n+\tres, err := resource.New(ctx,\n+\t\t// Use the GCP resource detector to detect information about the GCP platform\n+\t\tresource.WithDetectors(gcp.NewDetector()),\n+\t\t// Keep the default detectors\n+\t\tresource.WithTelemetrySDK(),\n+\t\t// Add your own custom attributes to identify your application\n+\t\tresource.WithAttributes(\n+\t\t\tsemconv.ServiceNameKey.String(\"my-application\"),\n+\t\t),\n+\t)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"resource.New: %v\", err)\n \t}\n \n \t// Create trace provider with the exporter.",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-ummr-secret",
        "commit_id": "02cf1cf26e730cf92934e4f15796e2ba72c9cb05"
    },
    {
        "pr_title": "samples(compute): add compute samples for moving instances doc",
        "pr_number": 2630,
        "file_name": "compute/instances/create-start-instance/create_instance_test.go",
        "code_diff": "@@ -156,7 +156,7 @@\nfunc TestComputeCreateInstanceSnippets(t *testing.T) {\n \n \terr = createDisk(ctx, tc.ProjectID, zone, bootDiskName, *newestDebian.SelfLink)\n \tif err != nil {\n-\t\tt.Errorf(\"createDisk got err: %v\", err)\n+\t\tt.Fatalf(\"createDisk got err: %v\", err)\n \t}\n \n \tdiskNames := []string{",
        "comments": [
            {
                "comment": "prereqs and creation tasks shoul be t.Fatalf, the following 3 ",
                "position": null
            },
            {
                "comment": "Why we should modify in the following parts? From what I see 154 line makes sense to make fatalf, but we will not delete this disk if we will make next calls as fatalf? Or I am missing smth",
                "position": null
            },
            {
                "comment": "I think as resources are created perhaps we should defer deleting them, thoughts?",
                "position": null
            },
            {
                "comment": "Definitely agree, but adding Fatalf will not help from what I see\r\nIn Node.js we do this trick: https://github.com/googleapis/nodejs-compute/blob/main/samples/test/disks.test.js#L131 (deleting resources with the same name structure)",
                "position": null
            },
            {
                "comment": "Fatal helps because it stops the current test run in its tracks. Errors lets the test keep going which can make things in a worse state and make it harder to debug what the actual problem is.",
                "position": null
            },
            {
                "comment": "If you want to add a general cleanup call like that here I am okay with that.",
                "position": null
            }
        ],
        "commit_message": "add fatalf",
        "commit_id": "14ad97f2630bd88bf5d1b26b28ce65bac52677ed"
    },
    {
        "pr_title": "samples(compute): add snapshots samples",
        "pr_number": 2629,
        "file_name": "compute/snapshots/snapshots_test.go",
        "code_diff": "@@ -139,7 +139,7 @@\nfunc TestComputeSnapshotsSnippets(t *testing.T) {\n \t}\n \n \tif err := createSnapshot(buf, tc.ProjectID, diskName, snapshotName, zone, \"\", location, \"\"); err != nil {\n-\t\tt.Errorf(\"createSnapshot got err: %v\", err)\n+\t\tt.Fatalf(\"createSnapshot got err: %v\", err)\n \t}\n \tif got := buf.String(); !strings.Contains(got, want) {\n \t\tt.Errorf(\"createSnapshot got %q, want %q\", got, want)",
        "comments": [
            {
                "comment": "These two creates should be t.Fatalf",
                "position": null
            }
        ],
        "commit_message": "add fatalf",
        "commit_id": "3e26aca94d254d173d1dbb1ae5a19969cd12a15c"
    },
    {
        "pr_title": "samples(compute): add disks samples",
        "pr_number": 2628,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -164,7 +164,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \n \t\terr = createDiskSnapshot(ctx, tc.ProjectID, zone, diskName, snapshotName)\n \t\tif err != nil {\n-\t\t\tt.Errorf(\"createDiskSnapshot got err: %v\", err)\n+\t\t\tt.Fatalf(\"createDiskSnapshot got err: %v\", err)\n \t\t}\n \n \t\tif err := createDiskFromSnapshot(buf, tc.ProjectID, zone, diskName2, diskType, diskSnapshotLink); err != nil {",
        "comments": [
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "but if I understood correctly in this case will not delete the disk created here: https://github.com/GoogleCloudPlatform/golang-samples/pull/2628/files/3ed7310ea030f23ddc9d747772f3b9541a4bf590#diff-8c1d3e8777449a285bf474a434998f576b0a37604c242aded58ff842441448cdR160",
                "position": null
            },
            {
                "comment": "@quartzmo wdyt?",
                "position": null
            },
            {
                "comment": "OK, I see. Please use `Errorf` if concerned about orphaned disk.",
                "position": null
            }
        ],
        "commit_message": "add fatalf",
        "commit_id": "79d584006c13f48140a6c50c8b87e1e845eaa138"
    },
    {
        "pr_title": "samples(compute): add disks samples",
        "pr_number": 2628,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -200,7 +200,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\twant = \"Disk created\"\n \n \t\tif err := createEmptyDisk(buf, tc.ProjectID, zone, diskName, diskType); err != nil {\n-\t\t\tt.Errorf(\"createEmptyDisk got err: %v\", err)\n+\t\t\tt.Fatalf(\"createEmptyDisk got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createEmptyDisk got %q, want %q\", got, want)",
        "comments": [
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "Use `t.Fatalf` here because subsequent operation(s) depend on this one succeeding?",
                "position": null
            },
            {
                "comment": "but if I understood correctly in this case will not delete the disk created here: https://github.com/GoogleCloudPlatform/golang-samples/pull/2628/files/3ed7310ea030f23ddc9d747772f3b9541a4bf590#diff-8c1d3e8777449a285bf474a434998f576b0a37604c242aded58ff842441448cdR160",
                "position": null
            },
            {
                "comment": "@quartzmo wdyt?",
                "position": null
            },
            {
                "comment": "OK, I see. Please use `Errorf` if concerned about orphaned disk.",
                "position": null
            }
        ],
        "commit_message": "add fatalf",
        "commit_id": "79d584006c13f48140a6c50c8b87e1e845eaa138"
    },
    {
        "pr_title": "samples(mediacdn): init cme samples",
        "pr_number": 2627,
        "file_name": "mediacdn/sign_cookie.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2021 Google LLC\n+// Copyright 2022 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [
            {
                "comment": "Why is \"Signed\" capitalized here?",
                "position": null
            },
            {
                "comment": "> signCookie prints\r\n\r\nIt looks to me that this function returns a string, but does not print anything.",
                "position": null
            },
            {
                "comment": "What do you think about renaming `base64Key` to `privateKey` (which is the param name in `ed25519.Sign`) as well as documenting all parameters in the function description, so that users know exactly what is expected.",
                "position": null
            }
        ],
        "commit_message": "fix review comments",
        "commit_id": "06cfdcbbeaa85d517bad58dc541a51473631a6e8"
    },
    {
        "pr_title": "samples(mediacdn): init cme samples",
        "pr_number": 2627,
        "file_name": "mediacdn/sign_cookie.go",
        "code_diff": "@@ -19,14 +19,15 @@\nimport (\n \t\"crypto/ed25519\"\n \t\"encoding/base64\"\n \t\"fmt\"\n+\t\"io\"\n \t\"time\"\n )\n \n-// signCookie prints the Signed cookie value for the specified URL prefix and configuration.\n-func signCookie(urlPrefix, keyName string, base64Key []byte, expires time.Time) string {\n+// signCookie prints the signed cookie value for the specified URL prefix and configuration.\n+func signCookie(w io.Writer, urlPrefix, keyName string, privateKey []byte, expires time.Time) error {\n \t// urlPrefix := \"http://example.com\"\n \t// keyName := \"your_key_name\"\n-\t// base64Key := \"[]byte{34, 31, ...}\"\n+\t// privateKey := \"[]byte{34, 31, ...}\"\n \t// expires := time.Unix(1558131350, 0)\n \n \ttoSign := fmt.Sprintf(",
        "comments": [
            {
                "comment": "Why is \"Signed\" capitalized here?",
                "position": null
            },
            {
                "comment": "> signCookie prints\r\n\r\nIt looks to me that this function returns a string, but does not print anything.",
                "position": null
            },
            {
                "comment": "What do you think about renaming `base64Key` to `privateKey` (which is the param name in `ed25519.Sign`) as well as documenting all parameters in the function description, so that users know exactly what is expected.",
                "position": null
            }
        ],
        "commit_message": "fix review comments",
        "commit_id": "06cfdcbbeaa85d517bad58dc541a51473631a6e8"
    },
    {
        "pr_title": "samples(mediacdn): init cme samples",
        "pr_number": 2627,
        "file_name": "mediacdn/sign_test.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2022 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [
            {
                "comment": "2021",
                "position": null
            },
            {
                "comment": "Maybe add a comment for maintainers about how this value was produced?",
                "position": null
            },
            {
                "comment": "renamed to privateKey",
                "position": null
            }
        ],
        "commit_message": "fix review comments",
        "commit_id": "06cfdcbbeaa85d517bad58dc541a51473631a6e8"
    },
    {
        "pr_title": "samples(mediacdn): init cme samples",
        "pr_number": 2627,
        "file_name": "mediacdn/sign_test.go",
        "code_diff": "@@ -14,17 +14,21 @@\npackage snippets\n \n import (\n+\t\"bytes\"\n+\t\"strings\"\n \t\"testing\"\n \t\"time\"\n )\n \n-var testKey = []byte{34, 31, 185, 24, 168, 225, 242, 115, 112, 155, 38,\n+var privateTestKey = []byte{34, 31, 185, 24, 168, 225, 242, 115, 112, 155, 38,\n \t157, 183, 65, 104, 243, 85, 182, 188, 26, 176, 101, 247, 177,\n \t243, 93, 114, 156, 94, 191, 219, 75, 183, 211, 110, 78, 223,\n \t133, 62, 172, 159, 217, 158, 126, 34, 6, 254, 108, 57, 194,\n \t141, 93, 219, 91, 8, 162, 88, 62, 52, 75, 42, 103, 202, 238,\n }\n \n+var buf = &bytes.Buffer{}\n+\n func TestSignURL(t *testing.T) {\n \tcases := []struct {\n \t\ttestName   string",
        "comments": [
            {
                "comment": "2021",
                "position": null
            },
            {
                "comment": "Maybe add a comment for maintainers about how this value was produced?",
                "position": null
            },
            {
                "comment": "renamed to privateKey",
                "position": null
            }
        ],
        "commit_message": "fix review comments",
        "commit_id": "06cfdcbbeaa85d517bad58dc541a51473631a6e8"
    },
    {
        "pr_title": "samples(mediacdn): init cme samples",
        "pr_number": 2627,
        "file_name": "mediacdn/sign_test.go",
        "code_diff": "@@ -58,11 +62,11 @@\nfunc TestSignURL(t *testing.T) {\n \n \tfor _, c := range cases {\n \t\tt.Run(c.testName, func(t *testing.T) {\n-\t\t\tsignedValue := signURL(\n-\t\t\t\tc.url, c.keyName, testKey, c.expiration,\n-\t\t\t)\n-\t\t\tif signedValue != c.out {\n-\t\t\t\tt.Errorf(\"signed value incorrectly matched: got %s, want %s\", signedValue, c.out)\n+\t\t\tif err := signURL(buf, c.url, c.keyName, privateTestKey, c.expiration); err != nil {\n+\t\t\t\tt.Errorf(\"signURL got err: %v\", err)\n+\t\t\t}\n+\t\t\tif got := buf.String(); !strings.Contains(got, c.out) {\n+\t\t\t\tt.Errorf(\"signed value incorrectly matched: got %q, want %q\", got, c.out)\n \t\t\t}\n \t\t})\n \t}",
        "comments": [
            {
                "comment": "2021",
                "position": null
            },
            {
                "comment": "Maybe add a comment for maintainers about how this value was produced?",
                "position": null
            },
            {
                "comment": "renamed to privateKey",
                "position": null
            }
        ],
        "commit_message": "fix review comments",
        "commit_id": "06cfdcbbeaa85d517bad58dc541a51473631a6e8"
    },
    {
        "pr_title": "samples(mediacdn): init cme samples",
        "pr_number": 2627,
        "file_name": "mediacdn/sign_test.go",
        "code_diff": "@@ -101,11 +105,11 @@\nfunc TestSignURLPrefix(t *testing.T) {\n \n \tfor _, c := range cases {\n \t\tt.Run(c.testName, func(t *testing.T) {\n-\t\t\tsignedValue := signURLPrefix(\n-\t\t\t\tc.url, c.keyName, testKey, c.expiration,\n-\t\t\t)\n-\t\t\tif signedValue != c.out {\n-\t\t\t\tt.Errorf(\"signed value incorrectly matched: got %s, want %s\", signedValue, c.out)\n+\t\t\tif err := signURLPrefix(buf, c.url, c.keyName, privateTestKey, c.expiration); err != nil {\n+\t\t\t\tt.Errorf(\"signURLPrefix got err: %v\", err)\n+\t\t\t}\n+\t\t\tif got := buf.String(); !strings.Contains(got, c.out) {\n+\t\t\t\tt.Errorf(\"signed value incorrectly matched: got %q, want %q\", got, c.out)\n \t\t\t}\n \t\t})\n \t}",
        "comments": [
            {
                "comment": "2021",
                "position": null
            },
            {
                "comment": "Maybe add a comment for maintainers about how this value was produced?",
                "position": null
            },
            {
                "comment": "renamed to privateKey",
                "position": null
            }
        ],
        "commit_message": "fix review comments",
        "commit_id": "06cfdcbbeaa85d517bad58dc541a51473631a6e8"
    },
    {
        "pr_title": "samples(mediacdn): init cme samples",
        "pr_number": 2627,
        "file_name": "mediacdn/sign_url.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2021 Google LLC\n+// Copyright 2022 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [
            {
                "comment": "What do you think about renaming `base64Key` to `privateKey` (which is the param name in `ed25519.Sign`) as well as documenting all parameters in the function description, so that users know exactly what is expected.",
                "position": null
            }
        ],
        "commit_message": "fix review comments",
        "commit_id": "06cfdcbbeaa85d517bad58dc541a51473631a6e8"
    },
    {
        "pr_title": "samples(mediacdn): init cme samples",
        "pr_number": 2627,
        "file_name": "mediacdn/sign_url_prefix.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2021 Google LLC\n+// Copyright 2022 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [
            {
                "comment": "Why is \"Signed\" capitalized here?",
                "position": null
            },
            {
                "comment": "> signURLPrefix prints\r\n\r\nIt looks to me that this function returns a string, but does not print anything.",
                "position": null
            },
            {
                "comment": "What do you think about renaming `base64Key` to `privateKey` (which is the param name in `ed25519.Sign`) as well as documenting all parameters in the function description, so that users know exactly what is expected.",
                "position": null
            }
        ],
        "commit_message": "fix review comments",
        "commit_id": "06cfdcbbeaa85d517bad58dc541a51473631a6e8"
    },
    {
        "pr_title": "samples(mediacdn): init cme samples",
        "pr_number": 2627,
        "file_name": "mediacdn/sign_url_prefix.go",
        "code_diff": "@@ -19,15 +19,16 @@\nimport (\n \t\"crypto/ed25519\"\n \t\"encoding/base64\"\n \t\"fmt\"\n+\t\"io\"\n \t\"strings\"\n \t\"time\"\n )\n \n-// signURLPrefix prints the Signed URL string for the specified URL prefix and configuration.\n-func signURLPrefix(urlPrefix, keyName string, base64Key []byte, expires time.Time) string {\n+// signURLPrefix prints the signed URL string for the specified URL prefix and configuration.\n+func signURLPrefix(w io.Writer, urlPrefix, keyName string, privateKey []byte, expires time.Time) error {\n \t// urlPrefix := \"https://examples.com\"\n \t// keyName := \"your_key_name\"\n-\t// base64Key := \"[]byte{34, 31, ...}\"\n+\t// privateKey := \"[]byte{34, 31, ...}\"\n \t// expires := time.Unix(1558131350, 0)\n \n \tsep := '?'",
        "comments": [
            {
                "comment": "Why is \"Signed\" capitalized here?",
                "position": null
            },
            {
                "comment": "> signURLPrefix prints\r\n\r\nIt looks to me that this function returns a string, but does not print anything.",
                "position": null
            },
            {
                "comment": "What do you think about renaming `base64Key` to `privateKey` (which is the param name in `ed25519.Sign`) as well as documenting all parameters in the function description, so that users know exactly what is expected.",
                "position": null
            }
        ],
        "commit_message": "fix review comments",
        "commit_id": "06cfdcbbeaa85d517bad58dc541a51473631a6e8"
    },
    {
        "pr_title": "feat(pubsub): create BigQuerySubscription sample",
        "pr_number": 2611,
        "file_name": "functions/functionsv2/imagemagick/imagemagick_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage imagemagick\n \n import (\n \t\"context\"\n+\t\"io/ioutil\"\n \t\"os\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into pubsub-bigquery-subscriptions",
        "commit_id": "18d07bc312bf67ec1affaac7bf0214e82790cbf3"
    },
    {
        "pr_title": "compute: add sample for Neos Quickstart",
        "pr_number": 2610,
        "file_name": "monitoring/snippets/channel_enable_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"io/ioutil\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'tpryan-compute-quickstart-fix' of https://github.com/tpryan/golang-samples into tpryan-compute-quickstart-fix",
        "commit_id": "234e5458266a2ed384e969a4dedddc92fb2fcdf3"
    },
    {
        "pr_title": "fix(firestore): Fix documented error code returned by `DocumentSnapshotIterator.Next()`",
        "pr_number": 2595,
        "file_name": "functions/functionsv2/label_gce_instance/label_gce_instance.go",
        "code_diff": "@@ -25,6 +25,7 @@\nimport (\n \t\"strings\"\n \n \tcompute \"cloud.google.com/go/compute/apiv1\"\n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \t\"github.com/cloudevents/sdk-go/v2/event\"\n \tcomputepb \"google.golang.org/genproto/googleapis/cloud/compute/v1\"\n \t\"google.golang.org/protobuf/proto\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into patch-1",
        "commit_id": "6a954c623492bbb9c76a0164984530abc6d5db3b"
    },
    {
        "pr_title": "feat: add Video Stitcher VOD session samples and tests",
        "pr_number": 2581,
        "file_name": "media/videostitcher/get_cdn_key.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage videostitcher\n // [START video_stitcher_get_cdn_key]\n import (\n \t\"context\"\n+\t\"encoding/json\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_message": "address feedback; output indented JSON",
        "commit_id": "f878f65b1ddca6e36d0690cd540ca2fb1bb223d4"
    },
    {
        "pr_title": "feat: add Video Stitcher VOD session samples and tests",
        "pr_number": 2581,
        "file_name": "media/videostitcher/get_slate.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage videostitcher\n // [START video_stitcher_get_slate]\n import (\n \t\"context\"\n+\t\"encoding/json\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_message": "address feedback; output indented JSON",
        "commit_id": "f878f65b1ddca6e36d0690cd540ca2fb1bb223d4"
    },
    {
        "pr_title": "feat: add Video Stitcher VOD session samples and tests",
        "pr_number": 2581,
        "file_name": "media/videostitcher/get_vod_ad_tag_detail.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage videostitcher\n // [START video_stitcher_get_vod_ad_tag_detail]\n import (\n \t\"context\"\n+\t\"encoding/json\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [
            {
                "comment": "Nit: this looks a little odd, I would do `fmt.Fprintf(w, \"%v: %v\", i, v)`",
                "position": null
            },
            {
                "comment": "This is a little confusing-- is it possible that only some of the requests would error? Might be good to clarify in a comment why this is being printed.",
                "position": null
            },
            {
                "comment": "refactored; uses json.MarshalIndent and no hardcoded fields ",
                "position": null
            },
            {
                "comment": "refactored; uses json.MarshalIndent and no hardcoded fields ",
                "position": null
            }
        ],
        "commit_message": "address feedback; output indented JSON",
        "commit_id": "f878f65b1ddca6e36d0690cd540ca2fb1bb223d4"
    },
    {
        "pr_title": "feat: add Video Stitcher VOD session samples and tests",
        "pr_number": 2581,
        "file_name": "media/videostitcher/get_vod_session.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage videostitcher\n // [START video_stitcher_get_vod_session]\n import (\n \t\"context\"\n+\t\"encoding/json\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [
            {
                "comment": "Generally to print out a whole struct or map, use `%v+` to include the keys as well as values (here and elsewhere).",
                "position": null
            },
            {
                "comment": "refactored; uses json.MarshalIndent and no hardcoded fields ",
                "position": null
            }
        ],
        "commit_message": "address feedback; output indented JSON",
        "commit_id": "f878f65b1ddca6e36d0690cd540ca2fb1bb223d4"
    },
    {
        "pr_title": "feat: add Video Stitcher VOD session samples and tests",
        "pr_number": 2581,
        "file_name": "media/videostitcher/get_vod_stitch_detail.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage videostitcher\n // [START video_stitcher_get_vod_stitch_detail]\n import (\n \t\"context\"\n+\t\"encoding/json\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_message": "address feedback; output indented JSON",
        "commit_id": "f878f65b1ddca6e36d0690cd540ca2fb1bb223d4"
    },
    {
        "pr_title": "feat: add Video Stitcher CDN key samples and tests",
        "pr_number": 2577,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -32,16 +32,14 @@\nconst (\n \tslateID             = \"my-go-test-slate\"\n \tdeleteSlateResponse = \"Deleted slate\"\n \n-\tdeleteCdnKeyResponse  = \"Deleted CDN key\"\n-\tgcdnCdnKeyID          = \"my-go-test-google-cdn\"\n-\takamaiCdnKeyID        = \"my-go-test-akamai-cdn\"\n-\thostname              = \"cdn.example.com\"\n-\tupdatedHostname       = \"updated.example.com\"\n-\tgcdnKeyname           = \"gcdn-key\"\n-\tgcdnPrivateKey        = \"VGhpcyBpcyBhIHRlc3Qgc3RyaW5nLg==\"\n-\tupdatedGcdnPrivateKey = \"VGhpcyBpcyBhbiB1cGRhdGVkIHRlc3Qgc3RyaW5nLg==\"\n-\takamaiTokenKey        = gcdnPrivateKey\n-\tupdatedAkamaiTokenKey = updatedGcdnPrivateKey\n+\tdeleteCdnKeyResponse = \"Deleted CDN key\"\n+\tgcdnCdnKeyID         = \"my-go-test-google-cdn\"\n+\takamaiCdnKeyID       = \"my-go-test-akamai-cdn\"\n+\thostname             = \"cdn.example.com\"\n+\tupdatedHostname      = \"updated.example.com\"\n+\tgcdnKeyname          = \"gcdn-key\"\n+\tprivateKey           = \"VGhpcyBpcyBhIHRlc3Qgc3RyaW5nLg==\"\n+\tupdatedPrivateKey    = \"VGhpcyBpcyBhbiB1cGRhdGVkIHRlc3Qgc3RyaW5nLg==\"\n )\n \n var bucketName string",
        "comments": [
            {
                "comment": "This and the next car are not needed if there are just the same string as above.",
                "position": null
            },
            {
                "comment": "Removed and renamed existing vars",
                "position": null
            }
        ],
        "commit_message": "address feedback",
        "commit_id": "3331dd50979244524da4aedbb7876d8a11238bfc"
    },
    {
        "pr_title": "feat: add Video Stitcher CDN key samples and tests",
        "pr_number": 2577,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -186,7 +184,7 @@\nfunc TestCdnKeys(t *testing.T) {\n \t// Create a new Google CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectNumber, location, gcdnCdnKeyID)\n-\t\tif err := createCdnKey(buf, tc.ProjectID, gcdnCdnKeyID, hostname, gcdnKeyname, gcdnPrivateKey, \"\"); err != nil {\n+\t\tif err := createCdnKey(buf, tc.ProjectID, gcdnCdnKeyID, hostname, gcdnKeyname, privateKey, \"\"); err != nil {\n \t\t\tr.Errorf(\"createCdnKey (GCDN) got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {",
        "comments": [
            {
                "comment": "This and the next car are not needed if there are just the same string as above.",
                "position": null
            },
            {
                "comment": "Removed and renamed existing vars",
                "position": null
            }
        ],
        "commit_message": "address feedback",
        "commit_id": "3331dd50979244524da4aedbb7876d8a11238bfc"
    },
    {
        "pr_title": "feat: add Video Stitcher CDN key samples and tests",
        "pr_number": 2577,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -210,7 +208,7 @@\nfunc TestCdnKeys(t *testing.T) {\n \t// Update an existing CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, gcdnCdnKeyID)\n-\t\tif err := updateCdnKey(buf, tc.ProjectID, gcdnCdnKeyID, updatedHostname, gcdnKeyname, updatedGcdnPrivateKey, \"\"); err != nil {\n+\t\tif err := updateCdnKey(buf, tc.ProjectID, gcdnCdnKeyID, updatedHostname, gcdnKeyname, updatedPrivateKey, \"\"); err != nil {\n \t\t\tr.Errorf(\"updateCdnKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {",
        "comments": [
            {
                "comment": "This and the next car are not needed if there are just the same string as above.",
                "position": null
            },
            {
                "comment": "Removed and renamed existing vars",
                "position": null
            }
        ],
        "commit_message": "address feedback",
        "commit_id": "3331dd50979244524da4aedbb7876d8a11238bfc"
    },
    {
        "pr_title": "feat: add Video Stitcher CDN key samples and tests",
        "pr_number": 2577,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -245,7 +243,7 @@\nfunc TestCdnKeys(t *testing.T) {\n \t// Create a new Akamai CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectNumber, location, akamaiCdnKeyID)\n-\t\tif err := createCdnKey(buf, tc.ProjectID, akamaiCdnKeyID, hostname, \"\", \"\", akamaiTokenKey); err != nil {\n+\t\tif err := createCdnKey(buf, tc.ProjectID, akamaiCdnKeyID, hostname, \"\", \"\", privateKey); err != nil {\n \t\t\tr.Errorf(\"createCdnKey (Akamai) got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {",
        "comments": [
            {
                "comment": "This and the next car are not needed if there are just the same string as above.",
                "position": null
            },
            {
                "comment": "Removed and renamed existing vars",
                "position": null
            }
        ],
        "commit_message": "address feedback",
        "commit_id": "3331dd50979244524da4aedbb7876d8a11238bfc"
    },
    {
        "pr_title": "feat(compute): add samples for suspend/resume",
        "pr_number": 2574,
        "file_name": "compute/instances/suspend-resume/resume.go",
        "code_diff": "@@ -26,9 +26,7 @@\nimport (\n \n // resumeInstance resumes a suspended Google Compute Engine instance\n // (with unencrypted disks).\n-func resumeInstance(\n-\tw io.Writer, projectID, zone, instanceName string,\n-) error {\n+func resumeInstance(w io.Writer, projectID, zone, instanceName string) error {\n \t// projectID := \"your_project_id\"\n \t// zone := \"europe-central2-b\"\n \t// instanceName := \"your_instance_name\"",
        "comments": [
            {
                "comment": "looks like some leftover comments which can be removed.",
                "position": null
            },
            {
                "comment": "This indentation style seems inconsistent with other samples. While I dont see any explicit guidance on function signatures, most others are on a single line.",
                "position": null
            }
        ],
        "commit_message": "review fixes",
        "commit_id": "3c46343e5da5fc3082f7e25bebcf68bf6b4f6403"
    },
    {
        "pr_title": "feat: add code samples and tests for Video Stitcher",
        "pr_number": 2572,
        "file_name": "run/testing/grpc_server_streaming.e2e_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"crypto/x509\"\n \t\"io\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "eb9ee303f87aeab5a7f9b97c6cd296b481ad9894"
    },
    {
        "pr_title": "feat(functions): Imagemagick tutorial for functions v2",
        "pr_number": 2564,
        "file_name": "bigquery/bigquery_migration_quickstart/main.go",
        "code_diff": "@@ -26,10 +26,8 @@\nimport (\n \t\"log\"\n \t\"time\"\n \n-\tmigration \"cloud.google.com/go/bigquery/migration/apiv2alpha\"\n-\ttranslationtaskpb \"google.golang.org/genproto/googleapis/cloud/bigquery/migration/tasks/translation/v2alpha\"\n-\tmigrationpb \"google.golang.org/genproto/googleapis/cloud/bigquery/migration/v2alpha\"\n-\t\"google.golang.org/protobuf/types/known/anypb\"\n+\tmigration \"cloud.google.com/go/bigquery/migration/apiv2\"\n+\tmigrationpb \"google.golang.org/genproto/googleapis/cloud/bigquery/migration/v2\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'main' into gcf2-imagemagick",
        "commit_id": "a2596b169369f6e64cb599fa3d1cfc763ccd72ec"
    },
    {
        "pr_title": "feat(functionsv2): add slack tutorial code",
        "pr_number": 2563,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -72,9 +72,8 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \toutputURIForAnimatedOverlay := \"gs://\" + bucketName + \"/test-output-animated-overlay/\"\n \toutputDirForSetNumberSpritesheet := \"test-output-set-number-spritesheet/\"\n \toutputURIForSetNumberSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForSetNumberSpritesheet\n-\t// TODO: Uncomment following lines and testJobWithPeriodicImagesSpritesheet after fixing https://github.com/GoogleCloudPlatform/golang-samples/issues/2432 (t.Skip not used due to size of test)\n-\t//outputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n-\t//outputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n+\toutputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n+\toutputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n \toutputURIForConcat := \"gs://\" + bucketName + \"/test-output-concat/\"\n \toutputURIForEmbeddedCaptions := \"gs://\" + bucketName + \"/test-output-embedded-captions/\"\n \toutputURIForStandaloneCaptions := \"gs://\" + bucketName + \"/test-output-standalone-captions/\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into gcf2-slack",
        "commit_id": "747ded9566b81ad51148960f05362477dc3c33cb"
    },
    {
        "pr_title": "feat(functionsv2): add slack tutorial code",
        "pr_number": 2563,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -111,12 +110,11 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tcheckGCSFileExists(t, bucketName, outputDirForSetNumberSpritesheet+smallSpriteSheetFileName)\n \tcheckGCSFileExists(t, bucketName, outputDirForSetNumberSpritesheet+largeSpriteSheetFileName)\n \n-\t// TODO: Uncomment following lines and testJobWithPeriodicImagesSpritesheet after fixing https://github.com/GoogleCloudPlatform/golang-samples/issues/2432 (t.Skip not used due to size of test)\n-\t//testJobWithPeriodicImagesSpritesheet(t, projectNumber, inputURI, outputURIForPeriodicSpritesheet)\n-\t//t.Logf(\"\\ntestJobWithPeriodicImagesSpritesheet() completed\\n\")\n+\ttestJobWithPeriodicImagesSpritesheet(t, projectNumber, inputURI, outputURIForPeriodicSpritesheet)\n+\tt.Logf(\"\\ntestJobWithPeriodicImagesSpritesheet() completed\\n\")\n \t// Check if the spritesheets exist.\n-\t//checkGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+smallSpriteSheetFileName)\n-\t//checkGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+largeSpriteSheetFileName)\n+\tcheckGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+smallSpriteSheetFileName)\n+\tcheckGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+largeSpriteSheetFileName)\n \n \ttestJobWithConcatenatedInputs(t, projectNumber, inputURI, 0*time.Second, 8*time.Second+100*time.Millisecond, inputConcatURI, 3*time.Second+500*time.Millisecond, 15*time.Second, outputURIForConcat)\n \tt.Logf(\"\\ntestJobWithConcatenatedInputs() completed\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'main' into gcf2-slack",
        "commit_id": "747ded9566b81ad51148960f05362477dc3c33cb"
    },
    {
        "pr_title": "feat(compute): add preemtible samples",
        "pr_number": 2558,
        "file_name": "compute/instances/preemptible/preemptible_history.go",
        "code_diff": "@@ -29,11 +29,11 @@\nimport (\n \n // preemptionHisory gets a list of preemption operations from given zone in a project.\n // Optionally limit the results to instance name.\n-func preemptionHisory(w io.Writer, projectID, zone, instanceName, filter string) error {\n+func preemptionHisory(w io.Writer, projectID, zone, instanceName, customFilter string) error {\n \t// projectID := \"your_project_id\"\n \t// zone := \"europe-central2-b\"\n \t// instanceName := \"your_instance_name\"\n-\t// filter := \"operationType=\\\"compute.instances.preempted\\\"\"\n+\t// customFilter := \"operationType=\\\"compute.instances.preempted\\\"\"\n \n \tctx := context.Background()\n \toperationsClient, err := compute.NewZoneOperationsRESTClient(ctx)",
        "comments": [],
        "commit_message": "update to customFilter",
        "commit_id": "b1066061ee5ef9aa512811f43b2b54b259370726"
    },
    {
        "pr_title": "feat: sample for creating channel with failover backup input",
        "pr_number": 2550,
        "file_name": "media/livestream/create_channel_with_backup_input.go",
        "code_diff": "@@ -27,7 +27,7 @@\nimport (\n )\n \n // createChannelWithBackupInput creates a channel with a failover backup input.\n-func createChannelWithBackupInput(w io.Writer, projectID string, location string, channelID string, primaryInputID string, backupInputID string, outputURI string) error {\n+func createChannelWithBackupInput(w io.Writer, projectID, location, channelID, primaryInputID, backupInputID, outputURI string) error {\n \t// projectID := \"my-project-id\"\n \t// location := \"us-central1\"\n \t// channelID := \"my-channel\"",
        "comments": [
            {
                "comment": "You don't need to redeclare the string type each time. Instead do:\r\n\r\n``` golang\r\nfunc createChannelWithBackupInput(w io.Writer, projectID, location, channelID, primaryInputID, backupInputID, outputURI string) error { \r\n  /* ... */\r\n}\r\n```",
                "position": null
            },
            {
                "comment": "Done for all files",
                "position": null
            }
        ],
        "commit_message": "better utilize horizontal width",
        "commit_id": "4fad2d9d8eaeeb1783bf1c6817abc25351adee9d"
    },
    {
        "pr_title": "feat(compute): custom vm type samples 3",
        "pr_number": 2549,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -32,6 +32,7 @@\nconst (\n \tstopChannelResponse        = \"Stopped channel\"\n \tlocation                   = \"us-central1\"\n \tinputID                    = \"my-go-test-input\"\n+\tbackupInputID              = \"my-go-test-backup-input\"\n \tchannelID                  = \"my-go-test-channel\"\n \teventID                    = \"my-go-test-channel-event\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into custom-vm-type-samples-3",
        "commit_id": "1dbab5b13518d304a50e1e60e4488315ae3642ed"
    },
    {
        "pr_title": "feat(compute): custom vm type samples 3",
        "pr_number": 2549,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -94,6 +95,22 @@\nfunc testInputs(t *testing.T) {\n \t\t})\n \t}\n \n+\t// Delete the default backup input if it exists\n+\tif err := getInput(buf, tc.ProjectID, location, backupInputID); err == nil {\n+\t\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\t\tif err := deleteInput(buf, tc.ProjectID, location, backupInputID); err != nil {\n+\t\t\t\tr.Errorf(\"deleteInput got err: %v\", err)\n+\t\t\t}\n+\t\t})\n+\t}\n+\n+\t// Create a new backup input.\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\tif err := createInput(buf, tc.ProjectID, location, backupInputID); err != nil {\n+\t\t\tr.Errorf(\"createInput got err: %v\", err)\n+\t\t}\n+\t})\n+\n \t// Tests\n \n \t// Create a new input.",
        "comments": [],
        "commit_message": "Merge branch 'main' into custom-vm-type-samples-3",
        "commit_id": "1dbab5b13518d304a50e1e60e4488315ae3642ed"
    },
    {
        "pr_title": "feat(compute): custom vm type samples 3",
        "pr_number": 2549,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -283,8 +300,30 @@\nfunc testChannels(t *testing.T, outputURI string) {\n \t})\n \tbuf.Reset()\n \n+\t// Create a new channel with backup input.\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\tchannelName := fmt.Sprintf(\"projects/%s/locations/%s/channels/%s\", tc.ProjectID, location, channelID)\n+\t\tif err := createChannelWithBackupInput(buf, tc.ProjectID, location, channelID, inputID, backupInputID, outputURI); err != nil {\n+\t\t\tr.Errorf(\"createChannel got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, channelName) {\n+\t\t\tr.Errorf(\"createChannel got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, channelName)\n+\t\t}\n+\t})\n+\tbuf.Reset()\n+\n \t// Clean up\n \n+\t// Delete the channel with backup input.\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\tif err := deleteChannel(buf, tc.ProjectID, location, channelID); err != nil {\n+\t\t\tr.Errorf(\"deleteChannel got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, deleteChannelResponse) {\n+\t\t\tr.Errorf(\"deleteChannel got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteChannelResponse)\n+\t\t}\n+\t})\n+\n \t// Delete the input.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tif err := deleteInput(buf, tc.ProjectID, location, inputID); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into custom-vm-type-samples-3",
        "commit_id": "1dbab5b13518d304a50e1e60e4488315ae3642ed"
    },
    {
        "pr_title": "feat(compute): add compute_machine_type samples 2",
        "pr_number": 2545,
        "file_name": "compute/instances/custom-machine-type/create_custom_machine_type.go",
        "code_diff": "@@ -27,7 +27,10 @@\nimport (\n \n // createInstanceWithCustomMachineType sends an instance creation request\n // to the Compute Engine API and waits for it to complete.\n-func createInstanceWithCustomMachineType(w io.Writer, projectID, zone, instanceName, machineType string) error {\n+func createInstanceWithCustomMachineType(\n+\tw io.Writer,\n+\tprojectID, zone, instanceName, machineType string,\n+) error {\n \t// projectID := \"your_project_id\"\n \t// zone := \"europe-central2-b\"\n \t// instanceName := \"your_instance_name\"",
        "comments": [],
        "commit_message": "fix linelength",
        "commit_id": "8afc3c9045677181616bf8aa9f0234c4e8391c64"
    },
    {
        "pr_title": "feat(compute): add compute_machine_type samples 2",
        "pr_number": 2545,
        "file_name": "compute/instances/custom-machine-type/create_shared_with_helper.go",
        "code_diff": "@@ -129,7 +129,11 @@\nfunc customMachineTypeSharedCoreURI(zone, cpuSeries string, memory int) (string,\n \n \t// Check the number of cores\n \tif len(tl.allowedCores) > 0 && !containsInt(tl.allowedCores, coreCount) {\n-\t\treturn \"\", fmt.Errorf(\"invalid number of cores requested. Allowed number of cores for %v is: %v\", cpuSeries, tl.allowedCores)\n+\t\treturn \"\", fmt.Errorf(\n+\t\t\t\"invalid number of cores requested. Allowed number of cores for %v is: %v\",\n+\t\t\tcpuSeries,\n+\t\t\ttl.allowedCores,\n+\t\t)\n \t}\n \n \t// Memory must be a multiple of 256 MB",
        "comments": [
            {
                "comment": "The error should be the last return value.",
                "position": null
            }
        ],
        "commit_message": "fix linelength",
        "commit_id": "8afc3c9045677181616bf8aa9f0234c4e8391c64"
    },
    {
        "pr_title": "feat(compute): add compute_machine_type samples 2",
        "pr_number": 2545,
        "file_name": "compute/instances/custom-machine-type/create_shared_with_helper.go",
        "code_diff": "@@ -139,15 +143,27 @@\nfunc customMachineTypeSharedCoreURI(zone, cpuSeries string, memory int) (string,\n \n \t// Check if the requested memory isn't too little\n \tif memory < coreCount*tl.minMemPerCore {\n-\t\treturn \"\", fmt.Errorf(\"requested memory is too low. Minimal memory for %v is %v MB per core\", cpuSeries, tl.minMemPerCore)\n+\t\treturn \"\", fmt.Errorf(\n+\t\t\t\"requested memory is too low. Minimal memory for %v is %v MB per core\",\n+\t\t\tcpuSeries,\n+\t\t\ttl.minMemPerCore,\n+\t\t)\n \t}\n \n \t// Check if the requested memory isn't too much\n \tif memory > coreCount*tl.maxMemPerCore && !tl.allowExtraMemory {\n-\t\treturn \"\", fmt.Errorf(\"requested memory is too large.. Maximum memory allowed for %v is %v MB per core\", cpuSeries, tl.maxMemPerCore)\n+\t\treturn \"\", fmt.Errorf(\n+\t\t\t\"requested memory is too large.. Maximum memory allowed for %v is %v MB per core\",\n+\t\t\tcpuSeries,\n+\t\t\ttl.maxMemPerCore,\n+\t\t)\n \t}\n \tif memory > tl.extraMemoryLimit && tl.allowExtraMemory {\n-\t\treturn \"\", fmt.Errorf(\"requested memory is too large.. Maximum memory allowed for %v is %v MB\", cpuSeries, tl.extraMemoryLimit)\n+\t\treturn \"\", fmt.Errorf(\n+\t\t\t\"requested memory is too large.. Maximum memory allowed for %v is %v MB\",\n+\t\t\tcpuSeries,\n+\t\t\ttl.extraMemoryLimit,\n+\t\t)\n \t}\n \n \t// Return the custom machine type in form of a string acceptable by Compute Engine API.",
        "comments": [
            {
                "comment": "The error should be the last return value.",
                "position": null
            }
        ],
        "commit_message": "fix linelength",
        "commit_id": "8afc3c9045677181616bf8aa9f0234c4e8391c64"
    },
    {
        "pr_title": "feat(compute): add compute_machine_type samples 2",
        "pr_number": 2545,
        "file_name": "compute/instances/custom-machine-type/create_shared_with_helper.go",
        "code_diff": "@@ -156,14 +172,24 @@\nfunc customMachineTypeSharedCoreURI(zone, cpuSeries string, memory int) (string,\n \t}\n \n \tif memory > coreCount*tl.maxMemPerCore {\n-\t\treturn fmt.Sprintf(\"zones/%v/machineTypes/%v-%v-%v-ext\", zone, cpuSeries, coreCount, memory), nil\n+\t\treturn fmt.Sprintf(\n+\t\t\t\"zones/%v/machineTypes/%v-%v-%v-ext\",\n+\t\t\tzone,\n+\t\t\tcpuSeries,\n+\t\t\tcoreCount,\n+\t\t\tmemory,\n+\t\t), nil\n \t}\n \n \treturn fmt.Sprintf(\"zones/%v/machineTypes/%v-%v-%v\", zone, cpuSeries, coreCount, memory), nil\n }\n \n // createInstanceWithCustomSharedCore creates a new VM instance with a custom type using shared CPUs.\n-func createInstanceWithCustomSharedCore(w io.Writer, projectID, zone, instanceName, cpuSeries string, memory int) error {\n+func createInstanceWithCustomSharedCore(\n+\tw io.Writer,\n+\tprojectID, zone, instanceName, cpuSeries string,\n+\tmemory int,\n+) error {\n \t// projectID := \"your_project_id\"\n \t// zone := \"europe-central2-b\"\n \t// instanceName := \"your_instance_name\"",
        "comments": [
            {
                "comment": "The error should be the last return value.",
                "position": null
            }
        ],
        "commit_message": "fix linelength",
        "commit_id": "8afc3c9045677181616bf8aa9f0234c4e8391c64"
    },
    {
        "pr_title": "feat(compute): add compute_machine_type samples 2",
        "pr_number": 2545,
        "file_name": "compute/instances/custom-machine-type/create_with_helper.go",
        "code_diff": "@@ -128,7 +128,11 @@\nfunc customMachineTypeURI(zone, cpuSeries string, coreCount, memory int) (string\n \n \t// Check the number of cores\n \tif len(tl.allowedCores) > 0 && !containsInt(tl.allowedCores, coreCount) {\n-\t\treturn \"\", fmt.Errorf(\"invalid number of cores requested. Allowed number of cores for %v is: %v\", cpuSeries, tl.allowedCores)\n+\t\treturn \"\", fmt.Errorf(\n+\t\t\t\"invalid number of cores requested. Allowed number of cores for %v is: %v\",\n+\t\t\tcpuSeries,\n+\t\t\ttl.allowedCores,\n+\t\t)\n \t}\n \n \t// Memory must be a multiple of 256 MB",
        "comments": [
            {
                "comment": "Same here. Error should be the last return value.",
                "position": null
            },
            {
                "comment": "What's a better name for this function? Helper isn't descriptive. Perhaps `instanceURI`? Or whatever the appropriate term is for \"zones/%v/machineTypes/%v-%v-%v\"?",
                "position": null
            }
        ],
        "commit_message": "fix linelength",
        "commit_id": "8afc3c9045677181616bf8aa9f0234c4e8391c64"
    },
    {
        "pr_title": "feat(compute): add compute_machine_type samples 2",
        "pr_number": 2545,
        "file_name": "compute/instances/custom-machine-type/create_with_helper.go",
        "code_diff": "@@ -138,15 +142,27 @@\nfunc customMachineTypeURI(zone, cpuSeries string, coreCount, memory int) (string\n \n \t// Check if the requested memory isn't too little\n \tif memory < coreCount*tl.minMemPerCore {\n-\t\treturn \"\", fmt.Errorf(\"requested memory is too low. Minimal memory for %v is %v MB per core\", cpuSeries, tl.minMemPerCore)\n+\t\treturn \"\", fmt.Errorf(\n+\t\t\t\"requested memory is too low. Minimal memory for %v is %v MB per core\",\n+\t\t\tcpuSeries,\n+\t\t\ttl.minMemPerCore,\n+\t\t)\n \t}\n \n \t// Check if the requested memory isn't too much\n \tif memory > coreCount*tl.maxMemPerCore && !tl.allowExtraMemory {\n-\t\treturn \"\", fmt.Errorf(\"requested memory is too large.. Maximum memory allowed for %v is %v MB per core\", cpuSeries, tl.maxMemPerCore)\n+\t\treturn \"\", fmt.Errorf(\n+\t\t\t\"requested memory is too large.. Maximum memory allowed for %v is %v MB per core\",\n+\t\t\tcpuSeries,\n+\t\t\ttl.maxMemPerCore,\n+\t\t)\n \t}\n \tif memory > tl.extraMemoryLimit && tl.allowExtraMemory {\n-\t\treturn \"\", fmt.Errorf(\"requested memory is too large.. Maximum memory allowed for %v is %v MB\", cpuSeries, tl.extraMemoryLimit)\n+\t\treturn \"\", fmt.Errorf(\n+\t\t\t\"requested memory is too large.. Maximum memory allowed for %v is %v MB\",\n+\t\t\tcpuSeries,\n+\t\t\ttl.extraMemoryLimit,\n+\t\t)\n \t}\n \n \t// Return the custom machine type in form of a string acceptable by Compute Engine API.",
        "comments": [
            {
                "comment": "Same here. Error should be the last return value.",
                "position": null
            },
            {
                "comment": "What's a better name for this function? Helper isn't descriptive. Perhaps `instanceURI`? Or whatever the appropriate term is for \"zones/%v/machineTypes/%v-%v-%v\"?",
                "position": null
            }
        ],
        "commit_message": "fix linelength",
        "commit_id": "8afc3c9045677181616bf8aa9f0234c4e8391c64"
    },
    {
        "pr_title": "feat(compute): add compute_machine_type samples 2",
        "pr_number": 2545,
        "file_name": "compute/instances/custom-machine-type/create_with_helper.go",
        "code_diff": "@@ -155,14 +171,24 @@\nfunc customMachineTypeURI(zone, cpuSeries string, coreCount, memory int) (string\n \t}\n \n \tif memory > coreCount*tl.maxMemPerCore {\n-\t\treturn fmt.Sprintf(\"zones/%v/machineTypes/%v-%v-%v-ext\", zone, cpuSeries, coreCount, memory), nil\n+\t\treturn fmt.Sprintf(\n+\t\t\t\"zones/%v/machineTypes/%v-%v-%v-ext\",\n+\t\t\tzone,\n+\t\t\tcpuSeries,\n+\t\t\tcoreCount,\n+\t\t\tmemory,\n+\t\t), nil\n \t}\n \n \treturn fmt.Sprintf(\"zones/%v/machineTypes/%v-%v-%v\", zone, cpuSeries, coreCount, memory), nil\n }\n \n // createInstanceWithCustomMachineTypeWithHelper creates a new VM instance with a custom machine type.\n-func createInstanceWithCustomMachineTypeWithHelper(w io.Writer, projectID, zone, instanceName, cpuSeries string, coreCount, memory int) error {\n+func createInstanceWithCustomMachineTypeWithHelper(\n+\tw io.Writer,\n+\tprojectID, zone, instanceName, cpuSeries string,\n+\tcoreCount, memory int,\n+) error {\n \t// projectID := \"your_project_id\"\n \t// zone := \"europe-central2-b\"\n \t// instanceName := \"your_instance_name\"",
        "comments": [
            {
                "comment": "Same here. Error should be the last return value.",
                "position": null
            },
            {
                "comment": "What's a better name for this function? Helper isn't descriptive. Perhaps `instanceURI`? Or whatever the appropriate term is for \"zones/%v/machineTypes/%v-%v-%v\"?",
                "position": null
            }
        ],
        "commit_message": "fix linelength",
        "commit_id": "8afc3c9045677181616bf8aa9f0234c4e8391c64"
    },
    {
        "pr_title": "feat(compute): add compute_machine_type samples 2",
        "pr_number": 2545,
        "file_name": "compute/instances/custom-machine-type/custom_machine_type_test.go",
        "code_diff": "@@ -47,7 +47,10 @@\nfunc deleteInstance(ctx context.Context, projectId, zone, instanceName string) e\n \treturn op.Wait(ctx)\n }\n \n-func getInstance(ctx context.Context, projectID, zone, instanceName string) (*computepb.Instance, error) {\n+func getInstance(\n+\tctx context.Context,\n+\tprojectID, zone, instanceName string,\n+) (*computepb.Instance, error) {\n \tinstancesClient, err := compute.NewInstancesRESTClient(ctx)\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_message": "fix linelength",
        "commit_id": "8afc3c9045677181616bf8aa9f0234c4e8391c64"
    },
    {
        "pr_title": "feat(compute): add compute_machine_type samples 2",
        "pr_number": 2545,
        "file_name": "compute/instances/custom-machine-type/custom_machine_type_test.go",
        "code_diff": "@@ -92,7 +95,11 @@\nfunc TestComputeCreateInstanceWithCustomMachineTypeSnippets(t *testing.T) {\n \t\tt.Errorf(\"unable to get instance: %v\", err)\n \t}\n \n-\twant = fmt.Sprintf(\"https://www.googleapis.com/compute/v1/projects/%s/zones/%s/machineTypes/n2-custom-8-10240\", tc.ProjectID, zone)\n+\twant = fmt.Sprintf(\n+\t\t\"https://www.googleapis.com/compute/v1/projects/%s/zones/%s/machineTypes/n2-custom-8-10240\",\n+\t\ttc.ProjectID,\n+\t\tzone,\n+\t)\n \tif instance.GetMachineType() != want {\n \t\tt.Errorf(\"incorrect instance MachineType got %q, want %q\", instance.GetMachineType(), want)\n \t}",
        "comments": [],
        "commit_message": "fix linelength",
        "commit_id": "8afc3c9045677181616bf8aa9f0234c4e8391c64"
    },
    {
        "pr_title": "feat(compute): add compute_machine_type samples 2",
        "pr_number": 2545,
        "file_name": "compute/instances/custom-machine-type/custom_machine_type_test.go",
        "code_diff": "@@ -117,7 +124,11 @@\nfunc TestComputeCreateInstanceWithCustomMachineTypeSnippets(t *testing.T) {\n \t\tt.Errorf(\"unable to get instance: %v\", err)\n \t}\n \n-\twant = fmt.Sprintf(\"https://www.googleapis.com/compute/v1/projects/%s/zones/%s/machineTypes/e2-custom-4-8192\", tc.ProjectID, zone)\n+\twant = fmt.Sprintf(\n+\t\t\"https://www.googleapis.com/compute/v1/projects/%s/zones/%s/machineTypes/e2-custom-4-8192\",\n+\t\ttc.ProjectID,\n+\t\tzone,\n+\t)\n \tif instance.GetMachineType() != want {\n \t\tt.Errorf(\"incorrect instance MachineType got %q, want %q\", instance.GetMachineType(), want)\n \t}",
        "comments": [],
        "commit_message": "fix linelength",
        "commit_id": "8afc3c9045677181616bf8aa9f0234c4e8391c64"
    },
    {
        "pr_title": "chore: Fix test flakes in TestJobTemplatesAndJobs",
        "pr_number": 2533,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -56,11 +56,12 @@\nvar (\n \t}\n \n \tadminCommands = map[string]adminCommand{\n-\t\t\"createdatabase\":   createDatabase,\n-\t\t\"addnewcolumn\":     addNewColumn,\n-\t\t\"pgaddnewcolumn\":   pgAddNewColumn,\n-\t\t\"addstoringindex\":  addStoringIndex,\n-\t\t\"pgcreatedatabase\": pgCreateDatabase,\n+\t\t\"createdatabase\":    createDatabase,\n+\t\t\"addnewcolumn\":      addNewColumn,\n+\t\t\"pgaddnewcolumn\":    pgAddNewColumn,\n+\t\t\"addstoringindex\":   addStoringIndex,\n+\t\t\"pgaddstoringindex\": pgAddStoringIndex,\n+\t\t\"pgcreatedatabase\":  pgCreateDatabase,\n \t}\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into test-flakes",
        "commit_id": "7e19ca958412834bd694862fdfb9e768e10edc84"
    },
    {
        "pr_title": "chore: Fix test flakes in TestJobTemplatesAndJobs",
        "pr_number": 2533,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -688,6 +689,23 @@\nfunc pgWriteWithTransactionUsingDML(ctx context.Context, w io.Writer, client *sp\n \treturn err\n }\n \n+func pgAddStoringIndex(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t\"CREATE INDEX AlbumsByAlbumTitle2 ON Albums(AlbumTitle) INCLUDE (MarketingBudget)\",\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"failed to execute spanner database DDL request: %v\", err)\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn fmt.Errorf(\"failed to complete spanner database DDL request: %v\", err)\n+\t}\n+\tfmt.Fprintf(w, \"Added storing index\\n\")\n+\treturn nil\n+}\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into test-flakes",
        "commit_id": "7e19ca958412834bd694862fdfb9e768e10edc84"
    },
    {
        "pr_title": "feat(spanner): add sample for STORING indexes on a Spanner PostgreSQL database",
        "pr_number": 2526,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -12,6 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START cloudrun_jobs_quickstart]\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-storing-index-sample",
        "commit_id": "ae958c1caadd85e18b89a434df2a00ae50413c31"
    },
    {
        "pr_title": "feat(spanner): add sample for STORING indexes on a Spanner PostgreSQL database",
        "pr_number": 2526,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -34,10 +35,14 @@\ntype Config struct {\n }\n \n func configFromEnv() (Config, error) {\n-\ttaskNum := os.Getenv(\"TASK_NUM\")\n-\tattemptNum := os.Getenv(\"ATTEMPT_NUM\")\n+\t// [START cloudrun_jobs_env_vars]\n+\t// Job-defined\n+\ttaskNum := os.Getenv(\"CLOUD_RUN_TASK_INDEX\")\n+\tattemptNum := os.Getenv(\"CLOUD_RUN_TASK_ATTEMPT\")\n+\t// User-defined\n \tsleepMs, err := sleepMsToInt(os.Getenv(\"SLEEP_MS\"))\n \tfailRate, err := failRateToFloat(os.Getenv(\"FAIL_RATE\"))\n+\t// [END cloudrun_jobs_env_vars]\n \n \tif err != nil {\n \t\treturn Config{}, err",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-storing-index-sample",
        "commit_id": "ae958c1caadd85e18b89a434df2a00ae50413c31"
    },
    {
        "pr_title": "feat(spanner): add sample for STORING indexes on a Spanner PostgreSQL database",
        "pr_number": 2526,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -90,7 +95,9 @@\nfunc main() {\n \t// Simulate errors\n \tif config.failRate > 0 {\n \t\tif failure := randomFailure(config); failure != nil {\n+\t\t\t// [START cloudrun_jobs_exit_process]\n \t\t\tlog.Fatalf(\"%v\", failure)\n+\t\t\t// [END cloudrun_jobs_exit_process]\n \t\t}\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-storing-index-sample",
        "commit_id": "ae958c1caadd85e18b89a434df2a00ae50413c31"
    },
    {
        "pr_title": "feat(compute): add windows os image sample",
        "pr_number": 2525,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -72,8 +72,9 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \toutputURIForAnimatedOverlay := \"gs://\" + bucketName + \"/test-output-animated-overlay/\"\n \toutputDirForSetNumberSpritesheet := \"test-output-set-number-spritesheet/\"\n \toutputURIForSetNumberSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForSetNumberSpritesheet\n-\toutputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n-\toutputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n+\t// TODO: Uncomment following lines and testJobWithPeriodicImagesSpritesheet after fixing https://github.com/GoogleCloudPlatform/golang-samples/issues/2432 (t.Skip not used due to size of test)\n+\t//outputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n+\t//outputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n \toutputURIForConcat := \"gs://\" + bucketName + \"/test-output-concat/\"\n \toutputURIForEmbeddedCaptions := \"gs://\" + bucketName + \"/test-output-embedded-captions/\"\n \toutputURIForStandaloneCaptions := \"gs://\" + bucketName + \"/test-output-standalone-captions/\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-windows-instance-samples",
        "commit_id": "70a1ed25cc873104d3925c509c0bd3b3942a7fff"
    },
    {
        "pr_title": "feat(compute): add windows os image sample",
        "pr_number": 2525,
        "file_name": "pubsub/topics/publish.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc publish(w io.Writer, projectID, topicID, msg string) error {\n \tctx := context.Background()\n \tclient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"pubsub.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"pubsub: NewClient: %v\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-windows-instance-samples",
        "commit_id": "70a1ed25cc873104d3925c509c0bd3b3942a7fff"
    },
    {
        "pr_title": "feat(compute): add windows os image sample",
        "pr_number": 2525,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -12,6 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START cloudrun_jobs_quickstart]\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-windows-instance-samples",
        "commit_id": "70a1ed25cc873104d3925c509c0bd3b3942a7fff"
    },
    {
        "pr_title": "feat(compute): add windows os image sample",
        "pr_number": 2525,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -34,10 +35,14 @@\ntype Config struct {\n }\n \n func configFromEnv() (Config, error) {\n-\ttaskNum := os.Getenv(\"TASK_NUM\")\n-\tattemptNum := os.Getenv(\"ATTEMPT_NUM\")\n+\t// [START cloudrun_jobs_env_vars]\n+\t// Job-defined\n+\ttaskNum := os.Getenv(\"CLOUD_RUN_TASK_INDEX\")\n+\tattemptNum := os.Getenv(\"CLOUD_RUN_TASK_ATTEMPT\")\n+\t// User-defined\n \tsleepMs, err := sleepMsToInt(os.Getenv(\"SLEEP_MS\"))\n \tfailRate, err := failRateToFloat(os.Getenv(\"FAIL_RATE\"))\n+\t// [END cloudrun_jobs_env_vars]\n \n \tif err != nil {\n \t\treturn Config{}, err",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-windows-instance-samples",
        "commit_id": "70a1ed25cc873104d3925c509c0bd3b3942a7fff"
    },
    {
        "pr_title": "feat(compute): add windows os image sample",
        "pr_number": 2525,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -90,7 +95,9 @@\nfunc main() {\n \t// Simulate errors\n \tif config.failRate > 0 {\n \t\tif failure := randomFailure(config); failure != nil {\n+\t\t\t// [START cloudrun_jobs_exit_process]\n \t\t\tlog.Fatalf(\"%v\", failure)\n+\t\t\t// [END cloudrun_jobs_exit_process]\n \t\t}\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-windows-instance-samples",
        "commit_id": "70a1ed25cc873104d3925c509c0bd3b3942a7fff"
    },
    {
        "pr_title": "feat(compute): add windows os image sample",
        "pr_number": 2525,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -56,11 +56,12 @@\nvar (\n \t}\n \n \tadminCommands = map[string]adminCommand{\n-\t\t\"createdatabase\":   createDatabase,\n-\t\t\"addnewcolumn\":     addNewColumn,\n-\t\t\"pgaddnewcolumn\":   pgAddNewColumn,\n-\t\t\"addstoringindex\":  addStoringIndex,\n-\t\t\"pgcreatedatabase\": pgCreateDatabase,\n+\t\t\"createdatabase\":    createDatabase,\n+\t\t\"addnewcolumn\":      addNewColumn,\n+\t\t\"pgaddnewcolumn\":    pgAddNewColumn,\n+\t\t\"addstoringindex\":   addStoringIndex,\n+\t\t\"pgaddstoringindex\": pgAddStoringIndex,\n+\t\t\"pgcreatedatabase\":  pgCreateDatabase,\n \t}\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-windows-instance-samples",
        "commit_id": "70a1ed25cc873104d3925c509c0bd3b3942a7fff"
    },
    {
        "pr_title": "feat(compute): add windows os image sample",
        "pr_number": 2525,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -688,6 +689,23 @@\nfunc pgWriteWithTransactionUsingDML(ctx context.Context, w io.Writer, client *sp\n \treturn err\n }\n \n+func pgAddStoringIndex(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t\"CREATE INDEX AlbumsByAlbumTitle2 ON Albums(AlbumTitle) INCLUDE (MarketingBudget)\",\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"failed to execute spanner database DDL request: %v\", err)\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn fmt.Errorf(\"failed to complete spanner database DDL request: %v\", err)\n+\t}\n+\tfmt.Fprintf(w, \"Added storing index\\n\")\n+\treturn nil\n+}\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-windows-instance-samples",
        "commit_id": "70a1ed25cc873104d3925c509c0bd3b3942a7fff"
    },
    {
        "pr_title": "feat(compute): add custom-machine-type helper class",
        "pr_number": 2524,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -72,8 +72,9 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \toutputURIForAnimatedOverlay := \"gs://\" + bucketName + \"/test-output-animated-overlay/\"\n \toutputDirForSetNumberSpritesheet := \"test-output-set-number-spritesheet/\"\n \toutputURIForSetNumberSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForSetNumberSpritesheet\n-\toutputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n-\toutputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n+\t// TODO: Uncomment following lines and testJobWithPeriodicImagesSpritesheet after fixing https://github.com/GoogleCloudPlatform/golang-samples/issues/2432 (t.Skip not used due to size of test)\n+\t//outputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n+\t//outputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n \toutputURIForConcat := \"gs://\" + bucketName + \"/test-output-concat/\"\n \toutputURIForEmbeddedCaptions := \"gs://\" + bucketName + \"/test-output-embedded-captions/\"\n \toutputURIForStandaloneCaptions := \"gs://\" + bucketName + \"/test-output-standalone-captions/\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute-custom-vm-1",
        "commit_id": "77c4d2e0facc44bfbe114abe45a704566abc30bb"
    },
    {
        "pr_title": "feat(compute): add custom-machine-type helper class",
        "pr_number": 2524,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -12,6 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START cloudrun_jobs_quickstart]\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute-custom-vm-1",
        "commit_id": "77c4d2e0facc44bfbe114abe45a704566abc30bb"
    },
    {
        "pr_title": "feat(compute): add custom-machine-type helper class",
        "pr_number": 2524,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -34,10 +35,14 @@\ntype Config struct {\n }\n \n func configFromEnv() (Config, error) {\n-\ttaskNum := os.Getenv(\"TASK_NUM\")\n-\tattemptNum := os.Getenv(\"ATTEMPT_NUM\")\n+\t// [START cloudrun_jobs_env_vars]\n+\t// Job-defined\n+\ttaskNum := os.Getenv(\"CLOUD_RUN_TASK_INDEX\")\n+\tattemptNum := os.Getenv(\"CLOUD_RUN_TASK_ATTEMPT\")\n+\t// User-defined\n \tsleepMs, err := sleepMsToInt(os.Getenv(\"SLEEP_MS\"))\n \tfailRate, err := failRateToFloat(os.Getenv(\"FAIL_RATE\"))\n+\t// [END cloudrun_jobs_env_vars]\n \n \tif err != nil {\n \t\treturn Config{}, err",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute-custom-vm-1",
        "commit_id": "77c4d2e0facc44bfbe114abe45a704566abc30bb"
    },
    {
        "pr_title": "feat(compute): add custom-machine-type helper class",
        "pr_number": 2524,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -90,7 +95,9 @@\nfunc main() {\n \t// Simulate errors\n \tif config.failRate > 0 {\n \t\tif failure := randomFailure(config); failure != nil {\n+\t\t\t// [START cloudrun_jobs_exit_process]\n \t\t\tlog.Fatalf(\"%v\", failure)\n+\t\t\t// [END cloudrun_jobs_exit_process]\n \t\t}\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute-custom-vm-1",
        "commit_id": "77c4d2e0facc44bfbe114abe45a704566abc30bb"
    },
    {
        "pr_title": "feat(compute): add custom-machine-type helper class",
        "pr_number": 2524,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -56,11 +56,12 @@\nvar (\n \t}\n \n \tadminCommands = map[string]adminCommand{\n-\t\t\"createdatabase\":   createDatabase,\n-\t\t\"addnewcolumn\":     addNewColumn,\n-\t\t\"pgaddnewcolumn\":   pgAddNewColumn,\n-\t\t\"addstoringindex\":  addStoringIndex,\n-\t\t\"pgcreatedatabase\": pgCreateDatabase,\n+\t\t\"createdatabase\":    createDatabase,\n+\t\t\"addnewcolumn\":      addNewColumn,\n+\t\t\"pgaddnewcolumn\":    pgAddNewColumn,\n+\t\t\"addstoringindex\":   addStoringIndex,\n+\t\t\"pgaddstoringindex\": pgAddStoringIndex,\n+\t\t\"pgcreatedatabase\":  pgCreateDatabase,\n \t}\n )",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute-custom-vm-1",
        "commit_id": "77c4d2e0facc44bfbe114abe45a704566abc30bb"
    },
    {
        "pr_title": "feat(compute): add custom-machine-type helper class",
        "pr_number": 2524,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -688,6 +689,23 @@\nfunc pgWriteWithTransactionUsingDML(ctx context.Context, w io.Writer, client *sp\n \treturn err\n }\n \n+func pgAddStoringIndex(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t\"CREATE INDEX AlbumsByAlbumTitle2 ON Albums(AlbumTitle) INCLUDE (MarketingBudget)\",\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"failed to execute spanner database DDL request: %v\", err)\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn fmt.Errorf(\"failed to complete spanner database DDL request: %v\", err)\n+\t}\n+\tfmt.Fprintf(w, \"Added storing index\\n\")\n+\treturn nil\n+}\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into compute-custom-vm-1",
        "commit_id": "77c4d2e0facc44bfbe114abe45a704566abc30bb"
    },
    {
        "pr_title": "fix(bigquery/storage): handle retryable RESOURCE_EXHAUSTED errors in bigquery storage sample",
        "pr_number": 2516,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -38,7 +38,10 @@\nimport (\n \tgax \"github.com/googleapis/gax-go/v2\"\n \tgoavro \"github.com/linkedin/goavro/v2\"\n \tbqStoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1\"\n+\t\"google.golang.org/genproto/googleapis/rpc/errdetails\"\n \t\"google.golang.org/grpc\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n // rpcOpts is used to configure the underlying gRPC client to accept large",
        "comments": [
            {
                "comment": "Can you reorder this so the `err==nil` case is last?  As it stands, the logic checks for io.EOF, no error, then generic error (where we inspect for the exhaustion/retryinfo).",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "The else here is superfluous with the return above.",
                "position": null
            },
            {
                "comment": "Please wrap this comment to under 100 characters.",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "fix(bigquery/storage): handle retryable RESOURCE_EXHAUSTED errors in bigquery storage sample\n\n* Adds special handling for retryable RESOURCE_EXHAUSTED errors returned from bigquery storage api, so they aren't treated as regular errors.\n* Fixes retries being reset every time an error is observed, so at most 3 back-to-back errors are retried.",
        "commit_id": "1ba40d4517f1b2edc5fab80956a6a7d7f4f5290b"
    },
    {
        "pr_title": "fix(bigquery/storage): handle retryable RESOURCE_EXHAUSTED errors in bigquery storage sample",
        "pr_number": 2516,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -207,8 +210,8 @@\nfunc processStream(ctx context.Context, client *bqStorage.BigQueryReadClient, st\n \t// stream, implement a retry that resets once progress is made.\n \tretryLimit := 3\n \n+\tretries := 0\n \tfor {\n-\t\tretries := 0\n \t\t// Send the initiating request to start streaming row blocks.\n \t\trowStream, err := client.ReadRows(ctx, &bqStoragepb.ReadRowsRequest{\n \t\t\tReadStream: st,",
        "comments": [
            {
                "comment": "Can you reorder this so the `err==nil` case is last?  As it stands, the logic checks for io.EOF, no error, then generic error (where we inspect for the exhaustion/retryinfo).",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "The else here is superfluous with the return above.",
                "position": null
            },
            {
                "comment": "Please wrap this comment to under 100 characters.",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "fix(bigquery/storage): handle retryable RESOURCE_EXHAUSTED errors in bigquery storage sample\n\n* Adds special handling for retryable RESOURCE_EXHAUSTED errors returned from bigquery storage api, so they aren't treated as regular errors.\n* Fixes retries being reset every time an error is observed, so at most 3 back-to-back errors are retried.",
        "commit_id": "1ba40d4517f1b2edc5fab80956a6a7d7f4f5290b"
    },
    {
        "pr_title": "feat(storage): add sample for creating a dual-region bucket",
        "pr_number": 2498,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -45,6 +45,7 @@\ntype sampleFunc func(w io.Writer, dbName string) error\n type sampleFuncWithContext func(ctx context.Context, w io.Writer, dbName string) error\n type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string) error\n+type backupSampleFuncWithoutContext func(w io.Writer, dbName, backupID string) error\n type createBackupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string, versionTime time.Time) error\n \n var (",
        "comments": [],
        "commit_message": "Merge branch 'main' into dual-region",
        "commit_id": "d4c634f9eb372086477058533205fdf96f560b2c"
    },
    {
        "pr_title": "feat(storage): add sample for creating a dual-region bucket",
        "pr_number": 2498,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -401,10 +402,11 @@\nfunc TestBackupSample(t *testing.T) {\n \tassertContains(t, out, fmt.Sprintf(\"/backups/%s\", backupID))\n \tassertContains(t, out, \"Backups listed.\")\n \n-\tout = runSampleWithContext(ctx, t, listBackupOperations, dbName, \"failed to list backup operations\")\n+\tout = runBackupSampleWithoutContext(t, listBackupOperations, dbName, backupID, \"failed to list backup operations\")\n \tassertContains(t, out, fmt.Sprintf(\"on database %s\", dbName))\n+\tassertContains(t, out, fmt.Sprintf(\"copied from %s\", backupID))\n \n-\tout = runBackupSample(ctx, t, updateBackup, dbName, backupID, \"failed to update a backup\")\n+\tout = runBackupSampleWithoutContext(t, updateBackup, dbName, backupID, \"failed to update a backup\")\n \tassertContains(t, out, fmt.Sprintf(\"Updated backup %s\", backupID))\n \n \tout = runBackupSampleWithRetry(ctx, t, restoreBackup, restoreDBName, backupID, \"failed to restore a backup\", 10)",
        "comments": [],
        "commit_message": "Merge branch 'main' into dual-region",
        "commit_id": "d4c634f9eb372086477058533205fdf96f560b2c"
    },
    {
        "pr_title": "feat(storage): add sample for creating a dual-region bucket",
        "pr_number": 2498,
        "file_name": "spanner/spanner_snippets/spanner/spanner_list_backup_operations.go",
        "code_diff": "@@ -28,7 +28,13 @@\nimport (\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n-func listBackupOperations(ctx context.Context, w io.Writer, db string) error {\n+// listBackupOperations lists the backup operations that are pending or have completed/failed/cancelled within the last 7 days.\n+func listBackupOperations(w io.Writer, db string, backupId string) error {\n+\t// db := \"projects/my-project/instances/my-instance/databases/my-database\"\n+\t// backupID := \"my-backup\"\n+\n+\tctx := context.Background()\n+\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'main' into dual-region",
        "commit_id": "d4c634f9eb372086477058533205fdf96f560b2c"
    },
    {
        "pr_title": "feat(storage): add sample for creating a dual-region bucket",
        "pr_number": 2498,
        "file_name": "spanner/spanner_snippets/spanner/spanner_update_backup.go",
        "code_diff": "@@ -24,12 +24,20 @@\nimport (\n \t\"time\"\n \n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n-\tpbts \"github.com/golang/protobuf/ptypes\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n \t\"google.golang.org/genproto/protobuf/field_mask\"\n+\t\"google.golang.org/protobuf/types/known/timestamppb\"\n )\n \n-func updateBackup(ctx context.Context, w io.Writer, db, backupID string) error {\n+// updateBackup updates the expiration time of a pending or completed backup.\n+func updateBackup(w io.Writer, db string, backupID string) error {\n+\t// db := \"projects/my-project/instances/my-instance/databases/my-database\"\n+\t// backupID := \"my-backup\"\n+\n+\t// Add timeout to context.\n+\tctx, cancel := context.WithTimeout(context.Background(), time.Hour)\n+\tdefer cancel()\n+\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'main' into dual-region",
        "commit_id": "d4c634f9eb372086477058533205fdf96f560b2c"
    },
    {
        "pr_title": "feat(storage): add setting client endpoint sample",
        "pr_number": 2483,
        "file_name": "run/sigterm-handler/main.go",
        "code_diff": "@@ -27,6 +27,9 @@\nimport (\n \t\"time\"\n )\n \n+// Create channel to listen for signals.\n+var signalChan chan (os.Signal) = make(chan os.Signal, 1)\n+\n func main() {\n \t// Determine port for HTTP service.\n \tport := os.Getenv(\"PORT\")",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage2463",
        "commit_id": "c73eab98c8725e3b17e555ede739ead0f66b14a6"
    },
    {
        "pr_title": "feat(storage): add setting client endpoint sample",
        "pr_number": 2483,
        "file_name": "run/sigterm-handler/main.go",
        "code_diff": "@@ -40,8 +43,6 @@\nfunc main() {\n \t\tHandler: http.HandlerFunc(handler),\n \t}\n \n-\t// Create channel to listen for signals.\n-\tsignalChan := make(chan os.Signal, 1)\n \t// SIGINT handles Ctrl+C locally.\n \t// SIGTERM handles Cloud Run termination signal.\n \tsignal.Notify(signalChan, syscall.SIGINT, syscall.SIGTERM)",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage2463",
        "commit_id": "c73eab98c8725e3b17e555ede739ead0f66b14a6"
    },
    {
        "pr_title": "feat(storage): add setting client endpoint sample",
        "pr_number": 2483,
        "file_name": "run/testing/sigterm_handler.e2e_test.go",
        "code_diff": "@@ -35,13 +35,14 @@\nfunc TestSigtermHandlerService(t *testing.T) {\n \tdefer GetLogEntries(service, t)\n \tdefer service.Clean()\n \n-\trequestPath := \"/\"\n+\t// Explicitly send SIGTERM\n+\trequestPath := \"/?terminate=1\"\n \treq, err := service.NewRequest(\"GET\", requestPath)\n \tif err != nil {\n \t\tt.Fatalf(\"service.NewRequest: %v\", err)\n \t}\n \n-\tclient := http.Client{Timeout: 10 * time.Second}\n+\tclient := http.Client{Timeout: 30 * time.Second}\n \tresp, err := client.Do(req)\n \tif err != nil {\n \t\tt.Fatalf(\"client.Do: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'main' into storage2463",
        "commit_id": "c73eab98c8725e3b17e555ede739ead0f66b14a6"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "pubsublite/admin/create_subscription.go",
        "code_diff": "@@ -23,11 +23,13 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func createSubscription(w io.Writer, projectID, region, zone, topicID, subID string) error {\n+func createSubscription(w io.Writer, projectID, region, location, topicID, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n-\t// NOTE: topic and subscription must be in the same zone (i.e. \"us-central1-a\")\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n+\t// NOTE: topic and subscription must be in the same region/zone (e.g. \"us-central1-a\")\n \t// topicID := \"my-topic\"\n \t// subID := \"my-subscription\"\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-samples",
        "commit_id": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "pubsublite/admin/create_topic.go",
        "code_diff": "@@ -23,13 +23,14 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func createTopic(w io.Writer, projectID, region, zone, topicID, reservation string, regional bool) error {\n+func createTopic(w io.Writer, projectID, region, location, topicID, reservation string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\" // see https://cloud.google.com/pubsub/lite/docs/locations\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// topicID := \"my-topic\"\n \t// reservation := \"projects/my-project-id/reservations/my-reservation\"\n-\t// regional := \"true\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-samples",
        "commit_id": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "pubsublite/admin/create_topic.go",
        "code_diff": "@@ -39,12 +40,7 @@\nfunc createTopic(w io.Writer, projectID, region, zone, topicID, reservation stri\n \n \tconst gib = 1 << 30\n \n-\tvar topicPath string\n-\tif regional {\n-\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, region, topicID)\n-\t} else {\n-\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, zone, topicID)\n-\t}\n+\ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, location, topicID)\n \t// For ranges of fields in TopicConfig, see https://pkg.go.dev/cloud.google.com/go/pubsublite/#TopicConfig\n \ttopic, err := client.CreateTopic(ctx, pubsublite.TopicConfig{\n \t\tName:                       topicPath,",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-samples",
        "commit_id": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "pubsublite/admin/delete_subscription.go",
        "code_diff": "@@ -23,10 +23,12 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func deleteSubscription(w io.Writer, projectID, region, zone, subID string) error {\n+func deleteSubscription(w io.Writer, projectID, region, location, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// subID := \"my-subscription\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-samples",
        "commit_id": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "pubsublite/admin/get_subscription.go",
        "code_diff": "@@ -23,10 +23,12 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func getSubscription(w io.Writer, projectID, region, zone, subID string) error {\n+func getSubscription(w io.Writer, projectID, region, location, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// subID := \"my-subscription\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-samples",
        "commit_id": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "pubsublite/admin/get_topic.go",
        "code_diff": "@@ -23,10 +23,12 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func getTopic(w io.Writer, projectID, region, zone, topicID string, regional bool) error {\n+func getTopic(w io.Writer, projectID, region, location, topicID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// topicID := \"my-topic\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-samples",
        "commit_id": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "pubsublite/admin/list_subscriptions_in_project.go",
        "code_diff": "@@ -24,10 +24,12 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n-func listSubscriptionsInProject(w io.Writer, projectID, region, zone string) error {\n+func listSubscriptionsInProject(w io.Writer, projectID, region, location string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-samples",
        "commit_id": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "pubsublite/admin/list_subscriptions_in_topic.go",
        "code_diff": "@@ -24,10 +24,12 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n-func listSubscriptionsInTopic(w io.Writer, projectID, region, zone, topicID string) error {\n+func listSubscriptionsInTopic(w io.Writer, projectID, region, location, topicID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central\"\n \t// topicID := \"my-topic\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-samples",
        "commit_id": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -86,15 +86,22 @@\nfunc TestTopicAdmin(t *testing.T) {\n \ttestZone := randomZone()\n \n \ttopicID := resourcePrefix + uuid.NewString()\n-\ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \tt.Run(\"CreateTopic\", func(t *testing.T) {\n+\t\tctx := context.Background()\n+\t\treservationID = resourcePrefix + uuid.NewString()\n+\t\treservationPath = fmt.Sprintf(\"projects/%s/locations/%s/reservations/%s\", projNumber, testRegion, reservationID)\n+\t\tclient.CreateReservation(ctx, pubsublite.ReservationConfig{\n+\t\t\tName:               reservationPath,\n+\t\t\tThroughputCapacity: 4,\n+\t\t})\n+\n \t\tbuf := new(bytes.Buffer)\n-\t\terr := createTopic(buf, tc.ProjectID, testRegion, testZone, topicID, \"\", false)\n+\t\terr := createTopic(buf, tc.ProjectID, testRegion, testZone, topicID, reservationPath)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"createTopic: %v\", err)\n \t\t}\n \t\tgot := buf.String()\n-\t\twant := \"Created zonal topic\"\n+\t\twant := \"Created topic\"\n \t\tif !strings.Contains(got, want) {\n \t\t\tt.Fatalf(\"createTopic() mismatch: got: %s\\nwant: %s\", got, want)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-samples",
        "commit_id": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "pubsublite/admin/update_subscription.go",
        "code_diff": "@@ -23,10 +23,12 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func updateSubscription(w io.Writer, projectID, region, zone, subID string) error {\n+func updateSubscription(w io.Writer, projectID, region, location, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// subID := \"my-subscription\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-samples",
        "commit_id": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "pubsublite/admin/update_topic.go",
        "code_diff": "@@ -24,26 +24,22 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func updateTopic(w io.Writer, projectID, region, zone, topicID, reservation string, regional bool) error {\n+func updateTopic(w io.Writer, projectID, region, location, topicID, reservation string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// topicID := \"my-topic\"\n \t// reservation := \"projects/my-project-id/reservations/my-reservation\"\n-\t// regional := \"true\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"pubsublite.NewAdminClient: %v\", err)\n \t}\n \tdefer client.Close()\n \n-\tvar topicPath string\n-\tif regional {\n-\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, region, topicID)\n-\t} else {\n-\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, zone, topicID)\n-\t}\n+\ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, location, topicID)\n \t// For ranges of fields in TopicConfigToUpdate, see https://pkg.go.dev/cloud.google.com/go/pubsublite/#TopicConfigToUpdate\n \tconfig := pubsublite.TopicConfigToUpdate{\n \t\tName:                       topicPath,",
        "comments": [],
        "commit_message": "Merge branch 'main' into pg-samples",
        "commit_id": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(storage): add notification samples",
        "pr_number": 2446,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql.go",
        "code_diff": "@@ -12,11 +12,11 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Sample database-sql demonstrates connection to a Cloud SQL instance from App Engine\n-// standard. The application is a Golang version of the \"Tabs vs Spaces\" web\n-// app presented at Cloud Next '19 as seen in this video:\n+// Sample database-sql demonstrates connecting to a Cloud SQL instance.\n+// The application is a Go version of the \"Tabs vs Spaces\"\n+// web app presented at Google Cloud Next 2019 as seen in this video:\n // https://www.youtube.com/watch?v=qVgzP3PsXFw&t=1833s\n-package main\n+package cloudsql\n \n import (\n \t\"database/sql\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into pubsub-samples",
        "commit_id": "4b6bfb7bc813745fb40bef330abef3990583dae7"
    },
    {
        "pr_title": "feat(storage): add notification samples",
        "pr_number": 2446,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudsql\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into pubsub-samples",
        "commit_id": "4b6bfb7bc813745fb40bef330abef3990583dae7"
    },
    {
        "pr_title": "feat(cloudsql/sqlserver): update to v2 sample",
        "pr_number": 2436,
        "file_name": "cloudsql/postgres/database-sql/cloudsql.go",
        "code_diff": "@@ -176,18 +176,18 @@\nfunc mustConnect() *sql.DB {\n // configureConnectionPool sets database connection pool properties.\n // For more information, see https://golang.org/pkg/database/sql\n func configureConnectionPool(db *sql.DB) {\n-\t// [START cloud_sql_mysql_databasesql_limit]\n+\t// [START cloud_sql_postgres_databasesql_limit]\n \t// Set maximum number of connections in idle connection pool.\n \tdb.SetMaxIdleConns(5)\n \n \t// Set maximum number of open connections to the database.\n \tdb.SetMaxOpenConns(7)\n-\t// [END cloud_sql_mysql_databasesql_limit]\n+\t// [END cloud_sql_postgres_databasesql_limit]\n \n-\t// [START cloud_sql_mysql_databasesql_lifetime]\n+\t// [START cloud_sql_postgres_databasesql_lifetime]\n \t// Set Maximum time (in seconds) that a connection can remain open.\n \tdb.SetConnMaxLifetime(1800 * time.Second)\n-\t// [END cloud_sql_mysql_databasesql_lifetime]\n+\t// [END cloud_sql_postgres_databasesql_lifetime]\n }\n \n // Votes handles HTTP requests to alternatively show the voting app or to save a",
        "comments": [],
        "commit_message": "Merge branch 'main' into csql-v2-sqlserver",
        "commit_id": "cc4a6036f70102f27e2b4425bf9f9b532ba032ea"
    },
    {
        "pr_title": "fix(opencensus): trace exemplar example to show how to use attachments",
        "pr_number": 2402,
        "file_name": "opencensus/trace_exemplar.go",
        "code_diff": "@@ -19,15 +19,33 @@\npackage opencensus\n \n // [START monitoring_opencensus_configure_trace_exemplar]\n import (\n+\t\"fmt\"\n \t\"time\"\n \n \tgooglepb \"github.com/golang/protobuf/ptypes/timestamp\"\n \tdistributionpb \"google.golang.org/genproto/googleapis/api/distribution\"\n \tmonitoringpb \"google.golang.org/genproto/googleapis/monitoring/v3\"\n+\t\"google.golang.org/protobuf/types/known/anypb\"\n )\n \n-func createDataPointWithExemplar() *monitoringpb.Point {\n+// Generates metric TimeSeries points containing Exemplars with attached tracing span.\n+func createDataPointWithExemplar(projectID string) (*monitoringpb.Point, error) {\n+\t// projectID := \"my-cloud-project-id\"\n \tend := time.Now().Unix()\n+\ttraceId := \"0000000000000001\"\n+\tspanId := \"00000001\"\n+\tspanCtx, err := anypb.New(&monitoringpb.SpanContext{\n+\t\tSpanName: fmt.Sprintf(\"projects/%s/traces/%s/spans/%s\", projectID, traceId, spanId),\n+\t})\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tdroppedLabels, err := anypb.New(&monitoringpb.DroppedLabels{\n+\t\tLabel: map[string]string{\"Label\": \"Dropped\"},\n+\t})\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n \tdataPoint := &monitoringpb.Point{\n \t\tInterval: &monitoringpb.TimeInterval{\n \t\t\tStartTime: &googlepb.Timestamp{Seconds: end - 60},",
        "comments": [
            {
                "comment": "Please add a comment to this function: https://github.com/GoogleCloudPlatform/golang-samples/blob/main/CONTRIBUTING.md#comment-functions-and-packages",
                "position": null
            },
            {
                "comment": "Please supply example value for projectID: https://github.com/GoogleCloudPlatform/golang-samples/blob/main/CONTRIBUTING.md#function-arguments-for-snippets",
                "position": null
            },
            {
                "comment": "Please check the errors, can update function to return an error.",
                "position": null
            },
            {
                "comment": "Fixed.",
                "position": null
            },
            {
                "comment": "Fixed",
                "position": null
            }
        ],
        "commit_message": "fix: trace exemplar exemplar missing traces.\n\nTrace Exemplar example showed how to make exemplars, but not with attachments. This adds both the `DroppedLabels` attachment and the `SpanContext` attachment to demonstrate how to do trace-metric correlation.",
        "commit_id": "c989e7269bf29ee6fc4ede75df7d9f3fbf137f8c"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "compute/create_instance_from_template_test.go",
        "code_diff": "@@ -85,25 +85,8 @@\nfunc TestCreateInstanceFromTemplateSnippets(t *testing.T) {\n \t\tt.Fatalf(\"unable to create instance template: %v\", err)\n \t}\n \n-\tglobalOperationsClient, err := compute.NewGlobalOperationsRESTClient(ctx)\n-\tif err != nil {\n-\t\tt.Errorf(\"NewGlobalOperationsRESTClient: %v\", err)\n-\t}\n-\tdefer globalOperationsClient.Close()\n-\n-\tfor {\n-\t\twaitReq := &computepb.WaitGlobalOperationRequest{\n-\t\t\tOperation: op.Proto().GetName(),\n-\t\t\tProject:   tc.ProjectID,\n-\t\t}\n-\t\tglobalOp, err := globalOperationsClient.Wait(ctx, waitReq)\n-\t\tif err != nil {\n-\t\t\tt.Errorf(\"unable to wait for the operation: %v\", err)\n-\t\t}\n-\n-\t\tif *globalOp.Status.Enum() == computepb.Operation_DONE {\n-\t\t\tbreak\n-\t\t}\n+\tif err = op.Wait(ctx); err != nil {\n+\t\tt.Errorf(\"unable to wait for the operation: %v\", err)\n \t}\n \n \tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "compute/instance-templates/create-instance-templates/create_instance_templates_test.go",
        "code_diff": "@@ -113,20 +113,8 @@\nfunc TestCreateInstanceTemplatesSnippets(t *testing.T) {\n \t\tt.Errorf(\"unable to create instance: %v\", err)\n \t}\n \n-\tfor {\n-\t\twaitReq := &computepb.WaitZoneOperationRequest{\n-\t\t\tOperation: op.Proto().GetName(),\n-\t\t\tProject:   tc.ProjectID,\n-\t\t\tZone:      zone,\n-\t\t}\n-\t\tzoneOp, err := zoneOperationsClient.Wait(ctx, waitReq)\n-\t\tif err != nil {\n-\t\t\tt.Errorf(\"unable to wait for the operation: %v\", err)\n-\t\t}\n-\n-\t\tif *zoneOp.Status.Enum() == computepb.Operation_DONE {\n-\t\t\tbreak\n-\t\t}\n+\tif err = op.Wait(ctx); err != nil {\n+\t\tt.Errorf(\"unable to wait for the operation: %v\", err)\n \t}\n \n \tformattedInstanceName := fmt.Sprintf(\"projects/%s/zones/%s/instances/%s\", tc.ProjectID, zone, instanceName)",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "compute/instances/create-start-instance/create_instance_from_snapshot_test.go",
        "code_diff": "@@ -65,12 +65,6 @@\nfunc TestComputeCreateInstanceFromSnapshotSnippets(t *testing.T) {\n \t}\n \tdefer disksClient.Close()\n \n-\tzoneOperationsClient, err := compute.NewZoneOperationsRESTClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"NewZoneOperationsRESTClient: %v\", err)\n-\t}\n-\tdefer zoneOperationsClient.Close()\n-\n \tnewestDebianReq := &computepb.GetFromFamilyImageRequest{\n \t\tProject: \"debian-cloud\",\n \t\tFamily:  \"debian-11\",",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "compute/instances/create-start-instance/create_instance_from_snapshot_test.go",
        "code_diff": "@@ -106,7 +100,9 @@\nfunc TestComputeCreateInstanceFromSnapshotSnippets(t *testing.T) {\n \t\tt.Errorf(\"unable to create disk: %v\", err)\n \t}\n \n-\twaitZoneOp(ctx, tc.ProjectID, zone, *op)\n+\tif err = op.Wait(ctx); err != nil {\n+\t\tt.Errorf(\"unable to wait for the operation: %v\", err)\n+\t}\n \n \tdiskSnaphotReq := &computepb.CreateSnapshotDiskRequest{\n \t\tProject: tc.ProjectID,",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "compute/instances/create-start-instance/create_instance_from_snapshot_test.go",
        "code_diff": "@@ -122,7 +118,9 @@\nfunc TestComputeCreateInstanceFromSnapshotSnippets(t *testing.T) {\n \t\tt.Errorf(\"unable to create disk snapshot: %v\", err)\n \t}\n \n-\twaitZoneOp(ctx, tc.ProjectID, zone, *op)\n+\tif err = op.Wait(ctx); err != nil {\n+\t\tt.Errorf(\"unable to wait for the operation: %v\", err)\n+\t}\n \n \tdiskSnapshotLink := fmt.Sprintf(\"projects/%s/global/snapshots/%s\", tc.ProjectID, snapshotName)",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "compute/instances/create-start-instance/create_instance_from_snapshot_test.go",
        "code_diff": "@@ -166,7 +164,9 @@\nfunc TestComputeCreateInstanceFromSnapshotSnippets(t *testing.T) {\n \t\tt.Errorf(\"unable to delete disk snapshot: %v\", err)\n \t}\n \n-\twaitZoneOp(ctx, tc.ProjectID, zone, *op)\n+\tif err = op.Wait(ctx); err != nil {\n+\t\tt.Errorf(\"unable to wait for the operation: %v\", err)\n+\t}\n \n \tdeleteDiskReq := &computepb.DeleteDiskRequest{\n \t\tProject: tc.ProjectID,",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "compute/instances/create-start-instance/utils_test.go",
        "code_diff": "@@ -21,32 +21,6 @@\nimport (\n \tcomputepb \"google.golang.org/genproto/googleapis/cloud/compute/v1\"\n )\n \n-func waitZoneOp(ctx context.Context, projectId, zone string, op compute.Operation) error {\n-\tzoneOperationsClient, err := compute.NewZoneOperationsRESTClient(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tdefer zoneOperationsClient.Close()\n-\n-\tfor {\n-\t\twaitReq := &computepb.WaitZoneOperationRequest{\n-\t\t\tOperation: op.Proto().GetName(),\n-\t\t\tProject:   projectId,\n-\t\t\tZone:      zone,\n-\t\t}\n-\t\tzoneOp, err := zoneOperationsClient.Wait(ctx, waitReq)\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\n-\t\tif *zoneOp.Status.Enum() == computepb.Operation_DONE {\n-\t\t\tbreak\n-\t\t}\n-\t}\n-\n-\treturn nil\n-}\n-\n func deleteInstance(ctx context.Context, projectId, zone, instanceName string) error {\n \tinstancesClient, err := compute.NewInstancesRESTClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "pubsublite/admin/create_topic.go",
        "code_diff": "@@ -23,11 +23,13 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func createTopic(w io.Writer, projectID, region, zone, topicID string) error {\n+func createTopic(w io.Writer, projectID, region, zone, topicID, reservation string, regional bool) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\" // see https://cloud.google.com/pubsub/lite/docs/locations\n \t// zone := \"us-central1-a\"\n \t// topicID := \"my-topic\"\n+\t// reservation := \"projects/my-project-id/reservations/my-reservation\"\n+\t// regional := \"true\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "pubsublite/admin/get_topic.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func getTopic(w io.Writer, projectID, region, zone, topicID string) error {\n+func getTopic(w io.Writer, projectID, region, zone, topicID string, regional bool) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n \t// zone := \"us-central1-a\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -35,14 +35,16 @@\nimport (\n \n const (\n \tresourcePrefix = \"admin-test-\"\n-\ttestRegion     = \"us-central1\"\n+\ttestRegion     = \"us-west1\"\n )\n \n var (\n-\tsupportedZones = []string{\"us-central1-a\", \"us-central1-b\", \"us-central1-c\"}\n+\tsupportedZones = []string{\"us-west1-a\", \"us-west1-c\"}\n \n-\tonce       sync.Once\n-\tprojNumber string\n+\tonce            sync.Once\n+\tprojNumber      string\n+\treservationID   string\n+\treservationPath string\n )\n \n func setupAdmin(t *testing.T) *pubsublite.AdminClient {",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -70,7 +72,7 @@\nfunc setupAdmin(t *testing.T) *pubsublite.AdminClient {\n \n \t\tprojNumber = strconv.FormatInt(project.ProjectNumber, 10)\n \n-\t\tpsltest.Cleanup(t, client, projNumber, resourcePrefix, supportedZones)\n+\t\tpsltest.Cleanup(t, client, projNumber, testRegion, resourcePrefix, supportedZones)\n \t})\n \n \treturn client",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -87,21 +89,21 @@\nfunc TestTopicAdmin(t *testing.T) {\n \ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \tt.Run(\"CreateTopic\", func(t *testing.T) {\n \t\tbuf := new(bytes.Buffer)\n-\t\terr := createTopic(buf, tc.ProjectID, testRegion, testZone, topicID)\n+\t\terr := createTopic(buf, tc.ProjectID, testRegion, testZone, topicID, \"\", false)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"createTopic: %v\", err)\n \t\t}\n \t\tgot := buf.String()\n-\t\twant := fmt.Sprintf(\"Created topic: %s\\n\", topicPath)\n-\t\tif diff := cmp.Diff(want, got); diff != \"\" {\n-\t\t\tt.Fatalf(\"createTopic() mismatch: -want, +got:\\n%s\", diff)\n+\t\twant := \"Created zonal topic\"\n+\t\tif !strings.Contains(got, want) {\n+\t\t\tt.Fatalf(\"createTopic() mismatch: got: %s\\nwant: %s\", got, want)\n \t\t}\n \t})\n \n \tt.Run(\"GetTopic\", func(t *testing.T) {\n \t\ttestutil.Retry(t, 3, 5*time.Second, func(r *testutil.R) {\n \t\t\tbuf := new(bytes.Buffer)\n-\t\t\terr := getTopic(buf, tc.ProjectID, testRegion, testZone, topicID)\n+\t\t\terr := getTopic(buf, tc.ProjectID, testRegion, testZone, topicID, false)\n \t\t\tif err != nil {\n \t\t\t\tr.Errorf(\"getTopic: %v\", err)\n \t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "pubsublite/admin/update_topic.go",
        "code_diff": "@@ -24,19 +24,26 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func updateTopic(w io.Writer, projectID, region, zone, topicID string) error {\n+func updateTopic(w io.Writer, projectID, region, zone, topicID, reservation string, regional bool) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n \t// zone := \"us-central1-a\"\n \t// topicID := \"my-topic\"\n+\t// reservation := \"projects/my-project-id/reservations/my-reservation\"\n+\t// regional := \"true\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"pubsublite.NewAdminClient: %v\", err)\n \t}\n \tdefer client.Close()\n \n-\ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, zone, topicID)\n+\tvar topicPath string\n+\tif regional {\n+\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, region, topicID)\n+\t} else {\n+\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, zone, topicID)\n+\t}\n \t// For ranges of fields in TopicConfigToUpdate, see https://pkg.go.dev/cloud.google.com/go/pubsublite/#TopicConfigToUpdate\n \tconfig := pubsublite.TopicConfigToUpdate{\n \t\tName:                       topicPath,",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -28,11 +28,12 @@\nimport (\n // Cleanup deletes all previous test topics/subscriptions from previous test\n // runs. This prevents previous test failures from building up resources that\n // count against quota.\n-func Cleanup(t *testing.T, client *pubsublite.AdminClient, proj, namePrefix string, zones []string) {\n+func Cleanup(t *testing.T, client *pubsublite.AdminClient, proj, region, namePrefix string, zones []string) {\n \tctx := context.Background()\n \n \ttopicSubstring := \"/topics/\" + namePrefix\n \tsubscriptionSubstring := \"/subscriptions/\" + namePrefix\n+\treservationSubstring := \"/reservations/\" + namePrefix\n \n \tfor _, zone := range zones {\n \t\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", proj, zone)",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "docs(bigquery): add additional samples",
        "pr_number": 2371,
        "file_name": "functions/functionsv2/helloauditlog/hello_auditlog.go",
        "code_diff": "@@ -22,9 +22,14 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \t\"github.com/cloudevents/sdk-go/v2/event\"\n )\n \n+func init() {\n+\tfunctions.CloudEvent(\"HelloAuditLog\", helloAuditLog)\n+}\n+\n // AuditLogEntry represents a LogEntry as described at\n // https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\n type AuditLogEntry struct {",
        "comments": [],
        "commit_message": "Merge branch 'main' into sample-trample",
        "commit_id": "59515864b323b2e093d682a1509ae848158e5c37"
    },
    {
        "pr_title": "docs(bigquery): add additional samples",
        "pr_number": 2371,
        "file_name": "functions/functionsv2/hellopubsub/hello_pubsub.go",
        "code_diff": "@@ -22,9 +22,14 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \t\"github.com/cloudevents/sdk-go/v2/event\"\n )\n \n+func init() {\n+\tfunctions.CloudEvent(\"HelloPubSub\", helloPubSub)\n+}\n+\n // MessagePublishedData contains the full Pub/Sub message\n // See the documentation for more details:\n // https://cloud.google.com/eventarc/docs/cloudevents#pubsub",
        "comments": [],
        "commit_message": "Merge branch 'main' into sample-trample",
        "commit_id": "59515864b323b2e093d682a1509ae848158e5c37"
    },
    {
        "pr_title": "docs(bigquery): add additional samples",
        "pr_number": 2371,
        "file_name": "functions/functionsv2/hellostorage/hello_storage.go",
        "code_diff": "@@ -23,9 +23,14 @@\nimport (\n \t\"log\"\n \t\"time\"\n \n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \t\"github.com/cloudevents/sdk-go/v2/event\"\n )\n \n+func init() {\n+\tfunctions.CloudEvent(\"HelloStorage\", helloStorage)\n+}\n+\n // StorageObjectData contains metadata of the Cloud Storage object.\n type StorageObjectData struct {\n \tBucket         string    `json:\"bucket,omitempty\"`",
        "comments": [],
        "commit_message": "Merge branch 'main' into sample-trample",
        "commit_id": "59515864b323b2e093d682a1509ae848158e5c37"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_from_ad_hoc.go",
        "code_diff": "@@ -47,7 +47,7 @@\nfunc createJobFromAdHoc(w io.Writer, projectID string, location string, inputURI\n \t\t\tJobConfig: &transcoderpb.Job_Config{\n \t\t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_from_ad_hoc.go",
        "code_diff": "@@ -62,7 +62,7 @@\nfunc createJobFromAdHoc(w io.Writer, projectID string, location string, inputURI\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream1\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_from_ad_hoc.go",
        "code_diff": "@@ -77,7 +77,7 @@\nfunc createJobFromAdHoc(w io.Writer, projectID string, location string, inputURI\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_template.go",
        "code_diff": "@@ -44,7 +44,7 @@\nfunc createJobTemplate(w io.Writer, projectID string, location string, templateI\n \t\tJobTemplate: &transcoderpb.JobTemplate{\n \t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t{\n \t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_template.go",
        "code_diff": "@@ -59,7 +59,7 @@\nfunc createJobTemplate(w io.Writer, projectID string, location string, templateI\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n-\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t{\n \t\t\t\t\t\tKey: \"video_stream1\",\n \t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_template.go",
        "code_diff": "@@ -74,7 +74,7 @@\nfunc createJobTemplate(w io.Writer, projectID string, location string, templateI\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n-\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t{\n \t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_animated_overlay.go",
        "code_diff": "@@ -51,7 +51,7 @@\nfunc createJobWithAnimatedOverlay(w io.Writer, projectID string, location string\n \t\t\tJobConfig: &transcoderpb.Job_Config{\n \t\t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_animated_overlay.go",
        "code_diff": "@@ -66,7 +66,7 @@\nfunc createJobWithAnimatedOverlay(w io.Writer, projectID string, location string\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_animated_overlay.go",
        "code_diff": "@@ -77,14 +77,14 @@\nfunc createJobWithAnimatedOverlay(w io.Writer, projectID string, location string\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tMuxStreams: []*transcoderpb.MuxStream{\n-\t\t\t\t\t\t&transcoderpb.MuxStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey:               \"sd\",\n \t\t\t\t\t\t\tContainer:         \"mp4\",\n \t\t\t\t\t\t\tElementaryStreams: []string{\"video_stream0\", \"audio_stream0\"},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tOverlays: []*transcoderpb.Overlay{\n-\t\t\t\t\t\t&transcoderpb.Overlay{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tImage: &transcoderpb.Overlay_Image{\n \t\t\t\t\t\t\t\tUri: overlayImageURI,\n \t\t\t\t\t\t\t\tResolution: &transcoderpb.Overlay_NormalizedCoordinate{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_animated_overlay.go",
        "code_diff": "@@ -94,7 +94,7 @@\nfunc createJobWithAnimatedOverlay(w io.Writer, projectID string, location string\n \t\t\t\t\t\t\t\tAlpha: 1,\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t\tAnimations: []*transcoderpb.Overlay_Animation{\n-\t\t\t\t\t\t\t\t&transcoderpb.Overlay_Animation{\n+\t\t\t\t\t\t\t\t{\n \t\t\t\t\t\t\t\t\tAnimationType: &transcoderpb.Overlay_Animation_AnimationFade{\n \t\t\t\t\t\t\t\t\t\tAnimationFade: &transcoderpb.Overlay_AnimationFade{\n \t\t\t\t\t\t\t\t\t\t\tFadeType: transcoderpb.Overlay_FADE_IN,",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_periodic_images_spritesheet.go",
        "code_diff": "@@ -49,7 +49,7 @@\nfunc createJobWithPeriodicImagesSpritesheet(w io.Writer, projectID string, locat\n \t\t\tJobConfig: &transcoderpb.Job_Config{\n \t\t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_periodic_images_spritesheet.go",
        "code_diff": "@@ -64,7 +64,7 @@\nfunc createJobWithPeriodicImagesSpritesheet(w io.Writer, projectID string, locat\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_periodic_images_spritesheet.go",
        "code_diff": "@@ -75,14 +75,14 @@\nfunc createJobWithPeriodicImagesSpritesheet(w io.Writer, projectID string, locat\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tMuxStreams: []*transcoderpb.MuxStream{\n-\t\t\t\t\t\t&transcoderpb.MuxStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey:               \"sd\",\n \t\t\t\t\t\t\tContainer:         \"mp4\",\n \t\t\t\t\t\t\tElementaryStreams: []string{\"video_stream0\", \"audio_stream0\"},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tSpriteSheets: []*transcoderpb.SpriteSheet{\n-\t\t\t\t\t\t&transcoderpb.SpriteSheet{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tFilePrefix:         \"small-sprite-sheet\",\n \t\t\t\t\t\t\tSpriteWidthPixels:  64,\n \t\t\t\t\t\t\tSpriteHeightPixels: 32,",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_set_number_images_spritesheet.go",
        "code_diff": "@@ -46,7 +46,7 @@\nfunc createJobWithSetNumberImagesSpritesheet(w io.Writer, projectID string, loca\n \t\t\tJobConfig: &transcoderpb.Job_Config{\n \t\t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_set_number_images_spritesheet.go",
        "code_diff": "@@ -61,7 +61,7 @@\nfunc createJobWithSetNumberImagesSpritesheet(w io.Writer, projectID string, loca\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_set_number_images_spritesheet.go",
        "code_diff": "@@ -72,14 +72,14 @@\nfunc createJobWithSetNumberImagesSpritesheet(w io.Writer, projectID string, loca\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tMuxStreams: []*transcoderpb.MuxStream{\n-\t\t\t\t\t\t&transcoderpb.MuxStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey:               \"sd\",\n \t\t\t\t\t\t\tContainer:         \"mp4\",\n \t\t\t\t\t\t\tElementaryStreams: []string{\"video_stream0\", \"audio_stream0\"},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tSpriteSheets: []*transcoderpb.SpriteSheet{\n-\t\t\t\t\t\t&transcoderpb.SpriteSheet{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tFilePrefix:         \"small-sprite-sheet\",\n \t\t\t\t\t\t\tSpriteWidthPixels:  64,\n \t\t\t\t\t\t\tSpriteHeightPixels: 32,",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_static_overlay.go",
        "code_diff": "@@ -51,7 +51,7 @@\nfunc createJobWithStaticOverlay(w io.Writer, projectID string, location string,\n \t\t\tJobConfig: &transcoderpb.Job_Config{\n \t\t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_static_overlay.go",
        "code_diff": "@@ -66,7 +66,7 @@\nfunc createJobWithStaticOverlay(w io.Writer, projectID string, location string,\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_static_overlay.go",
        "code_diff": "@@ -77,14 +77,14 @@\nfunc createJobWithStaticOverlay(w io.Writer, projectID string, location string,\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tMuxStreams: []*transcoderpb.MuxStream{\n-\t\t\t\t\t\t&transcoderpb.MuxStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey:               \"sd\",\n \t\t\t\t\t\t\tContainer:         \"mp4\",\n \t\t\t\t\t\t\tElementaryStreams: []string{\"video_stream0\", \"audio_stream0\"},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tOverlays: []*transcoderpb.Overlay{\n-\t\t\t\t\t\t&transcoderpb.Overlay{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tImage: &transcoderpb.Overlay_Image{\n \t\t\t\t\t\t\t\tUri: overlayImageURI,\n \t\t\t\t\t\t\t\tResolution: &transcoderpb.Overlay_NormalizedCoordinate{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "media/transcoder/create_job_with_static_overlay.go",
        "code_diff": "@@ -94,7 +94,7 @@\nfunc createJobWithStaticOverlay(w io.Writer, projectID string, location string,\n \t\t\t\t\t\t\t\tAlpha: 1,\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t\tAnimations: []*transcoderpb.Overlay_Animation{\n-\t\t\t\t\t\t\t\t&transcoderpb.Overlay_Animation{\n+\t\t\t\t\t\t\t\t{\n \t\t\t\t\t\t\t\t\tAnimationType: &transcoderpb.Overlay_Animation_AnimationStatic{\n \t\t\t\t\t\t\t\t\t\tAnimationStatic: &transcoderpb.Overlay_AnimationStatic{\n \t\t\t\t\t\t\t\t\t\t\tXy: &transcoderpb.Overlay_NormalizedCoordinate{",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "samples(compute): add create instances compute samples",
        "pr_number": 2363,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -27,7 +27,6 @@\nimport (\n )\n \n func TestDetect(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2349\")\n \ttestutil.SystemTest(t)\n \n \ttests := []struct {",
        "comments": [],
        "commit_message": "Merge branch 'main' into create-start-instances",
        "commit_id": "b8665a91a6d7f7f04c353a10d6a47f7d9d4d9ca6"
    },
    {
        "pr_title": "feat(compute): add create template samples",
        "pr_number": 2352,
        "file_name": "compute/instance-templates/create-instance-templates/create_instance_templates_test.go",
        "code_diff": "@@ -47,13 +47,13 @@\nfunc TestCreateInstanceTemplatesSnippets(t *testing.T) {\n \n \tinstancesClient, err := compute.NewInstancesRESTClient(ctx)\n \tif err != nil {\n-\t\tt.Errorf(\"NewInstancesRESTClient: %v\", err)\n+\t\tt.Fatalf(\"NewInstancesRESTClient: %v\", err)\n \t}\n \tdefer instancesClient.Close()\n \n \tzoneOperationsClient, err := compute.NewZoneOperationsRESTClient(ctx)\n \tif err != nil {\n-\t\tt.Errorf(\"NewZoneOperationsRESTClient: %v\", err)\n+\t\tt.Fatalf(\"NewZoneOperationsRESTClient: %v\", err)\n \t}\n \tdefer zoneOperationsClient.Close()",
        "comments": [
            {
                "comment": "nit: I think many(or all?) of these should be t.Fatalf. This test in others seem sequential so it does not make sense to keep running the test if you can't create the client for instance. ",
                "position": null
            },
            {
                "comment": "For clients creating agreed.",
                "position": null
            }
        ],
        "commit_message": "review fixes",
        "commit_id": "b535cb8f61e9d94e1d4912178b22a041a65ebded"
    },
    {
        "pr_title": "samples(storage): Upload file download file into memory",
        "pr_number": 2327,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \t\"net/http\"\n \t\"net/http/httputil\"\n \t\"os\"\n+\t\"path/filepath\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [
            {
                "comment": "For safety, I would create a tempdir and then have the test write the file to that directory. Use a defer statement for cleanup. See https://pkg.go.dev/io/ioutil#TempDir (the example there should be helpful).",
                "position": null
            }
        ],
        "commit_message": "responded to PR comments",
        "commit_id": "e6c57ebec0a731fded6565ed4060a135b258b1cf"
    },
    {
        "pr_title": "samples(storage): Upload file download file into memory",
        "pr_number": 2327,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -204,7 +205,12 @@\nfunc TestObjects(t *testing.T) {\n \t})\n \n \tt.Run(\"downloadFile\", func(t *testing.T) {\n-\t\tdestination := \"fileDownloadDestination.txt\"\n+\t\tdir, err := ioutil.TempDir(\"\", \"downloadFileTestTempDir\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"ioutil.TempDir: %v\", err)\n+\t\t}\n+\t\tdefer os.RemoveAll(dir) // clean up\n+\t\tdestination := filepath.Join(dir, \"fileDownloadDestination.txt\")\n \t\terr = downloadFile(ioutil.Discard, bucket, object1, destination)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"downloadFile: %v\", err)",
        "comments": [
            {
                "comment": "For safety, I would create a tempdir and then have the test write the file to that directory. Use a defer statement for cleanup. See https://pkg.go.dev/io/ioutil#TempDir (the example there should be helpful).",
                "position": null
            }
        ],
        "commit_message": "responded to PR comments",
        "commit_id": "e6c57ebec0a731fded6565ed4060a135b258b1cf"
    },
    {
        "pr_title": "feat(functions): New v2 sample for GCE labeling on new instance creation",
        "pr_number": 2320,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"log\"\n \t\"os\"\n \t\"regexp\"\n \t\"strconv\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into gce-labeler",
        "commit_id": "018248cceaa523a9c95f5e7f260fcb0f19d5ce7a"
    },
    {
        "pr_title": "feat(functions): New v2 sample for GCE labeling on new instance creation",
        "pr_number": 2320,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -52,7 +53,12 @@\nvar (\n \n func initTest(t *testing.T, id string) (instName, dbName string, cleanup func()) {\n \tprojectID := getSampleProjectId(t)\n-\tinstName, cleanup = createTestInstance(t, projectID, \"regional-us-central1\")\n+\tconfigName := getSamplesInstanceConfig()\n+\tif configName == \"\" {\n+\t\tconfigName = \"regional-us-central1\"\n+\t}\n+\tlog.Printf(\"Running test by using the instance config: %s\\n\", configName)\n+\tinstName, cleanup = createTestInstance(t, projectID, configName)\n \tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n \tdbName = fmt.Sprintf(\"%s/databases/%s\", instName, dbID)",
        "comments": [],
        "commit_message": "Merge branch 'main' into gce-labeler",
        "commit_id": "018248cceaa523a9c95f5e7f260fcb0f19d5ce7a"
    },
    {
        "pr_title": "feat(functions): New v2 sample for GCE labeling on new instance creation",
        "pr_number": 2320,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -120,7 +126,6 @@\nfunc runCreateInstanceSample(t *testing.T, f instanceSampleFunc) {\n }\n \n func TestSample(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2143\")\n \t_ = testutil.SystemTest(t)\n \tt.Parallel()",
        "comments": [],
        "commit_message": "Merge branch 'main' into gce-labeler",
        "commit_id": "018248cceaa523a9c95f5e7f260fcb0f19d5ce7a"
    },
    {
        "pr_title": "feat(functions): New v2 sample for GCE labeling on new instance creation",
        "pr_number": 2320,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -365,7 +370,6 @@\nfunc TestSample(t *testing.T) {\n }\n \n func TestBackupSample(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2143\")\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip(\"GOLANG_SAMPLES_E2E_TEST not set\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into gce-labeler",
        "commit_id": "018248cceaa523a9c95f5e7f260fcb0f19d5ce7a"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage table\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"io/ioutil\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -94,6 +95,9 @@\nfunc TestTables(t *testing.T) {\n \t}\n \n \ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n+\tif err != nil {\n+\t\tt.Fatalf(\"couldn't generate unique table id: %v\", err)\n+\t}\n \tif err := createTableFromTemplateTable(\"bigquery-public-data\", \"samples\", \"shakespeare\", tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"createTableFromTemplateTable(%q %q): %v\", testDatasetID, testTableID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -106,13 +110,24 @@\nfunc TestTables(t *testing.T) {\n \t\tt.Fatalf(\"createTablePartitioned(%q %q): %v\", testDatasetID, testTableID, err)\n \t}\n \n+\ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n+\tif err != nil {\n+\t\tt.Fatalf(\"couldn't generate unique table id: %v\", err)\n+\t}\n+\tif err := createTableRangePartitioned(tc.ProjectID, testDatasetID, testTableID); err != nil {\n+\t\tt.Fatalf(\"createTableRangePartitioned(%q %q): %v\", testDatasetID, testTableID, err)\n+\t}\n+\n \ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n \tif err != nil {\n \t\tt.Fatalf(\"couldn't generate unique table id: %v\", err)\n \t}\n \tif err := createTableClustered(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"createTableClustered(%q %q): %v\", testDatasetID, testTableID, err)\n \t}\n+\tif err := updateIAMPolicy(tc.ProjectID, testDatasetID, testTableID); err != nil {\n+\t\tt.Fatalf(\"updateIAMPolicy(%q %q): %v\", testDatasetID, testTableID, err)\n+\t}\n \n \ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -158,6 +173,9 @@\nfunc TestTables(t *testing.T) {\n \n \t// Change tables to avoid hitting metadata update limits in a short period.\n \ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n+\tif err != nil {\n+\t\tt.Fatalf(\"couldn't generate unique table id: %v\", err)\n+\t}\n \tif err := createTableExplicitSchema(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"createTableExplicitSchema(%q %q): %v\", testDatasetID, testTableID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql.go",
        "code_diff": "@@ -27,6 +27,7 @@\nimport (\n \t\"net/http\"\n \t\"os\"\n \t\"strconv\"\n+\t\"strings\"\n \t\"time\"\n \n \t_ \"github.com/denisenkom/go-mssqldb\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "compute/set_usage_export_bucket.go",
        "code_diff": "@@ -25,7 +25,8 @@\nimport (\n \t\"google.golang.org/protobuf/proto\"\n )\n \n-// setUsageExportBucket sets the Compute Engine usage export bucket for the Cloud project. This sample presents how to interpret the default value for the report name prefix parameter.\n+// setUsageExportBucket sets the Compute Engine usage export bucket for the Cloud project.\n+// This sample presents how to interpret the default value for the report name prefix parameter.\n func setUsageExportBucket(w io.Writer, projectID, bucketName, reportNamePrefix string) error {\n \t// projectID := \"your_project_id\"\n \t// bucketName := \"your_bucket_name\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "functions/functionsv2/helloauditlog/hello_auditlog.go",
        "code_diff": "@@ -22,9 +22,14 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \t\"github.com/cloudevents/sdk-go/v2/event\"\n )\n \n+func init() {\n+\tfunctions.CloudEvent(\"HelloAuditLog\", helloAuditLog)\n+}\n+\n // AuditLogEntry represents a LogEntry as described at\n // https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\n type AuditLogEntry struct {",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "functions/functionsv2/hellopubsub/hello_pubsub.go",
        "code_diff": "@@ -22,9 +22,14 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \t\"github.com/cloudevents/sdk-go/v2/event\"\n )\n \n+func init() {\n+\tfunctions.CloudEvent(\"HelloPubSub\", helloPubSub)\n+}\n+\n // MessagePublishedData contains the full Pub/Sub message\n // See the documentation for more details:\n // https://cloud.google.com/eventarc/docs/cloudevents#pubsub",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "functions/functionsv2/hellostorage/hello_storage.go",
        "code_diff": "@@ -23,9 +23,14 @@\nimport (\n \t\"log\"\n \t\"time\"\n \n+\t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \t\"github.com/cloudevents/sdk-go/v2/event\"\n )\n \n+func init() {\n+\tfunctions.CloudEvent(\"HelloStorage\", helloStorage)\n+}\n+\n // StorageObjectData contains metadata of the Cloud Storage object.\n type StorageObjectData struct {\n \tBucket         string    `json:\"bucket,omitempty\"`",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_from_ad_hoc.go",
        "code_diff": "@@ -47,7 +47,7 @@\nfunc createJobFromAdHoc(w io.Writer, projectID string, location string, inputURI\n \t\t\tJobConfig: &transcoderpb.Job_Config{\n \t\t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_from_ad_hoc.go",
        "code_diff": "@@ -62,7 +62,7 @@\nfunc createJobFromAdHoc(w io.Writer, projectID string, location string, inputURI\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream1\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_from_ad_hoc.go",
        "code_diff": "@@ -77,7 +77,7 @@\nfunc createJobFromAdHoc(w io.Writer, projectID string, location string, inputURI\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_template.go",
        "code_diff": "@@ -44,7 +44,7 @@\nfunc createJobTemplate(w io.Writer, projectID string, location string, templateI\n \t\tJobTemplate: &transcoderpb.JobTemplate{\n \t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t{\n \t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_template.go",
        "code_diff": "@@ -59,7 +59,7 @@\nfunc createJobTemplate(w io.Writer, projectID string, location string, templateI\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n-\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t{\n \t\t\t\t\t\tKey: \"video_stream1\",\n \t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_template.go",
        "code_diff": "@@ -74,7 +74,7 @@\nfunc createJobTemplate(w io.Writer, projectID string, location string, templateI\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n-\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t{\n \t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_animated_overlay.go",
        "code_diff": "@@ -51,7 +51,7 @@\nfunc createJobWithAnimatedOverlay(w io.Writer, projectID string, location string\n \t\t\tJobConfig: &transcoderpb.Job_Config{\n \t\t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_animated_overlay.go",
        "code_diff": "@@ -66,7 +66,7 @@\nfunc createJobWithAnimatedOverlay(w io.Writer, projectID string, location string\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_animated_overlay.go",
        "code_diff": "@@ -77,14 +77,14 @@\nfunc createJobWithAnimatedOverlay(w io.Writer, projectID string, location string\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tMuxStreams: []*transcoderpb.MuxStream{\n-\t\t\t\t\t\t&transcoderpb.MuxStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey:               \"sd\",\n \t\t\t\t\t\t\tContainer:         \"mp4\",\n \t\t\t\t\t\t\tElementaryStreams: []string{\"video_stream0\", \"audio_stream0\"},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tOverlays: []*transcoderpb.Overlay{\n-\t\t\t\t\t\t&transcoderpb.Overlay{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tImage: &transcoderpb.Overlay_Image{\n \t\t\t\t\t\t\t\tUri: overlayImageURI,\n \t\t\t\t\t\t\t\tResolution: &transcoderpb.Overlay_NormalizedCoordinate{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_animated_overlay.go",
        "code_diff": "@@ -94,7 +94,7 @@\nfunc createJobWithAnimatedOverlay(w io.Writer, projectID string, location string\n \t\t\t\t\t\t\t\tAlpha: 1,\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t\tAnimations: []*transcoderpb.Overlay_Animation{\n-\t\t\t\t\t\t\t\t&transcoderpb.Overlay_Animation{\n+\t\t\t\t\t\t\t\t{\n \t\t\t\t\t\t\t\t\tAnimationType: &transcoderpb.Overlay_Animation_AnimationFade{\n \t\t\t\t\t\t\t\t\t\tAnimationFade: &transcoderpb.Overlay_AnimationFade{\n \t\t\t\t\t\t\t\t\t\t\tFadeType: transcoderpb.Overlay_FADE_IN,",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_periodic_images_spritesheet.go",
        "code_diff": "@@ -49,7 +49,7 @@\nfunc createJobWithPeriodicImagesSpritesheet(w io.Writer, projectID string, locat\n \t\t\tJobConfig: &transcoderpb.Job_Config{\n \t\t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_periodic_images_spritesheet.go",
        "code_diff": "@@ -64,7 +64,7 @@\nfunc createJobWithPeriodicImagesSpritesheet(w io.Writer, projectID string, locat\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_periodic_images_spritesheet.go",
        "code_diff": "@@ -75,14 +75,14 @@\nfunc createJobWithPeriodicImagesSpritesheet(w io.Writer, projectID string, locat\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tMuxStreams: []*transcoderpb.MuxStream{\n-\t\t\t\t\t\t&transcoderpb.MuxStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey:               \"sd\",\n \t\t\t\t\t\t\tContainer:         \"mp4\",\n \t\t\t\t\t\t\tElementaryStreams: []string{\"video_stream0\", \"audio_stream0\"},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tSpriteSheets: []*transcoderpb.SpriteSheet{\n-\t\t\t\t\t\t&transcoderpb.SpriteSheet{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tFilePrefix:         \"small-sprite-sheet\",\n \t\t\t\t\t\t\tSpriteWidthPixels:  64,\n \t\t\t\t\t\t\tSpriteHeightPixels: 32,",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_set_number_images_spritesheet.go",
        "code_diff": "@@ -46,7 +46,7 @@\nfunc createJobWithSetNumberImagesSpritesheet(w io.Writer, projectID string, loca\n \t\t\tJobConfig: &transcoderpb.Job_Config{\n \t\t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_set_number_images_spritesheet.go",
        "code_diff": "@@ -61,7 +61,7 @@\nfunc createJobWithSetNumberImagesSpritesheet(w io.Writer, projectID string, loca\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_set_number_images_spritesheet.go",
        "code_diff": "@@ -72,14 +72,14 @@\nfunc createJobWithSetNumberImagesSpritesheet(w io.Writer, projectID string, loca\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tMuxStreams: []*transcoderpb.MuxStream{\n-\t\t\t\t\t\t&transcoderpb.MuxStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey:               \"sd\",\n \t\t\t\t\t\t\tContainer:         \"mp4\",\n \t\t\t\t\t\t\tElementaryStreams: []string{\"video_stream0\", \"audio_stream0\"},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tSpriteSheets: []*transcoderpb.SpriteSheet{\n-\t\t\t\t\t\t&transcoderpb.SpriteSheet{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tFilePrefix:         \"small-sprite-sheet\",\n \t\t\t\t\t\t\tSpriteWidthPixels:  64,\n \t\t\t\t\t\t\tSpriteHeightPixels: 32,",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_static_overlay.go",
        "code_diff": "@@ -51,7 +51,7 @@\nfunc createJobWithStaticOverlay(w io.Writer, projectID string, location string,\n \t\t\tJobConfig: &transcoderpb.Job_Config{\n \t\t\t\tConfig: &transcoderpb.JobConfig{\n \t\t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"video_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n \t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_static_overlay.go",
        "code_diff": "@@ -66,7 +66,7 @@\nfunc createJobWithStaticOverlay(w io.Writer, projectID string, location string,\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},\n-\t\t\t\t\t\t&transcoderpb.ElementaryStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey: \"audio_stream0\",\n \t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n \t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_static_overlay.go",
        "code_diff": "@@ -77,14 +77,14 @@\nfunc createJobWithStaticOverlay(w io.Writer, projectID string, location string,\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tMuxStreams: []*transcoderpb.MuxStream{\n-\t\t\t\t\t\t&transcoderpb.MuxStream{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey:               \"sd\",\n \t\t\t\t\t\t\tContainer:         \"mp4\",\n \t\t\t\t\t\t\tElementaryStreams: []string{\"video_stream0\", \"audio_stream0\"},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tOverlays: []*transcoderpb.Overlay{\n-\t\t\t\t\t\t&transcoderpb.Overlay{\n+\t\t\t\t\t\t{\n \t\t\t\t\t\t\tImage: &transcoderpb.Overlay_Image{\n \t\t\t\t\t\t\t\tUri: overlayImageURI,\n \t\t\t\t\t\t\t\tResolution: &transcoderpb.Overlay_NormalizedCoordinate{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/create_job_with_static_overlay.go",
        "code_diff": "@@ -94,7 +94,7 @@\nfunc createJobWithStaticOverlay(w io.Writer, projectID string, location string,\n \t\t\t\t\t\t\t\tAlpha: 1,\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t\tAnimations: []*transcoderpb.Overlay_Animation{\n-\t\t\t\t\t\t\t\t&transcoderpb.Overlay_Animation{\n+\t\t\t\t\t\t\t\t{\n \t\t\t\t\t\t\t\t\tAnimationType: &transcoderpb.Overlay_Animation_AnimationStatic{\n \t\t\t\t\t\t\t\t\t\tAnimationStatic: &transcoderpb.Overlay_AnimationStatic{\n \t\t\t\t\t\t\t\t\t\t\tXy: &transcoderpb.Overlay_NormalizedCoordinate{",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"log\"\n \t\"os\"\n \t\"regexp\"\n \t\"strconv\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -52,7 +53,12 @@\nvar (\n \n func initTest(t *testing.T, id string) (instName, dbName string, cleanup func()) {\n \tprojectID := getSampleProjectId(t)\n-\tinstName, cleanup = createTestInstance(t, projectID, \"regional-us-central1\")\n+\tconfigName := getSamplesInstanceConfig()\n+\tif configName == \"\" {\n+\t\tconfigName = \"regional-us-central1\"\n+\t}\n+\tlog.Printf(\"Running test by using the instance config: %s\\n\", configName)\n+\tinstName, cleanup = createTestInstance(t, projectID, configName)\n \tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n \tdbName = fmt.Sprintf(\"%s/databases/%s\", instName, dbID)",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -120,7 +126,6 @@\nfunc runCreateInstanceSample(t *testing.T, f instanceSampleFunc) {\n }\n \n func TestSample(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2143\")\n \t_ = testutil.SystemTest(t)\n \tt.Parallel()",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -365,7 +370,7 @@\nfunc TestSample(t *testing.T) {\n }\n \n func TestBackupSample(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2143\")\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2333\")\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip(\"GOLANG_SAMPLES_E2E_TEST not set\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -439,7 +444,7 @@\nfunc TestCustomerManagedEncryptionKeys(t *testing.T) {\n \n \tvar b bytes.Buffer\n \n-\tlocationId := \"us-central1\"\n+\tlocationId := \"us-west1\"\n \tkeyRingId := \"spanner-test-keyring\"\n \tkeyId := \"spanner-test-key\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \t\"net/http\"\n \t\"net/http/httputil\"\n \t\"os\"\n+\t\"path/filepath\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -42,6 +43,12 @@\nfunc TestObjects(t *testing.T) {\n \t}\n \tdefer client.Close()\n \n+\tdir, err := ioutil.TempDir(\"\", \"objectsTestTempDir\")\n+\tif err != nil {\n+\t\tt.Fatalf(\"ioutil.TempDir: %v\", err)\n+\t}\n+\tdefer os.RemoveAll(dir) // clean up\n+\n \tvar (\n \t\tbucket           = tc.ProjectID + \"-samples-object-bucket-1\"\n \t\tdstBucket        = tc.ProjectID + \"-samples-object-bucket-2\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -67,8 +74,8 @@\nfunc TestObjects(t *testing.T) {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object2, err)\n \t}\n \n-\tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n-\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n+\tif err := streamFileUpload(ioutil.Discard, bucketVersioning, object1); err != nil {\n+\t\tt.Fatalf(\"streamFileUpload(%q): %v\", object1, err)\n \t}\n \t// Check enableVersioning correctly work.\n \tbkt := client.Bucket(bucketVersioning)",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -163,9 +170,9 @@\nfunc TestObjects(t *testing.T) {\n \tif err := deleteOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, gen); err != nil {\n \t\tt.Fatalf(\"deleteOldVersionOfObject: %v\", err)\n \t}\n-\tdata, err := downloadFile(ioutil.Discard, bucket, object1)\n+\tdata, err := downloadFileIntoMemory(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Fatalf(\"downloadFile: %v\", err)\n+\t\tt.Fatalf(\"downloadFileIntoMemory: %v\", err)\n \t}\n \tif got, want := string(data), \"Hello\\nworld\"; got != want {\n \t\tt.Errorf(\"contents = %q; want %q\", got, want)",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -203,6 +210,36 @@\nfunc TestObjects(t *testing.T) {\n \t\t}\n \t})\n \n+\tt.Run(\"downloadByteRange\", func(t *testing.T) {\n+\t\tdestination := filepath.Join(dir, \"fileDownloadByteRangeDestination.txt\")\n+\t\terr = downloadByteRange(ioutil.Discard, bucket, object1, 1, 4, destination)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"downloadFile: %v\", err)\n+\t\t}\n+\t\tdata, err := ioutil.ReadFile(destination)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"ioutil.ReadFile: %v\", err)\n+\t\t}\n+\t\tif got, want := string(data), \"ell\"; got != want {\n+\t\t\tt.Errorf(\"contents = %q; want %q\", got, want)\n+\t\t}\n+\t})\n+\n+\tt.Run(\"downloadFile\", func(t *testing.T) {\n+\t\tdestination := filepath.Join(dir, \"fileDownloadDestination.txt\")\n+\t\terr = downloadFile(ioutil.Discard, bucket, object1, destination)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"downloadFile: %v\", err)\n+\t\t}\n+\t\tdata, err := ioutil.ReadFile(destination)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"ioutil.ReadFile: %v\", err)\n+\t\t}\n+\t\tif got, want := string(data), \"Hello\\nworld\"; got != want {\n+\t\t\tt.Errorf(\"contents = %q; want %q\", got, want)\n+\t\t}\n+\t})\n+\n \terr = moveFile(ioutil.Discard, bucket, object1)\n \tif err != nil {\n \t\tt.Fatalf(\"moveFile: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -360,14 +397,10 @@\nfunc TestV4SignedURL(t *testing.T) {\n \n \tbucketName := tc.ProjectID + \"-signed-url-bucket-name\"\n \tobjectName := \"foo.txt\"\n-\tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n-\tif serviceAccount == \"\" {\n-\t\tt.Skip(\"GOOGLE_APPLICATION_CREDENTIALS must be set\")\n-\t}\n \n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tputBuf := new(bytes.Buffer)\n-\tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName, serviceAccount)\n+\tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4PutObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -383,12 +416,12 @@\nfunc TestV4SignedURL(t *testing.T) {\n \t}\n \trequest.ContentLength = 11\n \trequest.Header.Set(\"Content-Type\", \"application/octet-stream\")\n-\tresponse, err := httpClient.Do(request)\n+\t_, err = httpClient.Do(request)\n \tif err != nil {\n \t\tt.Errorf(\"httpClient.Do: %v\", err)\n \t}\n \tgetBuf := new(bytes.Buffer)\n-\tgetURL, err := generateV4GetObjectSignedURL(getBuf, bucketName, objectName, serviceAccount)\n+\tgetURL, err := generateV4GetObjectSignedURL(getBuf, bucketName, objectName)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4GetObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into main",
        "commit_id": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage table\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"io/ioutil\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -94,6 +95,9 @@\nfunc TestTables(t *testing.T) {\n \t}\n \n \ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n+\tif err != nil {\n+\t\tt.Fatalf(\"couldn't generate unique table id: %v\", err)\n+\t}\n \tif err := createTableFromTemplateTable(\"bigquery-public-data\", \"samples\", \"shakespeare\", tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"createTableFromTemplateTable(%q %q): %v\", testDatasetID, testTableID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -158,6 +162,9 @@\nfunc TestTables(t *testing.T) {\n \n \t// Change tables to avoid hitting metadata update limits in a short period.\n \ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n+\tif err != nil {\n+\t\tt.Fatalf(\"couldn't generate unique table id: %v\", err)\n+\t}\n \tif err := createTableExplicitSchema(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"createTableExplicitSchema(%q %q): %v\", testDatasetID, testTableID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "compute/set_usage_export_bucket.go",
        "code_diff": "@@ -25,7 +25,8 @@\nimport (\n \t\"google.golang.org/protobuf/proto\"\n )\n \n-// setUsageExportBucket sets the Compute Engine usage export bucket for the Cloud project. This sample presents how to interpret the default value for the report name prefix parameter.\n+// setUsageExportBucket sets the Compute Engine usage export bucket for the Cloud project.\n+// This sample presents how to interpret the default value for the report name prefix parameter.\n func setUsageExportBucket(w io.Writer, projectID, bucketName, reportNamePrefix string) error {\n \t// projectID := \"your_project_id\"\n \t// bucketName := \"your_bucket_name\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "compute/start_stop_instances_test.go",
        "code_diff": "@@ -65,7 +65,7 @@\nfunc TestStartStopSnippets(t *testing.T) {\n \t\tt.Errorf(\"unable to get instance: %v\", err)\n \t}\n \n-\tif *instance.Status.Enum() != computepb.Instance_RUNNING {\n+\tif *instance.Status != computepb.Instance_RUNNING.String() {\n \t\tt.Errorf(\"Instance is not in running status\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "compute/start_stop_instances_test.go",
        "code_diff": "@@ -85,7 +85,7 @@\nfunc TestStartStopSnippets(t *testing.T) {\n \t\tt.Errorf(\"unable to get instance: %v\", err)\n \t}\n \n-\tif *instance.Status.Enum() != computepb.Instance_TERMINATED {\n+\tif *instance.Status != computepb.Instance_TERMINATED.String() {\n \t\tt.Errorf(\"Instance is not in terminated status\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "compute/start_stop_instances_test.go",
        "code_diff": "@@ -105,7 +105,7 @@\nfunc TestStartStopSnippets(t *testing.T) {\n \t\tt.Errorf(\"unable to get instance: %v\", err)\n \t}\n \n-\tif *instance.Status.Enum() != computepb.Instance_RUNNING {\n+\tif *instance.Status != computepb.Instance_RUNNING.String() {\n \t\tt.Errorf(\"Instance is not in running status\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "compute/start_stop_instances_test.go",
        "code_diff": "@@ -145,7 +145,7 @@\nfunc TestStartStopSnippets(t *testing.T) {\n \t\t\t\t\t},\n \t\t\t\t\tAutoDelete: proto.Bool(true),\n \t\t\t\t\tBoot:       proto.Bool(true),\n-\t\t\t\t\tType:       computepb.AttachedDisk_PERSISTENT.Enum(),\n+\t\t\t\t\tType:       proto.String(computepb.AttachedDisk_PERSISTENT.String()),\n \t\t\t\t\tDiskEncryptionKey: &computepb.CustomerEncryptionKey{\n \t\t\t\t\t\tRawKey: proto.String(base64Key),\n \t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "compute/start_stop_instances_test.go",
        "code_diff": "@@ -198,7 +198,7 @@\nfunc TestStartStopSnippets(t *testing.T) {\n \t\tt.Errorf(\"unable to get instance: %v\", err)\n \t}\n \n-\tif *instance.Status.Enum() != computepb.Instance_TERMINATED {\n+\tif *instance.Status != computepb.Instance_TERMINATED.String() {\n \t\tt.Errorf(\"Instance is not in terminated status\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "gaming/servers/realm_test.go",
        "code_diff": "@@ -64,6 +64,19 @@\nfunc TestRealms(t *testing.T) {\n \t\t}\n \t})\n \n+\tt.Run(\"update realm\", func(t *testing.T) {\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif err := updateRealm(buf, tc.ProjectID, \"global\", \"myrealm\"); err != nil {\n+\t\t\tt.Errorf(\"updateRealm: %v\", err)\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\twant := \"Realm updated: projects/\" + tc.ProjectID + \"/locations/global/realms/myrealm\"\n+\t\tif got != want {\n+\t\t\tt.Errorf(\"updateRealm got %q, want %q\", got, want)\n+\t\t}\n+\t})\n+\n \tt.Run(\"cluster tests\", innerTestGameServerCluster)\n \n \tt.Run(\"delete realm\", func(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"log\"\n \t\"os\"\n \t\"regexp\"\n \t\"strconv\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -52,7 +53,12 @@\nvar (\n \n func initTest(t *testing.T, id string) (instName, dbName string, cleanup func()) {\n \tprojectID := getSampleProjectId(t)\n-\tinstName, cleanup = createTestInstance(t, projectID, \"regional-us-central1\")\n+\tconfigName := getSamplesInstanceConfig()\n+\tif configName == \"\" {\n+\t\tconfigName = \"regional-us-central1\"\n+\t}\n+\tlog.Printf(\"Running test by using the instance config: %s\\n\", configName)\n+\tinstName, cleanup = createTestInstance(t, projectID, configName)\n \tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n \tdbName = fmt.Sprintf(\"%s/databases/%s\", instName, dbID)",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -120,7 +126,6 @@\nfunc runCreateInstanceSample(t *testing.T, f instanceSampleFunc) {\n }\n \n func TestSample(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2143\")\n \t_ = testutil.SystemTest(t)\n \tt.Parallel()",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -365,7 +370,7 @@\nfunc TestSample(t *testing.T) {\n }\n \n func TestBackupSample(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2143\")\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2333\")\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip(\"GOLANG_SAMPLES_E2E_TEST not set\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -439,7 +444,7 @@\nfunc TestCustomerManagedEncryptionKeys(t *testing.T) {\n \n \tvar b bytes.Buffer\n \n-\tlocationId := \"us-central1\"\n+\tlocationId := \"us-west1\"\n \tkeyRingId := \"spanner-test-keyring\"\n \tkeyId := \"spanner-test-key\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \t\"net/http\"\n \t\"net/http/httputil\"\n \t\"os\"\n+\t\"path/filepath\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -42,6 +43,12 @@\nfunc TestObjects(t *testing.T) {\n \t}\n \tdefer client.Close()\n \n+\tdir, err := ioutil.TempDir(\"\", \"objectsTestTempDir\")\n+\tif err != nil {\n+\t\tt.Fatalf(\"ioutil.TempDir: %v\", err)\n+\t}\n+\tdefer os.RemoveAll(dir) // clean up\n+\n \tvar (\n \t\tbucket           = tc.ProjectID + \"-samples-object-bucket-1\"\n \t\tdstBucket        = tc.ProjectID + \"-samples-object-bucket-2\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -67,8 +74,8 @@\nfunc TestObjects(t *testing.T) {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object2, err)\n \t}\n \n-\tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n-\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n+\tif err := streamFileUpload(ioutil.Discard, bucketVersioning, object1); err != nil {\n+\t\tt.Fatalf(\"streamFileUpload(%q): %v\", object1, err)\n \t}\n \t// Check enableVersioning correctly work.\n \tbkt := client.Bucket(bucketVersioning)",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -163,9 +170,9 @@\nfunc TestObjects(t *testing.T) {\n \tif err := deleteOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, gen); err != nil {\n \t\tt.Fatalf(\"deleteOldVersionOfObject: %v\", err)\n \t}\n-\tdata, err := downloadFile(ioutil.Discard, bucket, object1)\n+\tdata, err := downloadFileIntoMemory(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Fatalf(\"downloadFile: %v\", err)\n+\t\tt.Fatalf(\"downloadFileIntoMemory: %v\", err)\n \t}\n \tif got, want := string(data), \"Hello\\nworld\"; got != want {\n \t\tt.Errorf(\"contents = %q; want %q\", got, want)",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -203,6 +210,36 @@\nfunc TestObjects(t *testing.T) {\n \t\t}\n \t})\n \n+\tt.Run(\"downloadByteRange\", func(t *testing.T) {\n+\t\tdestination := filepath.Join(dir, \"fileDownloadByteRangeDestination.txt\")\n+\t\terr = downloadByteRange(ioutil.Discard, bucket, object1, 1, 4, destination)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"downloadFile: %v\", err)\n+\t\t}\n+\t\tdata, err := ioutil.ReadFile(destination)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"ioutil.ReadFile: %v\", err)\n+\t\t}\n+\t\tif got, want := string(data), \"ell\"; got != want {\n+\t\t\tt.Errorf(\"contents = %q; want %q\", got, want)\n+\t\t}\n+\t})\n+\n+\tt.Run(\"downloadFile\", func(t *testing.T) {\n+\t\tdestination := filepath.Join(dir, \"fileDownloadDestination.txt\")\n+\t\terr = downloadFile(ioutil.Discard, bucket, object1, destination)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"downloadFile: %v\", err)\n+\t\t}\n+\t\tdata, err := ioutil.ReadFile(destination)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"ioutil.ReadFile: %v\", err)\n+\t\t}\n+\t\tif got, want := string(data), \"Hello\\nworld\"; got != want {\n+\t\t\tt.Errorf(\"contents = %q; want %q\", got, want)\n+\t\t}\n+\t})\n+\n \terr = moveFile(ioutil.Discard, bucket, object1)\n \tif err != nil {\n \t\tt.Fatalf(\"moveFile: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -360,14 +397,10 @@\nfunc TestV4SignedURL(t *testing.T) {\n \n \tbucketName := tc.ProjectID + \"-signed-url-bucket-name\"\n \tobjectName := \"foo.txt\"\n-\tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n-\tif serviceAccount == \"\" {\n-\t\tt.Skip(\"GOOGLE_APPLICATION_CREDENTIALS must be set\")\n-\t}\n \n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tputBuf := new(bytes.Buffer)\n-\tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName, serviceAccount)\n+\tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4PutObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -383,12 +416,12 @@\nfunc TestV4SignedURL(t *testing.T) {\n \t}\n \trequest.ContentLength = 11\n \trequest.Header.Set(\"Content-Type\", \"application/octet-stream\")\n-\tresponse, err := httpClient.Do(request)\n+\t_, err = httpClient.Do(request)\n \tif err != nil {\n \t\tt.Errorf(\"httpClient.Do: %v\", err)\n \t}\n \tgetBuf := new(bytes.Buffer)\n-\tgetURL, err := generateV4GetObjectSignedURL(getBuf, bucketName, objectName, serviceAccount)\n+\tgetURL, err := generateV4GetObjectSignedURL(getBuf, bucketName, objectName)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4GetObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(spanner): add disclaimer comment about gfe_latency metric",
        "pr_number": 2305,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -27,6 +27,7 @@\nimport (\n )\n \n func TestDetect(t *testing.T) {\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2349\")\n \ttestutil.SystemTest(t)\n \n \ttests := []struct {",
        "comments": [],
        "commit_message": "Merge branch 'main' into gfe_latency",
        "commit_id": "ae0ab7dd47f471456bd0a22fd02647dbdaa9ad9f"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -17,14 +17,24 @@\npackage testutil\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"log\"\n+\t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n+\t\"github.com/google/uuid\"\n \t\"google.golang.org/api/googleapi\"\n \t\"google.golang.org/api/iterator\"\n )\n \n+// CreateTestBucket creates a new bucket with the given prefix\n+func CreateTestBucket(ctx context.Context, t *testing.T, client *storage.Client, projectID, prefix string) (string, error) {\n+\tt.Helper()\n+\tbucketName := UniqueBucketName(prefix)\n+\treturn bucketName, cleanBucketWithClient(ctx, t, client, projectID, bucketName)\n+}\n+\n // CleanBucket creates a new bucket. If the bucket already exists, it will be\n // deleted and recreated.\n func CleanBucket(ctx context.Context, t *testing.T, projectID, bucket string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -34,12 +44,19 @@\nfunc CleanBucket(ctx context.Context, t *testing.T, projectID, bucket string) er\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\treturn cleanBucketWithClient(ctx, t, client, projectID, bucket)\n+}\n+\n+// cleanBucketWithClient creates a new bucket. If the bucket already exists, it will be\n+// deleted and recreated.\n+// Like CleanBucket but you must provide the storage client.\n+func cleanBucketWithClient(ctx context.Context, t *testing.T, client *storage.Client, projectID, bucket string) error {\n+\tt.Helper()\n \n \t// Delete the bucket if it exists.\n-\tif err := deleteBucketIfExists(ctx, client, bucket); err != nil {\n+\tif err := DeleteBucketIfExists(ctx, client, bucket); err != nil {\n \t\treturn fmt.Errorf(\"error deleting bucket: %v\", err)\n \t}\n-\n \tb := client.Bucket(bucket)\n \n \t// Now create the bucket.",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -49,7 +66,7 @@\nfunc CleanBucket(ctx context.Context, t *testing.T, projectID, bucket string) er\n \t\t\tif err, ok := err.(*googleapi.Error); ok {\n \t\t\t\t// Just in case...\n \t\t\t\tif err.Code == 409 {\n-\t\t\t\t\tdeleteBucketIfExists(ctx, client, bucket) // Ignore error.\n+\t\t\t\t\tDeleteBucketIfExists(ctx, client, bucket) // Ignore error.\n \t\t\t\t}\n \t\t\t}\n \t\t\tr.Errorf(\"Bucket.Create(%q): %v\", bucket, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -68,7 +85,8 @@\nfunc CleanBucket(ctx context.Context, t *testing.T, projectID, bucket string) er\n \treturn nil\n }\n \n-func deleteBucketIfExists(ctx context.Context, client *storage.Client, bucket string) error {\n+// DeleteBucketIfExists deletes a bucket and all its objects\n+func DeleteBucketIfExists(ctx context.Context, client *storage.Client, bucket string) error {\n \tb := client.Bucket(bucket)\n \n \t// Check if the bucket does not exist, return nil.",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -89,6 +107,7 @@\nfunc deleteBucketIfExists(ctx context.Context, client *storage.Client, bucket st\n \t\tif err != nil {\n \t\t\treturn fmt.Errorf(\"Bucket.Objects(%q): %v\", bucket, err)\n \t\t}\n+\t\t// Objects with a hold must have the hold released\n \t\tif attrs.EventBasedHold || attrs.TemporaryHold {\n \t\t\tif _, err := b.Object(attrs.Name).Update(ctx, storage.ObjectAttrsToUpdate{\n \t\t\t\tTemporaryHold:  false,",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -101,7 +120,6 @@\nfunc deleteBucketIfExists(ctx context.Context, client *storage.Client, bucket st\n \t\tif err := obj.Delete(ctx); err != nil {\n \t\t\treturn fmt.Errorf(\"Bucket(%q).Object(%q).Delete: %v\", bucket, attrs.Name, err)\n \t\t}\n-\n \t}\n \n \t// Then delete the bucket itself.",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n+\t\"log\"\n \t\"os\"\n \t\"reflect\"\n \t\"strings\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -31,41 +32,69 @@\nimport (\n \tiampb \"google.golang.org/genproto/googleapis/iam/v1\"\n )\n \n+const (\n+\ttestPrefix      = \"storage-buckets-test\"\n+\tbucketExpiryAge = time.Hour * 24\n+)\n+\n+var client *storage.Client\n+\n+func TestMain(m *testing.M) {\n+\t// Initialize global vars\n+\ttc, _ := testutil.ContextMain(m)\n+\n+\tctx := context.Background()\n+\tc, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tclient = c\n+\tdefer client.Close()\n+\n+\t// Run tests\n+\texit := m.Run()\n+\n+\t// Delete old buckets whose name begins with our test prefix\n+\tif err := testutil.DeleteExpiredBuckets(client, tc.ProjectID, testPrefix, bucketExpiryAge); err != nil {\n+\t\t// Don't fail the test if cleanup fails\n+\t\tlog.Printf(\"Post-test cleanup failed: %v\", err)\n+\t}\n+\tos.Exit(exit)\n+}\n+\n func TestCreate(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tbucketName := testutil.UniqueBucketName(testPrefix)\n+\tctx := context.Background()\n+\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n-\t// Clean up bucket before running tests.\n-\tdeleteBucket(ioutil.Discard, bucketName)\n \tif err := createBucket(ioutil.Discard, tc.ProjectID, bucketName); err != nil {\n \t\tt.Fatalf(\"createBucket: %v\", err)\n \t}\n }\n \n func TestCreateBucketClassLocation(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tname := tc.ProjectID + \"-storage-buckets-tests-attrs\"\n+\tbucketName := testutil.UniqueBucketName(testPrefix)\n+\tctx := context.Background()\n+\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n-\t// Clean up bucket before running the test.\n-\tdeleteBucket(ioutil.Discard, name)\n-\tif err := createBucketClassLocation(ioutil.Discard, tc.ProjectID, name); err != nil {\n+\tif err := createBucketClassLocation(ioutil.Discard, tc.ProjectID, bucketName); err != nil {\n \t\tt.Fatalf(\"createBucketClassLocation: %v\", err)\n \t}\n-\tif err := deleteBucket(ioutil.Discard, name); err != nil {\n-\t\tt.Fatalf(\"deleteBucket: %v\", err)\n-\t}\n }\n \n func TestStorageClass(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tif err := changeDefaultStorageClass(ioutil.Discard, bucketName); err != nil {\n \t\tt.Errorf(\"changeDefaultStorageClass: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -82,7 +111,13 @@\nfunc TestStorageClass(t *testing.T) {\n \n func TestListBuckets(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tbuckets, err := listBuckets(ioutil.Discard, tc.ProjectID)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -105,7 +140,13 @@\nfunc TestListBuckets(t *testing.T) {\n \n func TestGetBucketMetadata(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tbuf := new(bytes.Buffer)\n \tif _, err := getBucketMetadata(buf, bucketName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -120,7 +161,13 @@\nfunc TestGetBucketMetadata(t *testing.T) {\n \n func TestIAM(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tif _, err := getBucketPolicy(ioutil.Discard, bucketName); err != nil {\n \t\tt.Errorf(\"getBucketPolicy: %#v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -152,14 +199,13 @@\nfunc TestIAM(t *testing.T) {\n }\n func TestCORSConfiguration(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \twant := []storage.CORS{\n \t\t{",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -193,7 +239,13 @@\nfunc TestCORSConfiguration(t *testing.T) {\n \n func TestRequesterPays(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \t// Tests which update the bucket metadata must be retried in order to avoid\n \t// flakes from rate limits.",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -214,16 +266,13 @@\nfunc TestRequesterPays(t *testing.T) {\n \n func TestKMS(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tclient, err := storage.NewClient(ctx)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")\n \tcryptoKeyID := os.Getenv(\"GOLANG_SAMPLES_KMS_CRYPTOKEY\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -261,7 +310,13 @@\nfunc TestKMS(t *testing.T) {\n \n func TestBucketLock(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tretentionPeriod := 5 * time.Second\n \ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -346,7 +401,13 @@\nfunc TestBucketLock(t *testing.T) {\n \n func TestUniformBucketLevelAccess(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n \t\tif err := enableUniformBucketLevelAccess(ioutil.Discard, bucketName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -379,16 +440,13 @@\nfunc TestUniformBucketLevelAccess(t *testing.T) {\n \n func TestPublicAccessPrevention(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tclient, err := storage.NewClient(ctx)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tif err := setPublicAccessPreventionEnforced(ioutil.Discard, bucketName); err != nil {\n \t\tt.Errorf(\"setPublicAccessPreventionEnforced: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -441,22 +499,19 @@\nfunc TestPublicAccessPrevention(t *testing.T) {\n \n func TestLifecycleManagement(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tif err := enableBucketLifecycleManagement(ioutil.Discard, bucketName); err != nil {\n-\t\tt.Fatalf(\"enableBucketLifecycleManagement: %v\", err)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n-\t// verify lifecycle is set\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\tif err := enableBucketLifecycleManagement(ioutil.Discard, bucketName); err != nil {\n+\t\tt.Fatalf(\"enableBucketLifecycleManagement: %v\", err)\n \t}\n-\tdefer client.Close()\n \n+\t// Verify lifecycle is set\n \tattrs, err := client.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -492,16 +547,13 @@\nfunc TestLifecycleManagement(t *testing.T) {\n \n func TestBucketLabel(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tclient, err := storage.NewClient(ctx)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tlabelName := \"label-name\"\n \tlabelValue := \"label-value\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -537,16 +589,13 @@\nfunc TestBucketLabel(t *testing.T) {\n \n func TestBucketWebsiteInfo(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tclient, err := storage.NewClient(ctx)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tindex := \"index.html\"\n \tnotFoundPage := \"404.html\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -569,16 +618,13 @@\nfunc TestBucketWebsiteInfo(t *testing.T) {\n \n func TestSetBucketPublicIAM(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tclient, err := storage.NewClient(ctx)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tif err := setBucketPublicIAM(ioutil.Discard, bucketName); err != nil {\n \t\tt.Fatalf(\"setBucketPublicIAM: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(cloudsql): update sample apps with Kubernetes Engine yaml files",
        "pr_number": 2291,
        "file_name": "storage/s3_sdk/s3_gcs_test.go",
        "code_diff": "@@ -18,7 +18,6 @@\npackage s3sdk\n import (\n \t\"bytes\"\n \t\"context\"\n-\t\"fmt\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-cloud-sql-kubernetes-engine-yaml",
        "commit_id": "427584fa152607f3714779f9ccc4010f8b0e6672"
    },
    {
        "pr_title": "feat(storage): add turbo replication (RPO) samples",
        "pr_number": 2279,
        "file_name": "pubsub/topics/publish_flow_control.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage topics\n \n-// [START pubsub_publish_flow_control]\n+// [START pubsub_publisher_flow_control]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into rpo",
        "commit_id": "234cd0dc93cb33d69e061f4d4cedf6d5471eb3dd"
    },
    {
        "pr_title": "refactor(firestore): Add tests, move firestore to firestore package, test main",
        "pr_number": 2276,
        "file_name": "dataproc/quickstart/quickstart_test.go",
        "code_diff": "@@ -26,7 +26,6 @@\nimport (\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n-\t\"google.golang.org/api/iterator\"\n \t\"google.golang.org/api/option\"\n \tdataprocpb \"google.golang.org/genproto/googleapis/cloud/dataproc/v1\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into test-firestore-snippets",
        "commit_id": "d7ca384065373d8072cefa6b28d0bb9991b90dd8"
    },
    {
        "pr_title": "refactor(firestore): Add tests, move firestore to firestore package, test main",
        "pr_number": 2276,
        "file_name": "dataproc/quickstart/quickstart_test.go",
        "code_diff": "@@ -76,7 +75,8 @@\nfunc setup(t *testing.T, projectID string) {\n \t\tt.Errorf(\"Error closing file: %v\", err)\n \t}\n \n-\tdeleteClusters(ctx, projectID) // Ignore any errors.\n+\t// Opportunistically delete colliding cluster name.  Ignore errors.\n+\tdeleteCluster(ctx, projectID, region, clusterName)\n }\n \n func teardown(t *testing.T, projectID string) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into test-firestore-snippets",
        "commit_id": "d7ca384065373d8072cefa6b28d0bb9991b90dd8"
    },
    {
        "pr_title": "refactor(firestore): Add tests, move firestore to firestore package, test main",
        "pr_number": 2276,
        "file_name": "dataproc/quickstart/quickstart_test.go",
        "code_diff": "@@ -95,40 +95,25 @@\nfunc teardown(t *testing.T, projectID string) {\n \t\tt.Errorf(\"Error deleting bucket: %v\", err)\n \t}\n \n-\tif err := deleteClusters(ctx, projectID); err != nil {\n-\t\tt.Errorf(\"deleteClusters: %v\", err)\n-\t}\n+\t// Post-hoc cleanup, ignore errors.\n+\tdeleteCluster(ctx, projectID, region, clusterName)\n }\n \n-func deleteClusters(ctx context.Context, projectID string) error {\n+func deleteCluster(ctx context.Context, projectID, region, clusterName string) error {\n \tendpoint := fmt.Sprintf(\"%s-dataproc.googleapis.com:443\", region)\n \tclient, err := dataproc.NewClusterControllerClient(ctx, option.WithEndpoint(endpoint))\n \tif err != nil {\n \t\treturn fmt.Errorf(\"dataproc.NewClusterControllerClient: %v\", err)\n \t}\n \n-\tlReq := &dataprocpb.ListClustersRequest{ProjectId: projectID, Region: region}\n-\tit := client.ListClusters(ctx, lReq)\n-\n-\tfor {\n-\t\tresp, err := it.Next()\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn fmt.Errorf(\"ListClusters.Next: %v\", err)\n-\t\t}\n-\t\tif resp.ClusterName == clusterName {\n-\t\t\tdReq := &dataprocpb.DeleteClusterRequest{ProjectId: projectID, Region: region, ClusterName: clusterName}\n-\t\t\top, err := client.DeleteCluster(ctx, dReq)\n-\t\t\tif err != nil {\n-\t\t\t\treturn fmt.Errorf(\"DeleteCluster: %v\", err)\n-\t\t\t}\n+\tdReq := &dataprocpb.DeleteClusterRequest{ProjectId: projectID, Region: region, ClusterName: clusterName}\n+\top, err := client.DeleteCluster(ctx, dReq)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"DeleteCluster: %v\", err)\n+\t}\n \n-\t\t\tif err := op.Wait(ctx); err != nil {\n-\t\t\t\treturn fmt.Errorf(\"DeleteCluster.Wait: %v\", err)\n-\t\t\t}\n-\t\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn fmt.Errorf(\"DeleteCluster.Wait: %v\", err)\n \t}\n \treturn nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into test-firestore-snippets",
        "commit_id": "d7ca384065373d8072cefa6b28d0bb9991b90dd8"
    },
    {
        "pr_title": "refactor(firestore): Add tests, move firestore to firestore package, test main",
        "pr_number": 2276,
        "file_name": "dataproc/quickstart/quickstart_test.go",
        "code_diff": "@@ -144,10 +129,7 @@\nfunc TestQuickstart(t *testing.T) {\n \t}\n \n \ttestutil.Retry(t, 3, 30*time.Second, func(r *testutil.R) {\n-\t\tif err := deleteClusters(context.Background(), tc.ProjectID); err != nil {\n-\t\t\tr.Errorf(\"failed to deleteClusters: %v\", err)\n-\t\t\treturn\n-\t\t}\n+\n \t\tstdOut, stdErr, err := m.Run(nil, 10*time.Minute,\n \t\t\t\"--project_id\", tc.ProjectID,\n \t\t\t\"--region\", region,",
        "comments": [],
        "commit_message": "Merge branch 'master' into test-firestore-snippets",
        "commit_id": "d7ca384065373d8072cefa6b28d0bb9991b90dd8"
    },
    {
        "pr_title": "feat(bigquery): add migration quickstart",
        "pr_number": 2249,
        "file_name": "bigquery/bigquery_migration_quickstart/main.go",
        "code_diff": "@@ -15,7 +15,7 @@\n// [START bigquerymigration_quickstart]\n \n // The bigquery_migration_quickstart application demonstrates basic usage of the\n-// BigQuery migration API by executing workflow that performs an offline SQL\n+// BigQuery migration API by executing a workflow that performs an offline SQL\n // translation task.\n package main",
        "comments": [
            {
                "comment": "Is this a GCS path? If so, maybe we could stick something in our sample data bucket?",
                "position": null
            },
            {
                "comment": "I'm a bit confused why the API doesn't use a oneof here. Presumably it only supports a limited number of types + detail messages.",
                "position": null
            },
            {
                "comment": "It's because the intent is to allow user extension; so you end up with an arbitrary set of task definitions without a central registry.",
                "position": null
            },
            {
                "comment": "Yeah, I've added some resources to the public sample, but I think they still need work.",
                "position": null
            }
        ],
        "commit_message": "comment pass",
        "commit_id": "179e3608edfe4ab115609784750302078bf1c48f"
    },
    {
        "pr_title": "feat(bigquery): add migration quickstart",
        "pr_number": 2249,
        "file_name": "bigquery/bigquery_migration_quickstart/main.go",
        "code_diff": "@@ -33,7 +33,7 @@\nimport (\n )\n \n func main() {\n-\t// Define two command line flags for controlling the behavior of this quickstart.\n+\t// Define command line flags for controlling the behavior of this quickstart.\n \tprojectID := flag.String(\"project_id\", \"\", \"Cloud Project ID.\")\n \tlocation := flag.String(\"location\", \"us\", \"BigQuery Migration location used for interactions.\")\n \toutputPath := flag.String(\"output\", \"\", \"Cloud Storage path for translated resources.\")",
        "comments": [
            {
                "comment": "Is this a GCS path? If so, maybe we could stick something in our sample data bucket?",
                "position": null
            },
            {
                "comment": "I'm a bit confused why the API doesn't use a oneof here. Presumably it only supports a limited number of types + detail messages.",
                "position": null
            },
            {
                "comment": "It's because the intent is to allow user extension; so you end up with an arbitrary set of task definitions without a central registry.",
                "position": null
            },
            {
                "comment": "Yeah, I've added some resources to the public sample, but I think they still need work.",
                "position": null
            }
        ],
        "commit_message": "comment pass",
        "commit_id": "179e3608edfe4ab115609784750302078bf1c48f"
    },
    {
        "pr_title": "feat(bigquery): add migration quickstart",
        "pr_number": 2249,
        "file_name": "bigquery/bigquery_migration_quickstart/main.go",
        "code_diff": "@@ -67,19 +67,21 @@\nfunc main() {\n // executeTranslationWorkflow constructs a migration workflow that performs some offline SQL translation.\n func executeTranslationWorkflow(ctx context.Context, client *migration.Client, projectID, location, outPath string) (*migrationpb.MigrationWorkflow, error) {\n \n-\t// Tasks are extensible; the translation task is defined by the BigQuery Migration API.\n-\n-\ttranslationDetails := &translationtaskpb.TranslationTaskDetails{\n-\t\t// The path to objects in cloud storage containing queries to be translated.\n+\t// Tasks are extensible; the translation task is defined by the BigQuery Migration API, and so we construct the appropriate\n+\t// details for the task.\n+\tdetailsTranslation := &translationtaskpb.TranslationTaskDetails{\n+\t\t// The path to objects in cloud storage containing queries to be translated.  This is a prefix to some input text files.\n \t\tInputPath: \"gs://cloud-samples-data/bigquery/migration/translation/input/\",\n-\t\t// The path to objects in cloud storage containing DDL create statements.\n+\t\t// The path to objects in cloud storage containing DDL create statements.  This is a prefix to some input DDL text files.\n \t\tSchemaPath: \"gs://cloud-samples-data/bigquery/migration/translation/schema/\",\n+\t\t// This is the cloud storage path where results will be written.  In this case it will contain translated queries,\n+\t\t// and possibly error files.\n \t\tOutputPath: outPath,\n \t}\n \n \t// We then convert the task details for translation into the suitable protobuf `Any` representation needed\n \t// to define the workflow.\n-\tanyDetails, err := anypb.New(translationDetails)\n+\tdetailsAny, err := anypb.New(detailsTranslation)\n \tif err != nil {\n \t\treturn nil, err\n \t}",
        "comments": [
            {
                "comment": "Is this a GCS path? If so, maybe we could stick something in our sample data bucket?",
                "position": null
            },
            {
                "comment": "I'm a bit confused why the API doesn't use a oneof here. Presumably it only supports a limited number of types + detail messages.",
                "position": null
            },
            {
                "comment": "It's because the intent is to allow user extension; so you end up with an arbitrary set of task definitions without a central registry.",
                "position": null
            },
            {
                "comment": "Yeah, I've added some resources to the public sample, but I think they still need work.",
                "position": null
            }
        ],
        "commit_message": "comment pass",
        "commit_id": "179e3608edfe4ab115609784750302078bf1c48f"
    },
    {
        "pr_title": "feat: Adding cloud run jobs sample",
        "pr_number": 2235,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage table\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"io/ioutil\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'main' into run-jobs",
        "commit_id": "cda722ef9792b2b3cd2bcf269dcb3ddf7dfc68e3"
    },
    {
        "pr_title": "feat: Adding cloud run jobs sample",
        "pr_number": 2235,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -94,6 +95,9 @@\nfunc TestTables(t *testing.T) {\n \t}\n \n \ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n+\tif err != nil {\n+\t\tt.Fatalf(\"couldn't generate unique table id: %v\", err)\n+\t}\n \tif err := createTableFromTemplateTable(\"bigquery-public-data\", \"samples\", \"shakespeare\", tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"createTableFromTemplateTable(%q %q): %v\", testDatasetID, testTableID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into run-jobs",
        "commit_id": "cda722ef9792b2b3cd2bcf269dcb3ddf7dfc68e3"
    },
    {
        "pr_title": "feat: Adding cloud run jobs sample",
        "pr_number": 2235,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -158,6 +162,9 @@\nfunc TestTables(t *testing.T) {\n \n \t// Change tables to avoid hitting metadata update limits in a short period.\n \ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n+\tif err != nil {\n+\t\tt.Fatalf(\"couldn't generate unique table id: %v\", err)\n+\t}\n \tif err := createTableExplicitSchema(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"createTableExplicitSchema(%q %q): %v\", testDatasetID, testTableID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'main' into run-jobs",
        "commit_id": "cda722ef9792b2b3cd2bcf269dcb3ddf7dfc68e3"
    },
    {
        "pr_title": "feat: Adding cloud run jobs sample",
        "pr_number": 2235,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -27,6 +27,7 @@\nimport (\n )\n \n func TestDetect(t *testing.T) {\n+\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2349\")\n \ttestutil.SystemTest(t)\n \n \ttests := []struct {",
        "comments": [],
        "commit_message": "Merge branch 'main' into run-jobs",
        "commit_id": "cda722ef9792b2b3cd2bcf269dcb3ddf7dfc68e3"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "badfiles_test.go",
        "code_diff": "@@ -54,6 +54,7 @@\nvar allowList = []string{\n \t\"**/.gcloudignore\",\n \t\"**/Makefile\",\n \t\".gitignore\",\n+\t\"**/.gitkeep\",\n \n \t// Primarily ML APIs.\n \t\"**/testdata/**/*.jpg\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -19,16 +19,20 @@\npackage main\n \n import (\n+\t\"crypto/tls\"\n+\t\"crypto/x509\"\n \t\"database/sql\"\n+\t\"errors\"\n \t\"fmt\"\n \t\"html/template\"\n+\t\"io/ioutil\"\n \t\"log\"\n \t\"math\"\n \t\"net/http\"\n \t\"os\"\n \t\"strconv\"\n \n-\t_ \"github.com/go-sql-driver/mysql\"\n+\t\"github.com/go-sql-driver/mysql\"\n )\n \n // vote struct contains a single row from the votes table in the database.",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -165,7 +169,7 @@\nfunc currentTotals(app *app) (*templateData, error) {\n \t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}\n \n-\tvar voteDiffStr string = voteDiff(int(math.Abs(float64(tabVotes) - float64(spaceVotes)))).String()\n+\tvoteDiffStr := voteDiff(int(math.Abs(float64(tabVotes) - float64(spaceVotes)))).String()\n \n \tlatestVotesCast, err := recentVotes(app)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -245,8 +249,7 @@\nfunc initSocketConnectionPool() (*sql.DB, error) {\n \t\tsocketDir = \"/cloudsql\"\n \t}\n \n-\tvar dbURI string\n-\tdbURI = fmt.Sprintf(\"%s:%s@unix(/%s/%s)/%s?parseTime=true\", dbUser, dbPwd, socketDir, instanceConnectionName, dbName)\n+\tdbURI := fmt.Sprintf(\"%s:%s@unix(/%s/%s)/%s?parseTime=true\", dbUser, dbPwd, socketDir, instanceConnectionName, dbName)\n \n \t// dbPool is the pool of database connections.\n \tdbPool, err := sql.Open(\"mysql\", dbURI)",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -274,8 +277,42 @@\nfunc initTCPConnectionPool() (*sql.DB, error) {\n \t\tdbName    = mustGetenv(\"DB_NAME\") // e.g. 'my-database'\n \t)\n \n-\tvar dbURI string\n-\tdbURI = fmt.Sprintf(\"%s:%s@tcp(%s:%s)/%s?parseTime=true\", dbUser, dbPwd, dbTCPHost, dbPort, dbName)\n+\tdbURI := fmt.Sprintf(\"%s:%s@tcp(%s:%s)/%s?parseTime=true\", dbUser, dbPwd, dbTCPHost, dbPort, dbName)\n+\n+\t// [START_EXCLUDE]\n+\t// [START cloud_sql_postgres_databasesql_sslcerts]\n+\t// (OPTIONAL) Configure SSL certificates\n+\t// For deployments that connect directly to a Cloud SQL instance without\n+\t// using the Cloud SQL Proxy, configuring SSL certificates will ensure the\n+\t// connection is encrypted. This step is entirely OPTIONAL.\n+\tdbRootCert := os.Getenv(\"DB_ROOT_CERT\") // e.g., '/path/to/my/server-ca.pem'\n+\tif dbRootCert != \"\" {\n+\t\tvar (\n+\t\t\tdbCert = mustGetenv(\"DB_CERT\") // e.g. '/path/to/my/client-cert.pem'\n+\t\t\tdbKey  = mustGetenv(\"DB_KEY\")  // e.g. '/path/to/my/client-key.pem'\n+\t\t)\n+\t\tpool := x509.NewCertPool()\n+\t\tpem, err := ioutil.ReadFile(dbRootCert)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\tif ok := pool.AppendCertsFromPEM(pem); !ok {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\tcert, err := tls.LoadX509KeyPair(dbCert, dbKey)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\tmysql.RegisterTLSConfig(\"cloudsql\", &tls.Config{\n+\t\t\tRootCAs:               pool,\n+\t\t\tCertificates:          []tls.Certificate{cert},\n+\t\t\tInsecureSkipVerify:    true,\n+\t\t\tVerifyPeerCertificate: verifyPeerCertFunc(pool),\n+\t\t})\n+\t\tdbURI += \"&tls=cloudsql\"\n+\t}\n+\t// [END cloud_sql_postgres_databasesql_sslcerts]\n+\t// [END_EXCLUDE]\n \n \t// dbPool is the pool of database connections.\n \tdbPool, err := sql.Open(\"mysql\", dbURI)",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "cloudsql/postgres/database-sql/cloudsql.go",
        "code_diff": "@@ -169,7 +169,7 @@\nfunc currentTotals(app *app) (*templateData, error) {\n \t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}\n \n-\tvar voteDiffStr string = voteDiff(int(math.Abs(float64(tabVotes) - float64(spaceVotes)))).String()\n+\tvoteDiffStr := voteDiff(int(math.Abs(float64(tabVotes) - float64(spaceVotes)))).String()\n \n \tlatestVotesCast, err := recentVotes(app)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "cloudsql/postgres/database-sql/cloudsql.go",
        "code_diff": "@@ -249,8 +249,7 @@\nfunc initSocketConnectionPool() (*sql.DB, error) {\n \t\tsocketDir = \"/cloudsql\"\n \t}\n \n-\tvar dbURI string\n-\tdbURI = fmt.Sprintf(\"user=%s password=%s database=%s host=%s/%s\", dbUser, dbPwd, dbName, socketDir, instanceConnectionName)\n+\tdbURI := fmt.Sprintf(\"user=%s password=%s database=%s host=%s/%s\", dbUser, dbPwd, dbName, socketDir, instanceConnectionName)\n \n \t// dbPool is the pool of database connections.\n \tdbPool, err := sql.Open(\"pgx\", dbURI)",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql.go",
        "code_diff": "@@ -159,7 +159,7 @@\nfunc currentTotals(app *app) (*templateData, error) {\n \t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}\n \n-\tvar voteDiffStr string = voteDiff(int(math.Abs(float64(tabVotes) - float64(spaceVotes)))).String()\n+\tvoteDiffStr := voteDiff(int(math.Abs(float64(tabVotes) - float64(spaceVotes)))).String()\n \n \tlatestVotesCast, err := recentVotes(app)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -33,7 +33,7 @@\nconst (\n \tsubscriptionName = \"dlp-inspect-test-sub-\"\n \n \tssnFileName = \"fake_ssn.txt\"\n-\tbucketName  = \"golang-samples-dlp-test\"\n+\tbucketName  = \"golang-samples-dlp-test2\"\n )\n \n func TestInspectDatastore(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "gaming/servers/list_clusters.go",
        "code_diff": "@@ -40,6 +40,7 @@\nfunc listGameServerClusters(w io.Writer, projectID, location, realmID string) er\n \n \treq := &gamingpb.ListGameServerClustersRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/%s/realms/%s\", projectID, location, realmID),\n+\t\tView:   gamingpb.GameServerClusterView_FULL,\n \t}\n \n \tit := client.ListGameServerClusters(ctx, req)",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "gaming/servers/realm_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage servers\n \n import (\n \t\"bytes\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "feat(functions): add CloudEvent helloStorage sample",
        "pr_number": 2221,
        "file_name": "gaming/servers/realm_test.go",
        "code_diff": "@@ -116,7 +117,7 @@\nfunc innerTestGameServerCluster(t *testing.T) {\n \n \t\tgot := buf.String()\n \t\twant := \"Cluster retrieved: projects/\" + tc.ProjectID + \"/locations/global/realms/myrealm/gameServerClusters/mycluster\"\n-\t\tif got != want {\n+\t\tif !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"getGameServerCluster got %q, want %q\", got, want)\n \t\t}\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into fn-ce-hellostorage",
        "commit_id": "06f1008682822f5078decf890918e617d7c090a5"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "kms/create_key_asymmetric_decrypt.go",
        "code_diff": "@@ -19,9 +19,11 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/durationpb\"\n )\n \n // createKeyAsymmetricDecrypt creates a new asymmetric RSA encrypt/decrypt key",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "kms/create_key_asymmetric_sign.go",
        "code_diff": "@@ -19,9 +19,11 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/durationpb\"\n )\n \n // createKeyAsymmetricSign creates a new asymmetric RSA sign/verify key pair",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "kms/create_key_hsm.go",
        "code_diff": "@@ -19,9 +19,11 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/durationpb\"\n )\n \n // createKeyHSM creates a new symmetric encrypt/decrypt key on Cloud KMS.",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "kms/kms_helpers_test.go",
        "code_diff": "@@ -42,6 +42,7 @@\ntype kmsFixture struct {\n \tAsymmetricSignRSAKeyName string\n \tHSMKeyName               string\n \tSymmetricKeyName         string\n+\tHMACKeyName              string\n }\n \n func NewKMSFixture(projectID string) (*kmsFixture, error) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "kms/kms_helpers_test.go",
        "code_diff": "@@ -87,6 +88,11 @@\nfunc NewKMSFixture(projectID string) (*kmsFixture, error) {\n \t\treturn nil, fmt.Errorf(\"failed to create symmetric key: %v\", err)\n \t}\n \n+\tk.HMACKeyName, err = k.CreateHMACKey(k.KeyRingName)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"failed to create hmac key: %v\", err)\n+\t}\n+\n \treturn &k, nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -119,6 +119,21 @@\nfunc TestCreateKeyLabels(t *testing.T) {\n \t}\n }\n \n+func TestCreateKeyMAC(t *testing.T) {\n+\ttestutil.SystemTest(t)\n+\n+\tparent, id := fixture.KeyRingName, fixture.RandomID()\n+\n+\tvar b bytes.Buffer\n+\tif err := createKeyMac(&b, parent, id); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Created key:\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"createKeyMac: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestCreateKeySymmetricEncryptDecrypt(t *testing.T) {\n \ttestutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -346,6 +361,21 @@\nfunc TestEncryptSymmetric(t *testing.T) {\n \t}\n }\n \n+func TestGenerateRandomBytes(t *testing.T) {\n+\ttestutil.SystemTest(t)\n+\n+\tname := fixture.LocationName\n+\n+\tvar b bytes.Buffer\n+\tif err := generateRandomBytes(&b, name, 256); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Random bytes:\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"generateRandomBytes: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestGetKeyVersionAttestation(t *testing.T) {\n \ttestutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -469,6 +499,21 @@\nfunc TestSignAsymmetric(t *testing.T) {\n \t}\n }\n \n+func TestSignMac(t *testing.T) {\n+\ttestutil.SystemTest(t)\n+\n+\tname := fmt.Sprintf(\"%s/cryptoKeyVersions/1\", fixture.HMACKeyName)\n+\n+\tvar b bytes.Buffer\n+\tif err := signMac(&b, name, \"fruitloops\"); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Signature:\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"signMac: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestUpdateKeyUpdateLabels(t *testing.T) {\n \ttestutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -479,6 +479,30 @@\nfunc TestListSecretVersions(t *testing.T) {\n \t}\n }\n \n+func TestListSecretVersionsWithFilter(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tpayload := []byte(\"my-secret\")\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n+\tversion1 := testSecretVersion(t, secret.Name, payload)\n+\tversion2 := testSecretVersion(t, secret.Name, payload)\n+\n+\tvar b bytes.Buffer\n+\tif err := listSecretVersionsWithFilter(&b, secret.Name, fmt.Sprintf(\"name:%s\", version1.Name)); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), fmt.Sprintf(\"%s with state ENABLED\", version1.Name); !strings.Contains(got, want) {\n+\t\tt.Errorf(\"listSecretVersions: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tif got, lacked := b.String(), fmt.Sprintf(\"%s with state ENABLED\", version2.Name); strings.Contains(got, lacked) {\n+\t\tt.Errorf(\"listSecretVersions: expected %q to not contain %q\", got, lacked)\n+\t}\n+}\n+\n func TestListSecrets(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -160,6 +160,8 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"1 1 Total Junk\")\n \tout = runSample(t, query, dbName, \"failed to query data\")\n \tassertContains(t, out, \"1 1 Total Junk\")\n+\tout = runSample(t, queryRequestPriority, dbName, \"failed to query data with RequestPriority\")\n+\tassertContains(t, out, \"1 1 Total Junk\")\n \n \trunSampleWithContext(ctx, t, addIndex, dbName, \"failed to add index\")\n \tout = runSample(t, queryUsingIndex, dbName, \"failed to query using index\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -194,9 +196,17 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"Forever Hold Your Peace\")\n \tassertContains(t, out, \"Green\")\n \n+\tout = runSample(t, readRequestPriority, dbName, \"failed to read with RequestPriority\")\n+\tassertContains(t, out, \"Go, Go, Go\")\n+\tassertContains(t, out, \"Forever Hold Your Peace\")\n+\tassertContains(t, out, \"Green\")\n+\n \tout = runSample(t, readBatchData, dbName, \"failed to read batch data\")\n \tassertContains(t, out, \"1 Marc Richards\")\n \n+\tout = runSample(t, readBatchDataRequestPriority, dbName, \"failed to read batch data with RequestPriority\")\n+\tassertContains(t, out, \"1 Marc Richards\")\n+\n \trunSampleWithContext(ctx, t, addCommitTimestamp, dbName, \"failed to add commit timestamp\")\n \trunSample(t, updateWithTimestamp, dbName, \"failed to update with timestamp\")\n \tout = runSample(t, queryWithTimestamp, dbName, \"failed to query with timestamp\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -232,6 +242,9 @@\nfunc TestSample(t *testing.T) {\n \tout = runSample(t, insertUsingDML, dbName, \"failed to insert using DML\")\n \tassertContains(t, out, \"record(s) inserted\")\n \n+\tout = runSample(t, insertUsingDMLRequestPriority, dbName, \"failed to insert using DML with RequestPriority\")\n+\tassertContains(t, out, \"record(s) inserted\")\n+\n \tout = runSample(t, setCustomTimeoutAndRetry, dbName, \"failed to insert using DML with custom timeout and retry\")\n \tassertContains(t, out, \"record(s) inserted\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "downscope(examples): show credential downscoping with CAB",
        "pr_number": 2181,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -262,12 +275,18 @@\nfunc TestSample(t *testing.T) {\n \tout = runSample(t, updateUsingPartitionedDML, dbName, \"failed to update using partitioned DML\")\n \tassertContains(t, out, \"record(s) updated\")\n \n+\tout = runSample(t, updateUsingPartitionedDMLRequestPriority, dbName, \"failed to update using partitioned DML with RequestPriority\")\n+\tassertContains(t, out, \"record(s) updated\")\n+\n \tout = runSample(t, deleteUsingPartitionedDML, dbName, \"failed to delete using partitioned DML\")\n \tassertContains(t, out, \"record(s) deleted\")\n \n \tout = runSample(t, updateUsingBatchDML, dbName, \"failed to update using batch DML\")\n \tassertContains(t, out, \"Executed 2 SQL statements using Batch DML.\")\n \n+\tout = runSample(t, updateUsingBatchDMLRequestPriority, dbName, \"failed to update using batch DML with RequestPriority\")\n+\tassertContains(t, out, \"Executed 2 SQL statements using Batch DML.\")\n+\n \tout = runSampleWithContext(ctx, t, createTableWithDatatypes, dbName, \"failed to create table with data types\")\n \tassertContains(t, out, \"Created Venues table\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into downscoping-samples",
        "commit_id": "3e21c9e7ff6b3d48f2f0e52ebacfd510550d6b10"
    },
    {
        "pr_title": "feat(compute): add pagination samples",
        "pr_number": 2179,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -378,6 +378,9 @@\nfunc TestV4SignedURL(t *testing.T) {\n \n \thttpClient := &http.Client{}\n \trequest, err := http.NewRequest(\"PUT\", putURL, strings.NewReader(\"hello world\"))\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to compose HTTP request: %v\", err)\n+\t}\n \trequest.ContentLength = 11\n \trequest.Header.Set(\"Content-Type\", \"application/octet-stream\")\n \tresponse, err := httpClient.Do(request)",
        "comments": [],
        "commit_message": "Merge branch 'master' into compute-pagination",
        "commit_id": "721397e52bdb1a132bd562d3061ea3ca7eb1ba2b"
    },
    {
        "pr_title": "feat(compute): add pagination samples",
        "pr_number": 2179,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -422,6 +425,9 @@\nfunc TestPostPolicyV4(t *testing.T) {\n \tbucketName := tc.ProjectID + \"-post-policy-bucket-name\"\n \tobjectName := \"foo.txt\"\n \tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n+\tif serviceAccount == \"\" {\n+\t\tt.Error(\"GOOGLE_APPLICATION_CREDENTIALS must be set\")\n+\t}\n \n \tif err := testutil.CleanBucket(ctx, t, tc.ProjectID, bucketName); err != nil {\n \t\tt.Fatalf(\"CleanBucket: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into compute-pagination",
        "commit_id": "721397e52bdb1a132bd562d3061ea3ca7eb1ba2b"
    },
    {
        "pr_title": "fix(compute): iterator to match new return values",
        "pr_number": 2174,
        "file_name": "compute/list_instances.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n \t\"io\"\n \n \tcompute \"cloud.google.com/go/compute/apiv1\"\n+\t\"google.golang.org/api/iterator\"\n \tcomputepb \"google.golang.org/genproto/googleapis/cloud/compute/v1\"\n )",
        "comments": [],
        "commit_message": "fix(compute): iterator to match new return values",
        "commit_id": "3969750ab38b4e81b3ee01230d44c204c8a464fc"
    },
    {
        "pr_title": "feat(pubsub): add schema samples",
        "pr_number": 2164,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -33,7 +33,7 @@\nconst (\n \tsubscriptionName = \"dlp-inspect-test-sub-\"\n \n \tssnFileName = \"fake_ssn.txt\"\n-\tbucketName  = \"golang-samples-dlp-test\"\n+\tbucketName  = \"golang-samples-dlp-test2\"\n )\n \n func TestInspectDatastore(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-schema-beta",
        "commit_id": "73781b0c26c7cb0b47805d72bc966d287184a81c"
    },
    {
        "pr_title": "feat(spanner): add samples for query with GFE, gRPC and query stats",
        "pr_number": 2163,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -45,7 +45,6 @@\ntype sampleFuncWithContext func(ctx context.Context, w io.Writer, dbName string)\n type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string) error\n type createBackupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string, versionTime time.Time) error\n-type sampleFuncWithProjectID func(w io.Writer, dbName, projectID string) error\n \n var (\n \tvalidInstancePattern = regexp.MustCompile(\"^projects/(?P<project>[^/]+)/instances/(?P<instance>[^/]+)$\")",
        "comments": [
            {
                "comment": "Can we reuse the existing `sampleFunc` and extract `projectID` from `dbName` in the samples? If not, can we change the order of the parameters to `projectID, dbName string`? \r\n\r\nI still think extracting `projectID` from `dbName` might be better, like: \r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/296e1434dc002ab65f118c40dac5580dc002d451/spanner/spanner_snippets/spanner/integration_test.go#L713-L718\r\n\r\nBut of course, there are some code duplications. \r\n\r\nOr we should have a \r\n\r\n```go\r\ntype databaseSampleFunc func(w io.Writer, projectID, instanceID, databaseID string) error\r\n```",
                "position": null
            },
            {
                "comment": "Makes sense, changed to parse db name to get project IDs.",
                "position": null
            }
        ],
        "commit_message": "Parse project id from db name",
        "commit_id": "11bf4dd6d2471f5aa0cde3386d24583c4280338a"
    },
    {
        "pr_title": "feat(spanner): add samples for query with GFE, gRPC and query stats",
        "pr_number": 2163,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -305,12 +304,11 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"19 Venue 19\")\n \tassertContains(t, out, \"42 Venue 42\")\n \n-\tprojectID := getSampleProjectId(t)\n-\tout = runQueryWithMetricSample(t, queryWithGFELatency, dbName, projectID, \"failed to query with GFE latency\")\n+\tout = runSample(t, queryWithGFELatency, dbName, \"failed to query with GFE latency\")\n \tassertContains(t, out, \"1 1 Total Junk\")\n-\tout = runQueryWithMetricSample(t, queryWithGRPCMetric, dbName, projectID, \"failed to query with gRPC metric\")\n+\tout = runSample(t, queryWithGRPCMetric, dbName, \"failed to query with gRPC metric\")\n \tassertContains(t, out, \"1 1 Total Junk\")\n-\tout = runQueryWithMetricSample(t, queryWithQueryStats, dbName, projectID, \"failed to query with query stats\")\n+\tout = runSample(t, queryWithQueryStats, dbName, \"failed to query with query stats\")\n \tassertContains(t, out, \"1 1 Total Junk\")\n \n \trunSample(t, dropColumn, dbName, \"failed to drop column\")",
        "comments": [
            {
                "comment": "Can we reuse the existing `sampleFunc` and extract `projectID` from `dbName` in the samples? If not, can we change the order of the parameters to `projectID, dbName string`? \r\n\r\nI still think extracting `projectID` from `dbName` might be better, like: \r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/296e1434dc002ab65f118c40dac5580dc002d451/spanner/spanner_snippets/spanner/integration_test.go#L713-L718\r\n\r\nBut of course, there are some code duplications. \r\n\r\nOr we should have a \r\n\r\n```go\r\ntype databaseSampleFunc func(w io.Writer, projectID, instanceID, databaseID string) error\r\n```",
                "position": null
            },
            {
                "comment": "Makes sense, changed to parse db name to get project IDs.",
                "position": null
            }
        ],
        "commit_message": "Parse project id from db name",
        "commit_id": "11bf4dd6d2471f5aa0cde3386d24583c4280338a"
    },
    {
        "pr_title": "feat(spanner): add samples for query with GFE, gRPC and query stats",
        "pr_number": 2163,
        "file_name": "spanner/spanner_snippets/spanner/spanner_opencensus_capture_grpc_metric.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"regexp\"\n \n \t\"cloud.google.com/go/spanner\"\n \t\"google.golang.org/api/iterator\"",
        "comments": [],
        "commit_message": "Parse project id from db name",
        "commit_id": "11bf4dd6d2471f5aa0cde3386d24583c4280338a"
    },
    {
        "pr_title": "feat(spanner): add samples for query with GFE, gRPC and query stats",
        "pr_number": 2163,
        "file_name": "spanner/spanner_snippets/spanner/spanner_opencensus_capture_grpc_metric.go",
        "code_diff": "@@ -29,7 +30,14 @@\nimport (\n \t\"go.opencensus.io/stats/view\"\n )\n \n-func queryWithGRPCMetric(w io.Writer, db string, projectID string) error {\n+var validDatabasePattern = regexp.MustCompile(\"^projects/(?P<project>[^/]+)/instances/(?P<instance>[^/]+)/databases/(?P<database>[^/]+)$\")\n+\n+func queryWithGRPCMetric(w io.Writer, db string) error {\n+\tprojectID, _, _, err := parseDatabaseName(db)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n \tctx := context.Background()\n \tclient, err := spanner.NewClient(ctx, db)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Parse project id from db name",
        "commit_id": "11bf4dd6d2471f5aa0cde3386d24583c4280338a"
    },
    {
        "pr_title": "fix(run): Add retries to tests",
        "pr_number": 2152,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -207,6 +207,25 @@\nfunc TestDeleteSecret(t *testing.T) {\n \t}\n }\n \n+func TestDeleteSecretWithEtag(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n+\tif err := deleteSecretWithEtag(secret.Name, secret.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testClient(t)\n+\t_, err := client.GetSecret(ctx, &secretmanagerpb.GetSecretRequest{\n+\t\tName: secret.Name,\n+\t})\n+\tif terr, ok := grpcstatus.FromError(err); !ok || terr.Code() != grpccodes.NotFound {\n+\t\tt.Errorf(\"deleteSecret: expected %v to be not found\", err)\n+\t}\n+}\n+\n func TestDestroySecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into http2",
        "commit_id": "330bb3f79f2bd0ff8ac75f7b1e45f1f7d19992b8"
    },
    {
        "pr_title": "fix(run): Add retries to tests",
        "pr_number": 2152,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -232,6 +251,30 @@\nfunc TestDestroySecretVersion(t *testing.T) {\n \t}\n }\n \n+func TestDestroySecretVersionWithEtag(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tpayload := []byte(\"my-secret\")\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n+\tversion := testSecretVersion(t, secret.Name, payload)\n+\n+\tif err := destroySecretVersionWithEtag(version.Name, version.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testClient(t)\n+\tv, err := client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_DESTROYED; got != want {\n+\t\tt.Errorf(\"testSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+}\n+\n func TestDisableEnableSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into http2",
        "commit_id": "330bb3f79f2bd0ff8ac75f7b1e45f1f7d19992b8"
    },
    {
        "pr_title": "fix(run): Add retries to tests",
        "pr_number": 2152,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -271,6 +314,45 @@\nfunc TestDisableEnableSecretVersion(t *testing.T) {\n \t}\n }\n \n+func TestDisableEnableSecretVersionWithEtag(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tpayload := []byte(\"my-secret\")\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n+\tversion := testSecretVersion(t, secret.Name, payload)\n+\n+\tif err := disableSecretVersionWithEtag(version.Name, version.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testClient(t)\n+\tv, err := client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_DISABLED; got != want {\n+\t\tt.Errorf(\"testSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+\n+\tif err := enableSecretVersionWithEtag(version.Name, v.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tv, err = client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_ENABLED; got != want {\n+\t\tt.Errorf(\"testSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+}\n+\n func TestGetSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into http2",
        "commit_id": "330bb3f79f2bd0ff8ac75f7b1e45f1f7d19992b8"
    },
    {
        "pr_title": "feat(spanner): update samples for optimizer statistics package",
        "pr_number": 2094,
        "file_name": "opentelemetry/trace/main.go",
        "code_diff": "@@ -37,7 +37,6 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"texporter.NewExporter: %v\", err)\n \t}\n-\tdefer exporter.Shutdown(ctx) // flushes any pending spans\n \n \t// Create trace provider with the exporter.\n \t//",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-optimizer-stats-pkg",
        "commit_id": "6da2f92a19f2e0d5973611a853dd40814d9451d7"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "appengine/go11x/pubsub/authenicated_push/main_test.go",
        "code_diff": "@@ -41,32 +41,43 @@\nfunc TestReceiveMessagesHandler(t *testing.T) {\n \n \ttests := []struct {\n \t\tname    string\n+\t\temail   string\n \t\taud     string\n \t\ttoken   string\n \t\twantErr bool\n \t}{\n \t\t{\n \t\t\tname:    \"works\",\n+\t\t\temail:   \"test-service-account-email@example.com\",\n \t\t\taud:     \"http://example.com\",\n \t\t\ttoken:   testToken,\n \t\t\twantErr: false,\n \t\t},\n+\t\t{\n+\t\t\tname:    \"bad email\",\n+\t\t\temail:   \"bad-email@example.com\",\n+\t\t\taud:     \"http://example.com\",\n+\t\t\ttoken:   testToken,\n+\t\t\twantErr: true,\n+\t\t},\n \t\t{\n \t\t\tname:    \"bad token sent\",\n+\t\t\temail:   \"test-service-account-email@example.com\",\n \t\t\taud:     \"http://example.com\",\n \t\t\ttoken:   \"bad token\",\n \t\t\twantErr: true,\n \t\t},\n \t\t{\n \t\t\tname:    \"mismatched aud claim in auth token\",\n+\t\t\temail:   \"test-service-account-email@example.com\",\n \t\t\taud:     \"http://mismatched.com\",\n \t\t\ttoken:   testToken,\n \t\t\twantErr: true,\n \t\t},\n \t}\n \tfor _, tt := range tests {\n \t\tt.Run(tt.name, func(t *testing.T) {\n-\t\t\tauthToken, pk := createRS256JWT(t, tt.aud)\n+\t\t\tauthToken, pk := createRS256JWT(t, tt.email, tt.aud)\n \t\t\tapp := &app{pubsubVerificationToken: testToken}\n \t\t\tapp.defaultHTTPClient = createClient(t, pk)\n \t\t\tpr := &pushRequest{",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "appengine/go11x/pubsub/authenicated_push/main_test.go",
        "code_diff": "@@ -148,9 +159,9 @@\ntype jwk struct {\n \tN   string `json:\"n\"`\n }\n \n-func createRS256JWT(t *testing.T, aud string) (string, rsa.PublicKey) {\n+func createRS256JWT(t *testing.T, email string, aud string) (string, rsa.PublicKey) {\n \tt.Helper()\n-\ttoken := createAuthToken(t, aud)\n+\ttoken := createAuthToken(t, email, aud)\n \tprivateKey, err := rsa.GenerateKey(rand.Reader, 2048)\n \tif err != nil {\n \t\tt.Fatalf(\"unable to generate key: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "auth/snippets.go",
        "code_diff": "@@ -40,6 +40,7 @@\nfunc implicit() {\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n+\tdefer storageClient.Close()\n \n \tit := storageClient.Buckets(ctx, \"project-id\")\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "auth/snippets.go",
        "code_diff": "@@ -74,6 +75,7 @@\nfunc explicit(jsonPath, projectID string) {\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n+\tdefer client.Close()\n \tfmt.Println(\"Buckets:\")\n \tit := client.Buckets(ctx, projectID)\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -40,6 +40,7 @@\nfunc listAlertPolicies(w io.Writer, projectID string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \treq := &monitoringpb.ListAlertPoliciesRequest{\n \t\tName: \"projects/\" + projectID,",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -77,6 +78,7 @@\nfunc backupPolicies(w io.Writer, projectID string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer alertClient.Close()\n \talertReq := &monitoringpb.ListAlertPoliciesRequest{\n \t\tName: \"projects/\" + projectID,\n \t\t// Filter:  \"\", // See https://cloud.google.com/monitoring/api/v3/sorting-and-filtering.",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -99,6 +101,7 @@\nfunc backupPolicies(w io.Writer, projectID string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer channelClient.Close()\n \tchannelReq := &monitoringpb.ListNotificationChannelsRequest{\n \t\tName: \"projects/\" + projectID,\n \t\t// Filter:  \"\", // See https://cloud.google.com/monitoring/api/v3/sorting-and-filtering.",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -193,10 +196,12 @@\nfunc restorePolicies(w io.Writer, projectID string, r io.Reader) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer alertClient.Close()\n \tchannelClient, err := monitoring.NewNotificationChannelClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer channelClient.Close()\n \n \t// When a channel is recreated, rather than updated, it will get\n \t// a new name.  We have to update the AlertPolicy with the new",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -279,6 +284,7 @@\nfunc replaceChannels(w io.Writer, projectID, alertPolicyID string, channelIDs []\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \tpolicy := &monitoringpb.AlertPolicy{\n \t\tName: \"projects/\" + projectID + \"/alertPolicies/\" + alertPolicyID,",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -41,6 +41,7 @@\nfunc writeTimeSeriesValue(projectID, metricType string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer c.Close()\n \tnow := &timestamp.Timestamp{\n \t\tSeconds: time.Now().Unix(),\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "speech/caption/caption.go",
        "code_diff": "@@ -69,6 +69,7 @@\nfunc recognizeGCS(w io.Writer, gcsURI string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \t// Send the request with the URI (gs://...)\n \t// and sample rate information to be transcripted.",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n \n \t\"cloud.google.com/go/storage\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -40,6 +41,13 @@\nfunc TestMain(m *testing.M) {\n \tstorageClient, _ = storage.NewClient(ctx)\n \tdefer storageClient.Close()\n \n+\t// Delete all existing HMAC keys in the project to avoid running into\n+\t// resource constraints during the test.\n+\tprojectID := os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")\n+\tif err := deleteAllKeys(projectID); err != nil {\n+\t\tfmt.Printf(\"deleting existing keys: %v\", err)\n+\t}\n+\n \tos.Exit(m.Run())\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -68,10 +76,10 @@\nfunc TestCreateKey(t *testing.T) {\n \tdefer deleteTestKey(key)\n \n \tif err != nil {\n-\t\tt.Errorf(\"createHMACKey raised error: %s\", err)\n+\t\tt.Fatalf(\"createHMACKey raised error: %s\", err)\n \t}\n \tif key == nil {\n-\t\tt.Errorf(\"Returned nil key.\")\n+\t\tt.Fatalf(\"Returned nil key.\")\n \t}\n \tif key.State != \"ACTIVE\" {\n \t\tt.Errorf(\"State of key is %s, should be ACTIVE\", key.State)",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -94,7 +102,7 @@\nfunc TestActivateKey(t *testing.T) {\n \tkey, err = activateHMACKey(ioutil.Discard, key.AccessID, key.ProjectID)\n \n \tif err != nil {\n-\t\tt.Errorf(\"Error in activateHMACKey: %s\", err)\n+\t\tt.Fatalf(\"Error in activateHMACKey: %s\", err)\n \t}\n \tif key.State != \"ACTIVE\" {\n \t\tt.Errorf(\"State of key is %s, should be ACTIVE\", key.State)",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -111,7 +119,7 @@\nfunc TestDeactivateKey(t *testing.T) {\n \n \tkey, err = deactivateHMACKey(ioutil.Discard, key.AccessID, key.ProjectID)\n \tif err != nil {\n-\t\tt.Errorf(\"Error in deactivateHMACKey: %s\", err)\n+\t\tt.Fatalf(\"Error in deactivateHMACKey: %s\", err)\n \t}\n \tif key.State != \"INACTIVE\" {\n \t\tt.Errorf(\"State of key is %s, should be INACTIVE\", key.State)",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -127,12 +135,12 @@\nfunc TestGetKey(t *testing.T) {\n \t}\n \n \ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n-\t\tkey, err = getHMACKey(ioutil.Discard, key.AccessID, key.ProjectID)\n+\t\tgotKey, err := getHMACKey(ioutil.Discard, key.AccessID, key.ProjectID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"Error in getHMACKey: %s\", err)\n \t\t\treturn\n \t\t}\n-\t\tif key == nil {\n+\t\tif gotKey == nil {\n \t\t\tr.Errorf(\"Returned nil key.\")\n \t\t}\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "texttospeech/synthesize_file/synthesize_file.go",
        "code_diff": "@@ -39,6 +39,7 @@\nfunc SynthesizeTextFile(w io.Writer, textFile, outputFile string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \ttext, err := ioutil.ReadFile(textFile)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "texttospeech/synthesize_text/synthesize_text.go",
        "code_diff": "@@ -38,6 +38,7 @@\nfunc SynthesizeText(w io.Writer, text, outputFile string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \treq := texttospeechpb.SynthesizeSpeechRequest{\n \t\tInput: &texttospeechpb.SynthesisInput{",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -33,6 +33,7 @@\nfunc label(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn fmt.Errorf(\"video.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tfileBytes, err := ioutil.ReadFile(file)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -89,6 +90,7 @@\nfunc shotChange(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \tfileBytes, err := ioutil.ReadFile(file)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -128,6 +130,7 @@\nfunc explicitContent(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \tfileBytes, err := ioutil.ReadFile(file)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -32,6 +32,7 @@\nfunc labelURI(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn fmt.Errorf(\"video.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \top, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{\n \t\tFeatures: []videopb.Feature{",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -85,6 +86,7 @@\nfunc shotChangeURI(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \top, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{\n \t\tFeatures: []videopb.Feature{",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -123,6 +125,7 @@\nfunc explicitContentURI(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \top, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{\n \t\tFeatures: []videopb.Feature{",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-tests-refactor",
        "commit_id": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "docs(appengine): add comment about authenticated push JWT token validation",
        "pr_number": 2059,
        "file_name": "appengine/go11x/pubsub/authenicated_push/main_test.go",
        "code_diff": "@@ -178,8 +178,8 @@\nfunc createRS256JWT(t *testing.T, email string, aud string) (string, rsa.PublicK\n // present in Cloud Pub/Sub JWT tokens.\n type ExtendedPayload struct {\n \tidtoken.Payload\n-\tEmail    string                 `json:\"email\"`\n-\tEmailVerified    bool           `json:\"email_verified\"`\n+\tEmail         string `json:\"email\"`\n+\tEmailVerified bool   `json:\"email_verified\"`\n }\n \n func createAuthToken(t *testing.T, email string, aud string) *jwt {",
        "comments": [],
        "commit_message": "chore: goimports",
        "commit_id": "eb8fe22b538e92bfcdd3306e83f34e1c6cf5570f"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "eventarc/audit_storage/main.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START eventarc_gcs_handler]\n+// [START eventarc_audit_storage_handler]\n \n // Sample audit_storage is a Cloud Run service which handles Cloud Audit Log events with Cloud Storage data.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "eventarc/audit_storage/main.go",
        "code_diff": "@@ -31,8 +31,8 @@\nfunc HelloEventsStorage(w http.ResponseWriter, r *http.Request) {\n \tfmt.Fprintln(w, s)\n }\n \n-// [END eventarc_gcs_handler]\n-// [START eventarc_gcs_server]\n+// [END eventarc_audit_storage_handler]\n+// [START eventarc_audit_storage_server]\n \n func main() {\n \thttp.HandleFunc(\"/\", HelloEventsStorage)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -24,13 +24,18 @@\npackage cloudrunci\n \n import (\n+\t\"context\"\n \t\"errors\"\n \t\"fmt\"\n \t\"net/http\"\n \t\"net/url\"\n \t\"os/exec\"\n \t\"path\"\n+\t\"strings\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/logging/logadmin\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n // labels are used in operation-related logs.",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -39,6 +39,8 @@\nconst (\n \ttestVideoFileName        = \"ChromeCast.mp4\"\n \ttestOverlayImageFileName = \"overlay.jpg\"\n \tpreset                   = \"preset/web-hd\"\n+\tsmallSpriteSheetFileName = \"small-sprite-sheet0000000000.jpeg\"\n+\tlargeSpriteSheetFileName = \"large-sprite-sheet0000000000.jpeg\"\n )\n \n // To run the tests, do the following:",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -63,6 +65,10 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \toutputURIForAdHoc := \"gs://\" + bucketName + \"/test-output-adhoc/\"\n \toutputURIForStaticOverlay := \"gs://\" + bucketName + \"/test-output-static-overlay/\"\n \toutputURIForAnimatedOverlay := \"gs://\" + bucketName + \"/test-output-animated-overlay/\"\n+\toutputDirForSetNumberSpritesheet := \"test-output-set-number-spritesheet/\"\n+\toutputURIForSetNumberSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForSetNumberSpritesheet\n+\toutputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n+\toutputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n \n \t// Get the project number\n \tcloudresourcemanagerClient, err := cloudresourcemanager.NewService(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -89,6 +95,18 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tt.Logf(\"\\ntestJobWithStaticOverlay() completed\\n\")\n \ttestJobWithAnimatedOverlay(t, projectNumber, inputURI, inputOverlayImageURI, outputURIForAnimatedOverlay)\n \tt.Logf(\"\\ntestJobWithAnimatedOverlay() completed\\n\")\n+\n+\ttestJobWithSetNumberImagesSpritesheet(t, projectNumber, inputURI, outputURIForSetNumberSpritesheet)\n+\tt.Logf(\"\\ntestJobWithSetNumberImagesSpritesheet() completed\\n\")\n+\t// Check if the spritesheets exist.\n+\tcheckGCSFileExists(t, bucketName, outputDirForSetNumberSpritesheet+smallSpriteSheetFileName)\n+\tcheckGCSFileExists(t, bucketName, outputDirForSetNumberSpritesheet+largeSpriteSheetFileName)\n+\n+\ttestJobWithPeriodicImagesSpritesheet(t, projectNumber, inputURI, outputURIForPeriodicSpritesheet)\n+\tt.Logf(\"\\ntestJobWithPeriodicImagesSpritesheet() completed\\n\")\n+\t// Check if the spritesheets exist.\n+\tcheckGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+smallSpriteSheetFileName)\n+\tcheckGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+largeSpriteSheetFileName)\n }\n \n // testJobTemplates tests major operations on job templates. Create, get,",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -180,6 +198,29 @@\nfunc writeTestGCSFile(t *testing.T, dstBucket string, srcBucket string, srcObjec\n \t}\n }\n \n+func checkGCSFileExists(t *testing.T, bucketName string, fileName string) {\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n+\n+\tobjAttrs, err := client.Bucket(bucketName).Object(fileName).Attrs(ctx)\n+\tif err == nil && objAttrs != nil {\n+\t\treturn\n+\t}\n+\tif err == storage.ErrObjectNotExist {\n+\t\tt.Fatalf(\"Spritesheet %q does not exist in bucket %q: %v\", fileName, bucketName, err)\n+\t}\n+\tif err != nil {\n+\t\tt.Fatalf(\"Error getting bucket attrs: %v\", err)\n+\t}\n+}\n+\n // testJobFromPreset tests major operations on a job created from a preset. It\n // will wait until the job successfully completes as part of the test.\n func testJobFromPreset(t *testing.T, projectNumber string, inputURI string, outputURIForPreset string) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -34,9 +34,8 @@\nimport (\n )\n \n const (\n-\ttopic      = \"test-topic-\"\n-\tsub        = \"test-sub-\"\n-\ttestRegion = \"us-central1\"\n+\tresourcePrefix = \"admin-test-\"\n+\ttestRegion     = \"us-central1\"\n )\n \n var (",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -71,7 +70,7 @@\nfunc setupAdmin(t *testing.T) *pubsublite.AdminClient {\n \n \t\tprojNumber = strconv.FormatInt(project.ProjectNumber, 10)\n \n-\t\tpsltest.Cleanup(t, client, projNumber, supportedZones)\n+\t\tpsltest.Cleanup(t, client, projNumber, resourcePrefix, supportedZones)\n \t})\n \n \treturn client",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -84,7 +83,7 @@\nfunc TestTopicAdmin(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \ttestZone := randomZone()\n \n-\ttopicID := topic + uuid.NewString()\n+\ttopicID := resourcePrefix + uuid.NewString()\n \ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \tt.Run(\"CreateTopic\", func(t *testing.T) {\n \t\tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -106,7 +105,7 @@\nfunc TestTopicAdmin(t *testing.T) {\n \t\t\tt.Fatalf(\"getTopic: %v\", err)\n \t\t}\n \t\tgot := buf.String()\n-\t\twant := fmt.Sprintf(\"Got topic: %#v\\n\", *defaultTopicConfig(topicPath))\n+\t\twant := fmt.Sprintf(\"Got topic: %#v\\n\", *psltest.DefaultTopicConfig(topicPath))\n \t\tif diff := cmp.Diff(want, got); diff != \"\" {\n \t\t\tt.Fatalf(\"getTopic() mismatch: -want, +got:\\n%s\", diff)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -161,10 +160,10 @@\nfunc TestListTopics(t *testing.T) {\n \n \tvar topicPaths []string\n \tfor i := 0; i < 3; i++ {\n-\t\ttopicID := topic + uuid.NewString()\n+\t\ttopicID := resourcePrefix + uuid.NewString()\n \t\ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \t\ttopicPaths = append(topicPaths, topicPath)\n-\t\tmustCreateTopic(ctx, t, client, topicPath)\n+\t\tpsltest.MustCreateTopic(ctx, t, client, topicPath)\n \t}\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -184,28 +183,6 @@\nfunc TestListTopics(t *testing.T) {\n \t}\n }\n \n-func mustCreateTopic(ctx context.Context, t *testing.T, client *pubsublite.AdminClient, topicPath string) *pubsublite.TopicConfig {\n-\tt.Helper()\n-\tcfg := defaultTopicConfig(topicPath)\n-\ttopicConfig, err := client.CreateTopic(ctx, *cfg)\n-\tif err != nil {\n-\t\tt.Fatalf(\"AdminClient.CreateTopic got err: %v\", err)\n-\t}\n-\treturn topicConfig\n-}\n-\n-func defaultTopicConfig(topicPath string) *pubsublite.TopicConfig {\n-\tcfg := &pubsublite.TopicConfig{\n-\t\tName:                       topicPath,\n-\t\tPartitionCount:             2,\n-\t\tPublishCapacityMiBPerSec:   4,\n-\t\tSubscribeCapacityMiBPerSec: 8,\n-\t\tPerPartitionBytes:          30 * 1024 * 1024 * 1024, // 30 GiB\n-\t\tRetentionDuration:          pubsublite.InfiniteRetention,\n-\t}\n-\treturn cfg\n-}\n-\n func TestSubscriptionAdmin(t *testing.T) {\n \tt.Parallel()\n \tclient := setupAdmin(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -214,12 +191,12 @@\nfunc TestSubscriptionAdmin(t *testing.T) {\n \tctx := context.Background()\n \ttestZone := randomZone()\n \n-\ttopicID := topic + uuid.NewString()\n+\ttopicID := resourcePrefix + uuid.NewString()\n \ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \n-\tmustCreateTopic(ctx, t, client, topicPath)\n+\tpsltest.MustCreateTopic(ctx, t, client, topicPath)\n \n-\tsubID := sub + uuid.NewString()\n+\tsubID := resourcePrefix + uuid.NewString()\n \tsubPath := fmt.Sprintf(\"projects/%s/locations/%s/subscriptions/%s\", projNumber, testZone, subID)\n \n \tt.Run(\"CreateSubscription\", func(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -242,7 +219,7 @@\nfunc TestSubscriptionAdmin(t *testing.T) {\n \t\t\tt.Fatalf(\"getSubscription: %v\", err)\n \t\t}\n \t\tgot := buf.String()\n-\t\twant := fmt.Sprintf(\"Got subscription: %#v\\n\", defaultSubConfig(topicPath, subPath))\n+\t\twant := fmt.Sprintf(\"Got subscription: %#v\\n\", psltest.DefaultSubConfig(topicPath, subPath))\n \t\tif diff := cmp.Diff(want, got); diff != \"\" {\n \t\t\tt.Fatalf(\"getSubscription mismatch: -want, +got:\\n%s\", diff)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -293,14 +270,14 @@\nfunc TestListSubscriptions(t *testing.T) {\n \ttestZone := randomZone()\n \n \tvar subPaths []string\n-\ttopicID := topic + uuid.NewString()\n+\ttopicID := resourcePrefix + uuid.NewString()\n \ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n-\tmustCreateTopic(ctx, t, client, topicPath)\n+\tpsltest.MustCreateTopic(ctx, t, client, topicPath)\n \n \tfor i := 0; i < 3; i++ {\n-\t\tsubID := sub + uuid.NewString()\n+\t\tsubID := resourcePrefix + uuid.NewString()\n \t\tsubPath := fmt.Sprintf(\"projects/%s/locations/%s/subscriptions/%s\", projNumber, testZone, subID)\n-\t\tmustCreateSubscription(ctx, t, client, topicPath, subPath)\n+\t\tpsltest.MustCreateSubscription(ctx, t, client, topicPath, subPath)\n \t\tsubPaths = append(subPaths, subPath)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage psltest\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"cloud.google.com/go/pubsublite\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -27,9 +28,12 @@\nimport (\n // Cleanup deletes all previous test topics/subscriptions from previous test\n // runs. This prevents previous test failures from building up resources that\n // count against quota.\n-func Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []string) {\n+func Cleanup(t *testing.T, client *pubsublite.AdminClient, proj, namePrefix string, zones []string) {\n \tctx := context.Background()\n \n+\ttopicSubstring := \"/topics/\" + namePrefix\n+\tsubscriptionSubstring := \"/subscriptions/\" + namePrefix\n+\n \tfor _, zone := range zones {\n \t\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", proj, zone)\n \t\ttopicIter := client.Topics(ctx, parent)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -41,6 +45,9 @@\nfunc Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []\n \t\t\tif err != nil {\n \t\t\t\tt.Fatalf(\"topicIter.Next got err: %v\", err)\n \t\t\t}\n+\t\t\tif !strings.Contains(topic.Name, topicSubstring) {\n+\t\t\t\tcontinue\n+\t\t\t}\n \t\t\tif err := client.DeleteTopic(ctx, topic.Name); err != nil {\n \t\t\t\tt.Fatalf(\"AdminClient.DeleteTopic got err: %v\", err)\n \t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -55,6 +62,9 @@\nfunc Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []\n \t\t\tif err != nil {\n \t\t\t\tt.Fatalf(\"subIter.Next() got err: %v\", err)\n \t\t\t}\n+\t\t\tif !strings.Contains(sub.Name, subscriptionSubstring) {\n+\t\t\t\tcontinue\n+\t\t\t}\n \t\t\tif err := client.DeleteSubscription(ctx, sub.Name); err != nil {\n \t\t\t\tt.Fatalf(\"AdminClient.DeleteSubscription got err: %v\", err)\n \t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -65,20 +75,22 @@\nfunc Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []\n // MustCreateTopic creates a Pub/Sub Lite topic and fails the test if\n // unsuccessful.\n func MustCreateTopic(ctx context.Context, t *testing.T, client *pubsublite.AdminClient, topicPath string) *pubsublite.TopicConfig {\n-\tcfg := defaultTopicConfig(topicPath)\n+\tt.Helper()\n+\tcfg := DefaultTopicConfig(topicPath)\n \ttopicConfig, err := client.CreateTopic(ctx, *cfg)\n \tif err != nil {\n \t\tt.Fatalf(\"AdminClient.CreateTopic got err: %v\", err)\n \t}\n \treturn topicConfig\n }\n \n-func defaultTopicConfig(topicPath string) *pubsublite.TopicConfig {\n+// DefaultTopicConfig returns the default topic config for tests.\n+func DefaultTopicConfig(topicPath string) *pubsublite.TopicConfig {\n \tcfg := &pubsublite.TopicConfig{\n \t\tName:                       topicPath,\n \t\tPartitionCount:             2,\n \t\tPublishCapacityMiBPerSec:   4,\n-\t\tSubscribeCapacityMiBPerSec: 4,\n+\t\tSubscribeCapacityMiBPerSec: 8,\n \t\tPerPartitionBytes:          30 * 1024 * 1024 * 1024, // 30 GiB\n \t\tRetentionDuration:          pubsublite.InfiniteRetention,\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "pubsublite/quickstart_publisher/main.go",
        "code_diff": "@@ -21,9 +21,11 @@\nimport (\n \t\"flag\"\n \t\"fmt\"\n \t\"log\"\n+\t\"sync\"\n \n \t\"cloud.google.com/go/pubsub\"\n \t\"cloud.google.com/go/pubsublite/pscompat\"\n+\t\"golang.org/x/sync/errgroup\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -26,15 +26,18 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \tinstance \"cloud.google.com/go/spanner/admin/instance/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n \t\"google.golang.org/api/iterator\"\n+\tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n \tinstancepb \"google.golang.org/genproto/googleapis/spanner/admin/instance/v1\"\n \t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n type sampleFunc func(w io.Writer, dbName string) error",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -412,6 +415,108 @@\nfunc TestCreateDatabaseWithRetentionPeriodSample(t *testing.T) {\n \tassertContains(t, out, fmt.Sprintf(\"Created database [%s] with version retention period %q\", dbName, wantRetentionPeriod))\n }\n \n+func TestCustomerManagedEncryptionKeys(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tdbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tadminClient, err := database.NewDatabaseAdminClient(context.Background())\n+\tif err != nil {\n+\t\tt.Errorf(\"failed to create admin client: %v\", err)\n+\t}\n+\n+\tvar b bytes.Buffer\n+\n+\tinstanceName := getInstance(t)\n+\tlocationId := \"us-central1\"\n+\tkeyRingId := \"spanner-test-keyring\"\n+\tkeyId := \"spanner-test-key\"\n+\n+\t// Create an encryption key if it does not already exist.\n+\tif err := maybeCreateKey(tc.ProjectID, locationId, keyRingId, keyId); err != nil {\n+\t\tt.Errorf(\"failed to create encryption key: %v\", err)\n+\t}\n+\tkmsKeyName := fmt.Sprintf(\n+\t\t\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\",\n+\t\ttc.ProjectID,\n+\t\tlocationId,\n+\t\tkeyRingId,\n+\t\tkeyId,\n+\t)\n+\n+\t// Create an encrypted database. The database is automatically deleted by the cleanup function.\n+\tif err := createDatabaseWithCustomerManagedEncryptionKey(&b, dbName, kmsKeyName); err != nil {\n+\t\tt.Errorf(\"failed to create database with customer managed encryption key: %v\", err)\n+\t}\n+\tout := b.String()\n+\tassertContains(t, out, fmt.Sprintf(\"Created database [%s] using encryption key %q\", dbName, kmsKeyName))\n+\n+\t// Try to create a backup of the encrypted database and delete it after the test.\n+\tbackupId := fmt.Sprintf(\"enc-backup-%s\", randomID())\n+\tdefer func() {\n+\t\t_ = adminClient.DeleteBackup(context.Background(), &adminpb.DeleteBackupRequest{\n+\t\t\tName: fmt.Sprintf(\"%s/backups/%s\", instanceName, backupId),\n+\t\t})\n+\t}()\n+\tb.Reset()\n+\tif err := createBackupWithCustomerManagedEncryptionKey(&b, dbName, backupId, kmsKeyName); err != nil {\n+\t\tt.Errorf(\"failed to create backup with customer managed encryption key: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, fmt.Sprintf(\"backups/%s\", backupId))\n+\tassertContains(t, out, fmt.Sprintf(\"using encryption key %s\", kmsKeyName))\n+\n+\t// Try to restore the encrypted database and delete the restored database after the test.\n+\trestoredName := fmt.Sprintf(\"%s/databases/rest-enc-%s\", instanceName, randomID())\n+\tdefer func() {\n+\t\t_ = adminClient.DropDatabase(context.Background(), &adminpb.DropDatabaseRequest{\n+\t\t\tDatabase: restoredName,\n+\t\t})\n+\t}()\n+\trestoreFunc := func(w io.Writer, dbName, backupID string) error {\n+\t\treturn restoreBackupWithCustomerManagedEncryptionKey(w, dbName, backupId, kmsKeyName)\n+\t}\n+\tout = runBackupSampleWithRetry(t, restoreFunc, restoredName, backupId, \"failed to restore database with customer managed encryption key\", 10)\n+\tassertContains(t, out, fmt.Sprintf(\"Database %s restored\", dbName))\n+\tassertContains(t, out, fmt.Sprintf(\"using encryption key %s\", kmsKeyName))\n+}\n+\n+func maybeCreateKey(projectId, locationId, keyRingId, keyId string) error {\n+\tclient, err := kms.NewKeyManagementClient(context.Background())\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Try to create a key ring\n+\tcreateKeyRingRequest := kmspb.CreateKeyRingRequest{\n+\t\tParent:    fmt.Sprintf(\"projects/%s/locations/%s\", projectId, locationId),\n+\t\tKeyRingId: keyRingId,\n+\t\tKeyRing:   &kmspb.KeyRing{},\n+\t}\n+\t_, err = client.CreateKeyRing(context.Background(), &createKeyRingRequest)\n+\tif err != nil {\n+\t\tif status, ok := status.FromError(err); !ok || status.Code() != codes.AlreadyExists {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\t// Try to create a key\n+\tcreateKeyRequest := kmspb.CreateCryptoKeyRequest{\n+\t\tParent:      fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s\", projectId, locationId, keyRingId),\n+\t\tCryptoKeyId: keyId,\n+\t\tCryptoKey: &kmspb.CryptoKey{\n+\t\t\tPurpose: kmspb.CryptoKey_ENCRYPT_DECRYPT,\n+\t\t},\n+\t}\n+\t_, err = client.CreateCryptoKey(context.Background(), &createKeyRequest)\n+\tif err != nil {\n+\t\tif status, ok := status.FromError(err); !ok || status.Code() != codes.AlreadyExists {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n func runSample(t *testing.T, f sampleFunc, dbName, errMsg string) string {\n \tvar b bytes.Buffer\n \tif err := f(&b, dbName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bradmiro-patch-1",
        "commit_id": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "chore: add IoT entry to CODEOWNERS",
        "pr_number": 2028,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -26,15 +26,18 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \tinstance \"cloud.google.com/go/spanner/admin/instance/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n \t\"google.golang.org/api/iterator\"\n+\tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n \tinstancepb \"google.golang.org/genproto/googleapis/spanner/admin/instance/v1\"\n \t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n type sampleFunc func(w io.Writer, dbName string) error",
        "comments": [],
        "commit_message": "Merge branch 'master' into munkhuushmgl-patch-1",
        "commit_id": "08fee44bf703aa1345dee0ed9600ff09c154f1ad"
    },
    {
        "pr_title": "chore: add IoT entry to CODEOWNERS",
        "pr_number": 2028,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -412,6 +415,108 @@\nfunc TestCreateDatabaseWithRetentionPeriodSample(t *testing.T) {\n \tassertContains(t, out, fmt.Sprintf(\"Created database [%s] with version retention period %q\", dbName, wantRetentionPeriod))\n }\n \n+func TestCustomerManagedEncryptionKeys(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tdbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tadminClient, err := database.NewDatabaseAdminClient(context.Background())\n+\tif err != nil {\n+\t\tt.Errorf(\"failed to create admin client: %v\", err)\n+\t}\n+\n+\tvar b bytes.Buffer\n+\n+\tinstanceName := getInstance(t)\n+\tlocationId := \"us-central1\"\n+\tkeyRingId := \"spanner-test-keyring\"\n+\tkeyId := \"spanner-test-key\"\n+\n+\t// Create an encryption key if it does not already exist.\n+\tif err := maybeCreateKey(tc.ProjectID, locationId, keyRingId, keyId); err != nil {\n+\t\tt.Errorf(\"failed to create encryption key: %v\", err)\n+\t}\n+\tkmsKeyName := fmt.Sprintf(\n+\t\t\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\",\n+\t\ttc.ProjectID,\n+\t\tlocationId,\n+\t\tkeyRingId,\n+\t\tkeyId,\n+\t)\n+\n+\t// Create an encrypted database. The database is automatically deleted by the cleanup function.\n+\tif err := createDatabaseWithCustomerManagedEncryptionKey(&b, dbName, kmsKeyName); err != nil {\n+\t\tt.Errorf(\"failed to create database with customer managed encryption key: %v\", err)\n+\t}\n+\tout := b.String()\n+\tassertContains(t, out, fmt.Sprintf(\"Created database [%s] using encryption key %q\", dbName, kmsKeyName))\n+\n+\t// Try to create a backup of the encrypted database and delete it after the test.\n+\tbackupId := fmt.Sprintf(\"enc-backup-%s\", randomID())\n+\tdefer func() {\n+\t\t_ = adminClient.DeleteBackup(context.Background(), &adminpb.DeleteBackupRequest{\n+\t\t\tName: fmt.Sprintf(\"%s/backups/%s\", instanceName, backupId),\n+\t\t})\n+\t}()\n+\tb.Reset()\n+\tif err := createBackupWithCustomerManagedEncryptionKey(&b, dbName, backupId, kmsKeyName); err != nil {\n+\t\tt.Errorf(\"failed to create backup with customer managed encryption key: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, fmt.Sprintf(\"backups/%s\", backupId))\n+\tassertContains(t, out, fmt.Sprintf(\"using encryption key %s\", kmsKeyName))\n+\n+\t// Try to restore the encrypted database and delete the restored database after the test.\n+\trestoredName := fmt.Sprintf(\"%s/databases/rest-enc-%s\", instanceName, randomID())\n+\tdefer func() {\n+\t\t_ = adminClient.DropDatabase(context.Background(), &adminpb.DropDatabaseRequest{\n+\t\t\tDatabase: restoredName,\n+\t\t})\n+\t}()\n+\trestoreFunc := func(w io.Writer, dbName, backupID string) error {\n+\t\treturn restoreBackupWithCustomerManagedEncryptionKey(w, dbName, backupId, kmsKeyName)\n+\t}\n+\tout = runBackupSampleWithRetry(t, restoreFunc, restoredName, backupId, \"failed to restore database with customer managed encryption key\", 10)\n+\tassertContains(t, out, fmt.Sprintf(\"Database %s restored\", dbName))\n+\tassertContains(t, out, fmt.Sprintf(\"using encryption key %s\", kmsKeyName))\n+}\n+\n+func maybeCreateKey(projectId, locationId, keyRingId, keyId string) error {\n+\tclient, err := kms.NewKeyManagementClient(context.Background())\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Try to create a key ring\n+\tcreateKeyRingRequest := kmspb.CreateKeyRingRequest{\n+\t\tParent:    fmt.Sprintf(\"projects/%s/locations/%s\", projectId, locationId),\n+\t\tKeyRingId: keyRingId,\n+\t\tKeyRing:   &kmspb.KeyRing{},\n+\t}\n+\t_, err = client.CreateKeyRing(context.Background(), &createKeyRingRequest)\n+\tif err != nil {\n+\t\tif status, ok := status.FromError(err); !ok || status.Code() != codes.AlreadyExists {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\t// Try to create a key\n+\tcreateKeyRequest := kmspb.CreateCryptoKeyRequest{\n+\t\tParent:      fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s\", projectId, locationId, keyRingId),\n+\t\tCryptoKeyId: keyId,\n+\t\tCryptoKey: &kmspb.CryptoKey{\n+\t\t\tPurpose: kmspb.CryptoKey_ENCRYPT_DECRYPT,\n+\t\t},\n+\t}\n+\t_, err = client.CreateCryptoKey(context.Background(), &createKeyRequest)\n+\tif err != nil {\n+\t\tif status, ok := status.FromError(err); !ok || status.Code() != codes.AlreadyExists {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n func runSample(t *testing.T, f sampleFunc, dbName, errMsg string) string {\n \tvar b bytes.Buffer\n \tif err := f(&b, dbName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into munkhuushmgl-patch-1",
        "commit_id": "08fee44bf703aa1345dee0ed9600ff09c154f1ad"
    },
    {
        "pr_title": "feat: add samples for CMEK with Spanner",
        "pr_number": 2001,
        "file_name": "pubsublite/quickstart_publisher/main.go",
        "code_diff": "@@ -21,9 +21,11 @@\nimport (\n \t\"flag\"\n \t\"fmt\"\n \t\"log\"\n+\t\"sync\"\n \n \t\"cloud.google.com/go/pubsub\"\n \t\"cloud.google.com/go/pubsublite/pscompat\"\n+\t\"golang.org/x/sync/errgroup\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner-cmek-samples",
        "commit_id": "7d31c309c2d7ec0c41b8373726b65016391a550e"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "eventarc/audit_storage/main.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START eventarc_gcs_handler]\n+// [START eventarc_audit_storage_handler]\n \n // Sample audit_storage is a Cloud Run service which handles Cloud Audit Log events with Cloud Storage data.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "eventarc/audit_storage/main.go",
        "code_diff": "@@ -31,8 +31,8 @@\nfunc HelloEventsStorage(w http.ResponseWriter, r *http.Request) {\n \tfmt.Fprintln(w, s)\n }\n \n-// [END eventarc_gcs_handler]\n-// [START eventarc_gcs_server]\n+// [END eventarc_audit_storage_handler]\n+// [START eventarc_audit_storage_server]\n \n func main() {\n \thttp.HandleFunc(\"/\", HelloEventsStorage)",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -34,9 +34,8 @@\nimport (\n )\n \n const (\n-\ttopic      = \"test-topic-\"\n-\tsub        = \"test-sub-\"\n-\ttestRegion = \"us-central1\"\n+\tresourcePrefix = \"admin-test-\"\n+\ttestRegion     = \"us-central1\"\n )\n \n var (",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -71,7 +70,7 @@\nfunc setupAdmin(t *testing.T) *pubsublite.AdminClient {\n \n \t\tprojNumber = strconv.FormatInt(project.ProjectNumber, 10)\n \n-\t\tpsltest.Cleanup(t, client, projNumber, supportedZones)\n+\t\tpsltest.Cleanup(t, client, projNumber, resourcePrefix, supportedZones)\n \t})\n \n \treturn client",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -84,7 +83,7 @@\nfunc TestTopicAdmin(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \ttestZone := randomZone()\n \n-\ttopicID := topic + uuid.NewString()\n+\ttopicID := resourcePrefix + uuid.NewString()\n \ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \tt.Run(\"CreateTopic\", func(t *testing.T) {\n \t\tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -106,7 +105,7 @@\nfunc TestTopicAdmin(t *testing.T) {\n \t\t\tt.Fatalf(\"getTopic: %v\", err)\n \t\t}\n \t\tgot := buf.String()\n-\t\twant := fmt.Sprintf(\"Got topic: %#v\\n\", *defaultTopicConfig(topicPath))\n+\t\twant := fmt.Sprintf(\"Got topic: %#v\\n\", *psltest.DefaultTopicConfig(topicPath))\n \t\tif diff := cmp.Diff(want, got); diff != \"\" {\n \t\t\tt.Fatalf(\"getTopic() mismatch: -want, +got:\\n%s\", diff)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -161,10 +160,10 @@\nfunc TestListTopics(t *testing.T) {\n \n \tvar topicPaths []string\n \tfor i := 0; i < 3; i++ {\n-\t\ttopicID := topic + uuid.NewString()\n+\t\ttopicID := resourcePrefix + uuid.NewString()\n \t\ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \t\ttopicPaths = append(topicPaths, topicPath)\n-\t\tmustCreateTopic(ctx, t, client, topicPath)\n+\t\tpsltest.MustCreateTopic(ctx, t, client, topicPath)\n \t}\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -184,28 +183,6 @@\nfunc TestListTopics(t *testing.T) {\n \t}\n }\n \n-func mustCreateTopic(ctx context.Context, t *testing.T, client *pubsublite.AdminClient, topicPath string) *pubsublite.TopicConfig {\n-\tt.Helper()\n-\tcfg := defaultTopicConfig(topicPath)\n-\ttopicConfig, err := client.CreateTopic(ctx, *cfg)\n-\tif err != nil {\n-\t\tt.Fatalf(\"AdminClient.CreateTopic got err: %v\", err)\n-\t}\n-\treturn topicConfig\n-}\n-\n-func defaultTopicConfig(topicPath string) *pubsublite.TopicConfig {\n-\tcfg := &pubsublite.TopicConfig{\n-\t\tName:                       topicPath,\n-\t\tPartitionCount:             2,\n-\t\tPublishCapacityMiBPerSec:   4,\n-\t\tSubscribeCapacityMiBPerSec: 8,\n-\t\tPerPartitionBytes:          30 * 1024 * 1024 * 1024, // 30 GiB\n-\t\tRetentionDuration:          pubsublite.InfiniteRetention,\n-\t}\n-\treturn cfg\n-}\n-\n func TestSubscriptionAdmin(t *testing.T) {\n \tt.Parallel()\n \tclient := setupAdmin(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -214,12 +191,12 @@\nfunc TestSubscriptionAdmin(t *testing.T) {\n \tctx := context.Background()\n \ttestZone := randomZone()\n \n-\ttopicID := topic + uuid.NewString()\n+\ttopicID := resourcePrefix + uuid.NewString()\n \ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \n-\tmustCreateTopic(ctx, t, client, topicPath)\n+\tpsltest.MustCreateTopic(ctx, t, client, topicPath)\n \n-\tsubID := sub + uuid.NewString()\n+\tsubID := resourcePrefix + uuid.NewString()\n \tsubPath := fmt.Sprintf(\"projects/%s/locations/%s/subscriptions/%s\", projNumber, testZone, subID)\n \n \tt.Run(\"CreateSubscription\", func(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -242,7 +219,7 @@\nfunc TestSubscriptionAdmin(t *testing.T) {\n \t\t\tt.Fatalf(\"getSubscription: %v\", err)\n \t\t}\n \t\tgot := buf.String()\n-\t\twant := fmt.Sprintf(\"Got subscription: %#v\\n\", defaultSubConfig(topicPath, subPath))\n+\t\twant := fmt.Sprintf(\"Got subscription: %#v\\n\", psltest.DefaultSubConfig(topicPath, subPath))\n \t\tif diff := cmp.Diff(want, got); diff != \"\" {\n \t\t\tt.Fatalf(\"getSubscription mismatch: -want, +got:\\n%s\", diff)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -293,14 +270,14 @@\nfunc TestListSubscriptions(t *testing.T) {\n \ttestZone := randomZone()\n \n \tvar subPaths []string\n-\ttopicID := topic + uuid.NewString()\n+\ttopicID := resourcePrefix + uuid.NewString()\n \ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n-\tmustCreateTopic(ctx, t, client, topicPath)\n+\tpsltest.MustCreateTopic(ctx, t, client, topicPath)\n \n \tfor i := 0; i < 3; i++ {\n-\t\tsubID := sub + uuid.NewString()\n+\t\tsubID := resourcePrefix + uuid.NewString()\n \t\tsubPath := fmt.Sprintf(\"projects/%s/locations/%s/subscriptions/%s\", projNumber, testZone, subID)\n-\t\tmustCreateSubscription(ctx, t, client, topicPath, subPath)\n+\t\tpsltest.MustCreateSubscription(ctx, t, client, topicPath, subPath)\n \t\tsubPaths = append(subPaths, subPath)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage psltest\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"cloud.google.com/go/pubsublite\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -27,9 +28,12 @@\nimport (\n // Cleanup deletes all previous test topics/subscriptions from previous test\n // runs. This prevents previous test failures from building up resources that\n // count against quota.\n-func Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []string) {\n+func Cleanup(t *testing.T, client *pubsublite.AdminClient, proj, namePrefix string, zones []string) {\n \tctx := context.Background()\n \n+\ttopicSubstring := \"/topics/\" + namePrefix\n+\tsubscriptionSubstring := \"/subscriptions/\" + namePrefix\n+\n \tfor _, zone := range zones {\n \t\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", proj, zone)\n \t\ttopicIter := client.Topics(ctx, parent)",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -41,6 +45,9 @@\nfunc Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []\n \t\t\tif err != nil {\n \t\t\t\tt.Fatalf(\"topicIter.Next got err: %v\", err)\n \t\t\t}\n+\t\t\tif !strings.Contains(topic.Name, topicSubstring) {\n+\t\t\t\tcontinue\n+\t\t\t}\n \t\t\tif err := client.DeleteTopic(ctx, topic.Name); err != nil {\n \t\t\t\tt.Fatalf(\"AdminClient.DeleteTopic got err: %v\", err)\n \t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -55,6 +62,9 @@\nfunc Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []\n \t\t\tif err != nil {\n \t\t\t\tt.Fatalf(\"subIter.Next() got err: %v\", err)\n \t\t\t}\n+\t\t\tif !strings.Contains(sub.Name, subscriptionSubstring) {\n+\t\t\t\tcontinue\n+\t\t\t}\n \t\t\tif err := client.DeleteSubscription(ctx, sub.Name); err != nil {\n \t\t\t\tt.Fatalf(\"AdminClient.DeleteSubscription got err: %v\", err)\n \t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -65,20 +75,22 @@\nfunc Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []\n // MustCreateTopic creates a Pub/Sub Lite topic and fails the test if\n // unsuccessful.\n func MustCreateTopic(ctx context.Context, t *testing.T, client *pubsublite.AdminClient, topicPath string) *pubsublite.TopicConfig {\n-\tcfg := defaultTopicConfig(topicPath)\n+\tt.Helper()\n+\tcfg := DefaultTopicConfig(topicPath)\n \ttopicConfig, err := client.CreateTopic(ctx, *cfg)\n \tif err != nil {\n \t\tt.Fatalf(\"AdminClient.CreateTopic got err: %v\", err)\n \t}\n \treturn topicConfig\n }\n \n-func defaultTopicConfig(topicPath string) *pubsublite.TopicConfig {\n+// DefaultTopicConfig returns the default topic config for tests.\n+func DefaultTopicConfig(topicPath string) *pubsublite.TopicConfig {\n \tcfg := &pubsublite.TopicConfig{\n \t\tName:                       topicPath,\n \t\tPartitionCount:             2,\n \t\tPublishCapacityMiBPerSec:   4,\n-\t\tSubscribeCapacityMiBPerSec: 4,\n+\t\tSubscribeCapacityMiBPerSec: 8,\n \t\tPerPartitionBytes:          30 * 1024 * 1024 * 1024, // 30 GiB\n \t\tRetentionDuration:          pubsublite.InfiniteRetention,\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into spritesheet",
        "commit_id": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "automl/operation_status_get.go",
        "code_diff": "@@ -22,14 +22,15 @@\nimport (\n \t\"io\"\n \n \tautoml \"cloud.google.com/go/automl/apiv1\"\n-\t\"google.golang.org/genproto/googleapis/longrunning\"\n+\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1\"\n )\n \n // getOperationStatus gets an operation's status.\n-func getOperationStatus(w io.Writer, projectID string, location string, operationID string) error {\n+func getOperationStatus(w io.Writer, projectID string, location string, datasetID string, modelName string) error {\n \t// projectID := \"my-project-id\"\n \t// location := \"us-central1\"\n-\t// operationID := \"TRL123456789...\"\n+\t// datasetID := \"ICN123456789...\"\n+\t// modelName := \"model_display_name\"\n \n \tctx := context.Background()\n \tclient, err := automl.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "cloudsql/mysql/database-sql/cloudsql_test.go",
        "code_diff": "@@ -22,20 +22,50 @@\nimport (\n \t\"testing\"\n )\n \n+type testInfo struct {\n+\tdbName                 string\n+\tdbPass                 string\n+\tdbUser                 string\n+\tdbPort                 string\n+\tinstanceConnectionName string\n+}\n+\n func TestIndex(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"MYSQL_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"MYSQL_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"MYSQL_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"MYSQL_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"MYSQL_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"MYSQL_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "cloudsql/mysql/database-sql/cloudsql_test.go",
        "code_diff": "@@ -54,22 +84,52 @@\nfunc TestIndex(t *testing.T) {\n \t\t}\n \t\tos.Setenv(\"DB_HOST\", oldDBHost)\n \t}\n+\t// Restore original values\n+\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\tos.Setenv(\"DB_NAME\", oldDBName)\n+\tos.Setenv(\"DB_PASS\", oldDBPass)\n+\tos.Setenv(\"DB_PORT\", oldDBPort)\n+\tos.Setenv(\"DB_USER\", oldDBUser)\n+\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", oldInstance)\n }\n \n func TestCastVote(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"MYSQL_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"MYSQL_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"MYSQL_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"MYSQL_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"MYSQL_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"MYSQL_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "cloudsql/postgres/database-sql/cloudsql_test.go",
        "code_diff": "@@ -22,20 +22,51 @@\nimport (\n \t\"testing\"\n )\n \n+type testInfo struct {\n+\tdbName                 string\n+\tdbPass                 string\n+\tdbUser                 string\n+\tdbPort                 string\n+\tinstanceConnectionName string\n+}\n+\n func TestIndex(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"POSTGRES_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"POSTGRES_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"POSTGRES_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"POSTGRES_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"POSTGRES_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"POSTGRES_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "cloudsql/postgres/database-sql/cloudsql_test.go",
        "code_diff": "@@ -52,24 +83,54 @@\nfunc TestIndex(t *testing.T) {\n \t\tif !strings.Contains(body, want) {\n \t\t\tt.Errorf(\"With dbHost='%s', expected to see '%s' in indexHandler response body\", test.dbHost, want)\n \t\t}\n-\t\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\n \t}\n+\t// Restore original values\n+\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\tos.Setenv(\"DB_NAME\", oldDBName)\n+\tos.Setenv(\"DB_PASS\", oldDBPass)\n+\tos.Setenv(\"DB_PORT\", oldDBPort)\n+\tos.Setenv(\"DB_USER\", oldDBUser)\n+\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", oldInstance)\n }\n \n func TestCastVote(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"POSTGRES_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"POSTGRES_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"POSTGRES_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"POSTGRES_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"POSTGRES_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"POSTGRES_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql_test.go",
        "code_diff": "@@ -22,19 +22,49 @@\nimport (\n \t\"testing\"\n )\n \n+type testInfo struct {\n+\tdbName                 string\n+\tdbPass                 string\n+\tdbUser                 string\n+\tdbPort                 string\n+\tinstanceConnectionName string\n+}\n+\n func TestIndex(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"SQLSERVER_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"SQLSERVER_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"SQLSERVER_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"SQLSERVER_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"SQLSERVER_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"SQLSERVER_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql_test.go",
        "code_diff": "@@ -53,21 +83,50 @@\nfunc TestIndex(t *testing.T) {\n \t\t}\n \t\tos.Setenv(\"DB_HOST\", oldDBHost)\n \t}\n+\t// Restore original values\n+\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\tos.Setenv(\"DB_NAME\", oldDBName)\n+\tos.Setenv(\"DB_PASS\", oldDBPass)\n+\tos.Setenv(\"DB_PORT\", oldDBPort)\n+\tos.Setenv(\"DB_USER\", oldDBUser)\n+\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", oldInstance)\n }\n \n func TestCastVote(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"SQLSERVER_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"SQLSERVER_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"SQLSERVER_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"SQLSERVER_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"SQLSERVER_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"SQLSERVER_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "feat(datacatalog): add a quickstart for datacatalog",
        "pr_number": 1979,
        "file_name": "datacatalog/datacatalog_quickstart/main.go",
        "code_diff": "@@ -32,12 +32,9 @@\nimport (\n )\n \n func main() {\n-\n-\tvar (\n-\t\tprojectID = flag.String(\"project_id\", \"\", \"Cloud Project ID, used for session creation.\")\n-\t\tlocation  = flag.String(\"location\", \"us-central1\", \"data catalog region to use for the quickstart\")\n-\t\ttable     = flag.String(\"table\", \"myproject.mydataset.mytable\", \"bigquery table to tag in project.dataset.table format\")\n-\t)\n+\tprojectID := flag.String(\"project_id\", \"\", \"Cloud Project ID, used for session creation.\")\n+\tlocation := flag.String(\"location\", \"us-central1\", \"data catalog region to use for the quickstart\")\n+\ttable := flag.String(\"table\", \"myproject.mydataset.mytable\", \"bigquery table to tag in project.dataset.table format\")\n \n \tflag.Parse()",
        "comments": [
            {
                "comment": "Delete.",
                "position": null
            },
            {
                "comment": "Any particular reason to use a `var` group instead of `:=`?",
                "position": null
            },
            {
                "comment": "Include the bad string?",
                "position": null
            },
            {
                "comment": "Mostly a carryover from idioms when they're globals.  Removed the var group.",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            }
        ],
        "commit_message": "address reviewer comments",
        "commit_id": "1e2ee82a27e8d3f72dc6bb0bc023d916097f57d3"
    },
    {
        "pr_title": "feat(datacatalog): add a quickstart for datacatalog",
        "pr_number": 1979,
        "file_name": "datacatalog/datacatalog_quickstart/main.go",
        "code_diff": "@@ -78,9 +75,7 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"couldn't create tag: %v\", err)\n \t}\n-\n \tfmt.Printf(\"Created tag: %s\", tag.GetName())\n-\n }\n \n // createQuickstartTagTemplate registers a tag template in datacatalog.",
        "comments": [
            {
                "comment": "Delete.",
                "position": null
            },
            {
                "comment": "Any particular reason to use a `var` group instead of `:=`?",
                "position": null
            },
            {
                "comment": "Include the bad string?",
                "position": null
            },
            {
                "comment": "Mostly a carryover from idioms when they're globals.  Removed the var group.",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            }
        ],
        "commit_message": "address reviewer comments",
        "commit_id": "1e2ee82a27e8d3f72dc6bb0bc023d916097f57d3"
    },
    {
        "pr_title": "feat(datacatalog): add a quickstart for datacatalog",
        "pr_number": 1979,
        "file_name": "datacatalog/datacatalog_quickstart/main.go",
        "code_diff": "@@ -143,7 +138,6 @@\nfunc createQuickstartTagTemplate(ctx context.Context, client *datacatalog.Client\n \t// To aid testing, we add some uniqueness to the template ID.\n \treq.TagTemplateId = fmt.Sprintf(\"%s_%d\", req.GetTagTemplateId(), time.Now().UnixNano())\n \t// [START data_catalog_quickstart]\n-\n \treturn client.CreateTagTemplate(ctx, req)\n \n }",
        "comments": [
            {
                "comment": "Delete.",
                "position": null
            },
            {
                "comment": "Any particular reason to use a `var` group instead of `:=`?",
                "position": null
            },
            {
                "comment": "Include the bad string?",
                "position": null
            },
            {
                "comment": "Mostly a carryover from idioms when they're globals.  Removed the var group.",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            }
        ],
        "commit_message": "address reviewer comments",
        "commit_id": "1e2ee82a27e8d3f72dc6bb0bc023d916097f57d3"
    },
    {
        "pr_title": "feat(datacatalog): add a quickstart for datacatalog",
        "pr_number": 1979,
        "file_name": "datacatalog/datacatalog_quickstart/main.go",
        "code_diff": "@@ -178,7 +172,6 @@\nfunc createQuickstartTag(ctx context.Context, client *datacatalog.Client, tagID,\n \t\tParent: entryName,\n \t\tTag:    tag,\n \t}\n-\n \treturn client.CreateTag(ctx, req)\n }",
        "comments": [
            {
                "comment": "Delete.",
                "position": null
            },
            {
                "comment": "Any particular reason to use a `var` group instead of `:=`?",
                "position": null
            },
            {
                "comment": "Include the bad string?",
                "position": null
            },
            {
                "comment": "Mostly a carryover from idioms when they're globals.  Removed the var group.",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            }
        ],
        "commit_message": "address reviewer comments",
        "commit_id": "1e2ee82a27e8d3f72dc6bb0bc023d916097f57d3"
    },
    {
        "pr_title": "samples(pubsublite): add admin samples for lite",
        "pr_number": 1977,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -27,10 +27,10 @@\nimport (\n \n \t\"cloud.google.com/go/pubsublite\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/pubsublite/internal/psltest\"\n \t\"github.com/google/go-cmp/cmp\"\n \t\"github.com/google/uuid\"\n \t\"google.golang.org/api/cloudresourcemanager/v1\"\n-\t\"google.golang.org/api/iterator\"\n )\n \n const (",
        "comments": [],
        "commit_message": "switch to psltest util for cleanup",
        "commit_id": "d1d4e87aae0e7f60be25b71de2ca706906ee55b3"
    },
    {
        "pr_title": "samples(pubsublite): add admin samples for lite",
        "pr_number": 1977,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -40,7 +40,7 @@\nconst (\n )\n \n var (\n-\tsupportedZoneIDs = []string{\"a\", \"b\", \"c\"}\n+\tsupportedZones = []string{\"us-central1-a\", \"us-central1-b\", \"us-central1-c\"}\n \n \tonce       sync.Once\n \tprojNumber string",
        "comments": [],
        "commit_message": "switch to psltest util for cleanup",
        "commit_id": "d1d4e87aae0e7f60be25b71de2ca706906ee55b3"
    },
    {
        "pr_title": "samples(pubsublite): add admin samples for lite",
        "pr_number": 1977,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -71,51 +71,12 @@\nfunc setupAdmin(t *testing.T) *pubsublite.AdminClient {\n \n \t\tprojNumber = strconv.FormatInt(project.ProjectNumber, 10)\n \n-\t\tcleanup(t, client, projNumber)\n+\t\tpsltest.Cleanup(t, client, projNumber, supportedZones)\n \t})\n \n \treturn client\n }\n \n-// cleanup deletes all previous test topics/subscriptions from\n-// previous test runs. This prevents previous test failures\n-// from building up resources that count against quota.\n-func cleanup(t *testing.T, client *pubsublite.AdminClient, proj string) {\n-\tctx := context.Background()\n-\n-\tfor _, zoneID := range supportedZoneIDs {\n-\t\tzone := fmt.Sprintf(\"%s-%s\", testRegion, zoneID)\n-\t\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", proj, zone)\n-\t\ttopicIter := client.Topics(ctx, parent)\n-\t\tfor {\n-\t\t\ttopic, err := topicIter.Next()\n-\t\t\tif err == iterator.Done {\n-\t\t\t\tbreak\n-\t\t\t}\n-\t\t\tif err != nil {\n-\t\t\t\tt.Fatalf(\"topicIter.Next got err: %v\", err)\n-\t\t\t}\n-\t\t\tif err := client.DeleteTopic(ctx, topic.Name); err != nil {\n-\t\t\t\tt.Fatalf(\"client.DeleteTopic got err: %v\", err)\n-\t\t\t}\n-\t\t}\n-\n-\t\tsubIter := client.Subscriptions(ctx, parent)\n-\t\tfor {\n-\t\t\tsub, err := subIter.Next()\n-\t\t\tif err == iterator.Done {\n-\t\t\t\tbreak\n-\t\t\t}\n-\t\t\tif err != nil {\n-\t\t\t\tt.Fatalf(\"subIter.Next() got err: %v\", err)\n-\t\t\t}\n-\t\t\tif err := client.DeleteSubscription(ctx, sub.Name); err != nil {\n-\t\t\t\tt.Fatalf(\"client.DeleteSubscription got err: %v\", err)\n-\t\t\t}\n-\t\t}\n-\t}\n-}\n-\n func TestTopicAdmin(t *testing.T) {\n \tt.Parallel()\n \tclient := setupAdmin(t)",
        "comments": [],
        "commit_message": "switch to psltest util for cleanup",
        "commit_id": "d1d4e87aae0e7f60be25b71de2ca706906ee55b3"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/assets/add_delete_security_marks.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_add_delete_security_marks]\n-// [START add_delete_security_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/assets/add_security_marks.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_add_security_marks]\n-// [START add_security_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/assets/delete_security_marks.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_delete_security_marks]\n-// [START delete_security_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/assets/list_all_assets.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_list_all_assets]\n-// [START list_all_assets]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/assets/list_all_project_assets.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_list_assets_with_filter]\n-// [START list_project_assets]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/assets/list_assets_with_security_marks.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_list_assets_with_security_marks]\n-// [START list_assets_with_security_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/assets/list_project_assets_and_state_changes.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_list_assets_and_changes]\n-// [START list_project_assets_and_state_changes]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/assets/list_project_assets_at_time.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_list_assets_at_time]\n-// [START list_project_assets_at_time]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/add_security_marks.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_add_finding_security_marks]\n-// [START add_security_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/create_finding.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_create_finding]\n-// [START create_finding]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/create_finding_with_source_properties.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_create_finding_with_source_properties]\n-// [START create_finding_with_source_properties]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/create_source.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_create_source]\n-// [START create_source]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/get_source.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_get_source]\n-// [START get_source]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/get_source_iam.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_get_source_iam]\n-// [START get_iam_policy_source]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/list_all_findings.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_list_all_findings]\n-// [START list_all_findings]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/list_filtered_findings.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_list_filtered_findings]\n-// [START list_filtered_findings]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/list_findings_at_time.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_list_findings_at_time]\n-// [START list_findings_at_time]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/list_findings_with_security_mark.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_list_findings_with_security_marks]\n-// [START list_findings_with_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/list_sources.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_list_sources]\n-// [START list_sources]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/set_finding_state.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_update_finding_state]\n-// [START set_finding_state]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/set_source_iam.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_set_source_iam]\n-// [START set_iam_policy_source]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/test_iam.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_test_iam]\n-// [START test_iam]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/update_finding_source_properties.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_update_finding_source_properties]\n-// [START update_finding_source_properties]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/findings/update_source.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_update_source]\n-// [START update_source]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/notifications/create_notification_config.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_create_notification_config]\n-// [START scc_create_notification_config]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/notifications/delete_notification_config.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_delete_notification_config]\n-// [START scc_delete_notification_config]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/notifications/get_notification_config.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_get_notification_config]\n-// [START scc_get_notification_config]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/notifications/list_notification_configs.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_list_notification_configs]\n-// [START scc_list_notification_configs]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/notifications/receive_notifications.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_receive_notifications]\n-// [START scc_receive_notifications]\n import (\n \t\"bytes\"\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/notifications/update_notification_config.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_update_notification_config]\n-// [START scc_update_notification_config]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/settings/enable_asset_discovery.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage settings\n \n // [START securitycenter_enable_asset_discovery]\n-// [START get_org_settings]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "feat(bigquery): add template table creation sample",
        "pr_number": 1976,
        "file_name": "securitycenter/settings/get_org_settings.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage settings\n \n // [START securitycenter_get_org_settings]\n-// [START get_org_settings]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-template-table-sample",
        "commit_id": "88910553217ffe7b23edf17734640b4926bf4938"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/assets/add_delete_security_marks.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_add_delete_security_marks]\n-// [START add_delete_security_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/assets/add_security_marks.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_add_security_marks]\n-// [START add_security_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/assets/delete_security_marks.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_delete_security_marks]\n-// [START delete_security_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/assets/list_all_assets.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_list_all_assets]\n-// [START list_all_assets]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/assets/list_all_project_assets.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_list_assets_with_filter]\n-// [START list_project_assets]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/assets/list_assets_with_security_marks.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_list_assets_with_security_marks]\n-// [START list_assets_with_security_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/assets/list_project_assets_and_state_changes.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_list_assets_and_changes]\n-// [START list_project_assets_and_state_changes]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/assets/list_project_assets_at_time.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage assets\n \n // [START securitycenter_list_assets_at_time]\n-// [START list_project_assets_at_time]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/add_security_marks.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_add_finding_security_marks]\n-// [START add_security_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/create_finding.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_create_finding]\n-// [START create_finding]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/create_finding_with_source_properties.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_create_finding_with_source_properties]\n-// [START create_finding_with_source_properties]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/create_source.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_create_source]\n-// [START create_source]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/get_source.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_get_source]\n-// [START get_source]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/get_source_iam.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_get_source_iam]\n-// [START get_iam_policy_source]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/list_all_findings.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_list_all_findings]\n-// [START list_all_findings]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/list_filtered_findings.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_list_filtered_findings]\n-// [START list_filtered_findings]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/list_findings_at_time.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_list_findings_at_time]\n-// [START list_findings_at_time]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/list_findings_with_security_mark.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_list_findings_with_security_marks]\n-// [START list_findings_with_marks]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/list_sources.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_list_sources]\n-// [START list_sources]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/set_finding_state.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_update_finding_state]\n-// [START set_finding_state]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/set_source_iam.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_set_source_iam]\n-// [START set_iam_policy_source]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/test_iam.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_test_iam]\n-// [START test_iam]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/update_finding_source_properties.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_update_finding_source_properties]\n-// [START update_finding_source_properties]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/findings/update_source.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage findings\n \n // [START securitycenter_update_source]\n-// [START update_source]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/notifications/create_notification_config.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_create_notification_config]\n-// [START scc_create_notification_config]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/notifications/delete_notification_config.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_delete_notification_config]\n-// [START scc_delete_notification_config]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/notifications/get_notification_config.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_get_notification_config]\n-// [START scc_get_notification_config]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/notifications/list_notification_configs.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_list_notification_configs]\n-// [START scc_list_notification_configs]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/notifications/receive_notifications.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_receive_notifications]\n-// [START scc_receive_notifications]\n import (\n \t\"bytes\"\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/notifications/update_notification_config.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage notifications\n \n // [START securitycenter_update_notification_config]\n-// [START scc_update_notification_config]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/settings/enable_asset_discovery.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage settings\n \n // [START securitycenter_enable_asset_discovery]\n-// [START get_org_settings]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "securitycenter/settings/get_org_settings.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage settings\n \n // [START securitycenter_get_org_settings]\n-// [START get_org_settings]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pitr-samples-backup-fix",
        "commit_id": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "fix(bigquery): correct error checking logic in dry run example",
        "pr_number": 1959,
        "file_name": "eventarc/audit_storage/main.go",
        "code_diff": "@@ -14,7 +14,7 @@\n// [START eventarc_gcs_handler]\n \n-// Sample audit_storage is a Cloud Run service which handles Cloud Audit Log messages with Cloud Storage data.\n+// Sample audit_storage is a Cloud Run service which handles Cloud Audit Log events with Cloud Storage data.\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix-dryrun-error",
        "commit_id": "efd1cfd861fbd0dc93729a9c50083ca6794621c7"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -33,6 +33,15 @@\nimport (\n \t\"time\"\n )\n \n+// labels are used in operation-related logs.\n+const (\n+\tlabelOperationDeploy        = \"deploy service\"\n+\tlabelOperationBuild         = \"build container image\"\n+\tlabelOperationDeleteService = \"delete service\"\n+\tlabelOperationDeleteImage   = \"delete container image\"\n+\tlabelOperationGetURL        = \"get url\"\n+)\n+\n // Service describes a Cloud Run service\n type Service struct {\n \t// Name is an ID, used for logging and to generate a unique version to this run.",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -143,7 +152,7 @@\nfunc (s *Service) ParsedURL() (*url.URL, error) {\n \t\treturn nil, errors.New(\"URL called before Deploy\")\n \t}\n \tif s.url == nil {\n-\t\tout, err := gcloud(s.operationLabel(\"get url\"), s.urlCmd())\n+\t\tout, err := gcloud(s.operationLabel(labelOperationGetURL), s.urlCmd())\n \t\tif err != nil {\n \t\t\treturn nil, fmt.Errorf(\"gcloud: %s: %q\", s.Name, err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -199,7 +208,7 @@\nfunc (s *Service) Deploy() error {\n \t\t}\n \t}\n \n-\tif _, err := gcloud(s.operationLabel(\"deploy service\"), s.deployCmd()); err != nil {\n+\tif _, err := gcloud(s.operationLabel(labelOperationDeploy), s.deployCmd()); err != nil {\n \t\treturn fmt.Errorf(\"gcloud: %s: %q\", s.version(), err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -223,7 +232,7 @@\nfunc (s *Service) Build() error {\n \t\ts.Image = fmt.Sprintf(\"gcr.io/%s/%s:%s\", s.ProjectID, s.Name, runID)\n \t}\n \n-\tif out, err := gcloud(s.operationLabel(\"build container image\"), s.buildCmd()); err != nil {\n+\tif out, err := gcloud(s.operationLabel(labelOperationBuild), s.buildCmd()); err != nil {\n \t\tfmt.Printf(string(out))\n \t\treturn fmt.Errorf(\"gcloud: %s: %q\", s.Image, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "securitycenter/assets/list_all_project_assets.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage assets\n \n-// [START securitycenter_list_project_assets]\n+// [START securitycenter_list_assets_with_filter]\n // [START list_project_assets]\n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "securitycenter/assets/list_project_assets_and_state_changes.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage assets\n \n-// [START securitycenter_list_project_assets_and_state_changes]\n+// [START securitycenter_list_assets_and_changes]\n // [START list_project_assets_and_state_changes]\n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "securitycenter/assets/list_project_assets_at_time.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage assets\n \n-// [START securitycenter_list_project_assets_at_time]\n+// [START securitycenter_list_assets_at_time]\n // [START list_project_assets_at_time]\n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "securitycenter/findings/get_source_iam.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage findings\n \n-// [START securitycenter_get_iam_policy_source]\n+// [START securitycenter_get_source_iam]\n // [START get_iam_policy_source]\n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "securitycenter/findings/list_findings_with_security_mark.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage findings\n \n-// [START securitycenter_list_findings_with_marks]\n+// [START securitycenter_list_findings_with_security_marks]\n // [START list_findings_with_marks]\n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "securitycenter/findings/set_finding_state.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage findings\n \n-// [START securitycenter_set_finding_state]\n+// [START securitycenter_update_finding_state]\n // [START set_finding_state]\n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "securitycenter/findings/set_source_iam.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage findings\n \n-// [START securitycenter_set_iam_policy_source]\n+// [START securitycenter_set_source_iam]\n // [START set_iam_policy_source]\n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "securitycenter/settings/enable_asset_discovery.go",
        "code_diff": "@@ -15,7 +15,7 @@\n// Package settings contains snippets for working with CSCC organization settings.\n package settings\n \n-// [START securitycenter_get_org_settings]\n+// [START securitycenter_enable_asset_discovery]\n // [START get_org_settings]\n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -264,6 +264,9 @@\nfunc TestSample(t *testing.T) {\n \tout = runSample(t, writeUsingDML, dbName, \"failed to write using DML\")\n \tassertContains(t, out, \"record(s) inserted\")\n \n+\tout = runSample(t, commitStats, dbName, \"failed to request commit stats\")\n+\tassertContains(t, out, \"3 mutations in transaction\")\n+\n \tout = runSample(t, queryWithParameter, dbName, \"failed to query with parameter\")\n \tassertContains(t, out, \"12 Melissa Garcia\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -321,6 +324,7 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"19 Venue 19\")\n \tassertContains(t, out, \"42 Venue 42\")\n \n+\trunSample(t, dropColumn, dbName, \"failed to drop column\")\n \trunSample(t, addNumericColumn, dbName, \"failed to add numeric column\")\n \trunSample(t, updateDataWithNumericColumn, dbName, \"failed to update data with numeric\")\n \tout = runSample(t, queryWithNumericParameter, dbName, \"failed to query with numeric parameter\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_cal_storage_name",
        "commit_id": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "testing(run): increase retry delay for builds to reduce flakiness",
        "pr_number": 1947,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -33,6 +33,15 @@\nimport (\n \t\"time\"\n )\n \n+// labels are used in operation-related logs.\n+const (\n+\tlabelOperationDeploy        = \"deploy service\"\n+\tlabelOperationBuild         = \"build container image\"\n+\tlabelOperationDeleteService = \"delete service\"\n+\tlabelOperationDeleteImage   = \"delete container image\"\n+\tlabelOperationGetURL        = \"get url\"\n+)\n+\n // Service describes a Cloud Run service\n type Service struct {\n \t// Name is an ID, used for logging and to generate a unique version to this run.",
        "comments": [],
        "commit_message": "use labels for constants",
        "commit_id": "6fbfabf219ab5642db787765a29059ad087c9f23"
    },
    {
        "pr_title": "testing(run): increase retry delay for builds to reduce flakiness",
        "pr_number": 1947,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -143,7 +152,7 @@\nfunc (s *Service) ParsedURL() (*url.URL, error) {\n \t\treturn nil, errors.New(\"URL called before Deploy\")\n \t}\n \tif s.url == nil {\n-\t\tout, err := gcloud(s.operationLabel(\"get url\"), s.urlCmd())\n+\t\tout, err := gcloud(s.operationLabel(labelOperationGetURL), s.urlCmd())\n \t\tif err != nil {\n \t\t\treturn nil, fmt.Errorf(\"gcloud: %s: %q\", s.Name, err)\n \t\t}",
        "comments": [],
        "commit_message": "use labels for constants",
        "commit_id": "6fbfabf219ab5642db787765a29059ad087c9f23"
    },
    {
        "pr_title": "testing(run): increase retry delay for builds to reduce flakiness",
        "pr_number": 1947,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -199,7 +208,7 @@\nfunc (s *Service) Deploy() error {\n \t\t}\n \t}\n \n-\tif _, err := gcloud(s.operationLabel(\"deploy service\"), s.deployCmd()); err != nil {\n+\tif _, err := gcloud(s.operationLabel(labelOperationDeploy), s.deployCmd()); err != nil {\n \t\treturn fmt.Errorf(\"gcloud: %s: %q\", s.version(), err)\n \t}",
        "comments": [],
        "commit_message": "use labels for constants",
        "commit_id": "6fbfabf219ab5642db787765a29059ad087c9f23"
    },
    {
        "pr_title": "testing(run): increase retry delay for builds to reduce flakiness",
        "pr_number": 1947,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -223,7 +232,7 @@\nfunc (s *Service) Build() error {\n \t\ts.Image = fmt.Sprintf(\"gcr.io/%s/%s:%s\", s.ProjectID, s.Name, runID)\n \t}\n \n-\tif out, err := gcloud(s.operationLabel(\"build container image\"), s.buildCmd()); err != nil {\n+\tif out, err := gcloud(s.operationLabel(labelOperationBuild), s.buildCmd()); err != nil {\n \t\tfmt.Printf(string(out))\n \t\treturn fmt.Errorf(\"gcloud: %s: %q\", s.Image, err)\n \t}",
        "comments": [],
        "commit_message": "use labels for constants",
        "commit_id": "6fbfabf219ab5642db787765a29059ad087c9f23"
    },
    {
        "pr_title": "docs(spanner): add CommitStats sample",
        "pr_number": 1945,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -33,6 +33,15 @@\nimport (\n \t\"time\"\n )\n \n+// labels are used in operation-related logs.\n+const (\n+\tlabelOperationDeploy        = \"deploy service\"\n+\tlabelOperationBuild         = \"build container image\"\n+\tlabelOperationDeleteService = \"delete service\"\n+\tlabelOperationDeleteImage   = \"delete container image\"\n+\tlabelOperationGetURL        = \"get url\"\n+)\n+\n // Service describes a Cloud Run service\n type Service struct {\n \t// Name is an ID, used for logging and to generate a unique version to this run.",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner-add-commit-stats-sample",
        "commit_id": "216419c262dc68a59c5f95a369ccf1958c89c422"
    },
    {
        "pr_title": "docs(spanner): add CommitStats sample",
        "pr_number": 1945,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -143,7 +152,7 @@\nfunc (s *Service) ParsedURL() (*url.URL, error) {\n \t\treturn nil, errors.New(\"URL called before Deploy\")\n \t}\n \tif s.url == nil {\n-\t\tout, err := gcloud(s.operationLabel(\"get url\"), s.urlCmd())\n+\t\tout, err := gcloud(s.operationLabel(labelOperationGetURL), s.urlCmd())\n \t\tif err != nil {\n \t\t\treturn nil, fmt.Errorf(\"gcloud: %s: %q\", s.Name, err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner-add-commit-stats-sample",
        "commit_id": "216419c262dc68a59c5f95a369ccf1958c89c422"
    },
    {
        "pr_title": "docs(spanner): add CommitStats sample",
        "pr_number": 1945,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -199,7 +208,7 @@\nfunc (s *Service) Deploy() error {\n \t\t}\n \t}\n \n-\tif _, err := gcloud(s.operationLabel(\"deploy service\"), s.deployCmd()); err != nil {\n+\tif _, err := gcloud(s.operationLabel(labelOperationDeploy), s.deployCmd()); err != nil {\n \t\treturn fmt.Errorf(\"gcloud: %s: %q\", s.version(), err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner-add-commit-stats-sample",
        "commit_id": "216419c262dc68a59c5f95a369ccf1958c89c422"
    },
    {
        "pr_title": "docs(spanner): add CommitStats sample",
        "pr_number": 1945,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -223,7 +232,7 @@\nfunc (s *Service) Build() error {\n \t\ts.Image = fmt.Sprintf(\"gcr.io/%s/%s:%s\", s.ProjectID, s.Name, runID)\n \t}\n \n-\tif out, err := gcloud(s.operationLabel(\"build container image\"), s.buildCmd()); err != nil {\n+\tif out, err := gcloud(s.operationLabel(labelOperationBuild), s.buildCmd()); err != nil {\n \t\tfmt.Printf(string(out))\n \t\treturn fmt.Errorf(\"gcloud: %s: %q\", s.Image, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner-add-commit-stats-sample",
        "commit_id": "216419c262dc68a59c5f95a369ccf1958c89c422"
    },
    {
        "pr_title": "fix: add NUMERIC column to sample",
        "pr_number": 1943,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -33,6 +33,15 @@\nimport (\n \t\"time\"\n )\n \n+// labels are used in operation-related logs.\n+const (\n+\tlabelOperationDeploy        = \"deploy service\"\n+\tlabelOperationBuild         = \"build container image\"\n+\tlabelOperationDeleteService = \"delete service\"\n+\tlabelOperationDeleteImage   = \"delete container image\"\n+\tlabelOperationGetURL        = \"get url\"\n+)\n+\n // Service describes a Cloud Run service\n type Service struct {\n \t// Name is an ID, used for logging and to generate a unique version to this run.",
        "comments": [],
        "commit_message": "Merge branch 'master' into issue-1942",
        "commit_id": "7eb4057eb748c7499d0e7889c18854c09c610d71"
    },
    {
        "pr_title": "fix: add NUMERIC column to sample",
        "pr_number": 1943,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -143,7 +152,7 @@\nfunc (s *Service) ParsedURL() (*url.URL, error) {\n \t\treturn nil, errors.New(\"URL called before Deploy\")\n \t}\n \tif s.url == nil {\n-\t\tout, err := gcloud(s.operationLabel(\"get url\"), s.urlCmd())\n+\t\tout, err := gcloud(s.operationLabel(labelOperationGetURL), s.urlCmd())\n \t\tif err != nil {\n \t\t\treturn nil, fmt.Errorf(\"gcloud: %s: %q\", s.Name, err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into issue-1942",
        "commit_id": "7eb4057eb748c7499d0e7889c18854c09c610d71"
    },
    {
        "pr_title": "fix: add NUMERIC column to sample",
        "pr_number": 1943,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -199,7 +208,7 @@\nfunc (s *Service) Deploy() error {\n \t\t}\n \t}\n \n-\tif _, err := gcloud(s.operationLabel(\"deploy service\"), s.deployCmd()); err != nil {\n+\tif _, err := gcloud(s.operationLabel(labelOperationDeploy), s.deployCmd()); err != nil {\n \t\treturn fmt.Errorf(\"gcloud: %s: %q\", s.version(), err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into issue-1942",
        "commit_id": "7eb4057eb748c7499d0e7889c18854c09c610d71"
    },
    {
        "pr_title": "fix: add NUMERIC column to sample",
        "pr_number": 1943,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -223,7 +232,7 @@\nfunc (s *Service) Build() error {\n \t\ts.Image = fmt.Sprintf(\"gcr.io/%s/%s:%s\", s.ProjectID, s.Name, runID)\n \t}\n \n-\tif out, err := gcloud(s.operationLabel(\"build container image\"), s.buildCmd()); err != nil {\n+\tif out, err := gcloud(s.operationLabel(labelOperationBuild), s.buildCmd()); err != nil {\n \t\tfmt.Printf(string(out))\n \t\treturn fmt.Errorf(\"gcloud: %s: %q\", s.Image, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into issue-1942",
        "commit_id": "7eb4057eb748c7499d0e7889c18854c09c610d71"
    },
    {
        "pr_title": "test(spanner): unflake backup sample tests",
        "pr_number": 1932,
        "file_name": "internal/cloudrunci/gcloud.go",
        "code_diff": "@@ -37,12 +37,13 @@\nfunc init() {\n }\n \n // gcloud provides a common mechanism for executing gcloud commands.\n-// It will attempt to retry failed commands 3 times with 2 second wait intervals.\n+// It will attempt to retry failed commands. Use gcloudWithoutRetry() for no retry.\n func gcloud(label string, cmd *exec.Cmd) ([]byte, error) {\n \tvar out []byte\n \tvar err error\n \n-\tsuccess := testutil.RetryWithoutTest(3, 2*time.Second, func(r *testutil.R) {\n+\tmaxAttempts := 5\n+\tsuccess := testutil.RetryWithoutTest(maxAttempts, 2*time.Second, func(r *testutil.R) {\n \t\tout, err = gcloudExec(fmt.Sprintf(\"Attempt #%d: \", r.Attempt), label, cmd)\n \t\tif err != nil {\n \t\t\tlog.Printf(\"gcloudExec: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into issue-1900",
        "commit_id": "dd8f5b9015442e90ab7491faea5410bc246ce56b"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "eventarc/audit_storage/main.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START eventarc_gcs_handler]\n+// [START eventarc_audit_storage_handler]\n \n // Sample audit_storage is a Cloud Run service which handles Cloud Audit Log events with Cloud Storage data.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "eventarc/audit_storage/main.go",
        "code_diff": "@@ -31,8 +31,8 @@\nfunc HelloEventsStorage(w http.ResponseWriter, r *http.Request) {\n \tfmt.Fprintln(w, s)\n }\n \n-// [END eventarc_gcs_handler]\n-// [START eventarc_gcs_server]\n+// [END eventarc_audit_storage_handler]\n+// [START eventarc_audit_storage_server]\n \n func main() {\n \thttp.HandleFunc(\"/\", HelloEventsStorage)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -39,6 +39,8 @@\nconst (\n \ttestVideoFileName        = \"ChromeCast.mp4\"\n \ttestOverlayImageFileName = \"overlay.jpg\"\n \tpreset                   = \"preset/web-hd\"\n+\tsmallSpriteSheetFileName = \"small-sprite-sheet0000000000.jpeg\"\n+\tlargeSpriteSheetFileName = \"large-sprite-sheet0000000000.jpeg\"\n )\n \n // To run the tests, do the following:",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -63,6 +65,10 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \toutputURIForAdHoc := \"gs://\" + bucketName + \"/test-output-adhoc/\"\n \toutputURIForStaticOverlay := \"gs://\" + bucketName + \"/test-output-static-overlay/\"\n \toutputURIForAnimatedOverlay := \"gs://\" + bucketName + \"/test-output-animated-overlay/\"\n+\toutputDirForSetNumberSpritesheet := \"test-output-set-number-spritesheet/\"\n+\toutputURIForSetNumberSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForSetNumberSpritesheet\n+\toutputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n+\toutputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n \n \t// Get the project number\n \tcloudresourcemanagerClient, err := cloudresourcemanager.NewService(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -89,6 +95,18 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tt.Logf(\"\\ntestJobWithStaticOverlay() completed\\n\")\n \ttestJobWithAnimatedOverlay(t, projectNumber, inputURI, inputOverlayImageURI, outputURIForAnimatedOverlay)\n \tt.Logf(\"\\ntestJobWithAnimatedOverlay() completed\\n\")\n+\n+\ttestJobWithSetNumberImagesSpritesheet(t, projectNumber, inputURI, outputURIForSetNumberSpritesheet)\n+\tt.Logf(\"\\ntestJobWithSetNumberImagesSpritesheet() completed\\n\")\n+\t// Check if the spritesheets exist.\n+\tcheckGCSFileExists(t, bucketName, outputDirForSetNumberSpritesheet+smallSpriteSheetFileName)\n+\tcheckGCSFileExists(t, bucketName, outputDirForSetNumberSpritesheet+largeSpriteSheetFileName)\n+\n+\ttestJobWithPeriodicImagesSpritesheet(t, projectNumber, inputURI, outputURIForPeriodicSpritesheet)\n+\tt.Logf(\"\\ntestJobWithPeriodicImagesSpritesheet() completed\\n\")\n+\t// Check if the spritesheets exist.\n+\tcheckGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+smallSpriteSheetFileName)\n+\tcheckGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+largeSpriteSheetFileName)\n }\n \n // testJobTemplates tests major operations on job templates. Create, get,",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -180,6 +198,29 @@\nfunc writeTestGCSFile(t *testing.T, dstBucket string, srcBucket string, srcObjec\n \t}\n }\n \n+func checkGCSFileExists(t *testing.T, bucketName string, fileName string) {\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n+\n+\tobjAttrs, err := client.Bucket(bucketName).Object(fileName).Attrs(ctx)\n+\tif err == nil && objAttrs != nil {\n+\t\treturn\n+\t}\n+\tif err == storage.ErrObjectNotExist {\n+\t\tt.Fatalf(\"Spritesheet %q does not exist in bucket %q: %v\", fileName, bucketName, err)\n+\t}\n+\tif err != nil {\n+\t\tt.Fatalf(\"Error getting bucket attrs: %v\", err)\n+\t}\n+}\n+\n // testJobFromPreset tests major operations on a job created from a preset. It\n // will wait until the job successfully completes as part of the test.\n func testJobFromPreset(t *testing.T, projectNumber string, inputURI string, outputURIForPreset string) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -34,9 +34,8 @@\nimport (\n )\n \n const (\n-\ttopic      = \"test-topic-\"\n-\tsub        = \"test-sub-\"\n-\ttestRegion = \"us-central1\"\n+\tresourcePrefix = \"admin-test-\"\n+\ttestRegion     = \"us-central1\"\n )\n \n var (",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -71,7 +70,7 @@\nfunc setupAdmin(t *testing.T) *pubsublite.AdminClient {\n \n \t\tprojNumber = strconv.FormatInt(project.ProjectNumber, 10)\n \n-\t\tpsltest.Cleanup(t, client, projNumber, supportedZones)\n+\t\tpsltest.Cleanup(t, client, projNumber, resourcePrefix, supportedZones)\n \t})\n \n \treturn client",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -84,7 +83,7 @@\nfunc TestTopicAdmin(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \ttestZone := randomZone()\n \n-\ttopicID := topic + uuid.NewString()\n+\ttopicID := resourcePrefix + uuid.NewString()\n \ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \tt.Run(\"CreateTopic\", func(t *testing.T) {\n \t\tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -106,7 +105,7 @@\nfunc TestTopicAdmin(t *testing.T) {\n \t\t\tt.Fatalf(\"getTopic: %v\", err)\n \t\t}\n \t\tgot := buf.String()\n-\t\twant := fmt.Sprintf(\"Got topic: %#v\\n\", *defaultTopicConfig(topicPath))\n+\t\twant := fmt.Sprintf(\"Got topic: %#v\\n\", *psltest.DefaultTopicConfig(topicPath))\n \t\tif diff := cmp.Diff(want, got); diff != \"\" {\n \t\t\tt.Fatalf(\"getTopic() mismatch: -want, +got:\\n%s\", diff)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -161,10 +160,10 @@\nfunc TestListTopics(t *testing.T) {\n \n \tvar topicPaths []string\n \tfor i := 0; i < 3; i++ {\n-\t\ttopicID := topic + uuid.NewString()\n+\t\ttopicID := resourcePrefix + uuid.NewString()\n \t\ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \t\ttopicPaths = append(topicPaths, topicPath)\n-\t\tmustCreateTopic(ctx, t, client, topicPath)\n+\t\tpsltest.MustCreateTopic(ctx, t, client, topicPath)\n \t}\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -184,28 +183,6 @@\nfunc TestListTopics(t *testing.T) {\n \t}\n }\n \n-func mustCreateTopic(ctx context.Context, t *testing.T, client *pubsublite.AdminClient, topicPath string) *pubsublite.TopicConfig {\n-\tt.Helper()\n-\tcfg := defaultTopicConfig(topicPath)\n-\ttopicConfig, err := client.CreateTopic(ctx, *cfg)\n-\tif err != nil {\n-\t\tt.Fatalf(\"AdminClient.CreateTopic got err: %v\", err)\n-\t}\n-\treturn topicConfig\n-}\n-\n-func defaultTopicConfig(topicPath string) *pubsublite.TopicConfig {\n-\tcfg := &pubsublite.TopicConfig{\n-\t\tName:                       topicPath,\n-\t\tPartitionCount:             2,\n-\t\tPublishCapacityMiBPerSec:   4,\n-\t\tSubscribeCapacityMiBPerSec: 8,\n-\t\tPerPartitionBytes:          30 * 1024 * 1024 * 1024, // 30 GiB\n-\t\tRetentionDuration:          pubsublite.InfiniteRetention,\n-\t}\n-\treturn cfg\n-}\n-\n func TestSubscriptionAdmin(t *testing.T) {\n \tt.Parallel()\n \tclient := setupAdmin(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -214,12 +191,12 @@\nfunc TestSubscriptionAdmin(t *testing.T) {\n \tctx := context.Background()\n \ttestZone := randomZone()\n \n-\ttopicID := topic + uuid.NewString()\n+\ttopicID := resourcePrefix + uuid.NewString()\n \ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \n-\tmustCreateTopic(ctx, t, client, topicPath)\n+\tpsltest.MustCreateTopic(ctx, t, client, topicPath)\n \n-\tsubID := sub + uuid.NewString()\n+\tsubID := resourcePrefix + uuid.NewString()\n \tsubPath := fmt.Sprintf(\"projects/%s/locations/%s/subscriptions/%s\", projNumber, testZone, subID)\n \n \tt.Run(\"CreateSubscription\", func(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -242,7 +219,7 @@\nfunc TestSubscriptionAdmin(t *testing.T) {\n \t\t\tt.Fatalf(\"getSubscription: %v\", err)\n \t\t}\n \t\tgot := buf.String()\n-\t\twant := fmt.Sprintf(\"Got subscription: %#v\\n\", defaultSubConfig(topicPath, subPath))\n+\t\twant := fmt.Sprintf(\"Got subscription: %#v\\n\", psltest.DefaultSubConfig(topicPath, subPath))\n \t\tif diff := cmp.Diff(want, got); diff != \"\" {\n \t\t\tt.Fatalf(\"getSubscription mismatch: -want, +got:\\n%s\", diff)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -293,14 +270,14 @@\nfunc TestListSubscriptions(t *testing.T) {\n \ttestZone := randomZone()\n \n \tvar subPaths []string\n-\ttopicID := topic + uuid.NewString()\n+\ttopicID := resourcePrefix + uuid.NewString()\n \ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n-\tmustCreateTopic(ctx, t, client, topicPath)\n+\tpsltest.MustCreateTopic(ctx, t, client, topicPath)\n \n \tfor i := 0; i < 3; i++ {\n-\t\tsubID := sub + uuid.NewString()\n+\t\tsubID := resourcePrefix + uuid.NewString()\n \t\tsubPath := fmt.Sprintf(\"projects/%s/locations/%s/subscriptions/%s\", projNumber, testZone, subID)\n-\t\tmustCreateSubscription(ctx, t, client, topicPath, subPath)\n+\t\tpsltest.MustCreateSubscription(ctx, t, client, topicPath, subPath)\n \t\tsubPaths = append(subPaths, subPath)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage psltest\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"cloud.google.com/go/pubsublite\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -27,9 +28,12 @@\nimport (\n // Cleanup deletes all previous test topics/subscriptions from previous test\n // runs. This prevents previous test failures from building up resources that\n // count against quota.\n-func Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []string) {\n+func Cleanup(t *testing.T, client *pubsublite.AdminClient, proj, namePrefix string, zones []string) {\n \tctx := context.Background()\n \n+\ttopicSubstring := \"/topics/\" + namePrefix\n+\tsubscriptionSubstring := \"/subscriptions/\" + namePrefix\n+\n \tfor _, zone := range zones {\n \t\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", proj, zone)\n \t\ttopicIter := client.Topics(ctx, parent)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -41,6 +45,9 @@\nfunc Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []\n \t\t\tif err != nil {\n \t\t\t\tt.Fatalf(\"topicIter.Next got err: %v\", err)\n \t\t\t}\n+\t\t\tif !strings.Contains(topic.Name, topicSubstring) {\n+\t\t\t\tcontinue\n+\t\t\t}\n \t\t\tif err := client.DeleteTopic(ctx, topic.Name); err != nil {\n \t\t\t\tt.Fatalf(\"AdminClient.DeleteTopic got err: %v\", err)\n \t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -55,6 +62,9 @@\nfunc Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []\n \t\t\tif err != nil {\n \t\t\t\tt.Fatalf(\"subIter.Next() got err: %v\", err)\n \t\t\t}\n+\t\t\tif !strings.Contains(sub.Name, subscriptionSubstring) {\n+\t\t\t\tcontinue\n+\t\t\t}\n \t\t\tif err := client.DeleteSubscription(ctx, sub.Name); err != nil {\n \t\t\t\tt.Fatalf(\"AdminClient.DeleteSubscription got err: %v\", err)\n \t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -65,20 +75,22 @@\nfunc Cleanup(t *testing.T, client *pubsublite.AdminClient, proj string, zones []\n // MustCreateTopic creates a Pub/Sub Lite topic and fails the test if\n // unsuccessful.\n func MustCreateTopic(ctx context.Context, t *testing.T, client *pubsublite.AdminClient, topicPath string) *pubsublite.TopicConfig {\n-\tcfg := defaultTopicConfig(topicPath)\n+\tt.Helper()\n+\tcfg := DefaultTopicConfig(topicPath)\n \ttopicConfig, err := client.CreateTopic(ctx, *cfg)\n \tif err != nil {\n \t\tt.Fatalf(\"AdminClient.CreateTopic got err: %v\", err)\n \t}\n \treturn topicConfig\n }\n \n-func defaultTopicConfig(topicPath string) *pubsublite.TopicConfig {\n+// DefaultTopicConfig returns the default topic config for tests.\n+func DefaultTopicConfig(topicPath string) *pubsublite.TopicConfig {\n \tcfg := &pubsublite.TopicConfig{\n \t\tName:                       topicPath,\n \t\tPartitionCount:             2,\n \t\tPublishCapacityMiBPerSec:   4,\n-\t\tSubscribeCapacityMiBPerSec: 4,\n+\t\tSubscribeCapacityMiBPerSec: 8,\n \t\tPerPartitionBytes:          30 * 1024 * 1024 * 1024, // 30 GiB\n \t\tRetentionDuration:          pubsublite.InfiniteRetention,\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "pubsublite/quickstart_publisher/main.go",
        "code_diff": "@@ -21,9 +21,11 @@\nimport (\n \t\"flag\"\n \t\"fmt\"\n \t\"log\"\n+\t\"sync\"\n \n \t\"cloud.google.com/go/pubsub\"\n \t\"cloud.google.com/go/pubsublite/pscompat\"\n+\t\"golang.org/x/sync/errgroup\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -26,15 +26,18 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \tinstance \"cloud.google.com/go/spanner/admin/instance/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n \t\"google.golang.org/api/iterator\"\n+\tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n \tinstancepb \"google.golang.org/genproto/googleapis/spanner/admin/instance/v1\"\n \t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n type sampleFunc func(w io.Writer, dbName string) error",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "samples(bigtable): connection pool configuration",
        "pr_number": 1920,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -412,6 +415,108 @@\nfunc TestCreateDatabaseWithRetentionPeriodSample(t *testing.T) {\n \tassertContains(t, out, fmt.Sprintf(\"Created database [%s] with version retention period %q\", dbName, wantRetentionPeriod))\n }\n \n+func TestCustomerManagedEncryptionKeys(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tdbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tadminClient, err := database.NewDatabaseAdminClient(context.Background())\n+\tif err != nil {\n+\t\tt.Errorf(\"failed to create admin client: %v\", err)\n+\t}\n+\n+\tvar b bytes.Buffer\n+\n+\tinstanceName := getInstance(t)\n+\tlocationId := \"us-central1\"\n+\tkeyRingId := \"spanner-test-keyring\"\n+\tkeyId := \"spanner-test-key\"\n+\n+\t// Create an encryption key if it does not already exist.\n+\tif err := maybeCreateKey(tc.ProjectID, locationId, keyRingId, keyId); err != nil {\n+\t\tt.Errorf(\"failed to create encryption key: %v\", err)\n+\t}\n+\tkmsKeyName := fmt.Sprintf(\n+\t\t\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\",\n+\t\ttc.ProjectID,\n+\t\tlocationId,\n+\t\tkeyRingId,\n+\t\tkeyId,\n+\t)\n+\n+\t// Create an encrypted database. The database is automatically deleted by the cleanup function.\n+\tif err := createDatabaseWithCustomerManagedEncryptionKey(&b, dbName, kmsKeyName); err != nil {\n+\t\tt.Errorf(\"failed to create database with customer managed encryption key: %v\", err)\n+\t}\n+\tout := b.String()\n+\tassertContains(t, out, fmt.Sprintf(\"Created database [%s] using encryption key %q\", dbName, kmsKeyName))\n+\n+\t// Try to create a backup of the encrypted database and delete it after the test.\n+\tbackupId := fmt.Sprintf(\"enc-backup-%s\", randomID())\n+\tdefer func() {\n+\t\t_ = adminClient.DeleteBackup(context.Background(), &adminpb.DeleteBackupRequest{\n+\t\t\tName: fmt.Sprintf(\"%s/backups/%s\", instanceName, backupId),\n+\t\t})\n+\t}()\n+\tb.Reset()\n+\tif err := createBackupWithCustomerManagedEncryptionKey(&b, dbName, backupId, kmsKeyName); err != nil {\n+\t\tt.Errorf(\"failed to create backup with customer managed encryption key: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, fmt.Sprintf(\"backups/%s\", backupId))\n+\tassertContains(t, out, fmt.Sprintf(\"using encryption key %s\", kmsKeyName))\n+\n+\t// Try to restore the encrypted database and delete the restored database after the test.\n+\trestoredName := fmt.Sprintf(\"%s/databases/rest-enc-%s\", instanceName, randomID())\n+\tdefer func() {\n+\t\t_ = adminClient.DropDatabase(context.Background(), &adminpb.DropDatabaseRequest{\n+\t\t\tDatabase: restoredName,\n+\t\t})\n+\t}()\n+\trestoreFunc := func(w io.Writer, dbName, backupID string) error {\n+\t\treturn restoreBackupWithCustomerManagedEncryptionKey(w, dbName, backupId, kmsKeyName)\n+\t}\n+\tout = runBackupSampleWithRetry(t, restoreFunc, restoredName, backupId, \"failed to restore database with customer managed encryption key\", 10)\n+\tassertContains(t, out, fmt.Sprintf(\"Database %s restored\", dbName))\n+\tassertContains(t, out, fmt.Sprintf(\"using encryption key %s\", kmsKeyName))\n+}\n+\n+func maybeCreateKey(projectId, locationId, keyRingId, keyId string) error {\n+\tclient, err := kms.NewKeyManagementClient(context.Background())\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Try to create a key ring\n+\tcreateKeyRingRequest := kmspb.CreateKeyRingRequest{\n+\t\tParent:    fmt.Sprintf(\"projects/%s/locations/%s\", projectId, locationId),\n+\t\tKeyRingId: keyRingId,\n+\t\tKeyRing:   &kmspb.KeyRing{},\n+\t}\n+\t_, err = client.CreateKeyRing(context.Background(), &createKeyRingRequest)\n+\tif err != nil {\n+\t\tif status, ok := status.FromError(err); !ok || status.Code() != codes.AlreadyExists {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\t// Try to create a key\n+\tcreateKeyRequest := kmspb.CreateCryptoKeyRequest{\n+\t\tParent:      fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s\", projectId, locationId, keyRingId),\n+\t\tCryptoKeyId: keyId,\n+\t\tCryptoKey: &kmspb.CryptoKey{\n+\t\t\tPurpose: kmspb.CryptoKey_ENCRYPT_DECRYPT,\n+\t\t},\n+\t}\n+\t_, err = client.CreateCryptoKey(context.Background(), &createKeyRequest)\n+\tif err != nil {\n+\t\tif status, ok := status.FromError(err); !ok || status.Code() != codes.AlreadyExists {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n func runSample(t *testing.T, f sampleFunc, dbName, errMsg string) string {\n \tvar b bytes.Buffer\n \tif err := f(&b, dbName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bt-connection-pool",
        "commit_id": "bc57216057fa3e892ae2d4a3fa32cbc829ccb917"
    },
    {
        "pr_title": "ci(all): allow nightly tests on specific submodules",
        "pr_number": 1899,
        "file_name": "opentelemetry/trace/main.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \t\"os\"\n \n \ttexporter \"github.com/GoogleCloudPlatform/opentelemetry-operations-go/exporter/trace\"\n-\t\"go.opentelemetry.io/otel/api/global\"\n+\t\"go.opentelemetry.io/otel\"\n \tsdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix1895",
        "commit_id": "71004acbf90e55e4baed549945f2635f726b7744"
    },
    {
        "pr_title": "feat: add h2c sample for Cloud Run",
        "pr_number": 1887,
        "file_name": "opentelemetry/trace/main.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \t\"os\"\n \n \ttexporter \"github.com/GoogleCloudPlatform/opentelemetry-operations-go/exporter/trace\"\n-\t\"go.opentelemetry.io/otel/api/global\"\n+\t\"go.opentelemetry.io/otel\"\n \tsdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-h2c-sample",
        "commit_id": "165ad02c9ec0cfd5947af2b0f6f2499db4d4a02c"
    },
    {
        "pr_title": "feat: add h2c sample for Cloud Run",
        "pr_number": 1887,
        "file_name": "servicedirectory/create_endpoint.go",
        "code_diff": "@@ -20,8 +20,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tservicedirectory \"cloud.google.com/go/servicedirectory/apiv1beta1\"\n-\tsdpb \"google.golang.org/genproto/googleapis/cloud/servicedirectory/v1beta1\"\n+\tservicedirectory \"cloud.google.com/go/servicedirectory/apiv1\"\n+\tsdpb \"google.golang.org/genproto/googleapis/cloud/servicedirectory/v1\"\n )\n \n func createEndpoint(w io.Writer, projectID string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-h2c-sample",
        "commit_id": "165ad02c9ec0cfd5947af2b0f6f2499db4d4a02c"
    },
    {
        "pr_title": "feat: add h2c sample for Cloud Run",
        "pr_number": 1887,
        "file_name": "servicedirectory/create_service.go",
        "code_diff": "@@ -20,8 +20,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tservicedirectory \"cloud.google.com/go/servicedirectory/apiv1beta1\"\n-\tsdpb \"google.golang.org/genproto/googleapis/cloud/servicedirectory/v1beta1\"\n+\tservicedirectory \"cloud.google.com/go/servicedirectory/apiv1\"\n+\tsdpb \"google.golang.org/genproto/googleapis/cloud/servicedirectory/v1\"\n )\n \n func createService(w io.Writer, projectID string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-h2c-sample",
        "commit_id": "165ad02c9ec0cfd5947af2b0f6f2499db4d4a02c"
    },
    {
        "pr_title": "feat: add h2c sample for Cloud Run",
        "pr_number": 1887,
        "file_name": "servicedirectory/quickstart/quickstart.go",
        "code_diff": "@@ -23,8 +23,8 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \n-\tservicedirectory \"cloud.google.com/go/servicedirectory/apiv1beta1\"\n-\tsdpb \"google.golang.org/genproto/googleapis/cloud/servicedirectory/v1beta1\"\n+\tservicedirectory \"cloud.google.com/go/servicedirectory/apiv1\"\n+\tsdpb \"google.golang.org/genproto/googleapis/cloud/servicedirectory/v1\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-h2c-sample",
        "commit_id": "165ad02c9ec0cfd5947af2b0f6f2499db4d4a02c"
    },
    {
        "pr_title": "feat: add h2c sample for Cloud Run",
        "pr_number": 1887,
        "file_name": "servicedirectory/quickstart/quickstart.go",
        "code_diff": "@@ -62,7 +62,7 @@\nfunc main() {\n \t\tParent:    namespace.Name,\n \t\tServiceId: serviceID,\n \t\tService: &sdpb.Service{\n-\t\t\tMetadata: map[string]string{\n+\t\t\tAnnotations: map[string]string{\n \t\t\t\t\"key1\": \"value1\",\n \t\t\t\t\"key2\": \"value2\",\n \t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-h2c-sample",
        "commit_id": "165ad02c9ec0cfd5947af2b0f6f2499db4d4a02c"
    },
    {
        "pr_title": "feat: add h2c sample for Cloud Run",
        "pr_number": 1887,
        "file_name": "servicedirectory/resolve_service.go",
        "code_diff": "@@ -20,8 +20,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tservicedirectory \"cloud.google.com/go/servicedirectory/apiv1beta1\"\n-\tsdpb \"google.golang.org/genproto/googleapis/cloud/servicedirectory/v1beta1\"\n+\tservicedirectory \"cloud.google.com/go/servicedirectory/apiv1\"\n+\tsdpb \"google.golang.org/genproto/googleapis/cloud/servicedirectory/v1\"\n )\n \n func resolveService(w io.Writer, projectID string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-h2c-sample",
        "commit_id": "165ad02c9ec0cfd5947af2b0f6f2499db4d4a02c"
    },
    {
        "pr_title": "feat: add h2c sample for Cloud Run",
        "pr_number": 1887,
        "file_name": "videointelligence/annotate/logo_detection.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n+\t\"time\"\n \n \tvideo \"cloud.google.com/go/videointelligence/apiv1\"\n \t\"github.com/golang/protobuf/ptypes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-h2c-sample",
        "commit_id": "165ad02c9ec0cfd5947af2b0f6f2499db4d4a02c"
    },
    {
        "pr_title": "feat: add h2c sample for Cloud Run",
        "pr_number": 1887,
        "file_name": "videointelligence/annotate/logo_detection_gcs.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n \n \tvideo \"cloud.google.com/go/videointelligence/apiv1\"\n \t\"github.com/golang/protobuf/ptypes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-h2c-sample",
        "commit_id": "165ad02c9ec0cfd5947af2b0f6f2499db4d4a02c"
    },
    {
        "pr_title": "chore(bigquery): add verbose logging to flaky test",
        "pr_number": 1869,
        "file_name": "bigquery/bigquery_storage_quickstart/main_test.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage main\n \n import (\n \t\"fmt\"\n-\t\"log\"\n \t\"testing\"\n \t\"time\"",
        "comments": [
            {
                "comment": "Please use `t.Log`.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "address reviewer feedback",
        "commit_id": "b1d365e5454e90c74e8da8591af58f477b51b8dc"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "translate/v3/batch_translate_text_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into wrapRegionTags",
        "commit_id": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "feat(bigquery): add hive partitioning table sample",
        "pr_number": 1862,
        "file_name": "bigquery/snippets/table/bigquery_create_table_external_hivepartitioned.go",
        "code_diff": "@@ -40,7 +40,6 @@\nfunc createTableExternalHivePartitioned(projectID, datasetID, tableID string) er\n \t//\n \t// Example file:\n \t// gs://cloud-samples-data/bigquery/hive-partitioning-samples/autolayout/dt=2020-11-15/file1.parquet\n-\n \tmetadata := &bigquery.TableMetadata{\n \t\tDescription: \"An example table that demonstrates hive partitioning against external parquet files\",\n \t\tExternalDataConfig: &bigquery.ExternalDataConfig{",
        "comments": [
            {
                "comment": "Do we have examples of such queries? It's not clear with all the autodetection what the column names are.",
                "position": null
            },
            {
                "comment": "That's the interesting bit.  Should we actually perform a predicate query in the same sample, or just add a comment of an example?",
                "position": null
            }
        ],
        "commit_message": "whitespace cleanup",
        "commit_id": "4d83d95e8efa7aba074fed63f78e6560f73c0120"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "automl/operation_status_get.go",
        "code_diff": "@@ -22,14 +22,15 @@\nimport (\n \t\"io\"\n \n \tautoml \"cloud.google.com/go/automl/apiv1\"\n-\t\"google.golang.org/genproto/googleapis/longrunning\"\n+\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1\"\n )\n \n // getOperationStatus gets an operation's status.\n-func getOperationStatus(w io.Writer, projectID string, location string, operationID string) error {\n+func getOperationStatus(w io.Writer, projectID string, location string, datasetID string, modelName string) error {\n \t// projectID := \"my-project-id\"\n \t// location := \"us-central1\"\n-\t// operationID := \"TRL123456789...\"\n+\t// datasetID := \"ICN123456789...\"\n+\t// modelName := \"model_display_name\"\n \n \tctx := context.Background()\n \tclient, err := automl.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "cloudsql/mysql/database-sql/cloudsql_test.go",
        "code_diff": "@@ -22,20 +22,50 @@\nimport (\n \t\"testing\"\n )\n \n+type testInfo struct {\n+\tdbName                 string\n+\tdbPass                 string\n+\tdbUser                 string\n+\tdbPort                 string\n+\tinstanceConnectionName string\n+}\n+\n func TestIndex(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"MYSQL_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"MYSQL_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"MYSQL_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"MYSQL_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"MYSQL_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"MYSQL_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "cloudsql/mysql/database-sql/cloudsql_test.go",
        "code_diff": "@@ -54,22 +84,52 @@\nfunc TestIndex(t *testing.T) {\n \t\t}\n \t\tos.Setenv(\"DB_HOST\", oldDBHost)\n \t}\n+\t// Restore original values\n+\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\tos.Setenv(\"DB_NAME\", oldDBName)\n+\tos.Setenv(\"DB_PASS\", oldDBPass)\n+\tos.Setenv(\"DB_PORT\", oldDBPort)\n+\tos.Setenv(\"DB_USER\", oldDBUser)\n+\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", oldInstance)\n }\n \n func TestCastVote(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"MYSQL_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"MYSQL_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"MYSQL_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"MYSQL_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"MYSQL_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"MYSQL_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "cloudsql/postgres/database-sql/cloudsql_test.go",
        "code_diff": "@@ -22,20 +22,51 @@\nimport (\n \t\"testing\"\n )\n \n+type testInfo struct {\n+\tdbName                 string\n+\tdbPass                 string\n+\tdbUser                 string\n+\tdbPort                 string\n+\tinstanceConnectionName string\n+}\n+\n func TestIndex(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"POSTGRES_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"POSTGRES_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"POSTGRES_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"POSTGRES_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"POSTGRES_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"POSTGRES_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "cloudsql/postgres/database-sql/cloudsql_test.go",
        "code_diff": "@@ -52,24 +83,54 @@\nfunc TestIndex(t *testing.T) {\n \t\tif !strings.Contains(body, want) {\n \t\t\tt.Errorf(\"With dbHost='%s', expected to see '%s' in indexHandler response body\", test.dbHost, want)\n \t\t}\n-\t\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\n \t}\n+\t// Restore original values\n+\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\tos.Setenv(\"DB_NAME\", oldDBName)\n+\tos.Setenv(\"DB_PASS\", oldDBPass)\n+\tos.Setenv(\"DB_PORT\", oldDBPort)\n+\tos.Setenv(\"DB_USER\", oldDBUser)\n+\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", oldInstance)\n }\n \n func TestCastVote(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"POSTGRES_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"POSTGRES_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"POSTGRES_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"POSTGRES_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"POSTGRES_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"POSTGRES_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql_test.go",
        "code_diff": "@@ -22,19 +22,49 @@\nimport (\n \t\"testing\"\n )\n \n+type testInfo struct {\n+\tdbName                 string\n+\tdbPass                 string\n+\tdbUser                 string\n+\tdbPort                 string\n+\tinstanceConnectionName string\n+}\n+\n func TestIndex(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"SQLSERVER_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"SQLSERVER_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"SQLSERVER_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"SQLSERVER_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"SQLSERVER_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"SQLSERVER_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql_test.go",
        "code_diff": "@@ -53,21 +83,50 @@\nfunc TestIndex(t *testing.T) {\n \t\t}\n \t\tos.Setenv(\"DB_HOST\", oldDBHost)\n \t}\n+\t// Restore original values\n+\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\tos.Setenv(\"DB_NAME\", oldDBName)\n+\tos.Setenv(\"DB_PASS\", oldDBPass)\n+\tos.Setenv(\"DB_PORT\", oldDBPort)\n+\tos.Setenv(\"DB_USER\", oldDBUser)\n+\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", oldInstance)\n }\n \n func TestCastVote(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"SQLSERVER_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"SQLSERVER_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"SQLSERVER_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"SQLSERVER_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"SQLSERVER_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"SQLSERVER_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"context\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/datastore\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -50,14 +51,17 @@\nfunc TestInspectDatastore(t *testing.T) {\n \tfor _, test := range tests {\n \t\tt.Run(test.kind, func(t *testing.T) {\n \t\t\tt.Parallel()\n-\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n-\t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, \"\", test.kind); err != nil {\n-\t\t\t\tt.Errorf(\"inspectDatastore(%s) got err: %v\", test.kind, err)\n-\t\t\t}\n-\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n-\t\t\t}\n+\t\t\ttestutil.Retry(t, 5, 15*time.Second, func(r *testutil.R) {\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tbuf := new(bytes.Buffer)\n+\t\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, \"\", test.kind); err != nil {\n+\t\t\t\t\tr.Errorf(\"inspectDatastore(%s) got err: %v\", test.kind, err)\n+\t\t\t\t\treturn\n+\t\t\t\t}\n+\t\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\t\tr.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n+\t\t\t\t}\n+\t\t\t})\n \t\t})\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -66,10 +70,6 @@\ntype SSNTask struct {\n \tDescription string\n }\n \n-type BoringTask struct {\n-\tDescription string\n-}\n-\n func writeTestDatastoreFiles(t *testing.T, projectID string) {\n \tt.Helper()\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -18,8 +18,6 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n-\t\"io\"\n-\t\"os\"\n \t\"strconv\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -31,14 +29,16 @@\nimport (\n )\n \n const (\n-\tlocation              = \"us-central1\"\n-\ttemplateID            = \"my-go-test-template\"\n-\tdeleteTemplateReponse = \"Deleted job template\"\n-\tdeleteJobReponse      = \"Deleted job\"\n-\tjobSucceededState     = \"SUCCEEDED\"\n-\ttestVideoFileName     = \"ChromeCast.mp4\"\n-\ttestVideoFileLocation = \"../testdata/\"\n-\tpreset                = \"preset/web-hd\"\n+\tlocation                 = \"us-central1\"\n+\ttemplateID               = \"my-go-test-template\"\n+\tdeleteTemplateReponse    = \"Deleted job template\"\n+\tdeleteJobReponse         = \"Deleted job\"\n+\tjobSucceededState        = \"SUCCEEDED\"\n+\ttestBucketName           = \"cloud-samples-data\"\n+\ttestBucketDirName        = \"media/\"\n+\ttestVideoFileName        = \"ChromeCast.mp4\"\n+\ttestOverlayImageFileName = \"overlay.jpg\"\n+\tpreset                   = \"preset/web-hd\"\n )\n \n // To run the tests, do the following:",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -56,10 +56,13 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tctx := context.Background()\n \n \tbucketName := tc.ProjectID + \"-golang-samples-transcoder-test\"\n-\tinputURI := \"gs://\" + bucketName + \"/\" + testVideoFileName\n+\tinputURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testVideoFileName\n+\tinputOverlayImageURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testOverlayImageFileName\n \toutputURIForPreset := \"gs://\" + bucketName + \"/test-output-preset/\"\n \toutputURIForTemplate := \"gs://\" + bucketName + \"/test-output-template/\"\n \toutputURIForAdHoc := \"gs://\" + bucketName + \"/test-output-adhoc/\"\n+\toutputURIForStaticOverlay := \"gs://\" + bucketName + \"/test-output-static-overlay/\"\n+\toutputURIForAnimatedOverlay := \"gs://\" + bucketName + \"/test-output-animated-overlay/\"\n \n \t// Get the project number\n \tcloudresourcemanagerClient, err := cloudresourcemanager.NewService(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -74,14 +77,18 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \n \ttestJobTemplates(t, projectNumber)\n \tt.Logf(\"\\ntestJobTemplates() completed\\n\")\n-\twriteTestGCSFile(t, tc.ProjectID, bucketName)\n-\tt.Logf(\"\\nwriteTestGCSFile() completed\\n\")\n+\twriteTestGCSFiles(t, tc.ProjectID, bucketName)\n+\tt.Logf(\"\\nwriteTestGCSFiles() completed\\n\")\n \ttestJobFromPreset(t, projectNumber, inputURI, outputURIForPreset)\n \tt.Logf(\"\\ntestJobFromPreset() completed\\n\")\n \ttestJobFromTemplate(t, projectNumber, inputURI, outputURIForTemplate)\n \tt.Logf(\"\\ntestJobFromTemplate() completed\\n\")\n \ttestJobFromAdHoc(t, projectNumber, inputURI, outputURIForAdHoc)\n \tt.Logf(\"\\ntestJobFromAdHoc() completed\\n\")\n+\ttestJobWithStaticOverlay(t, projectNumber, inputURI, inputOverlayImageURI, outputURIForStaticOverlay)\n+\tt.Logf(\"\\ntestJobWithStaticOverlay() completed\\n\")\n+\ttestJobWithAnimatedOverlay(t, projectNumber, inputURI, inputOverlayImageURI, outputURIForAnimatedOverlay)\n+\tt.Logf(\"\\ntestJobWithAnimatedOverlay() completed\\n\")\n }\n \n // testJobTemplates tests major operations on job templates. Create, get,",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -144,35 +151,32 @@\nfunc testJobTemplates(t *testing.T, projectNumber string) {\n \t})\n }\n \n-// writeTestGCSFile deletes the GCS test bucket and uploads a test video file to it.\n-func writeTestGCSFile(t *testing.T, projectID string, bucketName string) {\n+func writeTestGCSFiles(t *testing.T, projectID string, bucketName string) {\n \tt.Helper()\n+\tctx := context.Background()\n+\ttestutil.CleanBucket(ctx, t, projectID, bucketName)\n+\twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testVideoFileName)\n+\twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testOverlayImageFileName)\n+}\n+\n+// writeTestGCSFile deletes the GCS test bucket and uploads a test video file to it.\n+func writeTestGCSFile(t *testing.T, dstBucket string, srcBucket string, srcObject string) {\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n \tdefer client.Close()\n \n-\ttestutil.CleanBucket(ctx, t, projectID, bucketName)\n-\n-\t// Open local test file.\n-\tf, err := os.Open(testVideoFileLocation + testVideoFileName)\n-\tif err != nil {\n-\t\tt.Fatalf(\"os.Open: %v\", err)\n-\t}\n-\tdefer f.Close()\n-\n-\tctx, cancel := context.WithTimeout(ctx, time.Second*120)\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \n-\t// Upload an object with storage.Writer.\n-\twc := client.Bucket(bucketName).Object(testVideoFileName).NewWriter(ctx)\n-\tif _, err = io.Copy(wc, f); err != nil {\n-\t\tt.Fatalf(\"io.Copy: %v\", err)\n-\t}\n-\tif err := wc.Close(); err != nil {\n-\t\tt.Fatalf(\"Writer.Close: %v\", err)\n+\tdstObject := srcObject\n+\tsrc := client.Bucket(srcBucket).Object(srcObject)\n+\tdst := client.Bucket(dstBucket).Object(dstObject)\n+\n+\tif _, err := dst.CopierFrom(src).Run(ctx); err != nil {\n+\t\tt.Fatalf(\"Object(%q).CopierFrom(%q).Run: %v\", dstObject, srcObject, err)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -40,6 +40,7 @@\nimport (\n type sampleFunc func(w io.Writer, dbName string) error\n type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(w io.Writer, dbName, backupID string) error\n+type createBackupSampleFunc func(w io.Writer, dbName, backupID string, versionTime time.Time) error\n \n var (\n \tvalidInstancePattern = regexp.MustCompile(\"^projects/(?P<project>[^/]+)/instances/(?P<instance>[^/]+)$\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -74,6 +75,30 @@\nfunc initTest(t *testing.T, id string) (dbName string, cleanup func()) {\n \treturn\n }\n \n+func getVersionTime(t *testing.T, dbName string) (versionTime time.Time) {\n+\tctx := context.Background()\n+\tclient, err := spanner.NewClient(ctx, dbName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create client: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT CURRENT_TIMESTAMP()`,\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\trow, err := iter.Next()\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to get current time: %v\", err)\n+\t}\n+\tif err := row.Columns(&versionTime); err != nil {\n+\t\tt.Fatalf(\"failed to get version time: %v\", err)\n+\t}\n+\n+\treturn versionTime\n+}\n+\n func initBackupTest(t *testing.T, id, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n \tinstance := getInstance(t)\n \trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", id), t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -346,7 +371,8 @@\nfunc TestBackupSample(t *testing.T) {\n \trunSample(t, write, dbName, \"failed to insert data\")\n \n \t// Start testing backup operations.\n-\tout = runBackupSample(t, createBackup, dbName, backupID, \"failed to create a backup\")\n+\tversionTime := getVersionTime(t, dbName)\n+\tout = runCreateBackupSample(t, createBackup, dbName, backupID, versionTime, \"failed to create a backup\")\n \tassertContains(t, out, fmt.Sprintf(\"backups/%s\", backupID))\n \n \tout = runBackupSample(t, cancelBackup, dbName, cancelledBackupID, \"failed to cancel a backup\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "spanner/spanner_snippets/spanner/spanner_create_backup.go",
        "code_diff": "@@ -28,7 +28,8 @@\nimport (\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n-func createBackup(w io.Writer, db, backupID string) error {\n+func createBackup(w io.Writer, db, backupID string, versionTime time.Time) error {\n+\t// versionTime := time.Now().AddDate(0, 0, -1) // one day ago\n \tmatches := regexp.MustCompile(\"^(.+)/databases/(.+)$\").FindStringSubmatch(db)\n \tif matches == nil || len(matches) != 3 {\n \t\treturn fmt.Errorf(\"createBackup: invalid database id %q\", db)",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "spanner/spanner_snippets/spanner/spanner_create_backup.go",
        "code_diff": "@@ -40,10 +41,6 @@\nfunc createBackup(w io.Writer, db, backupID string) error {\n \t\treturn fmt.Errorf(\"createBackup.NewDatabaseAdminClient: %v\", err)\n \t}\n \tdefer adminClient.Close()\n-\tdbMetadata, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: db})\n-\tif err != nil {\n-\t\treturn fmt.Errorf(\"createBackup.GetDatabase: %v\", err)\n-\t}\n \n \texpireTime := time.Now().AddDate(0, 0, 14)\n \t// Create a backup.",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "testing(functions): pattern for complete system tests",
        "pr_number": 1859,
        "file_name": "spanner/spanner_snippets/spanner/spanner_create_backup.go",
        "code_diff": "@@ -53,7 +50,7 @@\nfunc createBackup(w io.Writer, db, backupID string) error {\n \t\tBackup: &adminpb.Backup{\n \t\t\tDatabase:    db,\n \t\t\tExpireTime:  &pbt.Timestamp{Seconds: expireTime.Unix(), Nanos: int32(expireTime.Nanosecond())},\n-\t\t\tVersionTime: dbMetadata.EarliestVersionTime,\n+\t\t\tVersionTime: &pbt.Timestamp{Seconds: versionTime.Unix(), Nanos: int32(versionTime.Nanosecond())},\n \t\t},\n \t}\n \top, err := adminClient.CreateBackup(ctx, &req)",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions-testmain",
        "commit_id": "f78843933229d31e9fff172b6d66f062a610c07c"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "getting-started/background/translate_test.go",
        "code_diff": "@@ -56,7 +56,7 @@\nfunc TestTranslate(t *testing.T) {\n \t\t\t}\n \n \t\t\tmsg, err := json.Marshal(Translation{\n-\t\t\t\tOriginal: \"Hello\",\n+\t\t\t\tOriginal: \"Me\",\n \t\t\t\tLanguage: \"fr\",\n \t\t\t})\n \t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "kms/decrypt_asymmetric.go",
        "code_diff": "@@ -18,10 +18,12 @@\npackage kms\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // decryptAsymmetric will attempt to decrypt a given ciphertext with an",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "kms/decrypt_symmetric.go",
        "code_diff": "@@ -18,10 +18,12 @@\npackage kms\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // decryptSymmetric will decrypt the input ciphertext bytes using the specified symmetric key.",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "kms/encrypt_symmetric.go",
        "code_diff": "@@ -18,10 +18,12 @@\npackage kms\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // encryptSymmetric encrypts the input plaintext with the specified symmetric",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "kms/encrypt_symmetric.go",
        "code_diff": "@@ -41,10 +43,18 @@\nfunc encryptSymmetric(w io.Writer, name string, message string) error {\n \t// ciphertexts are always byte arrays.\n \tplaintext := []byte(message)\n \n+\t// Optional but recommended: Compute plaintext's CRC32C.\n+\tcrc32c := func(data []byte) uint32 {\n+\t\tt := crc32.MakeTable(crc32.Castagnoli)\n+\t\treturn crc32.Checksum(data, t)\n+\t}\n+\tplaintextCRC32C := crc32c(plaintext)\n+\n \t// Build the request.\n \treq := &kmspb.EncryptRequest{\n-\t\tName:      name,\n-\t\tPlaintext: plaintext,\n+\t\tName:            name,\n+\t\tPlaintext:       plaintext,\n+\t\tPlaintextCrc32C: wrapperspb.Int64(int64(plaintextCRC32C)),\n \t}\n \n \t// Call the API.",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "kms/get_public_key.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"crypto/x509\"\n \t\"encoding/pem\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "kms/sign_asymmetric.go",
        "code_diff": "@@ -19,10 +19,12 @@\nimport (\n \t\"context\"\n \t\"crypto/sha256\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // signAsymmetric will sign a plaintext message using a saved asymmetric private",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "kms/sign_asymmetric.go",
        "code_diff": "@@ -48,6 +50,14 @@\nfunc signAsymmetric(w io.Writer, name string, message string) error {\n \t\treturn fmt.Errorf(\"failed to create digest: %v\", err)\n \t}\n \n+\t// Optional but recommended: Compute digest's CRC32C.\n+\tcrc32c := func(data []byte) uint32 {\n+\t\tt := crc32.MakeTable(crc32.Castagnoli)\n+\t\treturn crc32.Checksum(data, t)\n+\n+\t}\n+\tdigestCRC32C := crc32c(digest.Sum(nil))\n+\n \t// Build the signing request.\n \t//\n \t// Note: Key algorithms will require a varying hash function. For example,",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "spanner/spanner_leaderboard/leaderboard_test.go",
        "code_diff": "@@ -66,9 +66,9 @@\nfunc TestSample(t *testing.T) {\n \t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName}))\n \t}\n \n-\tassertContains := func(t *testing.T, out string, sub string) {\n+\tassertContains := func(t *testing.T, name, out, sub string) {\n \t\tif !strings.Contains(out, sub) {\n-\t\t\tt.Errorf(\"got output %q; want it to contain %q\", out, sub)\n+\t\t\tt.Errorf(\"%s failed: got output %q; want it to contain %q\", name, out, sub)\n \t\t}\n \t}\n \trunCommand := func(t *testing.T, cmd string, dbName string, timespan int) string {",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -43,14 +43,15 @@\nfunc TestObjects(t *testing.T) {\n \tdefer client.Close()\n \n \tvar (\n-\t\tbucket                = tc.ProjectID + \"-samples-object-bucket-1\"\n-\t\tdstBucket             = tc.ProjectID + \"-samples-object-bucket-2\"\n-\t\tbucketVersioning      = tc.ProjectID + \"-bucket-versioning-enabled\"\n-\t\tobject1               = \"foo.txt\"\n-\t\tobject2               = \"foo/a.txt\"\n-\t\tobject3               = \"bar.txt\"\n-\t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers\n-\t\troleReader            = storage.RoleReader\n+\t\tbucket           = tc.ProjectID + \"-samples-object-bucket-1\"\n+\t\tdstBucket        = tc.ProjectID + \"-samples-object-bucket-2\"\n+\t\tbucketVersioning = tc.ProjectID + \"-bucket-versioning-enabled\"\n+\t\tobject1          = \"foo.txt\"\n+\t\tobject2          = \"foo/a.txt\"\n+\t\tobject3          = \"bar.txt\"\n+\t\tdstObj           = \"foobar.txt\"\n+\t\tallUsers         = storage.AllUsers\n+\t\troleReader       = storage.RoleReader\n \t)\n \n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -142,6 +143,21 @@\nfunc TestObjects(t *testing.T) {\n \t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)\n \t\t}\n \t}\n+\tt.Run(\"changeObjectStorageClass\", func(t *testing.T) {\n+\t\tbkt := client.Bucket(bucket)\n+\t\tobj := bkt.Object(object1)\n+\t\tif err := changeObjectStorageClass(ioutil.Discard, bucket, object1); err != nil {\n+\t\t\tt.Errorf(\"changeObjectStorageClass: %v\", err)\n+\t\t}\n+\t\twantStorageClass := \"COLDLINE\"\n+\t\toattrs, err := obj.Attrs(ctx)\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"obj.Attrs: %v\", err)\n+\t\t}\n+\t\tif oattrs.StorageClass != wantStorageClass {\n+\t\t\tt.Errorf(\"object storage class: got %q, want %q\", oattrs.StorageClass, wantStorageClass)\n+\t\t}\n+\t})\n \tif err := copyOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, object3, gen); err != nil {\n \t\tt.Fatalf(\"copyOldVersionOfObject: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -161,9 +177,18 @@\nfunc TestObjects(t *testing.T) {\n \tif err != nil {\n \t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n-\tif err := makePublic(ioutil.Discard, bucket, object1, allAuthenticatedUsers, roleReader); err != nil {\n-\t\tt.Errorf(\"makePublic: %v\", err)\n-\t}\n+\tt.Run(\"publicFile\", func(t *testing.T) {\n+\t\tif err := makePublic(ioutil.Discard, bucket, object1, allUsers, roleReader); err != nil {\n+\t\t\tt.Errorf(\"makePublic: %v\", err)\n+\t\t}\n+\t\tdata, err = downloadPublicFile(ioutil.Discard, bucket, object1)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"downloadPublicFile: %v\", err)\n+\t\t}\n+\t\tif got, want := string(data), \"Hello\\nworld\"; got != want {\n+\t\t\tt.Errorf(\"contents = %q; want %q\", got, want)\n+\t\t}\n+\t})\n \n \terr = moveFile(ioutil.Discard, bucket, object1)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -175,6 +200,19 @@\nfunc TestObjects(t *testing.T) {\n \tif err := copyFile(ioutil.Discard, dstBucket, bucket, object1); err != nil {\n \t\tt.Errorf(\"copyFile: %v\", err)\n \t}\n+\tt.Run(\"composeFile\", func(t *testing.T) {\n+\t\tif err := composeFile(ioutil.Discard, bucket, object1, object2, dstObj); err != nil {\n+\t\t\tt.Errorf(\"composeFile: %v\", err)\n+\t\t}\n+\t\tbkt := client.Bucket(bucket)\n+\t\tobj := bkt.Object(dstObj)\n+\t\t_, err = obj.Attrs(ctx)\n+\t\tif err == storage.ErrObjectNotExist {\n+\t\t\tt.Errorf(\"Destination object was not created\")\n+\t\t} else if err != nil {\n+\t\t\tt.Errorf(\"object.Attrs: %v\", err)\n+\t\t}\n+\t})\n \n \tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \tnewKey := []byte(\"My-secret-AES-256-encryption-key\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -201,10 +239,13 @@\nfunc TestObjects(t *testing.T) {\n \tif err := deleteFile(ioutil.Discard, bucket, object2); err != nil {\n \t\tt.Errorf(\"deleteFile: %v\", err)\n \t}\n+\to := client.Bucket(bucket).Object(dstObj)\n+\tif err := o.Delete(ctx); err != nil {\n+\t\tt.Errorf(\"Object(%q).Delete: %v\", dstObj, err)\n+\t}\n \tif err := disableVersioning(ioutil.Discard, bucketVersioning); err != nil {\n \t\tt.Fatalf(\"disableVersioning: %v\", err)\n \t}\n-\n \tbAttrs, err = bkt.Attrs(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketVersioning, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -262,6 +303,31 @@\nfunc TestKMSObjects(t *testing.T) {\n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n+\tt.Run(\"\u0441hangeObjectCSEKtoKMS\", func(t *testing.T) {\n+\t\tobject1 := \"foo.txt\"\n+\t\tkey := []byte(\"my-secret-AES-256-encryption-key\")\n+\t\tobj := client.Bucket(bucket).Object(object1)\n+\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\twc := obj.Key(key).NewWriter(ctx)\n+\t\t\tif _, err := wc.Write([]byte(\"top secret\")); err != nil {\n+\t\t\t\tr.Errorf(\"Writer.Write: %v\", err)\n+\t\t\t}\n+\t\t\tif err := wc.Close(); err != nil {\n+\t\t\t\tr.Errorf(\"Writer.Close: %v\", err)\n+\t\t\t}\n+\t\t})\n+\t\tif err := \u0441hangeObjectCSEKToKMS(ioutil.Discard, bucket, object1, key, kmsKeyName); err != nil {\n+\t\t\tt.Errorf(\"\u0441hangeObjectCSEKtoKMS: %v\", err)\n+\t\t}\n+\t\tattrs, err := obj.Attrs(ctx)\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"obj.Attrs: %v\", err)\n+\t\t}\n+\t\tif got, want := attrs.KMSKeyName, kmsKeyName; !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"attrs.KMSKeyName expected %q to contain %q\", got, want)\n+\t\t}\n+\t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object, kmsKeyName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-qs-fix",
        "commit_id": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "asset/quickstart/list-assets/main_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage main\n \n // [START fs_initialize]\n+// [START firestore_setup_client_create]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -39,6 +40,7 @@\nfunc createClient(ctx context.Context) *firestore.Client {\n \treturn client\n }\n \n+// [END firestore_setup_client_create]\n // [END fs_initialize]\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -48,6 +50,7 @@\nfunc main() {\n \tdefer client.Close()\n \n \t// [START fs_add_data_1]\n+\t// [START firestore_setup_dataset_pt1]\n \t_, _, err := client.Collection(\"users\").Add(ctx, map[string]interface{}{\n \t\t\"first\": \"Ada\",\n \t\t\"last\":  \"Lovelace\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -56,9 +59,11 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"Failed adding alovelace: %v\", err)\n \t}\n+\t// [END firestore_setup_dataset_pt1]\n \t// [END fs_add_data_1]\n \n \t// [START fs_add_data_2]\n+\t// [START firestore_setup_dataset_pt2]\n \t_, _, err = client.Collection(\"users\").Add(ctx, map[string]interface{}{\n \t\t\"first\":  \"Alan\",\n \t\t\"middle\": \"Mathison\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -68,9 +73,11 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"Failed adding aturing: %v\", err)\n \t}\n+\t// [END firestore_setup_dataset_pt2]\n \t// [END fs_add_data_2]\n \n \t// [START fs_get_all_users]\n+\t// [START firestore_setup_dataset_read]\n \titer := client.Collection(\"users\").Documents(ctx)\n \tfor {\n \t\tdoc, err := iter.Next()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/collection_group_query.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_collection_group_query]\n+// [START firestore_query_collection_group_filter_eq]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/collection_group_setup.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_collection_group_query_data_setup]\n+// [START firestore_query_collection_group_dataset]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/increment.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_update_document_increment]\n+// [START firestore_data_set_numeric_increment]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/listen_changes.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_changes]\n+// [START firestore_listen_query_changes]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/listen_document.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_document]\n+// [START firestore_listen_document]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/listen_document.go",
        "code_diff": "@@ -29,11 +29,11 @@\nimport (\n // listenDocument listens to a single document.\n func listenDocument(ctx context.Context, w io.Writer, projectID, collection string) error {\n \t// projectID := \"project-id\"\n-\t// [START fs_detach_listener]\n+\t// [START firestore_listen_detach]\n \t// \u0421ontext with timeout stops listening to changes.\n \tctx, cancel := context.WithTimeout(ctx, 30*time.Second)\n \tdefer cancel()\n-\t// [END fs_detach_listener]\n+\t// [END firestore_listen_detach]\n \n \tclient, err := firestore.NewClient(ctx, projectID)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/listen_errors.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_errors]\n+// [START firestore_listen_handle_error]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/listen_multiple.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_multiple]\n+// [START firestore_listen_query_snapshots]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/main.go",
        "code_diff": "@@ -25,6 +25,7 @@\nimport (\n )\n \n // [START fs_class_definition]\n+// [START firestore_data_custom_type_definition]\n \n // City represents a city.\n type City struct {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -15,17 +15,20 @@\npackage main\n \n // [START fs_dependencies]\n+// [START firestore_setup_dependencies]\n import (\n \t\"context\"\n \t\"fmt\"\n \n \t\"cloud.google.com/go/firestore\"\n )\n \n+// [END firestore_setup_dependencies]\n // [END fs_dependencies]\n \n func prepareQuery(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_create_examples]\n+\t// [START firestore_query_filter_dataset]\n \tcities := []struct {\n \t\tid string\n \t\tc  City",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -66,30 +69,37 @@\nfunc prepareQuery(ctx context.Context, client *firestore.Client) error {\n \t\t\treturn err\n \t\t}\n \t}\n+\t// [END firestore_query_filter_dataset]\n \t// [END fs_query_create_examples]\n \treturn nil\n }\n \n func createQuery(client *firestore.Client) {\n \t// [START fs_create_query]\n+\t// [START firestore_query_filter_eq_boolean]\n \tquery := client.Collection(\"cities\").Where(\"capital\", \"==\", true)\n+\t// [END firestore_query_filter_eq_boolean]\n \t// [END fs_create_query]\n \t_ = query\n }\n \n func createQueryTwo(client *firestore.Client) {\n \t// [START fs_create_query_two]\n+\t// [START firestore_query_filter_eq_string]\n \tquery := client.Collection(\"cities\").Where(\"state\", \"==\", \"CA\")\n+\t// [END firestore_query_filter_eq_string]\n \t// [END fs_create_query_two]\n \t_ = query\n }\n \n func createSimpleQueries(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_simple_queries]\n+\t// [START firestore_query_filter_single_examples]\n \tcountryQuery := cities.Where(\"state\", \"==\", \"CA\")\n \tpopQuery := cities.Where(\"population\", \"<\", 1000000)\n \tcityQuery := cities.Where(\"name\", \">=\", \"San Francisco\")\n+\t// [END firestore_query_filter_single_examples]\n \t// [END fs_simple_queries]\n \n \t_ = countryQuery",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -100,8 +110,10 @@\nfunc createSimpleQueries(client *firestore.Client) {\n func createChainedQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_chained_query]\n+\t// [START firestore_query_filter_compound_multi_eq]\n \tdenverQuery := cities.Where(\"name\", \"==\", \"Denver\").Where(\"state\", \"==\", \"CO\")\n \tcaliQuery := cities.Where(\"state\", \"==\", \"CA\").Where(\"population\", \"<=\", 1000000)\n+\t// [END firestore_query_filter_compound_multi_eq]\n \t// [END fs_chained_query]\n \n \t_ = denverQuery",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -112,7 +124,9 @@\nfunc createInvalidChainedQuery(client *firestore.Client) {\n \t// Note: this is an instance of a currently unsupported chained query\n \tcities := client.Collection(\"cities\")\n \t// [START fs_invalid_chained_query]\n+\t// [START firestore_query_filter_compound_multi_eq]\n \tquery := cities.Where(\"country\", \"==\", \"USA\").Where(\"population\", \">\", 5000000)\n+\t// [END firestore_query_filter_compound_multi_eq]\n \t// [END fs_invalid_chained_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -121,8 +135,10 @@\nfunc createInvalidChainedQuery(client *firestore.Client) {\n func createRangeQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_range_query]\n+\t// [START firestore_query_filter_range_valid]\n \tstateQuery := cities.Where(\"state\", \">=\", \"CA\").Where(\"state\", \"<\", \"IN\")\n \tpopulationQuery := cities.Where(\"state\", \"==\", \"CA\").Where(\"population\", \">\", 1000000)\n+\t// [END firestore_query_filter_range_valid]\n \t// [END fs_range_query]\n \n \t_ = stateQuery",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -134,7 +150,9 @@\nfunc createInvalidRangeQuery(client *firestore.Client) {\n \t// are limited to a single field.\n \tcities := client.Collection(\"cities\")\n \t// [START fs_invalid_range_query]\n+\t// [START firestore_query_filter_range_invalid]\n \tquery := cities.Where(\"state\", \">=\", \"CA\").Where(\"population\", \">\", 1000000)\n+\t// [END firestore_query_filter_range_invalid]\n \t// [END fs_invalid_range_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -143,7 +161,9 @@\nfunc createInvalidRangeQuery(client *firestore.Client) {\n func createOrderByNameLimitQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_order_by_name_limit_query]\n+\t// [START firestore_query_order_limit]\n \tquery := cities.OrderBy(\"name\", firestore.Asc).Limit(3)\n+\t// [END firestore_query_order_limit]\n \t// [END fs_order_by_name_limit_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -152,7 +172,9 @@\nfunc createOrderByNameLimitQuery(client *firestore.Client) {\n func createOrderByNameLimitToLastQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_order_by_name_limit_to_last_query]\n+\t// [START firestore_query_order_limit]\n \tquery := cities.OrderBy(\"name\", firestore.Asc).LimitToLast(3)\n+\t// [END firestore_query_order_limit]\n \t// [END fs_order_by_name_limit_to_last_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -161,23 +183,29 @@\nfunc createOrderByNameLimitToLastQuery(client *firestore.Client) {\n func createOrderByNameDescLimitQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_order_by_name_desc_limit_query]\n+\t// [START firestore_query_order_desc_limit]\n \tquery := cities.OrderBy(\"name\", firestore.Desc).Limit(3)\n+\t// [END firestore_query_order_desc_limit]\n \t// [END fs_order_by_name_desc_limit_query]\n \n \t_ = query\n }\n \n func createMultipleOrderByQuery(client *firestore.Client) {\n \t// [START fs_order_by_multiple]\n+\t// [START firestore_query_order_multi]\n \tquery := client.Collection(\"cities\").OrderBy(\"state\", firestore.Asc).OrderBy(\"population\", firestore.Desc)\n+\t// [END firestore_query_order_multi]\n \t// [END fs_order_by_multiple]\n \t_ = query\n }\n \n func createRangeWithOrderByAndLimitQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_where_order_by_limit_query]\n+\t// [START firestore_query_order_limit_field_valid]\n \tquery := cities.Where(\"population\", \">\", 2500000).OrderBy(\"population\", firestore.Desc).Limit(2)\n+\t// [END firestore_query_order_limit_field_valid]\n \t// [END fs_where_order_by_limit_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -186,7 +214,9 @@\nfunc createRangeWithOrderByAndLimitQuery(client *firestore.Client) {\n func createRangeWithOrderByQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_range_order_by_query]\n+\t// [START firestore_query_order_with_filter]\n \tquery := cities.Where(\"population\", \">\", 2500000).OrderBy(\"population\", firestore.Asc)\n+\t// [END firestore_query_order_with_filter]\n \t// [END fs_range_order_by_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -195,30 +225,37 @@\nfunc createRangeWithOrderByQuery(client *firestore.Client) {\n func createInvalidRangeWithOrderByQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_invalid_range_order_by_query]\n+\t// [START firestore_query_order_field_invalid]\n \t// Note: This is an invalid query. It violates the constraint that range\n \t// and order by are required to be on the same field.\n \tquery := cities.Where(\"population\", \">\", 2500000).OrderBy(\"country\", firestore.Asc)\n+\t// [END firestore_query_order_field_invalid]\n \t// [END fs_invalid_range_order_by_query]\n \n \t_ = query\n }\n \n func createSimpleStartAtQuery(client *firestore.Client) {\n \t// [START fs_simple_start_at]\n+\t// [START firestore_query_cursor_start_at_field_value_single]\n \tquery := client.Collection(\"cities\").OrderBy(\"population\", firestore.Asc).StartAt(1000000)\n+\t// [END firestore_query_cursor_start_at_field_value_single]\n \t// [END fs_simple_start_at]\n \t_ = query\n }\n \n func createSimpleEndtAtQuery(client *firestore.Client) {\n \t// [START fs_simple_end_at]\n+\t// [START firestore_query_cursor_end_at_field_value_single]\n \tquery := client.Collection(\"cities\").OrderBy(\"population\", firestore.Asc).EndAt(1000000)\n+\t// [END firestore_query_cursor_end_at_field_value_single]\n \t// [END fs_simple_end_at]\n \t_ = query\n }\n \n func paginateCursor(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_paginate_cursor]\n+\t// [START firestore_query_cursor_pagination]\n \tcities := client.Collection(\"cities\")\n \n \t// Get the first 25 cities, ordered by population.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -237,13 +274,15 @@\nfunc paginateCursor(ctx context.Context, client *firestore.Client) error {\n \t\tLimit(25)\n \n \t// ...\n+\t// [END firestore_query_cursor_pagination]\n \t// [END fs_paginate_cursor]\n \t_ = secondPage\n \treturn nil\n }\n \n func createMultipleStartAtQuery(client *firestore.Client) {\n \t// [START fs_start_at_multiple]\n+\t// [START firestore_query_cursor_start_at_field_value_multi]\n \t// Will return all Springfields.\n \tclient.Collection(\"cities\").\n \t\tOrderBy(\"name\", firestore.Asc).",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -255,13 +294,16 @@\nfunc createMultipleStartAtQuery(client *firestore.Client) {\n \t\tOrderBy(\"name\", firestore.Asc).\n \t\tOrderBy(\"state\", firestore.Asc).\n \t\tStartAt(\"Springfield\", \"Wisconsin\")\n+\t// [END firestore_query_cursor_start_at_field_value_multi]\n \t// [END fs_start_at_multiple]\n }\n \n func createInQuery(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_filter_in]\n+\t// [START firestore_query_filter_in]\n \tcities := client.Collection(\"cities\")\n \tquery := cities.Where(\"country\", \"in\", []string{\"USA\", \"Japan\"}).Documents(ctx)\n+\t// [END firestore_query_filter_in]\n \t// [END fs_query_filter_in]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -270,8 +312,10 @@\nfunc createInQuery(ctx context.Context, client *firestore.Client) error {\n \n func createInQueryWithArray(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_filter_in_with_array]\n+\t// [START firestore_query_filter_in_with_array]\n \tcities := client.Collection(\"cities\")\n \tquery := cities.Where(\"regions\", \"in\", [][]string{{\"west_coast\"}, {\"east_coast\"}}).Documents(ctx)\n+\t// [END firestore_query_filter_in_with_array]\n \t// [END fs_query_filter_in_with_array]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -281,7 +325,9 @@\nfunc createInQueryWithArray(ctx context.Context, client *firestore.Client) error\n func createArrayContainsQuery(ctx context.Context, client *firestore.Client) error {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_array_contains_query]\n+\t// [START firestore_query_filter_array_contains]\n \tquery := cities.Where(\"regions\", \"array-contains\", \"west_coast\").Documents(ctx)\n+\t// [END firestore_query_filter_array_contains]\n \t// [END fs_array_contains_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -290,8 +336,10 @@\nfunc createArrayContainsQuery(ctx context.Context, client *firestore.Client) err\n \n func createArrayContainsAnyQuery(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_filter_array_contains_any]\n+\t// [START firestore_query_filter_array_contains_any]\n \tcities := client.Collection(\"cities\")\n \tquery := cities.Where(\"regions\", \"array-contains-any\", []string{\"west_coast\", \"east_coast\"}).Documents(ctx)\n+\t// [END firestore_query_filter_array_contains_any]\n \t// [END fs_query_filter_array_contains_any]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -25,39 +25,48 @@\nimport (\n \n func createDocReference(client *firestore.Client) {\n \t// [START fs_doc_reference]\n+\t// [START firestore_data_reference_document]\n \talovelaceRef := client.Collection(\"users\").Doc(\"alovelace\")\n+\t// [END firestore_data_reference_document]\n \t// [END fs_doc_reference]\n \n \t_ = alovelaceRef\n }\n \n func createCollectionReference(client *firestore.Client) {\n \t// [START fs_coll_reference]\n+\t// [START firestore_data_reference_collection]\n \tusersRef := client.Collection(\"users\")\n+\t// [END firestore_data_reference_collection]\n \t// [END fs_coll_reference]\n \n \t_ = usersRef\n }\n \n func createDocReferenceFromString(client *firestore.Client) {\n \t// [START fs_doc_reference_alternate]\n+\t// [START firestore_data_reference_document_path]\n \talovelaceRef := client.Doc(\"users/alovelace\")\n+\t// [END firestore_data_reference_document_path]\n \t// [END fs_doc_reference_alternate]\n \n \t_ = alovelaceRef\n }\n \n func createSubcollectionReference(client *firestore.Client) {\n \t// [START fs_subcoll_reference]\n+\t// [START firestore_data_reference_subcollection]\n \tmessageRef := client.Collection(\"rooms\").Doc(\"roomA\").\n \t\tCollection(\"messages\").Doc(\"message1\")\n+\t// [END firestore_data_reference_subcollection]\n \t// [END fs_subcoll_reference]\n \n \t_ = messageRef\n }\n \n func prepareRetrieve(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_retrieve_create_examples]\n+\t// [START firestore_data_get_dataset]\n \tcities := []struct {\n \t\tid string\n \t\tc  City",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -74,37 +83,43 @@\nfunc prepareRetrieve(ctx context.Context, client *firestore.Client) error {\n \t\t\treturn err\n \t\t}\n \t}\n+\t// [END firestore_data_get_dataset]\n \t// [END fs_retrieve_create_examples]\n \treturn nil\n }\n \n func docAsMap(ctx context.Context, client *firestore.Client) (map[string]interface{}, error) {\n \t// [START fs_get_doc_as_map]\n+\t// [START firestore_data_get_as_map]\n \tdsnap, err := client.Collection(\"cities\").Doc(\"SF\").Get(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \tm := dsnap.Data()\n \tfmt.Printf(\"Document data: %#v\\n\", m)\n+\t// [END firestore_data_get_as_map]\n \t// [END fs_get_doc_as_map]\n \treturn m, nil\n }\n \n func docAsEntity(ctx context.Context, client *firestore.Client) (*City, error) {\n \t// [START fs_get_doc_as_entity]\n+\t// [START firestore_data_get_as_custom_type]\n \tdsnap, err := client.Collection(\"cities\").Doc(\"BJ\").Get(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \tvar c City\n \tdsnap.DataTo(&c)\n \tfmt.Printf(\"Document data: %#v\\n\", c)\n+\t// [END firestore_data_get_as_custom_type]\n \t// [END fs_get_doc_as_entity]\n \treturn &c, nil\n }\n \n func multipleDocs(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_get_multiple_docs]\n+\t// [START firestore_data_query]\n \tfmt.Println(\"All capital cities:\")\n \titer := client.Collection(\"cities\").Where(\"capital\", \"==\", true).Documents(ctx)\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -117,12 +132,14 @@\nfunc multipleDocs(ctx context.Context, client *firestore.Client) error {\n \t\t}\n \t\tfmt.Println(doc.Data())\n \t}\n+\t// [END firestore_data_query]\n \t// [END fs_get_multiple_docs]\n \treturn nil\n }\n \n func allDocs(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_get_all_docs]\n+\t// [START firestore_data_get_all_documents]\n \tfmt.Println(\"All cities:\")\n \titer := client.Collection(\"cities\").Documents(ctx)\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -135,12 +152,14 @@\nfunc allDocs(ctx context.Context, client *firestore.Client) error {\n \t\t}\n \t\tfmt.Println(doc.Data())\n \t}\n+\t// [END firestore_data_get_all_documents]\n \t// [END fs_get_all_docs]\n \treturn nil\n }\n \n func getCollections(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_get_collections]\n+\t// [START firestore_data_get_sub_collections]\n \titer := client.Collection(\"cities\").Doc(\"SF\").Collections(ctx)\n \tfor {\n \t\tcollRef, err := iter.Next()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -27,6 +27,7 @@\nimport (\n \n func addDocAsMap(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_simple_doc_as_map]\n+\t// [START firestore_data_set_from_map]\n \t_, err := client.Collection(\"cities\").Doc(\"LA\").Set(ctx, map[string]interface{}{\n \t\t\"name\":    \"Los Angeles\",\n \t\t\"state\":   \"CA\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -36,12 +37,14 @@\nfunc addDocAsMap(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_from_map]\n \t// [END fs_add_simple_doc_as_map]\n \treturn err\n }\n \n func addDocDataTypes(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_doc_data_types]\n+\t// [START firestore_data_set_from_map_nested]\n \tdoc := make(map[string]interface{})\n \tdoc[\"stringExample\"] = \"Hello world!\"\n \tdoc[\"booleanExample\"] = true",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -59,24 +62,28 @@\nfunc addDocDataTypes(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_from_map_nested]\n \t// [END fs_add_doc_data_types]\n \treturn err\n }\n \n func addDocWithID(ctx context.Context, client *firestore.Client) error {\n \tvar data = make(map[string]interface{})\n \t// [START fs_add_doc_with_id]\n+\t// [START firestore_data_set_id_specified]\n \t_, err := client.Collection(\"cities\").Doc(\"new-city-id\").Set(ctx, data)\n \tif err != nil {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_id_specified]\n \t// [END fs_add_doc_with_id]\n \treturn err\n }\n \n func addDocWithoutID(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_doc_auto_id]\n+\t// [START firestore_data_set_id_random_collection]\n \t_, _, err := client.Collection(\"cities\").Add(ctx, map[string]interface{}{\n \t\t\"name\":    \"Tokyo\",\n \t\t\"country\": \"Japan\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -85,12 +92,14 @@\nfunc addDocWithoutID(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_id_random_collection]\n \t// [END fs_add_doc_auto_id]\n \treturn err\n }\n \n func addDocAsEntity(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_simple_doc_as_entity]\n+\t// [START firestore_data_set_from_custom_type]\n \tcity := City{\n \t\tName:    \"Los Angeles\",\n \t\tCountry: \"USA\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -100,6 +109,7 @@\nfunc addDocAsEntity(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_from_custom_type]\n \t// [END fs_add_simple_doc_as_entity]\n \treturn err\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -111,6 +121,7 @@\nfunc addDocAfterAutoGeneratedID(ctx context.Context, client *firestore.Client) e\n \t}\n \n \t// [START fs_add_doc_data_after_auto_id]\n+\t// [START firestore_data_set_id_random_document_ref]\n \tref := client.Collection(\"cities\").NewDoc()\n \n \t// later...",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -119,6 +130,7 @@\nfunc addDocAfterAutoGeneratedID(ctx context.Context, client *firestore.Client) e\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_id_random_document_ref]\n \t// [END fs_add_doc_data_after_auto_id]\n \treturn err\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -132,6 +144,7 @@\nfunc updateDoc(ctx context.Context, client *firestore.Client) error {\n \t\tlog.Printf(\"adding city DC: %s\", err)\n \t}\n \t// [START fs_update_doc]\n+\t// [START firestore_data_set_field]\n \t_, err = client.Collection(\"cities\").Doc(\"DC\").Update(ctx, []firestore.Update{\n \t\t{\n \t\t\tPath:  \"capital\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -142,12 +155,14 @@\nfunc updateDoc(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_field]\n \t// [END fs_update_doc]\n \treturn err\n }\n \n func updateDocCreateIfMissing(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_update_create_if_missing]\n+\t// [START firestore_data_set_doc_upsert]\n \t_, err := client.Collection(\"cities\").Doc(\"BJ\").Set(ctx, map[string]interface{}{\n \t\t\"capital\": true,\n \t}, firestore.MergeAll)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -156,6 +171,7 @@\nfunc updateDocCreateIfMissing(ctx context.Context, client *firestore.Client) err\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_doc_upsert]\n \t// [END fs_update_create_if_missing]\n \treturn err\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -183,6 +199,7 @@\nfunc updateDocMultiple(ctx context.Context, client *firestore.Client) error {\n \n func updateDocNested(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_update_nested_fields]\n+\t// [START firestore_data_set_nested_fields]\n \tinitialData := map[string]interface{}{\n \t\t\"name\": \"Frank\",\n \t\t\"age\":  12,",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -210,6 +227,7 @@\nfunc updateDocNested(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_nested_fields]\n \t// [END fs_update_nested_fields]\n \treturn err\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -223,30 +241,35 @@\nfunc updateDocServerTimestamp(ctx context.Context, client *firestore.Client) err\n \t}\n \n \t// [START fs_update_server_timestamp]\n+\t// [START firestore_data_set_server_timestamp]\n \t_, err := client.Collection(\"objects\").Doc(\"some-id\").Set(ctx, map[string]interface{}{\n \t\t\"timestamp\": firestore.ServerTimestamp,\n \t}, firestore.MergeAll)\n \tif err != nil {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_server_timestamp]\n \t// [END fs_update_server_timestamp]\n \treturn err\n }\n \n func deleteDoc(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_delete_doc]\n+\t// [START firestore_data_delete_doc]\n \t_, err := client.Collection(\"cities\").Doc(\"DC\").Delete(ctx)\n \tif err != nil {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_delete_doc]\n \t// [END fs_delete_doc]\n \treturn err\n }\n \n func deleteField(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_delete_field]\n+\t// [START firestore_data_delete_field]\n \t_, err := client.Collection(\"cities\").Doc(\"BJ\").Update(ctx, []firestore.Update{\n \t\t{\n \t\t\tPath:  \"capital\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -257,6 +280,7 @@\nfunc deleteField(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_delete_field]\n \t// [END fs_delete_field]\n \n \t// Use Set once this feature is implemented:",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -268,6 +292,7 @@\nfunc deleteField(ctx context.Context, client *firestore.Client) error {\n }\n \n // [START fs_delete_collection]\n+// [START firestore_data_delete_collection]\n func deleteCollection(ctx context.Context, client *firestore.Client,\n \tref *firestore.CollectionRef, batchSize int) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -306,6 +331,7 @@\nfunc deleteCollection(ctx context.Context, client *firestore.Client,\n \t}\n }\n \n+// [END firestore_data_delete_collection]\n // [END fs_delete_collection]\n \n func runSimpleTransaction(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -318,6 +344,7 @@\nfunc runSimpleTransaction(ctx context.Context, client *firestore.Client) error {\n \t}\n \n \t// [START fs_run_simple_transaction]\n+\t// [START firestore_transaction_document_update]\n \tref := client.Collection(\"cities\").Doc(\"SF\")\n \terr := client.RunTransaction(ctx, func(ctx context.Context, tx *firestore.Transaction) error {\n \t\tdoc, err := tx.Get(ref) // tx.Get, NOT ref.Get!",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -336,12 +363,14 @@\nfunc runSimpleTransaction(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors appropriately in this section.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_transaction_document_update]\n \t// [END fs_run_simple_transaction]\n \treturn err\n }\n \n func infoTransaction(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_return_info_transaction]\n+\t// [START firestore_transaction_document_update_conditional]\n \tref := client.Collection(\"cities\").Doc(\"SF\")\n \terr := client.RunTransaction(ctx, func(ctx context.Context, tx *firestore.Transaction) error {\n \t\tdoc, err := tx.Get(ref)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -364,12 +393,14 @@\nfunc infoTransaction(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_transaction_document_update_conditional]\n \t// [END fs_return_info_transaction]\n \treturn err\n }\n \n func batchWrite(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_batch_write]\n+\t// [START firestore_data_batch_writes]\n \t// Get a new write batch.\n \tbatch := client.Batch()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_counter_classes]\n+// [START firestore_solution_sharded_counter_custom_type]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -37,9 +38,11 @@\ntype Shard struct {\n \tCount int\n }\n \n+// [END firestore_solution_sharded_counter_custom_type]\n // [END fs_counter_classes]\n \n // [START fs_create_counter]\n+// [START firestore_solution_sharded_counter_create]\n \n // initCounter creates a given number of shards as\n // subcollection of specified document.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -57,9 +60,11 @@\nfunc (c *Counter) initCounter(ctx context.Context, docRef *firestore.DocumentRef\n \treturn nil\n }\n \n+// [END firestore_solution_sharded_counter_create]\n // [END fs_create_counter]\n \n // [START fs_increment_counter]\n+// [START firestore_solution_sharded_counter_increment]\n \n // incrementCounter increments a randomly picked shard.\n func (c *Counter) incrementCounter(ctx context.Context, docRef *firestore.DocumentRef) (*firestore.WriteResult, error) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(asset): add samples for AnalyzeIamPolicy and AnalyzeIamPolicyLongrunning",
        "pr_number": 1840,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -71,9 +76,11 @@\nfunc (c *Counter) incrementCounter(ctx context.Context, docRef *firestore.Docume\n \t})\n }\n \n+// [END firestore_solution_sharded_counter_increment]\n // [END fs_increment_counter]\n \n // [START fs_get_count]\n+// [START firestore_solution_sharded_counter_get]\n \n // getCount returns a total count across all shards.\n func (c *Counter) getCount(ctx context.Context, docRef *firestore.DocumentRef) (int64, error) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "b119796b9c0db684abcb00943215a57ae4202709"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "asset/quickstart/list-assets/main_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage main\n \n // [START fs_initialize]\n+// [START firestore_setup_client_create]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -39,6 +40,7 @@\nfunc createClient(ctx context.Context) *firestore.Client {\n \treturn client\n }\n \n+// [END firestore_setup_client_create]\n // [END fs_initialize]\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -48,6 +50,7 @@\nfunc main() {\n \tdefer client.Close()\n \n \t// [START fs_add_data_1]\n+\t// [START firestore_setup_dataset_pt1]\n \t_, _, err := client.Collection(\"users\").Add(ctx, map[string]interface{}{\n \t\t\"first\": \"Ada\",\n \t\t\"last\":  \"Lovelace\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -56,9 +59,11 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"Failed adding alovelace: %v\", err)\n \t}\n+\t// [END firestore_setup_dataset_pt1]\n \t// [END fs_add_data_1]\n \n \t// [START fs_add_data_2]\n+\t// [START firestore_setup_dataset_pt2]\n \t_, _, err = client.Collection(\"users\").Add(ctx, map[string]interface{}{\n \t\t\"first\":  \"Alan\",\n \t\t\"middle\": \"Mathison\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -68,9 +73,11 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"Failed adding aturing: %v\", err)\n \t}\n+\t// [END firestore_setup_dataset_pt2]\n \t// [END fs_add_data_2]\n \n \t// [START fs_get_all_users]\n+\t// [START firestore_setup_dataset_read]\n \titer := client.Collection(\"users\").Documents(ctx)\n \tfor {\n \t\tdoc, err := iter.Next()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/collection_group_query.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_collection_group_query]\n+// [START firestore_query_collection_group_filter_eq]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/collection_group_setup.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_collection_group_query_data_setup]\n+// [START firestore_query_collection_group_dataset]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/increment.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_update_document_increment]\n+// [START firestore_data_set_numeric_increment]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/listen_changes.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_changes]\n+// [START firestore_listen_query_changes]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/listen_document.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_document]\n+// [START firestore_listen_document]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/listen_document.go",
        "code_diff": "@@ -29,11 +29,11 @@\nimport (\n // listenDocument listens to a single document.\n func listenDocument(ctx context.Context, w io.Writer, projectID, collection string) error {\n \t// projectID := \"project-id\"\n-\t// [START fs_detach_listener]\n+\t// [START firestore_listen_detach]\n \t// \u0421ontext with timeout stops listening to changes.\n \tctx, cancel := context.WithTimeout(ctx, 30*time.Second)\n \tdefer cancel()\n-\t// [END fs_detach_listener]\n+\t// [END firestore_listen_detach]\n \n \tclient, err := firestore.NewClient(ctx, projectID)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/listen_errors.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_errors]\n+// [START firestore_listen_handle_error]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/listen_multiple.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_multiple]\n+// [START firestore_listen_query_snapshots]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/main.go",
        "code_diff": "@@ -25,6 +25,7 @@\nimport (\n )\n \n // [START fs_class_definition]\n+// [START firestore_data_custom_type_definition]\n \n // City represents a city.\n type City struct {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -15,17 +15,20 @@\npackage main\n \n // [START fs_dependencies]\n+// [START firestore_setup_dependencies]\n import (\n \t\"context\"\n \t\"fmt\"\n \n \t\"cloud.google.com/go/firestore\"\n )\n \n+// [END firestore_setup_dependencies]\n // [END fs_dependencies]\n \n func prepareQuery(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_create_examples]\n+\t// [START firestore_query_filter_dataset]\n \tcities := []struct {\n \t\tid string\n \t\tc  City",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -66,30 +69,37 @@\nfunc prepareQuery(ctx context.Context, client *firestore.Client) error {\n \t\t\treturn err\n \t\t}\n \t}\n+\t// [END firestore_query_filter_dataset]\n \t// [END fs_query_create_examples]\n \treturn nil\n }\n \n func createQuery(client *firestore.Client) {\n \t// [START fs_create_query]\n+\t// [START firestore_query_filter_eq_boolean]\n \tquery := client.Collection(\"cities\").Where(\"capital\", \"==\", true)\n+\t// [END firestore_query_filter_eq_boolean]\n \t// [END fs_create_query]\n \t_ = query\n }\n \n func createQueryTwo(client *firestore.Client) {\n \t// [START fs_create_query_two]\n+\t// [START firestore_query_filter_eq_string]\n \tquery := client.Collection(\"cities\").Where(\"state\", \"==\", \"CA\")\n+\t// [END firestore_query_filter_eq_string]\n \t// [END fs_create_query_two]\n \t_ = query\n }\n \n func createSimpleQueries(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_simple_queries]\n+\t// [START firestore_query_filter_single_examples]\n \tcountryQuery := cities.Where(\"state\", \"==\", \"CA\")\n \tpopQuery := cities.Where(\"population\", \"<\", 1000000)\n \tcityQuery := cities.Where(\"name\", \">=\", \"San Francisco\")\n+\t// [END firestore_query_filter_single_examples]\n \t// [END fs_simple_queries]\n \n \t_ = countryQuery",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -100,8 +110,10 @@\nfunc createSimpleQueries(client *firestore.Client) {\n func createChainedQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_chained_query]\n+\t// [START firestore_query_filter_compound_multi_eq]\n \tdenverQuery := cities.Where(\"name\", \"==\", \"Denver\").Where(\"state\", \"==\", \"CO\")\n \tcaliQuery := cities.Where(\"state\", \"==\", \"CA\").Where(\"population\", \"<=\", 1000000)\n+\t// [END firestore_query_filter_compound_multi_eq]\n \t// [END fs_chained_query]\n \n \t_ = denverQuery",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -112,7 +124,9 @@\nfunc createInvalidChainedQuery(client *firestore.Client) {\n \t// Note: this is an instance of a currently unsupported chained query\n \tcities := client.Collection(\"cities\")\n \t// [START fs_invalid_chained_query]\n+\t// [START firestore_query_filter_compound_multi_eq]\n \tquery := cities.Where(\"country\", \"==\", \"USA\").Where(\"population\", \">\", 5000000)\n+\t// [END firestore_query_filter_compound_multi_eq]\n \t// [END fs_invalid_chained_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -121,8 +135,10 @@\nfunc createInvalidChainedQuery(client *firestore.Client) {\n func createRangeQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_range_query]\n+\t// [START firestore_query_filter_range_valid]\n \tstateQuery := cities.Where(\"state\", \">=\", \"CA\").Where(\"state\", \"<\", \"IN\")\n \tpopulationQuery := cities.Where(\"state\", \"==\", \"CA\").Where(\"population\", \">\", 1000000)\n+\t// [END firestore_query_filter_range_valid]\n \t// [END fs_range_query]\n \n \t_ = stateQuery",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -134,7 +150,9 @@\nfunc createInvalidRangeQuery(client *firestore.Client) {\n \t// are limited to a single field.\n \tcities := client.Collection(\"cities\")\n \t// [START fs_invalid_range_query]\n+\t// [START firestore_query_filter_range_invalid]\n \tquery := cities.Where(\"state\", \">=\", \"CA\").Where(\"population\", \">\", 1000000)\n+\t// [END firestore_query_filter_range_invalid]\n \t// [END fs_invalid_range_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -143,7 +161,9 @@\nfunc createInvalidRangeQuery(client *firestore.Client) {\n func createOrderByNameLimitQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_order_by_name_limit_query]\n+\t// [START firestore_query_order_limit]\n \tquery := cities.OrderBy(\"name\", firestore.Asc).Limit(3)\n+\t// [END firestore_query_order_limit]\n \t// [END fs_order_by_name_limit_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -152,7 +172,9 @@\nfunc createOrderByNameLimitQuery(client *firestore.Client) {\n func createOrderByNameLimitToLastQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_order_by_name_limit_to_last_query]\n+\t// [START firestore_query_order_limit]\n \tquery := cities.OrderBy(\"name\", firestore.Asc).LimitToLast(3)\n+\t// [END firestore_query_order_limit]\n \t// [END fs_order_by_name_limit_to_last_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -161,23 +183,29 @@\nfunc createOrderByNameLimitToLastQuery(client *firestore.Client) {\n func createOrderByNameDescLimitQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_order_by_name_desc_limit_query]\n+\t// [START firestore_query_order_desc_limit]\n \tquery := cities.OrderBy(\"name\", firestore.Desc).Limit(3)\n+\t// [END firestore_query_order_desc_limit]\n \t// [END fs_order_by_name_desc_limit_query]\n \n \t_ = query\n }\n \n func createMultipleOrderByQuery(client *firestore.Client) {\n \t// [START fs_order_by_multiple]\n+\t// [START firestore_query_order_multi]\n \tquery := client.Collection(\"cities\").OrderBy(\"state\", firestore.Asc).OrderBy(\"population\", firestore.Desc)\n+\t// [END firestore_query_order_multi]\n \t// [END fs_order_by_multiple]\n \t_ = query\n }\n \n func createRangeWithOrderByAndLimitQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_where_order_by_limit_query]\n+\t// [START firestore_query_order_limit_field_valid]\n \tquery := cities.Where(\"population\", \">\", 2500000).OrderBy(\"population\", firestore.Desc).Limit(2)\n+\t// [END firestore_query_order_limit_field_valid]\n \t// [END fs_where_order_by_limit_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -186,7 +214,9 @@\nfunc createRangeWithOrderByAndLimitQuery(client *firestore.Client) {\n func createRangeWithOrderByQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_range_order_by_query]\n+\t// [START firestore_query_order_with_filter]\n \tquery := cities.Where(\"population\", \">\", 2500000).OrderBy(\"population\", firestore.Asc)\n+\t// [END firestore_query_order_with_filter]\n \t// [END fs_range_order_by_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -195,30 +225,37 @@\nfunc createRangeWithOrderByQuery(client *firestore.Client) {\n func createInvalidRangeWithOrderByQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_invalid_range_order_by_query]\n+\t// [START firestore_query_order_field_invalid]\n \t// Note: This is an invalid query. It violates the constraint that range\n \t// and order by are required to be on the same field.\n \tquery := cities.Where(\"population\", \">\", 2500000).OrderBy(\"country\", firestore.Asc)\n+\t// [END firestore_query_order_field_invalid]\n \t// [END fs_invalid_range_order_by_query]\n \n \t_ = query\n }\n \n func createSimpleStartAtQuery(client *firestore.Client) {\n \t// [START fs_simple_start_at]\n+\t// [START firestore_query_cursor_start_at_field_value_single]\n \tquery := client.Collection(\"cities\").OrderBy(\"population\", firestore.Asc).StartAt(1000000)\n+\t// [END firestore_query_cursor_start_at_field_value_single]\n \t// [END fs_simple_start_at]\n \t_ = query\n }\n \n func createSimpleEndtAtQuery(client *firestore.Client) {\n \t// [START fs_simple_end_at]\n+\t// [START firestore_query_cursor_end_at_field_value_single]\n \tquery := client.Collection(\"cities\").OrderBy(\"population\", firestore.Asc).EndAt(1000000)\n+\t// [END firestore_query_cursor_end_at_field_value_single]\n \t// [END fs_simple_end_at]\n \t_ = query\n }\n \n func paginateCursor(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_paginate_cursor]\n+\t// [START firestore_query_cursor_pagination]\n \tcities := client.Collection(\"cities\")\n \n \t// Get the first 25 cities, ordered by population.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -237,13 +274,15 @@\nfunc paginateCursor(ctx context.Context, client *firestore.Client) error {\n \t\tLimit(25)\n \n \t// ...\n+\t// [END firestore_query_cursor_pagination]\n \t// [END fs_paginate_cursor]\n \t_ = secondPage\n \treturn nil\n }\n \n func createMultipleStartAtQuery(client *firestore.Client) {\n \t// [START fs_start_at_multiple]\n+\t// [START firestore_query_cursor_start_at_field_value_multi]\n \t// Will return all Springfields.\n \tclient.Collection(\"cities\").\n \t\tOrderBy(\"name\", firestore.Asc).",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -255,13 +294,16 @@\nfunc createMultipleStartAtQuery(client *firestore.Client) {\n \t\tOrderBy(\"name\", firestore.Asc).\n \t\tOrderBy(\"state\", firestore.Asc).\n \t\tStartAt(\"Springfield\", \"Wisconsin\")\n+\t// [END firestore_query_cursor_start_at_field_value_multi]\n \t// [END fs_start_at_multiple]\n }\n \n func createInQuery(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_filter_in]\n+\t// [START firestore_query_filter_in]\n \tcities := client.Collection(\"cities\")\n \tquery := cities.Where(\"country\", \"in\", []string{\"USA\", \"Japan\"}).Documents(ctx)\n+\t// [END firestore_query_filter_in]\n \t// [END fs_query_filter_in]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -270,8 +312,10 @@\nfunc createInQuery(ctx context.Context, client *firestore.Client) error {\n \n func createInQueryWithArray(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_filter_in_with_array]\n+\t// [START firestore_query_filter_in_with_array]\n \tcities := client.Collection(\"cities\")\n \tquery := cities.Where(\"regions\", \"in\", [][]string{{\"west_coast\"}, {\"east_coast\"}}).Documents(ctx)\n+\t// [END firestore_query_filter_in_with_array]\n \t// [END fs_query_filter_in_with_array]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -281,7 +325,9 @@\nfunc createInQueryWithArray(ctx context.Context, client *firestore.Client) error\n func createArrayContainsQuery(ctx context.Context, client *firestore.Client) error {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_array_contains_query]\n+\t// [START firestore_query_filter_array_contains]\n \tquery := cities.Where(\"regions\", \"array-contains\", \"west_coast\").Documents(ctx)\n+\t// [END firestore_query_filter_array_contains]\n \t// [END fs_array_contains_query]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -290,8 +336,10 @@\nfunc createArrayContainsQuery(ctx context.Context, client *firestore.Client) err\n \n func createArrayContainsAnyQuery(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_filter_array_contains_any]\n+\t// [START firestore_query_filter_array_contains_any]\n \tcities := client.Collection(\"cities\")\n \tquery := cities.Where(\"regions\", \"array-contains-any\", []string{\"west_coast\", \"east_coast\"}).Documents(ctx)\n+\t// [END firestore_query_filter_array_contains_any]\n \t// [END fs_query_filter_array_contains_any]\n \n \t_ = query",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -25,39 +25,48 @@\nimport (\n \n func createDocReference(client *firestore.Client) {\n \t// [START fs_doc_reference]\n+\t// [START firestore_data_reference_document]\n \talovelaceRef := client.Collection(\"users\").Doc(\"alovelace\")\n+\t// [END firestore_data_reference_document]\n \t// [END fs_doc_reference]\n \n \t_ = alovelaceRef\n }\n \n func createCollectionReference(client *firestore.Client) {\n \t// [START fs_coll_reference]\n+\t// [START firestore_data_reference_collection]\n \tusersRef := client.Collection(\"users\")\n+\t// [END firestore_data_reference_collection]\n \t// [END fs_coll_reference]\n \n \t_ = usersRef\n }\n \n func createDocReferenceFromString(client *firestore.Client) {\n \t// [START fs_doc_reference_alternate]\n+\t// [START firestore_data_reference_document_path]\n \talovelaceRef := client.Doc(\"users/alovelace\")\n+\t// [END firestore_data_reference_document_path]\n \t// [END fs_doc_reference_alternate]\n \n \t_ = alovelaceRef\n }\n \n func createSubcollectionReference(client *firestore.Client) {\n \t// [START fs_subcoll_reference]\n+\t// [START firestore_data_reference_subcollection]\n \tmessageRef := client.Collection(\"rooms\").Doc(\"roomA\").\n \t\tCollection(\"messages\").Doc(\"message1\")\n+\t// [END firestore_data_reference_subcollection]\n \t// [END fs_subcoll_reference]\n \n \t_ = messageRef\n }\n \n func prepareRetrieve(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_retrieve_create_examples]\n+\t// [START firestore_data_get_dataset]\n \tcities := []struct {\n \t\tid string\n \t\tc  City",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -74,37 +83,43 @@\nfunc prepareRetrieve(ctx context.Context, client *firestore.Client) error {\n \t\t\treturn err\n \t\t}\n \t}\n+\t// [END firestore_data_get_dataset]\n \t// [END fs_retrieve_create_examples]\n \treturn nil\n }\n \n func docAsMap(ctx context.Context, client *firestore.Client) (map[string]interface{}, error) {\n \t// [START fs_get_doc_as_map]\n+\t// [START firestore_data_get_as_map]\n \tdsnap, err := client.Collection(\"cities\").Doc(\"SF\").Get(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \tm := dsnap.Data()\n \tfmt.Printf(\"Document data: %#v\\n\", m)\n+\t// [END firestore_data_get_as_map]\n \t// [END fs_get_doc_as_map]\n \treturn m, nil\n }\n \n func docAsEntity(ctx context.Context, client *firestore.Client) (*City, error) {\n \t// [START fs_get_doc_as_entity]\n+\t// [START firestore_data_get_as_custom_type]\n \tdsnap, err := client.Collection(\"cities\").Doc(\"BJ\").Get(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \tvar c City\n \tdsnap.DataTo(&c)\n \tfmt.Printf(\"Document data: %#v\\n\", c)\n+\t// [END firestore_data_get_as_custom_type]\n \t// [END fs_get_doc_as_entity]\n \treturn &c, nil\n }\n \n func multipleDocs(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_get_multiple_docs]\n+\t// [START firestore_data_query]\n \tfmt.Println(\"All capital cities:\")\n \titer := client.Collection(\"cities\").Where(\"capital\", \"==\", true).Documents(ctx)\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -117,12 +132,14 @@\nfunc multipleDocs(ctx context.Context, client *firestore.Client) error {\n \t\t}\n \t\tfmt.Println(doc.Data())\n \t}\n+\t// [END firestore_data_query]\n \t// [END fs_get_multiple_docs]\n \treturn nil\n }\n \n func allDocs(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_get_all_docs]\n+\t// [START firestore_data_get_all_documents]\n \tfmt.Println(\"All cities:\")\n \titer := client.Collection(\"cities\").Documents(ctx)\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -135,12 +152,14 @@\nfunc allDocs(ctx context.Context, client *firestore.Client) error {\n \t\t}\n \t\tfmt.Println(doc.Data())\n \t}\n+\t// [END firestore_data_get_all_documents]\n \t// [END fs_get_all_docs]\n \treturn nil\n }\n \n func getCollections(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_get_collections]\n+\t// [START firestore_data_get_sub_collections]\n \titer := client.Collection(\"cities\").Doc(\"SF\").Collections(ctx)\n \tfor {\n \t\tcollRef, err := iter.Next()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -27,6 +27,7 @@\nimport (\n \n func addDocAsMap(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_simple_doc_as_map]\n+\t// [START firestore_data_set_from_map]\n \t_, err := client.Collection(\"cities\").Doc(\"LA\").Set(ctx, map[string]interface{}{\n \t\t\"name\":    \"Los Angeles\",\n \t\t\"state\":   \"CA\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -36,12 +37,14 @@\nfunc addDocAsMap(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_from_map]\n \t// [END fs_add_simple_doc_as_map]\n \treturn err\n }\n \n func addDocDataTypes(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_doc_data_types]\n+\t// [START firestore_data_set_from_map_nested]\n \tdoc := make(map[string]interface{})\n \tdoc[\"stringExample\"] = \"Hello world!\"\n \tdoc[\"booleanExample\"] = true",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -59,24 +62,28 @@\nfunc addDocDataTypes(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_from_map_nested]\n \t// [END fs_add_doc_data_types]\n \treturn err\n }\n \n func addDocWithID(ctx context.Context, client *firestore.Client) error {\n \tvar data = make(map[string]interface{})\n \t// [START fs_add_doc_with_id]\n+\t// [START firestore_data_set_id_specified]\n \t_, err := client.Collection(\"cities\").Doc(\"new-city-id\").Set(ctx, data)\n \tif err != nil {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_id_specified]\n \t// [END fs_add_doc_with_id]\n \treturn err\n }\n \n func addDocWithoutID(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_doc_auto_id]\n+\t// [START firestore_data_set_id_random_collection]\n \t_, _, err := client.Collection(\"cities\").Add(ctx, map[string]interface{}{\n \t\t\"name\":    \"Tokyo\",\n \t\t\"country\": \"Japan\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -85,12 +92,14 @@\nfunc addDocWithoutID(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_id_random_collection]\n \t// [END fs_add_doc_auto_id]\n \treturn err\n }\n \n func addDocAsEntity(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_simple_doc_as_entity]\n+\t// [START firestore_data_set_from_custom_type]\n \tcity := City{\n \t\tName:    \"Los Angeles\",\n \t\tCountry: \"USA\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -100,6 +109,7 @@\nfunc addDocAsEntity(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_from_custom_type]\n \t// [END fs_add_simple_doc_as_entity]\n \treturn err\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -111,6 +121,7 @@\nfunc addDocAfterAutoGeneratedID(ctx context.Context, client *firestore.Client) e\n \t}\n \n \t// [START fs_add_doc_data_after_auto_id]\n+\t// [START firestore_data_set_id_random_document_ref]\n \tref := client.Collection(\"cities\").NewDoc()\n \n \t// later...",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -119,6 +130,7 @@\nfunc addDocAfterAutoGeneratedID(ctx context.Context, client *firestore.Client) e\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_id_random_document_ref]\n \t// [END fs_add_doc_data_after_auto_id]\n \treturn err\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -132,6 +144,7 @@\nfunc updateDoc(ctx context.Context, client *firestore.Client) error {\n \t\tlog.Printf(\"adding city DC: %s\", err)\n \t}\n \t// [START fs_update_doc]\n+\t// [START firestore_data_set_field]\n \t_, err = client.Collection(\"cities\").Doc(\"DC\").Update(ctx, []firestore.Update{\n \t\t{\n \t\t\tPath:  \"capital\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -142,12 +155,14 @@\nfunc updateDoc(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_field]\n \t// [END fs_update_doc]\n \treturn err\n }\n \n func updateDocCreateIfMissing(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_update_create_if_missing]\n+\t// [START firestore_data_set_doc_upsert]\n \t_, err := client.Collection(\"cities\").Doc(\"BJ\").Set(ctx, map[string]interface{}{\n \t\t\"capital\": true,\n \t}, firestore.MergeAll)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -156,6 +171,7 @@\nfunc updateDocCreateIfMissing(ctx context.Context, client *firestore.Client) err\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_doc_upsert]\n \t// [END fs_update_create_if_missing]\n \treturn err\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -183,6 +199,7 @@\nfunc updateDocMultiple(ctx context.Context, client *firestore.Client) error {\n \n func updateDocNested(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_update_nested_fields]\n+\t// [START firestore_data_set_nested_fields]\n \tinitialData := map[string]interface{}{\n \t\t\"name\": \"Frank\",\n \t\t\"age\":  12,",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -210,6 +227,7 @@\nfunc updateDocNested(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_nested_fields]\n \t// [END fs_update_nested_fields]\n \treturn err\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -223,30 +241,35 @@\nfunc updateDocServerTimestamp(ctx context.Context, client *firestore.Client) err\n \t}\n \n \t// [START fs_update_server_timestamp]\n+\t// [START firestore_data_set_server_timestamp]\n \t_, err := client.Collection(\"objects\").Doc(\"some-id\").Set(ctx, map[string]interface{}{\n \t\t\"timestamp\": firestore.ServerTimestamp,\n \t}, firestore.MergeAll)\n \tif err != nil {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_server_timestamp]\n \t// [END fs_update_server_timestamp]\n \treturn err\n }\n \n func deleteDoc(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_delete_doc]\n+\t// [START firestore_data_delete_doc]\n \t_, err := client.Collection(\"cities\").Doc(\"DC\").Delete(ctx)\n \tif err != nil {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_delete_doc]\n \t// [END fs_delete_doc]\n \treturn err\n }\n \n func deleteField(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_delete_field]\n+\t// [START firestore_data_delete_field]\n \t_, err := client.Collection(\"cities\").Doc(\"BJ\").Update(ctx, []firestore.Update{\n \t\t{\n \t\t\tPath:  \"capital\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -257,6 +280,7 @@\nfunc deleteField(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_delete_field]\n \t// [END fs_delete_field]\n \n \t// Use Set once this feature is implemented:",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -268,6 +292,7 @@\nfunc deleteField(ctx context.Context, client *firestore.Client) error {\n }\n \n // [START fs_delete_collection]\n+// [START firestore_data_delete_collection]\n func deleteCollection(ctx context.Context, client *firestore.Client,\n \tref *firestore.CollectionRef, batchSize int) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -306,6 +331,7 @@\nfunc deleteCollection(ctx context.Context, client *firestore.Client,\n \t}\n }\n \n+// [END firestore_data_delete_collection]\n // [END fs_delete_collection]\n \n func runSimpleTransaction(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -318,6 +344,7 @@\nfunc runSimpleTransaction(ctx context.Context, client *firestore.Client) error {\n \t}\n \n \t// [START fs_run_simple_transaction]\n+\t// [START firestore_transaction_document_update]\n \tref := client.Collection(\"cities\").Doc(\"SF\")\n \terr := client.RunTransaction(ctx, func(ctx context.Context, tx *firestore.Transaction) error {\n \t\tdoc, err := tx.Get(ref) // tx.Get, NOT ref.Get!",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -336,12 +363,14 @@\nfunc runSimpleTransaction(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors appropriately in this section.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_transaction_document_update]\n \t// [END fs_run_simple_transaction]\n \treturn err\n }\n \n func infoTransaction(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_return_info_transaction]\n+\t// [START firestore_transaction_document_update_conditional]\n \tref := client.Collection(\"cities\").Doc(\"SF\")\n \terr := client.RunTransaction(ctx, func(ctx context.Context, tx *firestore.Transaction) error {\n \t\tdoc, err := tx.Get(ref)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -364,12 +393,14 @@\nfunc infoTransaction(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_transaction_document_update_conditional]\n \t// [END fs_return_info_transaction]\n \treturn err\n }\n \n func batchWrite(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_batch_write]\n+\t// [START firestore_data_batch_writes]\n \t// Get a new write batch.\n \tbatch := client.Batch()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_counter_classes]\n+// [START firestore_solution_sharded_counter_custom_type]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -37,9 +38,11 @@\ntype Shard struct {\n \tCount int\n }\n \n+// [END firestore_solution_sharded_counter_custom_type]\n // [END fs_counter_classes]\n \n // [START fs_create_counter]\n+// [START firestore_solution_sharded_counter_create]\n \n // initCounter creates a given number of shards as\n // subcollection of specified document.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -57,9 +60,11 @@\nfunc (c *Counter) initCounter(ctx context.Context, docRef *firestore.DocumentRef\n \treturn nil\n }\n \n+// [END firestore_solution_sharded_counter_create]\n // [END fs_create_counter]\n \n // [START fs_increment_counter]\n+// [START firestore_solution_sharded_counter_increment]\n \n // incrementCounter increments a randomly picked shard.\n func (c *Counter) incrementCounter(ctx context.Context, docRef *firestore.DocumentRef) (*firestore.WriteResult, error) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -71,9 +76,11 @@\nfunc (c *Counter) incrementCounter(ctx context.Context, docRef *firestore.Docume\n \t})\n }\n \n+// [END firestore_solution_sharded_counter_increment]\n // [END fs_increment_counter]\n \n // [START fs_get_count]\n+// [START firestore_solution_sharded_counter_get]\n \n // getCount returns a total count across all shards.\n func (c *Counter) getCount(ctx context.Context, docRef *firestore.DocumentRef) (int64, error) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "fix(pubsub): remove channel usage in concurrency sample",
        "pr_number": 1825,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -360,46 +360,55 @@\nfunc TestCreateWithDeadLetterPolicy(t *testing.T) {\n \tdeadLetterSubID := subID + \"-dead-letter-sub\"\n \tdeadLetterSinkID := topicID + \"-dead-letter-sink\"\n \n-\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSourceTopic.Delete(ctx)\n-\tdefer deadLetterSourceTopic.Stop()\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSourceTopic.Delete(ctx)\n+\t\tdefer deadLetterSourceTopic.Stop()\n \n-\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSinkTopic.Delete(ctx)\n-\tdefer deadLetterSinkTopic.Stop()\n+\t\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSinkTopic.Delete(ctx)\n+\t\tdefer deadLetterSinkTopic.Stop()\n \n-\tbuf := new(bytes.Buffer)\n-\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n-\t\tt.Fatalf(\"createSubWithDeadLetter failed: %v\", err)\n-\t}\n-\tsub := client.Subscription(deadLetterSubID)\n-\tok, err := sub.Exists(context.Background())\n-\tif err != nil {\n-\t\tt.Fatalf(\"sub.Exists failed: %v\", err)\n-\t}\n-\tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", deadLetterSubID)\n-\t}\n-\tdefer sub.Delete(ctx)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n+\t\t\tr.Errorf(\"createSubWithDeadLetter failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tsub := client.Subscription(deadLetterSubID)\n+\t\tok, err := sub.Exists(context.Background())\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"sub.Exists failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif !ok {\n+\t\t\tr.Errorf(\"got none; want sub = %q\", deadLetterSubID)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer sub.Delete(ctx)\n \n-\tcfg, err := sub.Config(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := cfg.DeadLetterPolicy\n-\twant := &pubsub.DeadLetterPolicy{\n-\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n-\t\tMaxDeliveryAttempts: 10,\n-\t}\n-\tif !cmp.Equal(got, want) {\n-\t\tt.Fatalf(\"got cfg: %+v; want cfg: %+v\", got, want)\n-\t}\n+\t\tcfg, err := sub.Config(ctx)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"createSubWithDeadLetter config: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tgot := cfg.DeadLetterPolicy\n+\t\twant := &pubsub.DeadLetterPolicy{\n+\t\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n+\t\t\tMaxDeliveryAttempts: 10,\n+\t\t}\n+\t\tif !cmp.Equal(got, want) {\n+\t\t\tr.Errorf(\"got cfg: %+v; want cfg: %+v\", got, want)\n+\t\t\treturn\n+\t\t}\n+\t})\n }\n \n func TestUpdateDeadLetterPolicy(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-concurrency",
        "commit_id": "6e2b16be2b421d9f1c9f87b0160ce8c454d9d880"
    },
    {
        "pr_title": "fix(pubsub): remove channel usage in concurrency sample",
        "pr_number": 1825,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -411,62 +420,75 @@\nfunc TestUpdateDeadLetterPolicy(t *testing.T) {\n \tdeadLetterSubID := subID + \"-update-sub\"\n \tdeadLetterSinkID := topicID + \"-update-sink\"\n \n-\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSourceTopic.Delete(ctx)\n-\tdefer deadLetterSourceTopic.Stop()\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSourceTopic.Delete(ctx)\n+\t\tdefer deadLetterSourceTopic.Stop()\n \n-\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSinkTopic.Delete(ctx)\n-\tdefer deadLetterSinkTopic.Stop()\n+\t\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSinkTopic.Delete(ctx)\n+\t\tdefer deadLetterSinkTopic.Stop()\n \n-\tbuf := new(bytes.Buffer)\n-\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n-\t\tt.Fatalf(\"createSubWithDeadLetter failed: %v\", err)\n-\t}\n-\tsub := client.Subscription(deadLetterSubID)\n-\tok, err := sub.Exists(context.Background())\n-\tif err != nil {\n-\t\tt.Fatalf(\"sub.Exists failed: %v\", err)\n-\t}\n-\tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", deadLetterSubID)\n-\t}\n-\tdefer sub.Delete(ctx)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n+\t\t\tr.Errorf(\"createSubWithDeadLetter failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tsub := client.Subscription(deadLetterSubID)\n+\t\tok, err := sub.Exists(context.Background())\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"sub.Exists failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif !ok {\n+\t\t\tr.Errorf(\"got none; want sub = %q\", deadLetterSubID)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer sub.Delete(ctx)\n \n-\tif err := updateDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSinkTopic.String()); err != nil {\n-\t\tt.Fatalf(\"updateDeadLetter failed: %v\", err)\n-\t}\n+\t\tif err := updateDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSinkTopic.String()); err != nil {\n+\t\t\tr.Errorf(\"updateDeadLetter failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n \n-\tcfg, err := sub.Config(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := cfg.DeadLetterPolicy\n-\twant := &pubsub.DeadLetterPolicy{\n-\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n-\t\tMaxDeliveryAttempts: 20,\n-\t}\n-\tif !cmp.Equal(got, want) {\n-\t\tt.Fatalf(\"got cfg: %+v; want cfg: %+v\", got, want)\n-\t}\n+\t\tcfg, err := sub.Config(ctx)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"update dead letter policy config: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tgot := cfg.DeadLetterPolicy\n+\t\twant := &pubsub.DeadLetterPolicy{\n+\t\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n+\t\t\tMaxDeliveryAttempts: 20,\n+\t\t}\n+\t\tif !cmp.Equal(got, want) {\n+\t\t\tr.Errorf(\"got cfg: %+v; want cfg: %+v\", got, want)\n+\t\t\treturn\n+\t\t}\n \n-\tif err := removeDeadLetterTopic(buf, tc.ProjectID, deadLetterSubID); err != nil {\n-\t\tt.Fatalf(\"removeDeadLetterTopic failed: %v\", err)\n-\t}\n-\tcfg, err = sub.Config(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot = cfg.DeadLetterPolicy\n-\tif got != nil {\n-\t\tt.Fatalf(\"got dead letter policy: %+v, want nil\", got)\n-\t}\n+\t\tif err := removeDeadLetterTopic(buf, tc.ProjectID, deadLetterSubID); err != nil {\n+\t\t\tr.Errorf(\"removeDeadLetterTopic failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tcfg, err = sub.Config(ctx)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"update dead letter policy config: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tgot = cfg.DeadLetterPolicy\n+\t\tif got != nil {\n+\t\t\tr.Errorf(\"got dead letter policy: %+v, want nil\", got)\n+\t\t\treturn\n+\t\t}\n+\t})\n }\n \n func TestPullMsgsDeadLetterDeliveryAttempts(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-concurrency",
        "commit_id": "6e2b16be2b421d9f1c9f87b0160ce8c454d9d880"
    },
    {
        "pr_title": "chore(opentelemetry): update trace example to latest released APIs",
        "pr_number": 1821,
        "file_name": "appengine/go11x/tasks/create_task/create_task_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage main\n \n import (\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "5bea6b818b2d03b5f771f0ec2ef28c1555e2b519"
    },
    {
        "pr_title": "chore(opentelemetry): update trace example to latest released APIs",
        "pr_number": 1821,
        "file_name": "functions/security/idtoken.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage security\n \n // [START functions_bearer_token]\n+// [START cloudrun_service_to_service_auth]\n // [START run_service_to_service_auth]\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "5bea6b818b2d03b5f771f0ec2ef28c1555e2b519"
    },
    {
        "pr_title": "chore(opentelemetry): update trace example to latest released APIs",
        "pr_number": 1821,
        "file_name": "functions/tips/lazy.go",
        "code_diff": "@@ -13,6 +13,7 @@\n// limitations under the License.\n \n // [START functions_tips_lazy_globals]\n+// [START cloudrun_tips_global_lazy]\n // [START run_tips_global_lazy]\n \n // Package tips contains tips for writing Cloud Functions in Go.",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "5bea6b818b2d03b5f771f0ec2ef28c1555e2b519"
    },
    {
        "pr_title": "chore(opentelemetry): update trace example to latest released APIs",
        "pr_number": 1821,
        "file_name": "functions/tips/scope.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n )\n \n // [START functions_tips_scopes]\n+// [START cloudrun_tips_global_scope]\n // [START run_tips_global_scope]\n \n // h is in the global (instance-wide) scope.",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "5bea6b818b2d03b5f771f0ec2ef28c1555e2b519"
    },
    {
        "pr_title": "chore(opentelemetry): update trace example to latest released APIs",
        "pr_number": 1821,
        "file_name": "pubsub/subscriptions/pull_concurrency.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"runtime\"\n+\t\"sync/atomic\"\n \t\"time\"\n \n \t\"cloud.google.com/go/pubsub\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "5bea6b818b2d03b5f771f0ec2ef28c1555e2b519"
    },
    {
        "pr_title": "chore(opentelemetry): update trace example to latest released APIs",
        "pr_number": 1821,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -302,9 +302,10 @@\nfunc TestPullMsgsConcurrencyControl(t *testing.T) {\n \tif err := pullMsgsConcurrenyControl(buf, tc.ProjectID, subIDConc); err != nil {\n \t\tt.Fatalf(\"failed to pull messages: %v\", err)\n \t}\n-\t// Check for number of newlines, which should correspond with number of messages.\n-\tif got := strings.Count(buf.String(), \"\\n\"); got != numMsgs {\n-\t\tt.Fatalf(\"pullMsgsConcurrencyControl got %d messages, want %d\", got, numMsgs)\n+\tgot := buf.String()\n+\twant := fmt.Sprintf(\"Received %d messages\\n\", numMsgs)\n+\tif got != want {\n+\t\tt.Fatalf(\"pullMsgsConcurrencyControl got %s\\nwant %s\", got, want)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "5bea6b818b2d03b5f771f0ec2ef28c1555e2b519"
    },
    {
        "pr_title": "chore(opentelemetry): update trace example to latest released APIs",
        "pr_number": 1821,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -359,46 +360,55 @@\nfunc TestCreateWithDeadLetterPolicy(t *testing.T) {\n \tdeadLetterSubID := subID + \"-dead-letter-sub\"\n \tdeadLetterSinkID := topicID + \"-dead-letter-sink\"\n \n-\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSourceTopic.Delete(ctx)\n-\tdefer deadLetterSourceTopic.Stop()\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSourceTopic.Delete(ctx)\n+\t\tdefer deadLetterSourceTopic.Stop()\n \n-\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSinkTopic.Delete(ctx)\n-\tdefer deadLetterSinkTopic.Stop()\n+\t\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSinkTopic.Delete(ctx)\n+\t\tdefer deadLetterSinkTopic.Stop()\n \n-\tbuf := new(bytes.Buffer)\n-\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n-\t\tt.Fatalf(\"createSubWithDeadLetter failed: %v\", err)\n-\t}\n-\tsub := client.Subscription(deadLetterSubID)\n-\tok, err := sub.Exists(context.Background())\n-\tif err != nil {\n-\t\tt.Fatalf(\"sub.Exists failed: %v\", err)\n-\t}\n-\tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", deadLetterSubID)\n-\t}\n-\tdefer sub.Delete(ctx)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n+\t\t\tr.Errorf(\"createSubWithDeadLetter failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tsub := client.Subscription(deadLetterSubID)\n+\t\tok, err := sub.Exists(context.Background())\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"sub.Exists failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif !ok {\n+\t\t\tr.Errorf(\"got none; want sub = %q\", deadLetterSubID)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer sub.Delete(ctx)\n \n-\tcfg, err := sub.Config(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := cfg.DeadLetterPolicy\n-\twant := &pubsub.DeadLetterPolicy{\n-\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n-\t\tMaxDeliveryAttempts: 10,\n-\t}\n-\tif !cmp.Equal(got, want) {\n-\t\tt.Fatalf(\"got cfg: %+v; want cfg: %+v\", got, want)\n-\t}\n+\t\tcfg, err := sub.Config(ctx)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"createSubWithDeadLetter config: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tgot := cfg.DeadLetterPolicy\n+\t\twant := &pubsub.DeadLetterPolicy{\n+\t\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n+\t\t\tMaxDeliveryAttempts: 10,\n+\t\t}\n+\t\tif !cmp.Equal(got, want) {\n+\t\t\tr.Errorf(\"got cfg: %+v; want cfg: %+v\", got, want)\n+\t\t\treturn\n+\t\t}\n+\t})\n }\n \n func TestUpdateDeadLetterPolicy(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "5bea6b818b2d03b5f771f0ec2ef28c1555e2b519"
    },
    {
        "pr_title": "chore(opentelemetry): update trace example to latest released APIs",
        "pr_number": 1821,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -410,62 +420,75 @@\nfunc TestUpdateDeadLetterPolicy(t *testing.T) {\n \tdeadLetterSubID := subID + \"-update-sub\"\n \tdeadLetterSinkID := topicID + \"-update-sink\"\n \n-\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSourceTopic.Delete(ctx)\n-\tdefer deadLetterSourceTopic.Stop()\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSourceTopic.Delete(ctx)\n+\t\tdefer deadLetterSourceTopic.Stop()\n \n-\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSinkTopic.Delete(ctx)\n-\tdefer deadLetterSinkTopic.Stop()\n+\t\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSinkTopic.Delete(ctx)\n+\t\tdefer deadLetterSinkTopic.Stop()\n \n-\tbuf := new(bytes.Buffer)\n-\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n-\t\tt.Fatalf(\"createSubWithDeadLetter failed: %v\", err)\n-\t}\n-\tsub := client.Subscription(deadLetterSubID)\n-\tok, err := sub.Exists(context.Background())\n-\tif err != nil {\n-\t\tt.Fatalf(\"sub.Exists failed: %v\", err)\n-\t}\n-\tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", deadLetterSubID)\n-\t}\n-\tdefer sub.Delete(ctx)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n+\t\t\tr.Errorf(\"createSubWithDeadLetter failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tsub := client.Subscription(deadLetterSubID)\n+\t\tok, err := sub.Exists(context.Background())\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"sub.Exists failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif !ok {\n+\t\t\tr.Errorf(\"got none; want sub = %q\", deadLetterSubID)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer sub.Delete(ctx)\n \n-\tif err := updateDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSinkTopic.String()); err != nil {\n-\t\tt.Fatalf(\"updateDeadLetter failed: %v\", err)\n-\t}\n+\t\tif err := updateDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSinkTopic.String()); err != nil {\n+\t\t\tr.Errorf(\"updateDeadLetter failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n \n-\tcfg, err := sub.Config(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := cfg.DeadLetterPolicy\n-\twant := &pubsub.DeadLetterPolicy{\n-\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n-\t\tMaxDeliveryAttempts: 20,\n-\t}\n-\tif !cmp.Equal(got, want) {\n-\t\tt.Fatalf(\"got cfg: %+v; want cfg: %+v\", got, want)\n-\t}\n+\t\tcfg, err := sub.Config(ctx)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"update dead letter policy config: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tgot := cfg.DeadLetterPolicy\n+\t\twant := &pubsub.DeadLetterPolicy{\n+\t\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n+\t\t\tMaxDeliveryAttempts: 20,\n+\t\t}\n+\t\tif !cmp.Equal(got, want) {\n+\t\t\tr.Errorf(\"got cfg: %+v; want cfg: %+v\", got, want)\n+\t\t\treturn\n+\t\t}\n \n-\tif err := removeDeadLetterTopic(buf, tc.ProjectID, deadLetterSubID); err != nil {\n-\t\tt.Fatalf(\"removeDeadLetterTopic failed: %v\", err)\n-\t}\n-\tcfg, err = sub.Config(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot = cfg.DeadLetterPolicy\n-\tif got != nil {\n-\t\tt.Fatalf(\"got dead letter policy: %+v, want nil\", got)\n-\t}\n+\t\tif err := removeDeadLetterTopic(buf, tc.ProjectID, deadLetterSubID); err != nil {\n+\t\t\tr.Errorf(\"removeDeadLetterTopic failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tcfg, err = sub.Config(ctx)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"update dead letter policy config: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tgot = cfg.DeadLetterPolicy\n+\t\tif got != nil {\n+\t\t\tr.Errorf(\"got dead letter policy: %+v, want nil\", got)\n+\t\t\treturn\n+\t\t}\n+\t})\n }\n \n func TestPullMsgsDeadLetterDeliveryAttempts(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "5bea6b818b2d03b5f771f0ec2ef28c1555e2b519"
    },
    {
        "pr_title": "test(pubsub): wrap dead letter sample test in retry",
        "pr_number": 1818,
        "file_name": "appengine/go11x/tasks/create_task/create_task_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage main\n \n import (\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into dlq-retry",
        "commit_id": "a24c17701f32d8df528378e5f2ecbf3a2c3b878a"
    },
    {
        "pr_title": "test(pubsub): wrap dead letter sample test in retry",
        "pr_number": 1818,
        "file_name": "functions/security/idtoken.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage security\n \n // [START functions_bearer_token]\n+// [START cloudrun_service_to_service_auth]\n // [START run_service_to_service_auth]\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into dlq-retry",
        "commit_id": "a24c17701f32d8df528378e5f2ecbf3a2c3b878a"
    },
    {
        "pr_title": "test(pubsub): wrap dead letter sample test in retry",
        "pr_number": 1818,
        "file_name": "functions/tips/lazy.go",
        "code_diff": "@@ -13,6 +13,7 @@\n// limitations under the License.\n \n // [START functions_tips_lazy_globals]\n+// [START cloudrun_tips_global_lazy]\n // [START run_tips_global_lazy]\n \n // Package tips contains tips for writing Cloud Functions in Go.",
        "comments": [],
        "commit_message": "Merge branch 'master' into dlq-retry",
        "commit_id": "a24c17701f32d8df528378e5f2ecbf3a2c3b878a"
    },
    {
        "pr_title": "test(pubsub): wrap dead letter sample test in retry",
        "pr_number": 1818,
        "file_name": "functions/tips/scope.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n )\n \n // [START functions_tips_scopes]\n+// [START cloudrun_tips_global_scope]\n // [START run_tips_global_scope]\n \n // h is in the global (instance-wide) scope.",
        "comments": [],
        "commit_message": "Merge branch 'master' into dlq-retry",
        "commit_id": "a24c17701f32d8df528378e5f2ecbf3a2c3b878a"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/authentication/auth.go",
        "code_diff": "@@ -15,6 +15,7 @@\n// Package authentication contains the authentication samples for Cloud Run.\n package authentication\n \n+// [START cloudrun_service_to_service_auth]\n // [START run_service_to_service_auth]\n import (\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/grpc-ping/connection.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage main\n \n+// [START cloudrun_grpc_conn]\n // [START run_grpc_conn]\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/grpc-ping/main.go",
        "code_diff": "@@ -25,6 +25,7 @@\nimport (\n \tpb \"github.com/GoogleCloudPlatform/golang-samples/run/grpc-ping/pkg/api/v1\"\n )\n \n+// [START cloudrun_grpc_server]\n // [START run_grpc_server]\n func main() {\n \tlog.Printf(\"grpc-ping: starting server...\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/grpc-ping/request.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage main\n \n+// [START cloudrun_grpc_request]\n // [START run_grpc_request]\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/grpc-ping/request_auth.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage main\n \n+// [START cloudrun_grpc_request_auth]\n // [START run_grpc_request_auth]\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/hello-broken/main.go",
        "code_diff": "@@ -12,6 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START cloudrun_broken_service]\n // [START run_broken_service]\n \n // Sample hello demonstrates a difficult to troubleshoot service.",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/hello-broken/main.go",
        "code_diff": "@@ -30,7 +31,9 @@\nfunc main() {\n \thttp.HandleFunc(\"/\", helloHandler)\n \n \t// [END run_broken_service]\n+\t// [END cloudrun_broken_service]\n \thttp.HandleFunc(\"/improved\", improvedHandler)\n+\t// [START cloudrun_broken_service]\n \t// [START run_broken_service]\n \n \tport := os.Getenv(\"PORT\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/hello-broken/main.go",
        "code_diff": "@@ -46,6 +49,7 @@\nfunc main() {\n func helloHandler(w http.ResponseWriter, r *http.Request) {\n \tlog.Print(\"hello: received request\")\n \n+\t// [START cloudrun_broken_service_problem]\n \t// [START run_broken_service_problem]\n \tname := os.Getenv(\"NAME\")\n \tif name == \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/helloworld/main.go",
        "code_diff": "@@ -12,6 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START cloudrun_helloworld_service]\n // [START run_helloworld_service]\n \n // Sample run-helloworld is a minimal Cloud Run service.",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/image-processing/imagemagick/imagemagick.go",
        "code_diff": "@@ -12,6 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START cloudrun_imageproc_handler_setup]\n // [START run_imageproc_handler_setup]\n \n // Package imagemagick contains an example of using ImageMagick to process a",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/image-processing/imagemagick/imagemagick.go",
        "code_diff": "@@ -53,7 +54,9 @@\nfunc init() {\n }\n \n // [END run_imageproc_handler_setup]\n+// [END cloudrun_imageproc_handler_setup]\n \n+// [START cloudrun_imageproc_handler_analyze]\n // [START run_imageproc_handler_analyze]\n \n // GCSEvent is the payload of a GCS event.",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/image-processing/imagemagick/imagemagick.go",
        "code_diff": "@@ -85,7 +88,9 @@\nfunc BlurOffensiveImages(ctx context.Context, e GCSEvent) error {\n }\n \n // [END run_imageproc_handler_analyze]\n+// [END cloudrun_imageproc_handler_analyze]\n \n+// [START cloudrun_imageproc_handler_blur]\n // [START run_imageproc_handler_blur]\n \n // blur blurs the image stored at gs://inputBucket/name and stores the result in",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/image-processing/main.go",
        "code_diff": "@@ -12,6 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START cloudrun_imageproc_controller]\n // [START run_imageproc_controller]\n \n // Sample image-processing is a Cloud Run service which performs asynchronous processing on images.",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/logging-manual/main.go",
        "code_diff": "@@ -51,6 +51,7 @@\nfunc main() {\n \tlog.Fatal(http.ListenAndServe(\":\"+port, nil))\n }\n \n+// [START cloudrun_manual_logging_object]\n // [START run_manual_logging_object]\n \n // Entry defines a log entry.",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/logging-manual/main.go",
        "code_diff": "@@ -76,6 +77,9 @@\nfunc (e Entry) String() string {\n }\n \n // [END run_manual_logging_object]\n+// [END cloudrun_manual_logging_object]\n+\n+// [START cloudrun_manual_logging]\n // [START run_manual_logging]\n \n func init() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage main\n \n+// [START cloudrun_secure_request]\n // [START run_secure_request]\n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -65,7 +66,9 @@\nfunc (s *RenderService) NewRequest(method string) (*http.Request, error) {\n }\n \n // [END run_secure_request]\n+// [END cloudrun_secure_request]\n \n+// [START cloudrun_secure_request_do]\n // [START run_secure_request_do]\n \n var renderClient = &http.Client{Timeout: 30 * time.Second}",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/pubsub/main.go",
        "code_diff": "@@ -12,6 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START cloudrun_pubsub_server]\n // [START run_pubsub_server]\n \n // Sample run-pubsub is a Cloud Run service which handles Pub/Sub messages.",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/pubsub/main.go",
        "code_diff": "@@ -41,7 +42,9 @@\nfunc main() {\n }\n \n // [END run_pubsub_server]\n+// [END cloudrun_pubsub_server]\n \n+// [START cloudrun_pubsub_handler]\n // [START run_pubsub_handler]\n \n // PubSubMessage is the payload of a Pub/Sub event.",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/system_package/graphviz.go",
        "code_diff": "@@ -53,6 +53,7 @@\nfunc main() {\n \t}\n }\n \n+// [START cloudrun_system_package_handler]\n // [START run_system_package_handler]\n \n // diagramHandler renders a diagram using HTTP request parameters and the dot command.",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "run/system_package/graphviz.go",
        "code_diff": "@@ -88,7 +89,9 @@\nfunc diagramHandler(w http.ResponseWriter, r *http.Request) {\n }\n \n // [END run_system_package_handler]\n+// [END cloudrun_system_package_handler]\n \n+// [START cloudrun_system_package_exec]\n // [START run_system_package_exec]\n \n // createDiagram generates a diagram image from the provided io.Reader written to the io.Writer.",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-task-retry",
        "commit_id": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "feat(logging): advanced log write sample",
        "pr_number": 1805,
        "file_name": "eventarc/generic/main.go",
        "code_diff": "@@ -14,7 +14,7 @@\n// [START eventarc_generic_handler]\n \n-// Sample eventarc-generic is a Cloud Run service which logs and echos received requests.\n+// Sample generic is a Cloud Run service which logs and echos received requests.\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:GoogleCloudPlatform/golang-samples into advanced-log",
        "commit_id": "fdc5857e99ed15e9175f45fe75fb2c6b01032933"
    },
    {
        "pr_title": "feat(logging): advanced log write sample",
        "pr_number": 1805,
        "file_name": "eventarc/generic/main.go",
        "code_diff": "@@ -24,34 +24,32 @@\nimport (\n \t\"log\"\n \t\"net/http\"\n \t\"os\"\n+\t\"strings\"\n )\n \n-func logAndRespond(w http.ResponseWriter, msg string) {\n-\tlog.Println(msg)\n-\tfmt.Fprintln(w, msg)\n-}\n-\n // GenericHandler receives and echos a HTTP request's headers and body.\n func GenericHandler(w http.ResponseWriter, r *http.Request) {\n-\tlogAndRespond(w, \"Event received!\")\n+\tlog.Println(\"Event received!\")\n \n \t// Log all headers besides authorization header\n-\tlogAndRespond(w, \"HEADERS:\")\n-\tdelete(r.Header, \"Authorization\")\n+\tlog.Println(\"HEADERS:\")\n \theaderMap := make(map[string]string)\n \tfor k, v := range r.Header {\n-\t\theaderMap[k] = string(v[0])\n-\t\tlogAndRespond(w, fmt.Sprintf(\"%q: %q\\n\", k, v[0]))\n+\t\tif k != \"Authorization\" {\n+\t\t\tval := strings.Join(v, \",\")\n+\t\t\theaderMap[k] = val\n+\t\t\tlog.Println(fmt.Sprintf(\"%q: %q\\n\", k, val))\n+\t\t}\n \t}\n \n \t// Log body\n-\tlogAndRespond(w, \"BODY:\")\n+\tlog.Println(\"BODY:\")\n \tbodyBytes, err := ioutil.ReadAll(r.Body)\n \tif err != nil {\n \t\tlog.Printf(\"error parsing body: %v\", err)\n \t}\n \tbody := string(bodyBytes)\n-\tlogAndRespond(w, body)\n+\tlog.Println(body)\n \n \t// Format and print full output\n \ttype result struct {",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:GoogleCloudPlatform/golang-samples into advanced-log",
        "commit_id": "fdc5857e99ed15e9175f45fe75fb2c6b01032933"
    },
    {
        "pr_title": "feat(logging): advanced log write sample",
        "pr_number": 1805,
        "file_name": "eventarc/generic/main_test.go",
        "code_diff": "@@ -25,7 +25,7 @@\nimport (\n \t\"testing\"\n )\n \n-func TestGenericCloudEvent(t *testing.T) {\n+func TestGenericHandler(t *testing.T) {\n \ttests := []struct {\n \t\twant string\n \t\tomit string",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:GoogleCloudPlatform/golang-samples into advanced-log",
        "commit_id": "fdc5857e99ed15e9175f45fe75fb2c6b01032933"
    },
    {
        "pr_title": "feat(logging): advanced log write sample",
        "pr_number": 1805,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -48,6 +48,7 @@\nfunc TestObjects(t *testing.T) {\n \t\tbucketVersioning      = tc.ProjectID + \"-bucket-versioning-enabled\"\n \t\tobject1               = \"foo.txt\"\n \t\tobject2               = \"foo/a.txt\"\n+\t\tobject3               = \"bar.txt\"\n \t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers\n \t\troleReader            = storage.RoleReader\n \t)",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:GoogleCloudPlatform/golang-samples into advanced-log",
        "commit_id": "fdc5857e99ed15e9175f45fe75fb2c6b01032933"
    },
    {
        "pr_title": "feat(logging): advanced log write sample",
        "pr_number": 1805,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -56,13 +57,8 @@\nfunc TestObjects(t *testing.T) {\n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, dstBucket)\n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketVersioning)\n \n-\t{\n-\t\t// Enable versioning\n-\t\tattr := storage.BucketAttrsToUpdate{VersioningEnabled: true}\n-\t\t_, err := client.Bucket(bucketVersioning).Update(ctx, attr)\n-\t\tif err != nil {\n-\t\t\tt.Fatalf(\"storage.BucketAttrsToUpdate{VersioningEnabled: true}: %v\", err)\n-\t\t}\n+\tif err := enableVersioning(ioutil.Discard, bucketVersioning); err != nil {\n+\t\tt.Fatalf(\"enableVersioning: %v\", err)\n \t}\n \n \tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:GoogleCloudPlatform/golang-samples into advanced-log",
        "commit_id": "fdc5857e99ed15e9175f45fe75fb2c6b01032933"
    },
    {
        "pr_title": "feat(logging): advanced log write sample",
        "pr_number": 1805,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -75,6 +71,20 @@\nfunc TestObjects(t *testing.T) {\n \tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n \t}\n+\t// Check enableVersioning correctly work.\n+\tbkt := client.Bucket(bucketVersioning)\n+\tbAttrs, err := bkt.Attrs(ctx)\n+\tif !bAttrs.VersioningEnabled {\n+\t\tt.Fatalf(\"object versioning is not enabled\")\n+\t}\n+\tobj := bkt.Object(object1)\n+\tattrs, err := obj.Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Object(%q).Attrs: %v\", bucketVersioning, object1, err)\n+\t}\n+\t// Keep the original generation of object1 before re-uploading\n+\t// to use in the versioning samples.\n+\tgen := attrs.Generation\n \tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:GoogleCloudPlatform/golang-samples into advanced-log",
        "commit_id": "fdc5857e99ed15e9175f45fe75fb2c6b01032933"
    },
    {
        "pr_title": "feat(logging): advanced log write sample",
        "pr_number": 1805,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -132,7 +142,13 @@\nfunc TestObjects(t *testing.T) {\n \t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)\n \t\t}\n \t}\n-\n+\tif err := copyOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, object3, gen); err != nil {\n+\t\tt.Fatalf(\"copyOldVersionOfObject: %v\", err)\n+\t}\n+\t// Delete the first version of an object1 for a bucketVersioning.\n+\tif err := deleteOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, gen); err != nil {\n+\t\tt.Fatalf(\"deleteOldVersionOfObject: %v\", err)\n+\t}\n \tdata, err := downloadFile(ioutil.Discard, bucket, object1)\n \tif err != nil {\n \t\tt.Fatalf(\"downloadFile: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:GoogleCloudPlatform/golang-samples into advanced-log",
        "commit_id": "fdc5857e99ed15e9175f45fe75fb2c6b01032933"
    },
    {
        "pr_title": "feat(logging): advanced log write sample",
        "pr_number": 1805,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -163,6 +179,9 @@\nfunc TestObjects(t *testing.T) {\n \tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \tnewKey := []byte(\"My-secret-AES-256-encryption-key\")\n \n+\tif err := generateEncryptionKey(ioutil.Discard); err != nil {\n+\t\tt.Errorf(\"generateEncryptionKey: %v\", err)\n+\t}\n \tif err := uploadEncryptedFile(ioutil.Discard, bucket, object1, key); err != nil {\n \t\tt.Errorf(\"uploadEncryptedFile: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:GoogleCloudPlatform/golang-samples into advanced-log",
        "commit_id": "fdc5857e99ed15e9175f45fe75fb2c6b01032933"
    },
    {
        "pr_title": "fix(firestore): fix TestListenChanges flakey test",
        "pr_number": 1793,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -25,8 +25,10 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\tiampb \"google.golang.org/genproto/googleapis/iam/v1\"\n )\n \n func TestCreate(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix_listen_changes_flakey_test",
        "commit_id": "970ecbe72c1dbfc946b781e0ea58d8e0c0a19392"
    },
    {
        "pr_title": "fix(firestore): fix TestListenChanges flakey test",
        "pr_number": 1793,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -124,6 +126,46 @@\nfunc TestIAM(t *testing.T) {\n \t\tt.Errorf(\"removeBucketConditionalIAMBinding: %v\", err)\n \t}\n }\n+func TestCORSConfiguration(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\twant := []storage.CORS{\n+\t\t{\n+\t\t\tMaxAge:          time.Hour,\n+\t\t\tMethods:         []string{\"GET\"},\n+\t\t\tOrigins:         []string{\"some-origin.com\"},\n+\t\t\tResponseHeaders: []string{\"Content-Type\"},\n+\t\t},\n+\t}\n+\tif err := setBucketCORSConfiguration(ioutil.Discard, bucketName, want[0].MaxAge, want[0].Methods, want[0].Origins, want[0].ResponseHeaders); err != nil {\n+\t\tt.Fatalf(\"setBucketCORSConfiguration: %v\", err)\n+\t}\n+\tattrs, err := client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif !reflect.DeepEqual(attrs.CORS, want) {\n+\t\tt.Fatalf(\"Unexpected CORS Configuration: got: %v, want: %v\", attrs.CORS, want)\n+\t}\n+\tif err := removeBucketCORSConfiguration(ioutil.Discard, bucketName); err != nil {\n+\t\tt.Fatalf(\"removeBucketCORSConfiguration: %v\", err)\n+\t}\n+\tattrs, err = client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif attrs.CORS != nil {\n+\t\tt.Fatalf(\"Unexpected CORS Configuration: got: %v, want: %v\", attrs.CORS, []storage.CORS{})\n+\t}\n+}\n \n func TestRequesterPays(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix_listen_changes_flakey_test",
        "commit_id": "970ecbe72c1dbfc946b781e0ea58d8e0c0a19392"
    },
    {
        "pr_title": "fix(firestore): fix TestListenChanges flakey test",
        "pr_number": 1793,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -144,6 +186,15 @@\nfunc TestKMS(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n \n+\tctx := context.Background()\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n+\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")\n \tcryptoKeyID := os.Getenv(\"GOLANG_SAMPLES_KMS_CRYPTOKEY\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix_listen_changes_flakey_test",
        "commit_id": "970ecbe72c1dbfc946b781e0ea58d8e0c0a19392"
    },
    {
        "pr_title": "fix(firestore): fix TestListenChanges flakey test",
        "pr_number": 1793,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -153,7 +204,24 @@\nfunc TestKMS(t *testing.T) {\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \tif err := setBucketDefaultKMSKey(ioutil.Discard, bucketName, kmsKeyName); err != nil {\n-\t\tt.Fatalf(\"setBucketDefaultKmsKey: failed to enable default kms key (%q): %v\", kmsKeyName, err)\n+\t\tt.Fatalf(\"setBucketDefaultKMSKey: failed to enable default KMS key (%q): %v\", kmsKeyName, err)\n+\t}\n+\tattrs, err := client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif attrs.Encryption.DefaultKMSKeyName != kmsKeyName {\n+\t\tt.Fatalf(\"Default KMS key was not set correctly: got %v, want %v\", attrs.Encryption.DefaultKMSKeyName, kmsKeyName)\n+\t}\n+\tif err := removeBucketDefaultKMSKey(ioutil.Discard, bucketName); err != nil {\n+\t\tt.Fatalf(\"removeBucketDefaultKMSKey: failed to remove default KMS key: %v\", err)\n+\t}\n+\tattrs, err = client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif attrs.Encryption != nil {\n+\t\tt.Fatalf(\"Default KMS key was not removed from a bucket(%v)\", bucketName)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix_listen_changes_flakey_test",
        "commit_id": "970ecbe72c1dbfc946b781e0ea58d8e0c0a19392"
    },
    {
        "pr_title": "fix(firestore): fix TestListenChanges flakey test",
        "pr_number": 1793,
        "file_name": "storage/buckets/get_bucket_policy.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage buckets\n \n-// [START storage_get_bucket_policy]\n+// [START storage_view_bucket_iam_members]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix_listen_changes_flakey_test",
        "commit_id": "970ecbe72c1dbfc946b781e0ea58d8e0c0a19392"
    },
    {
        "pr_title": "fix(firestore): fix TestListenChanges flakey test",
        "pr_number": 1793,
        "file_name": "storage/buckets/get_bucket_policy.go",
        "code_diff": "@@ -26,7 +26,7 @@\nimport (\n )\n \n // getBucketPolicy gets the bucket IAM policy.\n-func getBucketPolicy(w io.Writer, bucketName string) (*iam.Policy, error) {\n+func getBucketPolicy(w io.Writer, bucketName string) (*iam.Policy3, error) {\n \t// bucketName := \"bucket-name\"\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix_listen_changes_flakey_test",
        "commit_id": "970ecbe72c1dbfc946b781e0ea58d8e0c0a19392"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "endpoints/getting-started-grpc/server/main.go",
        "code_diff": "@@ -40,6 +40,7 @@\nimport (\n \t\"net\"\n \n \t\"google.golang.org/grpc\"\n+\t\"google.golang.org/grpc/examples/helloworld/helloworld\"\n \tpb \"google.golang.org/grpc/examples/helloworld/helloworld\"\n \t\"google.golang.org/grpc/reflection\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -25,8 +25,10 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\tiampb \"google.golang.org/genproto/googleapis/iam/v1\"\n )\n \n func TestCreate(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -124,6 +126,46 @@\nfunc TestIAM(t *testing.T) {\n \t\tt.Errorf(\"removeBucketConditionalIAMBinding: %v\", err)\n \t}\n }\n+func TestCORSConfiguration(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\twant := []storage.CORS{\n+\t\t{\n+\t\t\tMaxAge:          time.Hour,\n+\t\t\tMethods:         []string{\"GET\"},\n+\t\t\tOrigins:         []string{\"some-origin.com\"},\n+\t\t\tResponseHeaders: []string{\"Content-Type\"},\n+\t\t},\n+\t}\n+\tif err := setBucketCORSConfiguration(ioutil.Discard, bucketName, want[0].MaxAge, want[0].Methods, want[0].Origins, want[0].ResponseHeaders); err != nil {\n+\t\tt.Fatalf(\"setBucketCORSConfiguration: %v\", err)\n+\t}\n+\tattrs, err := client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif !reflect.DeepEqual(attrs.CORS, want) {\n+\t\tt.Fatalf(\"Unexpected CORS Configuration: got: %v, want: %v\", attrs.CORS, want)\n+\t}\n+\tif err := removeBucketCORSConfiguration(ioutil.Discard, bucketName); err != nil {\n+\t\tt.Fatalf(\"removeBucketCORSConfiguration: %v\", err)\n+\t}\n+\tattrs, err = client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif attrs.CORS != nil {\n+\t\tt.Fatalf(\"Unexpected CORS Configuration: got: %v, want: %v\", attrs.CORS, []storage.CORS{})\n+\t}\n+}\n \n func TestRequesterPays(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -144,6 +186,15 @@\nfunc TestKMS(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n \n+\tctx := context.Background()\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n+\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")\n \tcryptoKeyID := os.Getenv(\"GOLANG_SAMPLES_KMS_CRYPTOKEY\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -153,7 +204,24 @@\nfunc TestKMS(t *testing.T) {\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \tif err := setBucketDefaultKMSKey(ioutil.Discard, bucketName, kmsKeyName); err != nil {\n-\t\tt.Fatalf(\"setBucketDefaultKmsKey: failed to enable default kms key (%q): %v\", kmsKeyName, err)\n+\t\tt.Fatalf(\"setBucketDefaultKMSKey: failed to enable default KMS key (%q): %v\", kmsKeyName, err)\n+\t}\n+\tattrs, err := client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif attrs.Encryption.DefaultKMSKeyName != kmsKeyName {\n+\t\tt.Fatalf(\"Default KMS key was not set correctly: got %v, want %v\", attrs.Encryption.DefaultKMSKeyName, kmsKeyName)\n+\t}\n+\tif err := removeBucketDefaultKMSKey(ioutil.Discard, bucketName); err != nil {\n+\t\tt.Fatalf(\"removeBucketDefaultKMSKey: failed to remove default KMS key: %v\", err)\n+\t}\n+\tattrs, err = client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif attrs.Encryption != nil {\n+\t\tt.Fatalf(\"Default KMS key was not removed from a bucket(%v)\", bucketName)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "storage/buckets/get_bucket_policy.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage buckets\n \n-// [START storage_get_bucket_policy]\n+// [START storage_view_bucket_iam_members]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "storage/buckets/get_bucket_policy.go",
        "code_diff": "@@ -26,7 +26,7 @@\nimport (\n )\n \n // getBucketPolicy gets the bucket IAM policy.\n-func getBucketPolicy(w io.Writer, bucketName string) (*iam.Policy, error) {\n+func getBucketPolicy(w io.Writer, bucketName string) (*iam.Policy3, error) {\n \t// bucketName := \"bucket-name\"\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -48,6 +48,7 @@\nfunc TestObjects(t *testing.T) {\n \t\tbucketVersioning      = tc.ProjectID + \"-bucket-versioning-enabled\"\n \t\tobject1               = \"foo.txt\"\n \t\tobject2               = \"foo/a.txt\"\n+\t\tobject3               = \"bar.txt\"\n \t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers\n \t\troleReader            = storage.RoleReader\n \t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -56,13 +57,8 @@\nfunc TestObjects(t *testing.T) {\n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, dstBucket)\n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketVersioning)\n \n-\t{\n-\t\t// Enable versioning\n-\t\tattr := storage.BucketAttrsToUpdate{VersioningEnabled: true}\n-\t\t_, err := client.Bucket(bucketVersioning).Update(ctx, attr)\n-\t\tif err != nil {\n-\t\t\tt.Fatalf(\"storage.BucketAttrsToUpdate{VersioningEnabled: true}: %v\", err)\n-\t\t}\n+\tif err := enableVersioning(ioutil.Discard, bucketVersioning); err != nil {\n+\t\tt.Fatalf(\"enableVersioning: %v\", err)\n \t}\n \n \tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -75,6 +71,20 @@\nfunc TestObjects(t *testing.T) {\n \tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n \t}\n+\t// Check enableVersioning correctly work.\n+\tbkt := client.Bucket(bucketVersioning)\n+\tbAttrs, err := bkt.Attrs(ctx)\n+\tif !bAttrs.VersioningEnabled {\n+\t\tt.Fatalf(\"object versioning is not enabled\")\n+\t}\n+\tobj := bkt.Object(object1)\n+\tattrs, err := obj.Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Object(%q).Attrs: %v\", bucketVersioning, object1, err)\n+\t}\n+\t// Keep the original generation of object1 before re-uploading\n+\t// to use in the versioning samples.\n+\tgen := attrs.Generation\n \tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -132,7 +142,13 @@\nfunc TestObjects(t *testing.T) {\n \t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)\n \t\t}\n \t}\n-\n+\tif err := copyOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, object3, gen); err != nil {\n+\t\tt.Fatalf(\"copyOldVersionOfObject: %v\", err)\n+\t}\n+\t// Delete the first version of an object1 for a bucketVersioning.\n+\tif err := deleteOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, gen); err != nil {\n+\t\tt.Fatalf(\"deleteOldVersionOfObject: %v\", err)\n+\t}\n \tdata, err := downloadFile(ioutil.Discard, bucket, object1)\n \tif err != nil {\n \t\tt.Fatalf(\"downloadFile: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -163,6 +179,9 @@\nfunc TestObjects(t *testing.T) {\n \tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \tnewKey := []byte(\"My-secret-AES-256-encryption-key\")\n \n+\tif err := generateEncryptionKey(ioutil.Discard); err != nil {\n+\t\tt.Errorf(\"generateEncryptionKey: %v\", err)\n+\t}\n \tif err := uploadEncryptedFile(ioutil.Discard, bucket, object1, key); err != nil {\n \t\tt.Errorf(\"uploadEncryptedFile: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "videointelligence/annotate/object_tracking.go",
        "code_diff": "@@ -15,7 +15,7 @@\n// Package annotate contains speech examples.\n package annotate\n \n-// [START videointelligence_object_tracking]\n+// [START video_object_tracking]\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "videointelligence/annotate/object_tracking_gcs.go",
        "code_diff": "@@ -15,7 +15,7 @@\n// Package annotate contains speech examples.\n package annotate\n \n-// [START videointelligence_object_tracking_gcs]\n+// [START video_object_tracking_gcs]\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "videointelligence/annotate/text_detection.go",
        "code_diff": "@@ -15,7 +15,7 @@\n// Package annotate contains speech examples.\n package annotate\n \n-// [START videointelligence_text_detection]\n+// [START video_detect_text]\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "videointelligence/annotate/text_detection_gcs.go",
        "code_diff": "@@ -15,7 +15,7 @@\n// Package annotate contains speech examples.\n package annotate\n \n-// [START videointelligence_text_detection_gcs]\n+// [START video_detect_text_gcs]\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -159,7 +159,7 @@\nfunc explicitContent(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START video_analyze_speech_transcription]\n+// [START video_speech_transcription]\n \n func speechTranscription(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -151,7 +151,7 @@\nfunc explicitContentURI(w io.Writer, file string) error {\n \n // [END video_analyze_explicit_content]\n \n-// [START video_analyze_speech_transcription_gcs]\n+// [START video_speech_transcription_gcs]\n \n func speechTranscriptionURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_brushup",
        "commit_id": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "feature(datacatalog): add datacatalog policy tag manager snippets",
        "pr_number": 1785,
        "file_name": "datacatalog/snippets/policytagmanager/integration_test.go",
        "code_diff": "@@ -38,34 +38,34 @@\nfunc TestPolicyTagManager(t *testing.T) {\n \toutput := ioutil.Discard\n \n \ttaxonomyName := fmt.Sprintf(\"example-taxonomy-%d\", time.Now().UnixNano())\n-\ttaxID, err := createTaxonomy(tc.ProjectID, location, taxonomyName, output)\n+\ttaxID, err := createTaxonomy(output, tc.ProjectID, location, taxonomyName)\n \tif err != nil {\n \t\tt.Errorf(\"createTaxonomy: %v\", err)\n \t}\n \tdefer deleteTaxonomy(taxID)\n \n-\tif err := getTaxonomy(taxID, output); err != nil {\n+\tif err := getTaxonomy(output, taxID); err != nil {\n \t\tt.Errorf(\"getTaxonomy: %v\", err)\n \t}\n \n-\tif err := listTaxonomies(tc.ProjectID, location, output); err != nil {\n+\tif err := listTaxonomies(output, tc.ProjectID, location); err != nil {\n \t\tt.Errorf(\"listTaxonomies: %v\", err)\n \t}\n \n \t// Create some policy tags\n \tdisplayName := \"PII Tag\"\n-\ttagOne, err := createPolicyTag(taxID, displayName, \"\", output)\n+\ttagOne, err := createPolicyTag(output, taxID, displayName, \"\")\n \tif err != nil {\n \t\tt.Errorf(\"createPolicyTag(%s): %v\", displayName, err)\n \t}\n \n \tdisplayName = \"Child PII Tag\"\n-\ttagTwo, err := createPolicyTag(taxID, displayName, tagOne, output)\n+\ttagTwo, err := createPolicyTag(output, taxID, displayName, tagOne)\n \tif err != nil {\n \t\tt.Errorf(\"createPolicyTag(%s): %v\", displayName, err)\n \t}\n \n-\tif err := getPolicyTag(tagOne, output); err != nil {\n+\tif err := getPolicyTag(output, tagOne); err != nil {\n \t\tt.Errorf(\"getPolicyTag(%s): %v\", tagOne, err)\n \t}",
        "comments": [],
        "commit_message": "address reviewer comments",
        "commit_id": "1b24fe2844282e5109845e20ad36d59582695c4b"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "kms/decrypt_asymmetric.go",
        "code_diff": "@@ -18,10 +18,12 @@\npackage kms\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // decryptAsymmetric will attempt to decrypt a given ciphertext with an",
        "comments": [],
        "commit_message": "Merge branch 'master' into sample_gap_obj2",
        "commit_id": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "kms/decrypt_symmetric.go",
        "code_diff": "@@ -18,10 +18,12 @@\npackage kms\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // decryptSymmetric will decrypt the input ciphertext bytes using the specified symmetric key.",
        "comments": [],
        "commit_message": "Merge branch 'master' into sample_gap_obj2",
        "commit_id": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "kms/encrypt_symmetric.go",
        "code_diff": "@@ -18,10 +18,12 @@\npackage kms\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // encryptSymmetric encrypts the input plaintext with the specified symmetric",
        "comments": [],
        "commit_message": "Merge branch 'master' into sample_gap_obj2",
        "commit_id": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "kms/encrypt_symmetric.go",
        "code_diff": "@@ -41,10 +43,18 @@\nfunc encryptSymmetric(w io.Writer, name string, message string) error {\n \t// ciphertexts are always byte arrays.\n \tplaintext := []byte(message)\n \n+\t// Optional but recommended: Compute plaintext's CRC32C.\n+\tcrc32c := func(data []byte) uint32 {\n+\t\tt := crc32.MakeTable(crc32.Castagnoli)\n+\t\treturn crc32.Checksum(data, t)\n+\t}\n+\tplaintextCRC32C := crc32c(plaintext)\n+\n \t// Build the request.\n \treq := &kmspb.EncryptRequest{\n-\t\tName:      name,\n-\t\tPlaintext: plaintext,\n+\t\tName:            name,\n+\t\tPlaintext:       plaintext,\n+\t\tPlaintextCrc32C: wrapperspb.Int64(int64(plaintextCRC32C)),\n \t}\n \n \t// Call the API.",
        "comments": [],
        "commit_message": "Merge branch 'master' into sample_gap_obj2",
        "commit_id": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "kms/get_public_key.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"crypto/x509\"\n \t\"encoding/pem\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sample_gap_obj2",
        "commit_id": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "kms/sign_asymmetric.go",
        "code_diff": "@@ -19,10 +19,12 @@\nimport (\n \t\"context\"\n \t\"crypto/sha256\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // signAsymmetric will sign a plaintext message using a saved asymmetric private",
        "comments": [],
        "commit_message": "Merge branch 'master' into sample_gap_obj2",
        "commit_id": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "kms/sign_asymmetric.go",
        "code_diff": "@@ -48,6 +50,14 @@\nfunc signAsymmetric(w io.Writer, name string, message string) error {\n \t\treturn fmt.Errorf(\"failed to create digest: %v\", err)\n \t}\n \n+\t// Optional but recommended: Compute digest's CRC32C.\n+\tcrc32c := func(data []byte) uint32 {\n+\t\tt := crc32.MakeTable(crc32.Castagnoli)\n+\t\treturn crc32.Checksum(data, t)\n+\n+\t}\n+\tdigestCRC32C := crc32c(digest.Sum(nil))\n+\n \t// Build the signing request.\n \t//\n \t// Note: Key algorithms will require a varying hash function. For example,",
        "comments": [],
        "commit_message": "Merge branch 'master' into sample_gap_obj2",
        "commit_id": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "feat: add eventarc generic snippet",
        "pr_number": 1767,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -150,6 +150,12 @@\nfunc TestTables(t *testing.T) {\n \tif err := updateTableAddColumn(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"updateTableAddColumn(%q %q): %v\", testDatasetID, testTableID, err)\n \t}\n+\n+\t// Change tables to avoid hitting metadata update limits in a short period.\n+\ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n+\tif err := createTableExplicitSchema(tc.ProjectID, testDatasetID, testTableID); err != nil {\n+\t\tt.Fatalf(\"createTableExplicitSchema(%q %q): %v\", testDatasetID, testTableID, err)\n+\t}\n \tif err := addTableLabel(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"addTableLabel(%q %q): %v\", testDatasetID, testTableID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_generic",
        "commit_id": "ffbeb9c62d0d65bb8541aec14176a1edda4b7b8f"
    },
    {
        "pr_title": "feat: add eventarc generic snippet",
        "pr_number": 1767,
        "file_name": "logging/logging_quickstart/main.go",
        "code_diff": "@@ -14,7 +14,7 @@\n// [START logging_quickstart]\n \n-// Sample logging-quickstart writes a log entry to Stackdriver Logging.\n+// Sample logging-quickstart writes a log entry to Cloud Logging.\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_generic",
        "commit_id": "ffbeb9c62d0d65bb8541aec14176a1edda4b7b8f"
    },
    {
        "pr_title": "feat: add eventarc generic snippet",
        "pr_number": 1767,
        "file_name": "logging/stdlogging/main.go",
        "code_diff": "@@ -14,7 +14,7 @@\n// [START logging_stdlogging]\n \n-// Sample stdlogging writes log.Logger logs to the Stackdriver Logging.\n+// Sample stdlogging writes log.Logger logs to the Cloud Logging.\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_generic",
        "commit_id": "ffbeb9c62d0d65bb8541aec14176a1edda4b7b8f"
    },
    {
        "pr_title": "feat: add eventarc generic snippet",
        "pr_number": 1767,
        "file_name": "run/logging-manual/main.go",
        "code_diff": "@@ -59,11 +59,11 @@\ntype Entry struct {\n \tSeverity string `json:\"severity,omitempty\"`\n \tTrace    string `json:\"logging.googleapis.com/trace,omitempty\"`\n \n-\t// Stackdriver Log Viewer allows filtering and display of this as `jsonPayload.component`.\n+\t// Cloud Log Viewer allows filtering and display of this as `jsonPayload.component`.\n \tComponent string `json:\"component,omitempty\"`\n }\n \n-// String renders an entry structure to the JSON format expected by Stackdriver.\n+// String renders an entry structure to the JSON format expected by Cloud Logging.\n func (e Entry) String() string {\n \tif e.Severity == \"\" {\n \t\te.Severity = \"INFO\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_eventarc_generic",
        "commit_id": "ffbeb9c62d0d65bb8541aec14176a1edda4b7b8f"
    },
    {
        "pr_title": "refactor(logging): debrand stackdriver logging in favor of cloud logging",
        "pr_number": 1766,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -150,6 +150,12 @@\nfunc TestTables(t *testing.T) {\n \tif err := updateTableAddColumn(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"updateTableAddColumn(%q %q): %v\", testDatasetID, testTableID, err)\n \t}\n+\n+\t// Change tables to avoid hitting metadata update limits in a short period.\n+\ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n+\tif err := createTableExplicitSchema(tc.ProjectID, testDatasetID, testTableID); err != nil {\n+\t\tt.Fatalf(\"createTableExplicitSchema(%q %q): %v\", testDatasetID, testTableID, err)\n+\t}\n \tif err := addTableLabel(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"addTableLabel(%q %q): %v\", testDatasetID, testTableID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into debrandStackdriver",
        "commit_id": "fe44723340ca5073b072d8d3209cbfa71689fc36"
    },
    {
        "pr_title": "fix(bigquery):  minor refactor to avoid pushback failures",
        "pr_number": 1764,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -150,6 +150,12 @@\nfunc TestTables(t *testing.T) {\n \tif err := updateTableAddColumn(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"updateTableAddColumn(%q %q): %v\", testDatasetID, testTableID, err)\n \t}\n+\n+\t// Change tables to avoid hitting metadata update limits in a short period.\n+\ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n+\tif err := createTableExplicitSchema(tc.ProjectID, testDatasetID, testTableID); err != nil {\n+\t\tt.Fatalf(\"createTableExplicitSchema(%q %q): %v\", testDatasetID, testTableID, err)\n+\t}\n \tif err := addTableLabel(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"addTableLabel(%q %q): %v\", testDatasetID, testTableID, err)\n \t}",
        "comments": [],
        "commit_message": "fix(bigquery):  minor refactor to avoid pushback failures\n\nCurrently, table snippet tests mutate metadata for a table serially.\nRecently, changes to how mutation pushback work in the backend are\ncausing intermittent failures.  The pushback is significant enough\nthat retries are insufficient to address this with the table snippet\ntests.\n\nThis change addresses the problem by directing some of the mutation\nexamples to modify an additional BigQuery table.",
        "commit_id": "db96e981207e32811c19fe00b47fc5ab5519e667"
    },
    {
        "pr_title": "pubsub: fix error in the concurrency example.",
        "pr_number": 1753,
        "file_name": "pubsub/subscriptions/pull_concurrency.go",
        "code_diff": "@@ -18,14 +18,14 @@\npackage subscriptions\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"io\"\n \t\"runtime\"\n+\t\"sync/atomic\"\n \t\"time\"\n \n \t\"cloud.google.com/go/pubsub\"\n )\n \n-func pullMsgsConcurrenyControl(w io.Writer, projectID, subID string) error {\n+func pullMsgsConcurrenyControl(counter *int32, projectID, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// subID := \"my-sub\"\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "pubsub: fix error in the concurrency example\n\nThe current example is processing all the messages in a single goroutine\nand is NOT concurrent.\n\nTo make tests pass, use a counter that can be incremented concurrently.",
        "commit_id": "5361f14af0d9e3d4ce6369af303b101cd4b7ab05"
    },
    {
        "pr_title": "testing(run): add retry behavior to cloudrunci gcloud commands",
        "pr_number": 1741,
        "file_name": "dataproc/dataproc_test.go",
        "code_diff": "@@ -52,10 +52,10 @@\nfunc deleteCluster(projectID string, clusterName, region string) error {\n \treturn nil\n }\n \n-func TestCreateCluster(t *testing.T) {\n+func TestDataproc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tclusterName := fmt.Sprintf(\"go-cc-test-%s\", tc.ProjectID)\n+\tclusterName := fmt.Sprintf(\"go-dp-test-%s\", tc.ProjectID)\n \tregion := \"us-central1\"\n \n \tdeleteCluster(tc.ProjectID, clusterName, region) // Delete the cluster if it already exists, ignoring any errors.",
        "comments": [],
        "commit_message": "Merge branch 'master' into cloudrunci-retry",
        "commit_id": "ec2f33a8658029618e882504d4e28578a844bfc3"
    },
    {
        "pr_title": "testing(run): add retry behavior to cloudrunci gcloud commands",
        "pr_number": 1741,
        "file_name": "dataproc/quickstart/quickstart.go",
        "code_diff": "@@ -14,8 +14,8 @@\n// [START dataproc_quickstart]\n \n-// This quickstart shows how you can use the Cloud Dataproc Client library to create a\n-// Cloud Dataproc cluster, submit a PySpark job to the cluster, wait for the job to finish\n+// This quickstart shows how you can use the Dataproc Client library to create a\n+// Dataproc cluster, submit a PySpark job to the cluster, wait for the job to finish\n // and finally delete the cluster.\n //\n // Usage:",
        "comments": [],
        "commit_message": "Merge branch 'master' into cloudrunci-retry",
        "commit_id": "ec2f33a8658029618e882504d4e28578a844bfc3"
    },
    {
        "pr_title": "testing(run): add retry behavior to cloudrunci gcloud commands",
        "pr_number": 1741,
        "file_name": "dataproc/quickstart/quickstart.go",
        "code_diff": "@@ -30,7 +30,7 @@\nimport (\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n-\t\"time\"\n+\t\"regexp\"\n \n \tdataproc \"cloud.google.com/go/dataproc/apiv1\"\n \t\"cloud.google.com/go/storage\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into cloudrunci-retry",
        "commit_id": "ec2f33a8658029618e882504d4e28578a844bfc3"
    },
    {
        "pr_title": "testing(run): add retry behavior to cloudrunci gcloud commands",
        "pr_number": 1741,
        "file_name": "dataproc/quickstart/quickstart.go",
        "code_diff": "@@ -124,83 +124,35 @@\nfunc main() {\n \t\t},\n \t}\n \n-\tsubmitJobResp, err := jobClient.SubmitJob(ctx, submitJobReq)\n+\tsubmitJobOp, err := jobClient.SubmitJobAsOperation(ctx, submitJobReq)\n \tif err != nil {\n-\t\tfmt.Printf(\"error submitting job: %v\\n\", err)\n+\t\tfmt.Printf(\"error with request to submitting job: %v\\n\", err)\n \t\treturn\n \t}\n \n-\tid := submitJobResp.Reference.JobId\n-\n-\tfmt.Printf(\"Submitted job %q\\n\", id)\n-\n-\t// These states all signify that a job has terminated, successfully or not.\n-\tterminalStates := map[dataprocpb.JobStatus_State]bool{\n-\t\tdataprocpb.JobStatus_ERROR:     true,\n-\t\tdataprocpb.JobStatus_CANCELLED: true,\n-\t\tdataprocpb.JobStatus_DONE:      true,\n-\t}\n-\n-\t// We can create a timeout such that the job gets cancelled if not in a terminal state after a certain amount of time.\n-\ttimeout := 5 * time.Minute\n-\tstart := time.Now()\n-\n-\tvar state dataprocpb.JobStatus_State\n-\tfor {\n-\t\tif time.Since(start) > timeout {\n-\t\t\tcancelReq := &dataprocpb.CancelJobRequest{\n-\t\t\t\tProjectId: projectID,\n-\t\t\t\tRegion:    region,\n-\t\t\t\tJobId:     id,\n-\t\t\t}\n-\n-\t\t\tif _, err := jobClient.CancelJob(ctx, cancelReq); err != nil {\n-\t\t\t\tfmt.Printf(\"error cancelling job: %v\\n\", err)\n-\t\t\t}\n-\t\t\tfmt.Printf(\"job %q timed out after %d minutes\\n\", id, int64(timeout.Minutes()))\n-\t\t\treturn\n-\t\t}\n-\n-\t\tgetJobReq := &dataprocpb.GetJobRequest{\n-\t\t\tProjectId: projectID,\n-\t\t\tRegion:    region,\n-\t\t\tJobId:     id,\n-\t\t}\n-\t\tgetJobResp, err := jobClient.GetJob(ctx, getJobReq)\n-\t\tif err != nil {\n-\t\t\tfmt.Printf(\"error getting job %q with error: %v\\n\", id, err)\n-\t\t\treturn\n-\t\t}\n-\t\tstate = getJobResp.Status.State\n-\t\tif terminalStates[state] {\n-\t\t\tbreak\n-\t\t}\n-\n-\t\t// Sleep as to not excessively poll the API.\n-\t\ttime.Sleep(1 * time.Second)\n+\tsubmitJobResp, err := submitJobOp.Wait(ctx)\n+\tif err != nil {\n+\t\tfmt.Printf(\"error submitting job: %v\\n\", err)\n+\t\treturn\n \t}\n \n-\t// Cloud Dataproc job outget gets saved to a GCS bucket allocated to it.\n-\tgetCReq := &dataprocpb.GetClusterRequest{\n-\t\tProjectId:   projectID,\n-\t\tRegion:      region,\n-\t\tClusterName: clusterName,\n-\t}\n+\tre := regexp.MustCompile(\"gs://(.+?)/(.+)\")\n+\tmatches := re.FindStringSubmatch(submitJobResp.DriverOutputResourceUri)\n \n-\tresp, err := clusterClient.GetCluster(ctx, getCReq)\n-\tif err != nil {\n-\t\tfmt.Printf(\"error getting cluster %q: %v\\n\", clusterName, err)\n+\tif len(matches) < 3 {\n+\t\tfmt.Printf(\"regex error: %s\\n\", submitJobResp.DriverOutputResourceUri)\n \t\treturn\n \t}\n \n+\t// Dataproc job outget gets saved to a GCS bucket allocated to it.\n \tstorageClient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tfmt.Printf(\"error creating storage client: %v\\n\", err)\n \t\treturn\n \t}\n \n-\tobj := fmt.Sprintf(\"google-cloud-dataproc-metainfo/%s/jobs/%s/driveroutput.000000000\", resp.ClusterUuid, id)\n-\treader, err := storageClient.Bucket(resp.Config.ConfigBucket).Object(obj).NewReader(ctx)\n+\tobj := fmt.Sprintf(\"%s.000000000\", matches[2])\n+\treader, err := storageClient.Bucket(matches[1]).Object(obj).NewReader(ctx)\n \tif err != nil {\n \t\tfmt.Printf(\"error reading job output: %v\\n\", err)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into cloudrunci-retry",
        "commit_id": "ec2f33a8658029618e882504d4e28578a844bfc3"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "functions/tips/contexttip/context_tip.go",
        "code_diff": "@@ -14,6 +14,7 @@\n// [START functions_golang_context]\n // [START functions_tips_gcp_apis]\n+// [START functions_pubsub_setup]\n \n // Package contexttip is an example of how to use Pub/Sub and context.Context in\n // a Cloud Function.",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "functions/tips/contexttip/context_tip.go",
        "code_diff": "@@ -23,7 +24,6 @@\nimport (\n \t\"context\"\n \t\"encoding/json\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "functions/tips/contexttip/context_tip.go",
        "code_diff": "@@ -49,31 +49,36 @@\nfunc init() {\n \t}\n }\n \n+// [END functions_pubsub_setup]\n+\n+// [START functions_pubsub_publish]\n+\n type publishRequest struct {\n-\tTopic string `json:\"topic\"`\n+\tTopic   string `json:\"topic\"`\n+\tMessage string `json:\"message\"`\n }\n \n // PublishMessage publishes a message to Pub/Sub. PublishMessage only works\n // with topics that already exist.\n func PublishMessage(w http.ResponseWriter, r *http.Request) {\n-\t// Read the request body.\n-\tdata, err := ioutil.ReadAll(r.Body)\n-\tif err != nil {\n-\t\tlog.Printf(\"ioutil.ReadAll: %v\", err)\n-\t\thttp.Error(w, \"Error reading request\", http.StatusBadRequest)\n+\t// Parse the request body to get the topic name and message.\n+\tp := publishRequest{}\n+\n+\tif err := json.NewDecoder(r.Body).Decode(&p); err != nil {\n+\t\tlog.Printf(\"json.NewDecoder: %v\", err)\n+\t\thttp.Error(w, \"Error parsing request\", http.StatusBadRequest)\n \t\treturn\n \t}\n \n-\t// Parse the request body to get the topic name.\n-\tp := publishRequest{}\n-\tif err := json.Unmarshal(data, &p); err != nil {\n-\t\tlog.Printf(\"json.Unmarshal: %v\", err)\n-\t\thttp.Error(w, \"Error parsing request\", http.StatusBadRequest)\n+\tif p.Topic == \"\" || p.Message == \"\" {\n+\t\ts := \"missing 'topic' or 'message' parameter\"\n+\t\tlog.Println(s)\n+\t\thttp.Error(w, s, http.StatusBadRequest)\n \t\treturn\n \t}\n \n \tm := &pubsub.Message{\n-\t\tData: []byte(\"Test message\"),\n+\t\tData: []byte(p.Message),\n \t}\n \t// Publish and Get use r.Context() because they are only needed for this\n \t// function invocation. If this were a background function, they would use",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "functions/tips/contexttip/context_tip_test.go",
        "code_diff": "@@ -26,8 +26,6 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n )\n \n-const topicName = \"functions-test-topic\"\n-\n func TestPublishMessage(t *testing.T) {\n \t// TODO: Use testutil to get the project.\n \tprojectID = os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "functions/tips/contexttip/context_tip_test.go",
        "code_diff": "@@ -42,6 +40,11 @@\nfunc TestPublishMessage(t *testing.T) {\n \t\tt.Fatalf(\"pubsub.NewClient: %v\", err)\n \t}\n \n+\ttopicName := os.Getenv(\"FUNCTIONS_TOPIC_NAME\")\n+\tif topicName == \"\" {\n+\t\ttopicName = \"functions-test-topic\"\n+\t}\n+\n \ttopic := client.Topic(topicName)\n \texists, err := topic.Exists(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -12,8 +12,6 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// +build ignore\n-\n // Command spanner_snippets contains runnable snippet code for Cloud Spanner.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -28,107 +26,35 @@\nimport (\n \t\"strconv\"\n \t\"time\"\n \n-\t\"cloud.google.com/go/civil\"\n \t\"cloud.google.com/go/spanner\"\n-\t\"github.com/golang/protobuf/ptypes\"\n \t\"google.golang.org/api/iterator\"\n-\t\"google.golang.org/api/option\"\n-\t\"google.golang.org/genproto/googleapis/longrunning\"\n-\t\"google.golang.org/grpc\"\n-\t\"google.golang.org/grpc/codes\"\n \n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n-\tpbts \"github.com/golang/protobuf/ptypes\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n-\tsppb \"google.golang.org/genproto/googleapis/spanner/v1\"\n-\t\"google.golang.org/genproto/protobuf/field_mask\"\n-\t\"google.golang.org/grpc/status\"\n )\n \n type command func(ctx context.Context, w io.Writer, client *spanner.Client) error\n-type newClientCommand func(ctx context.Context, w io.Writer, database string) error\n type adminCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error\n-type backupCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error\n \n var (\n \tcommands = map[string]command{\n-\t\t\"write\":                       write,\n-\t\t\"delete\":                      delete,\n-\t\t\"query\":                       query,\n-\t\t\"read\":                        read,\n-\t\t\"update\":                      update,\n-\t\t\"writetransaction\":            writeWithTransaction,\n-\t\t\"querynewcolumn\":              queryNewColumn,\n-\t\t\"queryindex\":                  queryUsingIndex,\n-\t\t\"readindex\":                   readUsingIndex,\n-\t\t\"readstoringindex\":            readStoringIndex,\n-\t\t\"readonlytransaction\":         readOnlyTransaction,\n-\t\t\"readstaledata\":               readStaleData,\n-\t\t\"readbatchdata\":               readBatchData,\n-\t\t\"updatewithtimestamp\":         updateWithTimestamp,\n-\t\t\"querywithtimestamp\":          queryWithTimestamp,\n-\t\t\"writewithtimestamp\":          writeWithTimestamp,\n-\t\t\"querynewtable\":               queryNewTable,\n-\t\t\"writetodocstable\":            writeToDocumentsTable,\n-\t\t\"updatedocstable\":             updateDocumentsTable,\n-\t\t\"querydocstable\":              queryDocumentsTable,\n-\t\t\"writewithhistory\":            writeWithHistory,\n-\t\t\"updatewithhistory\":           updateWithHistory,\n-\t\t\"querywithhistory\":            queryWithHistory,\n-\t\t\"writestructdata\":             writeStructData,\n-\t\t\"querywithstruct\":             queryWithStruct,\n-\t\t\"querywitharrayofstruct\":      queryWithArrayOfStruct,\n-\t\t\"querywithstructfield\":        queryWithStructField,\n-\t\t\"querywithnestedstructfield\":  queryWithNestedStructField,\n-\t\t\"dmlinsert\":                   insertUsingDML,\n-\t\t\"dmlupdate\":                   updateUsingDML,\n-\t\t\"dmldelete\":                   deleteUsingDML,\n-\t\t\"dmlwithtimestamp\":            updateUsingDMLWithTimestamp,\n-\t\t\"dmlwriteread\":                writeAndReadUsingDML,\n-\t\t\"dmlupdatestruct\":             updateUsingDMLStruct,\n-\t\t\"dmlwrite\":                    writeUsingDML,\n-\t\t\"querywithparameter\":          queryWithParameter,\n-\t\t\"dmlwritetxn\":                 writeWithTransactionUsingDML,\n-\t\t\"dmlupdatepart\":               updateUsingPartitionedDML,\n-\t\t\"dmldeletepart\":               deleteUsingPartitionedDML,\n-\t\t\"dmlbatchupdate\":              updateUsingBatchDML,\n-\t\t\"writedatatypesdata\":          writeDatatypesData,\n-\t\t\"querywitharray\":              queryWithArray,\n-\t\t\"querywithbool\":               queryWithBool,\n-\t\t\"querywithbytes\":              queryWithBytes,\n-\t\t\"querywithdate\":               queryWithDate,\n-\t\t\"querywithfloat\":              queryWithFloat,\n-\t\t\"querywithint\":                queryWithInt,\n-\t\t\"querywithstring\":             queryWithString,\n-\t\t\"querywithtimestampparameter\": queryWithTimestampParameter,\n-\t\t\"querywithqueryoptions\":       queryWithQueryOptions,\n-\t}\n-\n-\tnewClientCommands = map[string]newClientCommand{\n-\t\t\"createclientwithqueryoptions\": createClientWithQueryOptions,\n+\t\t\"write\":               write,\n+\t\t\"read\":                read,\n+\t\t\"query\":               query,\n+\t\t\"update\":              update,\n+\t\t\"querynewcolumn\":      queryNewColumn,\n+\t\t\"querywithparameter\":  queryWithParameter,\n+\t\t\"dmlwrite\":            writeUsingDML,\n+\t\t\"dmlwritetxn\":         writeWithTransactionUsingDML,\n+\t\t\"readindex\":           readUsingIndex,\n+\t\t\"readstoringindex\":    readStoringIndex,\n+\t\t\"readonlytransaction\": readOnlyTransaction,\n \t}\n \n \tadminCommands = map[string]adminCommand{\n-\t\t\"createdatabase\":                  createDatabase,\n-\t\t\"addnewcolumn\":                    addNewColumn,\n-\t\t\"addindex\":                        addIndex,\n-\t\t\"addstoringindex\":                 addStoringIndex,\n-\t\t\"addcommittimestamp\":              addCommitTimestamp,\n-\t\t\"createtablewithtimestamp\":        createTableWithTimestamp,\n-\t\t\"createtablewithdatatypes\":        createTableWithDatatypes,\n-\t\t\"createtabledocswithtimestamp\":    createTableDocumentsWithTimestamp,\n-\t\t\"createtabledocswithhistorytable\": createTableDocumentsWithHistoryTable,\n-\t\t\"listbackupoperations\":            listBackupOperations,\n-\t\t\"listdatabaseoperations\":          listDatabaseOperations,\n-\t}\n-\n-\tbackupCommands = map[string]backupCommand{\n-\t\t\"createbackup\":  createBackup,\n-\t\t\"cancelbackup\":  cancelBackup,\n-\t\t\"listbackups\":   listBackups,\n-\t\t\"updatebackup\":  updateBackup,\n-\t\t\"deletebackup\":  deleteBackup,\n-\t\t\"restorebackup\": restoreBackup,\n+\t\t\"createdatabase\":  createDatabase,\n+\t\t\"addnewcolumn\":    addNewColumn,\n+\t\t\"addstoringindex\": addStoringIndex,\n \t}\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -169,83 +95,6 @@\nfunc createDatabase(ctx context.Context, w io.Writer, adminClient *database.Data\n \n // [END spanner_create_database]\n \n-// [START spanner_create_table_with_timestamp_column]\n-\n-func createTableWithTimestamp(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n-\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n-\t\tDatabase: database,\n-\t\tStatements: []string{\n-\t\t\t`CREATE TABLE Performances (\n-\t\t\t\tSingerId        INT64 NOT NULL,\n-\t\t\t\tVenueId         INT64 NOT NULL,\n-\t\t\t\tEventDate       Date,\n-\t\t\t\tRevenue         INT64,\n-\t\t\t\tLastUpdateTime  TIMESTAMP NOT NULL OPTIONS (allow_commit_timestamp=true)\n-\t\t\t) PRIMARY KEY (SingerId, VenueId, EventDate),\n-\t\t\tINTERLEAVE IN PARENT Singers ON DELETE CASCADE`,\n-\t\t},\n-\t})\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tif err := op.Wait(ctx); err != nil {\n-\t\treturn err\n-\t}\n-\tfmt.Fprintf(w, \"Created Performances table in database [%s]\\n\", database)\n-\treturn nil\n-}\n-\n-// [END spanner_create_table_with_timestamp_column]\n-\n-func createTableDocumentsWithTimestamp(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n-\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n-\t\tDatabase: database,\n-\t\tStatements: []string{\n-\t\t\t`CREATE TABLE DocumentsWithTimestamp(\n-\t\t\t\tUserId INT64 NOT NULL,\n-\t\t\t\tDocumentId INT64 NOT NULL,\n-\t\t\t    Timestamp TIMESTAMP NOT NULL OPTIONS(allow_commit_timestamp=true),\n-\t\t\t\tContents STRING(MAX) NOT NULL\n-\t\t\t) PRIMARY KEY(UserId, DocumentId)`,\n-\t\t},\n-\t})\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tif err := op.Wait(ctx); err != nil {\n-\t\treturn err\n-\t}\n-\tfmt.Fprintf(w, \"Created DocumentsWithTimestamp table in database [%s]\\n\", database)\n-\treturn nil\n-}\n-\n-func createTableDocumentsWithHistoryTable(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n-\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n-\t\tDatabase: database,\n-\t\tStatements: []string{\n-\t\t\t`CREATE TABLE Documents(\n-\t\t\t\tUserId INT64 NOT NULL,\n-\t\t\t\tDocumentId INT64 NOT NULL,\n-\t\t\t\tContents STRING(MAX) NOT NULL\n-\t\t\t) PRIMARY KEY(UserId, DocumentId)`,\n-\t\t\t`CREATE TABLE DocumentHistory(\n-\t\t\t\tUserId INT64 NOT NULL,\n-\t\t\t\tDocumentId INT64 NOT NULL,\n-\t\t\t\tTimestamp TIMESTAMP NOT NULL OPTIONS(allow_commit_timestamp=true),\n-\t\t\t\tPreviousContents STRING(MAX)\n-\t\t\t) PRIMARY KEY(UserId, DocumentId, Timestamp), INTERLEAVE IN PARENT Documents ON DELETE NO ACTION`,\n-\t\t},\n-\t})\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tif err := op.Wait(ctx); err != nil {\n-\t\treturn err\n-\t}\n-\tfmt.Fprintf(w, \"Created Documents and DocumentHistory tables in database [%s]\\n\", database)\n-\treturn nil\n-}\n-\n // [START spanner_insert_data]\n \n func write(ctx context.Context, w io.Writer, client *spanner.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -269,222 +118,6 @@\nfunc write(ctx context.Context, w io.Writer, client *spanner.Client) error {\n \n // [END spanner_insert_data]\n \n-// [START spanner_delete_data]\n-\n-func delete(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t// Delete each of the albums by individual key,\n-\t// then delete all the singers using a key range.\n-\tm := []*spanner.Mutation{\n-\t\tspanner.Delete(\"Albums\", spanner.Key{1, 1}),\n-\t\tspanner.Delete(\"Albums\", spanner.Key{1, 2}),\n-\t\tspanner.Delete(\"Albums\", spanner.Key{2, 1}),\n-\t\tspanner.Delete(\"Albums\", spanner.Key{2, 2}),\n-\t\tspanner.Delete(\"Albums\", spanner.Key{2, 3}),\n-\t\tspanner.Delete(\"Singers\", spanner.KeyRange{Start: spanner.Key{1}, End: spanner.Key{5}, Kind: spanner.ClosedClosed}),\n-\t}\n-\t_, err := client.Apply(ctx, m)\n-\treturn err\n-}\n-\n-// [END spanner_delete_data]\n-\n-// [START spanner_insert_data_with_timestamp_column]\n-\n-func writeWithTimestamp(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tperformanceColumns := []string{\"SingerId\", \"VenueId\", \"EventDate\", \"Revenue\", \"LastUpdateTime\"}\n-\tm := []*spanner.Mutation{\n-\t\tspanner.InsertOrUpdate(\"Performances\", performanceColumns, []interface{}{1, 4, \"2017-10-05\", 11000, spanner.CommitTimestamp}),\n-\t\tspanner.InsertOrUpdate(\"Performances\", performanceColumns, []interface{}{1, 19, \"2017-11-02\", 15000, spanner.CommitTimestamp}),\n-\t\tspanner.InsertOrUpdate(\"Performances\", performanceColumns, []interface{}{2, 42, \"2017-12-23\", 7000, spanner.CommitTimestamp}),\n-\t}\n-\t_, err := client.Apply(ctx, m)\n-\treturn err\n-}\n-\n-// [END spanner_insert_data_with_timestamp_column]\n-\n-// [START spanner_write_data_for_struct_queries]\n-\n-func writeStructData(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tsingerColumns := []string{\"SingerId\", \"FirstName\", \"LastName\"}\n-\tm := []*spanner.Mutation{\n-\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{6, \"Elena\", \"Campbell\"}),\n-\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{7, \"Gabriel\", \"Wright\"}),\n-\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{8, \"Benjamin\", \"Martinez\"}),\n-\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{9, \"Hannah\", \"Harris\"}),\n-\t}\n-\t_, err := client.Apply(ctx, m)\n-\treturn err\n-}\n-\n-// [END spanner_write_data_for_struct_queries]\n-\n-func queryWithStruct(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\n-\t// [START spanner_create_struct_with_data]\n-\n-\ttype name struct {\n-\t\tFirstName string\n-\t\tLastName  string\n-\t}\n-\tvar singerInfo = name{\"Elena\", \"Campbell\"}\n-\n-\t// [END spanner_create_struct_with_data]\n-\n-\t// [START spanner_query_data_with_struct]\n-\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT SingerId FROM SINGERS\n-\t\t\t\tWHERE (FirstName, LastName) = @singerinfo`,\n-\t\tParams: map[string]interface{}{\"singerinfo\": singerInfo},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar singerID int64\n-\t\tif err := row.Columns(&singerID); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d\\n\", singerID)\n-\t}\n-\n-\t// [END spanner_query_data_with_struct]\n-}\n-\n-func queryWithArrayOfStruct(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\n-\t// [START spanner_create_user_defined_struct]\n-\n-\ttype nameType struct {\n-\t\tFirstName string\n-\t\tLastName  string\n-\t}\n-\n-\t// [END spanner_create_user_defined_struct]\n-\n-\t// [START spanner_create_array_of_struct_with_data]\n-\n-\tvar bandMembers = []nameType{\n-\t\t{\"Elena\", \"Campbell\"},\n-\t\t{\"Gabriel\", \"Wright\"},\n-\t\t{\"Benjamin\", \"Martinez\"},\n-\t}\n-\n-\t// [END spanner_create_array_of_struct_with_data]\n-\n-\t// [START spanner_query_data_with_array_of_struct]\n-\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT SingerId FROM SINGERS\n-\t\t\tWHERE STRUCT<FirstName STRING, LastName STRING>(FirstName, LastName)\n-\t\t\tIN UNNEST(@names)`,\n-\t\tParams: map[string]interface{}{\"names\": bandMembers},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar singerID int64\n-\t\tif err := row.Columns(&singerID); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d\\n\", singerID)\n-\t}\n-\n-\t// [END spanner_query_data_with_array_of_struct]\n-}\n-\n-// [START spanner_field_access_on_struct_parameters]\n-\n-func queryWithStructField(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\ttype structParam struct {\n-\t\tFirstName string\n-\t\tLastName  string\n-\t}\n-\tvar singerInfo = structParam{\"Elena\", \"Campbell\"}\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT SingerId FROM SINGERS\n-\t\t\tWHERE FirstName = @name.FirstName`,\n-\t\tParams: map[string]interface{}{\"name\": singerInfo},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar singerID int64\n-\t\tif err := row.Columns(&singerID); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d\\n\", singerID)\n-\t}\n-}\n-\n-// [END spanner_field_access_on_struct_parameters]\n-\n-// [START spanner_field_access_on_nested_struct_parameters]\n-\n-func queryWithNestedStructField(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\ttype nameType struct {\n-\t\tFirstName string\n-\t\tLastName  string\n-\t}\n-\ttype songInfoStruct struct {\n-\t\tSongName    string\n-\t\tArtistNames []nameType\n-\t}\n-\tvar songInfo = songInfoStruct{\n-\t\tSongName: \"Imagination\",\n-\t\tArtistNames: []nameType{\n-\t\t\t{FirstName: \"Elena\", LastName: \"Campbell\"},\n-\t\t\t{FirstName: \"Hannah\", LastName: \"Harris\"},\n-\t\t},\n-\t}\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT SingerId, @songinfo.SongName FROM Singers\n-\t\t\tWHERE STRUCT<FirstName STRING, LastName STRING>(FirstName, LastName)\n-\t\t\tIN UNNEST(@songinfo.ArtistNames)`,\n-\t\tParams: map[string]interface{}{\"songinfo\": songInfo},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar singerID int64\n-\t\tvar songName string\n-\t\tif err := row.Columns(&singerID, &songName); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s\\n\", singerID, songName)\n-\t}\n-}\n-\n-// [END spanner_field_access_on_nested_struct_parameters]\n-\n // [START spanner_query_data]\n \n func query(ctx context.Context, w io.Writer, client *spanner.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -569,47 +202,6 @@\nfunc update(ctx context.Context, w io.Writer, client *spanner.Client) error {\n \n // [END spanner_update_data]\n \n-// [START spanner_read_write_transaction]\n-\n-func writeWithTransaction(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n-\t\tgetBudget := func(key spanner.Key) (int64, error) {\n-\t\t\trow, err := txn.ReadRow(ctx, \"Albums\", key, []string{\"MarketingBudget\"})\n-\t\t\tif err != nil {\n-\t\t\t\treturn 0, err\n-\t\t\t}\n-\t\t\tvar budget int64\n-\t\t\tif err := row.Column(0, &budget); err != nil {\n-\t\t\t\treturn 0, err\n-\t\t\t}\n-\t\t\treturn budget, nil\n-\t\t}\n-\t\talbum2Budget, err := getBudget(spanner.Key{2, 2})\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tconst transferAmt = 200000\n-\t\tif album2Budget >= transferAmt {\n-\t\t\talbum1Budget, err := getBudget(spanner.Key{1, 1})\n-\t\t\tif err != nil {\n-\t\t\t\treturn err\n-\t\t\t}\n-\t\t\talbum1Budget += transferAmt\n-\t\t\talbum2Budget -= transferAmt\n-\t\t\tcols := []string{\"SingerId\", \"AlbumId\", \"MarketingBudget\"}\n-\t\t\ttxn.BufferWrite([]*spanner.Mutation{\n-\t\t\t\tspanner.Update(\"Albums\", cols, []interface{}{1, 1, album1Budget}),\n-\t\t\t\tspanner.Update(\"Albums\", cols, []interface{}{2, 2, album2Budget}),\n-\t\t\t})\n-\t\t\tfmt.Fprintf(w, \"Moved %d from Album2's MarketingBudget to Album1's.\", transferAmt)\n-\t\t}\n-\t\treturn nil\n-\t})\n-\treturn err\n-}\n-\n-// [END spanner_read_write_transaction]\n-\n // [START spanner_query_data_with_new_column]\n \n func queryNewColumn(ctx context.Context, w io.Writer, client *spanner.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -645,72 +237,6 @@\nfunc queryNewColumn(ctx context.Context, w io.Writer, client *spanner.Client) er\n \n // [END spanner_query_data_with_new_column]\n \n-// [START spanner_create_index]\n-\n-func addIndex(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n-\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n-\t\tDatabase: database,\n-\t\tStatements: []string{\n-\t\t\t\"CREATE INDEX AlbumsByAlbumTitle ON Albums(AlbumTitle)\",\n-\t\t},\n-\t})\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tif err := op.Wait(ctx); err != nil {\n-\t\treturn err\n-\t}\n-\tfmt.Fprintf(w, \"Added index\\n\")\n-\treturn nil\n-}\n-\n-// [END spanner_create_index]\n-\n-// [START spanner_query_data_with_index]\n-\n-func queryUsingIndex(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT AlbumId, AlbumTitle, MarketingBudget\n-\t\t\tFROM Albums@{FORCE_INDEX=AlbumsByAlbumTitle}\n-\t\t\tWHERE AlbumTitle >= @start_title AND AlbumTitle < @end_title`,\n-\t\tParams: map[string]interface{}{\n-\t\t\t\"start_title\": \"Aardvark\",\n-\t\t\t\"end_title\":   \"Goo\",\n-\t\t},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar albumID int64\n-\t\tvar marketingBudget spanner.NullInt64\n-\t\tvar albumTitle string\n-\t\tif err := row.ColumnByName(\"AlbumId\", &albumID); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tif err := row.ColumnByName(\"AlbumTitle\", &albumTitle); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tif err := row.ColumnByName(\"MarketingBudget\", &marketingBudget); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tbudget := \"NULL\"\n-\t\tif marketingBudget.Valid {\n-\t\t\tbudget = strconv.FormatInt(marketingBudget.Int64, 10)\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s %s\\n\", albumID, albumTitle, budget)\n-\t}\n-\treturn nil\n-}\n-\n-// [END spanner_query_data_with_index]\n-\n // [START spanner_read_data_with_index]\n \n func readUsingIndex(ctx context.Context, w io.Writer, client *spanner.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -834,309 +360,7 @@\nfunc readOnlyTransaction(ctx context.Context, w io.Writer, client *spanner.Clien\n \n // [END spanner_read_only_transaction]\n \n-// [START spanner_read_stale_data]\n-\n-func readStaleData(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tro := client.ReadOnlyTransaction().WithTimestampBound(spanner.ExactStaleness(15 * time.Second))\n-\tdefer ro.Close()\n-\n-\titer := ro.Read(ctx, \"Albums\", spanner.AllKeys(), []string{\"SingerId\", \"AlbumId\", \"AlbumTitle\"})\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar singerID int64\n-\t\tvar albumID int64\n-\t\tvar albumTitle string\n-\t\tif err := row.Columns(&singerID, &albumID, &albumTitle); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %d %s\\n\", singerID, albumID, albumTitle)\n-\t}\n-}\n-\n-// [END spanner_read_stale_data]\n-\n-// [START spanner_batch_client]\n-\n-func readBatchData(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\ttxn, err := client.BatchReadOnlyTransaction(ctx, spanner.StrongRead())\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tdefer txn.Close()\n-\n-\t// Singer represents a row in the Singers table.\n-\ttype Singer struct {\n-\t\tSingerID   int64\n-\t\tFirstName  string\n-\t\tLastName   string\n-\t\tSingerInfo []byte\n-\t}\n-\tstmt := spanner.Statement{SQL: \"SELECT SingerId, FirstName, LastName FROM Singers;\"}\n-\tpartitions, err := txn.PartitionQuery(ctx, stmt, spanner.PartitionOptions{})\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\trecordCount := 0\n-\tfor i, p := range partitions {\n-\t\titer := txn.Execute(ctx, p)\n-\t\tdefer iter.Stop()\n-\t\tfor {\n-\t\t\trow, err := iter.Next()\n-\t\t\tif err == iterator.Done {\n-\t\t\t\tbreak\n-\t\t\t} else if err != nil {\n-\t\t\t\treturn err\n-\t\t\t}\n-\t\t\tvar s Singer\n-\t\t\tif err := row.ToStruct(&s); err != nil {\n-\t\t\t\treturn err\n-\t\t\t}\n-\t\t\tfmt.Fprintf(w, \"Partition (%d) %v\\n\", i, s)\n-\t\t\trecordCount++\n-\t\t}\n-\t}\n-\tfmt.Fprintf(w, \"Total partition count: %v\\n\", len(partitions))\n-\tfmt.Fprintf(w, \"Total record count: %v\\n\", recordCount)\n-\treturn nil\n-}\n-\n-// [END spanner_batch_client]\n-\n-// [START spanner_add_timestamp_column]\n-\n-func addCommitTimestamp(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n-\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n-\t\tDatabase: database,\n-\t\tStatements: []string{\n-\t\t\t\"ALTER TABLE Albums ADD COLUMN LastUpdateTime TIMESTAMP \" +\n-\t\t\t\t\"OPTIONS (allow_commit_timestamp=true)\",\n-\t\t},\n-\t})\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tif err := op.Wait(ctx); err != nil {\n-\t\treturn err\n-\t}\n-\tfmt.Fprintf(w, \"Added LastUpdateTime as a commit timestamp column in Albums table\\n\")\n-\treturn nil\n-}\n-\n-// [END spanner_add_timestamp_column]\n-\n-// [START spanner_update_data_with_timestamp_column]\n-\n-func updateWithTimestamp(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tcols := []string{\"SingerId\", \"AlbumId\", \"MarketingBudget\", \"LastUpdateTime\"}\n-\t_, err := client.Apply(ctx, []*spanner.Mutation{\n-\t\tspanner.Update(\"Albums\", cols, []interface{}{1, 1, 1000000, spanner.CommitTimestamp}),\n-\t\tspanner.Update(\"Albums\", cols, []interface{}{2, 2, 750000, spanner.CommitTimestamp}),\n-\t})\n-\treturn err\n-}\n-\n-// [END spanner_update_data_with_timestamp_column]\n-\n-// [START spanner_query_data_with_timestamp_column]\n-\n-func queryWithTimestamp(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT SingerId, AlbumId, MarketingBudget, LastUpdateTime\n-\t\t\t\tFROM Albums ORDER BY LastUpdateTime DESC`}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar singerID, albumID int64\n-\t\tvar marketingBudget spanner.NullInt64\n-\t\tvar lastUpdateTime spanner.NullTime\n-\t\tif err := row.ColumnByName(\"SingerId\", &singerID); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tif err := row.ColumnByName(\"AlbumId\", &albumID); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tif err := row.ColumnByName(\"MarketingBudget\", &marketingBudget); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tbudget := \"NULL\"\n-\t\tif marketingBudget.Valid {\n-\t\t\tbudget = strconv.FormatInt(marketingBudget.Int64, 10)\n-\t\t}\n-\t\tif err := row.ColumnByName(\"LastUpdateTime\", &lastUpdateTime); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\ttimestamp := \"NULL\"\n-\t\tif lastUpdateTime.Valid {\n-\t\t\ttimestamp = lastUpdateTime.String()\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %d %s %s\\n\", singerID, albumID, budget, timestamp)\n-\t}\n-}\n-\n-// [END spanner_query_data_with_timestamp_column]\n-\n-// [START spanner_dml_standard_insert]\n-\n-func insertUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n-\t\tstmt := spanner.Statement{\n-\t\t\tSQL: `INSERT Singers (SingerId, FirstName, LastName)\n-\t\t\t\t\tVALUES (10, 'Virginia', 'Watson')`,\n-\t\t}\n-\t\trowCount, err := txn.Update(ctx, stmt)\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d record(s) inserted.\\n\", rowCount)\n-\t\treturn nil\n-\t})\n-\treturn err\n-}\n-\n-// [END spanner_dml_standard_insert]\n-\n-// [START spanner_dml_standard_update]\n-\n-func updateUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n-\t\tstmt := spanner.Statement{\n-\t\t\tSQL: `UPDATE Albums\n-\t\t\t\tSET MarketingBudget = MarketingBudget * 2\n-\t\t\t\tWHERE SingerId = 1 and AlbumId = 1`,\n-\t\t}\n-\t\trowCount, err := txn.Update(ctx, stmt)\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d record(s) updated.\\n\", rowCount)\n-\t\treturn nil\n-\t})\n-\treturn err\n-}\n-\n-// [END spanner_dml_standard_update]\n-\n-// [START spanner_dml_standard_delete]\n-\n-func deleteUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n-\t\tstmt := spanner.Statement{SQL: `DELETE FROM Singers WHERE FirstName = 'Alice'`}\n-\t\trowCount, err := txn.Update(ctx, stmt)\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d record(s) deleted.\\n\", rowCount)\n-\t\treturn nil\n-\t})\n-\treturn err\n-}\n-\n-// [END spanner_dml_standard_delete]\n-\n-// [START spanner_dml_standard_update_with_timestamp]\n-\n-func updateUsingDMLWithTimestamp(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n-\t\tstmt := spanner.Statement{\n-\t\t\tSQL: `UPDATE Albums\n-\t\t\t\tSET LastUpdateTime = PENDING_COMMIT_TIMESTAMP()\n-\t\t\t\tWHERE SingerId = 1`,\n-\t\t}\n-\t\trowCount, err := txn.Update(ctx, stmt)\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d record(s) updated.\\n\", rowCount)\n-\t\treturn nil\n-\t})\n-\treturn err\n-}\n-\n-// [END spanner_dml_standard_update_with_timestamp]\n-\n-// [START spanner_dml_write_then_read]\n-\n-func writeAndReadUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n-\t\t// Insert Record\n-\t\tstmt := spanner.Statement{\n-\t\t\tSQL: `INSERT Singers (SingerId, FirstName, LastName)\n-\t\t\t\tVALUES (11, 'Timothy', 'Campbell')`,\n-\t\t}\n-\t\trowCount, err := txn.Update(ctx, stmt)\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d record(s) inserted.\\n\", rowCount)\n-\n-\t\t// Read newly inserted record\n-\t\tstmt = spanner.Statement{SQL: `SELECT FirstName, LastName FROM Singers WHERE SingerId = 11`}\n-\t\titer := txn.Query(ctx, stmt)\n-\t\tdefer iter.Stop()\n-\n-\t\tfor {\n-\t\t\trow, err := iter.Next()\n-\t\t\tif err == iterator.Done || err != nil {\n-\t\t\t\tbreak\n-\t\t\t}\n-\t\t\tvar firstName, lastName string\n-\t\t\tif err := row.ColumnByName(\"FirstName\", &firstName); err != nil {\n-\t\t\t\treturn err\n-\t\t\t}\n-\t\t\tif err := row.ColumnByName(\"LastName\", &lastName); err != nil {\n-\t\t\t\treturn err\n-\t\t\t}\n-\t\t\tfmt.Fprintf(w, \"Found record name with %s, %s\", firstName, lastName)\n-\t\t}\n-\t\treturn err\n-\t})\n-\treturn err\n-}\n-\n-// [END spanner_dml_write_then_read]\n-\n-// [START spanner_dml_structs]\n-\n-func updateUsingDMLStruct(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n-\t\ttype name struct {\n-\t\t\tFirstName string\n-\t\t\tLastName  string\n-\t\t}\n-\t\tvar singerInfo = name{\"Timothy\", \"Campbell\"}\n-\n-\t\tstmt := spanner.Statement{\n-\t\t\tSQL: `Update Singers Set LastName = 'Grant'\n-\t\t\t\tWHERE STRUCT<FirstName String, LastName String>(Firstname, LastName) = @name`,\n-\t\t\tParams: map[string]interface{}{\"name\": singerInfo},\n-\t\t}\n-\t\trowCount, err := txn.Update(ctx, stmt)\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d record(s) inserted.\\n\", rowCount)\n-\t\treturn nil\n-\t})\n-\treturn err\n-}\n-\n-// [END spanner_dml_structs]\n-\n-// [START spanner_dml_getting_started_insert]\n+// [START spanner_dml_getting_started_insert]\n \n func writeUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n \t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1253,1035 +477,21 @@\nfunc writeWithTransactionUsingDML(ctx context.Context, w io.Writer, client *span\n \n // [END spanner_dml_getting_started_update]\n \n-// [START spanner_dml_partitioned_update]\n-\n-func updateUsingPartitionedDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tstmt := spanner.Statement{SQL: \"UPDATE Albums SET MarketingBudget = 100000 WHERE SingerId > 1\"}\n-\trowCount, err := client.PartitionedUpdate(ctx, stmt)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tfmt.Fprintf(w, \"%d record(s) updated.\\n\", rowCount)\n-\treturn nil\n-}\n-\n-// [END spanner_dml_partitioned_update]\n-\n-// [START spanner_dml_partitioned_delete]\n-\n-func deleteUsingPartitionedDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tstmt := spanner.Statement{SQL: \"DELETE FROM Singers WHERE SingerId > 10\"}\n-\trowCount, err := client.PartitionedUpdate(ctx, stmt)\n+func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n+\tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {\n-\t\treturn err\n-\n+\t\tlog.Fatal(err)\n \t}\n-\tfmt.Fprintf(w, \"%d record(s) deleted.\", rowCount)\n-\treturn nil\n-}\n-\n-// [END spanner_dml_partitioned_delete]\n-\n-// [START spanner_dml_batch_update]\n-\n-func updateUsingBatchDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n-\t\tstmts := []spanner.Statement{\n-\t\t\t{SQL: `INSERT INTO Albums\n-\t\t\t\t(SingerId, AlbumId, AlbumTitle, MarketingBudget)\n-\t\t\t\tVALUES (1, 3, 'Test Album Title', 10000)`},\n-\t\t\t{SQL: `UPDATE Albums\n-\t\t\t\tSET MarketingBudget = MarketingBudget * 2\n-\t\t\t\tWHERE SingerId = 1 and AlbumId = 3`},\n-\t\t}\n-\t\trowCounts, err := txn.BatchUpdate(ctx, stmts)\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"Executed %d SQL statements using Batch DML.\\n\", len(rowCounts))\n-\t\treturn nil\n-\t})\n-\treturn err\n-}\n-\n-// [END spanner_dml_batch_update]\n \n-// [START spanner_create_table_with_datatypes]\n-\n-// Creates a Cloud Spanner table comprised of columns for each supported data type\n-// See https://cloud.google.com/spanner/docs/data-types\n-func createTableWithDatatypes(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n-\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n-\t\tDatabase: database,\n-\t\tStatements: []string{\n-\t\t\t`CREATE TABLE Venues (\n-\t\t\t\tVenueId\tINT64 NOT NULL,\n-\t\t\t\tVenueName STRING(100),\n-\t\t\t\tVenueInfo BYTES(MAX),\n-\t\t\t\tCapacity INT64,\n-\t\t\t\tAvailableDates ARRAY<DATE>,\n-\t\t\t\tLastContactDate DATE,\n-\t\t\t\tOutdoorVenue BOOL,\n-\t\t\t\tPopularityScore FLOAT64,\n-\t\t\t\tLastUpdateTime TIMESTAMP NOT NULL OPTIONS (allow_commit_timestamp=true)\n-\t\t\t) PRIMARY KEY (VenueId)`,\n-\t\t},\n-\t})\n+\tdataClient, err := spanner.NewClient(ctx, db)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"UpdateDatabaseDdl: %v\", err)\n-\t}\n-\tif err := op.Wait(ctx); err != nil {\n-\t\treturn err\n+\t\tlog.Fatal(err)\n \t}\n-\tfmt.Fprintf(w, \"Created Venues table in database [%s]\\n\", database)\n-\treturn nil\n-}\n-\n-// [END spanner_create_table_with_datatypes]\n \n-// [START spanner_insert_datatypes_data]\n-\n-func writeDatatypesData(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tvenueColumns := []string{\"VenueId\", \"VenueName\", \"VenueInfo\", \"Capacity\", \"AvailableDates\",\n-\t\t\"LastContactDate\", \"OutdoorVenue\", \"PopularityScore\", \"LastUpdateTime\"}\n-\tm := []*spanner.Mutation{\n-\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n-\t\t\t[]interface{}{4, \"Venue 4\", []byte(\"Hello World 1\"), 1800,\n-\t\t\t\t[]string{\"2020-12-01\", \"2020-12-02\", \"2020-12-03\"},\n-\t\t\t\t\"2018-09-02\", false, 0.85543, spanner.CommitTimestamp}),\n-\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n-\t\t\t[]interface{}{19, \"Venue 19\", []byte(\"Hello World 2\"), 6300,\n-\t\t\t\t[]string{\"2020-11-01\", \"2020-11-05\", \"2020-11-15\"},\n-\t\t\t\t\"2019-01-15\", true, 0.98716, spanner.CommitTimestamp}),\n-\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n-\t\t\t[]interface{}{42, \"Venue 42\", []byte(\"Hello World 3\"), 3000,\n-\t\t\t\t[]string{\"2020-10-01\", \"2020-10-07\"}, \"2018-10-01\",\n-\t\t\t\tfalse, 0.72598, spanner.CommitTimestamp}),\n-\t}\n-\t_, err := client.Apply(ctx, m)\n-\treturn err\n+\treturn adminClient, dataClient\n }\n \n-// [END spanner_insert_datatypes_data]\n-\n-// [START spanner_query_with_array_parameter]\n-\n-func queryWithArray(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tvar date1 = civil.Date{Year: 2020, Month: time.October, Day: 1}\n-\tvar date2 = civil.Date{Year: 2020, Month: time.November, Day: 1}\n-\tvar exampleArray = []civil.Date{date1, date2}\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT VenueId, VenueName, AvailableDate FROM Venues v,\n-            \tUNNEST(v.AvailableDates) as AvailableDate \n-            \tWHERE AvailableDate IN UNNEST(@availableDates)`,\n-\t\tParams: map[string]interface{}{\n-\t\t\t\"availableDates\": exampleArray,\n-\t\t},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar venueID int64\n-\t\tvar venueName string\n-\t\tvar availableDate civil.Date\n-\t\tif err := row.Columns(&venueID, &venueName, &availableDate); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, availableDate)\n-\t}\n-}\n-\n-// [END spanner_query_with_array_parameter]\n-\n-// [START spanner_query_with_bool_parameter]\n-\n-func queryWithBool(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tvar exampleBool = true\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT VenueId, VenueName, OutdoorVenue FROM Venues\n-            \tWHERE OutdoorVenue = @outdoorVenue`,\n-\t\tParams: map[string]interface{}{\n-\t\t\t\"outdoorVenue\": exampleBool,\n-\t\t},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar venueID int64\n-\t\tvar venueName string\n-\t\tvar outdoorVenue bool\n-\t\tif err := row.Columns(&venueID, &venueName, &outdoorVenue); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s %t\\n\", venueID, venueName, outdoorVenue)\n-\t}\n-}\n-\n-// [END spanner_query_with_bool_parameter]\n-\n-// [START spanner_query_with_bytes_parameter]\n-\n-func queryWithBytes(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tvar exampleBytes = []byte(\"Hello World 1\")\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT VenueId, VenueName FROM Venues\n-            \tWHERE VenueInfo = @venueInfo`,\n-\t\tParams: map[string]interface{}{\n-\t\t\t\"venueInfo\": exampleBytes,\n-\t\t},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar venueID int64\n-\t\tvar venueName string\n-\t\tif err := row.Columns(&venueID, &venueName); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s\\n\", venueID, venueName)\n-\t}\n-}\n-\n-// [END spanner_query_with_bytes_parameter]\n-\n-// [START spanner_query_with_date_parameter]\n-\n-func queryWithDate(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tvar exampleDate = civil.Date{Year: 2019, Month: time.January, Day: 1}\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT VenueId, VenueName, LastContactDate FROM Venues\n-            \tWHERE LastContactDate < @lastContactDate`,\n-\t\tParams: map[string]interface{}{\n-\t\t\t\"lastContactDate\": exampleDate,\n-\t\t},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar venueID int64\n-\t\tvar venueName string\n-\t\tvar lastContactDate civil.Date\n-\t\tif err := row.Columns(&venueID, &venueName, &lastContactDate); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s %v\\n\", venueID, venueName, lastContactDate)\n-\t}\n-}\n-\n-// [END spanner_query_with_date_parameter]\n-\n-// [START spanner_query_with_float_parameter]\n-\n-func queryWithFloat(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tvar exampleFloat = 0.8\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT VenueId, VenueName, PopularityScore FROM Venues\n-            \tWHERE PopularityScore > @popularityScore`,\n-\t\tParams: map[string]interface{}{\n-\t\t\t\"popularityScore\": exampleFloat,\n-\t\t},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar venueID int64\n-\t\tvar venueName string\n-\t\tvar popularityScore float64\n-\t\tif err := row.Columns(&venueID, &venueName, &popularityScore); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s %f\\n\", venueID, venueName, popularityScore)\n-\t}\n-}\n-\n-// [END spanner_query_with_float_parameter]\n-\n-// [START spanner_query_with_int_parameter]\n-\n-func queryWithInt(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tvar exampleInt = 3000\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT VenueId, VenueName, Capacity FROM Venues\n-            \tWHERE Capacity >= @capacity`,\n-\t\tParams: map[string]interface{}{\n-\t\t\t\"capacity\": exampleInt,\n-\t\t},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar venueID, capacity int64\n-\t\tvar venueName string\n-\t\tif err := row.Columns(&venueID, &venueName, &capacity); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s %d\\n\", venueID, venueName, capacity)\n-\t}\n-}\n-\n-// [END spanner_query_with_int_parameter]\n-\n-// [START spanner_query_with_string_parameter]\n-\n-func queryWithString(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tvar exampleString = \"Venue 42\"\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT VenueId, VenueName FROM Venues\n-            \tWHERE VenueName = @venueName`,\n-\t\tParams: map[string]interface{}{\n-\t\t\t\"venueName\": exampleString,\n-\t\t},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar venueID int64\n-\t\tvar venueName string\n-\t\tif err := row.Columns(&venueID, &venueName); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s\\n\", venueID, venueName)\n-\t}\n-}\n-\n-// [END spanner_query_with_string_parameter]\n-\n-// [START spanner_query_with_timestamp_parameter]\n-\n-func queryWithTimestampParameter(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tvar exampleTimestamp = time.Now()\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT VenueId, VenueName, LastUpdateTime FROM Venues\n-\t\tWHERE LastUpdateTime <= @lastUpdateTime`,\n-\t\tParams: map[string]interface{}{\n-\t\t\t\"lastUpdateTime\": exampleTimestamp,\n-\t\t},\n-\t}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar venueID int64\n-\t\tvar venueName string\n-\t\tvar lastUpdateTime time.Time\n-\t\tif err := row.Columns(&venueID, &venueName, &lastUpdateTime); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, lastUpdateTime)\n-\t}\n-}\n-\n-// [END spanner_query_with_timestamp_parameter]\n-\n-// [START spanner_query_with_query_options]\n-\n-func queryWithQueryOptions(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tstmt := spanner.Statement{SQL: `SELECT VenueId, VenueName, LastUpdateTime FROM Venues`}\n-\tqueryOptions := spanner.QueryOptions{\n-\t\tOptions: &sppb.ExecuteSqlRequest_QueryOptions{OptimizerVersion: \"1\"},\n-\t}\n-\titer := client.Single().QueryWithOptions(ctx, stmt, queryOptions)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar venueID int64\n-\t\tvar venueName string\n-\t\tvar lastUpdateTime time.Time\n-\t\tif err := row.Columns(&venueID, &venueName, &lastUpdateTime); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, lastUpdateTime)\n-\t}\n-}\n-\n-// [END spanner_query_with_query_options]\n-\n-func queryNewTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT SingerId, VenueId, EventDate, Revenue, LastUpdateTime FROM Performances\n-\t\t\t\tORDER BY LastUpdateTime DESC`}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar singerID, venueID int64\n-\t\tvar revenue spanner.NullInt64\n-\t\tvar eventDate, lastUpdateTime time.Time\n-\t\tif err := row.ColumnByName(\"SingerId\", &singerID); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tif err := row.ColumnByName(\"VenueId\", &venueID); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tif err := row.ColumnByName(\"EventDate\", &eventDate); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tif err := row.ColumnByName(\"Revenue\", &revenue); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tcurrentRevenue := \"NULL\"\n-\t\tif revenue.Valid {\n-\t\t\tcurrentRevenue = strconv.FormatInt(revenue.Int64, 10)\n-\t\t}\n-\t\tif err := row.ColumnByName(\"LastUpdateTime\", &lastUpdateTime); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\n-\t\tfmt.Fprintf(w, \"%d %d %s %s %s\\n\", singerID, venueID, eventDate, currentRevenue, lastUpdateTime)\n-\t}\n-}\n-\n-func writeToDocumentsTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tdocumentsColumns := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"Contents\"}\n-\tm := []*spanner.Mutation{\n-\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n-\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, \"Hello World 1\"}),\n-\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n-\t\t\t[]interface{}{1, 2, spanner.CommitTimestamp, \"Hello World 2\"}),\n-\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n-\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, \"Hello World 3\"}),\n-\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n-\t\t\t[]interface{}{2, 4, spanner.CommitTimestamp, \"Hello World 4\"}),\n-\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n-\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, \"Hello World 5\"}),\n-\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n-\t\t\t[]interface{}{3, 6, spanner.CommitTimestamp, \"Hello World 6\"}),\n-\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n-\t\t\t[]interface{}{3, 7, spanner.CommitTimestamp, \"Hello World 7\"}),\n-\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n-\t\t\t[]interface{}{3, 8, spanner.CommitTimestamp, \"Hello World 8\"}),\n-\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n-\t\t\t[]interface{}{3, 9, spanner.CommitTimestamp, \"Hello World 9\"}),\n-\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n-\t\t\t[]interface{}{3, 10, spanner.CommitTimestamp, \"Hello World 10\"}),\n-\t}\n-\t_, err := client.Apply(ctx, m)\n-\treturn err\n-}\n-\n-func updateDocumentsTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tcols := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"Contents\"}\n-\t_, err := client.Apply(ctx, []*spanner.Mutation{\n-\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n-\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, \"Hello World 1 Updated\"}),\n-\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n-\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, \"Hello World 3 Updated\"}),\n-\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n-\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, \"Hello World 5 Updated\"}),\n-\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n-\t\t\t[]interface{}{3, 7, spanner.CommitTimestamp, \"Hello World 7 Updated\"}),\n-\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n-\t\t\t[]interface{}{3, 9, spanner.CommitTimestamp, \"Hello World 9 Updated\"}),\n-\t})\n-\treturn err\n-}\n-\n-func queryDocumentsTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tstmt := spanner.Statement{SQL: `SELECT UserId, DocumentId, Timestamp, Contents FROM DocumentsWithTimestamp\n-\t\tORDER BY Timestamp DESC Limit 5`}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar userID, documentID int64\n-\t\tvar timestamp time.Time\n-\t\tvar contents string\n-\t\tif err := row.Columns(&userID, &documentID, &timestamp, &contents); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %d %s %s\\n\", userID, documentID, timestamp, contents)\n-\t}\n-}\n-\n-func writeWithHistory(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n-\t\tdocumentsColumns := []string{\"UserId\", \"DocumentId\", \"Contents\"}\n-\t\tdocumentHistoryColumns := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"PreviousContents\"}\n-\t\ttxn.BufferWrite([]*spanner.Mutation{\n-\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n-\t\t\t\t[]interface{}{1, 1, \"Hello World 1\"}),\n-\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n-\t\t\t\t[]interface{}{1, 2, \"Hello World 2\"}),\n-\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n-\t\t\t\t[]interface{}{1, 3, \"Hello World 3\"}),\n-\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n-\t\t\t\t[]interface{}{2, 4, \"Hello World 4\"}),\n-\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n-\t\t\t\t[]interface{}{2, 5, \"Hello World 5\"}),\n-\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n-\t\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, \"Hello World 1\"}),\n-\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n-\t\t\t\t[]interface{}{1, 2, spanner.CommitTimestamp, \"Hello World 2\"}),\n-\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n-\t\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, \"Hello World 3\"}),\n-\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n-\t\t\t\t[]interface{}{2, 4, spanner.CommitTimestamp, \"Hello World 4\"}),\n-\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n-\t\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, \"Hello World 5\"}),\n-\t\t})\n-\t\treturn nil\n-\t})\n-\treturn err\n-}\n-\n-func updateWithHistory(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n-\t\t// Create anonymous function \"getContents\" to read the current value of the Contents column for a given row.\n-\t\tgetContents := func(key spanner.Key) (string, error) {\n-\t\t\trow, err := txn.ReadRow(ctx, \"Documents\", key, []string{\"Contents\"})\n-\t\t\tif err != nil {\n-\t\t\t\treturn \"\", err\n-\t\t\t}\n-\t\t\tvar content string\n-\t\t\tif err := row.Column(0, &content); err != nil {\n-\t\t\t\treturn \"\", err\n-\t\t\t}\n-\t\t\treturn content, nil\n-\t\t}\n-\t\t// Create two string arrays corresponding to the columns in each table.\n-\t\tdocumentsColumns := []string{\"UserId\", \"DocumentId\", \"Contents\"}\n-\t\tdocumentHistoryColumns := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"PreviousContents\"}\n-\t\t// Get row's Contents before updating.\n-\t\tpreviousContents, err := getContents(spanner.Key{1, 1})\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\t// Update row's Contents while saving previous Contents in DocumentHistory table.\n-\t\ttxn.BufferWrite([]*spanner.Mutation{\n-\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n-\t\t\t\t[]interface{}{1, 1, \"Hello World 1 Updated\"}),\n-\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n-\t\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, previousContents}),\n-\t\t})\n-\t\tpreviousContents, err = getContents(spanner.Key{1, 3})\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\ttxn.BufferWrite([]*spanner.Mutation{\n-\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n-\t\t\t\t[]interface{}{1, 3, \"Hello World 3 Updated\"}),\n-\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n-\t\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, previousContents}),\n-\t\t})\n-\t\tpreviousContents, err = getContents(spanner.Key{2, 5})\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\ttxn.BufferWrite([]*spanner.Mutation{\n-\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n-\t\t\t\t[]interface{}{2, 5, \"Hello World 5 Updated\"}),\n-\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n-\t\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, previousContents}),\n-\t\t})\n-\t\treturn nil\n-\t})\n-\treturn err\n-}\n-\n-func queryWithHistory(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tstmt := spanner.Statement{\n-\t\tSQL: `SELECT d.UserId, d.DocumentId, d.Contents, dh.Timestamp, dh.PreviousContents\n-\t\t\t\tFROM Documents d JOIN DocumentHistory dh\n-\t\t\t\tON dh.UserId = d.UserId AND dh.DocumentId = d.DocumentId\n-\t\t\t\tORDER BY dh.Timestamp DESC LIMIT 3`}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar userID, documentID int64\n-\t\tvar timestamp time.Time\n-\t\tvar contents, previousContents string\n-\t\tif err := row.Columns(&userID, &documentID, &contents, &timestamp, &previousContents); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %d %s %s %s\\n\", userID, documentID, contents, timestamp, previousContents)\n-\t}\n-}\n-\n-// [START spanner_create_client_with_query_options]\n-\n-func createClientWithQueryOptions(ctx context.Context, w io.Writer, database string) error {\n-\tqueryOptions := spanner.QueryOptions{\n-\t\tOptions: &sppb.ExecuteSqlRequest_QueryOptions{OptimizerVersion: \"1\"},\n-\t}\n-\tclient, err := spanner.NewClientWithConfig(\n-\t\tctx, database, spanner.ClientConfig{QueryOptions: queryOptions},\n-\t)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tdefer client.Close()\n-\n-\tstmt := spanner.Statement{SQL: `SELECT VenueId, VenueName, LastUpdateTime FROM Venues`}\n-\titer := client.Single().Query(ctx, stmt)\n-\tdefer iter.Stop()\n-\tfor {\n-\t\trow, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\treturn nil\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tvar venueID int64\n-\t\tvar venueName string\n-\t\tvar lastUpdateTime time.Time\n-\t\tif err := row.Columns(&venueID, &venueName, &lastUpdateTime); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, lastUpdateTime)\n-\t}\n-}\n-\n-// [END spanner_create_client_with_query_options]\n-\n-// [START spanner_create_backup]\n-\n-func createBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n-\texpireTime := time.Now().AddDate(0, 0, 14)\n-\t// Create a backup.\n-\top, err := adminClient.StartBackupOperation(ctx, backupID, database, expireTime)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\t// Wait for backup operation to complete.\n-\tbackup, err := op.Wait(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\t// Get the name, create time and backup size.\n-\tcreateTime := time.Unix(backup.CreateTime.Seconds, int64(backup.CreateTime.Nanos))\n-\tfmt.Fprintf(w, \"Backup %s of size %d bytes was created at %s\\n\", backup.Name, backup.SizeBytes, createTime.Format(time.RFC3339))\n-\treturn nil\n-}\n-\n-// [END spanner_create_backup]\n-\n-// [START spanner_cancel_backup_create]\n-\n-func cancelBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n-\texpireTime := time.Now().AddDate(0, 0, 14)\n-\t// Create a backup.\n-\top, err := adminClient.StartBackupOperation(ctx, backupID, database, expireTime)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\t// Cancel backup creation.\n-\terr = adminClient.LROClient.CancelOperation(ctx, &longrunning.CancelOperationRequest{Name: op.Name()})\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\t// Cancel operations are best effort so either it will complete or be\n-\t// cancelled.\n-\tbackup, err := op.Wait(ctx)\n-\tif err != nil {\n-\t\tif waitStatus, ok := status.FromError(err); !ok || waitStatus.Code() != codes.Canceled {\n-\t\t\treturn err\n-\t\t}\n-\t} else {\n-\t\t// Backup was completed before it could be cancelled so delete the\n-\t\t// unwanted backup.\n-\t\terr = adminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: backup.Name})\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t}\n-\n-\tfmt.Fprintf(w, \"Backup cancelled.\\n\")\n-\treturn nil\n-}\n-\n-// [END spanner_cancel_backup_create]\n-\n-// [START spanner_list_backups]\n-\n-func listBackups(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, db, backupID string) error {\n-\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(db)\n-\tif matches == nil || len(matches) != 3 {\n-\t\treturn fmt.Errorf(\"Invalid database id %s\", db)\n-\t}\n-\tinstanceName := matches[1]\n-\n-\tprintBackups := func(iter *database.BackupIterator) error {\n-\t\tfor {\n-\t\t\tresp, err := iter.Next()\n-\t\t\tif err == iterator.Done {\n-\t\t\t\treturn nil\n-\t\t\t}\n-\t\t\tif err != nil {\n-\t\t\t\treturn err\n-\t\t\t}\n-\t\t\tfmt.Fprintf(w, \"Backup %s\\n\", resp.Name)\n-\t\t}\n-\t}\n-\n-\tvar iter *database.BackupIterator\n-\tvar filter string\n-\t// List all backups.\n-\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n-\t\tParent: instanceName,\n-\t})\n-\tif err := printBackups(iter); err != nil {\n-\t\treturn err\n-\t}\n-\n-\t// List all backups that contain a name.\n-\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n-\t\tParent: instanceName,\n-\t\tFilter: \"name:\" + backupID,\n-\t})\n-\tif err := printBackups(iter); err != nil {\n-\t\treturn err\n-\t}\n-\n-\t// List all backups that expire before a timestamp.\n-\texpireTime := time.Now().AddDate(0, 0, 30)\n-\tfilter = fmt.Sprintf(`expire_time < \"%s\"`, expireTime.Format(time.RFC3339))\n-\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n-\t\tParent: instanceName,\n-\t\tFilter: filter,\n-\t})\n-\tif err := printBackups(iter); err != nil {\n-\t\treturn err\n-\t}\n-\n-\t// List all backups for a database that contains a name.\n-\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n-\t\tParent: instanceName,\n-\t\tFilter: \"database:\" + db,\n-\t})\n-\tif err := printBackups(iter); err != nil {\n-\t\treturn err\n-\t}\n-\n-\t// List all backups with a size greater than some bytes.\n-\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n-\t\tParent: instanceName,\n-\t\tFilter: \"size_bytes > 100\",\n-\t})\n-\tif err := printBackups(iter); err != nil {\n-\t\treturn err\n-\t}\n-\n-\t// List backups that were created after a timestamp that are also ready.\n-\tcreateTime := time.Now().AddDate(0, 0, -1)\n-\tfilter = fmt.Sprintf(\n-\t\t`create_time >= \"%s\" AND state:READY`,\n-\t\tcreateTime.Format(time.RFC3339),\n-\t)\n-\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n-\t\tParent: instanceName,\n-\t\tFilter: filter,\n-\t})\n-\tif err := printBackups(iter); err != nil {\n-\t\treturn err\n-\t}\n-\n-\t// List backups with pagination.\n-\trequest := &adminpb.ListBackupsRequest{\n-\t\tParent:   instanceName,\n-\t\tPageSize: 10,\n-\t}\n-\tfor {\n-\t\titer = adminClient.ListBackups(ctx, request)\n-\t\tif err := printBackups(iter); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tpageToken := iter.PageInfo().Token\n-\t\tif pageToken == \"\" {\n-\t\t\tbreak\n-\t\t} else {\n-\t\t\trequest.PageToken = pageToken\n-\t\t}\n-\t}\n-\n-\tfmt.Fprintf(w, \"Backups listed.\\n\")\n-\treturn nil\n-}\n-\n-// [END spanner_list_backups]\n-\n-// [START spanner_list_backup_operations]\n-\n-func listBackupOperations(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n-\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n-\tif matches == nil || len(matches) != 3 {\n-\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n-\t}\n-\tinstanceName := matches[1]\n-\t// List the CreateBackup operations.\n-\tfilter := fmt.Sprintf(\"(metadata.database:%s) AND (metadata.@type:type.googleapis.com/google.spanner.admin.database.v1.CreateBackupMetadata)\", database)\n-\titer := adminClient.ListBackupOperations(ctx, &adminpb.ListBackupOperationsRequest{\n-\t\tParent: instanceName,\n-\t\tFilter: filter,\n-\t})\n-\tfor {\n-\t\tresp, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tmetadata := &adminpb.CreateBackupMetadata{}\n-\t\tif err := ptypes.UnmarshalAny(resp.Metadata, metadata); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"Backup %s on database %s is %d%% complete.\\n\",\n-\t\t\tmetadata.Name,\n-\t\t\tmetadata.Database,\n-\t\t\tmetadata.Progress.ProgressPercent,\n-\t\t)\n-\t}\n-\treturn nil\n-}\n-\n-// [END spanner_list_backup_operations]\n-\n-// [START spanner_list_database_operations]\n-\n-func listDatabaseOperations(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n-\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n-\tif matches == nil || len(matches) != 3 {\n-\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n-\t}\n-\tinstanceName := matches[1]\n-\t// List the databases that are being optimized after a restore operation.\n-\tfilter := \"(metadata.@type:type.googleapis.com/google.spanner.admin.database.v1.OptimizeRestoredDatabaseMetadata)\"\n-\titer := adminClient.ListDatabaseOperations(ctx, &adminpb.ListDatabaseOperationsRequest{\n-\t\tParent: instanceName,\n-\t\tFilter: filter,\n-\t})\n-\tfor {\n-\t\tresp, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tmetadata := &adminpb.OptimizeRestoredDatabaseMetadata{}\n-\t\tif err := ptypes.UnmarshalAny(resp.Metadata, metadata); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"Database %s restored from backup is %d%% optimized.\\n\",\n-\t\t\tmetadata.Name,\n-\t\t\tmetadata.Progress.ProgressPercent,\n-\t\t)\n-\t}\n-\treturn nil\n-}\n-\n-// [END spanner_list_database_operations]\n-\n-// [START spanner_update_backup]\n-\n-func updateBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n-\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n-\tif matches == nil || len(matches) != 3 {\n-\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n-\t}\n-\tbackupName := matches[1] + \"/backups/\" + backupID\n-\n-\tbackup, err := adminClient.GetBackup(ctx, &adminpb.GetBackupRequest{Name: backupName})\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\t// Expire time must be within 366 days of the create time of the backup.\n-\texpireTime := time.Unix(backup.CreateTime.Seconds, int64(backup.CreateTime.Nanos)).AddDate(0, 0, 30)\n-\texpirespb, err := pbts.TimestampProto(expireTime)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\t_, err = adminClient.UpdateBackup(ctx, &adminpb.UpdateBackupRequest{\n-\t\tBackup: &adminpb.Backup{\n-\t\t\tName:       backupName,\n-\t\t\tExpireTime: expirespb,\n-\t\t},\n-\t\tUpdateMask: &field_mask.FieldMask{Paths: []string{\"expire_time\"}},\n-\t})\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\tfmt.Fprintf(w, \"Updated backup %s\\n\", backupID)\n-\treturn nil\n-}\n-\n-// [END spanner_update_backup]\n-\n-// [START spanner_restore_backup]\n-\n-func restoreBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n-\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n-\tif matches == nil || len(matches) != 3 {\n-\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n-\t}\n-\tinstanceName := matches[1]\n-\tdatabaseID := matches[2]\n-\tbackupName := instanceName + \"/backups/\" + backupID\n-\n-\t// Start restoring backup to a new database.\n-\trestoreOp, err := adminClient.RestoreDatabase(ctx, &adminpb.RestoreDatabaseRequest{\n-\t\tParent:     instanceName,\n-\t\tDatabaseId: databaseID,\n-\t\tSource: &adminpb.RestoreDatabaseRequest_Backup{\n-\t\t\tBackup: backupName,\n-\t\t},\n-\t})\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\t// Wait for restore operation to complete.\n-\tdb, err := restoreOp.Wait(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\t// Newly created database has restore information.\n-\tbackupInfo := db.RestoreInfo.GetBackupInfo()\n-\tif backupInfo != nil {\n-\t\tfmt.Fprintf(w, \"Source database %s restored from backup %s\\n\", backupInfo.SourceDatabase, backupInfo.Backup)\n-\t}\n-\n-\treturn nil\n-}\n-\n-// [END spanner_restore_backup]\n-\n-// [START spanner_delete_backup]\n-\n-func deleteBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n-\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n-\tif matches == nil || len(matches) != 3 {\n-\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n-\t}\n-\tbackupName := matches[1] + \"/backups/\" + backupID\n-\t// Delete the backup.\n-\terr := adminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: backupName})\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tfmt.Fprintf(w, \"Deleted backup %s\\n\", backupID)\n-\treturn nil\n-}\n-\n-// [END spanner_delete_backup]\n-\n-func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n-\t// [START spanner_create_admin_client_for_emulator]\n-\n-\tvar opts []option.ClientOption\n-\n-\temulatorAddr := os.Getenv(\"SPANNER_EMULATOR_HOST\")\n-\tif emulatorAddr != \"\" {\n-\t\topts = append(\n-\t\t\topts,\n-\t\t\toption.WithEndpoint(emulatorAddr),\n-\t\t\toption.WithGRPCDialOption(grpc.WithInsecure()),\n-\t\t\toption.WithoutAuthentication(),\n-\t\t)\n-\t}\n-\n-\tadminClient, err := database.NewDatabaseAdminClient(ctx, opts...)\n-\tif err != nil {\n-\t\tlog.Fatal(err)\n-\t}\n-\n-\t// [END spanner_create_admin_client_for_emulator]\n-\n-\tdataClient, err := spanner.NewClient(ctx, db)\n-\tif err != nil {\n-\t\tlog.Fatal(err)\n-\t}\n-\n-\treturn adminClient, dataClient\n-}\n-\n-func run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, w io.Writer, cmd string, db string, backupID string) error {\n+func run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, w io.Writer, cmd string, db string) error {\n \tif adminCmdFn := adminCommands[cmd]; adminCmdFn != nil {\n \t\terr := adminCmdFn(ctx, w, adminClient, db)\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -2290,24 +500,6 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \t\treturn err\n \t}\n \n-\t// Command that needs a backup ID.\n-\tif backupCmdFn := backupCommands[cmd]; backupCmdFn != nil {\n-\t\terr := backupCmdFn(ctx, w, adminClient, db, backupID)\n-\t\tif err != nil {\n-\t\t\tfmt.Fprintf(w, \"%s failed with %v\", cmd, err)\n-\t\t}\n-\t\treturn err\n-\t}\n-\n-\t// Command that needs to create a new client.\n-\tif newClientCmdFn := newClientCommands[cmd]; newClientCmdFn != nil {\n-\t\terr := newClientCmdFn(ctx, w, db)\n-\t\tif err != nil {\n-\t\t\tfmt.Fprintf(w, \"%s failed with %v\", cmd, err)\n-\t\t}\n-\t\treturn err\n-\t}\n-\n \t// Normal mode\n \tcmdFn := commands[cmd]\n \tif cmdFn == nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "chore: Updated appengine samples to 1.14",
        "pr_number": 1733,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -2323,27 +515,15 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \n func main() {\n \tflag.Usage = func() {\n-\t\tfmt.Fprintf(os.Stderr, `Usage: spanner_snippets <command> <database_name> <backup_id>\n+\t\tfmt.Fprintf(os.Stderr, `Usage: spanner_snippets <command> <database_name>\n \n-\tCommand can be one of: createdatabase, write, query, read, update,\n-\t\twritetransaction, addnewcolumn, querynewcolumn, addindex, queryindex, readindex,\n-\t\taddstoringindex, readstoringindex, readonlytransaction, readstaledata, readbatchdata,\n-\t\taddcommittimestamp, updatewithtimestamp, querywithtimestamp, createtablewithtimestamp,\n-\t\twritewithtimestamp, querynewtable, createtabledocswithtimestamp, writetodocstable,\n-\t\tupdatedocstable, querydocstable, createtabledocswithhistorytable, writewithhistory,\n-\t\tupdatewithhistory, querywithhistory, writestructdata, querywithstruct, querywitharrayofstruct,\n-\t\tquerywithstructfield, querywithnestedstructfield, dmlinsert, dmlupdate, dmldelete,\n-\t\tdmlwithtimestamp, dmlwriteread, dmlwrite, dmlwritetxn, querywithparameter, dmlupdatepart,\n-\t\tdmldeletepart, dmlbatchupdate, createtablewithdatatypes, writedatatypesdata, querywitharray,\n-\t\tquerywithbool, querywithbytes, querywithdate, querywithfloat, querywithint, querywithstring,\n-\t\tquerywithtimestampparameter, createbackup, listbackups, updatebackup, deletebackup, restorebackup,\n-\t\tlistbackupoperations, listdatabaseoperations, querywithtimestampparameter, querywithqueryoptions,\n-\t\tcreateclientwithqueryoptions\n+\tCommand can be one of: write, read, query, update, querynewcolumn,\n+\t\tquerywithparameter, dmlwrite, dmlwritetxn, readindex, readstoringindex,\n+\t\treadonlytransaction, createdatabase, addnewcolumn, addstoringindex\n \n Examples:\n \tspanner_snippets createdatabase projects/my-project/instances/my-instance/databases/example-db\n \tspanner_snippets write projects/my-project/instances/my-instance/databases/example-db\n-\tspanner_snippets createbackup projects/my-project/instances/my-instance/databases/example-db my-backup\n `)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into update-appengine",
        "commit_id": "c623d60a61e58820c457ea2a72843f1ac9b46390"
    },
    {
        "pr_title": "feat(storage): sample gap (1/2 object part)",
        "pr_number": 1722,
        "file_name": "endpoints/getting-started-grpc/server/main.go",
        "code_diff": "@@ -40,6 +40,7 @@\nimport (\n \t\"net\"\n \n \t\"google.golang.org/grpc\"\n+\t\"google.golang.org/grpc/examples/helloworld/helloworld\"\n \tpb \"google.golang.org/grpc/examples/helloworld/helloworld\"\n \t\"google.golang.org/grpc/reflection\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into storage_sample_gap_obj",
        "commit_id": "808d0e9f9ec93d58a5f35163c6d1db0d17ef71e4"
    },
    {
        "pr_title": "feat(spanner): add numeric samples",
        "pr_number": 1708,
        "file_name": "spanner/spanner_snippets/spanner/spanner_query_with_numeric_parameter.go",
        "code_diff": "@@ -37,7 +37,7 @@\nfunc queryWithNumericParameter(w io.Writer, db string) error {\n \tstmt := spanner.Statement{\n \t\tSQL: `SELECT VenueId, Revenue FROM Venues WHERE Revenue < @revenue`,\n \t\tParams: map[string]interface{}{\n-\t\t\t\"revenue\": 100000,\n+\t\t\t\"revenue\": big.NewRat(100000, 1),\n \t\t},\n \t}\n \titer := client.Single().Query(ctx, stmt)",
        "comments": [
            {
                "comment": "I didn't realize that the different languages format their print statements differently. This should match the Golang style.\r\n\r\n```suggestion\r\n\t\tfmt.Fprintf(w, \"%v %v\\n\", venueID, revenue)\r\n```",
                "position": null
            }
        ],
        "commit_message": "Fix comments.",
        "commit_id": "cf8a59f1c761c2648a4186f7f937b74fce618294"
    },
    {
        "pr_title": "feat(spanner): add numeric samples",
        "pr_number": 1708,
        "file_name": "spanner/spanner_snippets/spanner/spanner_update_data_with_numeric_column.go",
        "code_diff": "@@ -14,15 +14,15 @@\npackage spanner\n \n-// [START spanner_update_data_with_numeric]\n+// [START spanner_update_data_with_numeric_column]\n import (\n \t\"context\"\n \t\"io\"\n \n \t\"cloud.google.com/go/spanner\"\n )\n \n-func updateDataWithNumeric(w io.Writer, db string) error {\n+func updateDataWithNumericColumn(w io.Writer, db string) error {\n \tctx := context.Background()\n \n \tclient, err := spanner.NewClient(ctx, db)",
        "comments": [],
        "commit_message": "Fix comments.",
        "commit_id": "cf8a59f1c761c2648a4186f7f937b74fce618294"
    },
    {
        "pr_title": "feat(iam): update quickstart samples",
        "pr_number": 1668,
        "file_name": "iam/quickstartv2/quickstart.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START iam_quickstartv2]\n+// [START iam_quickstart_v2]\n \n package main",
        "comments": [
            {
                "comment": "Delete newline.",
                "position": null
            },
            {
                "comment": "Do we need to keep both quickstarts? Should we just edit the existing one?\r\n\r\nThis one looks a bit long to be a single embed. But, it's up to you.",
                "position": null
            },
            {
                "comment": "File path comment: v2 in the directory name might be confusing -- normally used for API versions or Go module version. But, this is quickstart version.",
                "position": null
            },
            {
                "comment": "Inline to reduce indirection in the sample? Also, as a general rule, functions shouldn't `log.Fatal` -- they should return errors. But, at that point, inlining seems like the way to go.",
                "position": null
            },
            {
                "comment": "```suggestion\r\n\t// Find the policy binding for role. Only one binding can have the role.\r\n\tvar binding *cloudresourcemanager.Binding\r\n\tfor _, b := range policy.Bindings {\r\n\t\tif b.Role == role {\r\n\t\t\tbinding = b\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n```\r\n\r\n(Is the comment correct?)",
                "position": null
            },
            {
                "comment": "Is this formatting required? You could also do `strings.Join(binding.Members, \", \")`.",
                "position": null
            },
            {
                "comment": "```suggestion\r\n\t\tbinding = &cloudresourcemanager.Binding{\r\n\t\t\tRole:    role,\r\n\t\t\tMembers: []string{member},\r\n\t\t}\r\n```",
                "position": null
            },
            {
                "comment": "Why zero this out?",
                "position": null
            },
            {
                "comment": "We need to keep both around until I have a chance to update the document to describe the new flow. After that, I'll create a separate PR to remove the old sample and rename this one.",
                "position": null
            },
            {
                "comment": "Right. It's a temporary step. This is the last language I needed to write a sample for, so it should be a fairly quick turnaround.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "You're right, there's no reason to. Removed.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "Adjust region tag",
        "commit_id": "37474adf1d96103c825b4dcc4d40577c3219fa48"
    },
    {
        "pr_title": "fix(bigtable): add retry for writing data test",
        "pr_number": 1630,
        "file_name": "functions/helloworld/hello_cloud_storage.go",
        "code_diff": "@@ -19,8 +19,11 @@\npackage helloworld\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"log\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/functions/metadata\"\n )\n \n // GCSEvent is the payload of a GCS event.",
        "comments": [],
        "commit_message": "Merge branch 'master' into bigtable-flakey-tests",
        "commit_id": "3376870f2cc71961852cc041489033fd7cb68443"
    },
    {
        "pr_title": "feat(pubsub): add ordering key samples",
        "pr_number": 1625,
        "file_name": "run/events_pubsub/main.go",
        "code_diff": "@@ -12,38 +12,47 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START run_events_pubsub_server]\n+// [START run_events_pubsub_handler]\n \n-// Sample run-pubsub-events is a Cloud Run service which handles Pub/Sub messages.\n+// Sample run-events-pubsub is a Cloud Run service which handles Pub/Sub messages.\n package main\n \n import (\n-\t\"context\"\n+\t\"encoding/json\"\n \t\"fmt\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"\n-\n-\tcloudevents \"github.com/cloudevents/sdk-go/v2\"\n )\n \n-var (\n-\thandler = http.DefaultServeMux\n-)\n+// PubSubMessage is the payload of a Pub/Sub event.\n+type PubSubMessage struct {\n+\tMessage struct {\n+\t\tData []byte `json:\"data,omitempty\"`\n+\t\tID   string `json:\"id\"`\n+\t} `json:\"message\"`\n+\tSubscription string `json:\"subscription\"`\n+}\n \n-func main() {\n-\tctx := context.Background()\n-\t// Create a new HTTP client for CloudEvents\n-\tp, err := cloudevents.NewHTTP()\n-\tif err != nil {\n-\t\tlog.Fatal(err)\n+// HelloEventsPubSub receives and processes a Pub/Sub push message.\n+func HelloEventsPubSub(w http.ResponseWriter, r *http.Request) {\n+\tvar e PubSubMessage\n+\tif err := json.NewDecoder(r.Body).Decode(&e); err != nil {\n+\t\thttp.Error(w, \"Bad HTTP Request\", http.StatusBadRequest)\n+\t\tlog.Printf(\"Bad HTTP Request: %v\", http.StatusBadRequest)\n+\t\treturn\n \t}\n-\thandleFn, err := cloudevents.NewHTTPReceiveHandler(ctx, p, HelloPubSub)\n-\tif err != nil {\n-\t\tlog.Fatal(err)\n+\tname := string(e.Message.Data)\n+\tif name == \"\" {\n+\t\tname = \"World\"\n \t}\n-\thandler.Handle(\"/\", handleFn)\n+\ts := fmt.Sprintf(\"Hello, %s! ID: %s\", name, string(r.Header.Get(\"Ce-Id\")))\n+\tlog.Printf(s)\n+\tfmt.Fprintln(w, s)\n+}\n \n+func main() {\n+\thttp.HandleFunc(\"/\", HelloEventsPubSub)\n \t// Determine port for HTTP service.\n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub-ordering-key-samples",
        "commit_id": "14601bc51a617b9628057965294a3a5015c5e486"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "asset/quickstart/create-feed/main_test.go",
        "code_diff": "@@ -25,6 +25,7 @@\nimport (\n \tasset \"cloud.google.com/go/asset/apiv1\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n \tcloudresourcemanager \"google.golang.org/api/cloudresourcemanager/v1\"\n \tassetpb \"google.golang.org/genproto/googleapis/cloud/asset/v1\"\n \t\"google.golang.org/grpc/codes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "asset/quickstart/create-feed/main_test.go",
        "code_diff": "@@ -34,7 +35,7 @@\nimport (\n func TestMain(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tenv := map[string]string{\"GOOGLE_CLOUD_PROJECT\": tc.ProjectID}\n-\tfeedID := fmt.Sprintf(\"FEED-%s\", strconv.FormatInt(time.Now().UnixNano(), 10))\n+\tfeedID := fmt.Sprintf(\"FEED-%s\", uuid.Must(uuid.NewV4()).String()[:8])\n \n \tctx := context.Background()\n \tcloudresourcemanagerClient, err := cloudresourcemanager.NewService(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "asset/quickstart/delete-feed/main_test.go",
        "code_diff": "@@ -17,14 +17,14 @@\npackage main\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \tasset \"cloud.google.com/go/asset/apiv1\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n \tassetpb \"google.golang.org/genproto/googleapis/cloud/asset/v1\"\n \t\"google.golang.org/grpc/codes\"\n \t\"google.golang.org/grpc/status\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "asset/quickstart/delete-feed/main_test.go",
        "code_diff": "@@ -33,7 +33,7 @@\nimport (\n func TestMain(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tenv := map[string]string{\"GOOGLE_CLOUD_PROJECT\": tc.ProjectID}\n-\tfeedID := fmt.Sprintf(\"FEED-%s\", strconv.FormatInt(time.Now().UnixNano(), 10))\n+\tfeedID := fmt.Sprintf(\"FEED-%s\", uuid.Must(uuid.NewV4()).String()[:8])\n \n \tctx := context.Background()\n \tclient, err := asset.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "bigtable/writes/writes_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/bigtable\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "functions/helloworld/hello_cloud_storage.go",
        "code_diff": "@@ -19,8 +19,11 @@\npackage helloworld\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"log\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/functions/metadata\"\n )\n \n // GCSEvent is the payload of a GCS event.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "functions/security/idtoken.go",
        "code_diff": "@@ -16,6 +16,8 @@\npackage security\n \n // [START functions_bearer_token]\n+// [START run_service_to_service_auth]\n+\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "functions/security/idtoken.go",
        "code_diff": "@@ -24,20 +26,19 @@\nimport (\n \t\"google.golang.org/api/idtoken\"\n )\n \n-// callFunction makes a request to the provided functionURL with an\n-// authenticated client.\n-func callFunction(w io.Writer, functionURL string) error {\n-\t// functionURL := \"https://REGION-PROJECT.cloudfunctions.net/RECEIVING_FUNCTION\"\n+// makeGetRequest makes a request to the provided targetURL with an authenticated client.\n+func makeGetRequest(w io.Writer, targetURL string) error {\n+\t// functionURL := \"https://TARGET_URL\"\n \tctx := context.Background()\n \n \t// client is a http.Client that automatically adds an \"Authorization\" header\n \t// to any requests made.\n-\tclient, err := idtoken.NewClient(ctx, functionURL)\n+\tclient, err := idtoken.NewClient(ctx, targetURL)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"idtoken.NewClient: %v\", err)\n \t}\n \n-\tresp, err := client.Get(functionURL)\n+\tresp, err := client.Get(targetURL)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"client.Get: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -58,8 +58,11 @@\nfunc deleteBucketIfExists(ctx context.Context, t *testing.T, client *storage.Cli\n \t\treturn\n \t}\n \n-\t// Delete all of the elements in the already existent bucket.\n-\tit := b.Objects(ctx, nil)\n+\t// Delete all of the elements in the already existent bucket, including noncurrent objects.\n+\tit := b.Objects(ctx, &storage.Query{\n+\t\t// Versions true to output all generations of objects.\n+\t\tVersions: true,\n+\t})\n \tfor {\n \t\tattrs, err := it.Next()\n \t\tif err == iterator.Done {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "run/markdown-preview/editor/service.go",
        "code_diff": "@@ -45,10 +45,6 @@\nfunc NewServiceFromEnv() (*Service, error) {\n \tif url == \"\" {\n \t\treturn nil, errors.New(\"no configuration for upstream render service: add EDITOR_UPSTREAM_RENDER_URL environment variable\")\n \t}\n-\tauth := os.Getenv(\"EDITOR_UPSTREAM_UNAUTHENTICATED\") == \"\"\n-\tif !auth {\n-\t\tlog.Println(\"editor: starting in unauthenticated upstream mode\")\n-\t}\n \n \t// The use case of this service is the UI driven by these files.\n \t// Loading them as part of the server startup process keeps failures easily",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "run/markdown-preview/editor/service.go",
        "code_diff": "@@ -66,8 +62,7 @@\nfunc NewServiceFromEnv() (*Service, error) {\n \n \treturn &Service{\n \t\tRenderer: &RenderService{\n-\t\t\tURL:           url,\n-\t\t\tAuthenticated: auth,\n+\t\t\tURL: url,\n \t\t},\n \t\tparsedTemplate:  parsedTemplate,\n \t\tmarkdownDefault: markdownDefault,",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -45,6 +45,7 @@\nfunc TestObjects(t *testing.T) {\n \tvar (\n \t\tbucket                = tc.ProjectID + \"-samples-object-bucket-1\"\n \t\tdstBucket             = tc.ProjectID + \"-samples-object-bucket-2\"\n+\t\tbucketVersioning      = tc.ProjectID + \"-bucket-versioning-enabled\"\n \t\tobject1               = \"foo.txt\"\n \t\tobject2               = \"foo/a.txt\"\n \t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -53,6 +54,16 @@\nfunc TestObjects(t *testing.T) {\n \n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, dstBucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketVersioning)\n+\n+\t{\n+\t\t// Enable versioning\n+\t\tattr := storage.BucketAttrsToUpdate{VersioningEnabled: true}\n+\t\t_, err := client.Bucket(bucketVersioning).Update(ctx, attr)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"storage.BucketAttrsToUpdate{VersioningEnabled: true}: %v\", err)\n+\t\t}\n+\t}\n \n \tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -61,6 +72,13 @@\nfunc TestObjects(t *testing.T) {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object2, err)\n \t}\n \n+\tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n+\t}\n+\tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n+\t}\n+\n \t{\n \t\t// Should only show \"foo/a.txt\", not \"foo.txt\"\n \t\tvar buf bytes.Buffer",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -90,6 +108,25 @@\nfunc TestObjects(t *testing.T) {\n \t\t}\n \t}\n \n+\t{\n+\t\t// Should show 2 versions of foo.txt\n+\t\tvar buf bytes.Buffer\n+\t\tif err := listFilesAllVersion(&buf, bucketVersioning); err != nil {\n+\t\t\tt.Fatalf(\"listFilesAllVersion: %v\", err)\n+\t\t}\n+\n+\t\ti := 0\n+\t\tfor _, line := range strings.Split(strings.TrimSuffix(buf.String(), \"\\n\"), \"\\n\") {\n+\t\t\tif got, want := line, object1; !strings.Contains(got, want) {\n+\t\t\t\tt.Errorf(\"List(Versions: true) got %q; want to contain %q\", got, want)\n+\t\t\t}\n+\t\t\ti++\n+\t\t}\n+\t\tif i != 2 {\n+\t\t\tt.Errorf(\"listFilesAllVersion should show 2 versions of foo.txt; got %d\", i)\n+\t\t}\n+\t}\n+\n \t{\n \t\tif err := downloadUsingRequesterPays(ioutil.Discard, bucket, object1, tc.ProjectID); err != nil {\n \t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/markdown-preview/renderer/main_test.go",
        "code_diff": "@@ -15,15 +15,9 @@\npackage main\n \n import (\n-\t\"io/ioutil\"\n-\t\"net/http\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"\n-\t\"time\"\n-\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n var tests = []struct {",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/events_pubsub.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/events_storage.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/grpc_ping.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main_test\n+package cloudruntests\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/grpc_server_streaming.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main_test\n+package cloudruntests\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/hello_broken.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/helloworld.e2e_test.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/helloworld.e2e_test.go",
        "code_diff": "@@ -12,10 +12,11 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/helloworld.e2e_test.go",
        "code_diff": "@@ -24,17 +25,18 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func TestRendererServiceDeploy(t *testing.T) {\n+func TestHelloworldService(t *testing.T) {\n \ttc := testutil.EndToEndTest(t)\n \n-\tservice := cloudrunci.NewService(\"renderer\", tc.ProjectID)\n+\tservice := cloudrunci.NewService(\"helloworld\", tc.ProjectID)\n+\tservice.Env = cloudrunci.EnvVars{\"NAME\": \"Override\"}\n+\tservice.Dir = \"../helloworld\"\n \tif err := service.Deploy(); err != nil {\n \t\tt.Fatalf(\"service.Deploy %q: %v\", service.Name, err)\n \t}\n \tdefer service.Clean()\n \n-\trequestPath := \"/\"\n-\treq, err := service.NewRequest(\"POST\", requestPath)\n+\treq, err := service.NewRequest(\"GET\", \"/\")\n \tif err != nil {\n \t\tt.Fatalf(\"service.NewRequest: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/image_processing.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/logging_manual.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/pubsub.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "feat(firestore): query watch samples",
        "pr_number": 1618,
        "file_name": "run/testing/system_package.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into query_watch_samples",
        "commit_id": "03e80d982fb27bda03cef1611dc4ce3f241ba8e5"
    },
    {
        "pr_title": "docs(all): update contributing guide",
        "pr_number": 1616,
        "file_name": "dataproc/create_cluster_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tdataproc \"cloud.google.com/go/dataproc/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into contrib-update",
        "commit_id": "edca14b4fdf1f3323b6dfee980be4ce321816c49"
    },
    {
        "pr_title": "docs(all): update contributing guide",
        "pr_number": 1616,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -456,6 +456,9 @@\nfunc TestPullMsgsDeadLetterDeliveryAttempts(t *testing.T) {\n \t\t\tMaxDeliveryAttempts: 10,\n \t\t},\n \t})\n+\tif err != nil {\n+\t\tt.Fatalf(\"getOrCreateSub: %v\", err)\n+\t}\n \tdefer sub.Delete(ctx)\n \n \tif err = publishMsgs(ctx, deadLetterSourceTopic, 1); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into contrib-update",
        "commit_id": "edca14b4fdf1f3323b6dfee980be4ce321816c49"
    },
    {
        "pr_title": "docs(all): update contributing guide",
        "pr_number": 1616,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -17,12 +17,14 @@\npackage main\n // [START run_secure_request]\n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"net/http\"\n \t\"time\"\n \n-\t\"cloud.google.com/go/compute/metadata\"\n+\t\"golang.org/x/oauth2\"\n+\t\"google.golang.org/api/idtoken\"\n )\n \n // RenderService represents our upstream render service.",
        "comments": [],
        "commit_message": "Merge branch 'master' into contrib-update",
        "commit_id": "edca14b4fdf1f3323b6dfee980be4ce321816c49"
    },
    {
        "pr_title": "docs(all): update contributing guide",
        "pr_number": 1616,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -31,10 +33,12 @@\ntype RenderService struct {\n \tURL string\n \t// Authenticated determines whether identity token authentication will be used.\n \tAuthenticated bool\n+\t// tokenSource provides an identity token for requests to the Render Service.\n+\ttokenSource oauth2.TokenSource\n }\n \n-// NewRequest creates a new HTTP request with IAM ID Token credential.\n-// This token is automatically handled by private Cloud Run (fully managed) and Cloud Functions.\n+// NewRequest creates a new HTTP request to the Render service.\n+// If authentication is enabled, an Identity Token is created and added.\n func (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \treq, err := http.NewRequest(method, s.URL, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into contrib-update",
        "commit_id": "edca14b4fdf1f3323b6dfee980be4ce321816c49"
    },
    {
        "pr_title": "refactor(run/grpc-ping): use client library to mint identity token",
        "pr_number": 1614,
        "file_name": "functions/helloworld/hello_cloud_storage.go",
        "code_diff": "@@ -19,8 +19,11 @@\npackage helloworld\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"log\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/functions/metadata\"\n )\n \n // GCSEvent is the payload of a GCS event.",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-grpc-lib",
        "commit_id": "e605cafd7c74b10244f770c159ec474dd27e0a2f"
    },
    {
        "pr_title": "refactor(run/grpc-ping): use client library to mint identity token",
        "pr_number": 1614,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -58,8 +58,11 @@\nfunc deleteBucketIfExists(ctx context.Context, t *testing.T, client *storage.Cli\n \t\treturn\n \t}\n \n-\t// Delete all of the elements in the already existent bucket.\n-\tit := b.Objects(ctx, nil)\n+\t// Delete all of the elements in the already existent bucket, including noncurrent objects.\n+\tit := b.Objects(ctx, &storage.Query{\n+\t\t// Versions true to output all generations of objects.\n+\t\tVersions: true,\n+\t})\n \tfor {\n \t\tattrs, err := it.Next()\n \t\tif err == iterator.Done {",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-grpc-lib",
        "commit_id": "e605cafd7c74b10244f770c159ec474dd27e0a2f"
    },
    {
        "pr_title": "refactor(run/grpc-ping): use client library to mint identity token",
        "pr_number": 1614,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -17,12 +17,14 @@\npackage main\n // [START run_secure_request]\n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"net/http\"\n \t\"time\"\n \n-\t\"cloud.google.com/go/compute/metadata\"\n+\t\"golang.org/x/oauth2\"\n+\t\"google.golang.org/api/idtoken\"\n )\n \n // RenderService represents our upstream render service.",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-grpc-lib",
        "commit_id": "e605cafd7c74b10244f770c159ec474dd27e0a2f"
    },
    {
        "pr_title": "refactor(run/grpc-ping): use client library to mint identity token",
        "pr_number": 1614,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -31,10 +33,12 @@\ntype RenderService struct {\n \tURL string\n \t// Authenticated determines whether identity token authentication will be used.\n \tAuthenticated bool\n+\t// tokenSource provides an identity token for requests to the Render Service.\n+\ttokenSource oauth2.TokenSource\n }\n \n-// NewRequest creates a new HTTP request with IAM ID Token credential.\n-// This token is automatically handled by private Cloud Run (fully managed) and Cloud Functions.\n+// NewRequest creates a new HTTP request to the Render service.\n+// If authentication is enabled, an Identity Token is created and added.\n func (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \treq, err := http.NewRequest(method, s.URL, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-grpc-lib",
        "commit_id": "e605cafd7c74b10244f770c159ec474dd27e0a2f"
    },
    {
        "pr_title": "refactor(run/grpc-ping): use client library to mint identity token",
        "pr_number": 1614,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -45,6 +45,7 @@\nfunc TestObjects(t *testing.T) {\n \tvar (\n \t\tbucket                = tc.ProjectID + \"-samples-object-bucket-1\"\n \t\tdstBucket             = tc.ProjectID + \"-samples-object-bucket-2\"\n+\t\tbucketVersioning      = tc.ProjectID + \"-bucket-versioning-enabled\"\n \t\tobject1               = \"foo.txt\"\n \t\tobject2               = \"foo/a.txt\"\n \t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-grpc-lib",
        "commit_id": "e605cafd7c74b10244f770c159ec474dd27e0a2f"
    },
    {
        "pr_title": "refactor(run/grpc-ping): use client library to mint identity token",
        "pr_number": 1614,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -53,6 +54,16 @@\nfunc TestObjects(t *testing.T) {\n \n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, dstBucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketVersioning)\n+\n+\t{\n+\t\t// Enable versioning\n+\t\tattr := storage.BucketAttrsToUpdate{VersioningEnabled: true}\n+\t\t_, err := client.Bucket(bucketVersioning).Update(ctx, attr)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"storage.BucketAttrsToUpdate{VersioningEnabled: true}: %v\", err)\n+\t\t}\n+\t}\n \n \tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-grpc-lib",
        "commit_id": "e605cafd7c74b10244f770c159ec474dd27e0a2f"
    },
    {
        "pr_title": "refactor(run/grpc-ping): use client library to mint identity token",
        "pr_number": 1614,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -61,6 +72,13 @@\nfunc TestObjects(t *testing.T) {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object2, err)\n \t}\n \n+\tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n+\t}\n+\tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n+\t}\n+\n \t{\n \t\t// Should only show \"foo/a.txt\", not \"foo.txt\"\n \t\tvar buf bytes.Buffer",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-grpc-lib",
        "commit_id": "e605cafd7c74b10244f770c159ec474dd27e0a2f"
    },
    {
        "pr_title": "refactor(run/grpc-ping): use client library to mint identity token",
        "pr_number": 1614,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -90,6 +108,25 @@\nfunc TestObjects(t *testing.T) {\n \t\t}\n \t}\n \n+\t{\n+\t\t// Should show 2 versions of foo.txt\n+\t\tvar buf bytes.Buffer\n+\t\tif err := listFilesAllVersion(&buf, bucketVersioning); err != nil {\n+\t\t\tt.Fatalf(\"listFilesAllVersion: %v\", err)\n+\t\t}\n+\n+\t\ti := 0\n+\t\tfor _, line := range strings.Split(strings.TrimSuffix(buf.String(), \"\\n\"), \"\\n\") {\n+\t\t\tif got, want := line, object1; !strings.Contains(got, want) {\n+\t\t\t\tt.Errorf(\"List(Versions: true) got %q; want to contain %q\", got, want)\n+\t\t\t}\n+\t\t\ti++\n+\t\t}\n+\t\tif i != 2 {\n+\t\t\tt.Errorf(\"listFilesAllVersion should show 2 versions of foo.txt; got %d\", i)\n+\t\t}\n+\t}\n+\n \t{\n \t\tif err := downloadUsingRequesterPays(ioutil.Discard, bucket, object1, tc.ProjectID); err != nil {\n \t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into run-grpc-lib",
        "commit_id": "e605cafd7c74b10244f770c159ec474dd27e0a2f"
    },
    {
        "pr_title": "opencensus: add a sample for trace exemplar",
        "pr_number": 1607,
        "file_name": "dataproc/create_cluster_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tdataproc \"cloud.google.com/go/dataproc/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "04e84cfc8a833a55ae46003f411825bb96b9fc74"
    },
    {
        "pr_title": "opencensus: add a sample for trace exemplar",
        "pr_number": 1607,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -456,6 +456,9 @@\nfunc TestPullMsgsDeadLetterDeliveryAttempts(t *testing.T) {\n \t\t\tMaxDeliveryAttempts: 10,\n \t\t},\n \t})\n+\tif err != nil {\n+\t\tt.Fatalf(\"getOrCreateSub: %v\", err)\n+\t}\n \tdefer sub.Delete(ctx)\n \n \tif err = publishMsgs(ctx, deadLetterSourceTopic, 1); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "04e84cfc8a833a55ae46003f411825bb96b9fc74"
    },
    {
        "pr_title": "pubsub: add subscription detach samples",
        "pr_number": 1604,
        "file_name": "dataproc/create_cluster_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tdataproc \"cloud.google.com/go/dataproc/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into cps-detach-samples",
        "commit_id": "455044b8351f67b11897de911b19247c64695515"
    },
    {
        "pr_title": "firestore: add LimitToLast samples",
        "pr_number": 1599,
        "file_name": "dataproc/create_cluster_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tdataproc \"cloud.google.com/go/dataproc/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into limit_to_last_samples",
        "commit_id": "6ce4a77eef9d80c86228823964004d686af4c160"
    },
    {
        "pr_title": "storage: listing noncurrent object versions",
        "pr_number": 1585,
        "file_name": "dataproc/create_cluster_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tdataproc \"cloud.google.com/go/dataproc/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "30b14cbef2b9f4a9e6e1468231a2c87da12ff0e4"
    },
    {
        "pr_title": "storage: listing noncurrent object versions",
        "pr_number": 1585,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -456,6 +456,9 @@\nfunc TestPullMsgsDeadLetterDeliveryAttempts(t *testing.T) {\n \t\t\tMaxDeliveryAttempts: 10,\n \t\t},\n \t})\n+\tif err != nil {\n+\t\tt.Fatalf(\"getOrCreateSub: %v\", err)\n+\t}\n \tdefer sub.Delete(ctx)\n \n \tif err = publishMsgs(ctx, deadLetterSourceTopic, 1); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "30b14cbef2b9f4a9e6e1468231a2c87da12ff0e4"
    },
    {
        "pr_title": "storage: listing noncurrent object versions",
        "pr_number": 1585,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -17,12 +17,14 @@\npackage main\n // [START run_secure_request]\n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"net/http\"\n \t\"time\"\n \n-\t\"cloud.google.com/go/compute/metadata\"\n+\t\"golang.org/x/oauth2\"\n+\t\"google.golang.org/api/idtoken\"\n )\n \n // RenderService represents our upstream render service.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "30b14cbef2b9f4a9e6e1468231a2c87da12ff0e4"
    },
    {
        "pr_title": "storage: listing noncurrent object versions",
        "pr_number": 1585,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -31,10 +33,12 @@\ntype RenderService struct {\n \tURL string\n \t// Authenticated determines whether identity token authentication will be used.\n \tAuthenticated bool\n+\t// tokenSource provides an identity token for requests to the Render Service.\n+\ttokenSource oauth2.TokenSource\n }\n \n-// NewRequest creates a new HTTP request with IAM ID Token credential.\n-// This token is automatically handled by private Cloud Run (fully managed) and Cloud Functions.\n+// NewRequest creates a new HTTP request to the Render service.\n+// If authentication is enabled, an Identity Token is created and added.\n func (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \treq, err := http.NewRequest(method, s.URL, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "30b14cbef2b9f4a9e6e1468231a2c87da12ff0e4"
    },
    {
        "pr_title": "storage: unflake TestKMSObjects",
        "pr_number": 1575,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -20,6 +20,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"os\"\n+\t\"regexp\"\n+\t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-flake",
        "commit_id": "d039968307312df64ae4e3d0a4cf1647b0f745db"
    },
    {
        "pr_title": "storage: unflake TestKMSObjects",
        "pr_number": 1575,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -37,10 +39,14 @@\ntype sampleFunc func(w io.Writer, dbName string) error\n type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(w io.Writer, dbName, backupID string) error\n \n-func initTest(t *testing.T, projectID string) (dbName string, cleanup func()) {\n+var (\n+\tvalidInstancePattern = regexp.MustCompile(\"^projects/(?P<project>[^/]+)/instances/(?P<instance>[^/]+)$\")\n+)\n+\n+func initTest(t *testing.T, id string) (dbName string, cleanup func()) {\n \tinstance := getInstance(t)\n-\tdatabaseID := validLength(fmt.Sprintf(\"test-%s\", projectID), t)\n-\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, databaseID)\n+\tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n+\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, dbID)\n \n \tctx := context.Background()\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-flake",
        "commit_id": "d039968307312df64ae4e3d0a4cf1647b0f745db"
    },
    {
        "pr_title": "storage: unflake TestKMSObjects",
        "pr_number": 1575,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -66,12 +72,12 @@\nfunc initTest(t *testing.T, projectID string) (dbName string, cleanup func()) {\n \treturn\n }\n \n-func initBackupTest(t *testing.T, projectID, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n+func initBackupTest(t *testing.T, id, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n \tinstance := getInstance(t)\n-\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", projectID), t)\n+\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", id), t)\n \trestoreDBName = fmt.Sprintf(\"%s/databases/%s\", instance, restoreDatabaseID)\n-\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", projectID), t)\n-\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", projectID), t)\n+\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", id), t)\n+\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", id), t)\n \n \tctx := context.Background()\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-flake",
        "commit_id": "d039968307312df64ae4e3d0a4cf1647b0f745db"
    },
    {
        "pr_title": "storage: unflake TestKMSObjects",
        "pr_number": 1575,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -112,20 +118,24 @@\nfunc initBackupTest(t *testing.T, projectID, dbName string) (restoreDBName, back\n }\n \n func TestCreateInstance(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+\t_ = testutil.SystemTest(t)\n+\n+\tprojectID, _, err := parseInstanceName(getInstance(t))\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to parse instance name: %v\", err)\n+\t}\n \n \tinstanceID := fmt.Sprintf(\"go-sample-test-%s\", uuid.New().String()[:8])\n-\tout := runInstanceSample(t, createInstance, tc.ProjectID, instanceID, \"failed to create an instance\")\n-\tif err := cleanupInstance(tc.ProjectID, instanceID); err != nil {\n+\tout := runInstanceSample(t, createInstance, projectID, instanceID, \"failed to create an instance\")\n+\tif err := cleanupInstance(projectID, instanceID); err != nil {\n \t\tt.Logf(\"cleanupInstance error: %s\", err)\n \t}\n \tassertContains(t, out, fmt.Sprintf(\"Created instance [%s]\", instanceID))\n }\n \n func TestSample(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tdbName, cleanup := initTest(t, tc.ProjectID)\n+\t_ = testutil.SystemTest(t)\n+\tdbName, cleanup := initTest(t, randomID())\n \tdefer cleanup()\n \n \tvar out string",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-flake",
        "commit_id": "d039968307312df64ae4e3d0a4cf1647b0f745db"
    },
    {
        "pr_title": "storage: unflake TestKMSObjects",
        "pr_number": 1575,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -308,11 +318,12 @@\nfunc TestSample(t *testing.T) {\n }\n \n func TestBackupSample(t *testing.T) {\n-\ttc := testutil.EndToEndTest(t)\n+\t_ = testutil.EndToEndTest(t)\n \n-\tdbName, cleanup := initTest(t, tc.ProjectID)\n+\tid := randomID()\n+\tdbName, cleanup := initTest(t, id)\n \tdefer cleanup()\n-\trestoreDBName, backupID, cancelledBackupID, cleanupBackup := initBackupTest(t, tc.ProjectID, dbName)\n+\trestoreDBName, backupID, cancelledBackupID, cleanupBackup := initBackupTest(t, id, dbName)\n \n \tvar out string\n \t// Set up the database for testing backup operations.",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-flake",
        "commit_id": "d039968307312df64ae4e3d0a4cf1647b0f745db"
    },
    {
        "pr_title": "testing(run): add minimal end-to-end tests",
        "pr_number": 1568,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -38,7 +38,7 @@\ntype RenderService struct {\n func (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \treq, err := http.NewRequest(method, s.URL, nil)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"http.NewRequest: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"http.NewRequest: %w\", err)\n \t}\n \n \t// Skip authentication if not using HTTPS, such as for local development.",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/e2e-minimal",
        "commit_id": "b9d2026f1fef8407d942bc265d18512e3f9b6ea1"
    },
    {
        "pr_title": "testing(run): add minimal end-to-end tests",
        "pr_number": 1568,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -50,7 +50,7 @@\nfunc (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \ttokenURL := fmt.Sprintf(\"/instance/service-accounts/default/identity?audience=%s\", s.URL)\n \ttoken, err := metadata.Get(tokenURL)\n \tif err != nil {\n-\t\treturn req, fmt.Errorf(\"metadata.Get: failed to query id_token: %v\", err)\n+\t\treturn req, fmt.Errorf(\"metadata.Get: failed to query id_token: %w\", err)\n \t}\n \n \treq.Header.Add(\"Authorization\", fmt.Sprintf(\"Bearer %s\", token))",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/e2e-minimal",
        "commit_id": "b9d2026f1fef8407d942bc265d18512e3f9b6ea1"
    },
    {
        "pr_title": "testing(run): add minimal end-to-end tests",
        "pr_number": 1568,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -20,6 +20,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"os\"\n+\t\"regexp\"\n+\t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/e2e-minimal",
        "commit_id": "b9d2026f1fef8407d942bc265d18512e3f9b6ea1"
    },
    {
        "pr_title": "testing(run): add minimal end-to-end tests",
        "pr_number": 1568,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -37,10 +39,14 @@\ntype sampleFunc func(w io.Writer, dbName string) error\n type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(w io.Writer, dbName, backupID string) error\n \n-func initTest(t *testing.T, projectID string) (dbName string, cleanup func()) {\n+var (\n+\tvalidInstancePattern = regexp.MustCompile(\"^projects/(?P<project>[^/]+)/instances/(?P<instance>[^/]+)$\")\n+)\n+\n+func initTest(t *testing.T, id string) (dbName string, cleanup func()) {\n \tinstance := getInstance(t)\n-\tdatabaseID := validLength(fmt.Sprintf(\"test-%s\", projectID), t)\n-\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, databaseID)\n+\tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n+\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, dbID)\n \n \tctx := context.Background()\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/e2e-minimal",
        "commit_id": "b9d2026f1fef8407d942bc265d18512e3f9b6ea1"
    },
    {
        "pr_title": "testing(run): add minimal end-to-end tests",
        "pr_number": 1568,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -66,12 +72,12 @@\nfunc initTest(t *testing.T, projectID string) (dbName string, cleanup func()) {\n \treturn\n }\n \n-func initBackupTest(t *testing.T, projectID, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n+func initBackupTest(t *testing.T, id, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n \tinstance := getInstance(t)\n-\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", projectID), t)\n+\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", id), t)\n \trestoreDBName = fmt.Sprintf(\"%s/databases/%s\", instance, restoreDatabaseID)\n-\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", projectID), t)\n-\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", projectID), t)\n+\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", id), t)\n+\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", id), t)\n \n \tctx := context.Background()\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/e2e-minimal",
        "commit_id": "b9d2026f1fef8407d942bc265d18512e3f9b6ea1"
    },
    {
        "pr_title": "testing(run): add minimal end-to-end tests",
        "pr_number": 1568,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -112,20 +118,24 @@\nfunc initBackupTest(t *testing.T, projectID, dbName string) (restoreDBName, back\n }\n \n func TestCreateInstance(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+\t_ = testutil.SystemTest(t)\n+\n+\tprojectID, _, err := parseInstanceName(getInstance(t))\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to parse instance name: %v\", err)\n+\t}\n \n \tinstanceID := fmt.Sprintf(\"go-sample-test-%s\", uuid.New().String()[:8])\n-\tout := runInstanceSample(t, createInstance, tc.ProjectID, instanceID, \"failed to create an instance\")\n-\tif err := cleanupInstance(tc.ProjectID, instanceID); err != nil {\n+\tout := runInstanceSample(t, createInstance, projectID, instanceID, \"failed to create an instance\")\n+\tif err := cleanupInstance(projectID, instanceID); err != nil {\n \t\tt.Logf(\"cleanupInstance error: %s\", err)\n \t}\n \tassertContains(t, out, fmt.Sprintf(\"Created instance [%s]\", instanceID))\n }\n \n func TestSample(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tdbName, cleanup := initTest(t, tc.ProjectID)\n+\t_ = testutil.SystemTest(t)\n+\tdbName, cleanup := initTest(t, randomID())\n \tdefer cleanup()\n \n \tvar out string",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/e2e-minimal",
        "commit_id": "b9d2026f1fef8407d942bc265d18512e3f9b6ea1"
    },
    {
        "pr_title": "testing(run): add minimal end-to-end tests",
        "pr_number": 1568,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -308,11 +318,12 @@\nfunc TestSample(t *testing.T) {\n }\n \n func TestBackupSample(t *testing.T) {\n-\ttc := testutil.EndToEndTest(t)\n+\t_ = testutil.EndToEndTest(t)\n \n-\tdbName, cleanup := initTest(t, tc.ProjectID)\n+\tid := randomID()\n+\tdbName, cleanup := initTest(t, id)\n \tdefer cleanup()\n-\trestoreDBName, backupID, cancelledBackupID, cleanupBackup := initBackupTest(t, tc.ProjectID, dbName)\n+\trestoreDBName, backupID, cancelledBackupID, cleanupBackup := initBackupTest(t, id, dbName)\n \n \tvar out string\n \t// Set up the database for testing backup operations.",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/e2e-minimal",
        "commit_id": "b9d2026f1fef8407d942bc265d18512e3f9b6ea1"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "datastore/admin/datastore_admin_entities_export.go",
        "code_diff": "@@ -26,13 +26,13 @@\nimport (\n \n // entitiesExport exports a copy of all or a subset of entities from\n // Datastore to another storage system, such as Cloud Storage.\n-func entitiesExport(w io.Writer, projectID, outputURLPrefix string) error {\n+func entitiesExport(w io.Writer, projectID, outputURLPrefix string) (*adminpb.ExportEntitiesResponse, error) {\n \t// projectID := \"project-id\"\n \t// outputURLPrefix := \"gs://bucket-name\"\n \tctx := context.Background()\n \tclient, err := admin.NewDatastoreAdminClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"admin.NewDatastoreAdminClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"admin.NewDatastoreAdminClient: %v\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'master' into mysql-sample-update",
        "commit_id": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "datastore/admin/datastore_admin_test.go",
        "code_diff": "@@ -15,20 +15,27 @@\npackage samples\n \n import (\n+\t\"context\"\n \t\"io/ioutil\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func TestCreate(t *testing.T) {\n+func TestAdmin(t *testing.T) {\n+\t// Roles to be set in your Service Account and App Engine default service account\n+\t// to run this test:\n+\t// `Datastore Import Export Admin`, or `Cloud Datastore Owner`, or `Owner`,\n+\t// `Storage Admin`, or `Owner`.\n+\t// See https://cloud.google.com/datastore/docs/export-import-entities#permissions for full details\n+\ttc := testutil.SystemTest(t)\n+\tctx := context.Background()\n \tclient, err := clientCreate(ioutil.Discard)\n \tif err != nil {\n \t\tt.Fatalf(\"clientCreate: %v\", err)\n \t}\n \tdefer client.Close()\n \n-\ttc := testutil.SystemTest(t)\n \tindices, err := indexList(ioutil.Discard, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"indexList: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into mysql-sample-update",
        "commit_id": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -38,7 +38,7 @@\ntype RenderService struct {\n func (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \treq, err := http.NewRequest(method, s.URL, nil)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"http.NewRequest: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"http.NewRequest: %w\", err)\n \t}\n \n \t// Skip authentication if not using HTTPS, such as for local development.",
        "comments": [],
        "commit_message": "Merge branch 'master' into mysql-sample-update",
        "commit_id": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -50,7 +50,7 @@\nfunc (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \ttokenURL := fmt.Sprintf(\"/instance/service-accounts/default/identity?audience=%s\", s.URL)\n \ttoken, err := metadata.Get(tokenURL)\n \tif err != nil {\n-\t\treturn req, fmt.Errorf(\"metadata.Get: failed to query id_token: %v\", err)\n+\t\treturn req, fmt.Errorf(\"metadata.Get: failed to query id_token: %w\", err)\n \t}\n \n \treq.Header.Add(\"Authorization\", fmt.Sprintf(\"Bearer %s\", token))",
        "comments": [],
        "commit_message": "Merge branch 'master' into mysql-sample-update",
        "commit_id": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -20,6 +20,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"os\"\n+\t\"regexp\"\n+\t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into mysql-sample-update",
        "commit_id": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -37,10 +39,14 @@\ntype sampleFunc func(w io.Writer, dbName string) error\n type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(w io.Writer, dbName, backupID string) error\n \n-func initTest(t *testing.T, projectID string) (dbName string, cleanup func()) {\n+var (\n+\tvalidInstancePattern = regexp.MustCompile(\"^projects/(?P<project>[^/]+)/instances/(?P<instance>[^/]+)$\")\n+)\n+\n+func initTest(t *testing.T, id string) (dbName string, cleanup func()) {\n \tinstance := getInstance(t)\n-\tdatabaseID := validLength(fmt.Sprintf(\"test-%s\", projectID), t)\n-\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, databaseID)\n+\tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n+\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, dbID)\n \n \tctx := context.Background()\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into mysql-sample-update",
        "commit_id": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -66,12 +72,12 @@\nfunc initTest(t *testing.T, projectID string) (dbName string, cleanup func()) {\n \treturn\n }\n \n-func initBackupTest(t *testing.T, projectID, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n+func initBackupTest(t *testing.T, id, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n \tinstance := getInstance(t)\n-\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", projectID), t)\n+\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", id), t)\n \trestoreDBName = fmt.Sprintf(\"%s/databases/%s\", instance, restoreDatabaseID)\n-\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", projectID), t)\n-\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", projectID), t)\n+\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", id), t)\n+\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", id), t)\n \n \tctx := context.Background()\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into mysql-sample-update",
        "commit_id": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -112,20 +118,24 @@\nfunc initBackupTest(t *testing.T, projectID, dbName string) (restoreDBName, back\n }\n \n func TestCreateInstance(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+\t_ = testutil.SystemTest(t)\n+\n+\tprojectID, _, err := parseInstanceName(getInstance(t))\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to parse instance name: %v\", err)\n+\t}\n \n \tinstanceID := fmt.Sprintf(\"go-sample-test-%s\", uuid.New().String()[:8])\n-\tout := runInstanceSample(t, createInstance, tc.ProjectID, instanceID, \"failed to create an instance\")\n-\tif err := cleanupInstance(tc.ProjectID, instanceID); err != nil {\n+\tout := runInstanceSample(t, createInstance, projectID, instanceID, \"failed to create an instance\")\n+\tif err := cleanupInstance(projectID, instanceID); err != nil {\n \t\tt.Logf(\"cleanupInstance error: %s\", err)\n \t}\n \tassertContains(t, out, fmt.Sprintf(\"Created instance [%s]\", instanceID))\n }\n \n func TestSample(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tdbName, cleanup := initTest(t, tc.ProjectID)\n+\t_ = testutil.SystemTest(t)\n+\tdbName, cleanup := initTest(t, randomID())\n \tdefer cleanup()\n \n \tvar out string",
        "comments": [],
        "commit_message": "Merge branch 'master' into mysql-sample-update",
        "commit_id": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -308,11 +318,12 @@\nfunc TestSample(t *testing.T) {\n }\n \n func TestBackupSample(t *testing.T) {\n-\ttc := testutil.EndToEndTest(t)\n+\t_ = testutil.EndToEndTest(t)\n \n-\tdbName, cleanup := initTest(t, tc.ProjectID)\n+\tid := randomID()\n+\tdbName, cleanup := initTest(t, id)\n \tdefer cleanup()\n-\trestoreDBName, backupID, cancelledBackupID, cleanupBackup := initBackupTest(t, tc.ProjectID, dbName)\n+\trestoreDBName, backupID, cancelledBackupID, cleanupBackup := initBackupTest(t, id, dbName)\n \n \tvar out string\n \t// Set up the database for testing backup operations.",
        "comments": [],
        "commit_message": "Merge branch 'master' into mysql-sample-update",
        "commit_id": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "asset: add samples for ListAssets v1p5beta1",
        "pr_number": 1561,
        "file_name": "dataproc/create_cluster_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tdataproc \"cloud.google.com/go/dataproc/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "098da8a5d9446c88196097e112bd9394ae10f3af"
    },
    {
        "pr_title": "asset: add samples for ListAssets v1p5beta1",
        "pr_number": 1561,
        "file_name": "functions/helloworld/hello_pubsub.go",
        "code_diff": "@@ -13,7 +13,6 @@\n// limitations under the License.\n \n // [START functions_helloworld_pubsub]\n-// [START functions_helloworld_background]\n \n // Package helloworld provides a set of Cloud Functions samples.\n package helloworld",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "098da8a5d9446c88196097e112bd9394ae10f3af"
    },
    {
        "pr_title": "asset: add samples for ListAssets v1p5beta1",
        "pr_number": 1561,
        "file_name": "internal/mtls_smoketest/smoketest_test.go",
        "code_diff": "@@ -21,10 +21,13 @@\nimport (\n \t\"time\"\n \n \tbqstorage \"cloud.google.com/go/bigquery/storage/apiv1\"\n+\tgaming \"cloud.google.com/go/gaming/apiv1beta\"\n \tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n \t\"google.golang.org/api/option\"\n \tbqstoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1\"\n+\tgamingpb \"google.golang.org/genproto/googleapis/cloud/gaming/v1beta\"\n )\n \n var shouldFail = os.Getenv(\"GOOGLE_API_USE_MTLS\") == \"always\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "098da8a5d9446c88196097e112bd9394ae10f3af"
    },
    {
        "pr_title": "asset: add samples for ListAssets v1p5beta1",
        "pr_number": 1561,
        "file_name": "internal/mtls_smoketest/smoketest_test.go",
        "code_diff": "@@ -40,10 +43,14 @@\nfunc checkErr(err error, t *testing.T) {\n \t}\n }\n \n-// When this test starts failing, delete it and uncomment the \"testutil.KnownBadMTLS()\" lines in these packages:\n+// When this test starts failing, delete it and the corresponding lines in mtls_smoketest.bash\n+//\n+// functions/imagemagick\n+// functions/ocr/app\n+// run/image-processing/imagemagick\n // vision/detect\n // vision/label\n-// vision/product_search (mtls_smoketest_test.go)\n+// vision/product_search\n func TestVision(t *testing.T) {\n \ttc := testutil.EndToEndTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "098da8a5d9446c88196097e112bd9394ae10f3af"
    },
    {
        "pr_title": "asset: add samples for ListAssets v1p5beta1",
        "pr_number": 1561,
        "file_name": "internal/mtls_smoketest/smoketest_test.go",
        "code_diff": "@@ -71,7 +78,8 @@\nfunc TestVision(t *testing.T) {\n \tcheckErr(err, t)\n }\n \n-// When this test starts failing, delete it and uncomment the \"testutil.KnownBadMTLS()\" lines in these packages:\n+// When this test starts failing, delete it and the corresponding lines in mtls_smoketest.bash\n+//\n // bigquery/bigquery_storage_quickstart\n func TestBigquerystorage(t *testing.T) {\n \ttc := testutil.EndToEndTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "098da8a5d9446c88196097e112bd9394ae10f3af"
    },
    {
        "pr_title": "asset: add samples for ListAssets v1p5beta1",
        "pr_number": 1561,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -456,6 +456,9 @@\nfunc TestPullMsgsDeadLetterDeliveryAttempts(t *testing.T) {\n \t\t\tMaxDeliveryAttempts: 10,\n \t\t},\n \t})\n+\tif err != nil {\n+\t\tt.Fatalf(\"getOrCreateSub: %v\", err)\n+\t}\n \tdefer sub.Delete(ctx)\n \n \tif err = publishMsgs(ctx, deadLetterSourceTopic, 1); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "098da8a5d9446c88196097e112bd9394ae10f3af"
    },
    {
        "pr_title": "asset: add samples for ListAssets v1p5beta1",
        "pr_number": 1561,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -27,7 +27,6 @@\nimport (\n )\n \n func TestDetect(t *testing.T) {\n-\ttestutil.KnownBadMTLS(t)\n \ttestutil.SystemTest(t)\n \n \ttests := []struct {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "098da8a5d9446c88196097e112bd9394ae10f3af"
    },
    {
        "pr_title": "datastore: admin export/import samples",
        "pr_number": 1553,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -30,9 +30,6 @@\nimport (\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"google.golang.org/api/iterator\"\n-\t\"google.golang.org/grpc/codes\"\n-\t\"google.golang.org/grpc/status\"\n )\n \n // TestObjects runs all samples tests of the package.",
        "comments": [],
        "commit_message": "Merge branch 'master' into datastore_admin_export_import",
        "commit_id": "eb2b3d0efbd4336f257b156e6289e631cfe15efa"
    },
    {
        "pr_title": "datastore: admin export/import samples",
        "pr_number": 1553,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -54,8 +51,8 @@\nfunc TestObjects(t *testing.T) {\n \t\troleReader            = storage.RoleReader\n \t)\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n-\tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, dstBucket)\n \n \tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into datastore_admin_export_import",
        "commit_id": "eb2b3d0efbd4336f257b156e6289e631cfe15efa"
    },
    {
        "pr_title": "datastore: admin export/import samples",
        "pr_number": 1553,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -185,18 +182,14 @@\nfunc TestKMSObjects(t *testing.T) {\n \t\tt.Skip(\"GOLANG_SAMPLES_KMS_KEYRING and GOLANG_SAMPLES_KMS_CRYPTOKEY must be set\")\n \t}\n \n-\tvar (\n-\t\tbucket    = tc.ProjectID + \"-samples-object-bucket-1\"\n-\t\tdstBucket = tc.ProjectID + \"-samples-object-bucket-2\"\n-\t\tobject1   = \"foo.txt\"\n-\t)\n+\tbucket := tc.ProjectID + \"-samples-object-bucket-1\"\n+\tobject := \"foo.txt\"\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n-\tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \n-\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object1, kmsKeyName); err != nil {\n+\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object, kmsKeyName); err != nil {\n \t\tt.Errorf(\"uploadWithKMSKey: %v\", err)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into datastore_admin_export_import",
        "commit_id": "eb2b3d0efbd4336f257b156e6289e631cfe15efa"
    },
    {
        "pr_title": "datastore: admin export/import samples",
        "pr_number": 1553,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -214,7 +207,7 @@\nfunc TestV4SignedURL(t *testing.T) {\n \tobjectName := \"foo.txt\"\n \tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tputBuf := new(bytes.Buffer)\n \tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName, serviceAccount)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into datastore_admin_export_import",
        "commit_id": "eb2b3d0efbd4336f257b156e6289e631cfe15efa"
    },
    {
        "pr_title": "datastore: admin export/import samples",
        "pr_number": 1553,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -369,7 +362,7 @@\nfunc TestObjectBucketLock(t *testing.T) {\n \t\tretentionPeriod = 5 * time.Second\n \t)\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tbucket := client.Bucket(bucketName)\n \n \tif err := uploadFile(ioutil.Discard, bucketName, objectName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into datastore_admin_export_import",
        "commit_id": "eb2b3d0efbd4336f257b156e6289e631cfe15efa"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -24,11 +24,12 @@\nimport (\n \t\"cloud.google.com/go/datastore\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n )\n \n const (\n-\ttopicName        = \"dlp-inspect-test-topic\"\n-\tsubscriptionName = \"dlp-inspect-test-sub\"\n+\ttopicName        = \"dlp-inspect-test-topic-\"\n+\tsubscriptionName = \"dlp-inspect-test-sub-\"\n \n \tssnFileName = \"fake_ssn.txt\"\n \tbucketName  = \"golang-samples-dlp-test\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -49,8 +50,9 @@\nfunc TestInspectDatastore(t *testing.T) {\n \tfor _, test := range tests {\n \t\tt.Run(test.kind, func(t *testing.T) {\n \t\t\tt.Parallel()\n+\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n \t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, tc.ProjectID, \"\", test.kind); err != nil {\n+\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, \"\", test.kind); err != nil {\n \t\t\t\tt.Errorf(\"inspectDatastore(%s) got err: %v\", test.kind, err)\n \t\t\t}\n \t\t\tif got := buf.String(); !strings.Contains(got, test.want) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -101,8 +103,9 @@\nfunc TestInspectGCS(t *testing.T) {\n \tfor _, test := range tests {\n \t\tt.Run(test.fileName, func(t *testing.T) {\n \t\t\tt.Parallel()\n+\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n \t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, bucketName, test.fileName); err != nil {\n+\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, bucketName, test.fileName); err != nil {\n \t\t\t\tt.Errorf(\"inspectGCSFile(%s) got err: %v\", test.fileName, err)\n \t\t\t}\n \t\t\tif got := buf.String(); !strings.Contains(got, test.want) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -17,20 +17,27 @@\npackage risk\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n )\n \n const (\n-\triskTopicName        = \"dlp-risk-test-topic\"\n-\triskSubscriptionName = \"dlp-risk-test-sub\"\n+\triskTopicName        = \"dlp-risk-test-topic-\"\n+\triskSubscriptionName = \"dlp-risk-test-sub-\"\n )\n \n func TestRisk(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n+\tclient, err := pubsub.NewClient(context.Background(), tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"pubsub.NewClient: %v\", err)\n+\t}\n \ttests := []struct {\n \t\tname string\n \t\tfn   func(r *testutil.R)",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -39,7 +46,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Numerical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskNumerical got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -53,7 +62,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Categorical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskCategorical got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -67,7 +78,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Anonymity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskKAnonymity got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -81,7 +94,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"L Diversity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskLDiversity got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -95,7 +110,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Map\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n \t\t\t\t\tr.Errorf(\"riskKMap got %s, want substring %q\", got, want)\n \t\t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -30,9 +30,6 @@\nimport (\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"google.golang.org/api/iterator\"\n-\t\"google.golang.org/grpc/codes\"\n-\t\"google.golang.org/grpc/status\"\n )\n \n // TestObjects runs all samples tests of the package.",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -54,8 +51,8 @@\nfunc TestObjects(t *testing.T) {\n \t\troleReader            = storage.RoleReader\n \t)\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n-\tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, dstBucket)\n \n \tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -185,18 +182,14 @@\nfunc TestKMSObjects(t *testing.T) {\n \t\tt.Skip(\"GOLANG_SAMPLES_KMS_KEYRING and GOLANG_SAMPLES_KMS_CRYPTOKEY must be set\")\n \t}\n \n-\tvar (\n-\t\tbucket    = tc.ProjectID + \"-samples-object-bucket-1\"\n-\t\tdstBucket = tc.ProjectID + \"-samples-object-bucket-2\"\n-\t\tobject1   = \"foo.txt\"\n-\t)\n+\tbucket := tc.ProjectID + \"-samples-object-bucket-1\"\n+\tobject := \"foo.txt\"\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n-\tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \n-\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object1, kmsKeyName); err != nil {\n+\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object, kmsKeyName); err != nil {\n \t\tt.Errorf(\"uploadWithKMSKey: %v\", err)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -214,7 +207,7 @@\nfunc TestV4SignedURL(t *testing.T) {\n \tobjectName := \"foo.txt\"\n \tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tputBuf := new(bytes.Buffer)\n \tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName, serviceAccount)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "testing, .github: remove autoformat, move go vet and tidy to Actions",
        "pr_number": 1546,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -369,7 +362,7 @@\nfunc TestObjectBucketLock(t *testing.T) {\n \t\tretentionPeriod = 5 * time.Second\n \t)\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tbucket := client.Bucket(bucketName)\n \n \tif err := uploadFile(ioutil.Discard, bucketName, objectName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into lint",
        "commit_id": "8380d0c98bbcbd2f6b7f05586c318263e6aa60f3"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -28,20 +28,14 @@\nimport (\n \t\"os\"\n \t\"strconv\"\n \n-\t\"github.com/go-sql-driver/mysql\"\n+\t_ \"github.com/go-sql-driver/mysql\"\n )\n \n-// db is the global database connection pool.\n-var db *sql.DB\n-\n-// parsedTemplate is the global parsed HTML template.\n-var parsedTemplate *template.Template\n-\n // vote struct contains a single row from the votes table in the database.\n // Each vote includes a candidate (\"TABS\" or \"SPACES\") and a timestamp.\n type vote struct {\n \tCandidate string\n-\tVoteTime  mysql.NullTime\n+\tVoteTime  sql.NullTime\n }\n \n // voteDiff is used to provide a string representation of the current voting",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -63,38 +57,66 @@\ntype templateData struct {\n \tRecentVotes []vote\n }\n \n-func main() {\n-\tvar err error\n+// app struct contains global state.\n+type app struct {\n+\t// db is the global database connection pool.\n+\tdb *sql.DB\n+\t// tmpl is the parsed HTML template.\n+\ttmpl *template.Template\n+}\n+\n+// indexHandler handles requests to the / route.\n+func (app *app) indexHandler(w http.ResponseWriter, r *http.Request) {\n+\tswitch r.Method {\n+\tcase \"GET\":\n+\t\tif err := showTotals(w, r, app); err != nil {\n+\t\t\tlog.Printf(\"showTotals: %v\", err)\n+\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n+\t\t}\n+\tcase \"POST\":\n+\t\tif err := saveVote(w, r, app); err != nil {\n+\t\t\tlog.Printf(\"saveVote: %v\", err)\n+\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n+\t\t}\n+\tdefault:\n+\t\thttp.Error(w, fmt.Sprintf(\"HTTP Method %s Not Allowed\", r.Method), http.StatusMethodNotAllowed)\n+\t}\n+}\n \n-\tparsedTemplate, err = template.ParseFiles(\"templates/index.html\")\n+func main() {\n+\tparsedTemplate, err := template.ParseFiles(\"templates/index.html\")\n \tif err != nil {\n \t\tlog.Fatalf(\"unable to parse template file: %s\", err)\n \t}\n \n+\tapp := &app{\n+\t\ttmpl: parsedTemplate,\n+\t}\n+\n \t// If the optional DB_TCP_HOST environment variable is set, it contains\n \t// the IP address and port number of a TCP connection pool to be created,\n \t// such as \"127.0.0.1:3306\". If DB_TCP_HOST is not set, a Unix socket\n \t// connection pool will be created instead.\n \tif os.Getenv(\"DB_TCP_HOST\") != \"\" {\n-\t\tdb, err = initTcpConnectionPool()\n+\t\tapp.db, err = initTCPConnectionPool()\n \t\tif err != nil {\n-\t\t\tlog.Fatalf(\"initTcpConnectionPool: unable to connect: %s\", err)\n+\t\t\tlog.Fatalf(\"initTCPConnectionPool: unable to connect: %v\", err)\n \t\t}\n \t} else {\n-\t\tdb, err = initSocketConnectionPool()\n+\t\tapp.db, err = initSocketConnectionPool()\n \t\tif err != nil {\n-\t\t\tlog.Fatalf(\"initSocketConnectionPool: unable to connect: %s\", err)\n+\t\t\tlog.Fatalf(\"initSocketConnectionPool: unable to connect: %v\", err)\n \t\t}\n \t}\n \n \t// Create the votes table if it does not already exist.\n-\tif _, err = db.Exec(`CREATE TABLE IF NOT EXISTS votes\n+\tif _, err = app.db.Exec(`CREATE TABLE IF NOT EXISTS votes\n \t( vote_id SERIAL NOT NULL, time_cast timestamp NOT NULL,\n \tcandidate CHAR(6) NOT NULL, PRIMARY KEY (vote_id) );`); err != nil {\n \t\tlog.Fatalf(\"DB.Exec: unable to create table: %s\", err)\n \t}\n \n-\thttp.HandleFunc(\"/\", indexHandler)\n+\thttp.HandleFunc(\"/\", app.indexHandler)\n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {\n \t\tport = \"8080\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -107,28 +129,10 @@\nfunc main() {\n \n }\n \n-// indexHandler handles requests to the / route.\n-func indexHandler(w http.ResponseWriter, r *http.Request) {\n-\tswitch r.Method {\n-\tcase \"GET\":\n-\t\tif err := showTotals(w, r); err != nil {\n-\t\t\tlog.Printf(\"showTotals: %v\", err)\n-\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n-\t\t}\n-\tcase \"POST\":\n-\t\tif err := saveVote(w, r); err != nil {\n-\t\t\tlog.Printf(\"saveVote: %v\", err)\n-\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n-\t\t}\n-\tdefault:\n-\t\thttp.Error(w, fmt.Sprintf(\"HTTP Method %s Not Allowed\", r.Method), http.StatusMethodNotAllowed)\n-\t}\n-}\n-\n // recentVotes returns a slice of the last 5 votes cast.\n-func recentVotes() ([]vote, error) {\n+func recentVotes(app *app) ([]vote, error) {\n \tvar votes []vote\n-\trows, err := db.Query(`SELECT candidate, time_cast FROM votes ORDER BY time_cast DESC LIMIT 5`)\n+\trows, err := app.db.Query(`SELECT candidate, time_cast FROM votes ORDER BY time_cast DESC LIMIT 5`)\n \tif err != nil {\n \t\treturn votes, fmt.Errorf(\"DB.Query: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -145,60 +149,63 @@\nfunc recentVotes() ([]vote, error) {\n }\n \n // currentTotals returns a templateData structure for populating the web page.\n-func currentTotals() (templateData, error) {\n-\n+func currentTotals(app *app) (*templateData, error) {\n \t// get total votes for each candidate\n \tvar tabVotes, spaceVotes uint\n-\terr := db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='TABS'`).Scan(&tabVotes)\n+\terr := app.db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='TABS'`).Scan(&tabVotes)\n \tif err != nil {\n-\t\treturn templateData{}, fmt.Errorf(\"DB.QueryRow: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}\n-\terr = db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='SPACES'`).Scan(&spaceVotes)\n+\terr = app.db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='SPACES'`).Scan(&spaceVotes)\n \tif err != nil {\n-\t\treturn templateData{}, fmt.Errorf(\"DB.QueryRow: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}\n \n \tvar voteDiffStr string = voteDiff(int(math.Abs(float64(tabVotes) - float64(spaceVotes)))).String()\n \n-\tlatestVotesCast, err := recentVotes()\n+\tlatestVotesCast, err := recentVotes(app)\n \tif err != nil {\n-\t\treturn templateData{}, fmt.Errorf(\"recentVotes: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"recentVotes: %v\", err)\n \t}\n-\treturn templateData{tabVotes, spaceVotes, voteDiffStr, latestVotesCast}, nil\n \n+\tpageData := templateData{\n+\t\tTabsCount:   tabVotes,\n+\t\tSpacesCount: spaceVotes,\n+\t\tVoteMargin:  voteDiffStr,\n+\t\tRecentVotes: latestVotesCast,\n+\t}\n+\n+\treturn &pageData, nil\n }\n \n // showTotals renders an HTML template showing the current vote totals.\n-func showTotals(w http.ResponseWriter, r *http.Request) error {\n-\n-\ttotals, err := currentTotals()\n+func showTotals(w http.ResponseWriter, r *http.Request, app *app) error {\n+\ttotals, err := currentTotals(app)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"currentTotals: %v\", err)\n \t}\n-\terr = parsedTemplate.Execute(w, totals)\n+\terr = app.tmpl.Execute(w, totals)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Template.Execute: %v\", err)\n \t}\n \treturn nil\n }\n \n // saveVote saves a vote passed as http.Request form data.\n-func saveVote(w http.ResponseWriter, r *http.Request) error {\n+func saveVote(w http.ResponseWriter, r *http.Request, app *app) error {\n \tif err := r.ParseForm(); err != nil {\n \t\treturn fmt.Errorf(\"Request.ParseForm: %v\", err)\n \t}\n \n-\tvar team string\n-\tif teamprop, ok := r.Form[\"team\"]; ok {\n-\t\tteam = teamprop[0]\n-\t} else {\n+\tteam := r.FormValue(\"team\")\n+\tif team == \"\" {\n \t\treturn fmt.Errorf(\"team property missing from form submission\")\n \t}\n \n \t// [START cloud_sql_mysql_databasesql_connection]\n-\tsqlInsert := \"INSERT INTO votes (candidate) VALUES (?)\"\n+\tsqlInsert := \"INSERT INTO votes(candidate, time_cast) VALUES(?, NOW())\"\n \tif team == \"TABS\" || team == \"SPACES\" {\n-\t\tif _, err := db.Exec(sqlInsert, team); err != nil {\n+\t\tif _, err := app.db.Exec(sqlInsert, team); err != nil {\n \t\t\tfmt.Fprintf(w, \"unable to save vote: %s\", err)\n \t\t\treturn fmt.Errorf(\"DB.Exec: %v\", err)\n \t\t} else {",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -214,13 +221,13 @@\nfunc saveVote(w http.ResponseWriter, r *http.Request) error {\n func mustGetenv(k string) string {\n \tv := os.Getenv(k)\n \tif v == \"\" {\n-\t\tlog.Printf(\"Warning: %s environment variable not set.\\n\", k)\n+\t\tlog.Fatalf(\"Warning: %s environment variable not set.\\n\", k)\n \t}\n \treturn v\n }\n \n // initSocketConnectionPool initializes a Unix socket connection pool for\n-// a Cloud SQL instance of MySQL.\n+// a Cloud SQL instance of SQL Server.\n func initSocketConnectionPool() (*sql.DB, error) {\n \t// [START cloud_sql_mysql_databasesql_create_socket]\n \tvar (",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -230,8 +237,13 @@\nfunc initSocketConnectionPool() (*sql.DB, error) {\n \t\tdbName                 = mustGetenv(\"DB_NAME\")\n \t)\n \n+\tsocketDir, isSet := os.LookupEnv(\"DB_SOCKET_DIR\")\n+\tif !isSet {\n+\t\tsocketDir = \"/cloudsql\"\n+\t}\n+\n \tvar dbURI string\n-\tdbURI = fmt.Sprintf(\"%s:%s@unix(/cloudsql/%s)/%s\", dbUser, dbPwd, instanceConnectionName, dbName)\n+\tdbURI = fmt.Sprintf(\"%s:%s@unix(/%s/%s)/%s?parseTime=true\", dbUser, dbPwd, socketDir, instanceConnectionName, dbName)\n \n \t// dbPool is the pool of database connections.\n \tdbPool, err := sql.Open(\"mysql\", dbURI)",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "datastore/admin/datastore_admin_entities_export.go",
        "code_diff": "@@ -26,13 +26,13 @@\nimport (\n \n // entitiesExport exports a copy of all or a subset of entities from\n // Datastore to another storage system, such as Cloud Storage.\n-func entitiesExport(w io.Writer, projectID, outputURLPrefix string) error {\n+func entitiesExport(w io.Writer, projectID, outputURLPrefix string) (*adminpb.ExportEntitiesResponse, error) {\n \t// projectID := \"project-id\"\n \t// outputURLPrefix := \"gs://bucket-name\"\n \tctx := context.Background()\n \tclient, err := admin.NewDatastoreAdminClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"admin.NewDatastoreAdminClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"admin.NewDatastoreAdminClient: %v\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "datastore/admin/datastore_admin_test.go",
        "code_diff": "@@ -15,20 +15,27 @@\npackage samples\n \n import (\n+\t\"context\"\n \t\"io/ioutil\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func TestCreate(t *testing.T) {\n+func TestAdmin(t *testing.T) {\n+\t// Roles to be set in your Service Account and App Engine default service account\n+\t// to run this test:\n+\t// `Datastore Import Export Admin`, or `Cloud Datastore Owner`, or `Owner`,\n+\t// `Storage Admin`, or `Owner`.\n+\t// See https://cloud.google.com/datastore/docs/export-import-entities#permissions for full details\n+\ttc := testutil.SystemTest(t)\n+\tctx := context.Background()\n \tclient, err := clientCreate(ioutil.Discard)\n \tif err != nil {\n \t\tt.Fatalf(\"clientCreate: %v\", err)\n \t}\n \tdefer client.Close()\n \n-\ttc := testutil.SystemTest(t)\n \tindices, err := indexList(ioutil.Discard, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"indexList: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -24,11 +24,12 @@\nimport (\n \t\"cloud.google.com/go/datastore\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n )\n \n const (\n-\ttopicName        = \"dlp-inspect-test-topic\"\n-\tsubscriptionName = \"dlp-inspect-test-sub\"\n+\ttopicName        = \"dlp-inspect-test-topic-\"\n+\tsubscriptionName = \"dlp-inspect-test-sub-\"\n \n \tssnFileName = \"fake_ssn.txt\"\n \tbucketName  = \"golang-samples-dlp-test\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -49,8 +50,9 @@\nfunc TestInspectDatastore(t *testing.T) {\n \tfor _, test := range tests {\n \t\tt.Run(test.kind, func(t *testing.T) {\n \t\t\tt.Parallel()\n+\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n \t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, tc.ProjectID, \"\", test.kind); err != nil {\n+\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, \"\", test.kind); err != nil {\n \t\t\t\tt.Errorf(\"inspectDatastore(%s) got err: %v\", test.kind, err)\n \t\t\t}\n \t\t\tif got := buf.String(); !strings.Contains(got, test.want) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -101,8 +103,9 @@\nfunc TestInspectGCS(t *testing.T) {\n \tfor _, test := range tests {\n \t\tt.Run(test.fileName, func(t *testing.T) {\n \t\t\tt.Parallel()\n+\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n \t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, bucketName, test.fileName); err != nil {\n+\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, bucketName, test.fileName); err != nil {\n \t\t\t\tt.Errorf(\"inspectGCSFile(%s) got err: %v\", test.fileName, err)\n \t\t\t}\n \t\t\tif got := buf.String(); !strings.Contains(got, test.want) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -17,20 +17,27 @@\npackage risk\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n )\n \n const (\n-\triskTopicName        = \"dlp-risk-test-topic\"\n-\triskSubscriptionName = \"dlp-risk-test-sub\"\n+\triskTopicName        = \"dlp-risk-test-topic-\"\n+\triskSubscriptionName = \"dlp-risk-test-sub-\"\n )\n \n func TestRisk(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n+\tclient, err := pubsub.NewClient(context.Background(), tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"pubsub.NewClient: %v\", err)\n+\t}\n \ttests := []struct {\n \t\tname string\n \t\tfn   func(r *testutil.R)",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -39,7 +46,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Numerical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskNumerical got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -53,7 +62,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Categorical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskCategorical got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -67,7 +78,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Anonymity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskKAnonymity got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -81,7 +94,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"L Diversity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskLDiversity got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -95,7 +110,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Map\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n \t\t\t\t\tr.Errorf(\"riskKMap got %s, want substring %q\", got, want)\n \t\t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "gaming/servers/doc.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -38,7 +38,7 @@\ntype RenderService struct {\n func (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \treq, err := http.NewRequest(method, s.URL, nil)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"http.NewRequest: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"http.NewRequest: %w\", err)\n \t}\n \n \t// Skip authentication if not using HTTPS, such as for local development.",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -50,7 +50,7 @@\nfunc (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \ttokenURL := fmt.Sprintf(\"/instance/service-accounts/default/identity?audience=%s\", s.URL)\n \ttoken, err := metadata.Get(tokenURL)\n \tif err != nil {\n-\t\treturn req, fmt.Errorf(\"metadata.Get: failed to query id_token: %v\", err)\n+\t\treturn req, fmt.Errorf(\"metadata.Get: failed to query id_token: %w\", err)\n \t}\n \n \treq.Header.Add(\"Authorization\", fmt.Sprintf(\"Bearer %s\", token))",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -20,6 +20,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"os\"\n+\t\"regexp\"\n+\t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -37,10 +39,14 @@\ntype sampleFunc func(w io.Writer, dbName string) error\n type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(w io.Writer, dbName, backupID string) error\n \n-func initTest(t *testing.T, projectID string) (dbName string, cleanup func()) {\n+var (\n+\tvalidInstancePattern = regexp.MustCompile(\"^projects/(?P<project>[^/]+)/instances/(?P<instance>[^/]+)$\")\n+)\n+\n+func initTest(t *testing.T, id string) (dbName string, cleanup func()) {\n \tinstance := getInstance(t)\n-\tdatabaseID := validLength(fmt.Sprintf(\"test-%s\", projectID), t)\n-\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, databaseID)\n+\tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n+\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, dbID)\n \n \tctx := context.Background()\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -66,12 +72,12 @@\nfunc initTest(t *testing.T, projectID string) (dbName string, cleanup func()) {\n \treturn\n }\n \n-func initBackupTest(t *testing.T, projectID, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n+func initBackupTest(t *testing.T, id, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n \tinstance := getInstance(t)\n-\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", projectID), t)\n+\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", id), t)\n \trestoreDBName = fmt.Sprintf(\"%s/databases/%s\", instance, restoreDatabaseID)\n-\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", projectID), t)\n-\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", projectID), t)\n+\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", id), t)\n+\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", id), t)\n \n \tctx := context.Background()\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -112,20 +118,24 @@\nfunc initBackupTest(t *testing.T, projectID, dbName string) (restoreDBName, back\n }\n \n func TestCreateInstance(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+\t_ = testutil.SystemTest(t)\n+\n+\tprojectID, _, err := parseInstanceName(getInstance(t))\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to parse instance name: %v\", err)\n+\t}\n \n \tinstanceID := fmt.Sprintf(\"go-sample-test-%s\", uuid.New().String()[:8])\n-\tout := runInstanceSample(t, createInstance, tc.ProjectID, instanceID, \"failed to create an instance\")\n-\tif err := cleanupInstance(tc.ProjectID, instanceID); err != nil {\n+\tout := runInstanceSample(t, createInstance, projectID, instanceID, \"failed to create an instance\")\n+\tif err := cleanupInstance(projectID, instanceID); err != nil {\n \t\tt.Logf(\"cleanupInstance error: %s\", err)\n \t}\n \tassertContains(t, out, fmt.Sprintf(\"Created instance [%s]\", instanceID))\n }\n \n func TestSample(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tdbName, cleanup := initTest(t, tc.ProjectID)\n+\t_ = testutil.SystemTest(t)\n+\tdbName, cleanup := initTest(t, randomID())\n \tdefer cleanup()\n \n \tvar out string",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -308,11 +318,12 @@\nfunc TestSample(t *testing.T) {\n }\n \n func TestBackupSample(t *testing.T) {\n-\ttc := testutil.EndToEndTest(t)\n+\t_ = testutil.EndToEndTest(t)\n \n-\tdbName, cleanup := initTest(t, tc.ProjectID)\n+\tid := randomID()\n+\tdbName, cleanup := initTest(t, id)\n \tdefer cleanup()\n-\trestoreDBName, backupID, cancelledBackupID, cleanupBackup := initBackupTest(t, tc.ProjectID, dbName)\n+\trestoreDBName, backupID, cancelledBackupID, cleanupBackup := initBackupTest(t, id, dbName)\n \n \tvar out string\n \t// Set up the database for testing backup operations.",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -30,9 +30,6 @@\nimport (\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"google.golang.org/api/iterator\"\n-\t\"google.golang.org/grpc/codes\"\n-\t\"google.golang.org/grpc/status\"\n )\n \n // TestObjects runs all samples tests of the package.",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -54,8 +51,8 @@\nfunc TestObjects(t *testing.T) {\n \t\troleReader            = storage.RoleReader\n \t)\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n-\tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, dstBucket)\n \n \tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -185,20 +182,18 @@\nfunc TestKMSObjects(t *testing.T) {\n \t\tt.Skip(\"GOLANG_SAMPLES_KMS_KEYRING and GOLANG_SAMPLES_KMS_CRYPTOKEY must be set\")\n \t}\n \n-\tvar (\n-\t\tbucket    = tc.ProjectID + \"-samples-object-bucket-1\"\n-\t\tdstBucket = tc.ProjectID + \"-samples-object-bucket-2\"\n-\t\tobject1   = \"foo.txt\"\n-\t)\n+\tbucket := tc.ProjectID + \"-samples-object-bucket-1\"\n+\tobject := \"foo.txt\"\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n-\tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \n-\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object1, kmsKeyName); err != nil {\n-\t\tt.Errorf(\"uploadWithKMSKey: %v\", err)\n-\t}\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object, kmsKeyName); err != nil {\n+\t\t\tr.Errorf(\"uploadWithKMSKey: %v\", err)\n+\t\t}\n+\t})\n }\n \n func TestV4SignedURL(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -214,7 +209,7 @@\nfunc TestV4SignedURL(t *testing.T) {\n \tobjectName := \"foo.txt\"\n \tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tputBuf := new(bytes.Buffer)\n \tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName, serviceAccount)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "profiler: add WithTelemetryDisabled for OpenCensus users",
        "pr_number": 1543,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -369,7 +364,7 @@\nfunc TestObjectBucketLock(t *testing.T) {\n \t\tretentionPeriod = 5 * time.Second\n \t)\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tbucket := client.Bucket(bucketName)\n \n \tif err := uploadFile(ioutil.Discard, bucketName, objectName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into profiler",
        "commit_id": "a73d9309447926b6de50447f9189da69245c5b64"
    },
    {
        "pr_title": "memorystore: add Dockerfile for Cloud Run deployment",
        "pr_number": 1538,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -28,20 +28,14 @@\nimport (\n \t\"os\"\n \t\"strconv\"\n \n-\t\"github.com/go-sql-driver/mysql\"\n+\t_ \"github.com/go-sql-driver/mysql\"\n )\n \n-// db is the global database connection pool.\n-var db *sql.DB\n-\n-// parsedTemplate is the global parsed HTML template.\n-var parsedTemplate *template.Template\n-\n // vote struct contains a single row from the votes table in the database.\n // Each vote includes a candidate (\"TABS\" or \"SPACES\") and a timestamp.\n type vote struct {\n \tCandidate string\n-\tVoteTime  mysql.NullTime\n+\tVoteTime  sql.NullTime\n }\n \n // voteDiff is used to provide a string representation of the current voting",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "de643bdd241fe8d60039d3e55c1d7c956550028f"
    },
    {
        "pr_title": "memorystore: add Dockerfile for Cloud Run deployment",
        "pr_number": 1538,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -63,38 +57,66 @@\ntype templateData struct {\n \tRecentVotes []vote\n }\n \n-func main() {\n-\tvar err error\n+// app struct contains global state.\n+type app struct {\n+\t// db is the global database connection pool.\n+\tdb *sql.DB\n+\t// tmpl is the parsed HTML template.\n+\ttmpl *template.Template\n+}\n+\n+// indexHandler handles requests to the / route.\n+func (app *app) indexHandler(w http.ResponseWriter, r *http.Request) {\n+\tswitch r.Method {\n+\tcase \"GET\":\n+\t\tif err := showTotals(w, r, app); err != nil {\n+\t\t\tlog.Printf(\"showTotals: %v\", err)\n+\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n+\t\t}\n+\tcase \"POST\":\n+\t\tif err := saveVote(w, r, app); err != nil {\n+\t\t\tlog.Printf(\"saveVote: %v\", err)\n+\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n+\t\t}\n+\tdefault:\n+\t\thttp.Error(w, fmt.Sprintf(\"HTTP Method %s Not Allowed\", r.Method), http.StatusMethodNotAllowed)\n+\t}\n+}\n \n-\tparsedTemplate, err = template.ParseFiles(\"templates/index.html\")\n+func main() {\n+\tparsedTemplate, err := template.ParseFiles(\"templates/index.html\")\n \tif err != nil {\n \t\tlog.Fatalf(\"unable to parse template file: %s\", err)\n \t}\n \n+\tapp := &app{\n+\t\ttmpl: parsedTemplate,\n+\t}\n+\n \t// If the optional DB_TCP_HOST environment variable is set, it contains\n \t// the IP address and port number of a TCP connection pool to be created,\n \t// such as \"127.0.0.1:3306\". If DB_TCP_HOST is not set, a Unix socket\n \t// connection pool will be created instead.\n \tif os.Getenv(\"DB_TCP_HOST\") != \"\" {\n-\t\tdb, err = initTcpConnectionPool()\n+\t\tapp.db, err = initTCPConnectionPool()\n \t\tif err != nil {\n-\t\t\tlog.Fatalf(\"initTcpConnectionPool: unable to connect: %s\", err)\n+\t\t\tlog.Fatalf(\"initTCPConnectionPool: unable to connect: %v\", err)\n \t\t}\n \t} else {\n-\t\tdb, err = initSocketConnectionPool()\n+\t\tapp.db, err = initSocketConnectionPool()\n \t\tif err != nil {\n-\t\t\tlog.Fatalf(\"initSocketConnectionPool: unable to connect: %s\", err)\n+\t\t\tlog.Fatalf(\"initSocketConnectionPool: unable to connect: %v\", err)\n \t\t}\n \t}\n \n \t// Create the votes table if it does not already exist.\n-\tif _, err = db.Exec(`CREATE TABLE IF NOT EXISTS votes\n+\tif _, err = app.db.Exec(`CREATE TABLE IF NOT EXISTS votes\n \t( vote_id SERIAL NOT NULL, time_cast timestamp NOT NULL,\n \tcandidate CHAR(6) NOT NULL, PRIMARY KEY (vote_id) );`); err != nil {\n \t\tlog.Fatalf(\"DB.Exec: unable to create table: %s\", err)\n \t}\n \n-\thttp.HandleFunc(\"/\", indexHandler)\n+\thttp.HandleFunc(\"/\", app.indexHandler)\n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {\n \t\tport = \"8080\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "de643bdd241fe8d60039d3e55c1d7c956550028f"
    },
    {
        "pr_title": "memorystore: add Dockerfile for Cloud Run deployment",
        "pr_number": 1538,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -107,28 +129,10 @@\nfunc main() {\n \n }\n \n-// indexHandler handles requests to the / route.\n-func indexHandler(w http.ResponseWriter, r *http.Request) {\n-\tswitch r.Method {\n-\tcase \"GET\":\n-\t\tif err := showTotals(w, r); err != nil {\n-\t\t\tlog.Printf(\"showTotals: %v\", err)\n-\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n-\t\t}\n-\tcase \"POST\":\n-\t\tif err := saveVote(w, r); err != nil {\n-\t\t\tlog.Printf(\"saveVote: %v\", err)\n-\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n-\t\t}\n-\tdefault:\n-\t\thttp.Error(w, fmt.Sprintf(\"HTTP Method %s Not Allowed\", r.Method), http.StatusMethodNotAllowed)\n-\t}\n-}\n-\n // recentVotes returns a slice of the last 5 votes cast.\n-func recentVotes() ([]vote, error) {\n+func recentVotes(app *app) ([]vote, error) {\n \tvar votes []vote\n-\trows, err := db.Query(`SELECT candidate, time_cast FROM votes ORDER BY time_cast DESC LIMIT 5`)\n+\trows, err := app.db.Query(`SELECT candidate, time_cast FROM votes ORDER BY time_cast DESC LIMIT 5`)\n \tif err != nil {\n \t\treturn votes, fmt.Errorf(\"DB.Query: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "de643bdd241fe8d60039d3e55c1d7c956550028f"
    },
    {
        "pr_title": "memorystore: add Dockerfile for Cloud Run deployment",
        "pr_number": 1538,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -145,60 +149,63 @@\nfunc recentVotes() ([]vote, error) {\n }\n \n // currentTotals returns a templateData structure for populating the web page.\n-func currentTotals() (templateData, error) {\n-\n+func currentTotals(app *app) (*templateData, error) {\n \t// get total votes for each candidate\n \tvar tabVotes, spaceVotes uint\n-\terr := db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='TABS'`).Scan(&tabVotes)\n+\terr := app.db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='TABS'`).Scan(&tabVotes)\n \tif err != nil {\n-\t\treturn templateData{}, fmt.Errorf(\"DB.QueryRow: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}\n-\terr = db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='SPACES'`).Scan(&spaceVotes)\n+\terr = app.db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='SPACES'`).Scan(&spaceVotes)\n \tif err != nil {\n-\t\treturn templateData{}, fmt.Errorf(\"DB.QueryRow: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}\n \n \tvar voteDiffStr string = voteDiff(int(math.Abs(float64(tabVotes) - float64(spaceVotes)))).String()\n \n-\tlatestVotesCast, err := recentVotes()\n+\tlatestVotesCast, err := recentVotes(app)\n \tif err != nil {\n-\t\treturn templateData{}, fmt.Errorf(\"recentVotes: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"recentVotes: %v\", err)\n \t}\n-\treturn templateData{tabVotes, spaceVotes, voteDiffStr, latestVotesCast}, nil\n \n+\tpageData := templateData{\n+\t\tTabsCount:   tabVotes,\n+\t\tSpacesCount: spaceVotes,\n+\t\tVoteMargin:  voteDiffStr,\n+\t\tRecentVotes: latestVotesCast,\n+\t}\n+\n+\treturn &pageData, nil\n }\n \n // showTotals renders an HTML template showing the current vote totals.\n-func showTotals(w http.ResponseWriter, r *http.Request) error {\n-\n-\ttotals, err := currentTotals()\n+func showTotals(w http.ResponseWriter, r *http.Request, app *app) error {\n+\ttotals, err := currentTotals(app)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"currentTotals: %v\", err)\n \t}\n-\terr = parsedTemplate.Execute(w, totals)\n+\terr = app.tmpl.Execute(w, totals)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Template.Execute: %v\", err)\n \t}\n \treturn nil\n }\n \n // saveVote saves a vote passed as http.Request form data.\n-func saveVote(w http.ResponseWriter, r *http.Request) error {\n+func saveVote(w http.ResponseWriter, r *http.Request, app *app) error {\n \tif err := r.ParseForm(); err != nil {\n \t\treturn fmt.Errorf(\"Request.ParseForm: %v\", err)\n \t}\n \n-\tvar team string\n-\tif teamprop, ok := r.Form[\"team\"]; ok {\n-\t\tteam = teamprop[0]\n-\t} else {\n+\tteam := r.FormValue(\"team\")\n+\tif team == \"\" {\n \t\treturn fmt.Errorf(\"team property missing from form submission\")\n \t}\n \n \t// [START cloud_sql_mysql_databasesql_connection]\n-\tsqlInsert := \"INSERT INTO votes (candidate) VALUES (?)\"\n+\tsqlInsert := \"INSERT INTO votes(candidate, time_cast) VALUES(?, NOW())\"\n \tif team == \"TABS\" || team == \"SPACES\" {\n-\t\tif _, err := db.Exec(sqlInsert, team); err != nil {\n+\t\tif _, err := app.db.Exec(sqlInsert, team); err != nil {\n \t\t\tfmt.Fprintf(w, \"unable to save vote: %s\", err)\n \t\t\treturn fmt.Errorf(\"DB.Exec: %v\", err)\n \t\t} else {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "de643bdd241fe8d60039d3e55c1d7c956550028f"
    },
    {
        "pr_title": "memorystore: add Dockerfile for Cloud Run deployment",
        "pr_number": 1538,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -214,13 +221,13 @@\nfunc saveVote(w http.ResponseWriter, r *http.Request) error {\n func mustGetenv(k string) string {\n \tv := os.Getenv(k)\n \tif v == \"\" {\n-\t\tlog.Printf(\"Warning: %s environment variable not set.\\n\", k)\n+\t\tlog.Fatalf(\"Warning: %s environment variable not set.\\n\", k)\n \t}\n \treturn v\n }\n \n // initSocketConnectionPool initializes a Unix socket connection pool for\n-// a Cloud SQL instance of MySQL.\n+// a Cloud SQL instance of SQL Server.\n func initSocketConnectionPool() (*sql.DB, error) {\n \t// [START cloud_sql_mysql_databasesql_create_socket]\n \tvar (",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "de643bdd241fe8d60039d3e55c1d7c956550028f"
    },
    {
        "pr_title": "memorystore: add Dockerfile for Cloud Run deployment",
        "pr_number": 1538,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -230,8 +237,13 @@\nfunc initSocketConnectionPool() (*sql.DB, error) {\n \t\tdbName                 = mustGetenv(\"DB_NAME\")\n \t)\n \n+\tsocketDir, isSet := os.LookupEnv(\"DB_SOCKET_DIR\")\n+\tif !isSet {\n+\t\tsocketDir = \"/cloudsql\"\n+\t}\n+\n \tvar dbURI string\n-\tdbURI = fmt.Sprintf(\"%s:%s@unix(/cloudsql/%s)/%s\", dbUser, dbPwd, instanceConnectionName, dbName)\n+\tdbURI = fmt.Sprintf(\"%s:%s@unix(/%s/%s)/%s?parseTime=true\", dbUser, dbPwd, socketDir, instanceConnectionName, dbName)\n \n \t// dbPool is the pool of database connections.\n \tdbPool, err := sql.Open(\"mysql\", dbURI)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "de643bdd241fe8d60039d3e55c1d7c956550028f"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -24,11 +24,12 @@\nimport (\n \t\"cloud.google.com/go/datastore\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n )\n \n const (\n-\ttopicName        = \"dlp-inspect-test-topic\"\n-\tsubscriptionName = \"dlp-inspect-test-sub\"\n+\ttopicName        = \"dlp-inspect-test-topic-\"\n+\tsubscriptionName = \"dlp-inspect-test-sub-\"\n \n \tssnFileName = \"fake_ssn.txt\"\n \tbucketName  = \"golang-samples-dlp-test\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -49,8 +50,9 @@\nfunc TestInspectDatastore(t *testing.T) {\n \tfor _, test := range tests {\n \t\tt.Run(test.kind, func(t *testing.T) {\n \t\t\tt.Parallel()\n+\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n \t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, tc.ProjectID, \"\", test.kind); err != nil {\n+\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, \"\", test.kind); err != nil {\n \t\t\t\tt.Errorf(\"inspectDatastore(%s) got err: %v\", test.kind, err)\n \t\t\t}\n \t\t\tif got := buf.String(); !strings.Contains(got, test.want) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -101,8 +103,9 @@\nfunc TestInspectGCS(t *testing.T) {\n \tfor _, test := range tests {\n \t\tt.Run(test.fileName, func(t *testing.T) {\n \t\t\tt.Parallel()\n+\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n \t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, bucketName, test.fileName); err != nil {\n+\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, bucketName, test.fileName); err != nil {\n \t\t\t\tt.Errorf(\"inspectGCSFile(%s) got err: %v\", test.fileName, err)\n \t\t\t}\n \t\t\tif got := buf.String(); !strings.Contains(got, test.want) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -17,20 +17,27 @@\npackage risk\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n )\n \n const (\n-\triskTopicName        = \"dlp-risk-test-topic\"\n-\triskSubscriptionName = \"dlp-risk-test-sub\"\n+\triskTopicName        = \"dlp-risk-test-topic-\"\n+\triskSubscriptionName = \"dlp-risk-test-sub-\"\n )\n \n func TestRisk(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n+\tclient, err := pubsub.NewClient(context.Background(), tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"pubsub.NewClient: %v\", err)\n+\t}\n \ttests := []struct {\n \t\tname string\n \t\tfn   func(r *testutil.R)",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -39,7 +46,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Numerical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskNumerical got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -53,7 +62,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Categorical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskCategorical got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -67,7 +78,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Anonymity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskKAnonymity got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -81,7 +94,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"L Diversity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskLDiversity got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -95,7 +110,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Map\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n \t\t\t\t\tr.Errorf(\"riskKMap got %s, want substring %q\", got, want)\n \t\t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "internal/gomodversiontest/main.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -30,9 +30,6 @@\nimport (\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"google.golang.org/api/iterator\"\n-\t\"google.golang.org/grpc/codes\"\n-\t\"google.golang.org/grpc/status\"\n )\n \n // TestObjects runs all samples tests of the package.",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -54,8 +51,8 @@\nfunc TestObjects(t *testing.T) {\n \t\troleReader            = storage.RoleReader\n \t)\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n-\tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, dstBucket)\n \n \tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -185,18 +182,14 @@\nfunc TestKMSObjects(t *testing.T) {\n \t\tt.Skip(\"GOLANG_SAMPLES_KMS_KEYRING and GOLANG_SAMPLES_KMS_CRYPTOKEY must be set\")\n \t}\n \n-\tvar (\n-\t\tbucket    = tc.ProjectID + \"-samples-object-bucket-1\"\n-\t\tdstBucket = tc.ProjectID + \"-samples-object-bucket-2\"\n-\t\tobject1   = \"foo.txt\"\n-\t)\n+\tbucket := tc.ProjectID + \"-samples-object-bucket-1\"\n+\tobject := \"foo.txt\"\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n-\tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \n-\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object1, kmsKeyName); err != nil {\n+\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object, kmsKeyName); err != nil {\n \t\tt.Errorf(\"uploadWithKMSKey: %v\", err)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -214,7 +207,7 @@\nfunc TestV4SignedURL(t *testing.T) {\n \tobjectName := \"foo.txt\"\n \tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tputBuf := new(bytes.Buffer)\n \tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName, serviceAccount)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "feat: add run_events_pubsub",
        "pr_number": 1524,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -369,7 +362,7 @@\nfunc TestObjectBucketLock(t *testing.T) {\n \t\tretentionPeriod = 5 * time.Second\n \t)\n \n-\tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tbucket := client.Bucket(bucketName)\n \n \tif err := uploadFile(ioutil.Discard, bucketName, objectName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into grant_run_events_pubsub",
        "commit_id": "4d7efdf5fb192637b6e240420eaeeec4beef54b5"
    },
    {
        "pr_title": "asset: add samples for SearchAllResources and SearchAllIamPolicies",
        "pr_number": 1505,
        "file_name": "vision/product_search/remove_product_from_product_set_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\nimport (\n \t\"bytes\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:yuyifan-google/golang-samples",
        "commit_id": "3a5b7e133f20d945c2b88c05138481d37ccc7f1c"
    },
    {
        "pr_title": "storage: disable bucket lifecycle management",
        "pr_number": 1500,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -24,11 +24,12 @@\nimport (\n \t\"cloud.google.com/go/datastore\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n )\n \n const (\n-\ttopicName        = \"dlp-inspect-test-topic\"\n-\tsubscriptionName = \"dlp-inspect-test-sub\"\n+\ttopicName        = \"dlp-inspect-test-topic-\"\n+\tsubscriptionName = \"dlp-inspect-test-sub-\"\n \n \tssnFileName = \"fake_ssn.txt\"\n \tbucketName  = \"golang-samples-dlp-test\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into gcs-olm2",
        "commit_id": "8512dca243fbfbdd2026b5914e5e15f77de5e5fc"
    },
    {
        "pr_title": "storage: disable bucket lifecycle management",
        "pr_number": 1500,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -49,8 +50,9 @@\nfunc TestInspectDatastore(t *testing.T) {\n \tfor _, test := range tests {\n \t\tt.Run(test.kind, func(t *testing.T) {\n \t\t\tt.Parallel()\n+\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n \t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, tc.ProjectID, \"\", test.kind); err != nil {\n+\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, \"\", test.kind); err != nil {\n \t\t\t\tt.Errorf(\"inspectDatastore(%s) got err: %v\", test.kind, err)\n \t\t\t}\n \t\t\tif got := buf.String(); !strings.Contains(got, test.want) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into gcs-olm2",
        "commit_id": "8512dca243fbfbdd2026b5914e5e15f77de5e5fc"
    },
    {
        "pr_title": "storage: disable bucket lifecycle management",
        "pr_number": 1500,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -101,8 +103,9 @@\nfunc TestInspectGCS(t *testing.T) {\n \tfor _, test := range tests {\n \t\tt.Run(test.fileName, func(t *testing.T) {\n \t\t\tt.Parallel()\n+\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n \t\t\tbuf := new(bytes.Buffer)\n-\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, bucketName, test.fileName); err != nil {\n+\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, bucketName, test.fileName); err != nil {\n \t\t\t\tt.Errorf(\"inspectGCSFile(%s) got err: %v\", test.fileName, err)\n \t\t\t}\n \t\t\tif got := buf.String(); !strings.Contains(got, test.want) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into gcs-olm2",
        "commit_id": "8512dca243fbfbdd2026b5914e5e15f77de5e5fc"
    },
    {
        "pr_title": "storage: disable bucket lifecycle management",
        "pr_number": 1500,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -17,20 +17,27 @@\npackage risk\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n )\n \n const (\n-\triskTopicName        = \"dlp-risk-test-topic\"\n-\triskSubscriptionName = \"dlp-risk-test-sub\"\n+\triskTopicName        = \"dlp-risk-test-topic-\"\n+\triskSubscriptionName = \"dlp-risk-test-sub-\"\n )\n \n func TestRisk(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n+\tclient, err := pubsub.NewClient(context.Background(), tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"pubsub.NewClient: %v\", err)\n+\t}\n \ttests := []struct {\n \t\tname string\n \t\tfn   func(r *testutil.R)",
        "comments": [],
        "commit_message": "Merge branch 'master' into gcs-olm2",
        "commit_id": "8512dca243fbfbdd2026b5914e5e15f77de5e5fc"
    },
    {
        "pr_title": "storage: disable bucket lifecycle management",
        "pr_number": 1500,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -39,7 +46,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Numerical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskNumerical got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into gcs-olm2",
        "commit_id": "8512dca243fbfbdd2026b5914e5e15f77de5e5fc"
    },
    {
        "pr_title": "storage: disable bucket lifecycle management",
        "pr_number": 1500,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -53,7 +62,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Categorical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskCategorical got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into gcs-olm2",
        "commit_id": "8512dca243fbfbdd2026b5914e5e15f77de5e5fc"
    },
    {
        "pr_title": "storage: disable bucket lifecycle management",
        "pr_number": 1500,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -67,7 +78,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Anonymity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskKAnonymity got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into gcs-olm2",
        "commit_id": "8512dca243fbfbdd2026b5914e5e15f77de5e5fc"
    },
    {
        "pr_title": "storage: disable bucket lifecycle management",
        "pr_number": 1500,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -81,7 +94,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"L Diversity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {\n \t\t\t\t\tr.Errorf(\"riskLDiversity got err: %v\", err)\n \t\t\t\t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into gcs-olm2",
        "commit_id": "8512dca243fbfbdd2026b5914e5e15f77de5e5fc"
    },
    {
        "pr_title": "storage: disable bucket lifecycle management",
        "pr_number": 1500,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -95,7 +110,9 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Map\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n+\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n+\t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n \t\t\t\t\tr.Errorf(\"riskKMap got %s, want substring %q\", got, want)\n \t\t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into gcs-olm2",
        "commit_id": "8512dca243fbfbdd2026b5914e5e15f77de5e5fc"
    },
    {
        "pr_title": "monitoring: demonstrate creation of a POST uptime check to go along with the GET uptime check",
        "pr_number": 1499,
        "file_name": "pubsub/subscriptions/sync_pull.go",
        "code_diff": "@@ -51,16 +51,12 @@\nfunc pullMsgsSync(w io.Writer, projectID, subID string) error {\n \n \t// Create a channel to handle messages to as they come in.\n \tcm := make(chan *pubsub.Message)\n+\tdefer close(cm)\n \t// Handle individual messages in a goroutine.\n \tgo func() {\n-\t\tfor {\n-\t\t\tselect {\n-\t\t\tcase msg := <-cm:\n-\t\t\t\tfmt.Fprintf(w, \"Got message :%q\\n\", string(msg.Data))\n-\t\t\t\tmsg.Ack()\n-\t\t\tcase <-ctx.Done():\n-\t\t\t\treturn\n-\t\t\t}\n+\t\tfor msg := range cm {\n+\t\t\tfmt.Fprintf(w, \"Got message :%q\\n\", string(msg.Data))\n+\t\t\tmsg.Ack()\n \t\t}\n \t}()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "3b151248e58ad686c6ef99c1818c9a3b82d4d2ab"
    },
    {
        "pr_title": "spanner: add spanner_create_instance sample.",
        "pr_number": 1490,
        "file_name": "spanner/spanner_snippets/spanner/spanner_read_stale_data.go",
        "code_diff": "@@ -14,6 +14,8 @@\npackage spanner\n \n+// [START spanner_read_stale_data]\n+\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-create-instance",
        "commit_id": "4f685c393d9f2a2363f40875567470e7b6ab0d7e"
    },
    {
        "pr_title": "spanner: add spanner_create_instance sample.",
        "pr_number": 1490,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -16,13 +16,16 @@\npackage buckets\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"os\"\n+\t\"reflect\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-create-instance",
        "commit_id": "4f685c393d9f2a2363f40875567470e7b6ab0d7e"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -26,7 +26,8 @@\nimport (\n // firestoreDB persists books to Cloud Firestore.\n // See https://cloud.google.com/firestore/docs.\n type firestoreDB struct {\n-\tclient *firestore.Client\n+\tclient     *firestore.Client\n+\tcollection string\n }\n \n // Ensure firestoreDB conforms to the BookDatabase interface.",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -48,7 +49,8 @@\nfunc newFirestoreDB(client *firestore.Client) (*firestoreDB, error) {\n \t\treturn nil, fmt.Errorf(\"firestoredb: could not connect: %v\", err)\n \t}\n \treturn &firestoreDB{\n-\t\tclient: client,\n+\t\tclient:     client,\n+\t\tcollection: \"books\",\n \t}, nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -59,7 +61,7 @@\nfunc (db *firestoreDB) Close(context.Context) error {\n \n // Book retrieves a book by its ID.\n func (db *firestoreDB) GetBook(ctx context.Context, id string) (*Book, error) {\n-\tds, err := db.client.Collection(\"books\").Doc(id).Get(ctx)\n+\tds, err := db.client.Collection(db.collection).Doc(id).Get(ctx)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"firestoredb: Get: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -72,7 +74,7 @@\nfunc (db *firestoreDB) GetBook(ctx context.Context, id string) (*Book, error) {\n \n // AddBook saves a given book, assigning it a new ID.\n func (db *firestoreDB) AddBook(ctx context.Context, b *Book) (id string, err error) {\n-\tref := db.client.Collection(\"books\").NewDoc()\n+\tref := db.client.Collection(db.collection).NewDoc()\n \tb.ID = ref.ID\n \tif _, err := ref.Create(ctx, b); err != nil {\n \t\treturn \"\", fmt.Errorf(\"Create: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -82,15 +84,15 @@\nfunc (db *firestoreDB) AddBook(ctx context.Context, b *Book) (id string, err err\n \n // DeleteBook removes a given book by its ID.\n func (db *firestoreDB) DeleteBook(ctx context.Context, id string) error {\n-\tif _, err := db.client.Collection(\"books\").Doc(id).Delete(ctx); err != nil {\n+\tif _, err := db.client.Collection(db.collection).Doc(id).Delete(ctx); err != nil {\n \t\treturn fmt.Errorf(\"firestore: Delete: %v\", err)\n \t}\n \treturn nil\n }\n \n // UpdateBook updates the entry for a given book.\n func (db *firestoreDB) UpdateBook(ctx context.Context, b *Book) error {\n-\tif _, err := db.client.Collection(\"books\").Doc(b.ID).Set(ctx, b); err != nil {\n+\tif _, err := db.client.Collection(db.collection).Doc(b.ID).Set(ctx, b); err != nil {\n \t\treturn fmt.Errorf(\"firestsore: Set: %v\", err)\n \t}\n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "getting-started/bookshelf/db_test.go",
        "code_diff": "@@ -68,6 +68,10 @@\nfunc TestMemoryDB(t *testing.T) {\n }\n \n func TestFirestoreDB(t *testing.T) {\n+\tgeneralProjectID := os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")\n+\tif generalProjectID == \"\" {\n+\t\tt.Skip(\"GOLANG_SAMPLES_PROJECT_ID not set\")\n+\t}\n \tprojectID := os.Getenv(\"GOLANG_SAMPLES_FIRESTORE_PROJECT\")\n \tif projectID == \"\" {\n \t\tt.Skip(\"GOLANG_SAMPLES_FIRESTORE_PROJECT not set\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "getting-started/bookshelf/main_test.go",
        "code_diff": "@@ -40,11 +40,12 @@\nvar (\n func TestMain(m *testing.M) {\n \tctx := context.Background()\n \n-\tprojectID := os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")\n-\tif projectID == \"\" {\n+\tgeneralProjectID := os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")\n+\tif generalProjectID == \"\" {\n \t\tlog.Println(\"GOLANG_SAMPLES_PROJECT_ID not set. Skipping.\")\n \t\treturn\n \t}\n+\tprojectID := generalProjectID\n \n \tmemoryDB := newMemoryDB()\n \ttestDBs[\"memory\"] = memoryDB",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "getting-started/bookshelf/main_test.go",
        "code_diff": "@@ -57,8 +58,9 @@\nfunc TestMain(m *testing.M) {\n \t\t\tlog.Fatalf(\"firestore.NewClient: %v\", err)\n \t\t}\n \n+\t\tcollection := generalProjectID + \"-main-books\"\n \t\t// Delete all docs first to start with a clean slate.\n-\t\tdocs, err := client.Collection(\"books\").DocumentRefs(ctx).GetAll()\n+\t\tdocs, err := client.Collection(collection).DocumentRefs(ctx).GetAll()\n \t\tif err == nil {\n \t\t\tfor _, d := range docs {\n \t\t\t\tif _, err := d.Delete(ctx); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -12,60 +12,45 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package spanner\n \n import (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n+\t\"io\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n-\t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"google.golang.org/api/iterator\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n-type runCommandFunc func(t *testing.T, cmd, dbName string) string\n-type runBackupCommandFunc func(t *testing.T, cmd, dbName, backupID string) string\n+type sampleFunc func(w io.Writer, dbName string) error\n+type backupSampleFunc func(w io.Writer, dbName, backupID string) error\n \n-func initTest(t *testing.T, projectID string) (dbName string, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, runCommand runCommandFunc, mustRunCommand runCommandFunc, cleanup func()) {\n+func initTest(t *testing.T, projectID string) (dbName string, cleanup func()) {\n \tinstance := getInstance(t)\n \tdatabaseID := validLength(fmt.Sprintf(\"test-%s\", projectID), t)\n \tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, databaseID)\n \n \tctx := context.Background()\n-\tadminClient, dataClient = createClients(ctx, dbName)\n+\tadminClient, err := database.NewDatabaseAdminClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create DB admin client: %v\", err)\n+\t}\n \n-\t// Check for database existance prior to test start and delete, as resources may not have\n-\t// been cleaned up from previous invocations.\n+\t// Check for database existance prior to test start and delete, as resources\n+\t// may not have been cleaned up from previous invocations.\n \tif db, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: dbName}); err == nil {\n \t\tt.Logf(\"database %s exists in state %s. delete result: %v\", db.GetName(), db.GetState().String(),\n \t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName}))\n \t}\n-\n-\trunCommand = func(t *testing.T, cmd, dbName string) string {\n-\t\tt.Helper()\n-\t\tvar b bytes.Buffer\n-\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, \"\"); err != nil {\n-\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n-\t\t}\n-\t\treturn b.String()\n-\t}\n-\tmustRunCommand = func(t *testing.T, cmd, dbName string) string {\n-\t\tt.Helper()\n-\t\tvar b bytes.Buffer\n-\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, \"\"); err != nil {\n-\t\t\tt.Fatalf(\"run(%q, %q): %v\", cmd, dbName, err)\n-\t\t}\n-\t\treturn b.String()\n-\t}\n \tcleanup = func() {\n-\t\tdataClient.Close()\n \t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n \t\t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -77,14 +62,18 @@\nfunc initTest(t *testing.T, projectID string) (dbName string, adminClient *datab\n \treturn\n }\n \n-func initBackupTest(t *testing.T, projectID, dbName string, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client) (restoreDBName, backupID, cancelledBackupID string, runBackupCommand runBackupCommandFunc, cleanup func()) {\n+func initBackupTest(t *testing.T, projectID, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n \tinstance := getInstance(t)\n \trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", projectID), t)\n \trestoreDBName = fmt.Sprintf(\"%s/databases/%s\", instance, restoreDatabaseID)\n \tbackupID = validLength(fmt.Sprintf(\"backup-%s\", projectID), t)\n \tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", projectID), t)\n \n \tctx := context.Background()\n+\tadminClient, err := database.NewDatabaseAdminClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create admin client: %v\", err)\n+\t}\n \tif db, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: restoreDBName}); err == nil {\n \t\tt.Logf(\"database %s exists in state %s. delete result: %v\", db.GetName(), db.GetState().String(),\n \t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName}))",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -107,14 +96,6 @@\nfunc initBackupTest(t *testing.T, projectID, dbName string, adminClient *databas\n \t\t\tadminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: resp.Name}))\n \t}\n \n-\trunBackupCommand = func(t *testing.T, cmd, dbName, backupID string) string {\n-\t\tt.Helper()\n-\t\tvar b bytes.Buffer\n-\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, backupID); err != nil {\n-\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n-\t\t}\n-\t\treturn b.String()\n-\t}\n \tcleanup = func() {\n \t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName})",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -129,176 +110,182 @@\nfunc initBackupTest(t *testing.T, projectID, dbName string, adminClient *databas\n func TestSample(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tdbName, _, _, runCommand, mustRunCommand, cleanup := initTest(t, tc.ProjectID)\n+\tdbName, cleanup := initTest(t, tc.ProjectID)\n \tdefer cleanup()\n \n-\t// We execute all the commands of the tutorial code. These commands have to be run in a specific\n-\t// order since in many cases earlier commands setup the database for the subsequent commands.\n-\tmustRunCommand(t, \"createdatabase\", dbName)\n-\trunCommand(t, \"write\", dbName)\n-\trunCommand(t, \"addnewcolumn\", dbName)\n-\n-\trunCommand(t, \"delete\", dbName)\n-\trunCommand(t, \"write\", dbName)\n-\trunCommand(t, \"update\", dbName)\n-\tout := runCommand(t, \"dmlwritetxn\", dbName)\n+\tvar out string\n+\tmustRunSample(t, createDatabase, dbName, \"failed to create a database\")\n+\trunSample(t, write, dbName, \"failed to insert data\")\n+\trunSample(t, addNewColumn, dbName, \"failed to add new column\")\n+\trunSample(t, delete, dbName, \"failed to delete data\")\n+\trunSample(t, write, dbName, \"failed to insert data\")\n+\trunSample(t, update, dbName, \"failed to update data\")\n+\tout = runSample(t, writeWithTransactionUsingDML, dbName, \"failed to write with transaction using DML\")\n \tassertContains(t, out, \"Moved 200000 from Album2's MarketingBudget to Album1\")\n-\tout = runCommand(t, \"querynewcolumn\", dbName)\n+\tout = runSample(t, queryNewColumn, dbName, \"failed to query new column\")\n \tassertContains(t, out, \"1 1 300000\")\n \tassertContains(t, out, \"2 2 300000\")\n \n-\trunCommand(t, \"delete\", dbName)\n-\trunCommand(t, \"write\", dbName)\n-\trunCommand(t, \"update\", dbName)\n-\tout = runCommand(t, \"writetransaction\", dbName)\n+\trunSample(t, delete, dbName, \"failed to delete data\")\n+\trunSample(t, write, dbName, \"failed to insert data\")\n+\trunSample(t, update, dbName, \"failed to update data\")\n+\tout = runSample(t, writeWithTransaction, dbName, \"failed to write with transaction\")\n \tassertContains(t, out, \"Moved 200000 from Album2's MarketingBudget to Album1\")\n-\tout = runCommand(t, \"querynewcolumn\", dbName)\n+\tout = runSample(t, queryNewColumn, dbName, \"failed to query new column\")\n \tassertContains(t, out, \"1 1 300000\")\n \tassertContains(t, out, \"2 2 300000\")\n \n-\trunCommand(t, \"delete\", dbName)\n-\trunCommand(t, \"write\", dbName)\n+\trunSample(t, delete, dbName, \"failed to delete data\")\n+\trunSample(t, write, dbName, \"failed to insert data\")\n \twriteTime := time.Now()\n \n-\tassertContains(t, runCommand(t, \"read\", dbName), \"1 1 Total Junk\")\n-\n-\tassertContains(t, runCommand(t, \"query\", dbName), \"1 1 Total Junk\")\n+\tout = runSample(t, read, dbName, \"failed to read data\")\n+\tassertContains(t, out, \"1 1 Total Junk\")\n+\tout = runSample(t, query, dbName, \"failed to query data\")\n+\tassertContains(t, out, \"1 1 Total Junk\")\n \n-\trunCommand(t, \"addindex\", dbName)\n-\tout = runCommand(t, \"queryindex\", dbName)\n+\trunSample(t, addIndex, dbName, \"failed to add index\")\n+\tout = runSample(t, queryUsingIndex, dbName, \"failed to query using index\")\n \tassertContains(t, out, \"Go, Go, Go\")\n \tassertContains(t, out, \"Forever Hold Your Peace\")\n \tif strings.Contains(out, \"Green\") {\n \t\tt.Errorf(\"got output %q; should not contain Green\", out)\n \t}\n \n-\tout = runCommand(t, \"readindex\", dbName)\n+\tout = runSample(t, readUsingIndex, dbName, \"failed to read using index\")\n \tassertContains(t, out, \"Go, Go, Go\")\n \tassertContains(t, out, \"Forever Hold Your Peace\")\n \tassertContains(t, out, \"Green\")\n \n-\trunCommand(t, \"delete\", dbName)\n-\trunCommand(t, \"write\", dbName)\n-\trunCommand(t, \"update\", dbName)\n-\trunCommand(t, \"addstoringindex\", dbName)\n-\tassertContains(t, runCommand(t, \"readstoringindex\", dbName), \"500000\")\n-\tout = runCommand(t, \"readonlytransaction\", dbName)\n+\trunSample(t, delete, dbName, \"failed to delete data\")\n+\trunSample(t, write, dbName, \"failed to insert data\")\n+\trunSample(t, update, dbName, \"failed to update data\")\n+\n+\trunSample(t, addStoringIndex, dbName, \"failed to add storing index\")\n+\n+\tout = runSample(t, readStoringIndex, dbName, \"failed to read storing index\")\n+\tassertContains(t, out, \"500000\")\n+\tout = runSample(t, readOnlyTransaction, dbName, \"failed to read with ReadOnlyTransaction\")\n \tif strings.Count(out, \"Total Junk\") != 2 {\n \t\tt.Errorf(\"got output %q; wanted it to contain 2 occurrences of Total Junk\", out)\n \t}\n \n \t// Wait at least 15 seconds since the write.\n \ttime.Sleep(time.Until(writeTime.Add(16 * time.Second)))\n-\tout = runCommand(t, \"readstaledata\", dbName)\n+\tout = runSample(t, readStaleData, dbName, \"failed to read stale data\")\n \tassertContains(t, out, \"Go, Go, Go\")\n \tassertContains(t, out, \"Forever Hold Your Peace\")\n \tassertContains(t, out, \"Green\")\n \n-\tassertContains(t, runCommand(t, \"readbatchdata\", dbName), \"1 Marc Richards\")\n+\tout = runSample(t, readBatchData, dbName, \"failed to read batch data\")\n+\tassertContains(t, out, \"1 Marc Richards\")\n \n-\trunCommand(t, \"addcommittimestamp\", dbName)\n-\trunCommand(t, \"updatewithtimestamp\", dbName)\n-\tout = runCommand(t, \"querywithtimestamp\", dbName)\n+\trunSample(t, addCommitTimestamp, dbName, \"failed to add commit timestamp\")\n+\trunSample(t, updateWithTimestamp, dbName, \"failed to update with timestamp\")\n+\tout = runSample(t, queryWithTimestamp, dbName, \"failed to query with timestamp\")\n \tassertContains(t, out, \"1000000\")\n \n-\trunCommand(t, \"writestructdata\", dbName)\n-\tassertContains(t, runCommand(t, \"querywithstruct\", dbName), \"6\")\n-\tout = runCommand(t, \"querywitharrayofstruct\", dbName)\n+\trunSample(t, writeStructData, dbName, \"failed to write struct data\")\n+\tout = runSample(t, queryWithStruct, dbName, \"failed to query with struct\")\n+\tassertContains(t, out, \"6\")\n+\tout = runSample(t, queryWithArrayOfStruct, dbName, \"failed to query with array of struct\")\n \tassertContains(t, out, \"6\")\n \tassertContains(t, out, \"7\")\n \tassertContains(t, out, \"8\")\n-\tassertContains(t, runCommand(t, \"querywithstructfield\", dbName), \"6\")\n-\tout = runCommand(t, \"querywithnestedstructfield\", dbName)\n+\tout = runSample(t, queryWithStructField, dbName, \"failed to query with struct field\")\n+\tassertContains(t, out, \"6\")\n+\tout = runSample(t, queryWithNestedStructField, dbName, \"failed to query with nested struct field\")\n \tassertContains(t, out, \"6 Imagination\")\n \tassertContains(t, out, \"9 Imagination\")\n \n-\trunCommand(t, \"createtabledocswithtimestamp\", dbName)\n-\trunCommand(t, \"writetodocstable\", dbName)\n-\trunCommand(t, \"updatedocstable\", dbName)\n+\trunSample(t, createTableDocumentsWithTimestamp, dbName, \"failed to create documents table with timestamp\")\n+\trunSample(t, writeToDocumentsTable, dbName, \"failed to write to documents table\")\n+\trunSample(t, updateDocumentsTable, dbName, \"failed to update documents table\")\n \n-\tassertContains(t, runCommand(t, \"querydocstable\", dbName), \"Hello World 1 Updated\")\n+\tout = runSample(t, queryDocumentsTable, dbName, \"failed to query documents table\")\n+\tassertContains(t, out, \"Hello World 1 Updated\")\n \n-\trunCommand(t, \"createtabledocswithhistorytable\", dbName)\n-\trunCommand(t, \"writewithhistory\", dbName)\n-\trunCommand(t, \"updatewithhistory\", dbName)\n+\trunSample(t, createTableDocumentsWithHistoryTable, dbName, \"failed to create documents table with history table\")\n+\trunSample(t, writeWithHistory, dbName, \"failed to write with history\")\n+\trunSample(t, updateWithHistory, dbName, \"failed to update with history\")\n \n-\tout = runCommand(t, \"querywithhistory\", dbName)\n+\tout = runSample(t, queryWithHistory, dbName, \"failed to query with history\")\n \tassertContains(t, out, \"1 1 Hello World 1 Updated\")\n \n-\tout = runCommand(t, \"dmlinsert\", dbName)\n+\tout = runSample(t, insertUsingDML, dbName, \"failed to insert using DML\")\n \tassertContains(t, out, \"record(s) inserted\")\n \n-\tout = runCommand(t, \"dmlupdate\", dbName)\n+\tout = runSample(t, updateUsingDML, dbName, \"failed to update using DML\")\n \tassertContains(t, out, \"record(s) updated\")\n \n-\tout = runCommand(t, \"dmldelete\", dbName)\n+\tout = runSample(t, deleteUsingDML, dbName, \"failed to delete using DML\")\n \tassertContains(t, out, \"record(s) deleted\")\n \n-\tout = runCommand(t, \"dmlwithtimestamp\", dbName)\n+\tout = runSample(t, updateUsingDMLWithTimestamp, dbName, \"failed to update using DML with timestamp\")\n \tassertContains(t, out, \"record(s) updated\")\n \n-\tout = runCommand(t, \"dmlwriteread\", dbName)\n+\tout = runSample(t, writeAndReadUsingDML, dbName, \"failed to write and read using DML\")\n \tassertContains(t, out, \"Found record name with \")\n \n-\tout = runCommand(t, \"dmlupdatestruct\", dbName)\n+\tout = runSample(t, updateUsingDMLStruct, dbName, \"failed to update using DML with struct\")\n \tassertContains(t, out, \"record(s) inserted\")\n \n-\tout = runCommand(t, \"dmlwrite\", dbName)\n+\tout = runSample(t, writeUsingDML, dbName, \"failed to write using DML\")\n \tassertContains(t, out, \"record(s) inserted\")\n \n-\tout = runCommand(t, \"querywithparameter\", dbName)\n+\tout = runSample(t, queryWithParameter, dbName, \"failed to query with parameter\")\n \tassertContains(t, out, \"12 Melissa Garcia\")\n \n-\tout = runCommand(t, \"dmlupdatepart\", dbName)\n+\tout = runSample(t, updateUsingPartitionedDML, dbName, \"failed to update using partitioned DML\")\n \tassertContains(t, out, \"record(s) updated\")\n \n-\tout = runCommand(t, \"dmldeletepart\", dbName)\n+\tout = runSample(t, deleteUsingPartitionedDML, dbName, \"failed to delete using partitioned DML\")\n \tassertContains(t, out, \"record(s) deleted\")\n \n-\tout = runCommand(t, \"dmlbatchupdate\", dbName)\n+\tout = runSample(t, updateUsingBatchDML, dbName, \"failed to update using batch DML\")\n \tassertContains(t, out, \"Executed 2 SQL statements using Batch DML.\")\n \n-\tout = runCommand(t, \"createtablewithdatatypes\", dbName)\n+\tout = runSample(t, createTableWithDatatypes, dbName, \"failed to create table with data types\")\n \tassertContains(t, out, \"Created Venues table\")\n \n-\tout = runCommand(t, \"writedatatypesdata\", dbName)\n-\tout = runCommand(t, \"querywitharray\", dbName)\n+\trunSample(t, writeDatatypesData, dbName, \"failed to write data with different data types\")\n+\tout = runSample(t, queryWithArray, dbName, \"failed to query with array\")\n \tassertContains(t, out, \"19 Venue 19 2020-11-01\")\n \tassertContains(t, out, \"42 Venue 42 2020-10-01\")\n \n-\tout = runCommand(t, \"querywithbool\", dbName)\n+\tout = runSample(t, queryWithBool, dbName, \"failed to query with bool\")\n \tassertContains(t, out, \"19 Venue 19 true\")\n \n-\tout = runCommand(t, \"querywithbytes\", dbName)\n+\tout = runSample(t, queryWithBytes, dbName, \"failed to query with bytes\")\n \tassertContains(t, out, \"4 Venue 4\")\n \n-\tout = runCommand(t, \"querywithdate\", dbName)\n+\tout = runSample(t, queryWithDate, dbName, \"failed to query with date\")\n \tassertContains(t, out, \"4 Venue 4 2018-09-02\")\n \tassertContains(t, out, \"42 Venue 42 2018-10-01\")\n \n-\tout = runCommand(t, \"querywithfloat\", dbName)\n+\tout = runSample(t, queryWithFloat, dbName, \"failed to query with float\")\n \tassertContains(t, out, \"4 Venue 4 0.8\")\n \tassertContains(t, out, \"19 Venue 19 0.9\")\n \n-\tout = runCommand(t, \"querywithint\", dbName)\n+\tout = runSample(t, queryWithInt, dbName, \"failed to query with int\")\n \tassertContains(t, out, \"19 Venue 19 6300\")\n \tassertContains(t, out, \"42 Venue 42 3000\")\n \n-\tout = runCommand(t, \"querywithstring\", dbName)\n+\tout = runSample(t, queryWithString, dbName, \"failed to query with string\")\n \tassertContains(t, out, \"42 Venue 42\")\n \n \t// Wait 5 seconds to avoid a time drift issue for the next query:\n \t// https://github.com/GoogleCloudPlatform/golang-samples/issues/1146.\n \ttime.Sleep(time.Second * 5)\n-\tout = runCommand(t, \"querywithtimestampparameter\", dbName)\n+\tout = runSample(t, queryWithTimestampParameter, dbName, \"failed to query with timestamp parameter\")\n \tassertContains(t, out, \"4 Venue 4\")\n \tassertContains(t, out, \"19 Venue 19\")\n \tassertContains(t, out, \"42 Venue 42\")\n-\tout = runCommand(t, \"querywithqueryoptions\", dbName)\n+\tout = runSample(t, queryWithQueryOptions, dbName, \"failed to query with query options\")\n \tassertContains(t, out, \"4 Venue 4\")\n \tassertContains(t, out, \"19 Venue 19\")\n \tassertContains(t, out, \"42 Venue 42\")\n-\tout = runCommand(t, \"createclientwithqueryoptions\", dbName)\n+\tout = runSample(t, createClientWithQueryOptions, dbName, \"failed to create a client with query options\")\n \tassertContains(t, out, \"4 Venue 4\")\n \tassertContains(t, out, \"19 Venue 19\")\n \tassertContains(t, out, \"42 Venue 42\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into bugfix/pubsub-pull-concurrent-blocking",
        "commit_id": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "appengine: add sample for pubsub token validation",
        "pr_number": 1461,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -26,7 +26,8 @@\nimport (\n // firestoreDB persists books to Cloud Firestore.\n // See https://cloud.google.com/firestore/docs.\n type firestoreDB struct {\n-\tclient *firestore.Client\n+\tclient     *firestore.Client\n+\tcollection string\n }\n \n // Ensure firestoreDB conforms to the BookDatabase interface.",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "be10c0f3b0efbcede5233e636c995b8e4d9f8b32"
    },
    {
        "pr_title": "appengine: add sample for pubsub token validation",
        "pr_number": 1461,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -48,7 +49,8 @@\nfunc newFirestoreDB(client *firestore.Client) (*firestoreDB, error) {\n \t\treturn nil, fmt.Errorf(\"firestoredb: could not connect: %v\", err)\n \t}\n \treturn &firestoreDB{\n-\t\tclient: client,\n+\t\tclient:     client,\n+\t\tcollection: \"books\",\n \t}, nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "be10c0f3b0efbcede5233e636c995b8e4d9f8b32"
    },
    {
        "pr_title": "appengine: add sample for pubsub token validation",
        "pr_number": 1461,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -59,7 +61,7 @@\nfunc (db *firestoreDB) Close(context.Context) error {\n \n // Book retrieves a book by its ID.\n func (db *firestoreDB) GetBook(ctx context.Context, id string) (*Book, error) {\n-\tds, err := db.client.Collection(\"books\").Doc(id).Get(ctx)\n+\tds, err := db.client.Collection(db.collection).Doc(id).Get(ctx)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"firestoredb: Get: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "be10c0f3b0efbcede5233e636c995b8e4d9f8b32"
    },
    {
        "pr_title": "appengine: add sample for pubsub token validation",
        "pr_number": 1461,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -72,7 +74,7 @@\nfunc (db *firestoreDB) GetBook(ctx context.Context, id string) (*Book, error) {\n \n // AddBook saves a given book, assigning it a new ID.\n func (db *firestoreDB) AddBook(ctx context.Context, b *Book) (id string, err error) {\n-\tref := db.client.Collection(\"books\").NewDoc()\n+\tref := db.client.Collection(db.collection).NewDoc()\n \tb.ID = ref.ID\n \tif _, err := ref.Create(ctx, b); err != nil {\n \t\treturn \"\", fmt.Errorf(\"Create: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "be10c0f3b0efbcede5233e636c995b8e4d9f8b32"
    },
    {
        "pr_title": "appengine: add sample for pubsub token validation",
        "pr_number": 1461,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -82,15 +84,15 @@\nfunc (db *firestoreDB) AddBook(ctx context.Context, b *Book) (id string, err err\n \n // DeleteBook removes a given book by its ID.\n func (db *firestoreDB) DeleteBook(ctx context.Context, id string) error {\n-\tif _, err := db.client.Collection(\"books\").Doc(id).Delete(ctx); err != nil {\n+\tif _, err := db.client.Collection(db.collection).Doc(id).Delete(ctx); err != nil {\n \t\treturn fmt.Errorf(\"firestore: Delete: %v\", err)\n \t}\n \treturn nil\n }\n \n // UpdateBook updates the entry for a given book.\n func (db *firestoreDB) UpdateBook(ctx context.Context, b *Book) error {\n-\tif _, err := db.client.Collection(\"books\").Doc(b.ID).Set(ctx, b); err != nil {\n+\tif _, err := db.client.Collection(db.collection).Doc(b.ID).Set(ctx, b); err != nil {\n \t\treturn fmt.Errorf(\"firestsore: Set: %v\", err)\n \t}\n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "be10c0f3b0efbcede5233e636c995b8e4d9f8b32"
    },
    {
        "pr_title": "appengine: add sample for pubsub token validation",
        "pr_number": 1461,
        "file_name": "getting-started/bookshelf/db_test.go",
        "code_diff": "@@ -68,6 +68,10 @@\nfunc TestMemoryDB(t *testing.T) {\n }\n \n func TestFirestoreDB(t *testing.T) {\n+\tgeneralProjectID := os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")\n+\tif generalProjectID == \"\" {\n+\t\tt.Skip(\"GOLANG_SAMPLES_PROJECT_ID not set\")\n+\t}\n \tprojectID := os.Getenv(\"GOLANG_SAMPLES_FIRESTORE_PROJECT\")\n \tif projectID == \"\" {\n \t\tt.Skip(\"GOLANG_SAMPLES_FIRESTORE_PROJECT not set\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "be10c0f3b0efbcede5233e636c995b8e4d9f8b32"
    },
    {
        "pr_title": "appengine: add sample for pubsub token validation",
        "pr_number": 1461,
        "file_name": "getting-started/bookshelf/main_test.go",
        "code_diff": "@@ -40,11 +40,12 @@\nvar (\n func TestMain(m *testing.M) {\n \tctx := context.Background()\n \n-\tprojectID := os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")\n-\tif projectID == \"\" {\n+\tgeneralProjectID := os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")\n+\tif generalProjectID == \"\" {\n \t\tlog.Println(\"GOLANG_SAMPLES_PROJECT_ID not set. Skipping.\")\n \t\treturn\n \t}\n+\tprojectID := generalProjectID\n \n \tmemoryDB := newMemoryDB()\n \ttestDBs[\"memory\"] = memoryDB",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "be10c0f3b0efbcede5233e636c995b8e4d9f8b32"
    },
    {
        "pr_title": "appengine: add sample for pubsub token validation",
        "pr_number": 1461,
        "file_name": "getting-started/bookshelf/main_test.go",
        "code_diff": "@@ -57,8 +58,9 @@\nfunc TestMain(m *testing.M) {\n \t\t\tlog.Fatalf(\"firestore.NewClient: %v\", err)\n \t\t}\n \n+\t\tcollection := generalProjectID + \"-main-books\"\n \t\t// Delete all docs first to start with a clean slate.\n-\t\tdocs, err := client.Collection(\"books\").DocumentRefs(ctx).GetAll()\n+\t\tdocs, err := client.Collection(collection).DocumentRefs(ctx).GetAll()\n \t\tif err == nil {\n \t\t\tfor _, d := range docs {\n \t\t\t\tif _, err := d.Delete(ctx); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "be10c0f3b0efbcede5233e636c995b8e4d9f8b32"
    },
    {
        "pr_title": "bigquery: add a bigquery_connection_quickstart",
        "pr_number": 1446,
        "file_name": "bigquery/bigquery_connection_quickstart/main.go",
        "code_diff": "@@ -34,10 +34,9 @@\nimport (\n func main() {\n \n \t// Define two command line flags for controlling the behavior of this quickstart.\n-\tvar (\n-\t\tprojectID = flag.String(\"project_id\", \"\", \"Cloud Project ID, used for session creation.\")\n-\t\tlocation  = flag.String(\"location\", \"US\", \"BigQuery location used for interactions.\")\n-\t)\n+\tprojectID := flag.String(\"project_id\", \"\", \"Cloud Project ID, used for session creation.\")\n+\tlocation := flag.String(\"location\", \"US\", \"BigQuery location used for interactions.\")\n+\n \t// Parse flags and do some minimal validation.\n \tflag.Parse()\n \tif *projectID == \"\" {",
        "comments": [
            {
                "comment": "Optional:\r\n```suggestion\r\nfunc main() {\r\n\t// Define two command line flags for controlling the behavior of this quickstart.\r\n\tprojectID := flag.String(\"project_id\", \"\", \"Cloud Project ID, used for session creation.\")\r\n\tlocation  := flag.String(\"location\", \"US\", \"BigQuery location used for interactions.\")\r\n```",
                "position": null
            },
            {
                "comment": "```suggestion\r\n// unixMillisToTime converts the epoch-millisecond representations used by the API into a time.Time representation.\r\n```",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            }
        ],
        "commit_message": "address reviewer comments",
        "commit_id": "1c68995639a0b8cb694e1c75467f8f8740f2a20f"
    },
    {
        "pr_title": "bigquery: add reservation quickstart",
        "pr_number": 1439,
        "file_name": "logging/simplelog/simplelog_test.go",
        "code_diff": "@@ -28,7 +28,6 @@\nimport (\n )\n \n func TestSimplelog(t *testing.T) {\n-\tt.Skip(\"Flaky https://github.com/GoogleCloudPlatform/golang-samples/issues/696\")\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-resquickstart",
        "commit_id": "6dbf69727415e11b8d59940219c061173dae3d5f"
    },
    {
        "pr_title": "bigquery: add reservation quickstart",
        "pr_number": 1439,
        "file_name": "logging/simplelog/simplelog_test.go",
        "code_diff": "@@ -47,7 +46,7 @@\nfunc TestSimplelog(t *testing.T) {\n \t}()\n \n \tdefer func() {\n-\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\ttestutil.Retry(t, 10, 5*time.Second, func(r *testutil.R) {\n \t\t\tif err := deleteLog(adminClient); err != nil {\n \t\t\t\tr.Errorf(\"deleteLog: %v\", err)\n \t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into fr-resquickstart",
        "commit_id": "6dbf69727415e11b8d59940219c061173dae3d5f"
    },
    {
        "pr_title": "storage: enable bucket object lifecycle management",
        "pr_number": 1424,
        "file_name": "spanner/spanner_snippets/spanner/spanner_read_stale_data.go",
        "code_diff": "@@ -14,6 +14,8 @@\npackage spanner\n \n+// [START spanner_read_stale_data]\n+\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'gcs-olm' of github.com:GoogleCloudPlatform/golang-samples into gcs-olm",
        "commit_id": "6f813336bf9c6da89c45447e226f1dbd373bccfe"
    },
    {
        "pr_title": "trace/trace_quickstart: use Google Cloud propagation in server",
        "pr_number": 1417,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -195,6 +195,41 @@\nfunc TestDelete(t *testing.T) {\n \t}\n }\n \n+func TestPullMsgsAsync(t *testing.T) {\n+\tclient := setup(t)\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tasyncTopicID := topicID + \"-async\"\n+\tasyncSubID := subID + \"-async\"\n+\n+\ttopic, err := getOrCreateTopic(ctx, client, asyncTopicID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n+\t}\n+\tdefer topic.Delete(ctx)\n+\tdefer topic.Stop()\n+\n+\tsub, err := getOrCreateSub(ctx, client, topic, asyncSubID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"getOrCreateSub: %v\", err)\n+\t}\n+\tdefer sub.Delete(ctx)\n+\n+\t// Publish 10 messages on the topic.\n+\tconst numMsgs = 10\n+\tpublishMsgs(ctx, topic, numMsgs)\n+\n+\tbuf := new(bytes.Buffer)\n+\terr = pullMsgs(buf, tc.ProjectID, asyncSubID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to pull messages: %v\", err)\n+\t}\n+\t// Check for number of newlines, which should correspond with number of messages.\n+\tif got := strings.Count(buf.String(), \"\\n\"); got != numMsgs {\n+\t\tt.Fatalf(\"pullMsgsSync got %d messages, want %d\", got, numMsgs)\n+\t}\n+}\n+\n func TestPullMsgsSync(t *testing.T) {\n \tclient := setup(t)\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into trace-quickstart-propagation",
        "commit_id": "e971ebdc508b182248e281c454ee04c9b388996d"
    },
    {
        "pr_title": "functions: update ocr sample to use environment variables",
        "pr_number": 1403,
        "file_name": "regiontag_test.go",
        "code_diff": "@@ -18,11 +18,13 @@\nimport (\n \t\"bufio\"\n \t\"log\"\n \t\"os/exec\"\n-\t\"strings\"\n+\t\"regexp\"\n \t\"sync\"\n \t\"testing\"\n )\n \n+var startRe = regexp.MustCompile(\"\\\\[START ([[:word:]]+)\\\\]\")\n+\n func listPackages() <-chan string {\n \tc := make(chan string)\n \tgo func() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into func-app",
        "commit_id": "01e158b0cffa7e0d0aa95f9dd097ef2924d42ee7"
    },
    {
        "pr_title": "storage: add PostPolicyV4 sample",
        "pr_number": 1392,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -15,6 +15,7 @@\n// Sample firestore_quickstart demonstrates how to connect to Firestore, and add and list documents.\n package main\n \n+// [START fs_initialize]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a0e336aa7c813e4fccdbc5264a282dc41b32f064"
    },
    {
        "pr_title": "functions: cloud bigtable reading function example",
        "pr_number": 1383,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1032,7 +1032,7 @@\nfunc updateUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) er\n \n func deleteUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n \t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n-\t\tstmt := spanner.Statement{SQL: `DELETE Singers WHERE FirstName = 'Alice'`}\n+\t\tstmt := spanner.Statement{SQL: `DELETE FROM Singers WHERE FirstName = 'Alice'`}\n \t\trowCount, err := txn.Update(ctx, stmt)\n \t\tif err != nil {\n \t\t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'master' into bigtable-function",
        "commit_id": "41c7e3c9241e3fa85eb929f31deb4702c79d1dff"
    },
    {
        "pr_title": "functions: add sample calling a function with an ID token",
        "pr_number": 1380,
        "file_name": "badfiles_test.go",
        "code_diff": "@@ -51,6 +51,7 @@\nvar allowList = []string{\n \t\"**/*Dockerfile*\",\n \t\"**/.dockerignore\",\n \t\"**/Makefile\",\n+\t\".gitignore\",\n \n \t// Primarily ML APIs.\n \t\"**/testdata/**/*.jpg\",",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:codyoss/golang-samples into func-auth",
        "commit_id": "d536d08cb18d12c600341102c4bb74dbaa291248"
    },
    {
        "pr_title": "functions: add sample calling a function with an ID token",
        "pr_number": 1380,
        "file_name": "storage/s3_sdk/list_gcs_buckets.go",
        "code_diff": "@@ -28,7 +28,10 @@\nimport (\n \t\"github.com/aws/aws-sdk-go/service/s3\"\n )\n \n-func listGCSBuckets(w io.Writer, googleAccessKeyID string, googleAccessKeySecret string) ([]*s3.Bucket, error) {\n+func listGCSBuckets(w io.Writer, googleAccessKeyID string, googleAccessKeySecret string) error {\n+\t// googleAccessKeyID := \"Your Google Access Key ID\"\n+\t// googleAccessKeySecret := \"Your Google Access Key Secret\"\n+\n \t// Create a new client and do the following:\n \t// 1. Change the endpoint URL to use the Google Cloud Storage XML API endpoint.\n \t// 2. Use Cloud Storage HMAC Credentials.",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:codyoss/golang-samples into func-auth",
        "commit_id": "d536d08cb18d12c600341102c4bb74dbaa291248"
    },
    {
        "pr_title": "functions: add sample calling a function with an ID token",
        "pr_number": 1380,
        "file_name": "storage/s3_sdk/s3_gcs_test.go",
        "code_diff": "@@ -28,7 +28,7 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func TestList(t *testing.T) {\n+func TestListGCSBuckets(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:codyoss/golang-samples into func-auth",
        "commit_id": "d536d08cb18d12c600341102c4bb74dbaa291248"
    },
    {
        "pr_title": "functions: add sample calling a function with an ID token",
        "pr_number": 1380,
        "file_name": "storage/s3_sdk/s3_gcs_test.go",
        "code_diff": "@@ -50,7 +50,7 @@\nfunc TestList(t *testing.T) {\n \t// to that amount of time.\n \ttestutil.Retry(t, 75, time.Millisecond*200, func(r *testutil.R) {\n \t\tbuf.Reset()\n-\t\tif _, err := listGCSBuckets(buf, key.AccessID, key.Secret); err != nil {\n+\t\tif err := listGCSBuckets(buf, key.AccessID, key.Secret); err != nil {\n \t\t\tr.Errorf(\"listGCSBuckets: %v\", err)\n \t\t}\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' of github.com:codyoss/golang-samples into func-auth",
        "commit_id": "d536d08cb18d12c600341102c4bb74dbaa291248"
    },
    {
        "pr_title": "securitycenter: fix broken ListAssets test, stop skipping tests",
        "pr_number": 1379,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -117,7 +117,6 @@\nfunc cleanupNotificationConfig(t *testing.T, notificationConfigID string) error\n }\n \n func TestCreateNotificationConfig(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/1352\")\n \tbuf := new(bytes.Buffer)\n \trand, err := uuid.NewUUID()\n \tif err != nil {",
        "comments": [],
        "commit_message": "remove notification test skips",
        "commit_id": "a9bd0e4c086b1391acb21ff3c7c74642e880b775"
    },
    {
        "pr_title": "securitycenter: fix broken ListAssets test, stop skipping tests",
        "pr_number": 1379,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -137,7 +136,6 @@\nfunc TestCreateNotificationConfig(t *testing.T) {\n }\n \n func TestDeleteNotificationConfig(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/1353\")\n \tbuf := new(bytes.Buffer)\n \trand, err := uuid.NewUUID()\n \tif err != nil {",
        "comments": [],
        "commit_message": "remove notification test skips",
        "commit_id": "a9bd0e4c086b1391acb21ff3c7c74642e880b775"
    },
    {
        "pr_title": "securitycenter: fix broken ListAssets test, stop skipping tests",
        "pr_number": 1379,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -159,7 +157,6 @@\nfunc TestDeleteNotificationConfig(t *testing.T) {\n }\n \n func TestGetNotificationConfig(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/1354\")\n \tbuf := new(bytes.Buffer)\n \trand, err := uuid.NewUUID()\n \tif err != nil {",
        "comments": [],
        "commit_message": "remove notification test skips",
        "commit_id": "a9bd0e4c086b1391acb21ff3c7c74642e880b775"
    },
    {
        "pr_title": "securitycenter: fix broken ListAssets test, stop skipping tests",
        "pr_number": 1379,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -183,7 +180,6 @@\nfunc TestGetNotificationConfig(t *testing.T) {\n }\n \n func TestListNotificationConfigs(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/1355\")\n \tbuf := new(bytes.Buffer)\n \trand, err := uuid.NewUUID()\n \tif err != nil {",
        "comments": [],
        "commit_message": "remove notification test skips",
        "commit_id": "a9bd0e4c086b1391acb21ff3c7c74642e880b775"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/encrypt_asymmetric.go",
        "code_diff": "@@ -31,9 +31,9 @@\nimport (\n \n // encryptAsymmetric encrypts data on your local machine using an\n // 'RSA_DECRYPT_OAEP_2048_SHA256' public key retrieved from Cloud KMS.\n-func encryptAsymmetric(w io.Writer, name string, plaintext string) error {\n+func encryptAsymmetric(w io.Writer, name string, message string) error {\n \t// name := \"projects/my-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key/cryptoKeyVersions/123\"\n-\t// plaintext := \"Sample message\"\n+\t// message := \"Sample message\"\n \n \t// Create the client.\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Add more clarity on parameter names",
        "commit_id": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/encrypt_symmetric.go",
        "code_diff": "@@ -26,9 +26,9 @@\nimport (\n \n // encryptSymmetric encrypts the input plaintext with the specified symmetric\n // Cloud KMS key.\n-func encryptSymmetric(w io.Writer, name string, plaintext string) error {\n+func encryptSymmetric(w io.Writer, name string, message string) error {\n \t// name := \"projects/my-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key\"\n-\t// plaintext := \"Sample message\"\n+\t// message := \"Sample message\"\n \n \t// Create the client.\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Add more clarity on parameter names",
        "commit_id": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "telemetry: add trace example",
        "pr_number": 1320,
        "file_name": "opentelemetry/trace/main.go",
        "code_diff": "@@ -28,7 +28,7 @@\nimport (\n )\n \n // [END opentelemetry_trace_import]\n-// [START main_function]\n+// [START opentelemetry_trace_main_function]\n func main() {\n \t// Create exporter.\n \tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")",
        "comments": [
            {
                "comment": "Prefix with the product name. Probably `opentelemetry_trace_import`. Same with the other region.\r\n\r\nAre you sure you want a separate import block? Most quickstarts put it all in a single region to make it easy to copy.",
                "position": null
            },
            {
                "comment": "Nit: Periods at the end of sentences/comments.\r\n\r\nhttps://github.com/golang/go/wiki/CodeReviewComments#comment-sentences",
                "position": null
            },
            {
                "comment": "Might want to add context to this message.\r\n\r\n```suggestion\r\n\t\tlog.Fatalf(\"texporter.NewExporter: %v\", err)\r\n```\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/master/CONTRIBUTING.md#return-errors is relevant, but doesn't directly apply.",
                "position": null
            },
            {
                "comment": "Careful with this one -- we've run into issues when the imports aren't included in the region and users get confused. If this is all on the same page, it's probably OK. But, this shouldn't appear without the imports nearby.\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/master/CONTRIBUTING.md#include-imports-and-flags-in-region-tags",
                "position": null
            },
            {
                "comment": "Avoid terms like \"basic\" and \"simple\" -- when you're learning, it's not.\r\n\r\nhttps://developers.google.com/style/tone#some-things-to-avoid-where-possible",
                "position": null
            },
            {
                "comment": "done.",
                "position": null
            },
            {
                "comment": "fixed.",
                "position": null
            },
            {
                "comment": "changed.",
                "position": null
            },
            {
                "comment": "It would require to make a separate example. But then all the prior code is duplicated. Also without any spans created the quick_start example becomes meaningless. \r\n",
                "position": null
            },
            {
                "comment": "changed it to \"example.com/trace\"",
                "position": null
            },
            {
                "comment": "go 1.14 doesn't like single block of imports.  \r\nhttps://source.cloud.google.com/results/invocations/3231dde3-2f00-45eb-a685-1f37554d00ff/targets/cloud-devrel%2Fgo%2Fgolang-samples%2Fpresubmit%2Fgo114/log",
                "position": null
            }
        ],
        "commit_message": "add prefix to regions.",
        "commit_id": "c3c28c68ab0ec88f7df0a3e56bf72d996062417f"
    },
    {
        "pr_title": "telemetry: add trace example",
        "pr_number": 1320,
        "file_name": "opentelemetry/trace/main.go",
        "code_diff": "@@ -37,7 +37,7 @@\nfunc main() {\n \t\tlog.Fatalf(\"texporter.NewExporter: %v\", err)\n \t}\n \n-\t// Create trace provider with the exporter\n+\t// Create trace provider with the exporter.\n \t//\n \t// By default it uses AlwaysSample() which samples all traces.\n \t// In a production environment or high QPS setup please use",
        "comments": [
            {
                "comment": "Prefix with the product name. Probably `opentelemetry_trace_import`. Same with the other region.\r\n\r\nAre you sure you want a separate import block? Most quickstarts put it all in a single region to make it easy to copy.",
                "position": null
            },
            {
                "comment": "Nit: Periods at the end of sentences/comments.\r\n\r\nhttps://github.com/golang/go/wiki/CodeReviewComments#comment-sentences",
                "position": null
            },
            {
                "comment": "Might want to add context to this message.\r\n\r\n```suggestion\r\n\t\tlog.Fatalf(\"texporter.NewExporter: %v\", err)\r\n```\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/master/CONTRIBUTING.md#return-errors is relevant, but doesn't directly apply.",
                "position": null
            },
            {
                "comment": "Careful with this one -- we've run into issues when the imports aren't included in the region and users get confused. If this is all on the same page, it's probably OK. But, this shouldn't appear without the imports nearby.\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/master/CONTRIBUTING.md#include-imports-and-flags-in-region-tags",
                "position": null
            },
            {
                "comment": "Avoid terms like \"basic\" and \"simple\" -- when you're learning, it's not.\r\n\r\nhttps://developers.google.com/style/tone#some-things-to-avoid-where-possible",
                "position": null
            },
            {
                "comment": "done.",
                "position": null
            },
            {
                "comment": "fixed.",
                "position": null
            },
            {
                "comment": "changed.",
                "position": null
            },
            {
                "comment": "It would require to make a separate example. But then all the prior code is duplicated. Also without any spans created the quick_start example becomes meaningless. \r\n",
                "position": null
            },
            {
                "comment": "changed it to \"example.com/trace\"",
                "position": null
            },
            {
                "comment": "go 1.14 doesn't like single block of imports.  \r\nhttps://source.cloud.google.com/results/invocations/3231dde3-2f00-45eb-a685-1f37554d00ff/targets/cloud-devrel%2Fgo%2Fgolang-samples%2Fpresubmit%2Fgo114/log",
                "position": null
            }
        ],
        "commit_message": "add prefix to regions.",
        "commit_id": "c3c28c68ab0ec88f7df0a3e56bf72d996062417f"
    },
    {
        "pr_title": "video: add logo recognition samples",
        "pr_number": 1314,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/go-cmp/cmp\"\n )\n \n var topicID string",
        "comments": [],
        "commit_message": "Merge branch 'master' into video-logo",
        "commit_id": "fb875a854e4c85fe78a7326dee7a0d22716735cf"
    },
    {
        "pr_title": "video: add logo recognition samples",
        "pr_number": 1314,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -251,7 +252,7 @@\nfunc TestPullMsgsConcurrencyControl(t *testing.T) {\n \n \t// Publish 5 message to test with.\n \tconst numMsgs = 5\n-\tpublishMsgs(ctx, topic, 5)\n+\tpublishMsgs(ctx, topic, numMsgs)\n \n \tbuf := new(bytes.Buffer)\n \tif err := pullMsgsConcurrenyControl(buf, tc.ProjectID, subIDConc); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into video-logo",
        "commit_id": "fb875a854e4c85fe78a7326dee7a0d22716735cf"
    },
    {
        "pr_title": "video: add logo recognition samples",
        "pr_number": 1314,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -28,6 +28,8 @@\nimport (\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/storage\"\n \t\"google.golang.org/api/iterator\"\n+\tiampb \"google.golang.org/genproto/googleapis/iam/v1\"\n+\t\"google.golang.org/genproto/googleapis/type/expr\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into video-logo",
        "commit_id": "fb875a854e4c85fe78a7326dee7a0d22716735cf"
    },
    {
        "pr_title": "video: add logo recognition samples",
        "pr_number": 1314,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -159,18 +161,18 @@\nfunc deleteBucket(client *storage.Client, bucketName string) error {\n \treturn nil\n }\n \n-func getPolicy(c *storage.Client, bucketName string) (*iam.Policy, error) {\n+func getPolicy(c *storage.Client, bucketName string) (*iam.Policy3, error) {\n \t// [START storage_get_bucket_policy]\n \tctx := context.Background()\n \n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n-\tpolicy, err := c.Bucket(bucketName).IAM().Policy(ctx)\n+\tpolicy, err := c.Bucket(bucketName).IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\tfor _, role := range policy.Roles() {\n-\t\tlog.Printf(\"%q: %q\", role, policy.Members(role))\n+\tfor _, binding := range policy.Bindings {\n+\t\tlog.Printf(\"%q: %q (condition: %v)\", binding.Role, binding.Members, binding.Condition)\n \t}\n \t// [END storage_get_bucket_policy]\n \treturn policy, nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into video-logo",
        "commit_id": "fb875a854e4c85fe78a7326dee7a0d22716735cf"
    },
    {
        "pr_title": "video: add logo recognition samples",
        "pr_number": 1314,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -183,15 +185,18 @@\nfunc addUser(c *storage.Client, bucketName string) error {\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n-\tpolicy, err := bucket.IAM().Policy(ctx)\n+\tpolicy, err := bucket.IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Other valid prefixes are \"serviceAccount:\", \"user:\"\n \t// See the documentation for more values.\n \t// https://cloud.google.com/storage/docs/access-control/iam\n-\tpolicy.Add(\"group:cloud-logs@google.com\", \"roles/storage.objectViewer\")\n-\tif err := bucket.IAM().SetPolicy(ctx, policy); err != nil {\n+\tpolicy.Bindings = append(policy.Bindings, &iampb.Binding{\n+\t\tRole:    \"roles/storage.objectViewer\",\n+\t\tMembers: []string{\"group:cloud-logs@google.com\"},\n+\t})\n+\tif err := bucket.IAM().V3().SetPolicy(ctx, policy); err != nil {\n \t\treturn err\n \t}\n \t// NOTE: It may be necessary to retry this operation if IAM policies are",
        "comments": [],
        "commit_message": "Merge branch 'master' into video-logo",
        "commit_id": "fb875a854e4c85fe78a7326dee7a0d22716735cf"
    },
    {
        "pr_title": "video: add logo recognition samples",
        "pr_number": 1314,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -208,15 +213,32 @@\nfunc removeUser(c *storage.Client, bucketName string) error {\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n-\tpolicy, err := bucket.IAM().Policy(ctx)\n+\tpolicy, err := bucket.IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Other valid prefixes are \"serviceAccount:\", \"user:\"\n \t// See the documentation for more values.\n \t// https://cloud.google.com/storage/docs/access-control/iam\n-\tpolicy.Remove(\"group:cloud-logs@google.com\", \"roles/storage.objectViewer\")\n-\tif err := bucket.IAM().SetPolicy(ctx, policy); err != nil {\n+\tfor _, binding := range policy.Bindings {\n+\t\t// Only remove unconditional bindings matching role\n+\t\tif binding.Role == \"roles/storage.objectViewer\" && binding.Condition == nil {\n+\t\t\t// Filter out member.\n+\t\t\ti := -1\n+\t\t\tfor j, member := range binding.Members {\n+\t\t\t\tif member == \"group:cloud-logs@google.com\" {\n+\t\t\t\t\ti = j\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif i == -1 {\n+\t\t\t\treturn errors.New(\"No matching binding group found.\")\n+\t\t\t} else {\n+\t\t\t\tbinding.Members = append(binding.Members[:i], binding.Members[i+1:]...)\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif err := bucket.IAM().V3().SetPolicy(ctx, policy); err != nil {\n \t\treturn err\n \t}\n \t// NOTE: It may be necessary to retry this operation if IAM policies are",
        "comments": [],
        "commit_message": "Merge branch 'master' into video-logo",
        "commit_id": "fb875a854e4c85fe78a7326dee7a0d22716735cf"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "badfiles_test.go",
        "code_diff": "@@ -59,6 +59,7 @@\nvar allowList = []string{\n \t\"**/testdata/**/*.png\",\n \t\"**/testdata/**/*.txt\",\n \t\"**/testdata/**/*.csv\",\n+\t\"**/testdata/**/*.mp4\",\n \n \t// Healthcare data.\n \t\"healthcare/testdata/dicom_00000001_000.dcm\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/go-cmp/cmp\"\n )\n \n var topicID string",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -251,7 +252,7 @@\nfunc TestPullMsgsConcurrencyControl(t *testing.T) {\n \n \t// Publish 5 message to test with.\n \tconst numMsgs = 5\n-\tpublishMsgs(ctx, topic, 5)\n+\tpublishMsgs(ctx, topic, numMsgs)\n \n \tbuf := new(bytes.Buffer)\n \tif err := pullMsgsConcurrenyControl(buf, tc.ProjectID, subIDConc); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -28,18 +28,25 @@\nimport (\n \n \t\"cloud.google.com/go/civil\"\n \t\"cloud.google.com/go/spanner\"\n-\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n+\t\"github.com/golang/protobuf/ptypes\"\n \t\"google.golang.org/api/iterator\"\n \t\"google.golang.org/api/option\"\n+\t\"google.golang.org/genproto/googleapis/longrunning\"\n \t\"google.golang.org/grpc\"\n+\t\"google.golang.org/grpc/codes\"\n \n+\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n+\tpbts \"github.com/golang/protobuf/ptypes\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n \tsppb \"google.golang.org/genproto/googleapis/spanner/v1\"\n+\t\"google.golang.org/genproto/protobuf/field_mask\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n type command func(ctx context.Context, w io.Writer, client *spanner.Client) error\n type newClientCommand func(ctx context.Context, w io.Writer, database string) error\n type adminCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error\n+type backupCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error\n \n var (\n \tcommands = map[string]command{",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -109,6 +116,17 @@\nvar (\n \t\t\"createtablewithdatatypes\":        createTableWithDatatypes,\n \t\t\"createtabledocswithtimestamp\":    createTableDocumentsWithTimestamp,\n \t\t\"createtabledocswithhistorytable\": createTableDocumentsWithHistoryTable,\n+\t\t\"listbackupoperations\":            listBackupOperations,\n+\t\t\"listdatabaseoperations\":          listDatabaseOperations,\n+\t}\n+\n+\tbackupCommands = map[string]backupCommand{\n+\t\t\"createbackup\":  createBackup,\n+\t\t\"cancelbackup\":  cancelBackup,\n+\t\t\"listbackups\":   listBackups,\n+\t\t\"updatebackup\":  updateBackup,\n+\t\t\"deletebackup\":  deleteBackup,\n+\t\t\"restorebackup\": restoreBackup,\n \t}\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1894,6 +1912,343 @@\nfunc createClientWithQueryOptions(ctx context.Context, w io.Writer, database str\n \n // [END spanner_create_client_with_query_options]\n \n+// [START spanner_create_backup]\n+\n+func createBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\texpireTime := time.Now().AddDate(0, 0, 14)\n+\t// Create a backup.\n+\top, err := adminClient.StartBackupOperation(ctx, backupID, database, expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Wait for backup operation to complete.\n+\tbackup, err := op.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Get the name, create time and backup size.\n+\tcreateTime := time.Unix(backup.CreateTime.Seconds, int64(backup.CreateTime.Nanos))\n+\tfmt.Fprintf(w, \"Backup %s of size %d bytes was created at %s\\n\", backup.Name, backup.SizeBytes, createTime.Format(time.RFC3339))\n+\treturn nil\n+}\n+\n+// [END spanner_create_backup]\n+\n+// [START spanner_cancel_backup_create]\n+\n+func cancelBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\texpireTime := time.Now().AddDate(0, 0, 14)\n+\t// Create a backup.\n+\top, err := adminClient.StartBackupOperation(ctx, backupID, database, expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Cancel backup creation.\n+\terr = adminClient.LROClient.CancelOperation(ctx, &longrunning.CancelOperationRequest{Name: op.Name()})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Cancel operations are best effort so either it will complete or be\n+\t// cancelled.\n+\tbackup, err := op.Wait(ctx)\n+\tif err != nil {\n+\t\tif waitStatus, ok := status.FromError(err); !ok || waitStatus.Code() != codes.Canceled {\n+\t\t\treturn err\n+\t\t}\n+\t} else {\n+\t\t// Backup was completed before it could be cancelled so delete the\n+\t\t// unwanted backup.\n+\t\terr = adminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: backup.Name})\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\tfmt.Fprintf(w, \"Backup cancelled.\\n\")\n+\treturn nil\n+}\n+\n+// [END spanner_cancel_backup_create]\n+\n+// [START spanner_list_backups]\n+\n+func listBackups(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, db, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(db)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", db)\n+\t}\n+\tinstanceName := matches[1]\n+\n+\tprintBackups := func(iter *database.BackupIterator) error {\n+\t\tfor {\n+\t\t\tresp, err := iter.Next()\n+\t\t\tif err == iterator.Done {\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t\tif err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tfmt.Fprintf(w, \"Backup %s\\n\", resp.Name)\n+\t\t}\n+\t}\n+\n+\tvar iter *database.BackupIterator\n+\tvar filter string\n+\t// List all backups.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups that contain a name.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"name:\" + backupID,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups that expire before a timestamp.\n+\texpireTime := time.Now().AddDate(0, 0, 30)\n+\tfilter = fmt.Sprintf(`expire_time < \"%s\"`, expireTime.Format(time.RFC3339))\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups for a database that contains a name.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"database:\" + db,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups with a size greater than some bytes.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"size_bytes > 100\",\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List backups that were created after a timestamp that are also ready.\n+\tcreateTime := time.Now().AddDate(0, 0, -1)\n+\tfilter = fmt.Sprintf(\n+\t\t`create_time >= \"%s\" AND state:READY`,\n+\t\tcreateTime.Format(time.RFC3339),\n+\t)\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List backups with pagination.\n+\trequest := &adminpb.ListBackupsRequest{\n+\t\tParent:   instanceName,\n+\t\tPageSize: 10,\n+\t}\n+\tfor {\n+\t\titer = adminClient.ListBackups(ctx, request)\n+\t\tif err := printBackups(iter); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tpageToken := iter.PageInfo().Token\n+\t\tif pageToken == \"\" {\n+\t\t\tbreak\n+\t\t} else {\n+\t\t\trequest.PageToken = pageToken\n+\t\t}\n+\t}\n+\n+\tfmt.Fprintf(w, \"Backups listed.\\n\")\n+\treturn nil\n+}\n+\n+// [END spanner_list_backups]\n+\n+// [START spanner_list_backup_operations]\n+\n+func listBackupOperations(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\t// List the CreateBackup operations.\n+\tfilter := fmt.Sprintf(\"(metadata.database:%s) AND (metadata.@type:type.googleapis.com/google.spanner.admin.database.v1.CreateBackupMetadata)\", database)\n+\titer := adminClient.ListBackupOperations(ctx, &adminpb.ListBackupOperationsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tmetadata := &adminpb.CreateBackupMetadata{}\n+\t\tif err := ptypes.UnmarshalAny(resp.Metadata, metadata); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"Backup %s on database %s is %d%% complete.\\n\",\n+\t\t\tmetadata.Name,\n+\t\t\tmetadata.Database,\n+\t\t\tmetadata.Progress.ProgressPercent,\n+\t\t)\n+\t}\n+\treturn nil\n+}\n+\n+// [END spanner_list_backup_operations]\n+\n+// [START spanner_list_database_operations]\n+\n+func listDatabaseOperations(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\t// List the databases that are being optimized after a restore operation.\n+\tfilter := \"(metadata.@type:type.googleapis.com/google.spanner.admin.database.v1.OptimizeRestoredDatabaseMetadata)\"\n+\titer := adminClient.ListDatabaseOperations(ctx, &adminpb.ListDatabaseOperationsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tmetadata := &adminpb.OptimizeRestoredDatabaseMetadata{}\n+\t\tif err := ptypes.UnmarshalAny(resp.Metadata, metadata); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"Database %s restored from backup is %d%% optimized.\\n\",\n+\t\t\tmetadata.Name,\n+\t\t\tmetadata.Progress.ProgressPercent,\n+\t\t)\n+\t}\n+\treturn nil\n+}\n+\n+// [END spanner_list_database_operations]\n+\n+// [START spanner_update_backup]\n+\n+func updateBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tbackupName := matches[1] + \"/backups/\" + backupID\n+\n+\tbackup, err := adminClient.GetBackup(ctx, &adminpb.GetBackupRequest{Name: backupName})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Expire time must be within 366 days of the create time of the backup.\n+\texpireTime := time.Unix(backup.CreateTime.Seconds, int64(backup.CreateTime.Nanos)).AddDate(0, 0, 30)\n+\texpirespb, err := pbts.TimestampProto(expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t_, err = adminClient.UpdateBackup(ctx, &adminpb.UpdateBackupRequest{\n+\t\tBackup: &adminpb.Backup{\n+\t\t\tName:       backupName,\n+\t\t\tExpireTime: expirespb,\n+\t\t},\n+\t\tUpdateMask: &field_mask.FieldMask{Paths: []string{\"expire_time\"}},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Fprintf(w, \"Updated backup %s\\n\", backupID)\n+\treturn nil\n+}\n+\n+// [END spanner_update_backup]\n+\n+// [START spanner_restore_backup]\n+\n+func restoreBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\tdatabaseID := matches[2]\n+\tbackupName := instanceName + \"/backups/\" + backupID\n+\n+\t// Start restoring backup to a new database.\n+\trestoreOp, err := adminClient.RestoreDatabase(ctx, &adminpb.RestoreDatabaseRequest{\n+\t\tParent:     instanceName,\n+\t\tDatabaseId: databaseID,\n+\t\tSource: &adminpb.RestoreDatabaseRequest_Backup{\n+\t\t\tBackup: backupName,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Wait for restore operation to complete.\n+\tdb, err := restoreOp.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Newly created database has restore information.\n+\tbackupInfo := db.RestoreInfo.GetBackupInfo()\n+\tif backupInfo != nil {\n+\t\tfmt.Fprintf(w, \"Source database %s restored from backup %s\\n\", backupInfo.SourceDatabase, backupInfo.Backup)\n+\t}\n+\n+\treturn nil\n+}\n+\n+// [END spanner_restore_backup]\n+\n+// [START spanner_delete_backup]\n+\n+func deleteBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tbackupName := matches[1] + \"/backups/\" + backupID\n+\t// Delete the backup.\n+\terr := adminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: backupName})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Deleted backup %s\\n\", backupID)\n+\treturn nil\n+}\n+\n+// [END spanner_delete_backup]\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \t// [START spanner_create_admin_client_for_emulator]",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1924,7 +2279,7 @@\nfunc createClients(ctx context.Context, db string) (*database.DatabaseAdminClien\n \treturn adminClient, dataClient\n }\n \n-func run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, w io.Writer, cmd string, db string) error {\n+func run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, w io.Writer, cmd string, db string, backupID string) error {\n \tif adminCmdFn := adminCommands[cmd]; adminCmdFn != nil {\n \t\terr := adminCmdFn(ctx, w, adminClient, db)\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1933,6 +2288,15 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \t\treturn err\n \t}\n \n+\t// Command that needs a backup ID.\n+\tif backupCmdFn := backupCommands[cmd]; backupCmdFn != nil {\n+\t\terr := backupCmdFn(ctx, w, adminClient, db, backupID)\n+\t\tif err != nil {\n+\t\t\tfmt.Fprintf(w, \"%s failed with %v\", cmd, err)\n+\t\t}\n+\t\treturn err\n+\t}\n+\n \t// Command that needs to create a new client.\n \tif newClientCmdFn := newClientCommands[cmd]; newClientCmdFn != nil {\n \t\terr := newClientCmdFn(ctx, w, db)",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1957,7 +2321,7 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \n func main() {\n \tflag.Usage = func() {\n-\t\tfmt.Fprintf(os.Stderr, `Usage: spanner_snippets <command> <database_name>\n+\t\tfmt.Fprintf(os.Stderr, `Usage: spanner_snippets <command> <database_name> <backup_id>\n \n \tCommand can be one of: createdatabase, write, query, read, update,\n \t\twritetransaction, addnewcolumn, querynewcolumn, addindex, queryindex, readindex,",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -23,36 +23,23 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/spanner\"\n+\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n-func TestSample(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+type runCommandFunc func(t *testing.T, cmd, dbName string) string\n+type runBackupCommandFunc func(t *testing.T, cmd, dbName, backupID string) string\n \n-\tinstance := os.Getenv(\"GOLANG_SAMPLES_SPANNER\")\n-\tif instance == \"\" {\n-\t\tt.Skip(\"Skipping spanner integration test. Set GOLANG_SAMPLES_SPANNER.\")\n-\t}\n-\tif !strings.HasPrefix(instance, \"projects/\") {\n-\t\tt.Fatal(\"Spanner instance ref must be in the form of 'projects/PROJECT_ID/instances/INSTANCE_ID'\")\n-\t}\n-\tdbName := fmt.Sprintf(\"%s/databases/test-%s\", instance, tc.ProjectID)\n+func initTest(t *testing.T, projectID string) (dbName string, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, runCommand runCommandFunc, mustRunCommand runCommandFunc, cleanup func()) {\n+\tinstance := getInstance(t)\n+\tdatabaseID := validLength(fmt.Sprintf(\"test-%s\", projectID), t)\n+\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, databaseID)\n \n \tctx := context.Background()\n-\tadminClient, dataClient := createClients(ctx, dbName)\n-\tdefer adminClient.Close()\n-\t// The database should be dropped after closing the data client (defer is\n-\t// called in a LIFO order).\n-\tdefer func() {\n-\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n-\t\t\tif err != nil {\n-\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n-\t\t\t}\n-\t\t})\n-\t}()\n-\tdefer dataClient.Close()\n+\tadminClient, dataClient = createClients(ctx, dbName)\n \n \t// Check for database existance prior to test start and delete, as resources may not have\n \t// been cleaned up from previous invocations.",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -61,28 +48,89 @@\nfunc TestSample(t *testing.T) {\n \t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName}))\n \t}\n \n-\tassertContains := func(t *testing.T, out string, sub string) {\n+\trunCommand = func(t *testing.T, cmd, dbName string) string {\n \t\tt.Helper()\n-\t\tif !strings.Contains(out, sub) {\n-\t\t\tt.Errorf(\"got output %q; want it to contain %q\", out, sub)\n+\t\tvar b bytes.Buffer\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, \"\"); err != nil {\n+\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n+\t\treturn b.String()\n \t}\n-\trunCommand := func(t *testing.T, cmd string, dbName string) string {\n+\tmustRunCommand = func(t *testing.T, cmd, dbName string) string {\n \t\tt.Helper()\n \t\tvar b bytes.Buffer\n-\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName); err != nil {\n-\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, \"\"); err != nil {\n+\t\t\tt.Fatalf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n \t\treturn b.String()\n \t}\n-\tmustRunCommand := func(t *testing.T, cmd string, dbName string) string {\n+\tcleanup = func() {\n+\t\tdataClient.Close()\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n+\t\t\t}\n+\t\t})\n+\t\tadminClient.Close()\n+\t}\n+\treturn\n+}\n+\n+func initBackupTest(t *testing.T, projectID, dbName string, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client) (restoreDBName, backupID, cancelledBackupID string, runBackupCommand runBackupCommandFunc, cleanup func()) {\n+\tinstance := getInstance(t)\n+\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", projectID), t)\n+\trestoreDBName = fmt.Sprintf(\"%s/databases/%s\", instance, restoreDatabaseID)\n+\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", projectID), t)\n+\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", projectID), t)\n+\n+\tctx := context.Background()\n+\tif db, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: restoreDBName}); err == nil {\n+\t\tt.Logf(\"database %s exists in state %s. delete result: %v\", db.GetName(), db.GetState().String(),\n+\t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName}))\n+\t}\n+\n+\t// Check for any backups that were created from that database and delete those as well\n+\titer := adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instance,\n+\t\tFilter: \"database:\" + dbName,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"Failed to list backups for database %s: %v\", dbName, err)\n+\t\t}\n+\t\tt.Logf(\"backup %s exists. delete result: %v\", resp.Name,\n+\t\t\tadminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: resp.Name}))\n+\t}\n+\n+\trunBackupCommand = func(t *testing.T, cmd, dbName, backupID string) string {\n \t\tt.Helper()\n \t\tvar b bytes.Buffer\n-\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName); err != nil {\n-\t\t\tt.Fatalf(\"run(%q, %q): %v\", cmd, dbName, err)\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, backupID); err != nil {\n+\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n \t\treturn b.String()\n \t}\n+\tcleanup = func() {\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", restoreDBName, err)\n+\t\t\t}\n+\t\t})\n+\t}\n+\treturn\n+}\n+\n+func TestSample(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tdbName, _, _, runCommand, mustRunCommand, cleanup := initTest(t, tc.ProjectID)\n+\tdefer cleanup()\n \n \t// We execute all the commands of the tutorial code. These commands have to be run in a specific\n \t// order since in many cases earlier commands setup the database for the subsequent commands.",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "storage/buckets/get_bucket_metadata.go",
        "code_diff": "@@ -16,37 +16,34 @@\n// using the Google Storage API. More documentation is available at\n // https://cloud.google.com/storage/docs/json_api/v1/.\n \n-package main\n+package buckets\n \n // [START storage_get_bucket_metadata]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n )\n \n-func getBucketMetadata(w io.Writer, client *storage.Client, bucketName string) (*storage.BucketAttrs, error) {\n+// getBucketMetadata gets the bucket metadata.\n+func getBucketMetadata(w io.Writer, bucketName string) (*storage.BucketAttrs, error) {\n \t// bucketName := \"bucket-name\"\n \tctx := context.Background()\n-\n-\t// Initialize client.\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\treturn nil, fmt.Errorf(\"storage.NewClient: %v\", err)\n \t}\n-\tdefer client.Close() // Closing the client safely cleans up background resources.\n+\tdefer client.Close()\n \n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tattrs, err := client.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn nil, fmt.Errorf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n \t}\n-\n \tfmt.Fprintf(w, \"BucketName: %v\\n\", attrs.Name)\n \tfmt.Fprintf(w, \"Location: %v\\n\", attrs.Location)\n \tfmt.Fprintf(w, \"LocationType: %v\\n\", attrs.LocationType)",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -15,7 +15,9 @@\n// Sample buckets creates a bucket, lists buckets and deletes a bucket\n // using the Google Storage API. More documentation is available at\n // https://cloud.google.com/storage/docs/json_api/v1/.\n-package main\n+// +build ignore\n+\n+package buckets\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -28,6 +30,8 @@\nimport (\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/storage\"\n \t\"google.golang.org/api/iterator\"\n+\tiampb \"google.golang.org/genproto/googleapis/iam/v1\"\n+\t\"google.golang.org/genproto/googleapis/type/expr\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -159,18 +163,18 @@\nfunc deleteBucket(client *storage.Client, bucketName string) error {\n \treturn nil\n }\n \n-func getPolicy(c *storage.Client, bucketName string) (*iam.Policy, error) {\n+func getPolicy(c *storage.Client, bucketName string) (*iam.Policy3, error) {\n \t// [START storage_get_bucket_policy]\n \tctx := context.Background()\n \n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n-\tpolicy, err := c.Bucket(bucketName).IAM().Policy(ctx)\n+\tpolicy, err := c.Bucket(bucketName).IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\tfor _, role := range policy.Roles() {\n-\t\tlog.Printf(\"%q: %q\", role, policy.Members(role))\n+\tfor _, binding := range policy.Bindings {\n+\t\tlog.Printf(\"%q: %q (condition: %v)\", binding.Role, binding.Members, binding.Condition)\n \t}\n \t// [END storage_get_bucket_policy]\n \treturn policy, nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -183,15 +187,18 @@\nfunc addUser(c *storage.Client, bucketName string) error {\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n-\tpolicy, err := bucket.IAM().Policy(ctx)\n+\tpolicy, err := bucket.IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Other valid prefixes are \"serviceAccount:\", \"user:\"\n \t// See the documentation for more values.\n \t// https://cloud.google.com/storage/docs/access-control/iam\n-\tpolicy.Add(\"group:cloud-logs@google.com\", \"roles/storage.objectViewer\")\n-\tif err := bucket.IAM().SetPolicy(ctx, policy); err != nil {\n+\tpolicy.Bindings = append(policy.Bindings, &iampb.Binding{\n+\t\tRole:    \"roles/storage.objectViewer\",\n+\t\tMembers: []string{\"group:cloud-logs@google.com\"},\n+\t})\n+\tif err := bucket.IAM().V3().SetPolicy(ctx, policy); err != nil {\n \t\treturn err\n \t}\n \t// NOTE: It may be necessary to retry this operation if IAM policies are",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -208,15 +215,32 @@\nfunc removeUser(c *storage.Client, bucketName string) error {\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n-\tpolicy, err := bucket.IAM().Policy(ctx)\n+\tpolicy, err := bucket.IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Other valid prefixes are \"serviceAccount:\", \"user:\"\n \t// See the documentation for more values.\n \t// https://cloud.google.com/storage/docs/access-control/iam\n-\tpolicy.Remove(\"group:cloud-logs@google.com\", \"roles/storage.objectViewer\")\n-\tif err := bucket.IAM().SetPolicy(ctx, policy); err != nil {\n+\tfor _, binding := range policy.Bindings {\n+\t\t// Only remove unconditional bindings matching role\n+\t\tif binding.Role == \"roles/storage.objectViewer\" && binding.Condition == nil {\n+\t\t\t// Filter out member.\n+\t\t\ti := -1\n+\t\t\tfor j, member := range binding.Members {\n+\t\t\t\tif member == \"group:cloud-logs@google.com\" {\n+\t\t\t\t\ti = j\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif i == -1 {\n+\t\t\t\treturn errors.New(\"No matching binding group found.\")\n+\t\t\t} else {\n+\t\t\t\tbinding.Members = append(binding.Members[:i], binding.Members[i+1:]...)\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif err := bucket.IAM().V3().SetPolicy(ctx, policy); err != nil {\n \t\treturn err\n \t}\n \t// NOTE: It may be necessary to retry this operation if IAM policies are",
        "comments": [],
        "commit_message": "Merge branch 'master' into publish_with_settings",
        "commit_id": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/go-cmp/cmp\"\n )\n \n var topicID string",
        "comments": [],
        "commit_message": "Merge branch 'master' into prunge/backups-samples-with-restore-premerge",
        "commit_id": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -251,7 +252,7 @@\nfunc TestPullMsgsConcurrencyControl(t *testing.T) {\n \n \t// Publish 5 message to test with.\n \tconst numMsgs = 5\n-\tpublishMsgs(ctx, topic, 5)\n+\tpublishMsgs(ctx, topic, numMsgs)\n \n \tbuf := new(bytes.Buffer)\n \tif err := pullMsgsConcurrenyControl(buf, tc.ProjectID, subIDConc); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into prunge/backups-samples-with-restore-premerge",
        "commit_id": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -28,6 +28,8 @@\nimport (\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/storage\"\n \t\"google.golang.org/api/iterator\"\n+\tiampb \"google.golang.org/genproto/googleapis/iam/v1\"\n+\t\"google.golang.org/genproto/googleapis/type/expr\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into prunge/backups-samples-with-restore-premerge",
        "commit_id": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -159,18 +161,18 @@\nfunc deleteBucket(client *storage.Client, bucketName string) error {\n \treturn nil\n }\n \n-func getPolicy(c *storage.Client, bucketName string) (*iam.Policy, error) {\n+func getPolicy(c *storage.Client, bucketName string) (*iam.Policy3, error) {\n \t// [START storage_get_bucket_policy]\n \tctx := context.Background()\n \n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n-\tpolicy, err := c.Bucket(bucketName).IAM().Policy(ctx)\n+\tpolicy, err := c.Bucket(bucketName).IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\tfor _, role := range policy.Roles() {\n-\t\tlog.Printf(\"%q: %q\", role, policy.Members(role))\n+\tfor _, binding := range policy.Bindings {\n+\t\tlog.Printf(\"%q: %q (condition: %v)\", binding.Role, binding.Members, binding.Condition)\n \t}\n \t// [END storage_get_bucket_policy]\n \treturn policy, nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into prunge/backups-samples-with-restore-premerge",
        "commit_id": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -183,15 +185,18 @@\nfunc addUser(c *storage.Client, bucketName string) error {\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n-\tpolicy, err := bucket.IAM().Policy(ctx)\n+\tpolicy, err := bucket.IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Other valid prefixes are \"serviceAccount:\", \"user:\"\n \t// See the documentation for more values.\n \t// https://cloud.google.com/storage/docs/access-control/iam\n-\tpolicy.Add(\"group:cloud-logs@google.com\", \"roles/storage.objectViewer\")\n-\tif err := bucket.IAM().SetPolicy(ctx, policy); err != nil {\n+\tpolicy.Bindings = append(policy.Bindings, &iampb.Binding{\n+\t\tRole:    \"roles/storage.objectViewer\",\n+\t\tMembers: []string{\"group:cloud-logs@google.com\"},\n+\t})\n+\tif err := bucket.IAM().V3().SetPolicy(ctx, policy); err != nil {\n \t\treturn err\n \t}\n \t// NOTE: It may be necessary to retry this operation if IAM policies are",
        "comments": [],
        "commit_message": "Merge branch 'master' into prunge/backups-samples-with-restore-premerge",
        "commit_id": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -208,15 +213,32 @@\nfunc removeUser(c *storage.Client, bucketName string) error {\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n-\tpolicy, err := bucket.IAM().Policy(ctx)\n+\tpolicy, err := bucket.IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Other valid prefixes are \"serviceAccount:\", \"user:\"\n \t// See the documentation for more values.\n \t// https://cloud.google.com/storage/docs/access-control/iam\n-\tpolicy.Remove(\"group:cloud-logs@google.com\", \"roles/storage.objectViewer\")\n-\tif err := bucket.IAM().SetPolicy(ctx, policy); err != nil {\n+\tfor _, binding := range policy.Bindings {\n+\t\t// Only remove unconditional bindings matching role\n+\t\tif binding.Role == \"roles/storage.objectViewer\" && binding.Condition == nil {\n+\t\t\t// Filter out member.\n+\t\t\ti := -1\n+\t\t\tfor j, member := range binding.Members {\n+\t\t\t\tif member == \"group:cloud-logs@google.com\" {\n+\t\t\t\t\ti = j\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif i == -1 {\n+\t\t\t\treturn errors.New(\"No matching binding group found.\")\n+\t\t\t} else {\n+\t\t\t\tbinding.Members = append(binding.Members[:i], binding.Members[i+1:]...)\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif err := bucket.IAM().V3().SetPolicy(ctx, policy); err != nil {\n \t\treturn err\n \t}\n \t// NOTE: It may be necessary to retry this operation if IAM policies are",
        "comments": [],
        "commit_message": "Merge branch 'master' into prunge/backups-samples-with-restore-premerge",
        "commit_id": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: create admin client for emulator",
        "pr_number": 1278,
        "file_name": "securitycenter/notifications/create_notification_config.go",
        "code_diff": "@@ -19,8 +19,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tsecuritycenter \"cloud.google.com/go/securitycenter/apiv1\"\n-\tsecuritycenterpb \"google.golang.org/genproto/googleapis/cloud/securitycenter/v1\"\n+\tsecuritycenter \"cloud.google.com/go/securitycenter/apiv1p1beta1\"\n+\tsecuritycenterpb \"google.golang.org/genproto/googleapis/cloud/securitycenter/v1p1beta1\"\n )\n \n func createNotificationConfig(w io.Writer, orgID string, pubsubTopic string, notificationConfigID string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-admin-client-for-emulator",
        "commit_id": "c4cae917cebac2baedf6ba4e08ef440359a089c3"
    },
    {
        "pr_title": "spanner: create admin client for emulator",
        "pr_number": 1278,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -28,6 +28,8 @@\nimport (\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"google.golang.org/api/iterator\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n // TestObjects runs all samples tests of the package.",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-admin-client-for-emulator",
        "commit_id": "c4cae917cebac2baedf6ba4e08ef440359a089c3"
    },
    {
        "pr_title": "spanner: create admin client for emulator",
        "pr_number": 1278,
        "file_name": "storage/s3_sdk/list_gcs_buckets_test.go",
        "code_diff": "@@ -28,7 +28,6 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-\n func TestList(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into create-admin-client-for-emulator",
        "commit_id": "c4cae917cebac2baedf6ba4e08ef440359a089c3"
    },
    {
        "pr_title": "all: support Github Actions for linting and tests",
        "pr_number": 1267,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -28,6 +28,8 @@\nimport (\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"google.golang.org/api/iterator\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n // TestObjects runs all samples tests of the package.",
        "comments": [],
        "commit_message": "Merge branch 'master' into codyoss-patch-1",
        "commit_id": "c1599513fa9349c1ba51aaf5f6ddfb2d5fc13865"
    },
    {
        "pr_title": "all: support Github Actions for linting and tests",
        "pr_number": 1267,
        "file_name": "storage/s3_sdk/list_gcs_buckets_test.go",
        "code_diff": "@@ -28,7 +28,6 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-\n func TestList(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into codyoss-patch-1",
        "commit_id": "c1599513fa9349c1ba51aaf5f6ddfb2d5fc13865"
    },
    {
        "pr_title": "all: goimports and fix storage test",
        "pr_number": 1265,
        "file_name": "storage/acl/acl_test.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n // TestACL runs all of the package tests.",
        "comments": [],
        "commit_message": "storage/acl: clean test bucket",
        "commit_id": "cbb8567f8c1e1ec08cf861ab44685333ff3d0042"
    },
    {
        "pr_title": "all: goimports and fix storage test",
        "pr_number": 1265,
        "file_name": "storage/acl/acl_test.go",
        "code_diff": "@@ -41,10 +42,9 @@\nfunc TestACL(t *testing.T) {\n \t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers\n \t)\n \n+\tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n+\n \tb := client.Bucket(bucket)\n-\tif err := b.Create(ctx, tc.ProjectID, nil); err != nil {\n-\t\tt.Fatalf(\"Bucket(%q).Create: %v\", bucket, err)\n-\t}\n \n \t// Upload a test object with storage.Writer.\n \twc := b.Object(object).NewWriter(ctx)",
        "comments": [],
        "commit_message": "storage/acl: clean test bucket",
        "commit_id": "cbb8567f8c1e1ec08cf861ab44685333ff3d0042"
    },
    {
        "pr_title": "storage: use V3 IAM API",
        "pr_number": 1251,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/go-cmp/cmp\"\n )\n \n var topicID string",
        "comments": [],
        "commit_message": "Merge branch 'master' into storagev3",
        "commit_id": "8ea735be002a06c356bfd4d966c4c9b8fd2b28e3"
    },
    {
        "pr_title": "storage: use V3 IAM API",
        "pr_number": 1251,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -251,7 +252,7 @@\nfunc TestPullMsgsConcurrencyControl(t *testing.T) {\n \n \t// Publish 5 message to test with.\n \tconst numMsgs = 5\n-\tpublishMsgs(ctx, topic, 5)\n+\tpublishMsgs(ctx, topic, numMsgs)\n \n \tbuf := new(bytes.Buffer)\n \tif err := pullMsgsConcurrenyControl(buf, tc.ProjectID, subIDConc); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into storagev3",
        "commit_id": "8ea735be002a06c356bfd4d966c4c9b8fd2b28e3"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files (buckets part)",
        "pr_number": 1249,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -28,18 +28,25 @@\nimport (\n \n \t\"cloud.google.com/go/civil\"\n \t\"cloud.google.com/go/spanner\"\n-\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n+\t\"github.com/golang/protobuf/ptypes\"\n \t\"google.golang.org/api/iterator\"\n \t\"google.golang.org/api/option\"\n+\t\"google.golang.org/genproto/googleapis/longrunning\"\n \t\"google.golang.org/grpc\"\n+\t\"google.golang.org/grpc/codes\"\n \n+\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n+\tpbts \"github.com/golang/protobuf/ptypes\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n \tsppb \"google.golang.org/genproto/googleapis/spanner/v1\"\n+\t\"google.golang.org/genproto/protobuf/field_mask\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n type command func(ctx context.Context, w io.Writer, client *spanner.Client) error\n type newClientCommand func(ctx context.Context, w io.Writer, database string) error\n type adminCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error\n+type backupCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error\n \n var (\n \tcommands = map[string]command{",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples",
        "commit_id": "6f2852d3810b5ebfba12c872372847cbb655c719"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files (buckets part)",
        "pr_number": 1249,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -109,6 +116,17 @@\nvar (\n \t\t\"createtablewithdatatypes\":        createTableWithDatatypes,\n \t\t\"createtabledocswithtimestamp\":    createTableDocumentsWithTimestamp,\n \t\t\"createtabledocswithhistorytable\": createTableDocumentsWithHistoryTable,\n+\t\t\"listbackupoperations\":            listBackupOperations,\n+\t\t\"listdatabaseoperations\":          listDatabaseOperations,\n+\t}\n+\n+\tbackupCommands = map[string]backupCommand{\n+\t\t\"createbackup\":  createBackup,\n+\t\t\"cancelbackup\":  cancelBackup,\n+\t\t\"listbackups\":   listBackups,\n+\t\t\"updatebackup\":  updateBackup,\n+\t\t\"deletebackup\":  deleteBackup,\n+\t\t\"restorebackup\": restoreBackup,\n \t}\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples",
        "commit_id": "6f2852d3810b5ebfba12c872372847cbb655c719"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files (buckets part)",
        "pr_number": 1249,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1894,6 +1912,343 @@\nfunc createClientWithQueryOptions(ctx context.Context, w io.Writer, database str\n \n // [END spanner_create_client_with_query_options]\n \n+// [START spanner_create_backup]\n+\n+func createBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\texpireTime := time.Now().AddDate(0, 0, 14)\n+\t// Create a backup.\n+\top, err := adminClient.StartBackupOperation(ctx, backupID, database, expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Wait for backup operation to complete.\n+\tbackup, err := op.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Get the name, create time and backup size.\n+\tcreateTime := time.Unix(backup.CreateTime.Seconds, int64(backup.CreateTime.Nanos))\n+\tfmt.Fprintf(w, \"Backup %s of size %d bytes was created at %s\\n\", backup.Name, backup.SizeBytes, createTime.Format(time.RFC3339))\n+\treturn nil\n+}\n+\n+// [END spanner_create_backup]\n+\n+// [START spanner_cancel_backup_create]\n+\n+func cancelBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\texpireTime := time.Now().AddDate(0, 0, 14)\n+\t// Create a backup.\n+\top, err := adminClient.StartBackupOperation(ctx, backupID, database, expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Cancel backup creation.\n+\terr = adminClient.LROClient.CancelOperation(ctx, &longrunning.CancelOperationRequest{Name: op.Name()})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Cancel operations are best effort so either it will complete or be\n+\t// cancelled.\n+\tbackup, err := op.Wait(ctx)\n+\tif err != nil {\n+\t\tif waitStatus, ok := status.FromError(err); !ok || waitStatus.Code() != codes.Canceled {\n+\t\t\treturn err\n+\t\t}\n+\t} else {\n+\t\t// Backup was completed before it could be cancelled so delete the\n+\t\t// unwanted backup.\n+\t\terr = adminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: backup.Name})\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\tfmt.Fprintf(w, \"Backup cancelled.\\n\")\n+\treturn nil\n+}\n+\n+// [END spanner_cancel_backup_create]\n+\n+// [START spanner_list_backups]\n+\n+func listBackups(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, db, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(db)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", db)\n+\t}\n+\tinstanceName := matches[1]\n+\n+\tprintBackups := func(iter *database.BackupIterator) error {\n+\t\tfor {\n+\t\t\tresp, err := iter.Next()\n+\t\t\tif err == iterator.Done {\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t\tif err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tfmt.Fprintf(w, \"Backup %s\\n\", resp.Name)\n+\t\t}\n+\t}\n+\n+\tvar iter *database.BackupIterator\n+\tvar filter string\n+\t// List all backups.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups that contain a name.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"name:\" + backupID,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups that expire before a timestamp.\n+\texpireTime := time.Now().AddDate(0, 0, 30)\n+\tfilter = fmt.Sprintf(`expire_time < \"%s\"`, expireTime.Format(time.RFC3339))\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups for a database that contains a name.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"database:\" + db,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups with a size greater than some bytes.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"size_bytes > 100\",\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List backups that were created after a timestamp that are also ready.\n+\tcreateTime := time.Now().AddDate(0, 0, -1)\n+\tfilter = fmt.Sprintf(\n+\t\t`create_time >= \"%s\" AND state:READY`,\n+\t\tcreateTime.Format(time.RFC3339),\n+\t)\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List backups with pagination.\n+\trequest := &adminpb.ListBackupsRequest{\n+\t\tParent:   instanceName,\n+\t\tPageSize: 10,\n+\t}\n+\tfor {\n+\t\titer = adminClient.ListBackups(ctx, request)\n+\t\tif err := printBackups(iter); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tpageToken := iter.PageInfo().Token\n+\t\tif pageToken == \"\" {\n+\t\t\tbreak\n+\t\t} else {\n+\t\t\trequest.PageToken = pageToken\n+\t\t}\n+\t}\n+\n+\tfmt.Fprintf(w, \"Backups listed.\\n\")\n+\treturn nil\n+}\n+\n+// [END spanner_list_backups]\n+\n+// [START spanner_list_backup_operations]\n+\n+func listBackupOperations(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\t// List the CreateBackup operations.\n+\tfilter := fmt.Sprintf(\"(metadata.database:%s) AND (metadata.@type:type.googleapis.com/google.spanner.admin.database.v1.CreateBackupMetadata)\", database)\n+\titer := adminClient.ListBackupOperations(ctx, &adminpb.ListBackupOperationsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tmetadata := &adminpb.CreateBackupMetadata{}\n+\t\tif err := ptypes.UnmarshalAny(resp.Metadata, metadata); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"Backup %s on database %s is %d%% complete.\\n\",\n+\t\t\tmetadata.Name,\n+\t\t\tmetadata.Database,\n+\t\t\tmetadata.Progress.ProgressPercent,\n+\t\t)\n+\t}\n+\treturn nil\n+}\n+\n+// [END spanner_list_backup_operations]\n+\n+// [START spanner_list_database_operations]\n+\n+func listDatabaseOperations(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\t// List the databases that are being optimized after a restore operation.\n+\tfilter := \"(metadata.@type:type.googleapis.com/google.spanner.admin.database.v1.OptimizeRestoredDatabaseMetadata)\"\n+\titer := adminClient.ListDatabaseOperations(ctx, &adminpb.ListDatabaseOperationsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tmetadata := &adminpb.OptimizeRestoredDatabaseMetadata{}\n+\t\tif err := ptypes.UnmarshalAny(resp.Metadata, metadata); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"Database %s restored from backup is %d%% optimized.\\n\",\n+\t\t\tmetadata.Name,\n+\t\t\tmetadata.Progress.ProgressPercent,\n+\t\t)\n+\t}\n+\treturn nil\n+}\n+\n+// [END spanner_list_database_operations]\n+\n+// [START spanner_update_backup]\n+\n+func updateBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tbackupName := matches[1] + \"/backups/\" + backupID\n+\n+\tbackup, err := adminClient.GetBackup(ctx, &adminpb.GetBackupRequest{Name: backupName})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Expire time must be within 366 days of the create time of the backup.\n+\texpireTime := time.Unix(backup.CreateTime.Seconds, int64(backup.CreateTime.Nanos)).AddDate(0, 0, 30)\n+\texpirespb, err := pbts.TimestampProto(expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t_, err = adminClient.UpdateBackup(ctx, &adminpb.UpdateBackupRequest{\n+\t\tBackup: &adminpb.Backup{\n+\t\t\tName:       backupName,\n+\t\t\tExpireTime: expirespb,\n+\t\t},\n+\t\tUpdateMask: &field_mask.FieldMask{Paths: []string{\"expire_time\"}},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Fprintf(w, \"Updated backup %s\\n\", backupID)\n+\treturn nil\n+}\n+\n+// [END spanner_update_backup]\n+\n+// [START spanner_restore_backup]\n+\n+func restoreBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\tdatabaseID := matches[2]\n+\tbackupName := instanceName + \"/backups/\" + backupID\n+\n+\t// Start restoring backup to a new database.\n+\trestoreOp, err := adminClient.RestoreDatabase(ctx, &adminpb.RestoreDatabaseRequest{\n+\t\tParent:     instanceName,\n+\t\tDatabaseId: databaseID,\n+\t\tSource: &adminpb.RestoreDatabaseRequest_Backup{\n+\t\t\tBackup: backupName,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Wait for restore operation to complete.\n+\tdb, err := restoreOp.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Newly created database has restore information.\n+\tbackupInfo := db.RestoreInfo.GetBackupInfo()\n+\tif backupInfo != nil {\n+\t\tfmt.Fprintf(w, \"Source database %s restored from backup %s\\n\", backupInfo.SourceDatabase, backupInfo.Backup)\n+\t}\n+\n+\treturn nil\n+}\n+\n+// [END spanner_restore_backup]\n+\n+// [START spanner_delete_backup]\n+\n+func deleteBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tbackupName := matches[1] + \"/backups/\" + backupID\n+\t// Delete the backup.\n+\terr := adminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: backupName})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Deleted backup %s\\n\", backupID)\n+\treturn nil\n+}\n+\n+// [END spanner_delete_backup]\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \t// [START spanner_create_admin_client_for_emulator]",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples",
        "commit_id": "6f2852d3810b5ebfba12c872372847cbb655c719"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files (buckets part)",
        "pr_number": 1249,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1924,7 +2279,7 @@\nfunc createClients(ctx context.Context, db string) (*database.DatabaseAdminClien\n \treturn adminClient, dataClient\n }\n \n-func run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, w io.Writer, cmd string, db string) error {\n+func run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, w io.Writer, cmd string, db string, backupID string) error {\n \tif adminCmdFn := adminCommands[cmd]; adminCmdFn != nil {\n \t\terr := adminCmdFn(ctx, w, adminClient, db)\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples",
        "commit_id": "6f2852d3810b5ebfba12c872372847cbb655c719"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files (buckets part)",
        "pr_number": 1249,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1933,6 +2288,15 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \t\treturn err\n \t}\n \n+\t// Command that needs a backup ID.\n+\tif backupCmdFn := backupCommands[cmd]; backupCmdFn != nil {\n+\t\terr := backupCmdFn(ctx, w, adminClient, db, backupID)\n+\t\tif err != nil {\n+\t\t\tfmt.Fprintf(w, \"%s failed with %v\", cmd, err)\n+\t\t}\n+\t\treturn err\n+\t}\n+\n \t// Command that needs to create a new client.\n \tif newClientCmdFn := newClientCommands[cmd]; newClientCmdFn != nil {\n \t\terr := newClientCmdFn(ctx, w, db)",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples",
        "commit_id": "6f2852d3810b5ebfba12c872372847cbb655c719"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files (buckets part)",
        "pr_number": 1249,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1957,7 +2321,7 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \n func main() {\n \tflag.Usage = func() {\n-\t\tfmt.Fprintf(os.Stderr, `Usage: spanner_snippets <command> <database_name>\n+\t\tfmt.Fprintf(os.Stderr, `Usage: spanner_snippets <command> <database_name> <backup_id>\n \n \tCommand can be one of: createdatabase, write, query, read, update,\n \t\twritetransaction, addnewcolumn, querynewcolumn, addindex, queryindex, readindex,",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples",
        "commit_id": "6f2852d3810b5ebfba12c872372847cbb655c719"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files (buckets part)",
        "pr_number": 1249,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -23,36 +23,23 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/spanner\"\n+\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n-func TestSample(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+type runCommandFunc func(t *testing.T, cmd, dbName string) string\n+type runBackupCommandFunc func(t *testing.T, cmd, dbName, backupID string) string\n \n-\tinstance := os.Getenv(\"GOLANG_SAMPLES_SPANNER\")\n-\tif instance == \"\" {\n-\t\tt.Skip(\"Skipping spanner integration test. Set GOLANG_SAMPLES_SPANNER.\")\n-\t}\n-\tif !strings.HasPrefix(instance, \"projects/\") {\n-\t\tt.Fatal(\"Spanner instance ref must be in the form of 'projects/PROJECT_ID/instances/INSTANCE_ID'\")\n-\t}\n-\tdbName := fmt.Sprintf(\"%s/databases/test-%s\", instance, tc.ProjectID)\n+func initTest(t *testing.T, projectID string) (dbName string, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, runCommand runCommandFunc, mustRunCommand runCommandFunc, cleanup func()) {\n+\tinstance := getInstance(t)\n+\tdatabaseID := validLength(fmt.Sprintf(\"test-%s\", projectID), t)\n+\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, databaseID)\n \n \tctx := context.Background()\n-\tadminClient, dataClient := createClients(ctx, dbName)\n-\tdefer adminClient.Close()\n-\t// The database should be dropped after closing the data client (defer is\n-\t// called in a LIFO order).\n-\tdefer func() {\n-\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n-\t\t\tif err != nil {\n-\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n-\t\t\t}\n-\t\t})\n-\t}()\n-\tdefer dataClient.Close()\n+\tadminClient, dataClient = createClients(ctx, dbName)\n \n \t// Check for database existance prior to test start and delete, as resources may not have\n \t// been cleaned up from previous invocations.",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples",
        "commit_id": "6f2852d3810b5ebfba12c872372847cbb655c719"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files (buckets part)",
        "pr_number": 1249,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -61,28 +48,89 @@\nfunc TestSample(t *testing.T) {\n \t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName}))\n \t}\n \n-\tassertContains := func(t *testing.T, out string, sub string) {\n+\trunCommand = func(t *testing.T, cmd, dbName string) string {\n \t\tt.Helper()\n-\t\tif !strings.Contains(out, sub) {\n-\t\t\tt.Errorf(\"got output %q; want it to contain %q\", out, sub)\n+\t\tvar b bytes.Buffer\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, \"\"); err != nil {\n+\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n+\t\treturn b.String()\n \t}\n-\trunCommand := func(t *testing.T, cmd string, dbName string) string {\n+\tmustRunCommand = func(t *testing.T, cmd, dbName string) string {\n \t\tt.Helper()\n \t\tvar b bytes.Buffer\n-\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName); err != nil {\n-\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, \"\"); err != nil {\n+\t\t\tt.Fatalf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n \t\treturn b.String()\n \t}\n-\tmustRunCommand := func(t *testing.T, cmd string, dbName string) string {\n+\tcleanup = func() {\n+\t\tdataClient.Close()\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n+\t\t\t}\n+\t\t})\n+\t\tadminClient.Close()\n+\t}\n+\treturn\n+}\n+\n+func initBackupTest(t *testing.T, projectID, dbName string, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client) (restoreDBName, backupID, cancelledBackupID string, runBackupCommand runBackupCommandFunc, cleanup func()) {\n+\tinstance := getInstance(t)\n+\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", projectID), t)\n+\trestoreDBName = fmt.Sprintf(\"%s/databases/%s\", instance, restoreDatabaseID)\n+\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", projectID), t)\n+\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", projectID), t)\n+\n+\tctx := context.Background()\n+\tif db, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: restoreDBName}); err == nil {\n+\t\tt.Logf(\"database %s exists in state %s. delete result: %v\", db.GetName(), db.GetState().String(),\n+\t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName}))\n+\t}\n+\n+\t// Check for any backups that were created from that database and delete those as well\n+\titer := adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instance,\n+\t\tFilter: \"database:\" + dbName,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"Failed to list backups for database %s: %v\", dbName, err)\n+\t\t}\n+\t\tt.Logf(\"backup %s exists. delete result: %v\", resp.Name,\n+\t\t\tadminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: resp.Name}))\n+\t}\n+\n+\trunBackupCommand = func(t *testing.T, cmd, dbName, backupID string) string {\n \t\tt.Helper()\n \t\tvar b bytes.Buffer\n-\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName); err != nil {\n-\t\t\tt.Fatalf(\"run(%q, %q): %v\", cmd, dbName, err)\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, backupID); err != nil {\n+\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n \t\treturn b.String()\n \t}\n+\tcleanup = func() {\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", restoreDBName, err)\n+\t\t\t}\n+\t\t})\n+\t}\n+\treturn\n+}\n+\n+func TestSample(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tdbName, _, _, runCommand, mustRunCommand, cleanup := initTest(t, tc.ProjectID)\n+\tdefer cleanup()\n \n \t// We execute all the commands of the tutorial code. These commands have to be run in a specific\n \t// order since in many cases earlier commands setup the database for the subsequent commands.",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples",
        "commit_id": "6f2852d3810b5ebfba12c872372847cbb655c719"
    },
    {
        "pr_title": "spanner: add a sleep time to fix the flaky test.",
        "pr_number": 1242,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -42,6 +42,16 @@\nfunc TestSample(t *testing.T) {\n \tctx := context.Background()\n \tadminClient, dataClient := createClients(ctx, dbName)\n \tdefer adminClient.Close()\n+\t// The database should be dropped after closing the data client (defer is\n+\t// called in a LIFO order).\n+\tdefer func() {\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n+\t\t\t}\n+\t\t})\n+\t}()\n \tdefer dataClient.Close()\n \n \t// Check for database existance prior to test start and delete, as resources may not have",
        "comments": [
            {
                "comment": "Would you mind linking to the issue in this comment? Would be nice to have the extra context.",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'master' into fix-flaky-test-due-to-time-drift",
        "commit_id": "4d810d146f1cba64dd2b72b7e06d4e29845949f6"
    },
    {
        "pr_title": "speech: add speech adaptation sample",
        "pr_number": 1229,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -42,6 +42,16 @@\nfunc TestSample(t *testing.T) {\n \tctx := context.Background()\n \tadminClient, dataClient := createClients(ctx, dbName)\n \tdefer adminClient.Close()\n+\t// The database should be dropped after closing the data client (defer is\n+\t// called in a LIFO order).\n+\tdefer func() {\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n+\t\t\t}\n+\t\t})\n+\t}()\n \tdefer dataClient.Close()\n \n \t// Check for database existance prior to test start and delete, as resources may not have",
        "comments": [],
        "commit_message": "Merge branch 'master' into speech-adaptation",
        "commit_id": "6ebbc79c34a5adb0e9906ef62c1a9b47c20b6302"
    },
    {
        "pr_title": "speech: add speech adaptation sample",
        "pr_number": 1229,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -74,15 +84,6 @@\nfunc TestSample(t *testing.T) {\n \t\treturn b.String()\n \t}\n \n-\tdefer func() {\n-\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n-\t\t\tif err != nil {\n-\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n-\t\t\t}\n-\t\t})\n-\t}()\n-\n \t// We execute all the commands of the tutorial code. These commands have to be run in a specific\n \t// order since in many cases earlier commands setup the database for the subsequent commands.\n \tmustRunCommand(t, \"createdatabase\", dbName)",
        "comments": [],
        "commit_message": "Merge branch 'master' into speech-adaptation",
        "commit_id": "6ebbc79c34a5adb0e9906ef62c1a9b47c20b6302"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -33,11 +33,11 @@\nimport (\n \t\"sync\"\n \t\"time\"\n \n-\tbqStorage \"cloud.google.com/go/bigquery/storage/apiv1beta1\"\n+\tbqStorage \"cloud.google.com/go/bigquery/storage/apiv1\"\n \t\"github.com/golang/protobuf/ptypes\"\n \tgax \"github.com/googleapis/gax-go/v2\"\n \tgoavro \"github.com/linkedin/goavro/v2\"\n-\tbqStoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1beta1\"\n+\tbqStoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1\"\n \t\"google.golang.org/grpc\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -59,11 +59,11 @@\nvar (\n func main() {\n \tflag.Parse()\n \tctx := context.Background()\n-\tbqStorageClient, err := bqStorage.NewBigQueryStorageClient(ctx)\n+\tbqReadClient, err := bqStorage.NewBigQueryReadClient(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"NewBigQueryStorageClient: %v\", err)\n \t}\n-\tdefer bqStorageClient.Close()\n+\tdefer bqReadClient.Close()\n \n \t// Verify we've been provided a parent project which will contain the read session.  The\n \t// session may exist in a different project than the table being read.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -72,31 +72,33 @@\nfunc main() {\n \t}\n \n \t// This example uses baby name data from the public datasets.\n-\treadTable := &bqStoragepb.TableReference{\n-\t\tProjectId: \"bigquery-public-data\",\n-\t\tDatasetId: \"usa_names\",\n-\t\tTableId:   \"usa_1910_current\",\n-\t}\n+\tsrcProjectID := \"bigquery-public-data\"\n+\tsrcDatasetID := \"usa_names\"\n+\tsrcTableID := \"usa_1910_current\"\n+\treadTable := fmt.Sprintf(\"projects/%s/datasets/%s/tables/%s\",\n+\t\tsrcProjectID,\n+\t\tsrcDatasetID,\n+\t\tsrcTableID,\n+\t)\n \n \t// We limit the output columns to a subset of those allowed in the table,\n \t// and set a simple filter to only report names from the state of\n \t// Washington (WA).\n-\ttableReadOptions := &bqStoragepb.TableReadOptions{\n+\ttableReadOptions := &bqStoragepb.ReadSession_TableReadOptions{\n \t\tSelectedFields: []string{\"name\", \"number\", \"state\"},\n \t\tRowRestriction: `state = \"WA\"`,\n \t}\n \n-\treadSessionRequest := &bqStoragepb.CreateReadSessionRequest{\n-\t\tParent:         fmt.Sprintf(\"projects/%s\", *projectID),\n-\t\tTableReference: readTable,\n-\t\tReadOptions:    tableReadOptions,\n-\t\t// This API can also deliver data serialized in Apache Arrow format.\n-\t\t// This example leverages Apache Avro.\n-\t\tFormat: bqStoragepb.DataFormat_AVRO,\n-\t\t// We use a LIQUID strategy in this example because we only\n-\t\t// read from a single stream.  Consider BALANCED if you're consuming\n-\t\t// multiple streams concurrently and want more consistent stream sizes.\n-\t\tShardingStrategy: bqStoragepb.ShardingStrategy_LIQUID,\n+\tcreateReadSessionRequest := &bqStoragepb.CreateReadSessionRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%s\", *projectID),\n+\t\tReadSession: &bqStoragepb.ReadSession{\n+\t\t\tTable: readTable,\n+\t\t\t// This API can also deliver data serialized in Apache Arrow format.\n+\t\t\t// This example leverages Apache Avro.\n+\t\t\tDataFormat:  bqStoragepb.DataFormat_AVRO,\n+\t\t\tReadOptions: tableReadOptions,\n+\t\t},\n+\t\tMaxStreamCount: 1,\n \t}\n \n \t// Set a snapshot time if it's been specified.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -105,13 +107,13 @@\nfunc main() {\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"Invalid snapshot millis (%d): %v\", *snapshotMillis, err)\n \t\t}\n-\t\treadSessionRequest.TableModifiers = &bqStoragepb.TableModifiers{\n+\t\tcreateReadSessionRequest.ReadSession.TableModifiers = &bqStoragepb.ReadSession_TableModifiers{\n \t\t\tSnapshotTime: ts,\n \t\t}\n \t}\n \n \t// Create the session from the request.\n-\tsession, err := bqStorageClient.CreateReadSession(ctx, readSessionRequest, rpcOpts)\n+\tsession, err := bqReadClient.CreateReadSession(ctx, createReadSessionRequest, rpcOpts)\n \tif err != nil {\n \t\tlog.Fatalf(\"CreateReadSession: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -123,8 +125,8 @@\nfunc main() {\n \t// We'll use only a single stream for reading data from the table.  Because\n \t// of dynamic sharding, this will yield all the rows in the table. However,\n \t// if you wanted to fan out multiple readers you could do so by having a\n-\t// reader process each individual stream.\n-\treadStream := session.GetStreams()[0]\n+\t// increasing the MaxStreamCount.\n+\treadStream := session.GetStreams()[0].Name\n \n \tch := make(chan *bqStoragepb.AvroRows)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -135,7 +137,7 @@\nfunc main() {\n \twg.Add(1)\n \tgo func() {\n \t\tdefer wg.Done()\n-\t\tif err := processStream(ctx, bqStorageClient, readStream, ch); err != nil {\n+\t\tif err := processStream(ctx, bqReadClient, readStream, ch); err != nil {\n \t\t\tlog.Fatalf(\"processStream failure: %v\", err)\n \t\t}\n \t\tclose(ch)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -197,7 +199,7 @@\nfunc valueFromTypeMap(field interface{}) interface{} {\n // data blocks to a channel. This function will retry on transient stream\n // failures and bookmark progress to avoid re-reading data that's already been\n // successfully transmitted.\n-func processStream(ctx context.Context, client *bqStorage.BigQueryStorageClient, st *bqStoragepb.Stream, ch chan<- *bqStoragepb.AvroRows) error {\n+func processStream(ctx context.Context, client *bqStorage.BigQueryReadClient, st string, ch chan<- *bqStoragepb.AvroRows) error {\n \tvar offset int64\n \n \t// Streams may be long-running.  Rather than using a global retry for the",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -31,13 +31,23 @@\nimport (\n // [END bigquery_simple_app_deps]\n \n func main() {\n-\tproj := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n-\tif proj == \"\" {\n+\tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n+\tif projectID == \"\" {\n \t\tfmt.Println(\"GOOGLE_CLOUD_PROJECT environment variable must be set.\")\n \t\tos.Exit(1)\n \t}\n \n-\trows, err := query(proj)\n+\t// [START bigquery_simple_app_client]\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"bigquery.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\t// [END bigquery_simple_app_client]\n+\n+\trows, err := query(ctx, client)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -46,16 +56,8 @@\nfunc main() {\n \t}\n }\n \n-// query returns a slice of the results of a query.\n-func query(proj string) (*bigquery.RowIterator, error) {\n-\t// [START bigquery_simple_app_client]\n-\tctx := context.Background()\n-\n-\tclient, err := bigquery.NewClient(ctx, proj)\n-\tif err != nil {\n-\t\treturn nil, err\n-\t}\n-\t// [END bigquery_simple_app_client]\n+// query returns a row iterator suitable for reading query results.\n+func query(ctx context.Context, client *bigquery.Client) (*bigquery.RowIterator, error) {\n \n \t// [START bigquery_simple_app_query]\n \tquery := client.Query(",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -18,16 +18,17 @@\npackage job\n \n import (\n-\t\"cloud.google.com/go/bigquery\"\n-\t\"cloud.google.com/go/storage\"\n \t\"context\"\n \t\"fmt\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/bigquery/snippets/bqtestutil\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"google.golang.org/api/iterator\"\n \t\"io/ioutil\"\n \t\"testing\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/bigquery\"\n+\t\"cloud.google.com/go/storage\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/bigquery/snippets/bqtestutil\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n func TestJobs(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -38,6 +39,7 @@\nfunc TestJobs(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\tdefer client.Close()\n \n \t// Control a job lifecycle explicitly: create, report status, cancel.\n \texampleJobID, err := bqtestutil.UniqueBQName(\"golang_example_job\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -67,6 +69,7 @@\nfunc TestCopiesAndExtracts(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\tdefer client.Close()\n \n \tmeta := &bigquery.DatasetMetadata{\n \t\tLocation: \"US\", // See https://cloud.google.com/bigquery/docs/locations",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/snippets/querying/bigquery_query_clustered_table.go",
        "code_diff": "@@ -16,11 +16,12 @@\npackage querying\n \n // [START bigquery_query_clustered_table]\n import (\n-\t\"cloud.google.com/go/bigquery\"\n \t\"context\"\n \t\"fmt\"\n-\t\"google.golang.org/api/iterator\"\n \t\"io\"\n+\n+\t\"cloud.google.com/go/bigquery\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n // queryClusteredTable demonstrates querying a table that has a clustering specification.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "bigquery/snippets/table/bigquery_table_insert_rows.go",
        "code_diff": "@@ -29,11 +29,12 @@\ntype Item struct {\n }\n \n // Save implements the ValueSaver interface.\n+// This example disables best-effort de-duplication, which allows for higher throughput.\n func (i *Item) Save() (map[string]bigquery.Value, string, error) {\n \treturn map[string]bigquery.Value{\n \t\t\"full_name\": i.Name,\n \t\t\"age\":       i.Age,\n-\t}, \"\", nil\n+\t}, bigquery.NoDedupeID, nil\n }\n \n // insertRows demonstrates inserting data into a table using the streaming insert mechanism.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "iam/quickstart/quickstart.go",
        "code_diff": "@@ -21,21 +21,15 @@\nimport (\n \t\"context\"\n \t\"log\"\n \n-\t\"golang.org/x/oauth2/google\"\n \t\"google.golang.org/api/iam/v1\"\n )\n \n func main() {\n-\t// Get credentials.\n-\tclient, err := google.DefaultClient(context.Background(), iam.CloudPlatformScope)\n-\tif err != nil {\n-\t\tlog.Fatalf(\"google.DefaultClient: %v\", err)\n-\t}\n-\n \t// Create the Cloud IAM service object.\n-\tservice, err := iam.New(client)\n+\tctx := context.Background()\n+\tservice, err := iam.NewService(ctx)\n \tif err != nil {\n-\t\tlog.Fatalf(\"iam.New: %v\", err)\n+\t\tlog.Fatalf(\"iam.NewService: %v\", err)\n \t}\n \n \t// Call the Cloud IAM Roles API.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -42,6 +42,16 @@\nfunc TestSample(t *testing.T) {\n \tctx := context.Background()\n \tadminClient, dataClient := createClients(ctx, dbName)\n \tdefer adminClient.Close()\n+\t// The database should be dropped after closing the data client (defer is\n+\t// called in a LIFO order).\n+\tdefer func() {\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n+\t\t\t}\n+\t\t})\n+\t}()\n \tdefer dataClient.Close()\n \n \t// Check for database existance prior to test start and delete, as resources may not have",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -74,15 +84,6 @@\nfunc TestSample(t *testing.T) {\n \t\treturn b.String()\n \t}\n \n-\tdefer func() {\n-\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n-\t\t\tif err != nil {\n-\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n-\t\t\t}\n-\t\t})\n-\t}()\n-\n \t// We execute all the commands of the tutorial code. These commands have to be run in a specific\n \t// order since in many cases earlier commands setup the database for the subsequent commands.\n \tmustRunCommand(t, \"createdatabase\", dbName)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -12,65 +12,58 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package objects\n \n import (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n-\t\"log\"\n \t\"net/http\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n-\t\"google.golang.org/api/iterator\"\n-\n \t\"cloud.google.com/go/storage\"\n-\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n-func TestMain(m *testing.M) {\n-\t// These functions are noisy.\n-\tlog.SetOutput(ioutil.Discard)\n-\ts := m.Run()\n-\tlog.SetOutput(os.Stderr)\n-\tos.Exit(s)\n-}\n+// TestObjects runs all samples tests of the package.\n func TestObjects(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tvar (\n-\t\tbucket    = tc.ProjectID + \"-samples-object-bucket-1\"\n-\t\tdstBucket = tc.ProjectID + \"-samples-object-bucket-2\"\n-\n-\t\tobject1 = \"foo.txt\"\n-\t\tobject2 = \"foo/a.txt\"\n+\t\tbucket                = tc.ProjectID + \"-samples-object-bucket-1\"\n+\t\tdstBucket             = tc.ProjectID + \"-samples-object-bucket-2\"\n+\t\tobject1               = \"foo.txt\"\n+\t\tobject2               = \"foo/a.txt\"\n+\t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers\n+\t\troleReader            = storage.RoleReader\n \t)\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n \tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n \n-\tif err := write(client, bucket, object1); err != nil {\n-\t\tt.Fatalf(\"write(%q): %v\", object1, err)\n+\tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n \t}\n-\tif err := write(client, bucket, object2); err != nil {\n-\t\tt.Fatalf(\"write(%q): %v\", object2, err)\n+\tif err := uploadFile(ioutil.Discard, bucket, object2); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object2, err)\n \t}\n \n \t{\n \t\t// Should only show \"foo/a.txt\", not \"foo.txt\"\n \t\tvar buf bytes.Buffer\n-\t\tif err := list(&buf, client, bucket); err != nil {\n-\t\t\tt.Fatalf(\"cannot list objects: %v\", err)\n+\t\tif err := listFiles(&buf, bucket); err != nil {\n+\t\t\tt.Fatalf(\"listFiles: %v\", err)\n \t\t}\n \t\tif got, want := buf.String(), object1; !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"List() got %q; want to contain %q\", got, want)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -84,8 +77,8 @@\nfunc TestObjects(t *testing.T) {\n \t\t// Should only show \"foo/a.txt\", not \"foo.txt\"\n \t\tconst prefix = \"foo/\"\n \t\tvar buf bytes.Buffer\n-\t\tif err := listByPrefix(&buf, client, bucket, prefix, \"\"); err != nil {\n-\t\t\tt.Fatalf(\"cannot list objects by prefix: %v\", err)\n+\t\tif err := listFilesWithPrefix(&buf, bucket, prefix, \"\"); err != nil {\n+\t\t\tt.Fatalf(\"listFilesWithPrefix: %v\", err)\n \t\t}\n \t\tif got, want := buf.String(), object1; strings.Contains(got, want) {\n \t\t\tt.Errorf(\"List(%q) got %q; want NOT to contain %q\", prefix, got, want)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -95,101 +88,79 @@\nfunc TestObjects(t *testing.T) {\n \t\t}\n \t}\n \n-\tdata, err := read(client, bucket, object1)\n+\t{\n+\t\tif err := downloadUsingRequesterPays(ioutil.Discard, bucket, object1, tc.ProjectID); err != nil {\n+\t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)\n+\t\t}\n+\t}\n+\n+\tdata, err := downloadFile(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Fatalf(\"cannot read object: %v\", err)\n+\t\tt.Fatalf(\"downloadFile: %v\", err)\n \t}\n \tif got, want := string(data), \"Hello\\nworld\"; got != want {\n \t\tt.Errorf(\"contents = %q; want %q\", got, want)\n \t}\n-\t_, err = attrs(client, bucket, object1)\n+\n+\t_, err = getMetadata(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n-\tif err := makePublic(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot to make object public: %v\", err)\n+\tif err := makePublic(ioutil.Discard, bucket, object1, allAuthenticatedUsers, roleReader); err != nil {\n+\t\tt.Errorf(\"makePublic: %v\", err)\n \t}\n-\terr = move(client, bucket, object1)\n+\n+\terr = moveFile(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Fatalf(\"cannot move object: %v\", err)\n+\t\tt.Fatalf(\"moveFile: %v\", err)\n \t}\n \t// object1's new name.\n \tobject1 = object1 + \"-rename\"\n \n-\tif err := copyToBucket(client, dstBucket, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot copy object to bucket: %v\", err)\n-\t}\n-\tif err := addBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot add bucket acl: %v\", err)\n-\t}\n-\tif err := addDefaultBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot add bucket default acl: %v\", err)\n-\t}\n-\tif err := bucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot get bucket acl: %v\", err)\n-\t}\n-\tif err := bucketACLFiltered(client, bucket, storage.AllAuthenticatedUsers); err != nil {\n-\t\tt.Errorf(\"cannot filter bucket acl: %v\", err)\n-\t}\n-\tif err := deleteDefaultBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot delete bucket default acl: %v\", err)\n-\t}\n-\tif err := deleteBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot delete bucket acl: %v\", err)\n-\t}\n-\tif err := addObjectACL(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot add object acl: %v\", err)\n-\t}\n-\tif err := objectACL(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot get object acl: %v\", err)\n-\t}\n-\tif err := objectACLFiltered(client, bucket, object1, storage.AllAuthenticatedUsers); err != nil {\n-\t\tt.Errorf(\"cannot filter object acl: %v\", err)\n-\t}\n-\tif err := deleteObjectACL(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot delete object acl: %v\", err)\n+\tif err := copyFile(ioutil.Discard, dstBucket, bucket, object1); err != nil {\n+\t\tt.Errorf(\"copyFile: %v\", err)\n \t}\n \n \tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \tnewKey := []byte(\"My-secret-AES-256-encryption-key\")\n \n-\tif err := writeEncryptedObject(client, bucket, object1, key); err != nil {\n-\t\tt.Errorf(\"cannot write an encrypted object: %v\", err)\n+\tif err := uploadEncyptedFile(ioutil.Discard, bucket, object1, key); err != nil {\n+\t\tt.Errorf(\"uploadEncyptedFile: %v\", err)\n \t}\n-\tdata, err = readEncryptedObject(client, bucket, object1, key)\n+\tdata, err = downloadEncryptedFile(ioutil.Discard, bucket, object1, key)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot read the encrypted object: %v\", err)\n+\t\tt.Errorf(\"downloadEncryptedFile: %v\", err)\n \t}\n \tif got, want := string(data), \"top secret\"; got != want {\n \t\tt.Errorf(\"object content = %q; want %q\", got, want)\n \t}\n-\tif err := rotateEncryptionKey(client, bucket, object1, key, newKey); err != nil {\n-\t\tt.Errorf(\"cannot encrypt the object with the new key: %v\", err)\n+\tif err := rotateEncryptionKey(ioutil.Discard, bucket, object1, key, newKey); err != nil {\n+\t\tt.Errorf(\"rotateEncryptionKey: %v\", err)\n \t}\n-\tif err := delete(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot to delete object: %v\", err)\n+\tif err := deleteFile(ioutil.Discard, bucket, object1); err != nil {\n+\t\tt.Errorf(\"deleteFile: %v\", err)\n \t}\n-\tif err := delete(client, bucket, object2); err != nil {\n-\t\tt.Errorf(\"cannot to delete object: %v\", err)\n+\tif err := deleteFile(ioutil.Discard, bucket, object2); err != nil {\n+\t\tt.Errorf(\"deleteFile: %v\", err)\n \t}\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\t// Cleanup, this part won't be executed if Fatal happens.\n \t\t// TODO(jbd): Implement garbage cleaning.\n \t\tif err := client.Bucket(bucket).Delete(ctx); err != nil {\n-\t\t\tr.Errorf(\"cleanup of bucket failed: %v\", err)\n+\t\t\tr.Errorf(\"Bucket(%q).Delete: %v\", bucket, err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := delete(client, dstBucket, object1+\"-copy\"); err != nil {\n-\t\t\tr.Errorf(\"cannot to delete copy object: %v\", err)\n+\t\tif err := deleteFile(ioutil.Discard, dstBucket, object1+\"-copy\"); err != nil {\n+\t\t\tr.Errorf(\"deleteFile: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\tif err := client.Bucket(dstBucket).Delete(ctx); err != nil {\n-\t\t\tr.Errorf(\"cleanup of bucket failed: %v\", err)\n+\t\t\tr.Errorf(\"Bucket(%q).Delete: %v\", dstBucket, err)\n \t\t}\n \t})\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -201,6 +172,7 @@\nfunc TestKMSObjects(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")\n \tcryptoKeyID := os.Getenv(\"GOLANG_SAMPLES_KMS_CRYPTOKEY\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -211,17 +183,16 @@\nfunc TestKMSObjects(t *testing.T) {\n \tvar (\n \t\tbucket    = tc.ProjectID + \"-samples-object-bucket-1\"\n \t\tdstBucket = tc.ProjectID + \"-samples-object-bucket-2\"\n-\n-\t\tobject1 = \"foo.txt\"\n+\t\tobject1   = \"foo.txt\"\n \t)\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n \tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \n-\tif err := writeWithKMSKey(client, bucket, object1, kmsKeyName); err != nil {\n-\t\tt.Errorf(\"cannot write a KMS encrypted object: %v\", err)\n+\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object1, kmsKeyName); err != nil {\n+\t\tt.Errorf(\"uploadWithKMSKey: %v\", err)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -232,14 +203,15 @@\nfunc TestV4SignedURL(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tbucketName := tc.ProjectID + \"-signed-url-bucket-name\"\n \tobjectName := \"foo.txt\"\n \tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n \tputBuf := new(bytes.Buffer)\n-\tputURL, err := generateV4PutObjectSignedURL(putBuf, client, bucketName, objectName, serviceAccount)\n+\tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName, serviceAccount)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4PutObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -257,7 +229,7 @@\nfunc TestV4SignedURL(t *testing.T) {\n \t\tt.Errorf(\"httpClient.Do: %v\", err)\n \t}\n \tgetBuf := new(bytes.Buffer)\n-\tgetURL, err := generateV4GetObjectSignedURL(getBuf, client, bucketName, objectName, serviceAccount)\n+\tgetURL, err := generateV4GetObjectSignedURL(getBuf, bucketName, objectName, serviceAccount)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4GetObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -280,7 +252,6 @@\nfunc TestV4SignedURL(t *testing.T) {\n \tif got, want := string(body), \"hello world\"; got != want {\n \t\tt.Errorf(\"object content = %q; want %q\", got, want)\n \t}\n-\n }\n \n func TestObjectBucketLock(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -290,69 +261,68 @@\nfunc TestObjectBucketLock(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tvar (\n-\t\tbucketName = tc.ProjectID + \"-retent-samples-object-bucket\"\n-\n-\t\tobjectName = \"foo.txt\"\n-\n+\t\tbucketName      = tc.ProjectID + \"-retent-samples-object-bucket\"\n+\t\tobjectName      = \"foo.txt\"\n \t\tretentionPeriod = 5 * time.Second\n \t)\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n \tbucket := client.Bucket(bucketName)\n \n-\tif err := write(client, bucketName, objectName); err != nil {\n-\t\tt.Fatalf(\"write(%q): %v\", objectName, err)\n+\tif err := uploadFile(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", objectName, err)\n \t}\n \tif _, err := bucket.Update(ctx, storage.BucketAttrsToUpdate{\n \t\tRetentionPolicy: &storage.RetentionPolicy{\n \t\t\tRetentionPeriod: retentionPeriod,\n \t\t},\n \t}); err != nil {\n-\t\tt.Errorf(\"unable to set retention policy (%q): %v\", bucketName, err)\n+\t\tt.Errorf(\"Bucket(%q).Update: %v\", bucketName, err)\n \t}\n-\tif err := setEventBasedHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to set event-based hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := setEventBasedHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"setEventBasedHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err := attrs(client, bucketName, objectName)\n+\toAttrs, err := getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif !oAttrs.EventBasedHold {\n \t\tt.Errorf(\"event-based hold is not enabled\")\n \t}\n-\tif err := releaseEventBasedHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to set event-based hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := releaseEventBasedHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"releaseEventBasedHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err = attrs(client, bucketName, objectName)\n+\toAttrs, err = getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif oAttrs.EventBasedHold {\n \t\tt.Errorf(\"event-based hold is not disabled\")\n \t}\n \tif _, err := bucket.Update(ctx, storage.BucketAttrsToUpdate{\n \t\tRetentionPolicy: &storage.RetentionPolicy{},\n \t}); err != nil {\n-\t\tt.Errorf(\"unable to remove retention policy (%q): %v\", bucketName, err)\n+\t\tt.Errorf(\"Bucket(%q).Update: %v\", bucketName, err)\n \t}\n-\tif err := setTemporaryHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to set temporary hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := setTemporaryHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"setTemporaryHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err = attrs(client, bucketName, objectName)\n+\toAttrs, err = getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif !oAttrs.TemporaryHold {\n \t\tt.Errorf(\"temporary hold is not disabled\")\n \t}\n-\tif err := releaseTemporaryHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to release temporary hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := releaseTemporaryHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"releaseTemporaryHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err = attrs(client, bucketName, objectName)\n+\toAttrs, err = getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif oAttrs.TemporaryHold {\n \t\tt.Errorf(\"temporary hold is not disabled\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "storage: fix broken s3_sdk test",
        "pr_number": 1217,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -371,7 +341,7 @@\nfunc cleanBucket(t *testing.T, ctx context.Context, client *storage.Client, proj\n \t\t\t\tbreak\n \t\t\t}\n \t\t\tif err != nil {\n-\t\t\t\tt.Fatalf(\"Bucket.Objects(%q): %v\", bucket, err)\n+\t\t\t\tt.Fatalf(\"Bucket(%q).Objects: %v\", bucket, err)\n \t\t\t}\n \t\t\tif attrs.EventBasedHold || attrs.TemporaryHold {\n \t\t\t\tif _, err := b.Object(attrs.Name).Update(ctx, storage.ObjectAttrsToUpdate{",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "d047bf3e55b071a028427147839668f0120236a8"
    },
    {
        "pr_title": "appengine: added closure of client to avoid memory spike",
        "pr_number": 1183,
        "file_name": "appengine/go11x/tasks/create_task/create_task.go",
        "code_diff": "@@ -34,6 +34,7 @@\nfunc createTask(projectID, locationID, queueID, message string) (*taskspb.Task,\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \t// Build the Task queue path.\n \tqueuePath := fmt.Sprintf(\"projects/%s/locations/%s/queues/%s\", projectID, locationID, queueID)",
        "comments": [
            {
                "comment": "Will you move this line to right below the error check for `NewClient` above? It's possible there will be some other issue between creating the client and here, so we want to make sure the `defer` is actually set.",
                "position": null
            },
            {
                "comment": "I don't think we need the comment? I could be convinced, though.",
                "position": null
            },
            {
                "comment": "Yes, sure",
                "position": null
            },
            {
                "comment": "Sure yeah",
                "position": null
            }
        ],
        "commit_message": "review comments",
        "commit_id": "a998ed28e365e3d15cf6e08671af11d6c6a193c5"
    },
    {
        "pr_title": "run/markdown-preview: sample for a secure 2-tier app",
        "pr_number": 1179,
        "file_name": "securitycenter/notifications/delete_notification_config.go",
        "code_diff": "@@ -16,8 +16,8 @@\npackage notifications\n // [START scc_delete_notification_config]\n import (\n \t\"context\"\n-\t\"io\"\n \t\"fmt\"\n+\t\"io\"\n \n \tsecuritycenter \"cloud.google.com/go/securitycenter/apiv1p1beta1\"\n \tsecuritycenterpb \"google.golang.org/genproto/googleapis/cloud/securitycenter/v1p1beta1\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/markdown-preview",
        "commit_id": "629b3281e8b3137b593710ad3904c7e3dfbbd97f"
    },
    {
        "pr_title": "run/markdown-preview: sample for a secure 2-tier app",
        "pr_number": 1179,
        "file_name": "speech/snippets/context_classes.go",
        "code_diff": "@@ -21,7 +21,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n+\t\"strings\"\n \n \tspeech \"cloud.google.com/go/speech/apiv1\"\n \tspeechpb \"google.golang.org/genproto/googleapis/cloud/speech/v1\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/markdown-preview",
        "commit_id": "629b3281e8b3137b593710ad3904c7e3dfbbd97f"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/get_bucket_metadata.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"log\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -95,8 +95,11 @@\nfunc main() {\n }\n \n func create(client *storage.Client, projectID, bucketName string) error {\n-\tctx := context.Background()\n \t// [START create_bucket]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif err := client.Bucket(bucketName).Create(ctx, projectID, nil); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -105,9 +108,12 @@\nfunc create(client *storage.Client, projectID, bucketName string) error {\n }\n \n func createWithAttrs(client *storage.Client, projectID, bucketName string) error {\n-\tctx := context.Background()\n \t// [START create_bucket_with_storageclass_and_location]\n+\tctx := context.Background()\n \tbucket := client.Bucket(bucketName)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif err := bucket.Create(ctx, projectID, &storage.BucketAttrs{\n \t\tStorageClass: \"COLDLINE\",\n \t\tLocation:     \"asia\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -119,9 +125,12 @@\nfunc createWithAttrs(client *storage.Client, projectID, bucketName string) error\n }\n \n func list(client *storage.Client, projectID string) ([]string, error) {\n-\tctx := context.Background()\n \t// [START list_buckets]\n+\tctx := context.Background()\n+\n \tvar buckets []string\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tit := client.Buckets(ctx, projectID)\n \tfor {\n \t\tbattrs, err := it.Next()",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -138,8 +147,11 @@\nfunc list(client *storage.Client, projectID string) ([]string, error) {\n }\n \n func deleteBucket(client *storage.Client, bucketName string) error {\n-\tctx := context.Background()\n \t// [START delete_bucket]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif err := client.Bucket(bucketName).Delete(ctx); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -148,9 +160,11 @@\nfunc deleteBucket(client *storage.Client, bucketName string) error {\n }\n \n func getPolicy(c *storage.Client, bucketName string) (*iam.Policy, error) {\n+\t// [START storage_get_bucket_policy]\n \tctx := context.Background()\n \n-\t// [START storage_get_bucket_policy]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tpolicy, err := c.Bucket(bucketName).IAM().Policy(ctx)\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -163,9 +177,11 @@\nfunc getPolicy(c *storage.Client, bucketName string) (*iam.Policy, error) {\n }\n \n func addUser(c *storage.Client, bucketName string) error {\n+\t// [START add_bucket_iam_member]\n \tctx := context.Background()\n \n-\t// [START add_bucket_iam_member]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n \tpolicy, err := bucket.IAM().Policy(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -186,9 +202,11 @@\nfunc addUser(c *storage.Client, bucketName string) error {\n }\n \n func removeUser(c *storage.Client, bucketName string) error {\n+\t// [START remove_bucket_iam_member]\n \tctx := context.Background()\n \n-\t// [START remove_bucket_iam_member]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n \tpolicy, err := bucket.IAM().Policy(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -209,15 +227,17 @@\nfunc removeUser(c *storage.Client, bucketName string) error {\n }\n \n func setRetentionPolicy(c *storage.Client, bucketName string, retentionPeriod time.Duration) error {\n+\t// [START storage_set_retention_policy]\n \tctx := context.Background()\n \n-\t// [START storage_set_retention_policy]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tRetentionPolicy: &storage.RetentionPolicy{\n \t\t\tRetentionPeriod: retentionPeriod,\n \t\t},\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -226,9 +246,8 @@\nfunc setRetentionPolicy(c *storage.Client, bucketName string, retentionPeriod ti\n }\n \n func removeRetentionPolicy(c *storage.Client, bucketName string) error {\n-\tctx := context.Background()\n-\n \t// [START storage_remove_retention_policy]\n+\tctx := context.Background()\n \tbucket := c.Bucket(bucketName)\n \n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -242,6 +261,8 @@\nfunc removeRetentionPolicy(c *storage.Client, bucketName string) error {\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tRetentionPolicy: &storage.RetentionPolicy{},\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -250,10 +271,12 @@\nfunc removeRetentionPolicy(c *storage.Client, bucketName string) error {\n }\n \n func lockRetentionPolicy(c *storage.Client, bucketName string) error {\n-\tctx := context.Background()\n-\n \t// [START storage_lock_retention_policy]\n+\tctx := context.Background()\n \tbucket := c.Bucket(bucketName)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -278,9 +301,11 @@\nfunc lockRetentionPolicy(c *storage.Client, bucketName string) error {\n }\n \n func getRetentionPolicy(c *storage.Client, bucketName string) (*storage.BucketAttrs, error) {\n+\t// [START storage_get_retention_policy]\n \tctx := context.Background()\n \n-\t// [START storage_get_retention_policy]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -296,13 +321,15 @@\nfunc getRetentionPolicy(c *storage.Client, bucketName string) (*storage.BucketAt\n }\n \n func enableDefaultEventBasedHold(c *storage.Client, bucketName string) error {\n+\t// [START storage_enable_default_event_based_hold]\n \tctx := context.Background()\n \n-\t// [START storage_enable_default_event_based_hold]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tDefaultEventBasedHold: true,\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -311,13 +338,15 @@\nfunc enableDefaultEventBasedHold(c *storage.Client, bucketName string) error {\n }\n \n func disableDefaultEventBasedHold(c *storage.Client, bucketName string) error {\n+\t// [START storage_disable_default_event_based_hold]\n \tctx := context.Background()\n \n-\t// [START storage_disable_default_event_based_hold]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tDefaultEventBasedHold: false,\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -326,9 +355,11 @@\nfunc disableDefaultEventBasedHold(c *storage.Client, bucketName string) error {\n }\n \n func getDefaultEventBasedHold(c *storage.Client, bucketName string) (*storage.BucketAttrs, error) {\n+\t// [START storage_get_default_event_based_hold]\n \tctx := context.Background()\n \n-\t// [START storage_get_default_event_based_hold]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -340,13 +371,15 @@\nfunc getDefaultEventBasedHold(c *storage.Client, bucketName string) (*storage.Bu\n }\n \n func enableRequesterPays(c *storage.Client, bucketName string) error {\n+\t// [START enable_requester_pays]\n \tctx := context.Background()\n \n-\t// [START enable_requester_pays]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tRequesterPays: true,\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -355,13 +388,15 @@\nfunc enableRequesterPays(c *storage.Client, bucketName string) error {\n }\n \n func disableRequesterPays(c *storage.Client, bucketName string) error {\n+\t// [START disable_requester_pays]\n \tctx := context.Background()\n \n-\t// [START disable_requester_pays]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tRequesterPays: false,\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -370,9 +405,11 @@\nfunc disableRequesterPays(c *storage.Client, bucketName string) error {\n }\n \n func checkRequesterPays(c *storage.Client, bucketName string) error {\n+\t// [START get_requester_pays_status]\n \tctx := context.Background()\n \n-\t// [START get_requester_pays_status]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -383,13 +420,15 @@\nfunc checkRequesterPays(c *storage.Client, bucketName string) error {\n }\n \n func setDefaultKMSkey(c *storage.Client, bucketName string, keyName string) error {\n+\t// [START storage_set_bucket_default_kms_key]\n \tctx := context.Background()\n \n-\t// [START storage_set_bucket_default_kms_key]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tEncryption: &storage.BucketEncryption{DefaultKMSKeyName: keyName},\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -398,15 +437,17 @@\nfunc setDefaultKMSkey(c *storage.Client, bucketName string, keyName string) erro\n }\n \n func enableUniformBucketLevelAccess(c *storage.Client, bucketName string) error {\n+\t// [START storage_enable_uniform_bucket_level_access]\n \tctx := context.Background()\n \n-\t// [START storage_enable_uniform_bucket_level_access]\n \tbucket := c.Bucket(bucketName)\n \tenableUniformBucketLevelAccess := storage.BucketAttrsToUpdate{\n \t\tUniformBucketLevelAccess: &storage.UniformBucketLevelAccess{\n \t\t\tEnabled: true,\n \t\t},\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, enableUniformBucketLevelAccess); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -415,15 +456,17 @@\nfunc enableUniformBucketLevelAccess(c *storage.Client, bucketName string) error\n }\n \n func disableUniformBucketLevelAccess(c *storage.Client, bucketName string) error {\n+\t// [START storage_disable_uniform_bucket_level_access]\n \tctx := context.Background()\n \n-\t// [START storage_disable_uniform_bucket_level_access]\n \tbucket := c.Bucket(bucketName)\n \tdisableUniformBucketLevelAccess := storage.BucketAttrsToUpdate{\n \t\tUniformBucketLevelAccess: &storage.UniformBucketLevelAccess{\n \t\t\tEnabled: false,\n \t\t},\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, disableUniformBucketLevelAccess); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -90,14 +90,16 @@\nfunc main() {\n }\n \n func write(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START upload_file]\n+\tctx := context.Background()\n \tf, err := os.Open(\"notes.txt\")\n \tif err != nil {\n \t\treturn err\n \t}\n \tdefer f.Close()\n \n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n \twc := client.Bucket(bucket).Object(object).NewWriter(ctx)\n \tif _, err = io.Copy(wc, f); err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -110,8 +112,11 @@\nfunc write(client *storage.Client, bucket, object string) error {\n }\n \n func list(w io.Writer, client *storage.Client, bucket string) error {\n-\tctx := context.Background()\n \t// [START storage_list_files]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tit := client.Bucket(bucket).Objects(ctx, nil)\n \tfor {\n \t\tattrs, err := it.Next()",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -128,7 +133,6 @@\nfunc list(w io.Writer, client *storage.Client, bucket string) error {\n }\n \n func listByPrefix(w io.Writer, client *storage.Client, bucket, prefix, delim string) error {\n-\tctx := context.Background()\n \t// [START storage_list_files_with_prefix]\n \t// Prefixes and delimiters can be used to emulate directory listings.\n \t// Prefixes can be used filter objects starting with prefix.",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -146,6 +150,10 @@\nfunc listByPrefix(w io.Writer, client *storage.Client, bucket, prefix, delim str\n \t//\n \t// However, if you specify prefix=\"a/\" and delim=\"/\", you'll get back:\n \t//   /a/1.txt\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tit := client.Bucket(bucket).Objects(ctx, &storage.Query{\n \t\tPrefix:    prefix,\n \t\tDelimiter: delim,",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -165,8 +173,11 @@\nfunc listByPrefix(w io.Writer, client *storage.Client, bucket, prefix, delim str\n }\n \n func read(client *storage.Client, bucket, object string) ([]byte, error) {\n-\tctx := context.Background()\n \t// [START download_file]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n \trc, err := client.Bucket(bucket).Object(object).NewReader(ctx)\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -182,8 +193,11 @@\nfunc read(client *storage.Client, bucket, object string) ([]byte, error) {\n }\n \n func attrs(client *storage.Client, bucket, object string) (*storage.ObjectAttrs, error) {\n-\tctx := context.Background()\n \t// [START get_metadata]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tattrs, err := o.Attrs(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -219,8 +233,11 @@\nfunc attrs(client *storage.Client, bucket, object string) (*storage.ObjectAttrs,\n }\n \n func setEventBasedHold(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START storage_set_event_based_hold]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tobjectAttrsToUpdate := storage.ObjectAttrsToUpdate{\n \t\tEventBasedHold: true,",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -233,8 +250,11 @@\nfunc setEventBasedHold(client *storage.Client, bucket, object string) error {\n }\n \n func releaseEventBasedHold(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START storage_release_event_based_hold]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tobjectAttrsToUpdate := storage.ObjectAttrsToUpdate{\n \t\tEventBasedHold: false,",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -247,8 +267,11 @@\nfunc releaseEventBasedHold(client *storage.Client, bucket, object string) error\n }\n \n func setTemporaryHold(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START storage_set_temporary_hold]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tobjectAttrsToUpdate := storage.ObjectAttrsToUpdate{\n \t\tTemporaryHold: true,",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -261,8 +284,11 @@\nfunc setTemporaryHold(client *storage.Client, bucket, object string) error {\n }\n \n func releaseTemporaryHold(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START storage_release_temporary_hold]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tobjectAttrsToUpdate := storage.ObjectAttrsToUpdate{\n \t\tTemporaryHold: false,",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -275,8 +301,11 @@\nfunc releaseTemporaryHold(client *storage.Client, bucket, object string) error {\n }\n \n func makePublic(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START public]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tacl := client.Bucket(bucket).Object(object).ACL()\n \tif err := acl.Set(ctx, storage.AllUsers, storage.RoleReader); err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -286,8 +315,11 @@\nfunc makePublic(client *storage.Client, bucket, object string) error {\n }\n \n func move(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START move_file]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tdstName := object + \"-rename\"\n \n \tsrc := client.Bucket(bucket).Object(object)",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -304,8 +336,11 @@\nfunc move(client *storage.Client, bucket, object string) error {\n }\n \n func copyToBucket(client *storage.Client, dstBucket, srcBucket, srcObject string) error {\n-\tctx := context.Background()\n \t// [START copy_file]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tdstObject := srcObject + \"-copy\"\n \tsrc := client.Bucket(srcBucket).Object(srcObject)\n \tdst := client.Bucket(dstBucket).Object(dstObject)",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -318,8 +353,11 @@\nfunc copyToBucket(client *storage.Client, dstBucket, srcBucket, srcObject string\n }\n \n func delete(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START delete_file]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tif err := o.Delete(ctx); err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -330,10 +368,13 @@\nfunc delete(client *storage.Client, bucket, object string) error {\n \n // writeEncryptedObject writes an object encrypted with user-provided AES key to a bucket.\n func writeEncryptedObject(client *storage.Client, bucket, object string, secretKey []byte) error {\n-\tctx := context.Background()\n-\n \t// [START storage_upload_encrypted_file]\n+\tctx := context.Background()\n \tobj := client.Bucket(bucket).Object(object)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n+\n \t// Encrypt the object's contents.\n \twc := obj.Key(secretKey).NewWriter(ctx)\n \tif _, err := wc.Write([]byte(\"top secret\")); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -348,10 +389,13 @@\nfunc writeEncryptedObject(client *storage.Client, bucket, object string, secretK\n \n // writeWithKMSKey writes an object encrypted with KMS-provided key to a bucket.\n func writeWithKMSKey(client *storage.Client, bucket, object string, keyName string) error {\n-\tctx := context.Background()\n-\n \t// [START storage_upload_with_kms_key]\n+\tctx := context.Background()\n \tobj := client.Bucket(bucket).Object(object)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n+\n \t// Encrypt the object's contents\n \twc := obj.NewWriter(ctx)\n \twc.KMSKeyName = keyName",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -366,10 +410,12 @@\nfunc writeWithKMSKey(client *storage.Client, bucket, object string, keyName stri\n }\n \n func readEncryptedObject(client *storage.Client, bucket, object string, secretKey []byte) ([]byte, error) {\n-\tctx := context.Background()\n-\n \t// [START storage_download_encrypted_file]\n+\tctx := context.Background()\n \tobj := client.Bucket(bucket).Object(object)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n \trc, err := obj.Key(secretKey).NewReader(ctx)\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -385,13 +431,17 @@\nfunc readEncryptedObject(client *storage.Client, bucket, object string, secretKe\n }\n \n func rotateEncryptionKey(client *storage.Client, bucket, object string, key, newKey []byte) error {\n-\tctx := context.Background()\n \t// [START storage_rotate_encryption_key]\n+\tctx := context.Background()\n+\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \tobj := client.Bucket(bucket).Object(object)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \t// obj is encrypted with key, we are encrypting it with the newKey.\n \t_, err = obj.Key(newKey).CopierFrom(obj.Key(key)).Run(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/s3_sdk/list_gcs_buckets.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n \n \t\"github.com/aws/aws-sdk-go/aws\"\n \t\"github.com/aws/aws-sdk-go/aws/credentials\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/service_account/hmac/activate.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n )\n \n // activateHMACKey activates the HMAC key with the given access ID.",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/service_account/hmac/create.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n )\n \n // createHMACKey creates a new HMAC key using the given project and service account.",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/service_account/hmac/deactivate.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n )\n \n // deactivateHMACKey deactivates the HMAC key with the given access ID.",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/service_account/hmac/delete.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n )\n \n // deleteHMACKey deletes the HMAC key with the given access ID. Key must have state",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/service_account/hmac/get.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n )\n \n // getHMACKey retrieves the HMACKeyMetadata with the given access id.",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/service_account/hmac/list.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n \t\"fmt\"\n \t\"google.golang.org/api/iterator\"\n \t\"io\"\n+\t\"time\"\n )\n \n // listHMACKeys lists all HMAC keys associated with the project.",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "storage/storage_quickstart/main.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"log\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into sethvargo/iam_samples",
        "commit_id": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -97,6 +97,7 @@\nfunc main() {\n func create(client *storage.Client, projectID, bucketName string) error {\n \t// [START create_bucket]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tif err := client.Bucket(bucketName).Create(ctx, projectID, nil); err != nil {",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -148,6 +149,7 @@\nfunc list(client *storage.Client, projectID string) ([]string, error) {\n func deleteBucket(client *storage.Client, bucketName string) error {\n \t// [START delete_bucket]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tif err := client.Bucket(bucketName).Delete(ctx); err != nil {",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -160,6 +162,7 @@\nfunc deleteBucket(client *storage.Client, bucketName string) error {\n func getPolicy(c *storage.Client, bucketName string) (*iam.Policy, error) {\n \t// [START storage_get_bucket_policy]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tpolicy, err := c.Bucket(bucketName).IAM().Policy(ctx)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -176,6 +179,7 @@\nfunc getPolicy(c *storage.Client, bucketName string) (*iam.Policy, error) {\n func addUser(c *storage.Client, bucketName string) error {\n \t// [START add_bucket_iam_member]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -200,6 +204,7 @@\nfunc addUser(c *storage.Client, bucketName string) error {\n func removeUser(c *storage.Client, bucketName string) error {\n \t// [START remove_bucket_iam_member]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -352,6 +357,7 @@\nfunc disableDefaultEventBasedHold(c *storage.Client, bucketName string) error {\n func getDefaultEventBasedHold(c *storage.Client, bucketName string) (*storage.BucketAttrs, error) {\n \t// [START storage_get_default_event_based_hold]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -401,6 +407,7 @@\nfunc disableRequesterPays(c *storage.Client, bucketName string) error {\n func checkRequesterPays(c *storage.Client, bucketName string) error {\n \t// [START get_requester_pays_status]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -114,6 +114,7 @@\nfunc write(client *storage.Client, bucket, object string) error {\n func list(w io.Writer, client *storage.Client, bucket string) error {\n \t// [START storage_list_files]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tit := client.Bucket(bucket).Objects(ctx, nil)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -150,6 +151,7 @@\nfunc listByPrefix(w io.Writer, client *storage.Client, bucket, prefix, delim str\n \t// However, if you specify prefix=\"a/\" and delim=\"/\", you'll get back:\n \t//   /a/1.txt\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tit := client.Bucket(bucket).Objects(ctx, &storage.Query{",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -173,6 +175,7 @@\nfunc listByPrefix(w io.Writer, client *storage.Client, bucket, prefix, delim str\n func read(client *storage.Client, bucket, object string) ([]byte, error) {\n \t// [START download_file]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n \tdefer cancel()\n \trc, err := client.Bucket(bucket).Object(object).NewReader(ctx)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -192,6 +195,7 @@\nfunc read(client *storage.Client, bucket, object string) ([]byte, error) {\n func attrs(client *storage.Client, bucket, object string) (*storage.ObjectAttrs, error) {\n \t// [START get_metadata]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \to := client.Bucket(bucket).Object(object)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -231,6 +235,7 @@\nfunc attrs(client *storage.Client, bucket, object string) (*storage.ObjectAttrs,\n func setEventBasedHold(client *storage.Client, bucket, object string) error {\n \t// [START storage_set_event_based_hold]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \to := client.Bucket(bucket).Object(object)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -247,6 +252,7 @@\nfunc setEventBasedHold(client *storage.Client, bucket, object string) error {\n func releaseEventBasedHold(client *storage.Client, bucket, object string) error {\n \t// [START storage_release_event_based_hold]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \to := client.Bucket(bucket).Object(object)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -263,6 +269,7 @@\nfunc releaseEventBasedHold(client *storage.Client, bucket, object string) error\n func setTemporaryHold(client *storage.Client, bucket, object string) error {\n \t// [START storage_set_temporary_hold]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \to := client.Bucket(bucket).Object(object)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -279,6 +286,7 @@\nfunc setTemporaryHold(client *storage.Client, bucket, object string) error {\n func releaseTemporaryHold(client *storage.Client, bucket, object string) error {\n \t// [START storage_release_temporary_hold]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \to := client.Bucket(bucket).Object(object)",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -295,6 +303,7 @@\nfunc releaseTemporaryHold(client *storage.Client, bucket, object string) error {\n func makePublic(client *storage.Client, bucket, object string) error {\n \t// [START public]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tacl := client.Bucket(bucket).Object(object).ACL()",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -308,6 +317,7 @@\nfunc makePublic(client *storage.Client, bucket, object string) error {\n func move(client *storage.Client, bucket, object string) error {\n \t// [START move_file]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tdstName := object + \"-rename\"",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -328,6 +338,7 @@\nfunc move(client *storage.Client, bucket, object string) error {\n func copyToBucket(client *storage.Client, dstBucket, srcBucket, srcObject string) error {\n \t// [START copy_file]\n \tctx := context.Background()\n+\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tdstObject := srcObject + \"-copy\"",
        "comments": [],
        "commit_message": "Add spacing between ctx creation and adding timeout.",
        "commit_id": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -31,13 +31,23 @@\nimport (\n // [END bigquery_simple_app_deps]\n \n func main() {\n-\tproj := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n-\tif proj == \"\" {\n+\tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n+\tif projectID == \"\" {\n \t\tfmt.Println(\"GOOGLE_CLOUD_PROJECT environment variable must be set.\")\n \t\tos.Exit(1)\n \t}\n \n-\trows, err := query(proj)\n+\t// [START bigquery_simple_app_client]\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"bigquery.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\t// [END bigquery_simple_app_client]\n+\n+\trows, err := query(ctx, client)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples-pt2",
        "commit_id": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -46,16 +56,8 @@\nfunc main() {\n \t}\n }\n \n-// query returns a slice of the results of a query.\n-func query(proj string) (*bigquery.RowIterator, error) {\n-\t// [START bigquery_simple_app_client]\n-\tctx := context.Background()\n-\n-\tclient, err := bigquery.NewClient(ctx, proj)\n-\tif err != nil {\n-\t\treturn nil, err\n-\t}\n-\t// [END bigquery_simple_app_client]\n+// query returns a row iterator suitable for reading query results.\n+func query(ctx context.Context, client *bigquery.Client) (*bigquery.RowIterator, error) {\n \n \t// [START bigquery_simple_app_query]\n \tquery := client.Query(",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples-pt2",
        "commit_id": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -38,6 +38,7 @@\nfunc TestJobs(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\tdefer client.Close()\n \n \t// Control a job lifecycle explicitly: create, report status, cancel.\n \texampleJobID, err := bqtestutil.UniqueBQName(\"golang_example_job\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples-pt2",
        "commit_id": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -67,6 +68,7 @@\nfunc TestCopiesAndExtracts(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\tdefer client.Close()\n \n \tmeta := &bigquery.DatasetMetadata{\n \t\tLocation: \"US\", // See https://cloud.google.com/bigquery/docs/locations",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples-pt2",
        "commit_id": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "bigquery/snippets/table/bigquery_table_insert_rows.go",
        "code_diff": "@@ -29,11 +29,12 @@\ntype Item struct {\n }\n \n // Save implements the ValueSaver interface.\n+// This example disables best-effort de-duplication, which allows for higher throughput.\n func (i *Item) Save() (map[string]bigquery.Value, string, error) {\n \treturn map[string]bigquery.Value{\n \t\t\"full_name\": i.Name,\n \t\t\"age\":       i.Age,\n-\t}, \"\", nil\n+\t}, bigquery.NoDedupeID, nil\n }\n \n // insertRows demonstrates inserting data into a table using the streaming insert mechanism.",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples-pt2",
        "commit_id": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -42,6 +42,16 @@\nfunc TestSample(t *testing.T) {\n \tctx := context.Background()\n \tadminClient, dataClient := createClients(ctx, dbName)\n \tdefer adminClient.Close()\n+\t// The database should be dropped after closing the data client (defer is\n+\t// called in a LIFO order).\n+\tdefer func() {\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n+\t\t\t}\n+\t\t})\n+\t}()\n \tdefer dataClient.Close()\n \n \t// Check for database existance prior to test start and delete, as resources may not have",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples-pt2",
        "commit_id": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -74,15 +84,6 @@\nfunc TestSample(t *testing.T) {\n \t\treturn b.String()\n \t}\n \n-\tdefer func() {\n-\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n-\t\t\tif err != nil {\n-\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n-\t\t\t}\n-\t\t})\n-\t}()\n-\n \t// We execute all the commands of the tutorial code. These commands have to be run in a specific\n \t// order since in many cases earlier commands setup the database for the subsequent commands.\n \tmustRunCommand(t, \"createdatabase\", dbName)",
        "comments": [],
        "commit_message": "Merge branch 'master' into separate_storage_samples-pt2",
        "commit_id": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "feat(run): grpc-server-streaming sample",
        "pr_number": 1164,
        "file_name": "dataproc/create_cluster_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tdataproc \"cloud.google.com/go/dataproc/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/grpc-server-streaming",
        "commit_id": "147c02d4c9c5f609da7fb101d51254e2a6d9e63b"
    },
    {
        "pr_title": "feat(run): grpc-server-streaming sample",
        "pr_number": 1164,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -456,6 +456,9 @@\nfunc TestPullMsgsDeadLetterDeliveryAttempts(t *testing.T) {\n \t\t\tMaxDeliveryAttempts: 10,\n \t\t},\n \t})\n+\tif err != nil {\n+\t\tt.Fatalf(\"getOrCreateSub: %v\", err)\n+\t}\n \tdefer sub.Delete(ctx)\n \n \tif err = publishMsgs(ctx, deadLetterSourceTopic, 1); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/grpc-server-streaming",
        "commit_id": "147c02d4c9c5f609da7fb101d51254e2a6d9e63b"
    },
    {
        "pr_title": "feat(run): grpc-server-streaming sample",
        "pr_number": 1164,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -17,12 +17,14 @@\npackage main\n // [START run_secure_request]\n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"net/http\"\n \t\"time\"\n \n-\t\"cloud.google.com/go/compute/metadata\"\n+\t\"golang.org/x/oauth2\"\n+\t\"google.golang.org/api/idtoken\"\n )\n \n // RenderService represents our upstream render service.",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/grpc-server-streaming",
        "commit_id": "147c02d4c9c5f609da7fb101d51254e2a6d9e63b"
    },
    {
        "pr_title": "feat(run): grpc-server-streaming sample",
        "pr_number": 1164,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -31,10 +33,12 @@\ntype RenderService struct {\n \tURL string\n \t// Authenticated determines whether identity token authentication will be used.\n \tAuthenticated bool\n+\t// tokenSource provides an identity token for requests to the Render Service.\n+\ttokenSource oauth2.TokenSource\n }\n \n-// NewRequest creates a new HTTP request with IAM ID Token credential.\n-// This token is automatically handled by private Cloud Run (fully managed) and Cloud Functions.\n+// NewRequest creates a new HTTP request to the Render service.\n+// If authentication is enabled, an Identity Token is created and added.\n func (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \treq, err := http.NewRequest(method, s.URL, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/grpc-server-streaming",
        "commit_id": "147c02d4c9c5f609da7fb101d51254e2a6d9e63b"
    },
    {
        "pr_title": "fix: updated contributing guide for more info on quickstarts",
        "pr_number": 1160,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -48,6 +48,9 @@\ntype Service struct {\n \t// The project to deploy to.\n \tProjectID string\n \n+\t// Allow unauthenticated request.\n+\tAllowUnauthenticated bool\n+\n \t// The platform to deploy to.\n \tPlatform Platform",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-samples",
        "commit_id": "e9c95a5ac2c419fc2ad9b8e789ce3f697d7e68e2"
    },
    {
        "pr_title": "fix: updated contributing guide for more info on quickstarts",
        "pr_number": 1160,
        "file_name": "run/grpc-ping/e2e_test.go",
        "code_diff": "@@ -39,7 +39,9 @@\nfunc TestGRPCPingService(t *testing.T) {\n \n \t// Prepare the container image for both services.\n \tpingService := cloudrunci.NewService(\"grpc-ping\", tc.ProjectID)\n-\tpingService.Build()\n+\tif err := pingService.Build(); err != nil {\n+\t\tt.Fatalf(\"Service.Build %q: %v\", pingService.Name, err)\n+\t}\n \n \t// Deploy the ping-upstream service.\n \tupstreamService := cloudrunci.NewService(\"grpc-ping-upstream\", tc.ProjectID)",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-samples",
        "commit_id": "e9c95a5ac2c419fc2ad9b8e789ce3f697d7e68e2"
    },
    {
        "pr_title": "fix: updated contributing guide for more info on quickstarts",
        "pr_number": 1160,
        "file_name": "run/grpc-ping/e2e_test.go",
        "code_diff": "@@ -53,7 +55,7 @@\nfunc TestGRPCPingService(t *testing.T) {\n \t// Deploy the ping service.\n \tupstreamHost, err := upstreamService.Host()\n \tif err != nil {\n-\t\tt.Errorf(\"Service.Host %q: %v\", upstreamService.Name, err)\n+\t\tt.Fatalf(\"Service.Host %q: %v\", upstreamService.Name, err)\n \t}\n \tpingService.Env = cloudrunci.EnvVars{\n \t\t\"GRPC_PING_HOST\": upstreamHost,",
        "comments": [],
        "commit_message": "Merge branch 'master' into dataproc-samples",
        "commit_id": "e9c95a5ac2c419fc2ad9b8e789ce3f697d7e68e2"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "asset/quickstart/export-assets/main_test.go",
        "code_diff": "@@ -22,9 +22,7 @@\nimport (\n \t\"strings\"\n \t\"testing\"\n \n-\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"google.golang.org/api/iterator\"\n )\n \n func TestMain(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "asset/quickstart/export-assets/main_test.go",
        "code_diff": "@@ -33,13 +31,9 @@\nfunc TestMain(t *testing.T) {\n \tos.Setenv(\"GOOGLE_CLOUD_PROJECT\", tc.ProjectID)\n \n \tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to create storage client: %v\", err)\n-\t}\n \n \t// Delete the bucket (if it exists) then recreate it.\n-\tcleanBucket(ctx, t, client, tc.ProjectID, bucketName)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n \toldStdout := os.Stdout\n \tr, w, _ := os.Pipe()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "badfiles_test.go",
        "code_diff": "@@ -59,6 +59,7 @@\nvar allowList = []string{\n \t\"**/testdata/**/*.png\",\n \t\"**/testdata/**/*.txt\",\n \t\"**/testdata/**/*.csv\",\n+\t\"**/testdata/**/*.mp4\",\n \n \t// Healthcare data.\n \t\"healthcare/testdata/dicom_00000001_000.dcm\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -33,11 +33,11 @@\nimport (\n \t\"sync\"\n \t\"time\"\n \n-\tbqStorage \"cloud.google.com/go/bigquery/storage/apiv1beta1\"\n+\tbqStorage \"cloud.google.com/go/bigquery/storage/apiv1\"\n \t\"github.com/golang/protobuf/ptypes\"\n \tgax \"github.com/googleapis/gax-go/v2\"\n \tgoavro \"github.com/linkedin/goavro/v2\"\n-\tbqStoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1beta1\"\n+\tbqStoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1\"\n \t\"google.golang.org/grpc\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -59,11 +59,11 @@\nvar (\n func main() {\n \tflag.Parse()\n \tctx := context.Background()\n-\tbqStorageClient, err := bqStorage.NewBigQueryStorageClient(ctx)\n+\tbqReadClient, err := bqStorage.NewBigQueryReadClient(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"NewBigQueryStorageClient: %v\", err)\n \t}\n-\tdefer bqStorageClient.Close()\n+\tdefer bqReadClient.Close()\n \n \t// Verify we've been provided a parent project which will contain the read session.  The\n \t// session may exist in a different project than the table being read.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -72,31 +72,33 @@\nfunc main() {\n \t}\n \n \t// This example uses baby name data from the public datasets.\n-\treadTable := &bqStoragepb.TableReference{\n-\t\tProjectId: \"bigquery-public-data\",\n-\t\tDatasetId: \"usa_names\",\n-\t\tTableId:   \"usa_1910_current\",\n-\t}\n+\tsrcProjectID := \"bigquery-public-data\"\n+\tsrcDatasetID := \"usa_names\"\n+\tsrcTableID := \"usa_1910_current\"\n+\treadTable := fmt.Sprintf(\"projects/%s/datasets/%s/tables/%s\",\n+\t\tsrcProjectID,\n+\t\tsrcDatasetID,\n+\t\tsrcTableID,\n+\t)\n \n \t// We limit the output columns to a subset of those allowed in the table,\n \t// and set a simple filter to only report names from the state of\n \t// Washington (WA).\n-\ttableReadOptions := &bqStoragepb.TableReadOptions{\n+\ttableReadOptions := &bqStoragepb.ReadSession_TableReadOptions{\n \t\tSelectedFields: []string{\"name\", \"number\", \"state\"},\n \t\tRowRestriction: `state = \"WA\"`,\n \t}\n \n-\treadSessionRequest := &bqStoragepb.CreateReadSessionRequest{\n-\t\tParent:         fmt.Sprintf(\"projects/%s\", *projectID),\n-\t\tTableReference: readTable,\n-\t\tReadOptions:    tableReadOptions,\n-\t\t// This API can also deliver data serialized in Apache Arrow format.\n-\t\t// This example leverages Apache Avro.\n-\t\tFormat: bqStoragepb.DataFormat_AVRO,\n-\t\t// We use a LIQUID strategy in this example because we only\n-\t\t// read from a single stream.  Consider BALANCED if you're consuming\n-\t\t// multiple streams concurrently and want more consistent stream sizes.\n-\t\tShardingStrategy: bqStoragepb.ShardingStrategy_LIQUID,\n+\tcreateReadSessionRequest := &bqStoragepb.CreateReadSessionRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%s\", *projectID),\n+\t\tReadSession: &bqStoragepb.ReadSession{\n+\t\t\tTable: readTable,\n+\t\t\t// This API can also deliver data serialized in Apache Arrow format.\n+\t\t\t// This example leverages Apache Avro.\n+\t\t\tDataFormat:  bqStoragepb.DataFormat_AVRO,\n+\t\t\tReadOptions: tableReadOptions,\n+\t\t},\n+\t\tMaxStreamCount: 1,\n \t}\n \n \t// Set a snapshot time if it's been specified.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -105,13 +107,13 @@\nfunc main() {\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"Invalid snapshot millis (%d): %v\", *snapshotMillis, err)\n \t\t}\n-\t\treadSessionRequest.TableModifiers = &bqStoragepb.TableModifiers{\n+\t\tcreateReadSessionRequest.ReadSession.TableModifiers = &bqStoragepb.ReadSession_TableModifiers{\n \t\t\tSnapshotTime: ts,\n \t\t}\n \t}\n \n \t// Create the session from the request.\n-\tsession, err := bqStorageClient.CreateReadSession(ctx, readSessionRequest, rpcOpts)\n+\tsession, err := bqReadClient.CreateReadSession(ctx, createReadSessionRequest, rpcOpts)\n \tif err != nil {\n \t\tlog.Fatalf(\"CreateReadSession: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -123,8 +125,8 @@\nfunc main() {\n \t// We'll use only a single stream for reading data from the table.  Because\n \t// of dynamic sharding, this will yield all the rows in the table. However,\n \t// if you wanted to fan out multiple readers you could do so by having a\n-\t// reader process each individual stream.\n-\treadStream := session.GetStreams()[0]\n+\t// increasing the MaxStreamCount.\n+\treadStream := session.GetStreams()[0].Name\n \n \tch := make(chan *bqStoragepb.AvroRows)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -135,7 +137,7 @@\nfunc main() {\n \twg.Add(1)\n \tgo func() {\n \t\tdefer wg.Done()\n-\t\tif err := processStream(ctx, bqStorageClient, readStream, ch); err != nil {\n+\t\tif err := processStream(ctx, bqReadClient, readStream, ch); err != nil {\n \t\t\tlog.Fatalf(\"processStream failure: %v\", err)\n \t\t}\n \t\tclose(ch)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -197,7 +199,7 @@\nfunc valueFromTypeMap(field interface{}) interface{} {\n // data blocks to a channel. This function will retry on transient stream\n // failures and bookmark progress to avoid re-reading data that's already been\n // successfully transmitted.\n-func processStream(ctx context.Context, client *bqStorage.BigQueryStorageClient, st *bqStoragepb.Stream, ch chan<- *bqStoragepb.AvroRows) error {\n+func processStream(ctx context.Context, client *bqStorage.BigQueryReadClient, st string, ch chan<- *bqStoragepb.AvroRows) error {\n \tvar offset int64\n \n \t// Streams may be long-running.  Rather than using a global retry for the",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -208,10 +210,9 @@\nfunc processStream(ctx context.Context, client *bqStorage.BigQueryStorageClient,\n \t\tretries := 0\n \t\t// Send the initiating request to start streaming row blocks.\n \t\trowStream, err := client.ReadRows(ctx, &bqStoragepb.ReadRowsRequest{\n-\t\t\tReadPosition: &bqStoragepb.StreamPosition{\n-\t\t\t\tStream: st,\n-\t\t\t\tOffset: offset,\n-\t\t\t}}, rpcOpts)\n+\t\t\tReadStream: st,\n+\t\t\tOffset:     offset,\n+\t\t}, rpcOpts)\n \t\tif err != nil {\n \t\t\treturn fmt.Errorf(\"Couldn't invoke ReadRows: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -31,13 +31,23 @@\nimport (\n // [END bigquery_simple_app_deps]\n \n func main() {\n-\tproj := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n-\tif proj == \"\" {\n+\tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n+\tif projectID == \"\" {\n \t\tfmt.Println(\"GOOGLE_CLOUD_PROJECT environment variable must be set.\")\n \t\tos.Exit(1)\n \t}\n \n-\trows, err := query(proj)\n+\t// [START bigquery_simple_app_client]\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"bigquery.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\t// [END bigquery_simple_app_client]\n+\n+\trows, err := query(ctx, client)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -46,16 +56,8 @@\nfunc main() {\n \t}\n }\n \n-// query returns a slice of the results of a query.\n-func query(proj string) (*bigquery.RowIterator, error) {\n-\t// [START bigquery_simple_app_client]\n-\tctx := context.Background()\n-\n-\tclient, err := bigquery.NewClient(ctx, proj)\n-\tif err != nil {\n-\t\treturn nil, err\n-\t}\n-\t// [END bigquery_simple_app_client]\n+// query returns a row iterator suitable for reading query results.\n+func query(ctx context.Context, client *bigquery.Client) (*bigquery.RowIterator, error) {\n \n \t// [START bigquery_simple_app_query]\n \tquery := client.Query(",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -18,16 +18,17 @@\npackage job\n \n import (\n-\t\"cloud.google.com/go/bigquery\"\n-\t\"cloud.google.com/go/storage\"\n \t\"context\"\n \t\"fmt\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/bigquery/snippets/bqtestutil\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"google.golang.org/api/iterator\"\n \t\"io/ioutil\"\n \t\"testing\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/bigquery\"\n+\t\"cloud.google.com/go/storage\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/bigquery/snippets/bqtestutil\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n func TestJobs(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -38,6 +39,7 @@\nfunc TestJobs(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\tdefer client.Close()\n \n \t// Control a job lifecycle explicitly: create, report status, cancel.\n \texampleJobID, err := bqtestutil.UniqueBQName(\"golang_example_job\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -67,6 +69,7 @@\nfunc TestCopiesAndExtracts(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\tdefer client.Close()\n \n \tmeta := &bigquery.DatasetMetadata{\n \t\tLocation: \"US\", // See https://cloud.google.com/bigquery/docs/locations",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/snippets/querying/bigquery_query_clustered_table.go",
        "code_diff": "@@ -16,11 +16,12 @@\npackage querying\n \n // [START bigquery_query_clustered_table]\n import (\n-\t\"cloud.google.com/go/bigquery\"\n \t\"context\"\n \t\"fmt\"\n-\t\"google.golang.org/api/iterator\"\n \t\"io\"\n+\n+\t\"cloud.google.com/go/bigquery\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n // queryClusteredTable demonstrates querying a table that has a clustering specification.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "bigquery/snippets/table/bigquery_table_insert_rows.go",
        "code_diff": "@@ -29,11 +29,12 @@\ntype Item struct {\n }\n \n // Save implements the ValueSaver interface.\n+// This example disables best-effort de-duplication, which allows for higher throughput.\n func (i *Item) Save() (map[string]bigquery.Value, string, error) {\n \treturn map[string]bigquery.Value{\n \t\t\"full_name\": i.Name,\n \t\t\"age\":       i.Age,\n-\t}, \"\", nil\n+\t}, bigquery.NoDedupeID, nil\n }\n \n // insertRows demonstrates inserting data into a table using the streaming insert mechanism.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "cdn/signedurls/signurl.go",
        "code_diff": "@@ -12,28 +12,30 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Command signedurls creates a signed URL for a Cloud CDN endpoint with the\n+// Package signedurl creates a signed URL for a Cloud CDN endpoint with the\n // given key.\n-package main\n+package signedurl\n \n+// [START example]\n import (\n \t\"crypto/hmac\"\n \t\"crypto/sha1\"\n \t\"encoding/base64\"\n \t\"fmt\"\n+\t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n+\t\"os\"\n \t\"strings\"\n \t\"time\"\n )\n \n-// [START example]\n-\n-// SignURL creates a signed URL for an endpoint on Cloud CDN. url must start\n-// with \"https://\" and should not have the \"Expires\", \"KeyName\", or \"Signature\"\n-// query parameters. key should be in raw form (not base64url-encoded) which is\n-// 16-bytes long. keyName should be added to the backend service or bucket.\n-func SignURL(url, keyName string, key []byte, expiration time.Time) string {\n+// SignURL creates a signed URL for an endpoint on Cloud CDN.\n+//\n+// - url must start with \"https://\" and should not have the \"Expires\", \"KeyName\", or \"Signature\"\n+// query parameters.\n+// - key should be in raw form (not base64url-encoded) which is 16-bytes long.\n+// - keyName must match a key added to the backend service or bucket.\n+func signURL(url, keyName string, key []byte, expiration time.Time) string {\n \tsep := \"?\"\n \tif strings.Contains(url, \"?\") {\n \t\tsep = \"&\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "cdn/signedurls/signurl.go",
        "code_diff": "@@ -49,6 +51,31 @@\nfunc SignURL(url, keyName string, key []byte, expiration time.Time) string {\n \treturn url\n }\n \n+// SignURLWithPrefix creates a signed URL prefix for an endpoint on Cloud CDN.\n+// Prefixes allow access to any URL with the same prefix, and can be useful for\n+// granting access broader content without signing multiple URLs.\n+//\n+// - urlPrefix must start with \"https://\" and should not include query parameters.\n+// - key should be in raw form (not base64url-encoded) which is 16-bytes long.\n+// - keyName must match a key added to the backend service or bucket.\n+func signURLWithPrefix(urlPrefix, keyName string, key []byte, expiration time.Time) (string, error) {\n+\tif strings.Contains(urlPrefix, \"?\") {\n+\t\treturn \"\", fmt.Errorf(\"urlPrefix must not include query params: %s\", urlPrefix)\n+\t}\n+\n+\tencodedURLPrefix := base64.URLEncoding.EncodeToString([]byte(urlPrefix))\n+\tinput := fmt.Sprintf(\"URLPrefix=%s&Expires=%d&KeyName=%s\",\n+\t\tencodedURLPrefix, expiration.Unix(), keyName)\n+\n+\tmac := hmac.New(sha1.New, key)\n+\tmac.Write([]byte(input))\n+\tsig := base64.URLEncoding.EncodeToString(mac.Sum(nil))\n+\n+\tsignedValue := fmt.Sprintf(\"%s&Signature=%s\", input, sig)\n+\n+\treturn signedValue, nil\n+}\n+\n // readKeyFile reads the base64url-encoded key file and decodes it.\n func readKeyFile(path string) ([]byte, error) {\n \tb, err := ioutil.ReadFile(path)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "cdn/signedurls/signurl_test.go",
        "code_diff": "@@ -11,7 +11,7 @@\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n // See the License for the specific language governing permissions and\n // limitations under the License.\n-package main\n+package signedurl\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "dataproc/quickstart/quickstart_test.go",
        "code_diff": "@@ -42,40 +42,6 @@\nsum = rdd.reduce(lambda x, y: x + y)`\n \tregion = \"us-central1\"\n )\n \n-func cleanBucket(ctx context.Context, t *testing.T, client *storage.Client, projectID, bucket string) {\n-\tb := client.Bucket(bucket)\n-\t_, err := b.Attrs(ctx)\n-\tif err == nil {\n-\t\tit := b.Objects(ctx, nil)\n-\t\tfor {\n-\t\t\tattrs, err := it.Next()\n-\t\t\tif err == iterator.Done {\n-\t\t\t\tbreak\n-\t\t\t}\n-\t\t\tif err != nil {\n-\t\t\t\tt.Fatalf(\"Bucket.Objects(%q): %v\", bucket, err)\n-\t\t\t}\n-\t\t\tif attrs.EventBasedHold || attrs.TemporaryHold {\n-\t\t\t\tif _, err := b.Object(attrs.Name).Update(ctx, storage.ObjectAttrsToUpdate{\n-\t\t\t\t\tTemporaryHold:  false,\n-\t\t\t\t\tEventBasedHold: false,\n-\t\t\t\t}); err != nil {\n-\t\t\t\t\tt.Fatalf(\"Bucket(%q).Object(%q).Update: %v\", bucket, attrs.Name, err)\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tif err := b.Object(attrs.Name).Delete(ctx); err != nil {\n-\t\t\t\tt.Fatalf(\"Bucket(%q).Object(%q).Delete: %v\", bucket, attrs.Name, err)\n-\t\t\t}\n-\t\t}\n-\t\tif err := b.Delete(ctx); err != nil {\n-\t\t\tt.Fatalf(\"Bucket.Delete(%q): %v\", bucket, err)\n-\t\t}\n-\t}\n-\tif err := b.Create(ctx, projectID, nil); err != nil {\n-\t\tt.Fatalf(\"Bucket.Create(%q): %v\", bucket, err)\n-\t}\n-}\n-\n func setup(t *testing.T, projectID string) {\n \tctx := context.Background()\n \tflag.Parse()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -98,7 +98,10 @@\nfunc riskCategorical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub\n \tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())\n \n \t// Wait for the risk job to finish by waiting for a PubSub message.\n-\tctx, cancel := context.WithCancel(ctx)\n+\t// This only waits for 1 minute. For long jobs, consider using a truly\n+\t// asynchronous execution model such as Cloud Functions.\n+\tctx, cancel := context.WithTimeout(ctx, 1*time.Minute)\n+\tdefer cancel()\n \terr = s.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\t// If this is the wrong job, do not process the result.\n \t\tif msg.Attributes[\"DlpJobName\"] != j.GetName() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -39,55 +39,55 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Numerical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\t\t\twants := []string{\"Created job\", \"Value range\", \"Value at\"}\n-\t\t\t\tgot := buf.String()\n-\t\t\t\tfor _, want := range wants {\n-\t\t\t\t\tif !strings.Contains(got, want) {\n-\t\t\t\t\t\tr.Errorf(\"riskNumerical got %s, want substring %q\", got, want)\n-\t\t\t\t\t}\n+\t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tr.Errorf(\"riskNumerical got err: %v\", err)\n+\t\t\t\t\treturn\n+\t\t\t\t}\n+\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n+\t\t\t\t\tr.Errorf(\"riskNumerical got %s, want substring %q\", got, want)\n \t\t\t\t}\n \t\t\t},\n \t\t},\n \t\t{\n \t\t\tname: \"Categorical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n-\t\t\t\twants := []string{\"Created job\", \"Histogram bucket\", \"Most common value occurs\"}\n-\t\t\t\tgot := buf.String()\n-\t\t\t\tfor _, want := range wants {\n-\t\t\t\t\tif !strings.Contains(got, want) {\n-\t\t\t\t\t\tr.Errorf(\"riskCategorical got %s, want substring %q\", got, want)\n-\t\t\t\t\t}\n+\t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tr.Errorf(\"riskCategorical got err: %v\", err)\n+\t\t\t\t\treturn\n+\t\t\t\t}\n+\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n+\t\t\t\t\tr.Errorf(\"riskCategorical got %s, want substring %q\", got, want)\n \t\t\t\t}\n \t\t\t},\n \t\t},\n \t\t{\n \t\t\tname: \"K Anonymity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n-\t\t\t\twants := []string{\"Created job\", \"Histogram bucket\", \"Size range\"}\n-\t\t\t\tgot := buf.String()\n-\t\t\t\tfor _, want := range wants {\n-\t\t\t\t\tif !strings.Contains(got, want) {\n-\t\t\t\t\t\tr.Errorf(\"riskKAnonymity got %s, want substring %q\", got, want)\n-\t\t\t\t\t}\n+\t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tr.Errorf(\"riskKAnonymity got err: %v\", err)\n+\t\t\t\t\treturn\n+\t\t\t\t}\n+\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n+\t\t\t\t\tr.Errorf(\"riskKAnonymity got %s, want substring %q\", got, want)\n \t\t\t\t}\n \t\t\t},\n \t\t},\n \t\t{\n \t\t\tname: \"L Diversity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n-\t\t\t\twants := []string{\"Created job\", \"Histogram bucket\", \"Size range\"}\n-\t\t\t\tgot := buf.String()\n-\t\t\t\tfor _, want := range wants {\n-\t\t\t\t\tif !strings.Contains(got, want) {\n-\t\t\t\t\t\tr.Errorf(\"riskLDiversity got %s, want substring %q\", got, want)\n-\t\t\t\t\t}\n+\t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tr.Errorf(\"riskLDiversity got err: %v\", err)\n+\t\t\t\t\treturn\n+\t\t\t\t}\n+\t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {\n+\t\t\t\t\tr.Errorf(\"riskLDiversity got %s, want substring %q\", got, want)\n \t\t\t\t}\n \t\t\t},\n \t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "functions/slack/search.go",
        "code_diff": "@@ -93,7 +93,7 @@\nfunc KGSearch(w http.ResponseWriter, r *http.Request) {\n \t}\n \n \tif len(r.Form[\"text\"]) == 0 {\n-\t\tlog.Fatalf(\"emtpy text in form\")\n+\t\tlog.Fatalf(\"empty text in form\")\n \t}\n \tkgSearchResponse, err := makeSearchRequest(r.Form[\"text\"][0])\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "healthcare/dicom_export.go",
        "code_diff": "@@ -20,7 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\thealthcare \"google.golang.org/api/healthcare/v1beta1\"\n+\thealthcare \"google.golang.org/api/healthcare/v1\"\n )\n \n // exportDICOMInstance exports DICOM objects to GCS.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "healthcare/dicom_import.go",
        "code_diff": "@@ -20,7 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\thealthcare \"google.golang.org/api/healthcare/v1beta1\"\n+\thealthcare \"google.golang.org/api/healthcare/v1\"\n )\n \n // importDICOMInstance imports DICOM objects from GCS.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "healthcare/fhir_resource_export.go",
        "code_diff": "@@ -21,7 +21,7 @@\nimport (\n \t\"io\"\n \t\"time\"\n \n-\thealthcare \"google.golang.org/api/healthcare/v1beta1\"\n+\thealthcare \"google.golang.org/api/healthcare/v1\"\n )\n \n // exportFHIRResource exports the resources in the FHIR store.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "healthcare/fhir_resource_import.go",
        "code_diff": "@@ -21,7 +21,7 @@\nimport (\n \t\"io\"\n \t\"time\"\n \n-\thealthcare \"google.golang.org/api/healthcare/v1beta1\"\n+\thealthcare \"google.golang.org/api/healthcare/v1\"\n )\n \n // importsFHIRResource imports an FHIR resource.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "healthcare/fhir_store_create.go",
        "code_diff": "@@ -20,7 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\thealthcare \"google.golang.org/api/healthcare/v1beta1\"\n+\thealthcare \"google.golang.org/api/healthcare/v1\"\n )\n \n // createFHIRStore creates an FHIR store.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "healthcare/fhir_test.go",
        "code_diff": "@@ -24,12 +24,10 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n-\t\"cloud.google.com/go/storage\"\n \tconditionaldelete \"github.com/GoogleCloudPlatform/golang-samples/healthcare/internal/fhir-resource-conditional-delete\"\n \tconditionalpatch \"github.com/GoogleCloudPlatform/golang-samples/healthcare/internal/fhir-resource-conditional-patch\"\n \tconditionalupdate \"github.com/GoogleCloudPlatform/golang-samples/healthcare/internal/fhir-resource-conditional-update\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"google.golang.org/api/iterator\"\n )\n \n // TestFHIRStore runs all FHIR store tests to avoid having to",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "healthcare/fhir_test.go",
        "code_diff": "@@ -248,7 +246,8 @@\nfunc TestFHIRStore(t *testing.T) {\n \t\t}\n \t})\n \n-\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t// Longer retry time to avoid bucket create/delete API quota issues.\n+\ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n \t\tbuf.Reset()\n \t\t// Delete the bucket (if it exists) then recreate it, optimistically\n \t\t// ignoring errors.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "healthcare/fhir_test.go",
        "code_diff": "@@ -257,7 +256,7 @@\nfunc TestFHIRStore(t *testing.T) {\n \t\t// fail until they give the agent access to the bucket.\n \t\tbucketName := tc.ProjectID + \"-healthcare-test\"\n \t\tgsURIPrefix := \"gs://\" + bucketName + \"/fhir-export/\"\n-\t\tcleanBucket(tc.ProjectID, bucketName)\n+\t\ttestutil.CleanBucket(context.Background(), t, tc.ProjectID, bucketName)\n \n \t\tif err := exportFHIRResource(buf, tc.ProjectID, location, datasetID, fhirStoreID, gsURIPrefix); err != nil {\n \t\t\tr.Errorf(\"exportFHIRResource got err: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "healthcare/hl7v2_message_list.go",
        "code_diff": "@@ -20,7 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\thealthcare \"google.golang.org/api/healthcare/v1beta1\"\n+\thealthcare \"google.golang.org/api/healthcare/v1\"\n )\n \n // listHL7V2Messages prints a list of HL7V2 messages to w.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "healthcare/hl7v2_store_patch.go",
        "code_diff": "@@ -20,7 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\thealthcare \"google.golang.org/api/healthcare/v1beta1\"\n+\thealthcare \"google.golang.org/api/healthcare/v1\"\n )\n \n // patchHL7V2Store updates (patches) a HL7V2 store by updating its Pub/sub topic name.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "iam/quickstart/quickstart.go",
        "code_diff": "@@ -21,21 +21,15 @@\nimport (\n \t\"context\"\n \t\"log\"\n \n-\t\"golang.org/x/oauth2/google\"\n \t\"google.golang.org/api/iam/v1\"\n )\n \n func main() {\n-\t// Get credentials.\n-\tclient, err := google.DefaultClient(context.Background(), iam.CloudPlatformScope)\n-\tif err != nil {\n-\t\tlog.Fatalf(\"google.DefaultClient: %v\", err)\n-\t}\n-\n \t// Create the Cloud IAM service object.\n-\tservice, err := iam.New(client)\n+\tctx := context.Background()\n+\tservice, err := iam.NewService(ctx)\n \tif err != nil {\n-\t\tlog.Fatalf(\"iam.New: %v\", err)\n+\t\tlog.Fatalf(\"iam.NewService: %v\", err)\n \t}\n \n \t// Call the Cloud IAM Roles API.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "internal/testutil/testutil.go",
        "code_diff": "@@ -23,12 +23,11 @@\nimport (\n \t\"path/filepath\"\n \t\"strings\"\n \t\"testing\"\n-\n-\t\"golang.org/x/tools/go/packages\"\n )\n \n-var noProjectID = errors.New(\"GOLANG_SAMPLES_PROJECT_ID not set\")\n+var errNoProjectID = errors.New(\"GOLANG_SAMPLES_PROJECT_ID not set\")\n \n+// Context holds information useful for tests.\n type Context struct {\n \tProjectID string\n \tDir       string",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "internal/testutil/testutil.go",
        "code_diff": "@@ -44,7 +43,7 @@\nfunc (tc Context) Path(p ...string) string {\n // ok is false if the project is not set up properly for system tests.\n func ContextMain(m *testing.M) (tc Context, ok bool) {\n \tc, err := testContext()\n-\tif err == noProjectID {\n+\tif err == errNoProjectID {\n \t\treturn c, false\n \t} else if err != nil {\n \t\tlog.Fatal(err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "internal/testutil/testutil.go",
        "code_diff": "@@ -56,7 +55,7 @@\nfunc ContextMain(m *testing.M) (tc Context, ok bool) {\n // The test is skipped if the GOLANG_SAMPLES_PROJECT_ID environment variable is not set.\n func SystemTest(t *testing.T) Context {\n \ttc, err := testContext()\n-\tif err == noProjectID {\n+\tif err == errNoProjectID {\n \t\tt.Skip(err)\n \t} else if err != nil {\n \t\tt.Fatal(err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "jobs/v4/howto/commute_search_sample.go",
        "code_diff": "@@ -22,7 +22,6 @@\nimport (\n \n \ttalent \"cloud.google.com/go/talent/apiv4beta1\"\n \t\"github.com/golang/protobuf/ptypes/duration\"\n-\t\"google.golang.org/api/iterator\"\n \ttalentpb \"google.golang.org/genproto/googleapis/cloud/talent/v4beta1\"\n \t\"google.golang.org/genproto/googleapis/type/latlng\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "jobs/v4/howto/custom_ranking_search.go",
        "code_diff": "@@ -21,7 +21,6 @@\nimport (\n \t\"io\"\n \n \ttalent \"cloud.google.com/go/talent/apiv4beta1\"\n-\t\"google.golang.org/api/iterator\"\n \ttalentpb \"google.golang.org/genproto/googleapis/cloud/talent/v4beta1\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "jobs/v4/howto/histogram_search_sample.go",
        "code_diff": "@@ -21,7 +21,6 @@\nimport (\n \t\"io\"\n \n \ttalent \"cloud.google.com/go/talent/apiv4beta1\"\n-\t\"google.golang.org/api/iterator\"\n \ttalentpb \"google.golang.org/genproto/googleapis/cloud/talent/v4beta1\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/create_key_asymmetric_decrypt.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/create_key_labels.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/create_key_ring.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/decrypt_asymmetric.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/decrypt_symmetric.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/destroy_key_version.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/disable_key_version.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/disable_key_version.go",
        "code_diff": "@@ -14,25 +14,28 @@\npackage kms\n \n-// [START kms_disable_cryptokey_version]\n+// [START kms_disable_key_version]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \n-\tcloudkms \"cloud.google.com/go/kms/apiv1\"\n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n \tfieldmask \"google.golang.org/genproto/protobuf/field_mask\"\n )\n \n-// disableCryptoKeyVersion disables a specified key version on KMS.\n-func disableCryptoKeyVersion(w io.Writer, name string) error {\n-\t// name := \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n+// disableKeyVersion disables the specified key version on Cloud KMS.\n+func disableKeyVersion(w io.Writer, name string) error {\n+\t// parent := \"projects/my-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key/cryptoKeyVersions/123\"\n+\n+\t// Create the client.\n \tctx := context.Background()\n-\tclient, err := cloudkms.NewKeyManagementClient(ctx)\n+\tclient, err := kms.NewKeyManagementClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"cloudkms.NewKeyManagementClient: %v\", err)\n+\t\treturn fmt.Errorf(\"failed to create kms client: %v\", err)\n \t}\n+\n \t// Build the request.\n \treq := &kmspb.UpdateCryptoKeyVersionRequest{\n \t\tCryptoKeyVersion: &kmspb.CryptoKeyVersion{",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/enable_key_version.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/enable_key_version.go",
        "code_diff": "@@ -14,25 +14,28 @@\npackage kms\n \n-// [START kms_enable_cryptokey_version]\n+// [START kms_enable_key_version]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \n-\tcloudkms \"cloud.google.com/go/kms/apiv1\"\n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n \tfieldmask \"google.golang.org/genproto/protobuf/field_mask\"\n )\n \n-// enableCryptoKeyVersion enables a previously disabled key version on KMS.\n-func enableCryptoKeyVersion(w io.Writer, name string) error {\n-\t// name := \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n+// enableKeyVersion disables the specified key version on Cloud KMS.\n+func enableKeyVersion(w io.Writer, name string) error {\n+\t// parent := \"projects/my-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key/cryptoKeyVersions/123\"\n+\n+\t// Create the client.\n \tctx := context.Background()\n-\tclient, err := cloudkms.NewKeyManagementClient(ctx)\n+\tclient, err := kms.NewKeyManagementClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"cloudkms.NewKeyManagementClient: %v\", err)\n+\t\treturn fmt.Errorf(\"failed to create kms client: %v\", err)\n \t}\n+\n \t// Build the request.\n \treq := &kmspb.UpdateCryptoKeyVersionRequest{\n \t\tCryptoKeyVersion: &kmspb.CryptoKeyVersion{",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/get_key_labels.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/quickstart/quickstart.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/quickstart/quickstart.go",
        "code_diff": "@@ -22,34 +22,34 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \n-\tcloudkms \"cloud.google.com/go/kms/apiv1\"\n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \t\"google.golang.org/api/iterator\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n )\n \n func main() {\n+\t// GCP project with which to communicate.\n \tprojectID := \"your-project-id\"\n-\t// Location of the key rings.\n+\n+\t// Location in which to list key rings.\n \tlocationID := \"global\"\n \n-\t// Create the KMS client.\n+\t// Create the client.\n \tctx := context.Background()\n-\tclient, err := cloudkms.NewKeyManagementClient(ctx)\n+\tclient, err := kms.NewKeyManagementClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\tlog.Fatalf(\"failed to setup client: %v\", err)\n \t}\n \n-\t// The resource name of the key rings.\n-\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", projectID, locationID)\n-\n-\t// Build the request.\n-\treq := &kmspb.ListKeyRingsRequest{\n-\t\tParent: parent,\n+\t// Create the request to list KeyRings.\n+\tlistKeyRingsReq := &kmspb.ListKeyRingsRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, locationID),\n \t}\n-\t// Query the API.\n-\tit := client.ListKeyRings(ctx, req)\n \n-\t// Iterate and print results.\n+\t// List the KeyRings.\n+\tit := client.ListKeyRings(ctx, listKeyRingsReq)\n+\n+\t// Iterate and print the results.\n \tfor {\n \t\tresp, err := it.Next()\n \t\tif err == iterator.Done {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/restore_key_version.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/sign_asymmetric.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "kms/sign_asymmetric.go",
        "code_diff": "@@ -19,25 +19,39 @@\nimport (\n \t\"context\"\n \t\"crypto/sha256\"\n \t\"fmt\"\n+\t\"io\"\n \n-\tcloudkms \"cloud.google.com/go/kms/apiv1\"\n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n )\n \n-// signAsymmetric will sign a plaintext message using a saved asymmetric private key.\n-func signAsymmetric(name string, message []byte) ([]byte, error) {\n-\t// name: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n-\t// Note: some key algorithms will require a different hash function.\n-\t// For example, EC_SIGN_P384_SHA384 requires SHA-384.\n+// signAsymmetric will sign a plaintext message using a saved asymmetric private\n+// key stored in Cloud KMS.\n+func signAsymmetric(w io.Writer, name string, message string) error {\n+\t// name := \"projects/my-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key/cryptoKeyVersions/123\"\n+\t// message := \"my message\"\n+\n+\t// Create the client.\n \tctx := context.Background()\n-\tclient, err := cloudkms.NewKeyManagementClient(ctx)\n+\tclient, err := kms.NewKeyManagementClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"cloudkms.NewKeyManagementClient: %v\", err)\n+\t\treturn fmt.Errorf(\"failed to create kms client: %v\", err)\n \t}\n-\t// Find the digest of the message.\n+\n+\t// Convert the message into bytes. Cryptographic plaintexts and\n+\t// ciphertexts are always byte arrays.\n+\tplaintext := []byte(message)\n+\n+\t// Calculate the digest of the message.\n \tdigest := sha256.New()\n-\tdigest.Write(message)\n+\tif _, err := digest.Write(plaintext); err != nil {\n+\t\treturn fmt.Errorf(\"failed to create digest: %v\", err)\n+\t}\n+\n \t// Build the signing request.\n+\t//\n+\t// Note: Key algorithms will require a varying hash function. For example,\n+\t// EC_SIGN_P384_SHA384 requires SHA-384.\n \treq := &kmspb.AsymmetricSignRequest{\n \t\tName: name,\n \t\tDigest: &kmspb.Digest{",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/go-cmp/cmp\"\n )\n \n var topicID string",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -251,7 +252,7 @@\nfunc TestPullMsgsConcurrencyControl(t *testing.T) {\n \n \t// Publish 5 message to test with.\n \tconst numMsgs = 5\n-\tpublishMsgs(ctx, topic, 5)\n+\tpublishMsgs(ctx, topic, numMsgs)\n \n \tbuf := new(bytes.Buffer)\n \tif err := pullMsgsConcurrenyControl(buf, tc.ProjectID, subIDConc); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\npackage topics\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"io/ioutil\"\n \t\"sync\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -117,7 +118,6 @@\nfunc TestPublish(t *testing.T) {\n func TestPublishThatScales(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n-\tsetup(t)\n \tclient := setup(t)\n \tclient.CreateTopic(ctx, topicID)\n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "run/logging-manual/main_test.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n \t\"log\"\n \t\"net/http\"\n \t\"net/http/httptest\"\n+\t\"os\"\n \t\"testing\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "securitycenter/notifications/doc.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -28,14 +28,25 @@\nimport (\n \n \t\"cloud.google.com/go/civil\"\n \t\"cloud.google.com/go/spanner\"\n-\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n+\t\"github.com/golang/protobuf/ptypes\"\n \t\"google.golang.org/api/iterator\"\n+\t\"google.golang.org/api/option\"\n+\t\"google.golang.org/genproto/googleapis/longrunning\"\n+\t\"google.golang.org/grpc\"\n+\t\"google.golang.org/grpc/codes\"\n \n+\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n+\tpbts \"github.com/golang/protobuf/ptypes\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n+\tsppb \"google.golang.org/genproto/googleapis/spanner/v1\"\n+\t\"google.golang.org/genproto/protobuf/field_mask\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n type command func(ctx context.Context, w io.Writer, client *spanner.Client) error\n+type newClientCommand func(ctx context.Context, w io.Writer, database string) error\n type adminCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error\n+type backupCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error\n \n var (\n \tcommands = map[string]command{",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -88,6 +99,11 @@\nvar (\n \t\t\"querywithint\":                queryWithInt,\n \t\t\"querywithstring\":             queryWithString,\n \t\t\"querywithtimestampparameter\": queryWithTimestampParameter,\n+\t\t\"querywithqueryoptions\":       queryWithQueryOptions,\n+\t}\n+\n+\tnewClientCommands = map[string]newClientCommand{\n+\t\t\"createclientwithqueryoptions\": createClientWithQueryOptions,\n \t}\n \n \tadminCommands = map[string]adminCommand{",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -100,6 +116,17 @@\nvar (\n \t\t\"createtablewithdatatypes\":        createTableWithDatatypes,\n \t\t\"createtabledocswithtimestamp\":    createTableDocumentsWithTimestamp,\n \t\t\"createtabledocswithhistorytable\": createTableDocumentsWithHistoryTable,\n+\t\t\"listbackupoperations\":            listBackupOperations,\n+\t\t\"listdatabaseoperations\":          listDatabaseOperations,\n+\t}\n+\n+\tbackupCommands = map[string]backupCommand{\n+\t\t\"createbackup\":  createBackup,\n+\t\t\"cancelbackup\":  cancelBackup,\n+\t\t\"listbackups\":   listBackups,\n+\t\t\"updatebackup\":  updateBackup,\n+\t\t\"deletebackup\":  deleteBackup,\n+\t\t\"restorebackup\": restoreBackup,\n \t}\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1599,6 +1626,35 @@\nfunc queryWithTimestampParameter(ctx context.Context, w io.Writer, client *spann\n \n // [END spanner_query_with_timestamp_parameter]\n \n+// [START spanner_query_with_query_options]\n+\n+func queryWithQueryOptions(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tstmt := spanner.Statement{SQL: `SELECT VenueId, VenueName, LastUpdateTime FROM Venues`}\n+\tqueryOptions := spanner.QueryOptions{\n+\t\tOptions: &sppb.ExecuteSqlRequest_QueryOptions{OptimizerVersion: \"1\"},\n+\t}\n+\titer := client.Single().QueryWithOptions(ctx, stmt, queryOptions)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar lastUpdateTime time.Time\n+\t\tif err := row.Columns(&venueID, &venueName, &lastUpdateTime); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, lastUpdateTime)\n+\t}\n+}\n+\n+// [END spanner_query_with_query_options]\n+\n func queryNewTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n \tstmt := spanner.Statement{\n \t\tSQL: `SELECT SingerId, VenueId, EventDate, Revenue, LastUpdateTime FROM Performances",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1819,12 +1875,402 @@\nfunc queryWithHistory(ctx context.Context, w io.Writer, client *spanner.Client)\n \t}\n }\n \n+// [START spanner_create_client_with_query_options]\n+\n+func createClientWithQueryOptions(ctx context.Context, w io.Writer, database string) error {\n+\tqueryOptions := spanner.QueryOptions{\n+\t\tOptions: &sppb.ExecuteSqlRequest_QueryOptions{OptimizerVersion: \"1\"},\n+\t}\n+\tclient, err := spanner.NewClientWithConfig(\n+\t\tctx, database, spanner.ClientConfig{QueryOptions: queryOptions},\n+\t)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tstmt := spanner.Statement{SQL: `SELECT VenueId, VenueName, LastUpdateTime FROM Venues`}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar lastUpdateTime time.Time\n+\t\tif err := row.Columns(&venueID, &venueName, &lastUpdateTime); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, lastUpdateTime)\n+\t}\n+}\n+\n+// [END spanner_create_client_with_query_options]\n+\n+// [START spanner_create_backup]\n+\n+func createBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\texpireTime := time.Now().AddDate(0, 0, 14)\n+\t// Create a backup.\n+\top, err := adminClient.StartBackupOperation(ctx, backupID, database, expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Wait for backup operation to complete.\n+\tbackup, err := op.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Get the name, create time and backup size.\n+\tcreateTime := time.Unix(backup.CreateTime.Seconds, int64(backup.CreateTime.Nanos))\n+\tfmt.Fprintf(w, \"Backup %s of size %d bytes was created at %s\\n\", backup.Name, backup.SizeBytes, createTime.Format(time.RFC3339))\n+\treturn nil\n+}\n+\n+// [END spanner_create_backup]\n+\n+// [START spanner_cancel_backup_create]\n+\n+func cancelBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\texpireTime := time.Now().AddDate(0, 0, 14)\n+\t// Create a backup.\n+\top, err := adminClient.StartBackupOperation(ctx, backupID, database, expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Cancel backup creation.\n+\terr = adminClient.LROClient.CancelOperation(ctx, &longrunning.CancelOperationRequest{Name: op.Name()})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Cancel operations are best effort so either it will complete or be\n+\t// cancelled.\n+\tbackup, err := op.Wait(ctx)\n+\tif err != nil {\n+\t\tif waitStatus, ok := status.FromError(err); !ok || waitStatus.Code() != codes.Canceled {\n+\t\t\treturn err\n+\t\t}\n+\t} else {\n+\t\t// Backup was completed before it could be cancelled so delete the\n+\t\t// unwanted backup.\n+\t\terr = adminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: backup.Name})\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\tfmt.Fprintf(w, \"Backup cancelled.\\n\")\n+\treturn nil\n+}\n+\n+// [END spanner_cancel_backup_create]\n+\n+// [START spanner_list_backups]\n+\n+func listBackups(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, db, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(db)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", db)\n+\t}\n+\tinstanceName := matches[1]\n+\n+\tprintBackups := func(iter *database.BackupIterator) error {\n+\t\tfor {\n+\t\t\tresp, err := iter.Next()\n+\t\t\tif err == iterator.Done {\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t\tif err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tfmt.Fprintf(w, \"Backup %s\\n\", resp.Name)\n+\t\t}\n+\t}\n+\n+\tvar iter *database.BackupIterator\n+\tvar filter string\n+\t// List all backups.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups that contain a name.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"name:\" + backupID,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups that expire before a timestamp.\n+\texpireTime := time.Now().AddDate(0, 0, 30)\n+\tfilter = fmt.Sprintf(`expire_time < \"%s\"`, expireTime.Format(time.RFC3339))\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups for a database that contains a name.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"database:\" + db,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups with a size greater than some bytes.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"size_bytes > 100\",\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List backups that were created after a timestamp that are also ready.\n+\tcreateTime := time.Now().AddDate(0, 0, -1)\n+\tfilter = fmt.Sprintf(\n+\t\t`create_time >= \"%s\" AND state:READY`,\n+\t\tcreateTime.Format(time.RFC3339),\n+\t)\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List backups with pagination.\n+\trequest := &adminpb.ListBackupsRequest{\n+\t\tParent:   instanceName,\n+\t\tPageSize: 10,\n+\t}\n+\tfor {\n+\t\titer = adminClient.ListBackups(ctx, request)\n+\t\tif err := printBackups(iter); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tpageToken := iter.PageInfo().Token\n+\t\tif pageToken == \"\" {\n+\t\t\tbreak\n+\t\t} else {\n+\t\t\trequest.PageToken = pageToken\n+\t\t}\n+\t}\n+\n+\tfmt.Fprintf(w, \"Backups listed.\\n\")\n+\treturn nil\n+}\n+\n+// [END spanner_list_backups]\n+\n+// [START spanner_list_backup_operations]\n+\n+func listBackupOperations(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\t// List the CreateBackup operations.\n+\tfilter := fmt.Sprintf(\"(metadata.database:%s) AND (metadata.@type:type.googleapis.com/google.spanner.admin.database.v1.CreateBackupMetadata)\", database)\n+\titer := adminClient.ListBackupOperations(ctx, &adminpb.ListBackupOperationsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tmetadata := &adminpb.CreateBackupMetadata{}\n+\t\tif err := ptypes.UnmarshalAny(resp.Metadata, metadata); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"Backup %s on database %s is %d%% complete.\\n\",\n+\t\t\tmetadata.Name,\n+\t\t\tmetadata.Database,\n+\t\t\tmetadata.Progress.ProgressPercent,\n+\t\t)\n+\t}\n+\treturn nil\n+}\n+\n+// [END spanner_list_backup_operations]\n+\n+// [START spanner_list_database_operations]\n+\n+func listDatabaseOperations(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\t// List the databases that are being optimized after a restore operation.\n+\tfilter := \"(metadata.@type:type.googleapis.com/google.spanner.admin.database.v1.OptimizeRestoredDatabaseMetadata)\"\n+\titer := adminClient.ListDatabaseOperations(ctx, &adminpb.ListDatabaseOperationsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tmetadata := &adminpb.OptimizeRestoredDatabaseMetadata{}\n+\t\tif err := ptypes.UnmarshalAny(resp.Metadata, metadata); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"Database %s restored from backup is %d%% optimized.\\n\",\n+\t\t\tmetadata.Name,\n+\t\t\tmetadata.Progress.ProgressPercent,\n+\t\t)\n+\t}\n+\treturn nil\n+}\n+\n+// [END spanner_list_database_operations]\n+\n+// [START spanner_update_backup]\n+\n+func updateBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tbackupName := matches[1] + \"/backups/\" + backupID\n+\n+\tbackup, err := adminClient.GetBackup(ctx, &adminpb.GetBackupRequest{Name: backupName})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Expire time must be within 366 days of the create time of the backup.\n+\texpireTime := time.Unix(backup.CreateTime.Seconds, int64(backup.CreateTime.Nanos)).AddDate(0, 0, 30)\n+\texpirespb, err := pbts.TimestampProto(expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t_, err = adminClient.UpdateBackup(ctx, &adminpb.UpdateBackupRequest{\n+\t\tBackup: &adminpb.Backup{\n+\t\t\tName:       backupName,\n+\t\t\tExpireTime: expirespb,\n+\t\t},\n+\t\tUpdateMask: &field_mask.FieldMask{Paths: []string{\"expire_time\"}},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Fprintf(w, \"Updated backup %s\\n\", backupID)\n+\treturn nil\n+}\n+\n+// [END spanner_update_backup]\n+\n+// [START spanner_restore_backup]\n+\n+func restoreBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\tdatabaseID := matches[2]\n+\tbackupName := instanceName + \"/backups/\" + backupID\n+\n+\t// Start restoring backup to a new database.\n+\trestoreOp, err := adminClient.RestoreDatabase(ctx, &adminpb.RestoreDatabaseRequest{\n+\t\tParent:     instanceName,\n+\t\tDatabaseId: databaseID,\n+\t\tSource: &adminpb.RestoreDatabaseRequest_Backup{\n+\t\t\tBackup: backupName,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Wait for restore operation to complete.\n+\tdb, err := restoreOp.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Newly created database has restore information.\n+\tbackupInfo := db.RestoreInfo.GetBackupInfo()\n+\tif backupInfo != nil {\n+\t\tfmt.Fprintf(w, \"Source database %s restored from backup %s\\n\", backupInfo.SourceDatabase, backupInfo.Backup)\n+\t}\n+\n+\treturn nil\n+}\n+\n+// [END spanner_restore_backup]\n+\n+// [START spanner_delete_backup]\n+\n+func deleteBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tbackupName := matches[1] + \"/backups/\" + backupID\n+\t// Delete the backup.\n+\terr := adminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: backupName})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Deleted backup %s\\n\", backupID)\n+\treturn nil\n+}\n+\n+// [END spanner_delete_backup]\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n-\tadminClient, err := database.NewDatabaseAdminClient(ctx)\n+\t// [START spanner_create_admin_client_for_emulator]\n+\n+\tvar opts []option.ClientOption\n+\n+\temulatorAddr := os.Getenv(\"SPANNER_EMULATOR_HOST\")\n+\tif emulatorAddr != \"\" {\n+\t\topts = append(\n+\t\t\topts,\n+\t\t\toption.WithEndpoint(emulatorAddr),\n+\t\t\toption.WithGRPCDialOption(grpc.WithInsecure()),\n+\t\t\toption.WithoutAuthentication(),\n+\t\t)\n+\t}\n+\n+\tadminClient, err := database.NewDatabaseAdminClient(ctx, opts...)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n \n+\t// [END spanner_create_admin_client_for_emulator]\n+\n \tdataClient, err := spanner.NewClient(ctx, db)\n \tif err != nil {\n \t\tlog.Fatal(err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1833,7 +2279,7 @@\nfunc createClients(ctx context.Context, db string) (*database.DatabaseAdminClien\n \treturn adminClient, dataClient\n }\n \n-func run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, w io.Writer, cmd string, db string) error {\n+func run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, w io.Writer, cmd string, db string, backupID string) error {\n \tif adminCmdFn := adminCommands[cmd]; adminCmdFn != nil {\n \t\terr := adminCmdFn(ctx, w, adminClient, db)\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1842,6 +2288,24 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \t\treturn err\n \t}\n \n+\t// Command that needs a backup ID.\n+\tif backupCmdFn := backupCommands[cmd]; backupCmdFn != nil {\n+\t\terr := backupCmdFn(ctx, w, adminClient, db, backupID)\n+\t\tif err != nil {\n+\t\t\tfmt.Fprintf(w, \"%s failed with %v\", cmd, err)\n+\t\t}\n+\t\treturn err\n+\t}\n+\n+\t// Command that needs to create a new client.\n+\tif newClientCmdFn := newClientCommands[cmd]; newClientCmdFn != nil {\n+\t\terr := newClientCmdFn(ctx, w, db)\n+\t\tif err != nil {\n+\t\t\tfmt.Fprintf(w, \"%s failed with %v\", cmd, err)\n+\t\t}\n+\t\treturn err\n+\t}\n+\n \t// Normal mode\n \tcmdFn := commands[cmd]\n \tif cmdFn == nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1857,7 +2321,7 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \n func main() {\n \tflag.Usage = func() {\n-\t\tfmt.Fprintf(os.Stderr, `Usage: spanner_snippets <command> <database_name>\n+\t\tfmt.Fprintf(os.Stderr, `Usage: spanner_snippets <command> <database_name> <backup_id>\n \n \tCommand can be one of: createdatabase, write, query, read, update,\n \t\twritetransaction, addnewcolumn, querynewcolumn, addindex, queryindex, readindex,",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -23,26 +23,23 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/spanner\"\n+\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n-func TestSample(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+type runCommandFunc func(t *testing.T, cmd, dbName string) string\n+type runBackupCommandFunc func(t *testing.T, cmd, dbName, backupID string) string\n \n-\tinstance := os.Getenv(\"GOLANG_SAMPLES_SPANNER\")\n-\tif instance == \"\" {\n-\t\tt.Skip(\"Skipping spanner integration test. Set GOLANG_SAMPLES_SPANNER.\")\n-\t}\n-\tif !strings.HasPrefix(instance, \"projects/\") {\n-\t\tt.Fatal(\"Spanner instance ref must be in the form of 'projects/PROJECT_ID/instances/INSTANCE_ID'\")\n-\t}\n-\tdbName := fmt.Sprintf(\"%s/databases/test-%s\", instance, tc.ProjectID)\n+func initTest(t *testing.T, projectID string) (dbName string, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, runCommand runCommandFunc, mustRunCommand runCommandFunc, cleanup func()) {\n+\tinstance := getInstance(t)\n+\tdatabaseID := validLength(fmt.Sprintf(\"test-%s\", projectID), t)\n+\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, databaseID)\n \n \tctx := context.Background()\n-\tadminClient, dataClient := createClients(ctx, dbName)\n-\tdefer adminClient.Close()\n-\tdefer dataClient.Close()\n+\tadminClient, dataClient = createClients(ctx, dbName)\n \n \t// Check for database existance prior to test start and delete, as resources may not have\n \t// been cleaned up from previous invocations.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -51,37 +48,89 @@\nfunc TestSample(t *testing.T) {\n \t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName}))\n \t}\n \n-\tassertContains := func(t *testing.T, out string, sub string) {\n-\t\tt.Helper()\n-\t\tif !strings.Contains(out, sub) {\n-\t\t\tt.Errorf(\"got output %q; want it to contain %q\", out, sub)\n-\t\t}\n-\t}\n-\trunCommand := func(t *testing.T, cmd string, dbName string) string {\n+\trunCommand = func(t *testing.T, cmd, dbName string) string {\n \t\tt.Helper()\n \t\tvar b bytes.Buffer\n-\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName); err != nil {\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, \"\"); err != nil {\n \t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n \t\treturn b.String()\n \t}\n-\tmustRunCommand := func(t *testing.T, cmd string, dbName string) string {\n+\tmustRunCommand = func(t *testing.T, cmd, dbName string) string {\n \t\tt.Helper()\n \t\tvar b bytes.Buffer\n-\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName); err != nil {\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, \"\"); err != nil {\n \t\t\tt.Fatalf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n \t\treturn b.String()\n \t}\n-\n-\tdefer func() {\n+\tcleanup = func() {\n+\t\tdataClient.Close()\n \t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n \t\t\tif err != nil {\n \t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n \t\t\t}\n \t\t})\n-\t}()\n+\t\tadminClient.Close()\n+\t}\n+\treturn\n+}\n+\n+func initBackupTest(t *testing.T, projectID, dbName string, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client) (restoreDBName, backupID, cancelledBackupID string, runBackupCommand runBackupCommandFunc, cleanup func()) {\n+\tinstance := getInstance(t)\n+\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", projectID), t)\n+\trestoreDBName = fmt.Sprintf(\"%s/databases/%s\", instance, restoreDatabaseID)\n+\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", projectID), t)\n+\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", projectID), t)\n+\n+\tctx := context.Background()\n+\tif db, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: restoreDBName}); err == nil {\n+\t\tt.Logf(\"database %s exists in state %s. delete result: %v\", db.GetName(), db.GetState().String(),\n+\t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName}))\n+\t}\n+\n+\t// Check for any backups that were created from that database and delete those as well\n+\titer := adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instance,\n+\t\tFilter: \"database:\" + dbName,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"Failed to list backups for database %s: %v\", dbName, err)\n+\t\t}\n+\t\tt.Logf(\"backup %s exists. delete result: %v\", resp.Name,\n+\t\t\tadminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: resp.Name}))\n+\t}\n+\n+\trunBackupCommand = func(t *testing.T, cmd, dbName, backupID string) string {\n+\t\tt.Helper()\n+\t\tvar b bytes.Buffer\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, backupID); err != nil {\n+\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n+\t\t}\n+\t\treturn b.String()\n+\t}\n+\tcleanup = func() {\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", restoreDBName, err)\n+\t\t\t}\n+\t\t})\n+\t}\n+\treturn\n+}\n+\n+func TestSample(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tdbName, _, _, runCommand, mustRunCommand, cleanup := initTest(t, tc.ProjectID)\n+\tdefer cleanup()\n \n \t// We execute all the commands of the tutorial code. These commands have to be run in a specific\n \t// order since in many cases earlier commands setup the database for the subsequent commands.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/acl/doc.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/buckets/doc.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/buckets/get_bucket_metadata.go",
        "code_diff": "@@ -16,37 +16,34 @@\n// using the Google Storage API. More documentation is available at\n // https://cloud.google.com/storage/docs/json_api/v1/.\n \n-package main\n+package buckets\n \n // [START storage_get_bucket_metadata]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n )\n \n-func getBucketMetadata(w io.Writer, client *storage.Client, bucketName string) (*storage.BucketAttrs, error) {\n+// getBucketMetadata gets the bucket metadata.\n+func getBucketMetadata(w io.Writer, bucketName string) (*storage.BucketAttrs, error) {\n \t// bucketName := \"bucket-name\"\n \tctx := context.Background()\n-\n-\t// Initialize client.\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\treturn nil, fmt.Errorf(\"storage.NewClient: %v\", err)\n \t}\n-\tdefer client.Close() // Closing the client safely cleans up background resources.\n+\tdefer client.Close()\n \n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tattrs, err := client.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn nil, fmt.Errorf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n \t}\n-\n \tfmt.Fprintf(w, \"BucketName: %v\\n\", attrs.Name)\n \tfmt.Fprintf(w, \"Location: %v\\n\", attrs.Location)\n \tfmt.Fprintf(w, \"LocationType: %v\\n\", attrs.LocationType)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -15,7 +15,9 @@\n// Sample buckets creates a bucket, lists buckets and deletes a bucket\n // using the Google Storage API. More documentation is available at\n // https://cloud.google.com/storage/docs/json_api/v1/.\n-package main\n+// +build ignore\n+\n+package buckets\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -28,6 +30,8 @@\nimport (\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/storage\"\n \t\"google.golang.org/api/iterator\"\n+\tiampb \"google.golang.org/genproto/googleapis/iam/v1\"\n+\t\"google.golang.org/genproto/googleapis/type/expr\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -159,18 +163,18 @@\nfunc deleteBucket(client *storage.Client, bucketName string) error {\n \treturn nil\n }\n \n-func getPolicy(c *storage.Client, bucketName string) (*iam.Policy, error) {\n+func getPolicy(c *storage.Client, bucketName string) (*iam.Policy3, error) {\n \t// [START storage_get_bucket_policy]\n \tctx := context.Background()\n \n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n-\tpolicy, err := c.Bucket(bucketName).IAM().Policy(ctx)\n+\tpolicy, err := c.Bucket(bucketName).IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\tfor _, role := range policy.Roles() {\n-\t\tlog.Printf(\"%q: %q\", role, policy.Members(role))\n+\tfor _, binding := range policy.Bindings {\n+\t\tlog.Printf(\"%q: %q (condition: %v)\", binding.Role, binding.Members, binding.Condition)\n \t}\n \t// [END storage_get_bucket_policy]\n \treturn policy, nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -183,15 +187,18 @@\nfunc addUser(c *storage.Client, bucketName string) error {\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n-\tpolicy, err := bucket.IAM().Policy(ctx)\n+\tpolicy, err := bucket.IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Other valid prefixes are \"serviceAccount:\", \"user:\"\n \t// See the documentation for more values.\n \t// https://cloud.google.com/storage/docs/access-control/iam\n-\tpolicy.Add(\"group:cloud-logs@google.com\", \"roles/storage.objectViewer\")\n-\tif err := bucket.IAM().SetPolicy(ctx, policy); err != nil {\n+\tpolicy.Bindings = append(policy.Bindings, &iampb.Binding{\n+\t\tRole:    \"roles/storage.objectViewer\",\n+\t\tMembers: []string{\"group:cloud-logs@google.com\"},\n+\t})\n+\tif err := bucket.IAM().V3().SetPolicy(ctx, policy); err != nil {\n \t\treturn err\n \t}\n \t// NOTE: It may be necessary to retry this operation if IAM policies are",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -208,15 +215,32 @@\nfunc removeUser(c *storage.Client, bucketName string) error {\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n-\tpolicy, err := bucket.IAM().Policy(ctx)\n+\tpolicy, err := bucket.IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Other valid prefixes are \"serviceAccount:\", \"user:\"\n \t// See the documentation for more values.\n \t// https://cloud.google.com/storage/docs/access-control/iam\n-\tpolicy.Remove(\"group:cloud-logs@google.com\", \"roles/storage.objectViewer\")\n-\tif err := bucket.IAM().SetPolicy(ctx, policy); err != nil {\n+\tfor _, binding := range policy.Bindings {\n+\t\t// Only remove unconditional bindings matching role\n+\t\tif binding.Role == \"roles/storage.objectViewer\" && binding.Condition == nil {\n+\t\t\t// Filter out member.\n+\t\t\ti := -1\n+\t\t\tfor j, member := range binding.Members {\n+\t\t\t\tif member == \"group:cloud-logs@google.com\" {\n+\t\t\t\t\ti = j\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif i == -1 {\n+\t\t\t\treturn errors.New(\"No matching binding group found.\")\n+\t\t\t} else {\n+\t\t\t\tbinding.Members = append(binding.Members[:i], binding.Members[i+1:]...)\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif err := bucket.IAM().V3().SetPolicy(ctx, policy); err != nil {\n \t\treturn err\n \t}\n \t// NOTE: It may be necessary to retry this operation if IAM policies are",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/gcsupload/gcsupload_test.go",
        "code_diff": "@@ -21,26 +21,17 @@\nimport (\n \t\"strings\"\n \t\"testing\"\n \n-\t\"google.golang.org/api/iterator\"\n-\n-\t\"cloud.google.com/go/storage\"\n-\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n func TestUpload(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n \tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Creating client: %v\", err)\n-\t}\n \tprojectID := tc.ProjectID\n \tbucket := projectID + \"-gcsupload\"\n \n-\tcleanBucket(t, ctx, client, projectID, bucket)\n-\tdefer deleteBucketIfExists(t, ctx, client, bucket)\n+\ttestutil.CleanBucket(ctx, t, projectID, bucket)\n \n \tinput := strings.Repeat(\"GCS test\\n\", 30)\n \tr := strings.NewReader(input)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -12,65 +12,60 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package objects\n \n import (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n-\t\"log\"\n \t\"net/http\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n-\t\"google.golang.org/api/iterator\"\n-\n \t\"cloud.google.com/go/storage\"\n-\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n-func TestMain(m *testing.M) {\n-\t// These functions are noisy.\n-\tlog.SetOutput(ioutil.Discard)\n-\ts := m.Run()\n-\tlog.SetOutput(os.Stderr)\n-\tos.Exit(s)\n-}\n+// TestObjects runs all samples tests of the package.\n func TestObjects(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tvar (\n-\t\tbucket    = tc.ProjectID + \"-samples-object-bucket-1\"\n-\t\tdstBucket = tc.ProjectID + \"-samples-object-bucket-2\"\n-\n-\t\tobject1 = \"foo.txt\"\n-\t\tobject2 = \"foo/a.txt\"\n+\t\tbucket                = tc.ProjectID + \"-samples-object-bucket-1\"\n+\t\tdstBucket             = tc.ProjectID + \"-samples-object-bucket-2\"\n+\t\tobject1               = \"foo.txt\"\n+\t\tobject2               = \"foo/a.txt\"\n+\t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers\n+\t\troleReader            = storage.RoleReader\n \t)\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n \tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n \n-\tif err := write(client, bucket, object1); err != nil {\n-\t\tt.Fatalf(\"write(%q): %v\", object1, err)\n+\tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n \t}\n-\tif err := write(client, bucket, object2); err != nil {\n-\t\tt.Fatalf(\"write(%q): %v\", object2, err)\n+\tif err := uploadFile(ioutil.Discard, bucket, object2); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object2, err)\n \t}\n \n \t{\n \t\t// Should only show \"foo/a.txt\", not \"foo.txt\"\n \t\tvar buf bytes.Buffer\n-\t\tif err := list(&buf, client, bucket); err != nil {\n-\t\t\tt.Fatalf(\"cannot list objects: %v\", err)\n+\t\tif err := listFiles(&buf, bucket); err != nil {\n+\t\t\tt.Fatalf(\"listFiles: %v\", err)\n \t\t}\n \t\tif got, want := buf.String(), object1; !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"List() got %q; want to contain %q\", got, want)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -84,8 +79,8 @@\nfunc TestObjects(t *testing.T) {\n \t\t// Should only show \"foo/a.txt\", not \"foo.txt\"\n \t\tconst prefix = \"foo/\"\n \t\tvar buf bytes.Buffer\n-\t\tif err := listByPrefix(&buf, client, bucket, prefix, \"\"); err != nil {\n-\t\t\tt.Fatalf(\"cannot list objects by prefix: %v\", err)\n+\t\tif err := listFilesWithPrefix(&buf, bucket, prefix, \"\"); err != nil {\n+\t\t\tt.Fatalf(\"listFilesWithPrefix: %v\", err)\n \t\t}\n \t\tif got, want := buf.String(), object1; strings.Contains(got, want) {\n \t\t\tt.Errorf(\"List(%q) got %q; want NOT to contain %q\", prefix, got, want)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -95,101 +90,79 @@\nfunc TestObjects(t *testing.T) {\n \t\t}\n \t}\n \n-\tdata, err := read(client, bucket, object1)\n+\t{\n+\t\tif err := downloadUsingRequesterPays(ioutil.Discard, bucket, object1, tc.ProjectID); err != nil {\n+\t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)\n+\t\t}\n+\t}\n+\n+\tdata, err := downloadFile(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Fatalf(\"cannot read object: %v\", err)\n+\t\tt.Fatalf(\"downloadFile: %v\", err)\n \t}\n \tif got, want := string(data), \"Hello\\nworld\"; got != want {\n \t\tt.Errorf(\"contents = %q; want %q\", got, want)\n \t}\n-\t_, err = attrs(client, bucket, object1)\n+\n+\t_, err = getMetadata(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n-\tif err := makePublic(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot to make object public: %v\", err)\n+\tif err := makePublic(ioutil.Discard, bucket, object1, allAuthenticatedUsers, roleReader); err != nil {\n+\t\tt.Errorf(\"makePublic: %v\", err)\n \t}\n-\terr = move(client, bucket, object1)\n+\n+\terr = moveFile(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Fatalf(\"cannot move object: %v\", err)\n+\t\tt.Fatalf(\"moveFile: %v\", err)\n \t}\n \t// object1's new name.\n \tobject1 = object1 + \"-rename\"\n \n-\tif err := copyToBucket(client, dstBucket, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot copy object to bucket: %v\", err)\n-\t}\n-\tif err := addBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot add bucket acl: %v\", err)\n-\t}\n-\tif err := addDefaultBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot add bucket default acl: %v\", err)\n-\t}\n-\tif err := bucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot get bucket acl: %v\", err)\n-\t}\n-\tif err := bucketACLFiltered(client, bucket, storage.AllAuthenticatedUsers); err != nil {\n-\t\tt.Errorf(\"cannot filter bucket acl: %v\", err)\n-\t}\n-\tif err := deleteDefaultBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot delete bucket default acl: %v\", err)\n-\t}\n-\tif err := deleteBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot delete bucket acl: %v\", err)\n-\t}\n-\tif err := addObjectACL(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot add object acl: %v\", err)\n-\t}\n-\tif err := objectACL(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot get object acl: %v\", err)\n-\t}\n-\tif err := objectACLFiltered(client, bucket, object1, storage.AllAuthenticatedUsers); err != nil {\n-\t\tt.Errorf(\"cannot filter object acl: %v\", err)\n-\t}\n-\tif err := deleteObjectACL(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot delete object acl: %v\", err)\n+\tif err := copyFile(ioutil.Discard, dstBucket, bucket, object1); err != nil {\n+\t\tt.Errorf(\"copyFile: %v\", err)\n \t}\n \n \tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \tnewKey := []byte(\"My-secret-AES-256-encryption-key\")\n \n-\tif err := writeEncryptedObject(client, bucket, object1, key); err != nil {\n-\t\tt.Errorf(\"cannot write an encrypted object: %v\", err)\n+\tif err := uploadEncryptedFile(ioutil.Discard, bucket, object1, key); err != nil {\n+\t\tt.Errorf(\"uploadEncryptedFile: %v\", err)\n \t}\n-\tdata, err = readEncryptedObject(client, bucket, object1, key)\n+\tdata, err = downloadEncryptedFile(ioutil.Discard, bucket, object1, key)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot read the encrypted object: %v\", err)\n+\t\tt.Errorf(\"downloadEncryptedFile: %v\", err)\n \t}\n \tif got, want := string(data), \"top secret\"; got != want {\n \t\tt.Errorf(\"object content = %q; want %q\", got, want)\n \t}\n-\tif err := rotateEncryptionKey(client, bucket, object1, key, newKey); err != nil {\n-\t\tt.Errorf(\"cannot encrypt the object with the new key: %v\", err)\n+\tif err := rotateEncryptionKey(ioutil.Discard, bucket, object1, key, newKey); err != nil {\n+\t\tt.Errorf(\"rotateEncryptionKey: %v\", err)\n \t}\n-\tif err := delete(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot to delete object: %v\", err)\n+\tif err := deleteFile(ioutil.Discard, bucket, object1); err != nil {\n+\t\tt.Errorf(\"deleteFile: %v\", err)\n \t}\n-\tif err := delete(client, bucket, object2); err != nil {\n-\t\tt.Errorf(\"cannot to delete object: %v\", err)\n+\tif err := deleteFile(ioutil.Discard, bucket, object2); err != nil {\n+\t\tt.Errorf(\"deleteFile: %v\", err)\n \t}\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\t// Cleanup, this part won't be executed if Fatal happens.\n \t\t// TODO(jbd): Implement garbage cleaning.\n \t\tif err := client.Bucket(bucket).Delete(ctx); err != nil {\n-\t\t\tr.Errorf(\"cleanup of bucket failed: %v\", err)\n+\t\t\tr.Errorf(\"Bucket(%q).Delete: %v\", bucket, err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := delete(client, dstBucket, object1+\"-copy\"); err != nil {\n-\t\t\tr.Errorf(\"cannot to delete copy object: %v\", err)\n+\t\tif err := deleteFile(ioutil.Discard, dstBucket, object1+\"-copy\"); err != nil {\n+\t\t\tr.Errorf(\"deleteFile: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\tif err := client.Bucket(dstBucket).Delete(ctx); err != nil {\n-\t\t\tr.Errorf(\"cleanup of bucket failed: %v\", err)\n+\t\t\tr.Errorf(\"Bucket(%q).Delete: %v\", dstBucket, err)\n \t\t}\n \t})\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -201,6 +174,7 @@\nfunc TestKMSObjects(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")\n \tcryptoKeyID := os.Getenv(\"GOLANG_SAMPLES_KMS_CRYPTOKEY\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -211,17 +185,16 @@\nfunc TestKMSObjects(t *testing.T) {\n \tvar (\n \t\tbucket    = tc.ProjectID + \"-samples-object-bucket-1\"\n \t\tdstBucket = tc.ProjectID + \"-samples-object-bucket-2\"\n-\n-\t\tobject1 = \"foo.txt\"\n+\t\tobject1   = \"foo.txt\"\n \t)\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n \tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \n-\tif err := writeWithKMSKey(client, bucket, object1, kmsKeyName); err != nil {\n-\t\tt.Errorf(\"cannot write a KMS encrypted object: %v\", err)\n+\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object1, kmsKeyName); err != nil {\n+\t\tt.Errorf(\"uploadWithKMSKey: %v\", err)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -232,14 +205,15 @@\nfunc TestV4SignedURL(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tbucketName := tc.ProjectID + \"-signed-url-bucket-name\"\n \tobjectName := \"foo.txt\"\n \tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n \tputBuf := new(bytes.Buffer)\n-\tputURL, err := generateV4PutObjectSignedURL(putBuf, client, bucketName, objectName, serviceAccount)\n+\tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName, serviceAccount)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4PutObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -257,7 +231,7 @@\nfunc TestV4SignedURL(t *testing.T) {\n \t\tt.Errorf(\"httpClient.Do: %v\", err)\n \t}\n \tgetBuf := new(bytes.Buffer)\n-\tgetURL, err := generateV4GetObjectSignedURL(getBuf, client, bucketName, objectName, serviceAccount)\n+\tgetURL, err := generateV4GetObjectSignedURL(getBuf, bucketName, objectName, serviceAccount)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4GetObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -280,7 +254,6 @@\nfunc TestV4SignedURL(t *testing.T) {\n \tif got, want := string(body), \"hello world\"; got != want {\n \t\tt.Errorf(\"object content = %q; want %q\", got, want)\n \t}\n-\n }\n \n func TestObjectBucketLock(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -290,69 +263,68 @@\nfunc TestObjectBucketLock(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tvar (\n-\t\tbucketName = tc.ProjectID + \"-retent-samples-object-bucket\"\n-\n-\t\tobjectName = \"foo.txt\"\n-\n+\t\tbucketName      = tc.ProjectID + \"-retent-samples-object-bucket\"\n+\t\tobjectName      = \"foo.txt\"\n \t\tretentionPeriod = 5 * time.Second\n \t)\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n \tbucket := client.Bucket(bucketName)\n \n-\tif err := write(client, bucketName, objectName); err != nil {\n-\t\tt.Fatalf(\"write(%q): %v\", objectName, err)\n+\tif err := uploadFile(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", objectName, err)\n \t}\n \tif _, err := bucket.Update(ctx, storage.BucketAttrsToUpdate{\n \t\tRetentionPolicy: &storage.RetentionPolicy{\n \t\t\tRetentionPeriod: retentionPeriod,\n \t\t},\n \t}); err != nil {\n-\t\tt.Errorf(\"unable to set retention policy (%q): %v\", bucketName, err)\n+\t\tt.Errorf(\"Bucket(%q).Update: %v\", bucketName, err)\n \t}\n-\tif err := setEventBasedHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to set event-based hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := setEventBasedHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"setEventBasedHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err := attrs(client, bucketName, objectName)\n+\toAttrs, err := getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif !oAttrs.EventBasedHold {\n \t\tt.Errorf(\"event-based hold is not enabled\")\n \t}\n-\tif err := releaseEventBasedHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to set event-based hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := releaseEventBasedHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"releaseEventBasedHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err = attrs(client, bucketName, objectName)\n+\toAttrs, err = getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif oAttrs.EventBasedHold {\n \t\tt.Errorf(\"event-based hold is not disabled\")\n \t}\n \tif _, err := bucket.Update(ctx, storage.BucketAttrsToUpdate{\n \t\tRetentionPolicy: &storage.RetentionPolicy{},\n \t}); err != nil {\n-\t\tt.Errorf(\"unable to remove retention policy (%q): %v\", bucketName, err)\n+\t\tt.Errorf(\"Bucket(%q).Update: %v\", bucketName, err)\n \t}\n-\tif err := setTemporaryHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to set temporary hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := setTemporaryHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"setTemporaryHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err = attrs(client, bucketName, objectName)\n+\toAttrs, err = getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif !oAttrs.TemporaryHold {\n \t\tt.Errorf(\"temporary hold is not disabled\")\n \t}\n-\tif err := releaseTemporaryHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to release temporary hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := releaseTemporaryHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"releaseTemporaryHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err = attrs(client, bucketName, objectName)\n+\toAttrs, err = getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif oAttrs.TemporaryHold {\n \t\tt.Errorf(\"temporary hold is not disabled\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -371,7 +343,7 @@\nfunc cleanBucket(t *testing.T, ctx context.Context, client *storage.Client, proj\n \t\t\t\tbreak\n \t\t\t}\n \t\t\tif err != nil {\n-\t\t\t\tt.Fatalf(\"Bucket.Objects(%q): %v\", bucket, err)\n+\t\t\t\tt.Fatalf(\"Bucket(%q).Objects: %v\", bucket, err)\n \t\t\t}\n \t\t\tif attrs.EventBasedHold || attrs.TemporaryHold {\n \t\t\t\tif _, err := b.Object(attrs.Name).Update(ctx, storage.ObjectAttrsToUpdate{",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/service_account/hmac/activate.go",
        "code_diff": "@@ -16,11 +16,12 @@\npackage hmac\n \n // [START storage_activate_hmac_key]\n import (\n-\t\"cloud.google.com/go/storage\"\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/storage\"\n )\n \n // activateHMACKey activates the HMAC key with the given access ID.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/service_account/hmac/create.go",
        "code_diff": "@@ -16,11 +16,12 @@\npackage hmac\n \n // [START storage_create_hmac_key]\n import (\n-\t\"cloud.google.com/go/storage\"\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/storage\"\n )\n \n // createHMACKey creates a new HMAC key using the given project and service account.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/service_account/hmac/deactivate.go",
        "code_diff": "@@ -16,11 +16,12 @@\npackage hmac\n \n // [START storage_deactivate_hmac_key]\n import (\n-\t\"cloud.google.com/go/storage\"\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/storage\"\n )\n \n // deactivateHMACKey deactivates the HMAC key with the given access ID.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/service_account/hmac/delete.go",
        "code_diff": "@@ -16,11 +16,12 @@\npackage hmac\n \n // [START storage_delete_hmac_key]\n import (\n-\t\"cloud.google.com/go/storage\"\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/storage\"\n )\n \n // deleteHMACKey deletes the HMAC key with the given access ID. Key must have state",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/service_account/hmac/get.go",
        "code_diff": "@@ -16,11 +16,12 @@\npackage hmac\n \n // [START storage_get_hmac_key]\n import (\n-\t\"cloud.google.com/go/storage\"\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/storage\"\n )\n \n // getHMACKey retrieves the HMACKeyMetadata with the given access id.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -17,10 +17,12 @@\npackage hmac\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"io/ioutil\"\n \t\"os\"\n \t\"testing\"\n+\t\"time\"\n+\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \n \t\"cloud.google.com/go/storage\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -29,6 +31,10 @@\nvar serviceAccountEmail = os.Getenv(\"GOLANG_SAMPLES_SERVICE_ACCOUNT_EMAIL\")\n var storageClient *storage.Client\n \n func TestMain(m *testing.M) {\n+\tif serviceAccountEmail == \"\" {\n+\t\tfmt.Fprintln(os.Stderr, \"GOLANG_SAMPLES_SERVICE_ACCOUNT_EMAIL not set. Skipping.\")\n+\t\treturn\n+\t}\n \tctx := context.Background()\n \tstorageClient, _ = storage.NewClient(ctx)\n \tdefer storageClient.Close()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "storage/service_account/hmac/list.go",
        "code_diff": "@@ -16,12 +16,13 @@\npackage hmac\n \n // [START storage_list_hmac_keys]\n import (\n-\t\"cloud.google.com/go/storage\"\n \t\"context\"\n \t\"fmt\"\n-\t\"google.golang.org/api/iterator\"\n \t\"io\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/storage\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n // listHMACKeys lists all HMAC keys associated with the project.",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -24,7 +24,6 @@\nimport (\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"google.golang.org/api/iterator\"\n )\n \n func TestDetect(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "asset: add export to BigQuery",
        "pr_number": 1140,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -96,7 +95,7 @@\nfunc TestDetectAsyncDocument(t *testing.T) {\n \n \tbucketName := fmt.Sprintf(\"%s-vision\", tc.ProjectID)\n \tbucket := client.Bucket(bucketName)\n-\tcleanBucket(ctx, t, client, tc.ProjectID, bucketName)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n \tvar buf bytes.Buffer\n \tgcsSourceURI := \"gs://python-docs-samples-tests/HodgeConj.pdf\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "a4e097164dd04367b6df436dd9c1482698226445"
    },
    {
        "pr_title": "dataproc: add CreateCluster and Quickstart samples",
        "pr_number": 1139,
        "file_name": "bigquery/snippets/bqtestutil/bqtestutil.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage bqtestutil\n \n import (\n \t\"fmt\"\n+\t\"os\"\n \t\"regexp\"\n \n \t\"github.com/gofrs/uuid\"",
        "comments": [],
        "commit_message": "Merge branch 'dataproc-samples' of github.com:bradmiro/golang-samples into dataproc-samples",
        "commit_id": "678dcf1ab40b03874d65e3537cd79749be566e44"
    },
    {
        "pr_title": "dataproc: add CreateCluster and Quickstart samples",
        "pr_number": 1139,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -89,17 +89,32 @@\nfunc TestCopiesAndExtracts(t *testing.T) {\n \t\tt.Fatalf(\"failed to generate example table2: %v\", err)\n \t}\n \n-\tif err := copyTable(tc.ProjectID, testDatasetID, \"table1\", \"copy1\"); err != nil {\n-\t\tt.Errorf(\"copyTable(%s): %v\", testDatasetID, err)\n-\t}\n-\n-\tif err := copyTableWithCMEK(tc.ProjectID, testDatasetID, \"copycmek\"); err != nil {\n-\t\tt.Errorf(\"copyTableWithCMEK(%s): %v\", testDatasetID, err)\n-\t}\n-\n-\tif err := copyMultiTable(tc.ProjectID, testDatasetID, []string{\"table1\", \"table2\"}, testDatasetID, \"copymulti\"); err != nil {\n-\t\tt.Errorf(\"copyMultiTable(%s): %v\", testDatasetID, err)\n-\t}\n+\t// Run copy job tests in parallel.\n+\tt.Run(\"copy\", func(t *testing.T) {\n+\t\tt.Run(\"copyTable\", func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tif err := copyTable(tc.ProjectID, testDatasetID, \"table1\", \"copy1\"); err != nil {\n+\t\t\t\tt.Errorf(\"copyTable(%s): %v\", testDatasetID, err)\n+\t\t\t}\n+\t\t})\n+\n+\t\tt.Run(\"copyTableWithCMEK\", func(t *testing.T) {\n+\t\t\tif !bqtestutil.RunCMEKTests() {\n+\t\t\t\tt.Skip(\"Skipping CMEK tests\")\n+\t\t\t}\n+\t\t\tt.Parallel()\n+\t\t\tif err := copyTableWithCMEK(tc.ProjectID, testDatasetID, \"copycmek\"); err != nil {\n+\t\t\t\tt.Errorf(\"copyTableWithCMEK(%s): %v\", testDatasetID, err)\n+\t\t\t}\n+\t\t})\n+\n+\t\tt.Run(\"copyMultiTable\", func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tif err := copyMultiTable(tc.ProjectID, testDatasetID, []string{\"table1\", \"table2\"}, testDatasetID, \"copymulti\"); err != nil {\n+\t\t\t\tt.Errorf(\"copyMultiTable(%s): %v\", testDatasetID, err)\n+\t\t\t}\n+\t\t})\n+\t})\n \n \t// Extract tests - setup bucket\n \tstorageClient, err := storage.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'dataproc-samples' of github.com:bradmiro/golang-samples into dataproc-samples",
        "commit_id": "678dcf1ab40b03874d65e3537cd79749be566e44"
    },
    {
        "pr_title": "dataproc: add CreateCluster and Quickstart samples",
        "pr_number": 1139,
        "file_name": "functions/slack/search.go",
        "code_diff": "@@ -19,11 +19,32 @@\npackage slack\n \n import (\n+\t\"bytes\"\n+\t\"crypto/hmac\"\n+\t\"crypto/sha256\"\n+\t\"encoding/hex\"\n \t\"encoding/json\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n-\t\"net/url\"\n+\t\"strconv\"\n+\t\"strings\"\n+\t\"time\"\n+)\n+\n+type oldTimeStampError struct {\n+\ts string\n+}\n+\n+func (e *oldTimeStampError) Error() string {\n+\treturn e.s\n+}\n+\n+const (\n+\tversion                     = \"v0\"\n+\tslackRequestTimestampHeader = \"X-Slack-Request-Timestamp\"\n+\tslackSignatureHeader        = \"X-Slack-Signature\"\n )\n \n type attachment struct {",
        "comments": [],
        "commit_message": "Merge branch 'dataproc-samples' of github.com:bradmiro/golang-samples into dataproc-samples",
        "commit_id": "678dcf1ab40b03874d65e3537cd79749be566e44"
    },
    {
        "pr_title": "dataproc: add CreateCluster and Quickstart samples",
        "pr_number": 1139,
        "file_name": "functions/slack/search.go",
        "code_diff": "@@ -46,16 +67,31 @@\ntype Message struct {\n // by a Slack command.\n func KGSearch(w http.ResponseWriter, r *http.Request) {\n \tsetup(r.Context())\n+\n+\tbodyBytes, err := ioutil.ReadAll(r.Body)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"Couldn't read request body: %v\", err)\n+\t}\n+\tr.Body = ioutil.NopCloser(bytes.NewBuffer(bodyBytes))\n+\n \tif r.Method != \"POST\" {\n \t\thttp.Error(w, \"Only POST requests are accepted\", 405)\n \t}\n \tif err := r.ParseForm(); err != nil {\n \t\thttp.Error(w, \"Couldn't parse form\", 400)\n \t\tlog.Fatalf(\"ParseForm: %v\", err)\n \t}\n-\tif err := verifyWebHook(r.Form); err != nil {\n+\n+\t// Reset r.Body as ParseForm depletes it by reading the io.ReadCloser.\n+\tr.Body = ioutil.NopCloser(bytes.NewBuffer(bodyBytes))\n+\tresult, err := verifyWebHook(r, config.Secret)\n+\tif err != nil {\n \t\tlog.Fatalf(\"verifyWebhook: %v\", err)\n \t}\n+\tif !result {\n+\t\tlog.Fatalf(\"signatures did not match.\")\n+\t}\n+\n \tif len(r.Form[\"text\"]) == 0 {\n \t\tlog.Fatalf(\"emtpy text in form\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'dataproc-samples' of github.com:bradmiro/golang-samples into dataproc-samples",
        "commit_id": "678dcf1ab40b03874d65e3537cd79749be566e44"
    },
    {
        "pr_title": "dataproc: add CreateCluster and Quickstart samples",
        "pr_number": 1139,
        "file_name": "functions/slack/search.go",
        "code_diff": "@@ -71,20 +107,6 @@\nfunc KGSearch(w http.ResponseWriter, r *http.Request) {\n \n // [END functions_slack_search]\n \n-// [START functions_verify_webhook]\n-func verifyWebHook(form url.Values) error {\n-\tt := form.Get(\"token\")\n-\tif len(t) == 0 {\n-\t\treturn fmt.Errorf(\"empty form token\")\n-\t}\n-\tif t != config.Token {\n-\t\treturn fmt.Errorf(\"invalid request/credentials: %q\", t[0])\n-\t}\n-\treturn nil\n-}\n-\n-// [END functions_verify_webhook]\n-\n // [START functions_slack_request]\n func makeSearchRequest(query string) (*Message, error) {\n \tres, err := entitiesService.Search().Query(query).Limit(1).Do()",
        "comments": [],
        "commit_message": "Merge branch 'dataproc-samples' of github.com:bradmiro/golang-samples into dataproc-samples",
        "commit_id": "678dcf1ab40b03874d65e3537cd79749be566e44"
    },
    {
        "pr_title": "dataproc: add CreateCluster and Quickstart samples",
        "pr_number": 1139,
        "file_name": "functions/slack/slack_test.go",
        "code_diff": "@@ -16,12 +16,16 @@\npackage slack\n \n import (\n \t\"context\"\n+\t\"encoding/hex\"\n+\t\"fmt\"\n \t\"log\"\n \t\"net/http/httptest\"\n \t\"net/url\"\n \t\"os\"\n+\t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"google.golang.org/api/kgsearch/v1\"\n \t\"google.golang.org/api/option\"",
        "comments": [],
        "commit_message": "Merge branch 'dataproc-samples' of github.com:bradmiro/golang-samples into dataproc-samples",
        "commit_id": "678dcf1ab40b03874d65e3537cd79749be566e44"
    },
    {
        "pr_title": "dataproc: add CreateCluster and Quickstart samples",
        "pr_number": 1139,
        "file_name": "functions/slack/slack_test.go",
        "code_diff": "@@ -46,11 +50,11 @@\nfunc TestMain(m *testing.M) {\n \t}\n \tconfig = &configuration{\n \t\tProjectID: projectID,\n-\t\tToken:     os.Getenv(\"GOLANG_SAMPLES_SLACK_TOKEN\"),\n+\t\tSecret:    os.Getenv(\"GOLANG_SAMPLES_SLACK_SECRET\"),\n \t\tKey:       os.Getenv(\"GOLANG_SAMPLES_KG_KEY\"),\n \t}\n-\tif config.Token == \"\" {\n-\t\tlog.Print(\"GOLANG_SAMPLES_SLACK_TOKEN is unset. Skipping.\")\n+\tif config.Secret == \"\" {\n+\t\tlog.Print(\"GOLANG_SAMPLES_SLACK_SECRET is unset. Skipping.\")\n \t\treturn\n \t}\n \tif config.Key == \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'dataproc-samples' of github.com:bradmiro/golang-samples into dataproc-samples",
        "commit_id": "678dcf1ab40b03874d65e3537cd79749be566e44"
    },
    {
        "pr_title": "dataproc: add CreateCluster and Quickstart samples",
        "pr_number": 1139,
        "file_name": "functions/slack/slack_test.go",
        "code_diff": "@@ -66,37 +70,6 @@\nfunc TestMain(m *testing.M) {\n \tos.Exit(m.Run())\n }\n \n-func TestVerifyWebHook(t *testing.T) {\n-\ttests := []struct {\n-\t\ttoken   string\n-\t\twantErr bool\n-\t}{\n-\t\t{\n-\t\t\ttoken:   config.Token,\n-\t\t\twantErr: false,\n-\t\t},\n-\t\t{\n-\t\t\ttoken:   \"this is not the token\",\n-\t\t\twantErr: true,\n-\t\t},\n-\t\t{\n-\t\t\ttoken:   \"\",\n-\t\t\twantErr: true,\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\tv := make(url.Values)\n-\t\tv.Set(\"token\", test.token)\n-\t\terr := verifyWebHook(v)\n-\t\tif test.wantErr && err == nil {\n-\t\t\tt.Errorf(\"verifyWebHook(%v) got no error, expected error\", test.token)\n-\t\t}\n-\t\tif !test.wantErr && err != nil {\n-\t\t\tt.Errorf(\"verifyWebHook(%v) got %v, want no error\", test.token, err)\n-\t\t}\n-\t}\n-}\n-\n func TestFormatSlackMessage(t *testing.T) {\n \ttests := []struct {\n \t\tquery string",
        "comments": [],
        "commit_message": "Merge branch 'dataproc-samples' of github.com:bradmiro/golang-samples into dataproc-samples",
        "commit_id": "678dcf1ab40b03874d65e3537cd79749be566e44"
    },
    {
        "pr_title": "dataproc: add CreateCluster and Quickstart samples",
        "pr_number": 1139,
        "file_name": "secretmanager/quickstart/quickstart.go",
        "code_diff": "@@ -23,7 +23,6 @@\nimport (\n \t\"log\"\n \n \tsecretmanager \"cloud.google.com/go/secretmanager/apiv1beta1\"\n-\t\"google.golang.org/api/iterator\"\n \tsecretmanagerpb \"google.golang.org/genproto/googleapis/cloud/secretmanager/v1beta1\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'dataproc-samples' of github.com:bradmiro/golang-samples into dataproc-samples",
        "commit_id": "678dcf1ab40b03874d65e3537cd79749be566e44"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \n \tsecretmanager \"cloud.google.com/go/secretmanager/apiv1beta1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n \tsecretmanagerpb \"google.golang.org/genproto/googleapis/cloud/secretmanager/v1beta1\"\n \tgrpccodes \"google.golang.org/grpc/codes\"\n \tgrpcstatus \"google.golang.org/grpc/status\"",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -40,9 +41,21 @@\nfunc testClient(tb testing.TB) (*secretmanager.Client, context.Context) {\n \treturn client, ctx\n }\n \n-func testSecret(tb testing.TB, projectID, secretID string) *secretmanagerpb.Secret {\n+func testName(tb testing.TB) string {\n \ttb.Helper()\n \n+\tu, err := uuid.NewV4()\n+\tif err != nil {\n+\t\ttb.Fatalf(\"testName: failed to generate uuid: %v\", err)\n+\t}\n+\treturn u.String()\n+}\n+\n+func testSecret(tb testing.TB, projectID string) *secretmanagerpb.Secret {\n+\ttb.Helper()\n+\n+\tsecretID := testName(tb)\n+\n \tclient, ctx := testClient(tb)\n \tsecret, err := client.CreateSecret(ctx, &secretmanagerpb.CreateSecretRequest{\n \t\tParent:   fmt.Sprintf(\"projects/%s\", projectID),",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            },
            {
                "comment": "@broady just filed #1133 to avoid using UUIDs. Can we use a consistent name and avoid any leaking of resources? Maybe only create a single secret and use it for all of the tests, rather than a secret for every test?",
                "position": 47
            },
            {
                "comment": "If we do that, tests can't run in parallel (one could be destroying while another is enabling), which is less than ideal. I can update the test helper to use a common prefix to make it easy to track down issues, but I think UUIDs are unavoidable if we want fully isolated tests and predictable tests for each sample.",
                "position": 47
            },
            {
                "comment": "Our CI system provides a level of isolation at the cloud project level. That is, when the tests for golang-samples run, the test run has exclusive access to the project that it's running in (tc.ProjectID/$GOLANG_SAMPLES_PROJECT_ID)\r\n\r\nSo you only need to use a resource name that includes tc.ProjectID plus a pre/suffix unique to golang-samples.\r\n\r\nUUIDs as resource IDs actually introduces more unpredictability because you end up with dangling resources when cleanup fails.",
                "position": 47
            },
            {
                "comment": "Yes, but the tests themselves (the tests in `secretmanager_test.go`) run in parallel. I can add the project ID prefix, but the secrets are also scoped to the project ID, so that seems redundant. \r\n\r\nFor example, `TestListSecrets` runs in parallel to `TestCreateSecret`, so the results are unpredictable if we use hard-coded values. Sometimes `TestCreateSecret` would run before `TestListSecrets`, sometimes after. Similarly, some tests actually destroy secrets, so they wouldn't exist in the next run. The tests then become dependent on the project being in a certain state instead of running in isolation.",
                "position": 47
            },
            {
                "comment": "As far as leaking resources, each function `defer` cleanup. It's theoretically possible that we'd leak if a quota issue or outage arose between the `testSecret` action and `testCleanupSecret`, but that should be incredibly rare.\r\n\r\nEach test as written here is fully isolated and independent from all other tests and prior state of the system, by design. ",
                "position": 47
            },
            {
                "comment": "Talked with @broady about this in chat and worked through it. Worked through quota issues by switching to `SystemTest`.",
                "position": 47
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -79,13 +92,13 @@\nfunc testSecretVersion(tb testing.TB, parent string, payload []byte) *secretmana\n \treturn version\n }\n \n-func testCleanupSecret(tb testing.TB, projectID, secretID string) {\n+func testCleanupSecret(tb testing.TB, name string) {\n \ttb.Helper()\n \n \tclient, ctx := testClient(tb)\n \n \tif err := client.DeleteSecret(ctx, &secretmanagerpb.DeleteSecretRequest{\n-\t\tName: fmt.Sprintf(\"projects/%s/secrets/%s\", projectID, secretID),\n+\t\tName: name,\n \t}); err != nil {\n \t\tif terr, ok := grpcstatus.FromError(err); !ok || terr.Code() != grpccodes.NotFound {\n \t\t\ttb.Fatalf(\"testCleanupSecret: failed to delete secret: %v\", err)",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -96,12 +109,10 @@\nfunc testCleanupSecret(tb testing.TB, projectID, secretID string) {\n func TestAccessSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tsecretID := \"accessSecretVersion\"\n-\ttestCleanupSecret(t, tc.ProjectID, secretID)\n-\tdefer testCleanupSecret(t, tc.ProjectID, secretID)\n-\n \tpayload := []byte(\"my-secret\")\n-\tsecret := testSecret(t, tc.ProjectID, secretID)\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n \tversion := testSecretVersion(t, secret.Name, payload)\n \n \tvar b bytes.Buffer",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -117,11 +128,8 @@\nfunc TestAccessSecretVersion(t *testing.T) {\n func TestAddSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tsecretID := \"addSecretVersion\"\n-\ttestCleanupSecret(t, tc.ProjectID, secretID)\n-\tdefer testCleanupSecret(t, tc.ProjectID, secretID)\n-\n-\tsecret := testSecret(t, tc.ProjectID, secretID)\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n \n \tvar b bytes.Buffer\n \tif err := addSecretVersion(&b, secret.Name); err != nil {",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -137,10 +145,9 @@\nfunc TestCreateSecret(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n \tsecretID := \"createSecret\"\n-\ttestCleanupSecret(t, tc.ProjectID, secretID)\n-\tdefer testCleanupSecret(t, tc.ProjectID, secretID)\n \n \tparent := fmt.Sprintf(\"projects/%s\", tc.ProjectID)\n+\tdefer testCleanupSecret(t, fmt.Sprintf(\"projects/%s/secrets/%s\", tc.ProjectID, secretID))\n \n \tvar b bytes.Buffer\n \tif err := createSecret(&b, parent, secretID); err != nil {",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -155,11 +162,8 @@\nfunc TestCreateSecret(t *testing.T) {\n func TestDeleteSecret(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tsecretID := \"deleteSecret\"\n-\ttestCleanupSecret(t, tc.ProjectID, secretID)\n-\tdefer testCleanupSecret(t, tc.ProjectID, secretID)\n-\n-\tsecret := testSecret(t, tc.ProjectID, secretID)\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n \n \tif err := deleteSecret(secret.Name); err != nil {\n \t\tt.Fatal(err)",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -177,12 +181,10 @@\nfunc TestDeleteSecret(t *testing.T) {\n func TestDestroySecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tsecretID := \"destroySecretVersion\"\n-\ttestCleanupSecret(t, tc.ProjectID, secretID)\n-\tdefer testCleanupSecret(t, tc.ProjectID, secretID)\n-\n \tpayload := []byte(\"my-secret\")\n-\tsecret := testSecret(t, tc.ProjectID, secretID)\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n \tversion := testSecretVersion(t, secret.Name, payload)\n \n \tif err := destroySecretVersion(version.Name); err != nil {",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -204,12 +206,10 @@\nfunc TestDestroySecretVersion(t *testing.T) {\n func TestDisableEnableSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tsecretID := \"disableEnableSecretVersion\"\n-\ttestCleanupSecret(t, tc.ProjectID, secretID)\n-\tdefer testCleanupSecret(t, tc.ProjectID, secretID)\n-\n \tpayload := []byte(\"my-secret\")\n-\tsecret := testSecret(t, tc.ProjectID, secretID)\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n \tversion := testSecretVersion(t, secret.Name, payload)\n \n \tif err := disableSecretVersion(version.Name); err != nil {",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -245,12 +245,10 @@\nfunc TestDisableEnableSecretVersion(t *testing.T) {\n func TestGetSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tsecretID := \"getSecretVersion\"\n-\ttestCleanupSecret(t, tc.ProjectID, secretID)\n-\tdefer testCleanupSecret(t, tc.ProjectID, secretID)\n-\n \tpayload := []byte(\"my-secret\")\n-\tsecret := testSecret(t, tc.ProjectID, secretID)\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n \tversion := testSecretVersion(t, secret.Name, payload)\n \n \tvar b bytes.Buffer",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -266,11 +264,8 @@\nfunc TestGetSecretVersion(t *testing.T) {\n func TestGetSecret(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tsecretID := \"getSecret\"\n-\ttestCleanupSecret(t, tc.ProjectID, secretID)\n-\tdefer testCleanupSecret(t, tc.ProjectID, secretID)\n-\n-\tsecret := testSecret(t, tc.ProjectID, secretID)\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n \n \tvar b bytes.Buffer\n \tif err := getSecret(&b, secret.Name); err != nil {",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -285,12 +280,9 @@\nfunc TestGetSecret(t *testing.T) {\n func TestListSecretVersions(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tsecretID := \"listSecretVersions\"\n-\ttestCleanupSecret(t, tc.ProjectID, secretID)\n-\tdefer testCleanupSecret(t, tc.ProjectID, secretID)\n-\n \tpayload := []byte(\"my-secret\")\n-\tsecret := testSecret(t, tc.ProjectID, secretID)\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n \n \tversion1 := testSecretVersion(t, secret.Name, payload)\n \tversion2 := testSecretVersion(t, secret.Name, payload)",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "secretmanager: add initial samples",
        "pr_number": 1131,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -312,16 +304,11 @@\nfunc TestListSecretVersions(t *testing.T) {\n func TestListSecrets(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tsecretID1 := \"listSecrets1\"\n-\ttestCleanupSecret(t, tc.ProjectID, secretID1)\n-\tdefer testCleanupSecret(t, tc.ProjectID, secretID1)\n+\tsecret1 := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret1.Name)\n \n-\tsecretID2 := \"listSecrets2\"\n-\ttestCleanupSecret(t, tc.ProjectID, secretID2)\n-\tdefer testCleanupSecret(t, tc.ProjectID, secretID2)\n-\n-\tsecret1 := testSecret(t, tc.ProjectID, secretID1)\n-\tsecret2 := testSecret(t, tc.ProjectID, secretID2)\n+\tsecret2 := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret2.Name)\n \n \tvar b bytes.Buffer\n \tif err := listSecrets(&b, fmt.Sprintf(\"projects/%s\", tc.ProjectID)); err != nil {",
        "comments": [
            {
                "comment": "Nit: we generally use `got` and `want`, following https://github.com/golang/go/wiki/TestComments.",
                "position": null
            },
            {
                "comment": "Please include the function that failed. https://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "Reduce API calls",
        "commit_id": "18a5daecb5fa79f93fdb6eb17b95d17a454500cc"
    },
    {
        "pr_title": "bigtable: reads and filters snippets",
        "pr_number": 1127,
        "file_name": "bigtable/reads/reads_test.go",
        "code_diff": "@@ -60,21 +60,21 @@\nfunc TestReads(t *testing.T) {\n \t}{\n \t\t{\n \t\t\tname: \"readRow\", filter: readRow, want: fmt.Sprintf(\n-\t\t\t`Reading data for phone#4c410523#20190501:\n+\t\t\t\t`Reading data for phone#4c410523#20190501:\n Column Family stats_summary\n \tconnected_cell: 1 @%[1]d\n \tconnected_wifi: 1 @%[1]d\n \tos_build: PQ2A.190405.003 @%[1]d`, timestamp),\n \t\t},\n \t\t{\n \t\t\tname: \"readRowPartial\", filter: readRowPartial, want: fmt.Sprintf(\n-\t\t\t`Reading data for phone#4c410523#20190501:\n+\t\t\t\t`Reading data for phone#4c410523#20190501:\n Column Family stats_summary\n \tos_build: PQ2A.190405.003 @%[1]d`, timestamp),\n \t\t},\n \t\t{\n \t\t\tname: \"readRows\", filter: readRows, want: fmt.Sprintf(\n-\t\t\t`Reading data for phone#4c410523#20190501:\n+\t\t\t\t`Reading data for phone#4c410523#20190501:\n Column Family stats_summary\n \tconnected_cell: 1 @%[1]d\n \tconnected_wifi: 1 @%[1]d",
        "comments": [
            {
                "comment": "Newline after `{`.",
                "position": null
            }
        ],
        "commit_message": "bigtable: run gofmt -w -s",
        "commit_id": "c8da4ffa8729343a95a068c35313c434cf8c6c93"
    },
    {
        "pr_title": "bigtable: reads and filters snippets",
        "pr_number": 1127,
        "file_name": "bigtable/reads/reads_test.go",
        "code_diff": "@@ -88,7 +88,7 @@\nColumn Family stats_summary\n \t\t},\n \t\t{\n \t\t\tname: \"readRowRange\", filter: readRowRange, want: fmt.Sprintf(\n-\t\t\t`Reading data for phone#4c410523#20190501:\n+\t\t\t\t`Reading data for phone#4c410523#20190501:\n Column Family stats_summary\n \tconnected_cell: 1 @%[1]d\n \tconnected_wifi: 1 @%[1]d",
        "comments": [
            {
                "comment": "Newline after `{`.",
                "position": null
            }
        ],
        "commit_message": "bigtable: run gofmt -w -s",
        "commit_id": "c8da4ffa8729343a95a068c35313c434cf8c6c93"
    },
    {
        "pr_title": "bigtable: reads and filters snippets",
        "pr_number": 1127,
        "file_name": "bigtable/reads/reads_test.go",
        "code_diff": "@@ -108,7 +108,7 @@\nColumn Family stats_summary\n \t\t},\n \t\t{\n \t\t\tname: \"readRowRanges\", filter: readRowRanges, want: fmt.Sprintf(\n-\t\t\t`Reading data for phone#4c410523#20190501:\n+\t\t\t\t`Reading data for phone#4c410523#20190501:\n Column Family stats_summary\n \tconnected_cell: 1 @%[1]d\n \tconnected_wifi: 1 @%[1]d",
        "comments": [
            {
                "comment": "Newline after `{`.",
                "position": null
            }
        ],
        "commit_message": "bigtable: run gofmt -w -s",
        "commit_id": "c8da4ffa8729343a95a068c35313c434cf8c6c93"
    },
    {
        "pr_title": "bigtable: reads and filters snippets",
        "pr_number": 1127,
        "file_name": "bigtable/reads/reads_test.go",
        "code_diff": "@@ -140,7 +140,7 @@\nColumn Family stats_summary\n \t\t},\n \t\t{\n \t\t\tname: \"readPrefix\", filter: readPrefix, want: fmt.Sprintf(\n-\t\t\t`Reading data for phone#4c410523#20190501:\n+\t\t\t\t`Reading data for phone#4c410523#20190501:\n Column Family stats_summary\n \tconnected_cell: 1 @%[1]d\n \tconnected_wifi: 1 @%[1]d",
        "comments": [
            {
                "comment": "Newline after `{`.",
                "position": null
            }
        ],
        "commit_message": "bigtable: run gofmt -w -s",
        "commit_id": "c8da4ffa8729343a95a068c35313c434cf8c6c93"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/dataset_delete.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_delete_dataset]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/dataset_export.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_export_dataset]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/dataset_get.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_get_dataset]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/dataset_import_data.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_import_data]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/dataset_list.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_list_datasets]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/batch_predict.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_language_batch_predict]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/entity_extraction/dataset_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_language_entity_extraction_create_dataset]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/entity_extraction/dataset_create.go",
        "code_diff": "@@ -21,8 +21,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tautoml \"cloud.google.com/go/automl/apiv1beta1\"\n-\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1beta1\"\n+\tautoml \"cloud.google.com/go/automl/apiv1\"\n+\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1\"\n )\n \n // languageEntityExtractionCreateDataset creates a dataset for text entity extraction.",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/entity_extraction/model_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_language_entity_extraction_create_model]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/entity_extraction/predict.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_language_entity_extraction_predict]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/sentiment_analysis/dataset_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_language_sentiment_analysis_create_dataset]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/sentiment_analysis/dataset_create.go",
        "code_diff": "@@ -21,8 +21,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tautoml \"cloud.google.com/go/automl/apiv1beta1\"\n-\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1beta1\"\n+\tautoml \"cloud.google.com/go/automl/apiv1\"\n+\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1\"\n )\n \n // languageSentimentAnalysisCreateDataset creates a dataset for text sentiment analysis.",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/sentiment_analysis/model_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_language_sentiment_analysis_create_model]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/sentiment_analysis/predict.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_language_sentiment_analysis_predict]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/text_classification/dataset_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_language_text_classification_create_dataset]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/text_classification/dataset_create.go",
        "code_diff": "@@ -21,8 +21,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tautoml \"cloud.google.com/go/automl/apiv1beta1\"\n-\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1beta1\"\n+\tautoml \"cloud.google.com/go/automl/apiv1\"\n+\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1\"\n )\n \n // languageTextClassificationCreateDataset creates a dataset for text classification.",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/text_classification/model_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_language_entity_extraction_create_model]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/language/text_classification/predict.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_language_text_classification_predict]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/model_delete.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_delete_model]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/model_deploy.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_deploy_model]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/model_evaluation_get.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_get_model_evaluation]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/model_evaluation_list.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_list_model_evaluations]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/model_export.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_export_model]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/model_get.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_get_model]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/model_list.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_list_models]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/model_undeploy.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_undeploy_model]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/operation_status_get.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_get_operation_status]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/operation_status_list.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_list_operation_status]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/translate/dataset_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_translate_create_dataset]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/translate/dataset_create.go",
        "code_diff": "@@ -21,8 +21,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tautoml \"cloud.google.com/go/automl/apiv1beta1\"\n-\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1beta1\"\n+\tautoml \"cloud.google.com/go/automl/apiv1\"\n+\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1\"\n )\n \n // translateCreateDataset creates a dataset for translate.",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/translate/model_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_translate_create_model]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/translate/predict.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_translate_predict]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/batch_predict.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_vision_batch_predict]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/classification/dataset_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_vision_classification_create_dataset]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/classification/dataset_create.go",
        "code_diff": "@@ -21,8 +21,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tautoml \"cloud.google.com/go/automl/apiv1beta1\"\n-\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1beta1\"\n+\tautoml \"cloud.google.com/go/automl/apiv1\"\n+\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1\"\n )\n \n // visionClassificationCreateDataset creates a dataset for image classification.",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/classification/model_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_vision_classification_create_model]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/classification/model_create.go",
        "code_diff": "@@ -21,8 +21,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tautoml \"cloud.google.com/go/automl/apiv1beta1\"\n-\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1beta1\"\n+\tautoml \"cloud.google.com/go/automl/apiv1\"\n+\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1\"\n )\n \n // visionClassificationCreateModel creates a model for image classification.",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/classification/model_deploy_with_node_count.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_vision_classification_deploy_model_node_count]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/classification/predict.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_vision_classification_predict]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/object_detection/dataset_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_vision_object_detection_create_dataset]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/object_detection/dataset_create.go",
        "code_diff": "@@ -21,8 +21,8 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tautoml \"cloud.google.com/go/automl/apiv1beta1\"\n-\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1beta1\"\n+\tautoml \"cloud.google.com/go/automl/apiv1\"\n+\tautomlpb \"google.golang.org/genproto/googleapis/cloud/automl/v1\"\n )\n \n // visionObjectDetectionCreateDataset creates a dataset for image object detection.",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/object_detection/model_create.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_vision_object_detection_create_model]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/object_detection/model_deploy_with_node_count.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_vision_object_detection_deploy_model_node_count]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "automl/vision/object_detection/predict.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Package automl contains samples for Google Cloud AutoML API v1beta1.\n+// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n // [START automl_vision_object_detection_predict]",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -54,9 +54,9 @@\ntype Service struct {\n \t// Additional runtime environment variable overrides for the app.\n \tEnv EnvVars\n \n-\tdeployed bool   // Whether the service has been deployed.\n-\tbuilt    bool   // Whether the container image has been built.\n-\turl      string // The url of the deployed service.\n+\tdeployed bool     // Whether the service has been deployed.\n+\tbuilt    bool     // Whether the container image has been built.\n+\turl      *url.URL // The url of the deployed service.\n }\n \n // runID is an identifier that changes between runs.",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -107,23 +107,47 @@\nfunc (s *Service) NewRequest(method, path string) (*http.Request, error) {\n // URL prepends the deployed service's base URL to the given path.\n // Returns an error if the application has not been deployed.\n func (s *Service) URL(p string) (string, error) {\n-\tif !s.deployed {\n-\t\treturn \"\", errors.New(\"URL called before Deploy\")\n+\tu, err := s.ParsedURL()\n+\tif err != nil {\n+\t\treturn \"\", fmt.Errorf(\"service.ParsedURL: %v\", err)\n \t}\n+\tmodified := &url.URL{}\n+\t*modified = *u\n+\tmodified.Path = path.Join(modified.Path, p)\n+\n+\treturn modified.String(), nil\n+}\n \n-\tout, err := gcloud(s.operationLabel(\"get url\"), s.urlCmd())\n+// Host returns the host:port of the service to facilitate new gRPC connections.\n+func (s *Service) Host() (string, error) {\n+\tu, err := s.ParsedURL()\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"gcloud: %s: %q\", s.Name, err)\n+\t\treturn \"\", fmt.Errorf(\"service.ParsedURL: %v\", err)\n \t}\n+\treturn u.Host + \":443\", nil\n+}\n \n-\tsURL := string(out)\n-\tu, err := url.Parse(sURL)\n-\tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"url.Parse: %v\", err)\n+// ParsedURL retrieves the parsed URL of the service.\n+// This URL is stored on the service struct for repeated retrieval.\n+func (s *Service) ParsedURL() (*url.URL, error) {\n+\tif !s.deployed {\n+\t\treturn nil, errors.New(\"URL called before Deploy\")\n \t}\n-\tu.Path = path.Join(u.Path, p)\n+\tif s.url == nil {\n+\t\tout, err := gcloud(s.operationLabel(\"get url\"), s.urlCmd())\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"gcloud: %s: %q\", s.Name, err)\n+\t\t}\n \n-\treturn u.String(), nil\n+\t\tsURL := string(out)\n+\t\tu, err := url.Parse(sURL)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"url.Parse: %v\", err)\n+\t\t}\n+\n+\t\ts.url = u\n+\t}\n+\treturn s.url, nil\n }\n \n // validate confirms all required service properties are present.",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "internal/cloudrunci/cloudrunci_test.go",
        "code_diff": "@@ -15,6 +15,8 @@\npackage cloudrunci\n \n import (\n+\t\"fmt\"\n+\t\"net/url\"\n \t\"strings\"\n \t\"testing\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "internal/cloudrunci/cloudrunci_test.go",
        "code_diff": "@@ -34,7 +36,7 @@\nfunc TestServiceValidateErrors(t *testing.T) {\n \n // TestServiceStateErrors checks that a service in the wrong state will be blocked from the requested operation.\n func TestServiceStateErrors(t *testing.T) {\n-\tservice := NewService(\"my-serivce\", \"my-project\")\n+\tservice := NewService(\"my-service\", \"my-project\")\n \n \twant := \"Request called before Deploy\"\n \tif _, err := service.Request(\"GET\", \"/\"); !strings.Contains(err.Error(), want) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "internal/cloudrunci/envvars.go",
        "code_diff": "@@ -24,22 +24,22 @@\nimport (\n // EnvVars is a collection of environment variables.\n type EnvVars map[string]string\n \n-// keyRegex defines valid environment variable name.\n-// Regex arranged so the first submatch will have the name without whitespace.\n-// https://stackoverflow.com/questions/2821043/allowed-characters-in-linux-environment-variable-names\n-var keyRegex = regexp.MustCompile(`^\\s*([a-zA-Z_]+\\w*)\\s*$`)\n-\n func (e EnvVars) String() string {\n \ts := make([]string, len(e))\n \ti := 0\n-\tfor k, v := range e {\n-\t\ts[i] = fmt.Sprintf(\"%s=%s\", strings.TrimSpace(k), v)\n+\tfor k := range e {\n+\t\ts[i] = e.Variable(k)\n \t\ti++\n \t}\n \tsort.Strings(s)\n \treturn strings.Join(s, \",\")\n }\n \n+// Variable retrieves an environment variable assignment as a string.\n+func (e EnvVars) Variable(k string) string {\n+\treturn fmt.Sprintf(\"%s=%s\", strings.TrimSpace(k), strings.TrimSpace(e[k]))\n+}\n+\n // KeyString converts the environment variables names to a comma-delimited list.\n func (e EnvVars) KeyString() string {\n \ts := make([]string, len(e))",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/annotate/object_tracking.go",
        "code_diff": "@@ -18,16 +18,13 @@\npackage annotate\n // [START videointelligence_object_tracking]\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n-\n-\t\"context\"\n-\n-\t\"github.com/golang/protobuf/ptypes\"\n \n \tvideo \"cloud.google.com/go/videointelligence/apiv1\"\n+\t\"github.com/golang/protobuf/ptypes\"\n \tvideopb \"google.golang.org/genproto/googleapis/cloud/videointelligence/v1\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/annotate/object_tracking.go",
        "code_diff": "@@ -40,7 +37,7 @@\nfunc objectTracking(w io.Writer, filename string) error {\n \t// Creates a client.\n \tclient, err := video.NewClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to create client: %v\", err)\n+\t\treturn fmt.Errorf(\"video.NewClient: %v\", err)\n \t}\n \n \tfileBytes, err := ioutil.ReadFile(filename)",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/annotate/object_tracking_gcs.go",
        "code_diff": "@@ -18,15 +18,12 @@\npackage annotate\n // [START videointelligence_object_tracking_gcs]\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\n-\t\"context\"\n-\n-\t\"github.com/golang/protobuf/ptypes\"\n \n \tvideo \"cloud.google.com/go/videointelligence/apiv1\"\n+\t\"github.com/golang/protobuf/ptypes\"\n \tvideopb \"google.golang.org/genproto/googleapis/cloud/videointelligence/v1\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/annotate/object_tracking_gcs.go",
        "code_diff": "@@ -39,7 +36,7 @@\nfunc objectTrackingGCS(w io.Writer, gcsURI string) error {\n \t// Creates a client.\n \tclient, err := video.NewClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to create client: %v\", err)\n+\t\treturn fmt.Errorf(\"video.NewClient: %v\", err)\n \t}\n \n \top, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/annotate/text_detection.go",
        "code_diff": "@@ -18,16 +18,13 @@\npackage annotate\n // [START videointelligence_text_detection]\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n-\n-\t\"context\"\n-\n-\t\"github.com/golang/protobuf/ptypes\"\n \n \tvideo \"cloud.google.com/go/videointelligence/apiv1\"\n+\t\"github.com/golang/protobuf/ptypes\"\n \tvideopb \"google.golang.org/genproto/googleapis/cloud/videointelligence/v1\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/annotate/text_detection.go",
        "code_diff": "@@ -40,12 +37,12 @@\nfunc textDetection(w io.Writer, filename string) error {\n \t// Creates a client.\n \tclient, err := video.NewClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to create client: %v\", err)\n+\t\treturn fmt.Errorf(\"video.NewClient: %v\", err)\n \t}\n \n \tfileBytes, err := ioutil.ReadFile(filename)\n \tif err != nil {\n-\t\treturn err\n+\t\treturn fmt.Errorf(\"ioutil.ReadFile: %v\", err)\n \t}\n \n \top, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/annotate/text_detection_gcs.go",
        "code_diff": "@@ -18,15 +18,12 @@\npackage annotate\n // [START videointelligence_text_detection_gcs]\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\n-\t\"context\"\n-\n-\t\"github.com/golang/protobuf/ptypes\"\n \n \tvideo \"cloud.google.com/go/videointelligence/apiv1\"\n+\t\"github.com/golang/protobuf/ptypes\"\n \tvideopb \"google.golang.org/genproto/googleapis/cloud/videointelligence/v1\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/annotate/text_detection_gcs.go",
        "code_diff": "@@ -39,7 +36,7 @@\nfunc textDetectionGCS(w io.Writer, gcsURI string) error {\n \t// Creates a client.\n \tclient, err := video.NewClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to create client: %v\", err)\n+\t\treturn fmt.Errorf(\"video.NewClient: %v\", err)\n \t}\n \n \top, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc label(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)\n \tif err != nil {\n-\t\treturn err\n+\t\treturn fmt.Errorf(\"video.NewClient: %v\", err)\n \t}\n \n \tfileBytes, err := ioutil.ReadFile(file)",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc labelURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)\n \tif err != nil {\n-\t\treturn err\n+\t\treturn fmt.Errorf(\"video.NewClient: %v\", err)\n \t}\n \n \top, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"io\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -27,7 +28,7 @@\nconst catVideo = \"gs://cloud-samples-data/video/cat.mp4\"\n const googleworkVideo = \"gs://python-docs-samples-tests/video/googlework_short.mp4\"\n \n func TestAnalyze(t *testing.T) {\n-\ttestutil.SystemTest(t)\n+\ttestutil.EndToEndTest(t)\n \n \ttests := []struct {\n \t\tname        string",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor-snippets",
        "commit_id": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "automl: remove old files and update region tags for samples",
        "pr_number": 1119,
        "file_name": "healthcare/fhir_resource_search.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage snippets\n \n-// [START healthcare_search_resources]\n+// [START healthcare_search_resources_post]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into automl-cleanup",
        "commit_id": "7122f6961996c51a00d46b50b2f038e7f9d52f62"
    },
    {
        "pr_title": "vision: add set_endpoint sample",
        "pr_number": 1113,
        "file_name": "vision/detect/set_endpoint_test.go",
        "code_diff": "@@ -15,24 +15,30 @@\npackage main\n \n import (\n-\t\"bytes\"\n \t\"context\"\n-\t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n \n+\tvision \"cloud.google.com/go/vision/apiv1\"\n+\t\"google.golang.org/api/option\"\n \tvisionpb \"google.golang.org/genproto/googleapis/cloud/vision/v1\"\n )\n \n func TestSetEndpoint(t *testing.T) {\n-\tctx := context.Background()\n-\n \tconst endpoint = \"eu-vision.googleapis.com:443\"\n \n-\tclient, err := setEndpoint(ctx, endpoint)\n+\t// Run the code sample to check for errors.\n+\terr := setEndpoint(endpoint)\n \tif err != nil {\n \t\tt.Fatalf(\"setEndpoint: %v\", err)\n \t}\n+\n+\t// Since we're not returning the client from the code sample, we create an equivalent client here.\n+\tctx := context.Background()\n+\tclient, err := vision.NewImageAnnotatorClient(ctx, option.WithEndpoint(endpoint))\n+\tif err != nil {\n+\t\tt.Fatalf(\"NewImageAnnotatorClient: %v\", err)\n+\t}\n \tdefer client.Close()\n \n \timage := &visionpb.Image{",
        "comments": [
            {
                "comment": "Create another client for the tests. It's less efficient, but more clear.",
                "position": null
            },
            {
                "comment": "Does the output of this change based on the endpoint? Is there a more direct way we can test the endpoint was actually set?",
                "position": 49
            },
            {
                "comment": "This is the test already. So, there is no need to write to a buffer. The result values can be checked directly.",
                "position": null
            },
            {
                "comment": "Alright",
                "position": null
            },
            {
                "comment": "I don't think the output changes, this is what they're doing in the canonical",
                "position": 49
            },
            {
                "comment": "Got it, changing",
                "position": null
            },
            {
                "comment": "@nnegrey do you know if there is a more direct way to test if the endpoint was actually used? Or is it completely transparent for users?",
                "position": 49
            },
            {
                "comment": "Not that I know of for this API, you can pass an invalid endpoint and get an error. But no resource is created. \r\n\r\nNatural Language for example has a different set of endpoints they support as documented here: https://cloud.google.com/natural-language/docs/locations",
                "position": 49
            },
            {
                "comment": "Could we remove this portion of the test if it's not testing the sample? Or is it needed to make sure it still works after changing the endpoint?",
                "position": 49
            },
            {
                "comment": "Mostly to just verify the endpoint works. ",
                "position": 49
            },
            {
                "comment": "@tbpg how do you feel about this? Would you still want to change anything or should we go ahead and merge?",
                "position": 49
            },
            {
                "comment": "Sounds good to me.",
                "position": 49
            },
            {
                "comment": "In the test, you could set the endpoint to a dummy gRPC server.\r\n\r\n(But I think this is good enough.)",
                "position": 49
            }
        ],
        "commit_message": "uncommented boilerplate and simplified test",
        "commit_id": "9c45a5de6c70296bc44a3c5168f89d850a343c0d"
    },
    {
        "pr_title": "storage: include metadata description in Go",
        "pr_number": 1092,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -27,6 +27,7 @@\nimport (\n \t\"errors\"\n \t\"fmt\"\n \t\"net/http\"\n+\t\"net/url\"\n \t\"os/exec\"\n \t\"path\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into gcf-gcs",
        "commit_id": "2101792801146d094d883fee597dfb450810e4a3"
    },
    {
        "pr_title": "storage: add list gcs objects with s3 library",
        "pr_number": 1079,
        "file_name": "storage/s3_sdk/s3_gcs_test.go",
        "code_diff": "@@ -28,7 +28,7 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func TestList(t *testing.T) {\n+func TestListGCSBuckets(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)",
        "comments": [
            {
                "comment": "Please keep these the same.\r\n\r\nhttps://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "storage: create HMAC test key on the fly",
        "commit_id": "46c0c1c4bd3d8657fec40b9fbe9c2a9e23c87005"
    },
    {
        "pr_title": "storage: add list gcs objects with s3 library",
        "pr_number": 1079,
        "file_name": "storage/s3_sdk/s3_gcs_test.go",
        "code_diff": "@@ -50,7 +50,7 @@\nfunc TestList(t *testing.T) {\n \t// to that amount of time.\n \ttestutil.Retry(t, 75, time.Millisecond*200, func(r *testutil.R) {\n \t\tbuf.Reset()\n-\t\tif _, err := listGCSBuckets(buf, key.AccessID, key.Secret); err != nil {\n+\t\tif err := listGCSBuckets(buf, key.AccessID, key.Secret); err != nil {\n \t\t\tr.Errorf(\"listGCSBuckets: %v\", err)\n \t\t}\n \t})",
        "comments": [
            {
                "comment": "Please keep these the same.\r\n\r\nhttps://github.com/golang/go/wiki/CodeReviewComments#useful-test-failures",
                "position": null
            }
        ],
        "commit_message": "storage: create HMAC test key on the fly",
        "commit_id": "46c0c1c4bd3d8657fec40b9fbe9c2a9e23c87005"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "appengine/go11x/static/main.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage main\n \n import (\n-\t\"fmt\"\n \t\"html/template\"\n \t\"log\"\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "appengine_flexible/websockets/main.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \t\"net/http\"\n+\t\"os\"\n \n \t\"github.com/gorilla/websocket\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "docs/error-reporting/fluent/main.go",
        "code_diff": "@@ -20,6 +20,7 @@\npackage main\n import (\n \t\"log\"\n \t\"net/http\"\n+\t\"os\"\n \t\"runtime\"\n \n \t\"github.com/fluent/fluent-logger-golang/fluent\"",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "endpoints/getting-started/app.go",
        "code_diff": "@@ -22,7 +22,6 @@\nimport (\n \t\"log\"\n \t\"net/http\"\n \t\"os\"\n-\t\"strconv\"\n \n \t\"github.com/gorilla/mux\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/bookshelf.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"io\"\n \t\"os\"\n \n+\t\"cloud.google.com/go/errorreporting\"\n \t\"cloud.google.com/go/storage\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/bookshelf.go",
        "code_diff": "@@ -49,9 +50,6 @@\ntype BookDatabase interface {\n \n \t// UpdateBook updates the entry for a given book.\n \tUpdateBook(ctx context.Context, b *Book) error\n-\n-\t// Close closes the database, freeing up any available resources.\n-\tClose(ctx context.Context) error\n }\n \n // Bookshelf holds a BookDatabase and storage info.",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/bookshelf.go",
        "code_diff": "@@ -62,7 +60,13 @@\ntype Bookshelf struct {\n \tStorageBucketName string\n \n \t// logWriter is used for request logging and can be overridden for tests.\n+\t//\n+\t// See https://cloud.google.com/logging/docs/setup/go for how to use the\n+\t// Stackdriver logging client. Output to stdout and stderr is automaticaly\n+\t// sent to Stackdriver when running on App Engine.\n \tlogWriter io.Writer\n+\n+\terrorClient *errorreporting.Client\n }\n \n // NewBookshelf creates a new Bookshelf.",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -32,8 +32,10 @@\ntype firestoreDB struct {\n // Ensure firestoreDB conforms to the BookDatabase interface.\n var _ BookDatabase = &firestoreDB{}\n \n+// [START getting_started_bookshelf_firestore]\n+\n // newFirestoreDB creates a new BookDatabase backed by Cloud Firestore.\n-// See the firestore and google packages for details on creating a suitable\n+// See the firestore package for details on creating a suitable\n // firestore.Client: https://godoc.org/cloud.google.com/go/firestore.\n func newFirestoreDB(client *firestore.Client) (*firestoreDB, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -55,7 +57,7 @@\nfunc (db *firestoreDB) Close(context.Context) error {\n \treturn db.client.Close()\n }\n \n-// GetBook retrieves a book by its ID.\n+// Book retrieves a book by its ID.\n func (db *firestoreDB) GetBook(ctx context.Context, id string) (*Book, error) {\n \tds, err := db.client.Collection(\"books\").Doc(id).Get(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -27,7 +27,9 @@\nimport (\n \t\"net/http\"\n \t\"os\"\n \t\"path\"\n+\t\"runtime/debug\"\n \n+\t\"cloud.google.com/go/errorreporting\"\n \t\"cloud.google.com/go/firestore\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/gofrs/uuid\"",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -62,16 +64,17 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"newFirestoreDB: %v\", err)\n \t}\n-\n-\tshelf, err := NewBookshelf(projectID, db)\n+\tb, err := NewBookshelf(projectID, db)\n \tif err != nil {\n \t\tlog.Fatalf(\"NewBookshelf: %v\", err)\n \t}\n \n-\tshelf.registerHandlers()\n+\tb.registerHandlers()\n \n \tlog.Printf(\"Listening on localhost:%s\", port)\n-\tlog.Fatal(http.ListenAndServe(fmt.Sprintf(\":%s\", port), nil))\n+\tif err := http.ListenAndServe(\":\"+port, nil); err != nil {\n+\t\tlog.Fatal(err)\n+\t}\n }\n \n func (b *Bookshelf) registerHandlers() {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -85,16 +88,16 @@\nfunc (b *Bookshelf) registerHandlers() {\n \t\tHandler(appHandler(b.listHandler))\n \tr.Methods(\"GET\").Path(\"/books/add\").\n \t\tHandler(appHandler(b.addFormHandler))\n-\tr.Methods(\"GET\").Path(\"/books/{id:[0-9a-zA-Z]+}\").\n+\tr.Methods(\"GET\").Path(\"/books/{id:[0-9a-zA-Z_\\\\-]+}\").\n \t\tHandler(appHandler(b.detailHandler))\n-\tr.Methods(\"GET\").Path(\"/books/{id:[0-9a-zA-Z]+}/edit\").\n+\tr.Methods(\"GET\").Path(\"/books/{id:[0-9a-zA-Z_\\\\-]+}/edit\").\n \t\tHandler(appHandler(b.editFormHandler))\n \n \tr.Methods(\"POST\").Path(\"/books\").\n \t\tHandler(appHandler(b.createHandler))\n-\tr.Methods(\"POST\", \"PUT\").Path(\"/books/{id:[0-9a-zA-Z]+}\").\n+\tr.Methods(\"POST\", \"PUT\").Path(\"/books/{id:[0-9a-zA-Z_\\\\-]+}\").\n \t\tHandler(appHandler(b.updateHandler))\n-\tr.Methods(\"POST\").Path(\"/books/{id:[0-9a-zA-Z]+}:delete\").\n+\tr.Methods(\"POST\").Path(\"/books/{id:[0-9a-zA-Z_\\\\-]+}:delete\").\n \t\tHandler(appHandler(b.deleteHandler)).Name(\"delete\")\n \n \t// Respond to App Engine and Compute Engine health checks.",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -104,22 +107,23 @@\nfunc (b *Bookshelf) registerHandlers() {\n \t\t\tw.Write([]byte(\"ok\"))\n \t\t})\n \n-\t// [START request_logging]\n+\tr.Methods(\"GET\").Path(\"/logs\").Handler(appHandler(b.sendLog))\n+\tr.Methods(\"GET\").Path(\"/errors\").Handler(appHandler(b.sendError))\n+\n \t// Delegate all of the HTTP routing and serving to the gorilla/mux router.\n \t// Log all requests using the standard Apache format.\n \thttp.Handle(\"/\", handlers.CombinedLoggingHandler(b.logWriter, r))\n-\t// [END request_logging]\n }\n \n // listHandler displays a list with summaries of books in the database.\n func (b *Bookshelf) listHandler(w http.ResponseWriter, r *http.Request) *appError {\n \tctx := r.Context()\n \tbooks, err := b.DB.ListBooks(ctx)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"could not list books: %v\", err)\n+\t\treturn b.appErrorf(r, err, \"could not list books: %v\", err)\n \t}\n \n-\treturn listTmpl.Execute(w, r, books)\n+\treturn listTmpl.Execute(b, w, r, books)\n }\n \n // bookFromRequest retrieves a book from the database given a book ID in the",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -141,27 +145,27 @@\nfunc (b *Bookshelf) bookFromRequest(r *http.Request) (*Book, error) {\n func (b *Bookshelf) detailHandler(w http.ResponseWriter, r *http.Request) *appError {\n \tbook, err := b.bookFromRequest(r)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"%v\", err)\n+\t\treturn b.appErrorf(r, err, \"%v\", err)\n \t}\n \n-\treturn detailTmpl.Execute(w, r, book)\n+\treturn detailTmpl.Execute(b, w, r, book)\n }\n \n // addFormHandler displays a form that captures details of a new book to add to\n // the database.\n func (b *Bookshelf) addFormHandler(w http.ResponseWriter, r *http.Request) *appError {\n-\treturn editTmpl.Execute(w, r, nil)\n+\treturn editTmpl.Execute(b, w, r, nil)\n }\n \n // editFormHandler displays a form that allows the user to edit the details of\n // a given book.\n func (b *Bookshelf) editFormHandler(w http.ResponseWriter, r *http.Request) *appError {\n \tbook, err := b.bookFromRequest(r)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"%v\", err)\n+\t\treturn b.appErrorf(r, err, \"%v\", err)\n \t}\n \n-\treturn editTmpl.Execute(w, r, book)\n+\treturn editTmpl.Execute(b, w, r, book)\n }\n \n // bookFromForm populates the fields of a Book from form values",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -187,6 +191,8 @@\nfunc (b *Bookshelf) bookFromForm(r *http.Request) (*Book, error) {\n \treturn book, nil\n }\n \n+// [START getting_started_bookshelf_storage]\n+\n // uploadFileFromForm uploads a file if it's present in the \"image\" form field.\n func (b *Bookshelf) uploadFileFromForm(ctx context.Context, r *http.Request) (url string, err error) {\n \tf, fh, err := r.FormFile(\"image\")",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -198,11 +204,11 @@\nfunc (b *Bookshelf) uploadFileFromForm(ctx context.Context, r *http.Request) (ur\n \t}\n \n \tif b.StorageBucket == nil {\n-\t\treturn \"\", errors.New(\"storage bucket is missing: check config.go\")\n+\t\treturn \"\", errors.New(\"storage bucket is missing: check bookshelf.go\")\n \t}\n \tif _, err := b.StorageBucket.Attrs(ctx); err != nil {\n \t\tif err == storage.ErrBucketNotExist {\n-\t\t\treturn \"\", fmt.Errorf(\"bucket %q does not exist: check config.go\", b.StorageBucketName)\n+\t\t\treturn \"\", fmt.Errorf(\"bucket %q does not exist: check bookshelf.go\", b.StorageBucketName)\n \t\t}\n \t\treturn \"\", fmt.Errorf(\"could not get bucket: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -230,16 +236,18 @@\nfunc (b *Bookshelf) uploadFileFromForm(ctx context.Context, r *http.Request) (ur\n \treturn fmt.Sprintf(publicURL, b.StorageBucketName, name), nil\n }\n \n+// [END getting_started_bookshelf_storage]\n+\n // createHandler adds a book to the database.\n func (b *Bookshelf) createHandler(w http.ResponseWriter, r *http.Request) *appError {\n \tctx := r.Context()\n \tbook, err := b.bookFromForm(r)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"could not parse book from form: %v\", err)\n+\t\treturn b.appErrorf(r, err, \"could not parse book from form: %v\", err)\n \t}\n \tid, err := b.DB.AddBook(ctx, book)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"could not save book: %v\", err)\n+\t\treturn b.appErrorf(r, err, \"could not save book: %v\", err)\n \t}\n \thttp.Redirect(w, r, fmt.Sprintf(\"/books/%s\", id), http.StatusFound)\n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -250,16 +258,16 @@\nfunc (b *Bookshelf) updateHandler(w http.ResponseWriter, r *http.Request) *appEr\n \tctx := r.Context()\n \tid := mux.Vars(r)[\"id\"]\n \tif id == \"\" {\n-\t\treturn appErrorf(errors.New(\"no book with empty ID\"), \"no book with empty ID\")\n+\t\treturn b.appErrorf(r, errors.New(\"no book with empty ID\"), \"no book with empty ID\")\n \t}\n \tbook, err := b.bookFromForm(r)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"could not parse book from form: %v\", err)\n+\t\treturn b.appErrorf(r, err, \"could not parse book from form: %v\", err)\n \t}\n \tbook.ID = id\n \n \tif err := b.DB.UpdateBook(ctx, book); err != nil {\n-\t\treturn appErrorf(err, \"UpdateBook: %v\", err)\n+\t\treturn b.appErrorf(r, err, \"UpdateBook: %v\", err)\n \t}\n \thttp.Redirect(w, r, fmt.Sprintf(\"/books/%s\", book.ID), http.StatusFound)\n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/bookshelf/main_test.go",
        "code_diff": "@@ -56,6 +56,17 @@\nfunc TestMain(m *testing.M) {\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"firestore.NewClient: %v\", err)\n \t\t}\n+\n+\t\t// Delete all docs first to start with a clean slate.\n+\t\tdocs, err := client.Collection(\"books\").DocumentRefs(ctx).GetAll()\n+\t\tif err == nil {\n+\t\t\tfor _, d := range docs {\n+\t\t\t\tif _, err := d.Delete(ctx); err != nil {\n+\t\t\t\t\tlog.Fatalf(\"Delete: %v\", err)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n \t\tdb, err := newFirestoreDB(client)\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"newFirestoreDB: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "getting-started/devflowapp/devflowapp.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \t\"net/http\"\n+\t\"os\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/getting-started/devflowapp/services\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/basic_company_sample_test.go",
        "code_diff": "@@ -24,6 +24,8 @@\nimport (\n )\n \n func TestGetCompany(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \tbuf := &bytes.Buffer{}\n \tif _, err := getCompany(buf, testCompany.Name); err != nil {\n \t\tt.Fatalf(\"getCompany: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/basic_company_sample_test.go",
        "code_diff": "@@ -35,6 +37,8 @@\nfunc TestGetCompany(t *testing.T) {\n }\n \n func TestUpdateCompany(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttestCompany.HiringAgency = false\n \tc, err := updateCompany(ioutil.Discard, testCompany.Name, testCompany)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/basic_company_sample_test.go",
        "code_diff": "@@ -54,6 +58,8 @@\nfunc TestUpdateCompany(t *testing.T) {\n }\n \n func TestUpdateCompanyWithMask(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttestCompany.HiringAgency = false\n \tc, err := updateCompanyWithMask(ioutil.Discard, testCompany.Name, \"hiring_agency\", testCompany)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/basic_job_sample_test.go",
        "code_diff": "@@ -25,6 +25,8 @@\nimport (\n )\n \n func TestGetJob(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \tbuf := &bytes.Buffer{}\n \tif _, err := getJob(buf, testJob.Name); err != nil {\n \t\tt.Fatalf(\"getJob: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/basic_job_sample_test.go",
        "code_diff": "@@ -36,6 +38,8 @@\nfunc TestGetJob(t *testing.T) {\n }\n \n func TestUpdateJob(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttestJob.Qualifications = \"foo\"\n \tj, err := updateJob(ioutil.Discard, testJob.Name, testJob)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/basic_job_sample_test.go",
        "code_diff": "@@ -55,6 +59,8 @@\nfunc TestUpdateJob(t *testing.T) {\n }\n \n func TestUpdateJobWithMask(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttestJob.Qualifications = \"foo\"\n \tj, err := updateJobWithMask(ioutil.Discard, testJob.Name, \"qualifications\", testJob)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/custom_attribute_sample_test.go",
        "code_diff": "@@ -24,6 +24,8 @@\nimport (\n )\n \n func TestFilterOnStringValueCustomAttribute(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {\n \t\tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/custom_attribute_sample_test.go",
        "code_diff": "@@ -38,6 +40,8 @@\nfunc TestFilterOnStringValueCustomAttribute(t *testing.T) {\n }\n \n func TestFilterOnLongValueCustomAttribute(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {\n \t\tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/general_search_sample_test.go",
        "code_diff": "@@ -24,6 +24,8 @@\nimport (\n )\n \n func TestBasicJobSearch(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/general_search_sample_test.go",
        "code_diff": "@@ -39,6 +41,8 @@\nfunc TestBasicJobSearch(t *testing.T) {\n }\n \n func TestCategoryFilterSearch(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/general_search_sample_test.go",
        "code_diff": "@@ -54,6 +58,8 @@\nfunc TestCategoryFilterSearch(t *testing.T) {\n }\n \n func TestEmploymentTypesSearch(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/general_search_sample_test.go",
        "code_diff": "@@ -69,6 +75,8 @@\nfunc TestEmploymentTypesSearch(t *testing.T) {\n }\n \n func TestDateRangeSearch(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/general_search_sample_test.go",
        "code_diff": "@@ -84,6 +92,8 @@\nfunc TestDateRangeSearch(t *testing.T) {\n }\n \n func TestLanguageCodeSearch(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/general_search_sample_test.go",
        "code_diff": "@@ -99,6 +109,8 @@\nfunc TestLanguageCodeSearch(t *testing.T) {\n }\n \n func TestCompanyDisplayNameSearch(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/location_based_search_sample_test.go",
        "code_diff": "@@ -24,6 +24,8 @@\nimport (\n )\n \n func TestBasicLocationSearch(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/location_based_search_sample_test.go",
        "code_diff": "@@ -39,6 +41,8 @@\nfunc TestBasicLocationSearch(t *testing.T) {\n }\n \n func TestCityLocationSearch(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/location_based_search_sample_test.go",
        "code_diff": "@@ -54,6 +58,8 @@\nfunc TestCityLocationSearch(t *testing.T) {\n }\n \n func TestBroadeningLocationSearch(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v3/howto/location_based_search_sample_test.go",
        "code_diff": "@@ -69,6 +75,8 @@\nfunc TestBroadeningLocationSearch(t *testing.T) {\n }\n \n func TestKeywordLocationSearch(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, 1*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "jobs/v4/howto/howto_test.go",
        "code_diff": "@@ -32,6 +32,8 @@\nvar testCompany *talentpb.Company\n var testJob *talentpb.Job\n \n func TestBasicUsage(t *testing.T) {\n+\tt.Skip(\"Flaky. https://github.com/GoogleCloudPlatform/golang-samples/issues/1061.\")\n+\n \ttc := testutil.SystemTest(t)\n \n \texternalID := fmt.Sprintf(\"company-%s\", uuid.Must(uuid.NewV4()).String())",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "run/image-processing/main.go",
        "code_diff": "@@ -19,7 +19,6 @@\npackage main\n \n import (\n \t\"encoding/json\"\n-\t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'launch' of https://github.com/GoogleCloudPlatform/golang-samples into launch",
        "commit_id": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "run/pubsub: update to go 1.13 and new Dockerfile standard",
        "pr_number": 1072,
        "file_name": "tasks/create_http_task.go",
        "code_diff": "@@ -21,15 +21,15 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2beta3\"\n-\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2beta3\"\n+\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2\"\n+\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2\"\n )\n \n // createHTTPTask creates a new task in your with a HTTP target.\n func createHTTPTask(projectID, locationID, queueID, url, message string) (*taskspb.Task, error) {\n \n \t// Create a new Cloud Tasks client instance.\n-\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2beta3\n+\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2\n \tctx := context.Background()\n \tclient, err := cloudtasks.NewClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/pubsub-113",
        "commit_id": "7889a230df0b8575c76e22ee713f10028d5116f1"
    },
    {
        "pr_title": "run/pubsub: update to go 1.13 and new Dockerfile standard",
        "pr_number": 1072,
        "file_name": "tasks/token/create_http_task_with_token.go",
        "code_diff": "@@ -20,15 +20,15 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2beta3\"\n-\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2beta3\"\n+\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2\"\n+\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2\"\n )\n \n // createHTTPTaskWithToken constructs a task with a authorization token\n // and HTTP target then adds it to a Queue.\n func createHTTPTaskWithToken(projectID, locationID, queueID, url, email, message string) (*taskspb.Task, error) {\n \t// Create a new Cloud Tasks client instance.\n-\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2beta3\n+\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2\n \tctx := context.Background()\n \tclient, err := cloudtasks.NewClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into run/pubsub-113",
        "commit_id": "7889a230df0b8575c76e22ee713f10028d5116f1"
    },
    {
        "pr_title": "run: add facility for e2e testing",
        "pr_number": 1070,
        "file_name": "internal/cloudrunci/gcloud_test.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n )\n \n func TestCreateIDToken(t *testing.T) {\n+\tt.Skip()\n \ttestutil.EndToEndTest(t)\n \t// TODO assign to token\n \t_, err := createIDToken(\"http://example.com\")",
        "comments": [],
        "commit_message": "run/e2e: more e2e test flagging",
        "commit_id": "ae91414c008e505f77fa50d8afa59a4e0eb58d63"
    },
    {
        "pr_title": "run: add facility for e2e testing",
        "pr_number": 1070,
        "file_name": "internal/cloudrunci/platform_test.go",
        "code_diff": "@@ -19,9 +19,11 @@\nimport (\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n func TestManagedPlatformRequest(t *testing.T) {\n+\ttestutil.EndToEndTest(t)\n \tp := cloudrunci.ManagedPlatform{}\n \n \treq, err := p.NewRequest(\"GET\", \"http://example.com\")",
        "comments": [],
        "commit_message": "run/e2e: more e2e test flagging",
        "commit_id": "ae91414c008e505f77fa50d8afa59a4e0eb58d63"
    },
    {
        "pr_title": "run: add facility for e2e testing",
        "pr_number": 1070,
        "file_name": "internal/cloudrunci/platform_test.go",
        "code_diff": "@@ -35,6 +37,7 @@\nfunc TestManagedPlatformRequest(t *testing.T) {\n }\n \n func TestGKEPlatformRequest(t *testing.T) {\n+\ttestutil.EndToEndTest(t)\n \tp := cloudrunci.GKEPlatform{}\n \n \treq, err := p.NewRequest(\"GET\", \"http://example.com\")",
        "comments": [],
        "commit_message": "run/e2e: more e2e test flagging",
        "commit_id": "ae91414c008e505f77fa50d8afa59a4e0eb58d63"
    },
    {
        "pr_title": "getting-started/gce: initial commit",
        "pr_number": 1063,
        "file_name": "appengine/go11x/static/main.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage main\n \n import (\n-\t\"fmt\"\n \t\"html/template\"\n \t\"log\"\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into gce",
        "commit_id": "9dd8cb46315064c25f4f9f18eb2e7ceb596e55de"
    },
    {
        "pr_title": "getting-started/gce: initial commit",
        "pr_number": 1063,
        "file_name": "appengine_flexible/websockets/main.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \t\"net/http\"\n+\t\"os\"\n \n \t\"github.com/gorilla/websocket\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into gce",
        "commit_id": "9dd8cb46315064c25f4f9f18eb2e7ceb596e55de"
    },
    {
        "pr_title": "getting-started/gce: initial commit",
        "pr_number": 1063,
        "file_name": "docs/error-reporting/fluent/main.go",
        "code_diff": "@@ -20,6 +20,7 @@\npackage main\n import (\n \t\"log\"\n \t\"net/http\"\n+\t\"os\"\n \t\"runtime\"\n \n \t\"github.com/fluent/fluent-logger-golang/fluent\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into gce",
        "commit_id": "9dd8cb46315064c25f4f9f18eb2e7ceb596e55de"
    },
    {
        "pr_title": "getting-started/gce: initial commit",
        "pr_number": 1063,
        "file_name": "endpoints/getting-started/app.go",
        "code_diff": "@@ -22,7 +22,6 @@\nimport (\n \t\"log\"\n \t\"net/http\"\n \t\"os\"\n-\t\"strconv\"\n \n \t\"github.com/gorilla/mux\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into gce",
        "commit_id": "9dd8cb46315064c25f4f9f18eb2e7ceb596e55de"
    },
    {
        "pr_title": "getting-started/gce: initial commit",
        "pr_number": 1063,
        "file_name": "getting-started/devflowapp/devflowapp.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \t\"net/http\"\n+\t\"os\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/getting-started/devflowapp/services\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into gce",
        "commit_id": "9dd8cb46315064c25f4f9f18eb2e7ceb596e55de"
    },
    {
        "pr_title": "getting-started/gce: initial commit",
        "pr_number": 1063,
        "file_name": "run/image-processing/main.go",
        "code_diff": "@@ -19,7 +19,6 @@\npackage main\n \n import (\n \t\"encoding/json\"\n-\t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into gce",
        "commit_id": "9dd8cb46315064c25f4f9f18eb2e7ceb596e55de"
    },
    {
        "pr_title": "getting-started/gce: initial commit",
        "pr_number": 1063,
        "file_name": "run/pubsub/main.go",
        "code_diff": "@@ -19,7 +19,6 @@\npackage main\n \n import (\n \t\"encoding/json\"\n-\t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into gce",
        "commit_id": "9dd8cb46315064c25f4f9f18eb2e7ceb596e55de"
    },
    {
        "pr_title": "getting-started/gce: initial commit",
        "pr_number": 1063,
        "file_name": "tasks/create_http_task.go",
        "code_diff": "@@ -21,15 +21,15 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2beta3\"\n-\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2beta3\"\n+\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2\"\n+\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2\"\n )\n \n // createHTTPTask creates a new task in your with a HTTP target.\n func createHTTPTask(projectID, locationID, queueID, url, message string) (*taskspb.Task, error) {\n \n \t// Create a new Cloud Tasks client instance.\n-\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2beta3\n+\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2\n \tctx := context.Background()\n \tclient, err := cloudtasks.NewClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into gce",
        "commit_id": "9dd8cb46315064c25f4f9f18eb2e7ceb596e55de"
    },
    {
        "pr_title": "getting-started/gce: initial commit",
        "pr_number": 1063,
        "file_name": "tasks/token/create_http_task_with_token.go",
        "code_diff": "@@ -20,15 +20,15 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2beta3\"\n-\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2beta3\"\n+\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2\"\n+\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2\"\n )\n \n // createHTTPTaskWithToken constructs a task with a authorization token\n // and HTTP target then adds it to a Queue.\n func createHTTPTaskWithToken(projectID, locationID, queueID, url, email, message string) (*taskspb.Task, error) {\n \t// Create a new Cloud Tasks client instance.\n-\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2beta3\n+\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2\n \tctx := context.Background()\n \tclient, err := cloudtasks.NewClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into gce",
        "commit_id": "9dd8cb46315064c25f4f9f18eb2e7ceb596e55de"
    },
    {
        "pr_title": "all: check PORT env var, explicit ListenAndServe err check, fix testing change check",
        "pr_number": 1060,
        "file_name": "endpoints/getting-started/app.go",
        "code_diff": "@@ -22,7 +22,6 @@\nimport (\n \t\"log\"\n \t\"net/http\"\n \t\"os\"\n-\t\"strconv\"\n \n \t\"github.com/gorilla/mux\"\n )",
        "comments": [
            {
                "comment": "The strconv seems unnecessary here.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "endpoints: no more Atoi",
        "commit_id": "b6e23f79b8ba9f45b1889f7e76366320d231c58b"
    },
    {
        "pr_title": "translate/v3: add samples for translate v3",
        "pr_number": 1047,
        "file_name": "translate/v3/create_and_delete_glossary_test.go",
        "code_diff": "@@ -37,13 +37,13 @@\nfunc TestCreateAndDeleteGlossary(t *testing.T) {\n \t\tt.Fatalf(\"createGlossary: %v\", err)\n \t}\n \tif got, want := buf.String(), \"Created\"; !strings.Contains(got, want) {\n-\t\tt.Fatalf(\"createGlossary got:\\n----\\n%s----\\nWant to contain:\\n----\\n%s\\n----\", got, want)\n+\t\tt.Errorf(\"createGlossary got:\\n----\\n%s----\\nWant to contain:\\n----\\n%s\\n----\", got, want)\n \t}\n \tif got, want := buf.String(), glossaryID; !strings.Contains(got, want) {\n-\t\tt.Fatalf(\"createGlossary got:\\n----\\n%s----\\nWant to contain:\\n----\\n%s\\n----\", got, want)\n+\t\tt.Errorf(\"createGlossary got:\\n----\\n%s----\\nWant to contain:\\n----\\n%s\\n----\", got, want)\n \t}\n \tif got, want := buf.String(), glossaryInputURI; !strings.Contains(got, want) {\n-\t\tt.Fatalf(\"createGlossary got:\\n----\\n%s----\\nWant to contain:\\n----\\n%s\\n----\", got, want)\n+\t\tt.Errorf(\"createGlossary got:\\n----\\n%s----\\nWant to contain:\\n----\\n%s\\n----\", got, want)\n \t}\n \n \t// Delete the glossary.",
        "comments": [
            {
                "comment": "I think this doesn't have to be predeclared.\r\n\r\n`got := buf.String()` on L42 should work. Needs to be fixed in other locations as well.",
                "position": null
            },
            {
                "comment": "Is `t.Fatalf` correct here? Usually, the guidance is to \"keep going,\" so you would use `t.Errorf`. But, it depends on the error whether or not you want to continue or not.",
                "position": null
            },
            {
                "comment": "Mmm I didn't know, but it makes sense. I'll make them `t.Errorf` instead of `t.Fatalf`.",
                "position": null
            }
        ],
        "commit_message": "Make errors on test checks non-fatal",
        "commit_id": "3738ad9eff4a760ae01351426f843dfc2d314794"
    },
    {
        "pr_title": "translate/v3: add samples for translate v3",
        "pr_number": 1047,
        "file_name": "translate/v3/delete_bucket.go",
        "code_diff": "@@ -26,7 +26,7 @@\nimport (\n func deleteBucket(ctx context.Context, t *testing.T, bucket *storage.BucketHandle) {\n \tbucketAttrs, err := bucket.Attrs(ctx)\n \tif err != nil {\n-\t\tt.Fatalf(\"bucket.Attrs: %v\", err)\n+\t\tt.Errorf(\"bucket.Attrs: %v\", err)\n \t}\n \tbucketName := bucketAttrs.Name\n \tit := bucket.Objects(ctx, nil)",
        "comments": [],
        "commit_message": "Make errors on test checks non-fatal",
        "commit_id": "3738ad9eff4a760ae01351426f843dfc2d314794"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -30,6 +30,7 @@\nimport (\n // the metadata of the DICOM file and make up the DicomWebPath\n // in the requests to retrieve studies/instances/frames/rendered.\n const (\n+\tstudyPath          = \"studies\"\n \tstudyUID           = \"studies/1.3.6.1.4.1.11129.5.5.111396399361969898205364400549799252857604/\"\n \tseriesUID          = \"series/1.3.6.1.4.1.11129.5.5.195628213694300498946760767481291263511724/\"\n \tinstanceUID        = \"instances/1.3.6.1.4.1.11129.5.5.153751009835107614666834563294684339746480/\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into correct-pubsub-subscription-reference",
        "commit_id": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -82,7 +83,7 @@\nfunc TestDICOMStore(t *testing.T) {\n \t\t\tr.Errorf(\"getDICOMStore got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, dicomStoreName) {\n-\t\t\tr.Errorf(\"listDICOMStores got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, dicomStoreName)\n+\t\t\tr.Errorf(\"getDICOMStores got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, dicomStoreName)\n \t\t}\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into correct-pubsub-subscription-reference",
        "commit_id": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "getting-started/authenticating-users: regions, tests, style",
        "pr_number": 1006,
        "file_name": "getting-started/authenticating-users/main.go",
        "code_diff": "@@ -31,8 +31,20 @@\nimport (\n \t\"github.com/dgrijalva/jwt-go\"\n )\n \n+// app holds the Cloud IAP certificates and audience field for this app, which\n+// are needed to verify authentication headers set by Cloud IAP.\n+type app struct {\n+\tcerts map[string]string\n+\taud   string\n+}\n+\n func main() {\n-\thttp.HandleFunc(\"/\", index)\n+\ta, err := newApp()\n+\tif err != nil {\n+\t\tlog.Fatal(err)\n+\t}\n+\n+\thttp.HandleFunc(\"/\", a.index)\n \n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {",
        "comments": [
            {
                "comment": "\"Hello None\"? o.O Is that meaningful somehow?",
                "position": null
            },
            {
                "comment": "Maybe just log.Println(err)? Seems like the err from a function like validateAssertion should be self-descriptive.",
                "position": null
            },
            {
                "comment": "super nit: here, the short form is local var, long form is function. Above, the opposite. Maybe consider being uniform?",
                "position": null
            },
            {
                "comment": "Seems like it needs a lock since it's used concurrently (via http.Handle)?",
                "position": null
            },
            {
                "comment": "Ditto lock (see: cachedAudiences)",
                "position": null
            },
            {
                "comment": "Agreed. It was for consistency with the tutorial. But, I just took a look and could remove all references to \"Hello None\". So, I made this more descriptive of what happened.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Added an app type to avoid caching, global variables, and locks all together.",
                "position": null
            },
            {
                "comment": "Ditto.",
                "position": null
            }
        ],
        "commit_message": "getting-started/authenticating-users: add app type, no \"Hello None\", & better errors",
        "commit_id": "97d03b73eef8945fe61f6d1d09c87203742ea49b"
    },
    {
        "pr_title": "getting-started/authenticating-users: regions, tests, style",
        "pr_number": 1006,
        "file_name": "getting-started/authenticating-users/main.go",
        "code_diff": "@@ -44,26 +56,46 @@\nfunc main() {\n \tlog.Fatal(http.ListenAndServe(\":\"+port, nil))\n }\n \n+// newApp creates a new app, returning an error if either the Cloud IAP\n+// certificates or the app's audience field cannot be obtained.\n+func newApp() (*app, error) {\n+\tcerts, err := certificates()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\taud, err := audience()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\ta := &app{\n+\t\tcerts: certs,\n+\t\taud:   aud,\n+\t}\n+\treturn a, nil\n+}\n+\n // [END getting_started_auth_setup]\n \n // [START getting_started_auth_front_controller]\n \n // index responds to requests with our greeting.\n-func index(w http.ResponseWriter, r *http.Request) {\n+func (a *app) index(w http.ResponseWriter, r *http.Request) {\n \tif r.URL.Path != \"/\" {\n \t\thttp.NotFound(w, r)\n \t\treturn\n \t}\n \n \tassertion := r.Header.Get(\"X-Goog-IAP-JWT-Assertion\")\n \tif assertion == \"\" {\n-\t\tfmt.Fprintln(w, \"Hello None\")\n+\t\tfmt.Fprintln(w, \"No Cloud IAP header found.\")\n \t\treturn\n \t}\n-\temail, _, err := validateAssertion(assertion)\n+\temail, _, err := validateAssertion(assertion, a.certs, a.aud)\n \tif err != nil {\n-\t\tlog.Printf(\"Assertion did not validate: %s\", err)\n-\t\tfmt.Fprintln(w, \"Hello None\")\n+\t\tlog.Println(err)\n+\t\tfmt.Fprintln(w, \"Could not validate assertion. Check app logs.\")\n \t\treturn\n \t}",
        "comments": [
            {
                "comment": "\"Hello None\"? o.O Is that meaningful somehow?",
                "position": null
            },
            {
                "comment": "Maybe just log.Println(err)? Seems like the err from a function like validateAssertion should be self-descriptive.",
                "position": null
            },
            {
                "comment": "super nit: here, the short form is local var, long form is function. Above, the opposite. Maybe consider being uniform?",
                "position": null
            },
            {
                "comment": "Seems like it needs a lock since it's used concurrently (via http.Handle)?",
                "position": null
            },
            {
                "comment": "Ditto lock (see: cachedAudiences)",
                "position": null
            },
            {
                "comment": "Agreed. It was for consistency with the tutorial. But, I just took a look and could remove all references to \"Hello None\". So, I made this more descriptive of what happened.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Added an app type to avoid caching, global variables, and locks all together.",
                "position": null
            },
            {
                "comment": "Ditto.",
                "position": null
            }
        ],
        "commit_message": "getting-started/authenticating-users: add app type, no \"Hello None\", & better errors",
        "commit_id": "97d03b73eef8945fe61f6d1d09c87203742ea49b"
    },
    {
        "pr_title": "getting-started/authenticating-users: regions, tests, style",
        "pr_number": 1006,
        "file_name": "getting-started/authenticating-users/main.go",
        "code_diff": "@@ -76,12 +108,7 @@\nfunc index(w http.ResponseWriter, r *http.Request) {\n \n // validateAssertion validates assertion was signed by Google and returns the\n // associated email and userID.\n-func validateAssertion(assertion string) (email string, userID string, err error) {\n-\tcertificates, err := certs()\n-\tif err != nil {\n-\t\treturn \"\", \"\", err\n-\t}\n-\n+func validateAssertion(assertion string, certs map[string]string, aud string) (email string, userID string, err error) {\n \ttoken, err := jwt.Parse(assertion, func(token *jwt.Token) (interface{}, error) {\n \t\tkeyID := token.Header[\"kid\"].(string)",
        "comments": [
            {
                "comment": "\"Hello None\"? o.O Is that meaningful somehow?",
                "position": null
            },
            {
                "comment": "Maybe just log.Println(err)? Seems like the err from a function like validateAssertion should be self-descriptive.",
                "position": null
            },
            {
                "comment": "super nit: here, the short form is local var, long form is function. Above, the opposite. Maybe consider being uniform?",
                "position": null
            },
            {
                "comment": "Seems like it needs a lock since it's used concurrently (via http.Handle)?",
                "position": null
            },
            {
                "comment": "Ditto lock (see: cachedAudiences)",
                "position": null
            },
            {
                "comment": "Agreed. It was for consistency with the tutorial. But, I just took a look and could remove all references to \"Hello None\". So, I made this more descriptive of what happened.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Added an app type to avoid caching, global variables, and locks all together.",
                "position": null
            },
            {
                "comment": "Ditto.",
                "position": null
            }
        ],
        "commit_message": "getting-started/authenticating-users: add app type, no \"Hello None\", & better errors",
        "commit_id": "97d03b73eef8945fe61f6d1d09c87203742ea49b"
    },
    {
        "pr_title": "getting-started/authenticating-users: regions, tests, style",
        "pr_number": 1006,
        "file_name": "getting-started/authenticating-users/main.go",
        "code_diff": "@@ -90,19 +117,14 @@\nfunc validateAssertion(assertion string) (email string, userID string, err error\n \t\t\treturn nil, fmt.Errorf(\"unexpected signing method: %q\", token.Header[\"alg\"])\n \t\t}\n \n-\t\tcert := certificates[keyID]\n+\t\tcert := certs[keyID]\n \t\treturn jwt.ParseECPublicKeyFromPEM([]byte(cert))\n \t})\n \n \tif err != nil {\n \t\treturn \"\", \"\", err\n \t}\n \n-\taud, err := audience()\n-\tif err != nil {\n-\t\treturn \"\", \"\", err\n-\t}\n-\n \tclaims, ok := token.Claims.(jwt.MapClaims)\n \tif !ok {\n \t\treturn \"\", \"\", fmt.Errorf(\"could not extract claims (%T): %+v\", token.Claims, token.Claims)",
        "comments": [
            {
                "comment": "\"Hello None\"? o.O Is that meaningful somehow?",
                "position": null
            },
            {
                "comment": "Maybe just log.Println(err)? Seems like the err from a function like validateAssertion should be self-descriptive.",
                "position": null
            },
            {
                "comment": "super nit: here, the short form is local var, long form is function. Above, the opposite. Maybe consider being uniform?",
                "position": null
            },
            {
                "comment": "Seems like it needs a lock since it's used concurrently (via http.Handle)?",
                "position": null
            },
            {
                "comment": "Ditto lock (see: cachedAudiences)",
                "position": null
            },
            {
                "comment": "Agreed. It was for consistency with the tutorial. But, I just took a look and could remove all references to \"Hello None\". So, I made this more descriptive of what happened.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Added an app type to avoid caching, global variables, and locks all together.",
                "position": null
            },
            {
                "comment": "Ditto.",
                "position": null
            }
        ],
        "commit_message": "getting-started/authenticating-users: add app type, no \"Hello None\", & better errors",
        "commit_id": "97d03b73eef8945fe61f6d1d09c87203742ea49b"
    },
    {
        "pr_title": "getting-started/authenticating-users: regions, tests, style",
        "pr_number": 1006,
        "file_name": "getting-started/authenticating-users/main.go",
        "code_diff": "@@ -118,15 +140,8 @@\nfunc validateAssertion(assertion string) (email string, userID string, err error\n \n // [START getting_started_auth_audience]\n \n-// cachedAudience caches the result of audience.\n-var cachedAudience string\n-\n // audience returns the expected audience value for this service.\n func audience() (string, error) {\n-\tif cachedAudience != \"\" {\n-\t\treturn cachedAudience, nil\n-\t}\n-\n \tprojectNumber, err := metadata.NumericProjectID()\n \tif err != nil {\n \t\treturn \"\", fmt.Errorf(\"metadata.NumericProjectID: %v\", err)",
        "comments": [
            {
                "comment": "\"Hello None\"? o.O Is that meaningful somehow?",
                "position": null
            },
            {
                "comment": "Maybe just log.Println(err)? Seems like the err from a function like validateAssertion should be self-descriptive.",
                "position": null
            },
            {
                "comment": "super nit: here, the short form is local var, long form is function. Above, the opposite. Maybe consider being uniform?",
                "position": null
            },
            {
                "comment": "Seems like it needs a lock since it's used concurrently (via http.Handle)?",
                "position": null
            },
            {
                "comment": "Ditto lock (see: cachedAudiences)",
                "position": null
            },
            {
                "comment": "Agreed. It was for consistency with the tutorial. But, I just took a look and could remove all references to \"Hello None\". So, I made this more descriptive of what happened.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Added an app type to avoid caching, global variables, and locks all together.",
                "position": null
            },
            {
                "comment": "Ditto.",
                "position": null
            }
        ],
        "commit_message": "getting-started/authenticating-users: add app type, no \"Hello None\", & better errors",
        "commit_id": "97d03b73eef8945fe61f6d1d09c87203742ea49b"
    },
    {
        "pr_title": "getting-started/authenticating-users: regions, tests, style",
        "pr_number": 1006,
        "file_name": "getting-started/authenticating-users/main.go",
        "code_diff": "@@ -137,24 +152,15 @@\nfunc audience() (string, error) {\n \t\treturn \"\", fmt.Errorf(\"metadata.ProjectID: %v\", err)\n \t}\n \n-\tcachedAudience = \"/projects/\" + projectNumber + \"/apps/\" + projectID\n-\n-\treturn cachedAudience, nil\n+\treturn \"/projects/\" + projectNumber + \"/apps/\" + projectID, nil\n }\n \n // [END getting_started_auth_audience]\n \n // [START getting_started_auth_certs]\n \n-// cachedCertificates caches the result of certs.\n-var cachedCertificates map[string]string\n-\n-// certs returns IAP's cryptographic public keys.\n-func certs() (map[string]string, error) {\n-\tif len(cachedCertificates) != 0 { // Already got them previously\n-\t\treturn cachedCertificates, nil\n-\t}\n-\n+// certificates returns Cloud IAP's cryptographic public keys.\n+func certificates() (map[string]string, error) {\n \tconst url = \"https://www.gstatic.com/iap/verify/public_key\"\n \tclient := http.Client{\n \t\tTimeout: 5 * time.Second,",
        "comments": [
            {
                "comment": "\"Hello None\"? o.O Is that meaningful somehow?",
                "position": null
            },
            {
                "comment": "Maybe just log.Println(err)? Seems like the err from a function like validateAssertion should be self-descriptive.",
                "position": null
            },
            {
                "comment": "super nit: here, the short form is local var, long form is function. Above, the opposite. Maybe consider being uniform?",
                "position": null
            },
            {
                "comment": "Seems like it needs a lock since it's used concurrently (via http.Handle)?",
                "position": null
            },
            {
                "comment": "Ditto lock (see: cachedAudiences)",
                "position": null
            },
            {
                "comment": "Agreed. It was for consistency with the tutorial. But, I just took a look and could remove all references to \"Hello None\". So, I made this more descriptive of what happened.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Added an app type to avoid caching, global variables, and locks all together.",
                "position": null
            },
            {
                "comment": "Ditto.",
                "position": null
            }
        ],
        "commit_message": "getting-started/authenticating-users: add app type, no \"Hello None\", & better errors",
        "commit_id": "97d03b73eef8945fe61f6d1d09c87203742ea49b"
    },
    {
        "pr_title": "getting-started/authenticating-users: regions, tests, style",
        "pr_number": 1006,
        "file_name": "getting-started/authenticating-users/main_test.go",
        "code_diff": "@@ -29,7 +29,7 @@\nfunc TestIndex(t *testing.T) {\n \t\t{\n \t\t\tpath:           \"/\",\n \t\t\twantStatusCode: http.StatusOK,\n-\t\t\twantBody:       \"Hello None\\n\",\n+\t\t\twantBody:       \"No Cloud IAP header found.\\n\",\n \t\t},\n \t\t{\n \t\t\tpath:           \"/hello\",",
        "comments": [],
        "commit_message": "getting-started/authenticating-users: add app type, no \"Hello None\", & better errors",
        "commit_id": "97d03b73eef8945fe61f6d1d09c87203742ea49b"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "appengine_flexible/websockets/main_test.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage main\n \n import (\n \t\"bytes\"\n-\t\"io/ioutil\"\n \t\"net/http\"\n \t\"net/http/httptest\"\n \t\"strings\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "asset/quickstart/create-feed/main_test.go",
        "code_diff": "@@ -23,9 +23,12 @@\nimport (\n \t\"time\"\n \n \tasset \"cloud.google.com/go/asset/apiv1p2beta1\"\n+\t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \tcloudresourcemanager \"google.golang.org/api/cloudresourcemanager/v1\"\n \tassetpb \"google.golang.org/genproto/googleapis/cloud/asset/v1p2beta1\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n func TestMain(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "asset/quickstart/create-feed/main_test.go",
        "code_diff": "@@ -50,6 +53,8 @@\nfunc TestMain(t *testing.T) {\n \t\tt.Fatalf(\"asset.NewClient: %v\", err)\n \t}\n \n+\tcreateTopic(ctx, t, tc.ProjectID, \"YOUR_TOPIC_NAME\")\n+\n \tm := testutil.BuildMain(t)\n \tdefer m.Cleanup()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "asset/quickstart/delete-feed/main_test.go",
        "code_diff": "@@ -23,8 +23,11 @@\nimport (\n \t\"time\"\n \n \tasset \"cloud.google.com/go/asset/apiv1p2beta1\"\n+\t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \tassetpb \"google.golang.org/genproto/googleapis/cloud/asset/v1p2beta1\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n func TestMain(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "asset/quickstart/delete-feed/main_test.go",
        "code_diff": "@@ -42,6 +45,8 @@\nfunc TestMain(t *testing.T) {\n \tassetNames := []string{\"YOUR_ASSET_NAME\"}\n \ttopic := fmt.Sprintf(\"projects/%s/topics/%s\", tc.ProjectID, \"YOUR_TOPIC_NAME\")\n \n+\tcreateTopic(ctx, t, tc.ProjectID, \"YOUR_TOPIC_NAME\")\n+\n \treq := &assetpb.CreateFeedRequest{\n \t\tParent: feedParent,\n \t\tFeedId: feedID,",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "asset/quickstart/get-feed/main_test.go",
        "code_diff": "@@ -23,9 +23,12 @@\nimport (\n \t\"time\"\n \n \tasset \"cloud.google.com/go/asset/apiv1p2beta1\"\n+\t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \tcloudresourcemanager \"google.golang.org/api/cloudresourcemanager/v1\"\n \tassetpb \"google.golang.org/genproto/googleapis/cloud/asset/v1p2beta1\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n func TestMain(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "asset/quickstart/get-feed/main_test.go",
        "code_diff": "@@ -53,6 +56,8 @@\nfunc TestMain(t *testing.T) {\n \tassetNames := []string{\"YOUR_ASSET_NAME\"}\n \ttopic := fmt.Sprintf(\"projects/%s/topics/%s\", tc.ProjectID, \"YOUR_TOPIC_NAME\")\n \n+\tcreateTopic(ctx, t, tc.ProjectID, \"YOUR_TOPIC_NAME\")\n+\n \treq := &assetpb.CreateFeedRequest{\n \t\tParent: feedParent,\n \t\tFeedId: feedID,",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "asset/quickstart/list-feeds/main_test.go",
        "code_diff": "@@ -23,9 +23,12 @@\nimport (\n \t\"time\"\n \n \tasset \"cloud.google.com/go/asset/apiv1p2beta1\"\n+\t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \tcloudresourcemanager \"google.golang.org/api/cloudresourcemanager/v1\"\n \tassetpb \"google.golang.org/genproto/googleapis/cloud/asset/v1p2beta1\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n func TestMain(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "asset/quickstart/list-feeds/main_test.go",
        "code_diff": "@@ -53,6 +56,8 @@\nfunc TestMain(t *testing.T) {\n \tassetNames := []string{\"YOUR_ASSET_NAME\"}\n \ttopic := fmt.Sprintf(\"projects/%s/topics/%s\", tc.ProjectID, \"YOUR_TOPIC_NAME\")\n \n+\tcreateTopic(ctx, t, tc.ProjectID, \"YOUR_TOPIC_NAME\")\n+\n \treq := &assetpb.CreateFeedRequest{\n \t\tParent: feedParent,\n \t\tFeedId: feedID,",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "asset/quickstart/update-feed/main_test.go",
        "code_diff": "@@ -23,9 +23,12 @@\nimport (\n \t\"time\"\n \n \tasset \"cloud.google.com/go/asset/apiv1p2beta1\"\n+\t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \tcloudresourcemanager \"google.golang.org/api/cloudresourcemanager/v1\"\n \tassetpb \"google.golang.org/genproto/googleapis/cloud/asset/v1p2beta1\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n func TestMain(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "asset/quickstart/update-feed/main_test.go",
        "code_diff": "@@ -53,6 +56,8 @@\nfunc TestMain(t *testing.T) {\n \tassetNames := []string{\"YOUR_ASSET_NAME\"}\n \ttopic := fmt.Sprintf(\"projects/%s/topics/%s\", tc.ProjectID, \"YOUR_TOPIC_NAME\")\n \n+\tcreateTopic(ctx, t, tc.ProjectID, \"TOPIC_TO_UPDATE\")\n+\n \tclient.DeleteFeed(ctx, &assetpb.DeleteFeedRequest{\n \t\tName: fmt.Sprintf(\"projects/%s/feeds/%s\", projectNumber, feedID),\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "bigtable/garbagecollection/garbagecollection_test.go",
        "code_diff": "@@ -17,16 +17,17 @@\npackage garbagecollection\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n \n \t\"cloud.google.com/go/bigtable\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n )\n \n func TestGarbageCollection(t *testing.T) {\n-\tt.Skip(\"Flaky: https://github.com/GoogleCloudPlatform/golang-samples/issues/914\")\n \ttc := testutil.SystemTest(t)\n \n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "bigtable/garbagecollection/garbagecollection_test.go",
        "code_diff": "@@ -36,8 +37,8 @@\nfunc TestGarbageCollection(t *testing.T) {\n \t\tt.Skip(\"Skipping bigtable integration test. Set GOLANG_SAMPLES_BIGTABLE_PROJECT and GOLANG_SAMPLES_BIGTABLE_INSTANCE.\")\n \t}\n \tadminClient, err := bigtable.NewAdminClient(ctx, project, instance)\n-\n-\ttableName := \"gc-table-\" + tc.ProjectID\n+\tuuid, err := uuid.NewRandom()\n+\ttableName := fmt.Sprintf(\"gc-table-%s-%s\", tc.ProjectID, uuid.String()[:8])\n \tadminClient.DeleteTable(ctx, tableName)\n \n \tif err := adminClient.CreateTable(ctx, tableName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/helloworld/hello_http_test.go",
        "code_diff": "@@ -17,7 +17,6 @@\npackage helloworld\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/helloworld/hello_world_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage helloworld\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/http/form_test.go",
        "code_diff": "@@ -17,7 +17,6 @@\npackage http\n import (\n \t\"bytes\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"mime/multipart\"\n \t\"net/http/httptest\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/http/http_content_type_test.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage http\n \n import (\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/http/http_request_method_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage http\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/http/request_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage http\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http\"\n \t\"net/http/httptest\"\n \t\"strings\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/http/stateless_test.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage http\n \n import (\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/http/xml_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage http\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/sql/mysql/mysql_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage sql\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/sql/postgres/postgres_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage sql\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/tips/env_var_test.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage tips\n \n import (\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"os\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/tips/file_system_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage tips\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "functions/tips/scope_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage tips\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "getting-started/sessions/main.go",
        "code_diff": "@@ -12,6 +12,8 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START getting_started_sessions_setup]\n+\n // Command sessions starts an HTTP server that uses session state.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "getting-started/sessions/main.go",
        "code_diff": "@@ -35,8 +37,18 @@\ntype app struct {\n \ttmpl  *template.Template\n }\n \n-// colors are the random background colors that will be assigned to sessions.\n-var colors = []string{\"red\", \"blue\", \"green\", \"yellow\", \"pink\"}\n+// greetings are the random greetings that will be assigned to sessions.\n+var greetings = []string{\n+\t\"Hello World\",\n+\t\"Hallo Welt\",\n+\t\"Ciao Mondo\",\n+\t\"Salut le Monde\",\n+\t\"Hola Mundo\",\n+}\n+\n+// [END getting_started_sessions_setup]\n+\n+// [START getting_started_sessions_main]\n \n func main() {\n \tport := os.Getenv(\"PORT\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "getting-started/sessions/main.go",
        "code_diff": "@@ -71,7 +83,7 @@\nfunc newApp(projectID string) (*app, error) {\n \t\tlog.Fatalf(\"firestoregorilla.New: %v\", err)\n \t}\n \n-\ttmpl, err := template.New(\"Index\").Parse(\"<body bgcolor={{.color}}>Views {{.views}}</body>\")\n+\ttmpl, err := template.New(\"Index\").Parse(`<body>{{.views}} {{if eq .views 1.0}}view{{else}}views{{end}} for \"{{.greeting}}\"</body>`)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"template.New: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "getting-started/sessions/main.go",
        "code_diff": "@@ -82,7 +94,12 @@\nfunc newApp(projectID string) (*app, error) {\n \t}, nil\n }\n \n-// index uses sessions to assign users a random color and keep track of views.\n+// [END getting_started_sessions_main]\n+\n+// [START getting_started_sessions_handler]\n+\n+// index uses sessions to assign users a random greeting and keep track of\n+// views.\n func (a *app) index(w http.ResponseWriter, r *http.Request) {\n \tif r.RequestURI != \"/\" {\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "getting-started/sessions/main.go",
        "code_diff": "@@ -91,7 +108,7 @@\nfunc (a *app) index(w http.ResponseWriter, r *http.Request) {\n \t// name is a non-empty identifier for this app's sessions. Set it to\n \t// something descriptive for your app. It is used as the Firestore\n \t// collection name that stores the sessions.\n-\tname := \"color-views\"\n+\tname := \"hello-views\"\n \tsession, err := a.store.Get(r, name)\n \tif err != nil {\n \t\t// Could not get the session. Log an error and continue, saving a new",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "getting-started/sessions/main_test.go",
        "code_diff": "@@ -37,7 +37,7 @@\nfunc TestIndex(t *testing.T) {\n \n \ta.index(rr, r)\n \n-\tif got, want := rr.Body.String(), \"Views 1\"; !strings.Contains(got, want) {\n+\tif got, want := rr.Body.String(), \"1 view\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"index first visit got:\\n----\\n%v\\n----\\nWant to contain %q\", got, want)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "getting-started/sessions/main_test.go",
        "code_diff": "@@ -49,7 +49,7 @@\nfunc TestIndex(t *testing.T) {\n \n \ta.index(rr, r)\n \n-\tif got, want := rr.Body.String(), \"Views 2\"; !strings.Contains(got, want) {\n+\tif got, want := rr.Body.String(), \"2 views\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"index second visit got:\\n----\\n%v\\n----\\nWant to contain %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "spanner/spanner_leaderboard/leaderboard_test.go",
        "code_diff": "@@ -25,12 +25,10 @@\nimport (\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n-\t\"google.golang.org/grpc/codes\"\n-\t\"google.golang.org/grpc/status\"\n )\n \n func TestSample(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+\ttc := testutil.EndToEndTest(t)\n \n \tinstance := os.Getenv(\"GOLANG_SAMPLES_SPANNER\")\n \tif instance == \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "spanner/spanner_leaderboard/leaderboard_test.go",
        "code_diff": "@@ -46,7 +44,14 @@\nfunc TestSample(t *testing.T) {\n \tdefer adminClient.Close()\n \tdefer dataClient.Close()\n \n-\tassertContains := func(out string, sub string) {\n+\t// Check for database existance prior to test start and delete, as resources may not have\n+\t// been cleaned up from previous invocations.\n+\tif db, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: dbName}); err == nil {\n+\t\tt.Logf(\"database %s exists in state %s. delete result: %v\", db.GetName(), db.GetState().String(),\n+\t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName}))\n+\t}\n+\n+\tassertContains := func(t *testing.T, out string, sub string) {\n \t\tif !strings.Contains(out, sub) {\n \t\t\tt.Errorf(\"got output %q; want it to contain %q\", out, sub)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -23,9 +23,8 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n-\tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n-\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n func TestSample(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -52,7 +51,8 @@\nfunc TestSample(t *testing.T) {\n \t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName}))\n \t}\n \n-\tassertContains := func(out string, sub string) {\n+\tassertContains := func(t *testing.T, out string, sub string) {\n+\t\tt.Helper()\n \t\tif !strings.Contains(out, sub) {\n \t\t\tt.Errorf(\"got output %q; want it to contain %q\", out, sub)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "profiler: add README.md",
        "pr_number": 1003,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -93,46 +93,46 @@\nfunc TestSample(t *testing.T) {\n \trunCommand(t, \"write\", dbName)\n \trunCommand(t, \"update\", dbName)\n \tout := runCommand(t, \"dmlwritetxn\", dbName)\n-\tassertContains(out, \"Moved 200000 from Album2's MarketingBudget to Album1\")\n+\tassertContains(t, out, \"Moved 200000 from Album2's MarketingBudget to Album1\")\n \tout = runCommand(t, \"querynewcolumn\", dbName)\n-\tassertContains(out, \"1 1 300000\")\n-\tassertContains(out, \"2 2 300000\")\n+\tassertContains(t, out, \"1 1 300000\")\n+\tassertContains(t, out, \"2 2 300000\")\n \n \trunCommand(t, \"delete\", dbName)\n \trunCommand(t, \"write\", dbName)\n \trunCommand(t, \"update\", dbName)\n \tout = runCommand(t, \"writetransaction\", dbName)\n-\tassertContains(out, \"Moved 200000 from Album2's MarketingBudget to Album1\")\n+\tassertContains(t, out, \"Moved 200000 from Album2's MarketingBudget to Album1\")\n \tout = runCommand(t, \"querynewcolumn\", dbName)\n-\tassertContains(out, \"1 1 300000\")\n-\tassertContains(out, \"2 2 300000\")\n+\tassertContains(t, out, \"1 1 300000\")\n+\tassertContains(t, out, \"2 2 300000\")\n \n \trunCommand(t, \"delete\", dbName)\n \trunCommand(t, \"write\", dbName)\n \twriteTime := time.Now()\n \n-\tassertContains(runCommand(t, \"read\", dbName), \"1 1 Total Junk\")\n+\tassertContains(t, runCommand(t, \"read\", dbName), \"1 1 Total Junk\")\n \n-\tassertContains(runCommand(t, \"query\", dbName), \"1 1 Total Junk\")\n+\tassertContains(t, runCommand(t, \"query\", dbName), \"1 1 Total Junk\")\n \n \trunCommand(t, \"addindex\", dbName)\n \tout = runCommand(t, \"queryindex\", dbName)\n-\tassertContains(out, \"Go, Go, Go\")\n-\tassertContains(out, \"Forever Hold Your Peace\")\n+\tassertContains(t, out, \"Go, Go, Go\")\n+\tassertContains(t, out, \"Forever Hold Your Peace\")\n \tif strings.Contains(out, \"Green\") {\n \t\tt.Errorf(\"got output %q; should not contain Green\", out)\n \t}\n \n \tout = runCommand(t, \"readindex\", dbName)\n-\tassertContains(out, \"Go, Go, Go\")\n-\tassertContains(out, \"Forever Hold Your Peace\")\n-\tassertContains(out, \"Green\")\n+\tassertContains(t, out, \"Go, Go, Go\")\n+\tassertContains(t, out, \"Forever Hold Your Peace\")\n+\tassertContains(t, out, \"Green\")\n \n \trunCommand(t, \"delete\", dbName)\n \trunCommand(t, \"write\", dbName)\n \trunCommand(t, \"update\", dbName)\n \trunCommand(t, \"addstoringindex\", dbName)\n-\tassertContains(runCommand(t, \"readstoringindex\", dbName), \"500000\")\n+\tassertContains(t, runCommand(t, \"readstoringindex\", dbName), \"500000\")\n \tout = runCommand(t, \"readonlytransaction\", dbName)\n \tif strings.Count(out, \"Total Junk\") != 2 {\n \t\tt.Errorf(\"got output %q; wanted it to contain 2 occurrences of Total Junk\", out)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9593568b8b0b6f1b0be7a82a058f419b0e28a16e"
    },
    {
        "pr_title": "iam: add service account enable/disable snippets",
        "pr_number": 997,
        "file_name": "bigtable/garbagecollection/garbagecollection_test.go",
        "code_diff": "@@ -17,16 +17,17 @@\npackage garbagecollection\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n \n \t\"cloud.google.com/go/bigtable\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n )\n \n func TestGarbageCollection(t *testing.T) {\n-\tt.Skip(\"Flaky: https://github.com/GoogleCloudPlatform/golang-samples/issues/914\")\n \ttc := testutil.SystemTest(t)\n \n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into enable-disable",
        "commit_id": "7b033329a7cf990799def2c11d04955376227aed"
    },
    {
        "pr_title": "iam: add service account enable/disable snippets",
        "pr_number": 997,
        "file_name": "bigtable/garbagecollection/garbagecollection_test.go",
        "code_diff": "@@ -36,8 +37,8 @@\nfunc TestGarbageCollection(t *testing.T) {\n \t\tt.Skip(\"Skipping bigtable integration test. Set GOLANG_SAMPLES_BIGTABLE_PROJECT and GOLANG_SAMPLES_BIGTABLE_INSTANCE.\")\n \t}\n \tadminClient, err := bigtable.NewAdminClient(ctx, project, instance)\n-\n-\ttableName := \"gc-table-\" + tc.ProjectID\n+\tuuid, err := uuid.NewRandom()\n+\ttableName := fmt.Sprintf(\"gc-table-%s-%s\", tc.ProjectID, uuid.String()[:8])\n \tadminClient.DeleteTable(ctx, tableName)\n \n \tif err := adminClient.CreateTable(ctx, tableName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into enable-disable",
        "commit_id": "7b033329a7cf990799def2c11d04955376227aed"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "appengine_flexible/websockets/main_test.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage main\n \n import (\n \t\"bytes\"\n-\t\"io/ioutil\"\n \t\"net/http\"\n \t\"net/http/httptest\"\n \t\"strings\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/helloworld/hello_http_test.go",
        "code_diff": "@@ -17,7 +17,6 @@\npackage helloworld\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/helloworld/hello_world_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage helloworld\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/http/form_test.go",
        "code_diff": "@@ -17,7 +17,6 @@\npackage http\n import (\n \t\"bytes\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"mime/multipart\"\n \t\"net/http/httptest\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/http/http_content_type_test.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage http\n \n import (\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/http/http_request_method_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage http\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/http/request_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage http\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http\"\n \t\"net/http/httptest\"\n \t\"strings\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/http/stateless_test.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage http\n \n import (\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/http/xml_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage http\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/sql/mysql/mysql_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage sql\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/sql/postgres/postgres_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage sql\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/tips/env_var_test.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage tips\n \n import (\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"os\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/tips/file_system_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage tips\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "functions/tips/scope_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage tips\n \n import (\n-\t\"io/ioutil\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into spanner",
        "commit_id": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "testing: include region tags in XML test output",
        "pr_number": 985,
        "file_name": "testing/sampletests/main_test.go",
        "code_diff": "@@ -73,8 +73,8 @@\nfunc TestTestCoverage(t *testing.T) {\n \t\twant := testRange{\n \t\t\tpkgPath:  \"github.com/GoogleCloudPlatform/golang-samples/testing/sampletests/fakesamples\",\n \t\t\ttestName: \"TestHello\",\n-\t\t\tstart:    26, // If hello.go changes, this test will intentionally break.\n-\t\t\tend:      34,\n+\t\t\tstart:    27, // If hello.go changes, this test will intentionally break.\n+\t\t\tend:      35,\n \t\t}\n \t\tif gotRange != want {\n \t\t\tt.Errorf(\"testCoverage found incorrect range: got %+v, want %+v\", gotRange, want)",
        "comments": [],
        "commit_message": "testing/sampletests: handle _test packages",
        "commit_id": "e851fce82b7f0d9ca65a622f33da0c0def471ce3"
    },
    {
        "pr_title": "profiler: remove the docdemo sample, merge it with hotapp",
        "pr_number": 983,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -37,6 +37,8 @@\nvar (\n \tversion = flag.String(\"version\", \"1.0.0\", \"service version\")\n \t// Skew of foo1 function over foo2, in the CPU busyloop, to simulate diff.\n \tskew = flag.Int(\"skew\", 100, \"skew of foo2 over foo1: foo2 will consume skew/100 CPU time compared to foo1 (default is no skew)\")\n+\t// Whether to run some local CPU work to increase the self metric.\n+\tlocalWork = flag.Bool(\"local_work\", false, \"whether to run some local CPU work\")\n \t// There are several goroutines continuously fighting for this mutex.\n \tmu sync.Mutex\n \t// Some allocated memory. Held in a global variable to protect it from GC.",
        "comments": [],
        "commit_message": "Remove the docdemo sample, merge it with hotapp.\n\nAdd a flag to hotapp sample to run some local work to make the flame\ngraph more interesting, thus allowing to use it as a doc sample.\n\nTested with command:\n\ngo run main.go -project_id oval-time-515 -service aalexand-test -version 1.0.0 -local_work",
        "commit_id": "d6798df2bf4c40b6aa735741c53d92cb23031d50"
    },
    {
        "pr_title": "profiler: remove the docdemo sample, merge it with hotapp",
        "pr_number": 983,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -98,6 +100,10 @@\nfunc allocMany() {\n // Simulates a CPU-intensive computation.\n func busyloop() {\n \tfor {\n+\t\tif *localWork {\n+\t\t\tfor i := 0; i < 100*(1<<16); i++ {\n+\t\t\t}\n+\t\t}\n \t\tfoo1(100)\n \t\tfoo2(*skew)\n \t\t// Yield so that some preemption happens.",
        "comments": [],
        "commit_message": "Remove the docdemo sample, merge it with hotapp.\n\nAdd a flag to hotapp sample to run some local work to make the flame\ngraph more interesting, thus allowing to use it as a doc sample.\n\nTested with command:\n\ngo run main.go -project_id oval-time-515 -service aalexand-test -version 1.0.0 -local_work",
        "commit_id": "d6798df2bf4c40b6aa735741c53d92cb23031d50"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/template/list.go",
        "code_diff": "@@ -22,6 +22,7 @@\nimport (\n \t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"github.com/golang/protobuf/ptypes\"\n \t\"google.golang.org/api/iterator\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )",
        "comments": [],
        "commit_message": "dlp: use ptypes",
        "commit_id": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/trigger/list.go",
        "code_diff": "@@ -22,6 +22,7 @@\nimport (\n \t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"github.com/golang/protobuf/ptypes\"\n \t\"google.golang.org/api/iterator\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )",
        "comments": [
            {
                "comment": "maybe move directly above where they're used?",
                "position": null
            },
            {
                "comment": "and maybe want to use ptypes?\r\n\r\nhttps://godoc.org/github.com/golang/protobuf/ptypes#Timestamp",
                "position": null
            },
            {
                "comment": "Done and done. Didn't know about that method - thanks.",
                "position": null
            }
        ],
        "commit_message": "dlp: use ptypes",
        "commit_id": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/quickstart/quickstart.go",
        "code_diff": "@@ -12,7 +12,9 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// dlp_quickstart is a basic example of using the Data Loss Prevention API.\n+// [START dlp_quickstart]\n+\n+// The quickstart program is an example of using the Data Loss Prevention API.\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -20,7 +20,6 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -32,10 +31,10 @@\nimport (\n // optional identifier needed for reidentification. surrogateInfoType can be any\n // value not found in your input.\n // Info types can be found with the infoTypes.list method or on https://cloud.google.com/dlp/docs/infotypes-reference\n-func deidentifyFPE(w io.Writer, projectID, input string, infoTypes []string, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n+func deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 123456789\"\n-\t// infoTypes := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n \t// keyFileName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"\n \t// cryptoKeyName := \"YOUR_ENCRYPTED_AES_256_KEY\"\n \t// surrogateInfoType := \"AGE\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/deid/mask.go",
        "code_diff": "@@ -26,10 +26,10 @@\nimport (\n \n // mask deidentifies the input by masking all provided info types with maskingCharacter\n // and prints the result to w.\n-func mask(w io.Writer, projectID, input string, infoTypes []string, maskingCharacter string, numberToMask int32) error {\n+func mask(w io.Writer, projectID, input string, infoTypeNames []string, maskingCharacter string, numberToMask int32) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 111222333\"\n-\t// infoTypes := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n \t// maskingCharacter := \"+\"\n \t// numberToMask := 6\n \t// Will print \"My SSN is ++++++333\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/deid/reid_fpe.go",
        "code_diff": "@@ -20,7 +20,6 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -16,12 +16,162 @@\npackage inspect\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"strings\"\n \t\"testing\"\n \n+\t\"cloud.google.com/go/bigquery\"\n+\t\"cloud.google.com/go/datastore\"\n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n+const (\n+\ttopicName        = \"dlp-inspect-test-topic\"\n+\tsubscriptionName = \"dlp-inspect-test-sub\"\n+\n+\tssnFileName             = \"fake_ssn.txt\"\n+\tnothingEventfulFileName = \"nothing_eventful.txt\"\n+\tbucketName              = \"golang-samples-dlp-test\"\n+)\n+\n+func TestInspectDatastore(t *testing.T) {\n+\ttc := testutil.EndToEndTest(t)\n+\twriteTestDatastoreFiles(t, tc.ProjectID)\n+\ttests := []struct {\n+\t\tkind string\n+\t\twant string\n+\t}{\n+\t\t{\n+\t\t\tkind: \"SSNTask\",\n+\t\t\twant: \"US_SOCIAL_SECURITY_NUMBER\",\n+\t\t},\n+\t\t{\n+\t\t\tkind: \"BoringTask\",\n+\t\t\twant: \"No results\",\n+\t\t},\n+\t}\n+\tfor _, test := range tests {\n+\t\tt.Run(test.kind, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, tc.ProjectID, \"\", test.kind)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+type SSNTask struct {\n+\tDescription string\n+}\n+\n+type BoringTask struct {\n+\tDescription string\n+}\n+\n+func writeTestDatastoreFiles(t *testing.T, projectID string) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := datastore.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"datastore.NewClient: %v\", err)\n+\t}\n+\tkind := \"SSNTask\"\n+\tname := \"ssntask1\"\n+\tssnKey := datastore.NameKey(kind, name, nil)\n+\ttask := SSNTask{\n+\t\tDescription: \"My SSN is 111222333\",\n+\t}\n+\tif _, err := client.Put(ctx, ssnKey, &task); err != nil {\n+\t\tt.Fatalf(\"Failed to save task: %v\", err)\n+\t}\n+\n+\tkind = \"BoringTask\"\n+\tname = \"boringtask1\"\n+\tboringKey := datastore.NameKey(kind, name, nil)\n+\tboringTask := BoringTask{\n+\t\tDescription: \"Nothing meaningful\",\n+\t}\n+\tif _, err := client.Put(ctx, boringKey, &boringTask); err != nil {\n+\t\tt.Fatalf(\"Failed to save task: %v\", err)\n+\t}\n+}\n+\n+func TestInspectGCS(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\twriteTestGCSFiles(t, tc.ProjectID)\n+\ttests := []struct {\n+\t\tfileName string\n+\t\twant     string\n+\t}{\n+\t\t{\n+\t\t\tfileName: ssnFileName,\n+\t\t\twant:     \"US_SOCIAL_SECURITY_NUMBER\",\n+\t\t},\n+\t\t{\n+\t\t\tfileName: nothingEventfulFileName,\n+\t\t\twant:     \"No results\",\n+\t\t},\n+\t}\n+\tfor _, test := range tests {\n+\t\tt.Run(test.fileName, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, bucketName, test.fileName)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectGCSFile(%s) = %q, want %q substring\", test.fileName, got, test.want)\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+func writeTestGCSFiles(t *testing.T, projectID string) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tbucket := client.Bucket(bucketName)\n+\t_, err = bucket.Attrs(ctx)\n+\tif err != nil {\n+\t\tswitch err {\n+\t\tcase storage.ErrObjectNotExist:\n+\t\t\tif err := bucket.Create(ctx, projectID, nil); err != nil {\n+\t\t\t\tt.Fatalf(\"bucket.Create: %v\", err)\n+\t\t\t}\n+\t\tdefault:\n+\t\t\tt.Fatalf(\"error getting bucket attrs: %v\", err)\n+\t\t}\n+\t}\n+\tif err := writeObject(ctx, bucket, ssnFileName, \"My SSN is 111222333\"); err != nil {\n+\t\tt.Fatalf(\"writeObject: %v\", err)\n+\t}\n+\tif err := writeObject(ctx, bucket, nothingEventfulFileName, \"Nothing eventful\"); err != nil {\n+\t\tt.Fatalf(\"writeObject: %v\", err)\n+\t}\n+}\n+\n+func writeObject(ctx context.Context, bucket *storage.BucketHandle, fileName, content string) error {\n+\tobj := bucket.Object(fileName)\n+\t_, err := obj.Attrs(ctx)\n+\tif err != nil {\n+\t\tswitch err {\n+\t\tcase storage.ErrObjectNotExist:\n+\t\t\tw := obj.NewWriter(ctx)\n+\t\t\tw.Write([]byte(content))\n+\t\t\tif err := w.Close(); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\tdefault:\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\treturn nil\n+}\n+\n func TestInspectString(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -32,7 +182,7 @@\nfunc TestInspectString(t *testing.T) {\n \n \tgot := buf.String()\n \tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"got %q, want %q\", got, want)\n+\t\tt.Errorf(\"inspectString got %q, want %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -19,13 +19,9 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n-\t\"io\"\n-\t\"io/ioutil\"\n-\t\"log\"\n \t\"regexp\"\n \t\"strings\"\n \t\"testing\"\n-\t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/pubsub\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -64,25 +60,18 @@\nfunc setupPubSub(projectID, topic, sub string) (*pubsub.Subscription, error) {\n }\n \n // riskNumerical computes the numerical risk of the given column.\n-func riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datasetID, tableID, columnName string) error {\n-\t// projectID := \"my-project-id\"\n-\t// dataProject := \"bigquery-public-data\"\n-\t// pubSubTopic := \"dlp-risk-sample-topic\"\n-\t// pubSubSub := \"dlp-risk-sample-sub\"\n-\t// datasetID := \"nhtsa_traffic_fatalities\"\n-\t// tableID := \"accident_2015\"\n-\t// columnName := \"state_number\"\n+func riskNumerical(projectID, dataProject, pubSubTopic, pubSubSub, datasetID, tableID, columnName string) error {\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -128,11 +117,10 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}\n-\tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())\n \n \t// Wait for the risk job to finish by waiting for a PubSub message.\n \tctx, cancel := context.WithCancel(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -143,22 +131,6 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t\treturn\n \t\t}\n \t\tmsg.Ack()\n-\t\ttime.Sleep(500 * time.Millisecond)\n-\t\tresp, err := client.GetDlpJob(ctx, &dlppb.GetDlpJobRequest{\n-\t\t\tName: j.GetName(),\n-\t\t})\n-\t\tif err != nil {\n-\t\t\tlog.Fatalf(\"GetDlpJob: %v\", err)\n-\t\t}\n-\t\tn := resp.GetRiskDetails().GetNumericalStatsResult()\n-\t\tfmt.Fprintf(w, \"Value range: [%v, %v]\\n\", n.GetMinValue(), n.GetMaxValue())\n-\t\tvar tmp string\n-\t\tfor p, v := range n.GetQuantileValues() {\n-\t\t\tif v.String() != tmp {\n-\t\t\t\tfmt.Fprintf(w, \"Value at %v quantile: %v\\n\", p, v)\n-\t\t\t\ttmp = v.String()\n-\t\t\t}\n-\t\t}\n \t\t// Stop listening for more messages.\n \t\tcancel()\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -175,7 +147,7 @@\nfunc TestListJobs(t *testing.T) {\n \ts := buf.String()\n \tif len(s) == 0 {\n \t\t// Create job.\n-\t\triskNumerical(ioutil.Discard, tc.ProjectID, \"bigquery-public-data\", \"risk-topic\", \"risk-sub\", \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\triskNumerical(tc.ProjectID, \"bigquery-public-data\", \"risk-topic\", \"risk-sub\", \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\tbuf.Reset()\n \t\terr := listJobs(buf, tc.ProjectID, \"\", \"RISK_ANALYSIS_JOB\")\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/redact/redact.go",
        "code_diff": "@@ -12,34 +12,45 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package redact\n \n+// [START dlp_redact_image]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )\n \n-// [START dlp_redact_image]\n-\n // redactImage blacks out the identified portions of the input image (with type bytesType)\n // and stores the result in outputPath.\n-func redactImage(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, infoTypes []string, bytesType dlppb.ByteContentItem_BytesType, inputPath, outputPath string) {\n+func redactImage(w io.Writer, projectID string, infoTypeNames []string, bytesType dlppb.ByteContentItem_BytesType, inputPath, outputPath string) error {\n+\t// projectID := \"my-project-id\"\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\t// bytesType := dlppb.ByteContentItem_IMAGE_PNG\n+\t// inputPath := /tmp/input\n+\t// outputPath := /tmp/output\n+\n+\tctx := context.Background()\n+\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t}\n+\n \t// Convert the info type strings to a list of InfoTypes.\n-\tvar i []*dlppb.InfoType\n-\tfor _, it := range infoTypes {\n-\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\tvar infoTypes []*dlppb.InfoType\n+\tfor _, it := range infoTypeNames {\n+\t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n \n \t// Convert the info type strings to a list of types to redact in the image.\n-\tvar ir []*dlppb.RedactImageRequest_ImageRedactionConfig\n-\tfor _, it := range infoTypes {\n-\t\tir = append(ir, &dlppb.RedactImageRequest_ImageRedactionConfig{\n+\tvar redactInfoTypes []*dlppb.RedactImageRequest_ImageRedactionConfig\n+\tfor _, it := range infoTypeNames {\n+\t\tredactInfoTypes = append(redactInfoTypes, &dlppb.RedactImageRequest_ImageRedactionConfig{\n \t\t\tTarget: &dlppb.RedactImageRequest_ImageRedactionConfig_InfoType{\n \t\t\t\tInfoType: &dlppb.InfoType{Name: it},\n \t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/redact/redact_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package redact\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/redact/redact_test.go",
        "code_diff": "@@ -24,7 +24,7 @@\nimport (\n )\n \n func TestRedactImage(t *testing.T) {\n-\ttestutil.SystemTest(t)\n+\ttc := testutil.SystemTest(t)\n \ttests := []struct {\n \t\tname      string\n \t\tinputPath string",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -42,11 +41,11 @@\nfunc riskCategorical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub\n \t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -92,7 +91,7 @@\nfunc riskCategorical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/k_anonymity.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"strings\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/k_anonymity.go",
        "code_diff": "@@ -44,11 +43,11 @@\nfunc riskKAnonymity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/k_anonymity.go",
        "code_diff": "@@ -98,7 +97,7 @@\nfunc riskKAnonymity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"strings\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -46,11 +45,11 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -108,7 +107,7 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"strings\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -45,11 +44,11 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -102,7 +101,7 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/numerical.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/numerical.go",
        "code_diff": "@@ -42,11 +41,11 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/risk/numerical.go",
        "code_diff": "@@ -92,7 +91,7 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -12,35 +12,44 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package trigger\n \n+// [START dlp_create_trigger]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\t\"time\"\n-\n-\t\"github.com/golang/protobuf/ptypes/duration\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n-\t\"google.golang.org/api/iterator\"\n+\t\"github.com/golang/protobuf/ptypes/duration\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )\n \n-// [START dlp_create_trigger]\n-\n // createTrigger creates a trigger with the given configuration.\n-func createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, triggerID, displayName, description, bucketName string, autoPopulateTimespan bool, scanPeriodDays int64, infoTypes []string) {\n+func createTrigger(w io.Writer, projectID string, triggerID, displayName, description, bucketName string, infoTypeNames []string) error {\n+\t// projectID := \"my-project-id\"\n+\t// triggerID := \"my-trigger\"\n+\t// displayName := \"My Trigger\"\n+\t// description := \"My trigger description\"\n+\t// bucketName := \"my-bucket\"\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\n+\tctx := context.Background()\n+\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t}\n+\n \t// Convert the info type strings to a list of InfoTypes.\n-\tvar i []*dlppb.InfoType\n-\tfor _, it := range infoTypes {\n-\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\tvar infoTypes []*dlppb.InfoType\n+\tfor _, it := range infoTypeNames {\n+\t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n \n \t// Create a configured request.\n \treq := &dlppb.CreateJobTriggerRequest{\n-\t\tParent:    \"projects/\" + project,\n+\t\tParent:    \"projects/\" + projectID,\n \t\tTriggerId: triggerID,\n \t\tJobTrigger: &dlppb.JobTrigger{\n \t\t\tDisplayName: displayName,",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -53,7 +62,7 @@\nfunc createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihoo\n \t\t\t\t\t\tSchedule: &dlppb.Schedule{\n \t\t\t\t\t\t\tOption: &dlppb.Schedule_RecurrencePeriodDuration{\n \t\t\t\t\t\t\t\tRecurrencePeriodDuration: &duration.Duration{\n-\t\t\t\t\t\t\t\t\tSeconds: scanPeriodDays * 60 * 60 * 24, // Days to seconds.\n+\t\t\t\t\t\t\t\t\tSeconds: 10 * 60 * 60 * 24, // 10 days in seconds.\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/sessions: initial commit",
        "pr_number": 955,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -64,10 +73,10 @@\nfunc createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihoo\n \t\t\tJob: &dlppb.JobTrigger_InspectJob{\n \t\t\t\tInspectJob: &dlppb.InspectJobConfig{\n \t\t\t\t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\t\t\t\tInfoTypes:     i,\n-\t\t\t\t\t\tMinLikelihood: minLikelihood,\n+\t\t\t\t\t\tInfoTypes:     infoTypes,\n+\t\t\t\t\t\tMinLikelihood: dlppb.Likelihood_POSSIBLE,\n \t\t\t\t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n-\t\t\t\t\t\t\tMaxFindingsPerRequest: maxFindings,\n+\t\t\t\t\t\t\tMaxFindingsPerRequest: 10,\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tStorageConfig: &dlppb.StorageConfig{",
        "comments": [],
        "commit_message": "Merge branch 'master' into sessions",
        "commit_id": "ac9609c5ad02fd4eebd4bfeb980c8f58d52c627c"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/quickstart/quickstart.go",
        "code_diff": "@@ -12,7 +12,9 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// dlp_quickstart is a basic example of using the Data Loss Prevention API.\n+// [START dlp_quickstart]\n+\n+// The quickstart program is an example of using the Data Loss Prevention API.\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -20,7 +20,6 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -32,10 +31,10 @@\nimport (\n // optional identifier needed for reidentification. surrogateInfoType can be any\n // value not found in your input.\n // Info types can be found with the infoTypes.list method or on https://cloud.google.com/dlp/docs/infotypes-reference\n-func deidentifyFPE(w io.Writer, projectID, input string, infoTypes []string, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n+func deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 123456789\"\n-\t// infoTypes := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n \t// keyFileName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"\n \t// cryptoKeyName := \"YOUR_ENCRYPTED_AES_256_KEY\"\n \t// surrogateInfoType := \"AGE\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/deid/mask.go",
        "code_diff": "@@ -26,10 +26,10 @@\nimport (\n \n // mask deidentifies the input by masking all provided info types with maskingCharacter\n // and prints the result to w.\n-func mask(w io.Writer, projectID, input string, infoTypes []string, maskingCharacter string, numberToMask int32) error {\n+func mask(w io.Writer, projectID, input string, infoTypeNames []string, maskingCharacter string, numberToMask int32) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 111222333\"\n-\t// infoTypes := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n \t// maskingCharacter := \"+\"\n \t// numberToMask := 6\n \t// Will print \"My SSN is ++++++333\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/deid/reid_fpe.go",
        "code_diff": "@@ -20,7 +20,6 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -16,12 +16,162 @@\npackage inspect\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"strings\"\n \t\"testing\"\n \n+\t\"cloud.google.com/go/bigquery\"\n+\t\"cloud.google.com/go/datastore\"\n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n+const (\n+\ttopicName        = \"dlp-inspect-test-topic\"\n+\tsubscriptionName = \"dlp-inspect-test-sub\"\n+\n+\tssnFileName             = \"fake_ssn.txt\"\n+\tnothingEventfulFileName = \"nothing_eventful.txt\"\n+\tbucketName              = \"golang-samples-dlp-test\"\n+)\n+\n+func TestInspectDatastore(t *testing.T) {\n+\ttc := testutil.EndToEndTest(t)\n+\twriteTestDatastoreFiles(t, tc.ProjectID)\n+\ttests := []struct {\n+\t\tkind string\n+\t\twant string\n+\t}{\n+\t\t{\n+\t\t\tkind: \"SSNTask\",\n+\t\t\twant: \"US_SOCIAL_SECURITY_NUMBER\",\n+\t\t},\n+\t\t{\n+\t\t\tkind: \"BoringTask\",\n+\t\t\twant: \"No results\",\n+\t\t},\n+\t}\n+\tfor _, test := range tests {\n+\t\tt.Run(test.kind, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, tc.ProjectID, \"\", test.kind)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+type SSNTask struct {\n+\tDescription string\n+}\n+\n+type BoringTask struct {\n+\tDescription string\n+}\n+\n+func writeTestDatastoreFiles(t *testing.T, projectID string) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := datastore.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"datastore.NewClient: %v\", err)\n+\t}\n+\tkind := \"SSNTask\"\n+\tname := \"ssntask1\"\n+\tssnKey := datastore.NameKey(kind, name, nil)\n+\ttask := SSNTask{\n+\t\tDescription: \"My SSN is 111222333\",\n+\t}\n+\tif _, err := client.Put(ctx, ssnKey, &task); err != nil {\n+\t\tt.Fatalf(\"Failed to save task: %v\", err)\n+\t}\n+\n+\tkind = \"BoringTask\"\n+\tname = \"boringtask1\"\n+\tboringKey := datastore.NameKey(kind, name, nil)\n+\tboringTask := BoringTask{\n+\t\tDescription: \"Nothing meaningful\",\n+\t}\n+\tif _, err := client.Put(ctx, boringKey, &boringTask); err != nil {\n+\t\tt.Fatalf(\"Failed to save task: %v\", err)\n+\t}\n+}\n+\n+func TestInspectGCS(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\twriteTestGCSFiles(t, tc.ProjectID)\n+\ttests := []struct {\n+\t\tfileName string\n+\t\twant     string\n+\t}{\n+\t\t{\n+\t\t\tfileName: ssnFileName,\n+\t\t\twant:     \"US_SOCIAL_SECURITY_NUMBER\",\n+\t\t},\n+\t\t{\n+\t\t\tfileName: nothingEventfulFileName,\n+\t\t\twant:     \"No results\",\n+\t\t},\n+\t}\n+\tfor _, test := range tests {\n+\t\tt.Run(test.fileName, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, bucketName, test.fileName)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectGCSFile(%s) = %q, want %q substring\", test.fileName, got, test.want)\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+func writeTestGCSFiles(t *testing.T, projectID string) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tbucket := client.Bucket(bucketName)\n+\t_, err = bucket.Attrs(ctx)\n+\tif err != nil {\n+\t\tswitch err {\n+\t\tcase storage.ErrObjectNotExist:\n+\t\t\tif err := bucket.Create(ctx, projectID, nil); err != nil {\n+\t\t\t\tt.Fatalf(\"bucket.Create: %v\", err)\n+\t\t\t}\n+\t\tdefault:\n+\t\t\tt.Fatalf(\"error getting bucket attrs: %v\", err)\n+\t\t}\n+\t}\n+\tif err := writeObject(ctx, bucket, ssnFileName, \"My SSN is 111222333\"); err != nil {\n+\t\tt.Fatalf(\"writeObject: %v\", err)\n+\t}\n+\tif err := writeObject(ctx, bucket, nothingEventfulFileName, \"Nothing eventful\"); err != nil {\n+\t\tt.Fatalf(\"writeObject: %v\", err)\n+\t}\n+}\n+\n+func writeObject(ctx context.Context, bucket *storage.BucketHandle, fileName, content string) error {\n+\tobj := bucket.Object(fileName)\n+\t_, err := obj.Attrs(ctx)\n+\tif err != nil {\n+\t\tswitch err {\n+\t\tcase storage.ErrObjectNotExist:\n+\t\t\tw := obj.NewWriter(ctx)\n+\t\t\tw.Write([]byte(content))\n+\t\t\tif err := w.Close(); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\tdefault:\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\treturn nil\n+}\n+\n func TestInspectString(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -32,7 +182,7 @@\nfunc TestInspectString(t *testing.T) {\n \n \tgot := buf.String()\n \tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"got %q, want %q\", got, want)\n+\t\tt.Errorf(\"inspectString got %q, want %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -19,13 +19,9 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n-\t\"io\"\n-\t\"io/ioutil\"\n-\t\"log\"\n \t\"regexp\"\n \t\"strings\"\n \t\"testing\"\n-\t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/pubsub\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -64,25 +60,18 @@\nfunc setupPubSub(projectID, topic, sub string) (*pubsub.Subscription, error) {\n }\n \n // riskNumerical computes the numerical risk of the given column.\n-func riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datasetID, tableID, columnName string) error {\n-\t// projectID := \"my-project-id\"\n-\t// dataProject := \"bigquery-public-data\"\n-\t// pubSubTopic := \"dlp-risk-sample-topic\"\n-\t// pubSubSub := \"dlp-risk-sample-sub\"\n-\t// datasetID := \"nhtsa_traffic_fatalities\"\n-\t// tableID := \"accident_2015\"\n-\t// columnName := \"state_number\"\n+func riskNumerical(projectID, dataProject, pubSubTopic, pubSubSub, datasetID, tableID, columnName string) error {\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -128,11 +117,10 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}\n-\tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())\n \n \t// Wait for the risk job to finish by waiting for a PubSub message.\n \tctx, cancel := context.WithCancel(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -143,22 +131,6 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t\treturn\n \t\t}\n \t\tmsg.Ack()\n-\t\ttime.Sleep(500 * time.Millisecond)\n-\t\tresp, err := client.GetDlpJob(ctx, &dlppb.GetDlpJobRequest{\n-\t\t\tName: j.GetName(),\n-\t\t})\n-\t\tif err != nil {\n-\t\t\tlog.Fatalf(\"GetDlpJob: %v\", err)\n-\t\t}\n-\t\tn := resp.GetRiskDetails().GetNumericalStatsResult()\n-\t\tfmt.Fprintf(w, \"Value range: [%v, %v]\\n\", n.GetMinValue(), n.GetMaxValue())\n-\t\tvar tmp string\n-\t\tfor p, v := range n.GetQuantileValues() {\n-\t\t\tif v.String() != tmp {\n-\t\t\t\tfmt.Fprintf(w, \"Value at %v quantile: %v\\n\", p, v)\n-\t\t\t\ttmp = v.String()\n-\t\t\t}\n-\t\t}\n \t\t// Stop listening for more messages.\n \t\tcancel()\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -175,7 +147,7 @@\nfunc TestListJobs(t *testing.T) {\n \ts := buf.String()\n \tif len(s) == 0 {\n \t\t// Create job.\n-\t\triskNumerical(ioutil.Discard, tc.ProjectID, \"bigquery-public-data\", \"risk-topic\", \"risk-sub\", \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\triskNumerical(tc.ProjectID, \"bigquery-public-data\", \"risk-topic\", \"risk-sub\", \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\tbuf.Reset()\n \t\terr := listJobs(buf, tc.ProjectID, \"\", \"RISK_ANALYSIS_JOB\")\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/redact/redact.go",
        "code_diff": "@@ -12,34 +12,45 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package redact\n \n+// [START dlp_redact_image]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )\n \n-// [START dlp_redact_image]\n-\n // redactImage blacks out the identified portions of the input image (with type bytesType)\n // and stores the result in outputPath.\n-func redactImage(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, infoTypes []string, bytesType dlppb.ByteContentItem_BytesType, inputPath, outputPath string) {\n+func redactImage(w io.Writer, projectID string, infoTypeNames []string, bytesType dlppb.ByteContentItem_BytesType, inputPath, outputPath string) error {\n+\t// projectID := \"my-project-id\"\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\t// bytesType := dlppb.ByteContentItem_IMAGE_PNG\n+\t// inputPath := /tmp/input\n+\t// outputPath := /tmp/output\n+\n+\tctx := context.Background()\n+\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t}\n+\n \t// Convert the info type strings to a list of InfoTypes.\n-\tvar i []*dlppb.InfoType\n-\tfor _, it := range infoTypes {\n-\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\tvar infoTypes []*dlppb.InfoType\n+\tfor _, it := range infoTypeNames {\n+\t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n \n \t// Convert the info type strings to a list of types to redact in the image.\n-\tvar ir []*dlppb.RedactImageRequest_ImageRedactionConfig\n-\tfor _, it := range infoTypes {\n-\t\tir = append(ir, &dlppb.RedactImageRequest_ImageRedactionConfig{\n+\tvar redactInfoTypes []*dlppb.RedactImageRequest_ImageRedactionConfig\n+\tfor _, it := range infoTypeNames {\n+\t\tredactInfoTypes = append(redactInfoTypes, &dlppb.RedactImageRequest_ImageRedactionConfig{\n \t\t\tTarget: &dlppb.RedactImageRequest_ImageRedactionConfig_InfoType{\n \t\t\t\tInfoType: &dlppb.InfoType{Name: it},\n \t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/redact/redact_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package redact\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/redact/redact_test.go",
        "code_diff": "@@ -24,7 +24,7 @@\nimport (\n )\n \n func TestRedactImage(t *testing.T) {\n-\ttestutil.SystemTest(t)\n+\ttc := testutil.SystemTest(t)\n \ttests := []struct {\n \t\tname      string\n \t\tinputPath string",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -42,11 +41,11 @@\nfunc riskCategorical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub\n \t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -92,7 +91,7 @@\nfunc riskCategorical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/k_anonymity.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"strings\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/k_anonymity.go",
        "code_diff": "@@ -44,11 +43,11 @@\nfunc riskKAnonymity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/k_anonymity.go",
        "code_diff": "@@ -98,7 +97,7 @@\nfunc riskKAnonymity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"strings\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -46,11 +45,11 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -108,7 +107,7 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"strings\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -45,11 +44,11 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -102,7 +101,7 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/numerical.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/numerical.go",
        "code_diff": "@@ -42,11 +41,11 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/risk/numerical.go",
        "code_diff": "@@ -92,7 +91,7 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -12,35 +12,44 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package trigger\n \n+// [START dlp_create_trigger]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\t\"time\"\n-\n-\t\"github.com/golang/protobuf/ptypes/duration\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n-\t\"google.golang.org/api/iterator\"\n+\t\"github.com/golang/protobuf/ptypes/duration\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )\n \n-// [START dlp_create_trigger]\n-\n // createTrigger creates a trigger with the given configuration.\n-func createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, triggerID, displayName, description, bucketName string, autoPopulateTimespan bool, scanPeriodDays int64, infoTypes []string) {\n+func createTrigger(w io.Writer, projectID string, triggerID, displayName, description, bucketName string, infoTypeNames []string) error {\n+\t// projectID := \"my-project-id\"\n+\t// triggerID := \"my-trigger\"\n+\t// displayName := \"My Trigger\"\n+\t// description := \"My trigger description\"\n+\t// bucketName := \"my-bucket\"\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\n+\tctx := context.Background()\n+\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t}\n+\n \t// Convert the info type strings to a list of InfoTypes.\n-\tvar i []*dlppb.InfoType\n-\tfor _, it := range infoTypes {\n-\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\tvar infoTypes []*dlppb.InfoType\n+\tfor _, it := range infoTypeNames {\n+\t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n \n \t// Create a configured request.\n \treq := &dlppb.CreateJobTriggerRequest{\n-\t\tParent:    \"projects/\" + project,\n+\t\tParent:    \"projects/\" + projectID,\n \t\tTriggerId: triggerID,\n \t\tJobTrigger: &dlppb.JobTrigger{\n \t\t\tDisplayName: displayName,",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -53,7 +62,7 @@\nfunc createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihoo\n \t\t\t\t\t\tSchedule: &dlppb.Schedule{\n \t\t\t\t\t\t\tOption: &dlppb.Schedule_RecurrencePeriodDuration{\n \t\t\t\t\t\t\t\tRecurrencePeriodDuration: &duration.Duration{\n-\t\t\t\t\t\t\t\t\tSeconds: scanPeriodDays * 60 * 60 * 24, // Days to seconds.\n+\t\t\t\t\t\t\t\t\tSeconds: 10 * 60 * 60 * 24, // 10 days in seconds.\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -64,10 +73,10 @@\nfunc createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihoo\n \t\t\tJob: &dlppb.JobTrigger_InspectJob{\n \t\t\t\tInspectJob: &dlppb.InspectJobConfig{\n \t\t\t\t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\t\t\t\tInfoTypes:     i,\n-\t\t\t\t\t\tMinLikelihood: minLikelihood,\n+\t\t\t\t\t\tInfoTypes:     infoTypes,\n+\t\t\t\t\t\tMinLikelihood: dlppb.Likelihood_POSSIBLE,\n \t\t\t\t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n-\t\t\t\t\t\t\tMaxFindingsPerRequest: maxFindings,\n+\t\t\t\t\t\t\tMaxFindingsPerRequest: 10,\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tStorageConfig: &dlppb.StorageConfig{",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "functions/imagemagick/imagemagick.go",
        "code_diff": "@@ -14,8 +14,8 @@\n// [START functions_imagemagick_setup]\n \n-// Package imagemagick contains an example of using ImageMagick from a Cloud\n-// Function.\n+// Package imagemagick contains an example of using ImageMagick to process a\n+// file uploaded to Cloud Storage.\n package imagemagick\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "functions/tips/error.go",
        "code_diff": "@@ -12,11 +12,11 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START functions_helloworld_error]\n+\n package tips\n \n import (\n-\t\"context\"\n-\t\"errors\"\n \t\"fmt\"\n \t\"net/http\"\n \t\"os\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "monitoring/irm/irm_test.go",
        "code_diff": "@@ -35,10 +35,10 @@\nfunc TestIncident(t *testing.T) {\n \n \tbuf.Reset()\n \tif err := changeStage(buf, incident.Name); err != nil {\n-\t\tt.Errorf(\"changeStage: %v\", err)\n+\t\tt.Errorf(\"changeStage(%q): %v\", incident.Name, err)\n \t}\n \tif got, want := buf.String(), \"Changed stage\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"changeStage got\\n----\\n%s\\n----\\nWant to contain\\n----\\n%s\\n\", got, want)\n+\t\tt.Errorf(\"changeStage(%q) got\\n----\\n%s\\n----\\nWant to contain\\n----\\n%s\\n\", incident.Name, got, want)\n \t}\n \n \tbuf.Reset()",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -12,9 +12,12 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+// package subscriptions is a tool to manage Google Cloud Pub/Sub subscriptions by using the Pub/Sub API.\n+// See more about Google Cloud Pub/Sub at https://cloud.google.com/pubsub/docs/overview.\n+package subscriptions\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"sync\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -26,79 +29,85 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-var topic *pubsub.Topic\n-var subID string\n+var topicName string\n+var subName string\n \n-var once sync.Once // guards cleanup related operations in setup.\n+// once guards cleanup related operations in setup. No need to set up and tear\n+// down every time, so this speeds things up.\n+var once sync.Once\n \n func setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n+\ttopicName = tc.ProjectID + \"-test-sub-topic\"\n+\tsubName = tc.ProjectID + \"-test-sub\"\n+\tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n \n-\tsubID = tc.ProjectID + \"-test-sub\"\n-\ttopicID := tc.ProjectID + \"-test-sub-topic\"\n-\n-\t// Cleanup resources from the previous failed tests.\n+\t// Cleanup resources from the previous tests.\n \tonce.Do(func() {\n-\t\t// Create a topic.\n-\t\ttopic = client.Topic(topicID)\n+\t\ttopic := client.Topic(topicName)\n \t\tok, err := topic.Exists(ctx)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t\t}\n-\t\tif !ok {\n-\t\t\tif topic, err = client.CreateTopic(ctx, topicID); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to create the topic: %v\", err)\n+\t\tif ok {\n+\t\t\tif err := topic.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicName, err)\n \t\t\t}\n \t\t}\n-\n-\t\t// Delete the sub if already exists.\n-\t\tsub := client.Subscription(subID)\n+\t\tsub := client.Subscription(subName)\n \t\tok, err = sub.Exists(ctx)\n \t\tif err != nil {\n-\t\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n+\t\t\tt.Fatalf(\"failed to check if subscription exists: %v\", err)\n \t\t}\n \t\tif ok {\n-\t\t\tif err := client.Subscription(subID).Delete(ctx); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", subID, err)\n+\t\t\tif err := sub.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the subscription (%q): %v\", subName, err)\n \t\t\t}\n \t\t}\n \t})\n+\n \treturn client\n }\n \n func TestCreate(t *testing.T) {\n-\tc := setup(t)\n-\n-\tif err := create(c, subID, topic); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\ttopic, err := client.CreateTopic(ctx, topicName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"CreateTopic: %v\", err)\n+\t}\n+\tbuf := new(bytes.Buffer)\n+\tif err := create(buf, tc.ProjectID, subName, topic); err != nil {\n \t\tt.Fatalf(\"failed to create a subscription: %v\", err)\n \t}\n-\tok, err := c.Subscription(subID).Exists(context.Background())\n+\tok, err := client.Subscription(subName).Exists(context.Background())\n \tif err != nil {\n \t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n \t}\n \tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", subID)\n+\t\tt.Fatalf(\"got none; want sub = %q\", subName)\n \t}\n }\n \n func TestList(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tsubs, err := list(c)\n+\t\tsubs, err := list(tc.ProjectID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"failed to list subscriptions: %v\", err)\n \t\t\treturn\n \t\t}\n \n \t\tfor _, sub := range subs {\n-\t\t\tif sub.ID() == subID {\n+\t\t\tif sub.ID() == subName {\n \t\t\t\treturn // PASS\n \t\t\t}\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -107,15 +116,16 @@\nfunc TestList(t *testing.T) {\n \t\tfor i, sub := range subs {\n \t\t\tsubNames[i] = sub.ID()\n \t\t}\n-\t\tr.Errorf(\"got %+v; want a list with subscription %q\", subNames, subID)\n+\t\tr.Errorf(\"got %+v; want a list with subscription %q\", subNames, subName)\n \t})\n }\n \n func TestIAM(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tperms, err := testPermissions(c, subID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tperms, err := testPermissions(buf, tc.ProjectID, subName)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"testPermissions: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -125,15 +135,16 @@\nfunc TestIAM(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := addUsers(c, subID); err != nil {\n+\t\tif err := addUsers(tc.ProjectID, subName); err != nil {\n \t\t\tr.Errorf(\"addUsers: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tpolicy, err := getPolicy(c, subID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tpolicy, err := policy(buf, tc.ProjectID, subName)\n \t\tif err != nil {\n-\t\t\tr.Errorf(\"getPolicy: %v\", err)\n+\t\t\tr.Errorf(\"policy: %v\", err)\n \t\t}\n \t\tif role, member := iam.Editor, \"group:cloud-logs@google.com\"; !policy.HasRole(member, role) {\n \t\t\tr.Errorf(\"want %q as viewer, policy=%v\", member, policy)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -12,9 +12,12 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+// Package topics is a tool to manage Google Cloud Pub/Sub topics by using the Pub/Sub API.\n+// See more about Google Cloud Pub/Sub at https://cloud.google.com/pubsub/docs/overview.package topics\n+package topics\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"sync\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -25,63 +28,67 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-var topicID string\n+var topicName string\n \n-var once sync.Once // guards cleanup related operations in setup.\n+// once guards cleanup related operations in setup. No need to set up and tear\n+// down every time, so this speeds things up.\n+var once sync.Once\n \n func setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n-\ttopicID = tc.ProjectID + \"-test-topic\"\n-\n+\ttopicName = tc.ProjectID + \"-test-topic\"\n+\tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n \n-\t// Cleanup resources from the previous failed tests.\n+\t// Cleanup resources from the previous tests.\n \tonce.Do(func() {\n-\t\ttopic := client.Topic(topicID)\n+\t\ttopic := client.Topic(topicName)\n \t\tok, err := topic.Exists(ctx)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t\t}\n-\t\tif !ok {\n-\t\t\treturn\n-\t\t}\n-\t\tif err := topic.Delete(ctx); err != nil {\n-\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicID, err)\n+\t\tif ok {\n+\t\t\tif err := topic.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicName, err)\n+\t\t\t}\n \t\t}\n \t})\n+\n \treturn client\n }\n \n func TestCreate(t *testing.T) {\n-\tc := setup(t)\n-\tif err := create(c, topicID); err != nil {\n+\tclient := setup(t)\n+\ttc := testutil.SystemTest(t)\n+\tbuf := new(bytes.Buffer)\n+\tif err := create(buf, tc.ProjectID, topicName); err != nil {\n \t\tt.Fatalf(\"failed to create a topic: %v\", err)\n \t}\n-\tok, err := c.Topic(topicID).Exists(context.Background())\n+\tok, err := client.Topic(topicName).Exists(context.Background())\n \tif err != nil {\n-\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n+\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t}\n \tif !ok {\n-\t\tt.Fatalf(\"got none; want topic = %q\", topicID)\n+\t\tt.Fatalf(\"got none; want topic = %q\", topicName)\n \t}\n }\n \n func TestList(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\ttopics, err := list(c)\n+\t\ttopics, err := list(tc.ProjectID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"failed to list topics: %v\", err)\n \t\t}\n \n \t\tfor _, t := range topics {\n-\t\t\tif t.ID() == topicID {\n+\t\t\tif t.ID() == topicName {\n \t\t\t\treturn // PASS\n \t\t\t}\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -90,38 +97,56 @@\nfunc TestList(t *testing.T) {\n \t\tfor i, t := range topics {\n \t\t\ttopicNames[i] = t.ID()\n \t\t}\n-\t\tr.Errorf(\"got %+v; want a list with topic = %q\", topicNames, topicID)\n+\t\tr.Errorf(\"got %+v; want a list with topic = %q\", topicNames, topicName)\n \t})\n }\n \n func TestPublish(t *testing.T) {\n \t// Nothing much to do here, unless we are consuming.\n \t// TODO(jbd): Merge topics and subscriptions programs maybe?\n-\tc := setup(t)\n-\tif err := publish(c, topicID, \"hello world\"); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publish(buf, tc.ProjectID, topicName, \"hello world\"); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestPublishThatScales(t *testing.T) {\n-\tc := setup(t)\n-\tif err := publishThatScales(c, topicID, 10); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tsetup(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publishThatScales(buf, tc.ProjectID, topicName, 10); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestPublishCustomAttributes(t *testing.T) {\n-\tc := setup(t)\n-\tif err := publishCustomAttributes(c, topicID); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tsetup(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publishCustomAttributes(buf, tc.ProjectID, topicName); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestIAM(t *testing.T) {\n-\tc := setup(t)\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tperms, err := testPermissions(c, topicID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tperms, err := testPermissions(buf, tc.ProjectID, topicName)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"testPermissions: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -131,15 +156,16 @@\nfunc TestIAM(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := addUsers(c, topicID); err != nil {\n+\t\tif err := addUsers(tc.ProjectID, topicName); err != nil {\n \t\t\tr.Errorf(\"addUsers: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tpolicy, err := getPolicy(c, topicID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tpolicy, err := policy(buf, tc.ProjectID, topicName)\n \t\tif err != nil {\n-\t\t\tr.Errorf(\"getPolicy: %v\", err)\n+\t\t\tr.Errorf(\"policy: %v\", err)\n \t\t}\n \t\tif role, member := iam.Editor, \"group:cloud-logs@google.com\"; !policy.HasRole(member, role) {\n \t\t\tr.Errorf(\"want %q as viewer, policy=%v\", member, policy)",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "run/pubsub/main.go",
        "code_diff": "@@ -20,6 +20,7 @@\npackage main\n import (\n \t\"encoding/json\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -26,6 +26,7 @@\nimport (\n \t\"strconv\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/civil\"\n \t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \t\"google.golang.org/api/iterator\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -38,46 +39,55 @@\ntype adminCommand func(ctx context.Context, w io.Writer, adminClient *database.D\n \n var (\n \tcommands = map[string]command{\n-\t\t\"write\":                      write,\n-\t\t\"delete\":                     delete,\n-\t\t\"query\":                      query,\n-\t\t\"read\":                       read,\n-\t\t\"update\":                     update,\n-\t\t\"writetransaction\":           writeWithTransaction,\n-\t\t\"querynewcolumn\":             queryNewColumn,\n-\t\t\"queryindex\":                 queryUsingIndex,\n-\t\t\"readindex\":                  readUsingIndex,\n-\t\t\"readstoringindex\":           readStoringIndex,\n-\t\t\"readonlytransaction\":        readOnlyTransaction,\n-\t\t\"readstaledata\":              readStaleData,\n-\t\t\"readbatchdata\":              readBatchData,\n-\t\t\"updatewithtimestamp\":        updateWithTimestamp,\n-\t\t\"querywithtimestamp\":         queryWithTimestamp,\n-\t\t\"writewithtimestamp\":         writeWithTimestamp,\n-\t\t\"querynewtable\":              queryNewTable,\n-\t\t\"writetodocstable\":           writeToDocumentsTable,\n-\t\t\"updatedocstable\":            updateDocumentsTable,\n-\t\t\"querydocstable\":             queryDocumentsTable,\n-\t\t\"writewithhistory\":           writeWithHistory,\n-\t\t\"updatewithhistory\":          updateWithHistory,\n-\t\t\"querywithhistory\":           queryWithHistory,\n-\t\t\"writestructdata\":            writeStructData,\n-\t\t\"querywithstruct\":            queryWithStruct,\n-\t\t\"querywitharrayofstruct\":     queryWithArrayOfStruct,\n-\t\t\"querywithstructfield\":       queryWithStructField,\n-\t\t\"querywithnestedstructfield\": queryWithNestedStructField,\n-\t\t\"dmlinsert\":                  insertUsingDML,\n-\t\t\"dmlupdate\":                  updateUsingDML,\n-\t\t\"dmldelete\":                  deleteUsingDML,\n-\t\t\"dmlwithtimestamp\":           updateUsingDMLWithTimestamp,\n-\t\t\"dmlwriteread\":               writeAndReadUsingDML,\n-\t\t\"dmlupdatestruct\":            updateUsingDMLStruct,\n-\t\t\"dmlwrite\":                   writeUsingDML,\n-\t\t\"querywithparameter\":         queryWithParameter,\n-\t\t\"dmlwritetxn\":                writeWithTransactionUsingDML,\n-\t\t\"dmlupdatepart\":              updateUsingPartitionedDML,\n-\t\t\"dmldeletepart\":              deleteUsingPartitionedDML,\n-\t\t\"dmlbatchupdate\":             updateUsingBatchDML,\n+\t\t\"write\":                       write,\n+\t\t\"delete\":                      delete,\n+\t\t\"query\":                       query,\n+\t\t\"read\":                        read,\n+\t\t\"update\":                      update,\n+\t\t\"writetransaction\":            writeWithTransaction,\n+\t\t\"querynewcolumn\":              queryNewColumn,\n+\t\t\"queryindex\":                  queryUsingIndex,\n+\t\t\"readindex\":                   readUsingIndex,\n+\t\t\"readstoringindex\":            readStoringIndex,\n+\t\t\"readonlytransaction\":         readOnlyTransaction,\n+\t\t\"readstaledata\":               readStaleData,\n+\t\t\"readbatchdata\":               readBatchData,\n+\t\t\"updatewithtimestamp\":         updateWithTimestamp,\n+\t\t\"querywithtimestamp\":          queryWithTimestamp,\n+\t\t\"writewithtimestamp\":          writeWithTimestamp,\n+\t\t\"querynewtable\":               queryNewTable,\n+\t\t\"writetodocstable\":            writeToDocumentsTable,\n+\t\t\"updatedocstable\":             updateDocumentsTable,\n+\t\t\"querydocstable\":              queryDocumentsTable,\n+\t\t\"writewithhistory\":            writeWithHistory,\n+\t\t\"updatewithhistory\":           updateWithHistory,\n+\t\t\"querywithhistory\":            queryWithHistory,\n+\t\t\"writestructdata\":             writeStructData,\n+\t\t\"querywithstruct\":             queryWithStruct,\n+\t\t\"querywitharrayofstruct\":      queryWithArrayOfStruct,\n+\t\t\"querywithstructfield\":        queryWithStructField,\n+\t\t\"querywithnestedstructfield\":  queryWithNestedStructField,\n+\t\t\"dmlinsert\":                   insertUsingDML,\n+\t\t\"dmlupdate\":                   updateUsingDML,\n+\t\t\"dmldelete\":                   deleteUsingDML,\n+\t\t\"dmlwithtimestamp\":            updateUsingDMLWithTimestamp,\n+\t\t\"dmlwriteread\":                writeAndReadUsingDML,\n+\t\t\"dmlupdatestruct\":             updateUsingDMLStruct,\n+\t\t\"dmlwrite\":                    writeUsingDML,\n+\t\t\"querywithparameter\":          queryWithParameter,\n+\t\t\"dmlwritetxn\":                 writeWithTransactionUsingDML,\n+\t\t\"dmlupdatepart\":               updateUsingPartitionedDML,\n+\t\t\"dmldeletepart\":               deleteUsingPartitionedDML,\n+\t\t\"dmlbatchupdate\":              updateUsingBatchDML,\n+\t\t\"writedatatypesdata\":          writeDatatypesData,\n+\t\t\"querywitharray\":              queryWithArray,\n+\t\t\"querywithbool\":               queryWithBool,\n+\t\t\"querywithbytes\":              queryWithBytes,\n+\t\t\"querywithdate\":               queryWithDate,\n+\t\t\"querywithfloat\":              queryWithFloat,\n+\t\t\"querywithint\":                queryWithInt,\n+\t\t\"querywithstring\":             queryWithString,\n+\t\t\"querywithtimestampparameter\": queryWithTimestampParameter,\n \t}\n \n \tadminCommands = map[string]adminCommand{",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -87,6 +97,7 @@\nvar (\n \t\t\"addstoringindex\":                 addStoringIndex,\n \t\t\"addcommittimestamp\":              addCommitTimestamp,\n \t\t\"createtablewithtimestamp\":        createTableWithTimestamp,\n+\t\t\"createtablewithdatatypes\":        createTableWithDatatypes,\n \t\t\"createtabledocswithtimestamp\":    createTableDocumentsWithTimestamp,\n \t\t\"createtabledocswithhistorytable\": createTableDocumentsWithHistoryTable,\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1266,10 +1277,332 @@\nfunc updateUsingBatchDML(ctx context.Context, w io.Writer, client *spanner.Clien\n \n // [END spanner_dml_batch_update]\n \n+// [START spanner_create_table_with_datatypes]\n+\n+// Creates a Cloud Spanner table comprised of columns for each supported data type\n+// See https://cloud.google.com/spanner/docs/data-types\n+func createTableWithDatatypes(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t`CREATE TABLE Venues (\n+\t\t\t\tVenueId\tINT64 NOT NULL,\n+\t\t\t\tVenueName STRING(100),\n+\t\t\t\tVenueInfo BYTES(MAX),\n+\t\t\t\tCapacity INT64,\n+\t\t\t\tAvailableDates ARRAY<DATE>,\n+\t\t\t\tLastContactDate DATE,\n+\t\t\t\tOutdoorVenue BOOL,\n+\t\t\t\tPopularityScore FLOAT64,\n+\t\t\t\tLastUpdateTime TIMESTAMP NOT NULL OPTIONS (allow_commit_timestamp=true)\n+\t\t\t) PRIMARY KEY (VenueId)`,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"UpdateDatabaseDdl: %v\", err)\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Created Venues table in database [%s]\\n\", database)\n+\treturn nil\n+}\n+\n+// [END spanner_create_table_with_datatypes]\n+\n+// [START spanner_insert_datatypes_data]\n+\n+func writeDatatypesData(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvenueColumns := []string{\"VenueId\", \"VenueName\", \"VenueInfo\", \"Capacity\", \"AvailableDates\",\n+\t\t\"LastContactDate\", \"OutdoorVenue\", \"PopularityScore\", \"LastUpdateTime\"}\n+\tm := []*spanner.Mutation{\n+\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n+\t\t\t[]interface{}{4, \"Venue 4\", []byte(\"Hello World 1\"), 1800,\n+\t\t\t\t[]string{\"2020-12-01\", \"2020-12-02\", \"2020-12-03\"},\n+\t\t\t\t\"2018-09-02\", false, 0.85543, spanner.CommitTimestamp}),\n+\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n+\t\t\t[]interface{}{19, \"Venue 19\", []byte(\"Hello World 2\"), 6300,\n+\t\t\t\t[]string{\"2020-11-01\", \"2020-11-05\", \"2020-11-15\"},\n+\t\t\t\t\"2019-01-15\", true, 0.98716, spanner.CommitTimestamp}),\n+\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n+\t\t\t[]interface{}{42, \"Venue 42\", []byte(\"Hello World 3\"), 3000,\n+\t\t\t\t[]string{\"2020-10-01\", \"2020-10-07\"}, \"2018-10-01\",\n+\t\t\t\tfalse, 0.72598, spanner.CommitTimestamp}),\n+\t}\n+\t_, err := client.Apply(ctx, m)\n+\treturn err\n+}\n+\n+// [END spanner_insert_datatypes_data]\n+\n+// [START spanner_query_with_array_parameter]\n+\n+func queryWithArray(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar date1 = civil.Date{Year: 2020, Month: time.October, Day: 1}\n+\tvar date2 = civil.Date{Year: 2020, Month: time.November, Day: 1}\n+\tvar exampleArray = []civil.Date{date1, date2}\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, AvailableDate FROM Venues v,\n+            \tUNNEST(v.AvailableDates) as AvailableDate \n+            \tWHERE AvailableDate IN UNNEST(@availableDates)`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"availableDates\": exampleArray,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar availableDate civil.Date\n+\t\tif err := row.Columns(&venueID, &venueName, &availableDate); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, availableDate)\n+\t}\n+}\n+\n+// [END spanner_query_with_array_parameter]\n+\n+// [START spanner_query_with_bool_parameter]\n+\n+func queryWithBool(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleBool = true\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, OutdoorVenue FROM Venues\n+            \tWHERE OutdoorVenue = @outdoorVenue`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"outdoorVenue\": exampleBool,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar outdoorVenue bool\n+\t\tif err := row.Columns(&venueID, &venueName, &outdoorVenue); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %t\\n\", venueID, venueName, outdoorVenue)\n+\t}\n+}\n+\n+// [END spanner_query_with_bool_parameter]\n+\n+// [START spanner_query_with_bytes_parameter]\n+\n+func queryWithBytes(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleBytes = []byte(\"Hello World 1\")\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName FROM Venues\n+            \tWHERE VenueInfo = @venueInfo`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"venueInfo\": exampleBytes,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tif err := row.Columns(&venueID, &venueName); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s\\n\", venueID, venueName)\n+\t}\n+}\n+\n+// [END spanner_query_with_bytes_parameter]\n+\n+// [START spanner_query_with_date_parameter]\n+\n+func queryWithDate(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleDate = civil.Date{Year: 2019, Month: time.January, Day: 1}\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, LastContactDate FROM Venues\n+            \tWHERE LastContactDate < @lastContactDate`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"lastContactDate\": exampleDate,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar lastContactDate civil.Date\n+\t\tif err := row.Columns(&venueID, &venueName, &lastContactDate); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %v\\n\", venueID, venueName, lastContactDate)\n+\t}\n+}\n+\n+// [END spanner_query_with_date_parameter]\n+\n+// [START spanner_query_with_float_parameter]\n+\n+func queryWithFloat(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleFloat = 0.8\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, PopularityScore FROM Venues\n+            \tWHERE PopularityScore > @popularityScore`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"popularityScore\": exampleFloat,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar popularityScore float64\n+\t\tif err := row.Columns(&venueID, &venueName, &popularityScore); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %f\\n\", venueID, venueName, popularityScore)\n+\t}\n+}\n+\n+// [END spanner_query_with_float_parameter]\n+\n+// [START spanner_query_with_int_parameter]\n+\n+func queryWithInt(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleInt = 3000\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, Capacity FROM Venues\n+            \tWHERE Capacity >= @capacity`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"capacity\": exampleInt,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID, capacity int64\n+\t\tvar venueName string\n+\t\tif err := row.Columns(&venueID, &venueName, &capacity); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %d\\n\", venueID, venueName, capacity)\n+\t}\n+}\n+\n+// [END spanner_query_with_int_parameter]\n+\n+// [START spanner_query_with_string_parameter]\n+\n+func queryWithString(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleString = \"Venue 42\"\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName FROM Venues\n+            \tWHERE VenueName = @venueName`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"venueName\": exampleString,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tif err := row.Columns(&venueID, &venueName); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s\\n\", venueID, venueName)\n+\t}\n+}\n+\n+// [END spanner_query_with_string_parameter]\n+\n+// [START spanner_query_with_timestamp_parameter]\n+\n+func queryWithTimestampParameter(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleTimestamp = time.Now()\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, LastUpdateTime FROM Venues\n+            \tWHERE LastUpdateTime < @lastUpdateTime`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"lastUpdateTime\": exampleTimestamp,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar lastUpdateTime time.Time\n+\t\tif err := row.Columns(&venueID, &venueName, &lastUpdateTime); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, lastUpdateTime)\n+\t}\n+}\n+\n+// [END spanner_query_with_timestamp_parameter]\n+\n func queryNewTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n \tstmt := spanner.Statement{\n \t\tSQL: `SELECT SingerId, VenueId, EventDate, Revenue, LastUpdateTime FROM Performances\n-\t\t\tORDER BY LastUpdateTime DESC`}\n+\t\t\t\tORDER BY LastUpdateTime DESC`}\n \titer := client.Single().Query(ctx, stmt)\n \tdefer iter.Stop()\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into bookshelf",
        "commit_id": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "pubsub: canonize Go samples",
        "pr_number": 937,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -32,13 +32,15 @@\nimport (\n var topicName string\n var subName string\n \n-var once sync.Once // guards cleanup related operations in setup.\n+// once guards cleanup related operations in setup. No need to set up and tear\n+// down every time, so this speeds things up.\n+var once sync.Once\n \n func setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n-\ttopicName = tc.ProjectID + \"-test-topic\"\n+\ttopicName = tc.ProjectID + \"-test-sub-topic\"\n \tsubName = tc.ProjectID + \"-test-sub\"\n \tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)",
        "comments": [
            {
                "comment": "I think this and `setup` can be deleted?",
                "position": null
            },
            {
                "comment": "Need to\r\n1. Initialize a client.\r\n1. Create a subscription if it doesn't already exist (can't depend on it already existing).\r\n1. Call `delete`.\r\n1. Check if the subscription still exists.",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            },
            {
                "comment": "Modified to match topics_test",
                "position": null
            }
        ],
        "commit_message": "pubsub: different sub topic name and use sync.Once",
        "commit_id": "37f1e34688d082d511cdc1b8e876aa68f6ba2b3c"
    },
    {
        "pr_title": "pubsub: canonize Go samples",
        "pr_number": 937,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -29,7 +29,10 @@\nimport (\n )\n \n var topicName string\n-var once sync.Once // guards cleanup related operations in setup.\n+\n+// once guards cleanup related operations in setup. No need to set up and tear\n+// down every time, so this speeds things up.\n+var once sync.Once\n \n func setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()",
        "comments": [
            {
                "comment": "Delete this and `setup`?",
                "position": null
            },
            {
                "comment": "Create a topic if it doesn't already exist before calling `delete`? Same as for subscriptions.",
                "position": null
            },
            {
                "comment": "Rewrote setup for similar functionality to topics_test setup (deleting old topic, creating client)",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "pubsub: different sub topic name and use sync.Once",
        "commit_id": "37f1e34688d082d511cdc1b8e876aa68f6ba2b3c"
    },
    {
        "pr_title": "translate: canonize snippets",
        "pr_number": 934,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -165,8 +165,10 @@\nfunc printDatum(d interface{}) {\n \t// Go's map implementation returns keys in a random ordering, so we sort\n \t// the keys before accessing.\n \tkeys := make([]string, len(m))\n+\ti := 0\n \tfor k := range m {\n-\t\tkeys = append(keys, k)\n+\t\tkeys[i] = k\n+\t\ti++\n \t}\n \tsort.Strings(keys)\n \tfor _, key := range keys {",
        "comments": [],
        "commit_message": "Merge branch 'master' into canon-go-translate",
        "commit_id": "8cbfac164727ead5107963f2a868ef1c9047a488"
    },
    {
        "pr_title": "translate: canonize snippets",
        "pr_number": 934,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -197,9 +199,13 @@\nfunc valueFromTypeMap(field interface{}) interface{} {\n // successfully transmitted.\n func processStream(ctx context.Context, client *bqStorage.BigQueryStorageClient, st *bqStoragepb.Stream, ch chan<- *bqStoragepb.AvroRows) error {\n \tvar offset int64\n-\tstreamRetry := 3\n+\n+\t// Streams may be long-running.  Rather than using a global retry for the\n+\t// stream, implement a retry that resets once progress is made.\n+\tretryLimit := 3\n \n \tfor {\n+\t\tretries := 0\n \t\t// Send the initiating request to start streaming row blocks.\n \t\trowStream, err := client.ReadRows(ctx, &bqStoragepb.ReadRowsRequest{\n \t\t\tReadPosition: &bqStoragepb.StreamPosition{",
        "comments": [],
        "commit_message": "Merge branch 'master' into canon-go-translate",
        "commit_id": "8cbfac164727ead5107963f2a868ef1c9047a488"
    },
    {
        "pr_title": "translate: canonize snippets",
        "pr_number": 934,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -217,8 +223,8 @@\nfunc processStream(ctx context.Context, client *bqStorage.BigQueryStorageClient,\n \t\t\t\treturn nil\n \t\t\t}\n \t\t\tif err != nil {\n-\t\t\t\tstreamRetry--\n-\t\t\t\tif streamRetry <= 0 {\n+\t\t\t\tretries++\n+\t\t\t\tif retries >= retryLimit {\n \t\t\t\t\treturn fmt.Errorf(\"processStream retries exhausted: %v\", err)\n \t\t\t\t}\n \t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into canon-go-translate",
        "commit_id": "8cbfac164727ead5107963f2a868ef1c9047a488"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -35,7 +35,7 @@\nimport (\n \n \tbqStorage \"cloud.google.com/go/bigquery/storage/apiv1beta1\"\n \t\"github.com/golang/protobuf/ptypes\"\n-\tgax \"github.com/googleapis/gax-go\"\n+\tgax \"github.com/googleapis/gax-go/v2\"\n \t\"github.com/linkedin/goavro\"\n \tbqStoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1beta1\"\n \t\"google.golang.org/grpc\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -165,8 +165,10 @@\nfunc printDatum(d interface{}) {\n \t// Go's map implementation returns keys in a random ordering, so we sort\n \t// the keys before accessing.\n \tkeys := make([]string, len(m))\n+\ti := 0\n \tfor k := range m {\n-\t\tkeys = append(keys, k)\n+\t\tkeys[i] = k\n+\t\ti++\n \t}\n \tsort.Strings(keys)\n \tfor _, key := range keys {",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -197,9 +199,13 @@\nfunc valueFromTypeMap(field interface{}) interface{} {\n // successfully transmitted.\n func processStream(ctx context.Context, client *bqStorage.BigQueryStorageClient, st *bqStoragepb.Stream, ch chan<- *bqStoragepb.AvroRows) error {\n \tvar offset int64\n-\tstreamRetry := 3\n+\n+\t// Streams may be long-running.  Rather than using a global retry for the\n+\t// stream, implement a retry that resets once progress is made.\n+\tretryLimit := 3\n \n \tfor {\n+\t\tretries := 0\n \t\t// Send the initiating request to start streaming row blocks.\n \t\trowStream, err := client.ReadRows(ctx, &bqStoragepb.ReadRowsRequest{\n \t\t\tReadPosition: &bqStoragepb.StreamPosition{",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -217,8 +223,8 @@\nfunc processStream(ctx context.Context, client *bqStorage.BigQueryStorageClient,\n \t\t\t\treturn nil\n \t\t\t}\n \t\t\tif err != nil {\n-\t\t\t\tstreamRetry--\n-\t\t\t\tif streamRetry <= 0 {\n+\t\t\t\tretries++\n+\t\t\t\tif retries >= retryLimit {\n \t\t\t\t\treturn fmt.Errorf(\"processStream retries exhausted: %v\", err)\n \t\t\t\t}\n \t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/quickstart/quickstart.go",
        "code_diff": "@@ -12,7 +12,9 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// dlp_quickstart is a basic example of using the Data Loss Prevention API.\n+// [START dlp_quickstart]\n+\n+// The quickstart program is an example of using the Data Loss Prevention API.\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -12,7 +12,8 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+// Package deid contains example snippets using the DLP deidentification API.\n+package deid\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -22,7 +23,7 @@\nimport (\n )\n \n func TestMask(t *testing.T) {\n-\ttestutil.SystemTest(t)\n+\ttc := testutil.SystemTest(t)\n \ttests := []struct {\n \t\tinput            string\n \t\tmaskingCharacter string",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -49,7 +50,10 @@\nfunc TestMask(t *testing.T) {\n \t\tt.Run(test.input, func(t *testing.T) {\n \t\t\tt.Parallel()\n \t\t\tbuf := new(bytes.Buffer)\n-\t\t\tmask(buf, client, projectID, test.input, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, test.maskingCharacter, test.numberToMask)\n+\t\t\terr := mask(buf, tc.ProjectID, test.input, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, test.maskingCharacter, test.numberToMask)\n+\t\t\tif err != nil {\n+\t\t\t\tt.Errorf(\"mask(%q, %s, %v) = error %q, want %q\", test.input, test.maskingCharacter, test.numberToMask, err, test.want)\n+\t\t\t}\n \t\t\tif got := buf.String(); got != test.want {\n \t\t\t\tt.Errorf(\"mask(%q, %s, %v) = %q, want %q\", test.input, test.maskingCharacter, test.numberToMask, got, test.want)\n \t\t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -58,7 +62,7 @@\nfunc TestMask(t *testing.T) {\n }\n \n func TestDeidentifyDateShift(t *testing.T) {\n-\ttestutil.SystemTest(t)\n+\ttc := testutil.SystemTest(t)\n \ttests := []struct {\n \t\tinput      string\n \t\twant       string",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -16,12 +16,162 @@\npackage inspect\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"strings\"\n \t\"testing\"\n \n+\t\"cloud.google.com/go/bigquery\"\n+\t\"cloud.google.com/go/datastore\"\n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n+const (\n+\ttopicName        = \"dlp-inspect-test-topic\"\n+\tsubscriptionName = \"dlp-inspect-test-sub\"\n+\n+\tssnFileName             = \"fake_ssn.txt\"\n+\tnothingEventfulFileName = \"nothing_eventful.txt\"\n+\tbucketName              = \"golang-samples-dlp-test\"\n+)\n+\n+func TestInspectDatastore(t *testing.T) {\n+\ttc := testutil.EndToEndTest(t)\n+\twriteTestDatastoreFiles(t, tc.ProjectID)\n+\ttests := []struct {\n+\t\tkind string\n+\t\twant string\n+\t}{\n+\t\t{\n+\t\t\tkind: \"SSNTask\",\n+\t\t\twant: \"US_SOCIAL_SECURITY_NUMBER\",\n+\t\t},\n+\t\t{\n+\t\t\tkind: \"BoringTask\",\n+\t\t\twant: \"No results\",\n+\t\t},\n+\t}\n+\tfor _, test := range tests {\n+\t\tt.Run(test.kind, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, tc.ProjectID, \"\", test.kind)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+type SSNTask struct {\n+\tDescription string\n+}\n+\n+type BoringTask struct {\n+\tDescription string\n+}\n+\n+func writeTestDatastoreFiles(t *testing.T, projectID string) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := datastore.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"datastore.NewClient: %v\", err)\n+\t}\n+\tkind := \"SSNTask\"\n+\tname := \"ssntask1\"\n+\tssnKey := datastore.NameKey(kind, name, nil)\n+\ttask := SSNTask{\n+\t\tDescription: \"My SSN is 111222333\",\n+\t}\n+\tif _, err := client.Put(ctx, ssnKey, &task); err != nil {\n+\t\tt.Fatalf(\"Failed to save task: %v\", err)\n+\t}\n+\n+\tkind = \"BoringTask\"\n+\tname = \"boringtask1\"\n+\tboringKey := datastore.NameKey(kind, name, nil)\n+\tboringTask := BoringTask{\n+\t\tDescription: \"Nothing meaningful\",\n+\t}\n+\tif _, err := client.Put(ctx, boringKey, &boringTask); err != nil {\n+\t\tt.Fatalf(\"Failed to save task: %v\", err)\n+\t}\n+}\n+\n+func TestInspectGCS(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\twriteTestGCSFiles(t, tc.ProjectID)\n+\ttests := []struct {\n+\t\tfileName string\n+\t\twant     string\n+\t}{\n+\t\t{\n+\t\t\tfileName: ssnFileName,\n+\t\t\twant:     \"US_SOCIAL_SECURITY_NUMBER\",\n+\t\t},\n+\t\t{\n+\t\t\tfileName: nothingEventfulFileName,\n+\t\t\twant:     \"No results\",\n+\t\t},\n+\t}\n+\tfor _, test := range tests {\n+\t\tt.Run(test.fileName, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, bucketName, test.fileName)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectGCSFile(%s) = %q, want %q substring\", test.fileName, got, test.want)\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+func writeTestGCSFiles(t *testing.T, projectID string) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tbucket := client.Bucket(bucketName)\n+\t_, err = bucket.Attrs(ctx)\n+\tif err != nil {\n+\t\tswitch err {\n+\t\tcase storage.ErrObjectNotExist:\n+\t\t\tif err := bucket.Create(ctx, projectID, nil); err != nil {\n+\t\t\t\tt.Fatalf(\"bucket.Create: %v\", err)\n+\t\t\t}\n+\t\tdefault:\n+\t\t\tt.Fatalf(\"error getting bucket attrs: %v\", err)\n+\t\t}\n+\t}\n+\tif err := writeObject(ctx, bucket, ssnFileName, \"My SSN is 111222333\"); err != nil {\n+\t\tt.Fatalf(\"writeObject: %v\", err)\n+\t}\n+\tif err := writeObject(ctx, bucket, nothingEventfulFileName, \"Nothing eventful\"); err != nil {\n+\t\tt.Fatalf(\"writeObject: %v\", err)\n+\t}\n+}\n+\n+func writeObject(ctx context.Context, bucket *storage.BucketHandle, fileName, content string) error {\n+\tobj := bucket.Object(fileName)\n+\t_, err := obj.Attrs(ctx)\n+\tif err != nil {\n+\t\tswitch err {\n+\t\tcase storage.ErrObjectNotExist:\n+\t\t\tw := obj.NewWriter(ctx)\n+\t\t\tw.Write([]byte(content))\n+\t\t\tif err := w.Close(); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\tdefault:\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\treturn nil\n+}\n+\n func TestInspectString(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -32,7 +182,7 @@\nfunc TestInspectString(t *testing.T) {\n \n \tgot := buf.String()\n \tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"got %q, want %q\", got, want)\n+\t\tt.Errorf(\"inspectString got %q, want %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -12,7 +12,8 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+// Package metadata contains example snippets using the DLP info types API.\n+package metadata\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/redact/redact.go",
        "code_diff": "@@ -12,34 +12,45 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package redact\n \n+// [START dlp_redact_image]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )\n \n-// [START dlp_redact_image]\n-\n // redactImage blacks out the identified portions of the input image (with type bytesType)\n // and stores the result in outputPath.\n-func redactImage(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, infoTypes []string, bytesType dlppb.ByteContentItem_BytesType, inputPath, outputPath string) {\n+func redactImage(w io.Writer, projectID string, infoTypeNames []string, bytesType dlppb.ByteContentItem_BytesType, inputPath, outputPath string) error {\n+\t// projectID := \"my-project-id\"\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\t// bytesType := dlppb.ByteContentItem_IMAGE_PNG\n+\t// inputPath := /tmp/input\n+\t// outputPath := /tmp/output\n+\n+\tctx := context.Background()\n+\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t}\n+\n \t// Convert the info type strings to a list of InfoTypes.\n-\tvar i []*dlppb.InfoType\n-\tfor _, it := range infoTypes {\n-\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\tvar infoTypes []*dlppb.InfoType\n+\tfor _, it := range infoTypeNames {\n+\t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n \n \t// Convert the info type strings to a list of types to redact in the image.\n-\tvar ir []*dlppb.RedactImageRequest_ImageRedactionConfig\n-\tfor _, it := range infoTypes {\n-\t\tir = append(ir, &dlppb.RedactImageRequest_ImageRedactionConfig{\n+\tvar redactInfoTypes []*dlppb.RedactImageRequest_ImageRedactionConfig\n+\tfor _, it := range infoTypeNames {\n+\t\tredactInfoTypes = append(redactInfoTypes, &dlppb.RedactImageRequest_ImageRedactionConfig{\n \t\t\tTarget: &dlppb.RedactImageRequest_ImageRedactionConfig_InfoType{\n \t\t\t\tInfoType: &dlppb.InfoType{Name: it},\n \t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/redact/redact_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package redact\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/redact/redact_test.go",
        "code_diff": "@@ -24,7 +24,7 @@\nimport (\n )\n \n func TestRedactImage(t *testing.T) {\n-\ttestutil.SystemTest(t)\n+\ttc := testutil.SystemTest(t)\n \ttests := []struct {\n \t\tname      string\n \t\tinputPath string",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -12,7 +12,8 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+// Package risk contains example snippets using the DLP API to create risk jobs.\n+package risk\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -29,7 +30,7 @@\nconst (\n )\n \n func TestRisk(t *testing.T) {\n-\ttestutil.SystemTest(t)\n+\ttc := testutil.SystemTest(t)\n \ttests := []struct {\n \t\tname string\n \t\tfn   func(r *testutil.R)",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -38,7 +39,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Numerical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskNumerical(buf, client, projectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\triskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\t\t\twants := []string{\"Created job\", \"Value range\", \"Value at\"}\n \t\t\t\tgot := buf.String()\n \t\t\t\tfor _, want := range wants {",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -52,7 +53,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Categorical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskCategorical(buf, client, projectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\t\t\triskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\t\t\twants := []string{\"Created job\", \"Histogram bucket\", \"Most common value occurs\"}\n \t\t\t\tgot := buf.String()\n \t\t\t\tfor _, want := range wants {",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -66,7 +67,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Anonymity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskKAnonymity(buf, client, projectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n+\t\t\t\triskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n \t\t\t\twants := []string{\"Created job\", \"Histogram bucket\", \"Size range\"}\n \t\t\t\tgot := buf.String()\n \t\t\t\tfor _, want := range wants {",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -80,7 +81,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"L Diversity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\triskLDiversity(buf, client, projectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n+\t\t\t\triskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName, riskSubscriptionName, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n \t\t\t\twants := []string{\"Created job\", \"Histogram bucket\", \"Size range\"}\n \t\t\t\tgot := buf.String()\n \t\t\t\tfor _, want := range wants {",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -12,35 +12,44 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package trigger\n \n+// [START dlp_create_trigger]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\t\"time\"\n-\n-\t\"github.com/golang/protobuf/ptypes/duration\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n-\t\"google.golang.org/api/iterator\"\n+\t\"github.com/golang/protobuf/ptypes/duration\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )\n \n-// [START dlp_create_trigger]\n-\n // createTrigger creates a trigger with the given configuration.\n-func createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, triggerID, displayName, description, bucketName string, autoPopulateTimespan bool, scanPeriodDays int64, infoTypes []string) {\n+func createTrigger(w io.Writer, projectID string, triggerID, displayName, description, bucketName string, infoTypeNames []string) error {\n+\t// projectID := \"my-project-id\"\n+\t// triggerID := \"my-trigger\"\n+\t// displayName := \"My Trigger\"\n+\t// description := \"My trigger description\"\n+\t// bucketName := \"my-bucket\"\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\n+\tctx := context.Background()\n+\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t}\n+\n \t// Convert the info type strings to a list of InfoTypes.\n-\tvar i []*dlppb.InfoType\n-\tfor _, it := range infoTypes {\n-\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\tvar infoTypes []*dlppb.InfoType\n+\tfor _, it := range infoTypeNames {\n+\t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n \n \t// Create a configured request.\n \treq := &dlppb.CreateJobTriggerRequest{\n-\t\tParent:    \"projects/\" + project,\n+\t\tParent:    \"projects/\" + projectID,\n \t\tTriggerId: triggerID,\n \t\tJobTrigger: &dlppb.JobTrigger{\n \t\t\tDisplayName: displayName,",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -53,7 +62,7 @@\nfunc createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihoo\n \t\t\t\t\t\tSchedule: &dlppb.Schedule{\n \t\t\t\t\t\t\tOption: &dlppb.Schedule_RecurrencePeriodDuration{\n \t\t\t\t\t\t\t\tRecurrencePeriodDuration: &duration.Duration{\n-\t\t\t\t\t\t\t\t\tSeconds: scanPeriodDays * 60 * 60 * 24, // Days to seconds.\n+\t\t\t\t\t\t\t\t\tSeconds: 10 * 60 * 60 * 24, // 10 days in seconds.\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -64,10 +73,10 @@\nfunc createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihoo\n \t\t\tJob: &dlppb.JobTrigger_InspectJob{\n \t\t\t\tInspectJob: &dlppb.InspectJobConfig{\n \t\t\t\t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\t\t\t\tInfoTypes:     i,\n-\t\t\t\t\t\tMinLikelihood: minLikelihood,\n+\t\t\t\t\t\tInfoTypes:     infoTypes,\n+\t\t\t\t\t\tMinLikelihood: dlppb.Likelihood_POSSIBLE,\n \t\t\t\t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n-\t\t\t\t\t\t\tMaxFindingsPerRequest: maxFindings,\n+\t\t\t\t\t\t\tMaxFindingsPerRequest: 10,\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tStorageConfig: &dlppb.StorageConfig{",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "functions/imagemagick/imagemagick.go",
        "code_diff": "@@ -14,8 +14,8 @@\n// [START functions_imagemagick_setup]\n \n-// Package imagemagick contains an example of using ImageMagick from a Cloud\n-// Function.\n+// Package imagemagick contains an example of using ImageMagick to process a\n+// file uploaded to Cloud Storage.\n package imagemagick\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -18,13 +18,26 @@\nimport (\n \t\"bytes\"\n \t\"fmt\"\n \t\"io/ioutil\"\n+\t\"os\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n+// The studyUID, seriesUID, and instanceUID are hard-coded into\n+// the metadata of the DICOM file and make up the DicomWebPath\n+// in the requests to retrieve studies/instances/frames/rendered.\n+const (\n+\tstudyUID           = \"studies/1.3.6.1.4.1.11129.5.5.111396399361969898205364400549799252857604/\"\n+\tseriesUID          = \"series/1.3.6.1.4.1.11129.5.5.195628213694300498946760767481291263511724/\"\n+\tinstanceUID        = \"instances/1.3.6.1.4.1.11129.5.5.153751009835107614666834563294684339746480/\"\n+\tstudyOutputFile    = \"study.multipart\"\n+\tinstanceOutputFile = \"instance.dcm\"\n+\trenderedOutputFile = \"rendered_image.png\"\n+)\n+\n // TestDICOMStore runs all DICOM store tests to avoid having to\n // create/delete DICOM stores for every sample function that needs to be\n // tested.",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -74,7 +87,7 @@\nfunc TestDICOMStore(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n-\t\tif err := dicomWebStoreInstance(ioutil.Discard, tc.ProjectID, location, datasetID, dicomStoreID, \"studies/1.3.6.1.4.1.11129.5.5.111396399361969898205364400549799252857604\", \"./testdata/dicom_00000001_000.dcm\"); err != nil {\n+\t\tif err := dicomWebStoreInstance(ioutil.Discard, tc.ProjectID, location, datasetID, dicomStoreID, studyUID, \"./testdata/dicom_00000001_000.dcm\"); err != nil {\n \t\t\tr.Errorf(\"dicomStoreInstance got err: %v\", err)\n \t\t}\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "healthcare/dicomweb_study_retrieve.go",
        "code_diff": "@@ -19,14 +19,20 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n+\t\"os\"\n \n \thealthcare \"google.golang.org/api/healthcare/v1beta1\"\n )\n \n // dicomWebRetrieveStudy retrieves all instances in the given dicomWebPath\n // study.\n-func dicomWebRetrieveStudy(w io.Writer, projectID, location, datasetID, dicomStoreID, dicomWebPath string) error {\n+func dicomWebRetrieveStudy(w io.Writer, projectID, location, datasetID, dicomStoreID, dicomWebPath string, outputFile string) error {\n+\t// projectID := \"my-project\"\n+\t// location := \"us-central1\"\n+\t// datasetID := \"my-dataset\"\n+\t// dicomStoreID := \"my-dicom-store\"\n+\t// dicomWebPath := \"studies/1.3.6.1.4.1.11129.5.5.111396399857604\"\n+\t// outputFile := \"study.multipart\"\n \tctx := context.Background()\n \n \thealthcareService, err := healthcare.NewService(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -12,6 +12,8 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// Package kms contains samples for asymmetric keys feature of Cloud Key Management Service\n+// https://cloud.google.com/kms/\n package kms\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -67,7 +69,7 @@\nfunc getTestVariables(projectID string) TestVariables {\n \n \tsym := keyRingPath + \"/cryptoKeys/\" + symID\n \tsymVersion := sym + \"/cryptoKeyVersions/1\"\n-\trsaDecrypt := keyRingPath + \"/cryptoKeys/\" + rsaDecryptID + \"/cryptoKeyVersions/2\"\n+\trsaDecryptPath := keyRingPath + \"/cryptoKeys/\" + rsaDecryptID + \"/cryptoKeyVersions/2\"\n \trsaSign := keyRingPath + \"/cryptoKeys/\" + rsaSignID + \"/cryptoKeyVersions/1\"\n \tecSign := keyRingPath + \"/cryptoKeys/\" + ecSignID + \"/cryptoKeyVersions/1\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "monitoring/irm/irm_test.go",
        "code_diff": "@@ -35,10 +35,10 @@\nfunc TestIncident(t *testing.T) {\n \n \tbuf.Reset()\n \tif err := changeStage(buf, incident.Name); err != nil {\n-\t\tt.Errorf(\"changeStage: %v\", err)\n+\t\tt.Errorf(\"changeStage(%q): %v\", incident.Name, err)\n \t}\n \tif got, want := buf.String(), \"Changed stage\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"changeStage got\\n----\\n%s\\n----\\nWant to contain\\n----\\n%s\\n\", got, want)\n+\t\tt.Errorf(\"changeStage(%q) got\\n----\\n%s\\n----\\nWant to contain\\n----\\n%s\\n\", incident.Name, got, want)\n \t}\n \n \tbuf.Reset()",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -12,9 +12,12 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+// package subscriptions is a tool to manage Google Cloud Pub/Sub subscriptions by using the Pub/Sub API.\n+// See more about Google Cloud Pub/Sub at https://cloud.google.com/pubsub/docs/overview.\n+package subscriptions\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"sync\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -26,79 +29,85 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-var topic *pubsub.Topic\n-var subID string\n+var topicName string\n+var subName string\n \n-var once sync.Once // guards cleanup related operations in setup.\n+// once guards cleanup related operations in setup. No need to set up and tear\n+// down every time, so this speeds things up.\n+var once sync.Once\n \n func setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n+\ttopicName = tc.ProjectID + \"-test-sub-topic\"\n+\tsubName = tc.ProjectID + \"-test-sub\"\n+\tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n \n-\tsubID = tc.ProjectID + \"-test-sub\"\n-\ttopicID := tc.ProjectID + \"-test-sub-topic\"\n-\n-\t// Cleanup resources from the previous failed tests.\n+\t// Cleanup resources from the previous tests.\n \tonce.Do(func() {\n-\t\t// Create a topic.\n-\t\ttopic = client.Topic(topicID)\n+\t\ttopic := client.Topic(topicName)\n \t\tok, err := topic.Exists(ctx)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t\t}\n-\t\tif !ok {\n-\t\t\tif topic, err = client.CreateTopic(ctx, topicID); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to create the topic: %v\", err)\n+\t\tif ok {\n+\t\t\tif err := topic.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicName, err)\n \t\t\t}\n \t\t}\n-\n-\t\t// Delete the sub if already exists.\n-\t\tsub := client.Subscription(subID)\n+\t\tsub := client.Subscription(subName)\n \t\tok, err = sub.Exists(ctx)\n \t\tif err != nil {\n-\t\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n+\t\t\tt.Fatalf(\"failed to check if subscription exists: %v\", err)\n \t\t}\n \t\tif ok {\n-\t\t\tif err := client.Subscription(subID).Delete(ctx); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", subID, err)\n+\t\t\tif err := sub.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the subscription (%q): %v\", subName, err)\n \t\t\t}\n \t\t}\n \t})\n+\n \treturn client\n }\n \n func TestCreate(t *testing.T) {\n-\tc := setup(t)\n-\n-\tif err := create(c, subID, topic); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\ttopic, err := client.CreateTopic(ctx, topicName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"CreateTopic: %v\", err)\n+\t}\n+\tbuf := new(bytes.Buffer)\n+\tif err := create(buf, tc.ProjectID, subName, topic); err != nil {\n \t\tt.Fatalf(\"failed to create a subscription: %v\", err)\n \t}\n-\tok, err := c.Subscription(subID).Exists(context.Background())\n+\tok, err := client.Subscription(subName).Exists(context.Background())\n \tif err != nil {\n \t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n \t}\n \tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", subID)\n+\t\tt.Fatalf(\"got none; want sub = %q\", subName)\n \t}\n }\n \n func TestList(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tsubs, err := list(c)\n+\t\tsubs, err := list(tc.ProjectID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"failed to list subscriptions: %v\", err)\n \t\t\treturn\n \t\t}\n \n \t\tfor _, sub := range subs {\n-\t\t\tif sub.ID() == subID {\n+\t\t\tif sub.ID() == subName {\n \t\t\t\treturn // PASS\n \t\t\t}\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -107,15 +116,16 @@\nfunc TestList(t *testing.T) {\n \t\tfor i, sub := range subs {\n \t\t\tsubNames[i] = sub.ID()\n \t\t}\n-\t\tr.Errorf(\"got %+v; want a list with subscription %q\", subNames, subID)\n+\t\tr.Errorf(\"got %+v; want a list with subscription %q\", subNames, subName)\n \t})\n }\n \n func TestIAM(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tperms, err := testPermissions(c, subID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tperms, err := testPermissions(buf, tc.ProjectID, subName)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"testPermissions: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -125,15 +135,16 @@\nfunc TestIAM(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := addUsers(c, subID); err != nil {\n+\t\tif err := addUsers(tc.ProjectID, subName); err != nil {\n \t\t\tr.Errorf(\"addUsers: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tpolicy, err := getPolicy(c, subID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tpolicy, err := policy(buf, tc.ProjectID, subName)\n \t\tif err != nil {\n-\t\t\tr.Errorf(\"getPolicy: %v\", err)\n+\t\t\tr.Errorf(\"policy: %v\", err)\n \t\t}\n \t\tif role, member := iam.Editor, \"group:cloud-logs@google.com\"; !policy.HasRole(member, role) {\n \t\t\tr.Errorf(\"want %q as viewer, policy=%v\", member, policy)",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -12,9 +12,12 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+// Package topics is a tool to manage Google Cloud Pub/Sub topics by using the Pub/Sub API.\n+// See more about Google Cloud Pub/Sub at https://cloud.google.com/pubsub/docs/overview.package topics\n+package topics\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"sync\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -25,63 +28,67 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-var topicID string\n+var topicName string\n \n-var once sync.Once // guards cleanup related operations in setup.\n+// once guards cleanup related operations in setup. No need to set up and tear\n+// down every time, so this speeds things up.\n+var once sync.Once\n \n func setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n-\ttopicID = tc.ProjectID + \"-test-topic\"\n-\n+\ttopicName = tc.ProjectID + \"-test-topic\"\n+\tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n \n-\t// Cleanup resources from the previous failed tests.\n+\t// Cleanup resources from the previous tests.\n \tonce.Do(func() {\n-\t\ttopic := client.Topic(topicID)\n+\t\ttopic := client.Topic(topicName)\n \t\tok, err := topic.Exists(ctx)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t\t}\n-\t\tif !ok {\n-\t\t\treturn\n-\t\t}\n-\t\tif err := topic.Delete(ctx); err != nil {\n-\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicID, err)\n+\t\tif ok {\n+\t\t\tif err := topic.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicName, err)\n+\t\t\t}\n \t\t}\n \t})\n+\n \treturn client\n }\n \n func TestCreate(t *testing.T) {\n-\tc := setup(t)\n-\tif err := create(c, topicID); err != nil {\n+\tclient := setup(t)\n+\ttc := testutil.SystemTest(t)\n+\tbuf := new(bytes.Buffer)\n+\tif err := create(buf, tc.ProjectID, topicName); err != nil {\n \t\tt.Fatalf(\"failed to create a topic: %v\", err)\n \t}\n-\tok, err := c.Topic(topicID).Exists(context.Background())\n+\tok, err := client.Topic(topicName).Exists(context.Background())\n \tif err != nil {\n-\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n+\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t}\n \tif !ok {\n-\t\tt.Fatalf(\"got none; want topic = %q\", topicID)\n+\t\tt.Fatalf(\"got none; want topic = %q\", topicName)\n \t}\n }\n \n func TestList(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\ttopics, err := list(c)\n+\t\ttopics, err := list(tc.ProjectID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"failed to list topics: %v\", err)\n \t\t}\n \n \t\tfor _, t := range topics {\n-\t\t\tif t.ID() == topicID {\n+\t\t\tif t.ID() == topicName {\n \t\t\t\treturn // PASS\n \t\t\t}\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -90,38 +97,56 @@\nfunc TestList(t *testing.T) {\n \t\tfor i, t := range topics {\n \t\t\ttopicNames[i] = t.ID()\n \t\t}\n-\t\tr.Errorf(\"got %+v; want a list with topic = %q\", topicNames, topicID)\n+\t\tr.Errorf(\"got %+v; want a list with topic = %q\", topicNames, topicName)\n \t})\n }\n \n func TestPublish(t *testing.T) {\n \t// Nothing much to do here, unless we are consuming.\n \t// TODO(jbd): Merge topics and subscriptions programs maybe?\n-\tc := setup(t)\n-\tif err := publish(c, topicID, \"hello world\"); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publish(buf, tc.ProjectID, topicName, \"hello world\"); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestPublishThatScales(t *testing.T) {\n-\tc := setup(t)\n-\tif err := publishThatScales(c, topicID, 10); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tsetup(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publishThatScales(buf, tc.ProjectID, topicName, 10); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestPublishCustomAttributes(t *testing.T) {\n-\tc := setup(t)\n-\tif err := publishCustomAttributes(c, topicID); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tsetup(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publishCustomAttributes(buf, tc.ProjectID, topicName); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestIAM(t *testing.T) {\n-\tc := setup(t)\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tperms, err := testPermissions(c, topicID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tperms, err := testPermissions(buf, tc.ProjectID, topicName)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"testPermissions: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -131,15 +156,16 @@\nfunc TestIAM(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := addUsers(c, topicID); err != nil {\n+\t\tif err := addUsers(tc.ProjectID, topicName); err != nil {\n \t\t\tr.Errorf(\"addUsers: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tpolicy, err := getPolicy(c, topicID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tpolicy, err := policy(buf, tc.ProjectID, topicName)\n \t\tif err != nil {\n-\t\t\tr.Errorf(\"getPolicy: %v\", err)\n+\t\t\tr.Errorf(\"policy: %v\", err)\n \t\t}\n \t\tif role, member := iam.Editor, \"group:cloud-logs@google.com\"; !policy.HasRole(member, role) {\n \t\t\tr.Errorf(\"want %q as viewer, policy=%v\", member, policy)",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "run/pubsub/main.go",
        "code_diff": "@@ -20,6 +20,7 @@\npackage main\n import (\n \t\"encoding/json\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -26,6 +26,7 @@\nimport (\n \t\"strconv\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/civil\"\n \t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \t\"google.golang.org/api/iterator\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -38,46 +39,55 @@\ntype adminCommand func(ctx context.Context, w io.Writer, adminClient *database.D\n \n var (\n \tcommands = map[string]command{\n-\t\t\"write\":                      write,\n-\t\t\"delete\":                     delete,\n-\t\t\"query\":                      query,\n-\t\t\"read\":                       read,\n-\t\t\"update\":                     update,\n-\t\t\"writetransaction\":           writeWithTransaction,\n-\t\t\"querynewcolumn\":             queryNewColumn,\n-\t\t\"queryindex\":                 queryUsingIndex,\n-\t\t\"readindex\":                  readUsingIndex,\n-\t\t\"readstoringindex\":           readStoringIndex,\n-\t\t\"readonlytransaction\":        readOnlyTransaction,\n-\t\t\"readstaledata\":              readStaleData,\n-\t\t\"readbatchdata\":              readBatchData,\n-\t\t\"updatewithtimestamp\":        updateWithTimestamp,\n-\t\t\"querywithtimestamp\":         queryWithTimestamp,\n-\t\t\"writewithtimestamp\":         writeWithTimestamp,\n-\t\t\"querynewtable\":              queryNewTable,\n-\t\t\"writetodocstable\":           writeToDocumentsTable,\n-\t\t\"updatedocstable\":            updateDocumentsTable,\n-\t\t\"querydocstable\":             queryDocumentsTable,\n-\t\t\"writewithhistory\":           writeWithHistory,\n-\t\t\"updatewithhistory\":          updateWithHistory,\n-\t\t\"querywithhistory\":           queryWithHistory,\n-\t\t\"writestructdata\":            writeStructData,\n-\t\t\"querywithstruct\":            queryWithStruct,\n-\t\t\"querywitharrayofstruct\":     queryWithArrayOfStruct,\n-\t\t\"querywithstructfield\":       queryWithStructField,\n-\t\t\"querywithnestedstructfield\": queryWithNestedStructField,\n-\t\t\"dmlinsert\":                  insertUsingDML,\n-\t\t\"dmlupdate\":                  updateUsingDML,\n-\t\t\"dmldelete\":                  deleteUsingDML,\n-\t\t\"dmlwithtimestamp\":           updateUsingDMLWithTimestamp,\n-\t\t\"dmlwriteread\":               writeAndReadUsingDML,\n-\t\t\"dmlupdatestruct\":            updateUsingDMLStruct,\n-\t\t\"dmlwrite\":                   writeUsingDML,\n-\t\t\"querywithparameter\":         queryWithParameter,\n-\t\t\"dmlwritetxn\":                writeWithTransactionUsingDML,\n-\t\t\"dmlupdatepart\":              updateUsingPartitionedDML,\n-\t\t\"dmldeletepart\":              deleteUsingPartitionedDML,\n-\t\t\"dmlbatchupdate\":             updateUsingBatchDML,\n+\t\t\"write\":                       write,\n+\t\t\"delete\":                      delete,\n+\t\t\"query\":                       query,\n+\t\t\"read\":                        read,\n+\t\t\"update\":                      update,\n+\t\t\"writetransaction\":            writeWithTransaction,\n+\t\t\"querynewcolumn\":              queryNewColumn,\n+\t\t\"queryindex\":                  queryUsingIndex,\n+\t\t\"readindex\":                   readUsingIndex,\n+\t\t\"readstoringindex\":            readStoringIndex,\n+\t\t\"readonlytransaction\":         readOnlyTransaction,\n+\t\t\"readstaledata\":               readStaleData,\n+\t\t\"readbatchdata\":               readBatchData,\n+\t\t\"updatewithtimestamp\":         updateWithTimestamp,\n+\t\t\"querywithtimestamp\":          queryWithTimestamp,\n+\t\t\"writewithtimestamp\":          writeWithTimestamp,\n+\t\t\"querynewtable\":               queryNewTable,\n+\t\t\"writetodocstable\":            writeToDocumentsTable,\n+\t\t\"updatedocstable\":             updateDocumentsTable,\n+\t\t\"querydocstable\":              queryDocumentsTable,\n+\t\t\"writewithhistory\":            writeWithHistory,\n+\t\t\"updatewithhistory\":           updateWithHistory,\n+\t\t\"querywithhistory\":            queryWithHistory,\n+\t\t\"writestructdata\":             writeStructData,\n+\t\t\"querywithstruct\":             queryWithStruct,\n+\t\t\"querywitharrayofstruct\":      queryWithArrayOfStruct,\n+\t\t\"querywithstructfield\":        queryWithStructField,\n+\t\t\"querywithnestedstructfield\":  queryWithNestedStructField,\n+\t\t\"dmlinsert\":                   insertUsingDML,\n+\t\t\"dmlupdate\":                   updateUsingDML,\n+\t\t\"dmldelete\":                   deleteUsingDML,\n+\t\t\"dmlwithtimestamp\":            updateUsingDMLWithTimestamp,\n+\t\t\"dmlwriteread\":                writeAndReadUsingDML,\n+\t\t\"dmlupdatestruct\":             updateUsingDMLStruct,\n+\t\t\"dmlwrite\":                    writeUsingDML,\n+\t\t\"querywithparameter\":          queryWithParameter,\n+\t\t\"dmlwritetxn\":                 writeWithTransactionUsingDML,\n+\t\t\"dmlupdatepart\":               updateUsingPartitionedDML,\n+\t\t\"dmldeletepart\":               deleteUsingPartitionedDML,\n+\t\t\"dmlbatchupdate\":              updateUsingBatchDML,\n+\t\t\"writedatatypesdata\":          writeDatatypesData,\n+\t\t\"querywitharray\":              queryWithArray,\n+\t\t\"querywithbool\":               queryWithBool,\n+\t\t\"querywithbytes\":              queryWithBytes,\n+\t\t\"querywithdate\":               queryWithDate,\n+\t\t\"querywithfloat\":              queryWithFloat,\n+\t\t\"querywithint\":                queryWithInt,\n+\t\t\"querywithstring\":             queryWithString,\n+\t\t\"querywithtimestampparameter\": queryWithTimestampParameter,\n \t}\n \n \tadminCommands = map[string]adminCommand{",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -87,6 +97,7 @@\nvar (\n \t\t\"addstoringindex\":                 addStoringIndex,\n \t\t\"addcommittimestamp\":              addCommitTimestamp,\n \t\t\"createtablewithtimestamp\":        createTableWithTimestamp,\n+\t\t\"createtablewithdatatypes\":        createTableWithDatatypes,\n \t\t\"createtabledocswithtimestamp\":    createTableDocumentsWithTimestamp,\n \t\t\"createtabledocswithhistorytable\": createTableDocumentsWithHistoryTable,\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1266,10 +1277,332 @@\nfunc updateUsingBatchDML(ctx context.Context, w io.Writer, client *spanner.Clien\n \n // [END spanner_dml_batch_update]\n \n+// [START spanner_create_table_with_datatypes]\n+\n+// Creates a Cloud Spanner table comprised of columns for each supported data type\n+// See https://cloud.google.com/spanner/docs/data-types\n+func createTableWithDatatypes(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t`CREATE TABLE Venues (\n+\t\t\t\tVenueId\tINT64 NOT NULL,\n+\t\t\t\tVenueName STRING(100),\n+\t\t\t\tVenueInfo BYTES(MAX),\n+\t\t\t\tCapacity INT64,\n+\t\t\t\tAvailableDates ARRAY<DATE>,\n+\t\t\t\tLastContactDate DATE,\n+\t\t\t\tOutdoorVenue BOOL,\n+\t\t\t\tPopularityScore FLOAT64,\n+\t\t\t\tLastUpdateTime TIMESTAMP NOT NULL OPTIONS (allow_commit_timestamp=true)\n+\t\t\t) PRIMARY KEY (VenueId)`,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"UpdateDatabaseDdl: %v\", err)\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Created Venues table in database [%s]\\n\", database)\n+\treturn nil\n+}\n+\n+// [END spanner_create_table_with_datatypes]\n+\n+// [START spanner_insert_datatypes_data]\n+\n+func writeDatatypesData(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvenueColumns := []string{\"VenueId\", \"VenueName\", \"VenueInfo\", \"Capacity\", \"AvailableDates\",\n+\t\t\"LastContactDate\", \"OutdoorVenue\", \"PopularityScore\", \"LastUpdateTime\"}\n+\tm := []*spanner.Mutation{\n+\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n+\t\t\t[]interface{}{4, \"Venue 4\", []byte(\"Hello World 1\"), 1800,\n+\t\t\t\t[]string{\"2020-12-01\", \"2020-12-02\", \"2020-12-03\"},\n+\t\t\t\t\"2018-09-02\", false, 0.85543, spanner.CommitTimestamp}),\n+\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n+\t\t\t[]interface{}{19, \"Venue 19\", []byte(\"Hello World 2\"), 6300,\n+\t\t\t\t[]string{\"2020-11-01\", \"2020-11-05\", \"2020-11-15\"},\n+\t\t\t\t\"2019-01-15\", true, 0.98716, spanner.CommitTimestamp}),\n+\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n+\t\t\t[]interface{}{42, \"Venue 42\", []byte(\"Hello World 3\"), 3000,\n+\t\t\t\t[]string{\"2020-10-01\", \"2020-10-07\"}, \"2018-10-01\",\n+\t\t\t\tfalse, 0.72598, spanner.CommitTimestamp}),\n+\t}\n+\t_, err := client.Apply(ctx, m)\n+\treturn err\n+}\n+\n+// [END spanner_insert_datatypes_data]\n+\n+// [START spanner_query_with_array_parameter]\n+\n+func queryWithArray(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar date1 = civil.Date{Year: 2020, Month: time.October, Day: 1}\n+\tvar date2 = civil.Date{Year: 2020, Month: time.November, Day: 1}\n+\tvar exampleArray = []civil.Date{date1, date2}\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, AvailableDate FROM Venues v,\n+            \tUNNEST(v.AvailableDates) as AvailableDate \n+            \tWHERE AvailableDate IN UNNEST(@availableDates)`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"availableDates\": exampleArray,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar availableDate civil.Date\n+\t\tif err := row.Columns(&venueID, &venueName, &availableDate); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, availableDate)\n+\t}\n+}\n+\n+// [END spanner_query_with_array_parameter]\n+\n+// [START spanner_query_with_bool_parameter]\n+\n+func queryWithBool(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleBool = true\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, OutdoorVenue FROM Venues\n+            \tWHERE OutdoorVenue = @outdoorVenue`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"outdoorVenue\": exampleBool,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar outdoorVenue bool\n+\t\tif err := row.Columns(&venueID, &venueName, &outdoorVenue); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %t\\n\", venueID, venueName, outdoorVenue)\n+\t}\n+}\n+\n+// [END spanner_query_with_bool_parameter]\n+\n+// [START spanner_query_with_bytes_parameter]\n+\n+func queryWithBytes(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleBytes = []byte(\"Hello World 1\")\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName FROM Venues\n+            \tWHERE VenueInfo = @venueInfo`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"venueInfo\": exampleBytes,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tif err := row.Columns(&venueID, &venueName); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s\\n\", venueID, venueName)\n+\t}\n+}\n+\n+// [END spanner_query_with_bytes_parameter]\n+\n+// [START spanner_query_with_date_parameter]\n+\n+func queryWithDate(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleDate = civil.Date{Year: 2019, Month: time.January, Day: 1}\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, LastContactDate FROM Venues\n+            \tWHERE LastContactDate < @lastContactDate`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"lastContactDate\": exampleDate,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar lastContactDate civil.Date\n+\t\tif err := row.Columns(&venueID, &venueName, &lastContactDate); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %v\\n\", venueID, venueName, lastContactDate)\n+\t}\n+}\n+\n+// [END spanner_query_with_date_parameter]\n+\n+// [START spanner_query_with_float_parameter]\n+\n+func queryWithFloat(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleFloat = 0.8\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, PopularityScore FROM Venues\n+            \tWHERE PopularityScore > @popularityScore`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"popularityScore\": exampleFloat,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar popularityScore float64\n+\t\tif err := row.Columns(&venueID, &venueName, &popularityScore); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %f\\n\", venueID, venueName, popularityScore)\n+\t}\n+}\n+\n+// [END spanner_query_with_float_parameter]\n+\n+// [START spanner_query_with_int_parameter]\n+\n+func queryWithInt(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleInt = 3000\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, Capacity FROM Venues\n+            \tWHERE Capacity >= @capacity`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"capacity\": exampleInt,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID, capacity int64\n+\t\tvar venueName string\n+\t\tif err := row.Columns(&venueID, &venueName, &capacity); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %d\\n\", venueID, venueName, capacity)\n+\t}\n+}\n+\n+// [END spanner_query_with_int_parameter]\n+\n+// [START spanner_query_with_string_parameter]\n+\n+func queryWithString(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleString = \"Venue 42\"\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName FROM Venues\n+            \tWHERE VenueName = @venueName`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"venueName\": exampleString,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tif err := row.Columns(&venueID, &venueName); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s\\n\", venueID, venueName)\n+\t}\n+}\n+\n+// [END spanner_query_with_string_parameter]\n+\n+// [START spanner_query_with_timestamp_parameter]\n+\n+func queryWithTimestampParameter(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleTimestamp = time.Now()\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, LastUpdateTime FROM Venues\n+            \tWHERE LastUpdateTime < @lastUpdateTime`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"lastUpdateTime\": exampleTimestamp,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar lastUpdateTime time.Time\n+\t\tif err := row.Columns(&venueID, &venueName, &lastUpdateTime); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, lastUpdateTime)\n+\t}\n+}\n+\n+// [END spanner_query_with_timestamp_parameter]\n+\n func queryNewTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n \tstmt := spanner.Statement{\n \t\tSQL: `SELECT SingerId, VenueId, EventDate, Revenue, LastUpdateTime FROM Performances\n-\t\t\tORDER BY LastUpdateTime DESC`}\n+\t\t\t\tORDER BY LastUpdateTime DESC`}\n \titer := client.Single().Query(ctx, stmt)\n \tdefer iter.Stop()\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -15,11 +15,13 @@\npackage main\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"os\"\n+\t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into functions_helloworld_error_test",
        "commit_id": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "getting-started/gopher-run: convert from Cloud Run to AppEngine",
        "pr_number": 922,
        "file_name": "jobs/v4/howto/howto_test.go",
        "code_diff": "@@ -15,12 +15,13 @@\npackage howto\n \n import (\n+\t\"bytes\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n-\t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/gofrs/uuid\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into gae-branch",
        "commit_id": "c1cb66a3f03a6c4f3d061cff70381407d0b2cc5e"
    },
    {
        "pr_title": "getting-started/gopher-run: convert from Cloud Run to AppEngine",
        "pr_number": 922,
        "file_name": "jobs/v4/howto/howto_test.go",
        "code_diff": "@@ -30,15 +31,14 @@\nimport (\n var testCompany *talentpb.Company\n var testJob *talentpb.Job\n \n-func TestMain(m *testing.M) {\n-\ttc, ok := testutil.ContextMain(m)\n-\tif !ok {\n-\t\tlog.Fatal(\"Error getting test context\")\n-\t}\n+func TestBasicUsage(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n \n \texternalID := fmt.Sprintf(\"company-%s\", uuid.Must(uuid.NewV4()).String())\n \tdisplayName := \"Google Sample\"\n \tvar err error\n+\n+\t// Create the company.\n \ttestCompany, err = createCompany(ioutil.Discard, tc.ProjectID, externalID, displayName)\n \tif err != nil {\n \t\tlog.Fatalf(\"createCompany: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into gae-branch",
        "commit_id": "c1cb66a3f03a6c4f3d061cff70381407d0b2cc5e"
    },
    {
        "pr_title": "getting-started/gopher-run: add AI automation and background generation",
        "pr_number": 910,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START getting_started_background_translate]\n+// [START getting_started_background_translate_setup]\n \n // Package background contains a Cloud Function to translate text.\n // The function listens to Pub/Sub, does the translations, and stores the",
        "comments": [],
        "commit_message": "Merge branch 'ai' of github.com:LogicalShark/golang-samples into ai",
        "commit_id": "e0afffe2cc04e62a9a5e5b971eb5f4b288d18590"
    },
    {
        "pr_title": "getting-started/gopher-run: add AI automation and background generation",
        "pr_number": 910,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -55,8 +55,13 @@\ntype PubSubMessage struct {\n \tData []byte `json:\"data\"`\n }\n \n-// Translate translates the given message and stores the result in Firestore.\n-func Translate(ctx context.Context, m PubSubMessage) error {\n+// [END getting_started_background_translate_setup]\n+\n+// [START getting_started_background_translate_init]\n+\n+// initializeClients creates translateClient and firestoreClient if they haven't\n+// been created yet.\n+func initializeClients() error {\n \tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tif projectID == \"\" {\n \t\treturn fmt.Errorf(\"GOOGLE_CLOUD_PROJECT must be set\")",
        "comments": [],
        "commit_message": "Merge branch 'ai' of github.com:LogicalShark/golang-samples into ai",
        "commit_id": "e0afffe2cc04e62a9a5e5b971eb5f4b288d18590"
    },
    {
        "pr_title": "getting-started/gopher-run: add AI automation and background generation",
        "pr_number": 910,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -80,6 +85,42 @@\nfunc Translate(ctx context.Context, m PubSubMessage) error {\n \t\t\treturn fmt.Errorf(\"firestore.NewClient: %v\", err)\n \t\t}\n \t}\n+\treturn nil\n+}\n+\n+// [END getting_started_background_translate_init]\n+\n+// [START getting_started_background_translate_string]\n+\n+// translateString translates text to lang, returning:\n+// * the translated text,\n+// * the automatically detected source language, and\n+// * an error.\n+func translateString(ctx context.Context, text string, lang string) (translated string, originalLang string, err error) {\n+\tl, err := language.Parse(lang)\n+\tif err != nil {\n+\t\treturn \"\", \"\", fmt.Errorf(\"language.Parse: %v\", err)\n+\t}\n+\n+\touts, err := translateClient.Translate(ctx, []string{text}, l, nil)\n+\tif err != nil {\n+\t\treturn \"\", \"\", fmt.Errorf(\"Translate: %v\", err)\n+\t}\n+\n+\tif len(outs) < 1 {\n+\t\treturn \"\", \"\", fmt.Errorf(\"Translate got %d translations, need at least 1\", len(outs))\n+\t}\n+\n+\treturn outs[0].Text, outs[0].Source.String(), nil\n+}\n+\n+// [END getting_started_background_translate_string]\n+\n+// [START getting_started_background_translate]\n+\n+// Translate translates the given message and stores the result in Firestore.\n+func Translate(ctx context.Context, m PubSubMessage) error {\n+\tinitializeClients()\n \n \tt := Translation{}\n \tif err := json.Unmarshal(m.Data, &t); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'ai' of github.com:LogicalShark/golang-samples into ai",
        "commit_id": "e0afffe2cc04e62a9a5e5b971eb5f4b288d18590"
    },
    {
        "pr_title": "getting-started/gopher-run: add AI automation and background generation",
        "pr_number": 910,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -96,6 +137,7 @@\nfunc Translate(ctx context.Context, m PubSubMessage) error {\n \tdocName = strings.Replace(docName, \"/\", \"-\", -1)\n \tref := firestoreClient.Collection(\"translations\").Doc(docName)\n \n+\t// Run in a transation to prevent concurrent duplicate translations.\n \terr := firestoreClient.RunTransaction(ctx, func(ctx context.Context, tx *firestore.Transaction) error {\n \t\tdoc, err := tx.Get(ref)\n \t\tif err != nil && status.Code(err) != codes.NotFound {",
        "comments": [],
        "commit_message": "Merge branch 'ai' of github.com:LogicalShark/golang-samples into ai",
        "commit_id": "e0afffe2cc04e62a9a5e5b971eb5f4b288d18590"
    },
    {
        "pr_title": "getting-started/gopher-run: add AI automation and background generation",
        "pr_number": 910,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -228,11 +228,10 @@\nfunc publishWithSettings(client *pubsub.Client, topic string, msg []byte) error\n \tctx := context.Background()\n \t// [START pubsub_publisher_batch_settings]\n \tt := client.Topic(topic)\n-\tt.PublishSettings = pubsub.PublishSettings{\n-\t\tByteThreshold:  5000,\n-\t\tCountThreshold: 10,\n-\t\tDelayThreshold: 100 * time.Millisecond,\n-\t}\n+\tt.PublishSettings.ByteThreshold = 5000\n+\tt.PublishSettings.CountThreshold = 10\n+\tt.PublishSettings.DelayThreshold = 100 * time.Millisecond\n+\n \tresult := t.Publish(ctx, &pubsub.Message{Data: msg})\n \t// Block until the result is returned and a server-generated\n \t// ID is returned for the published message.",
        "comments": [],
        "commit_message": "Merge branch 'ai' of github.com:LogicalShark/golang-samples into ai",
        "commit_id": "e0afffe2cc04e62a9a5e5b971eb5f4b288d18590"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -220,6 +220,11 @@\nfunc TestOccurrencesForNote(t *testing.T) {\n \n func TestPubSub(t *testing.T) {\n \tv := setup(t)\n+\t// Create a new Topic if needed\n+\tclient, _ := pubsub.NewClient(v.ctx, v.projectID)\n+\ttopicID := \"container-analysis-occurrences-v1\"\n+\tclient.CreateTopic(v.ctx, topicID)\n+\n \t// Create a new subscription if it doesn't exist.\n \tcreateOccurrenceSubscription(v.subID, v.projectID)",
        "comments": [],
        "commit_message": "Merge branch 'master' into moarsamples",
        "commit_id": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "appengine/go11x/cloudsql/cloudsql.go",
        "code_diff": "@@ -53,7 +53,8 @@\nfunc DB() *sql.DB {\n \tvar (\n \t\tconnectionName = mustGetenv(\"CLOUDSQL_CONNECTION_NAME\")\n \t\tuser           = mustGetenv(\"CLOUDSQL_USER\")\n-\t\tpassword       = os.Getenv(\"CLOUDSQL_PASSWORD\") // NOTE: password may be empty\n+\t\tdbName         = os.Getenv(\"CLOUDSQL_DATABASE_NAME\") // NOTE: dbName may be empty\n+\t\tpassword       = os.Getenv(\"CLOUDSQL_PASSWORD\")      // NOTE: password may be empty\n \t\tsocket         = os.Getenv(\"CLOUDSQL_SOCKET_PREFIX\")\n \t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "appengine_flexible/mailgun/mailgun.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \n-\t\"github.com/mailgun/mailgun-go\"\n+\tmailgun \"github.com/mailgun/mailgun-go/v3\"\n \t\"google.golang.org/appengine\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "appengine_flexible/mailgun/mailgun.go",
        "code_diff": "@@ -56,7 +56,7 @@\nfunc mustGetenv(k string) string {\n \n // [START gae_flex_mailgun_simple_message]\n func sendSimpleMessageHandler(w http.ResponseWriter, r *http.Request) {\n-\tmsg, id, err := mailgunClient.Send(mailgunClient.NewMessage(\n+\tmsg, id, err := mailgunClient.Send(r.Context(), mailgunClient.NewMessage(\n \t\t/* From */ fmt.Sprintf(\"Excited User <mailgun@%s>\", mailgunDomain),\n \t\t/* Subject */ \"Hello\",\n \t\t/* Body */ \"Testing some Mailgun awesomness!\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "badfiles_test.go",
        "code_diff": "@@ -44,9 +44,11 @@\nvar allowList = []string{\n \t\"**/*.html\",\n \t\"**/*.js\",\n \t\"**/*.sql\",\n+\t\"**/*.dot\",\n \n \t\"LICENSE\",\n-\t\"**/Dockerfile*\",\n+\t\"**/*Dockerfile*\",\n+\t\"**/.dockerignore\",\n \t\"**/Makefile\",\n \n \t// Primarily ML APIs.",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -35,7 +35,7 @@\nimport (\n \n \tbqStorage \"cloud.google.com/go/bigquery/storage/apiv1beta1\"\n \t\"github.com/golang/protobuf/ptypes\"\n-\tgax \"github.com/googleapis/gax-go\"\n+\tgax \"github.com/googleapis/gax-go/v2\"\n \t\"github.com/linkedin/goavro\"\n \tbqStoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1beta1\"\n \t\"google.golang.org/grpc\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -90,6 +90,13 @@\nfunc main() {\n \t\tParent:         fmt.Sprintf(\"projects/%s\", *projectID),\n \t\tTableReference: readTable,\n \t\tReadOptions:    tableReadOptions,\n+\t\t// This API can also deliver data serialized in Apache Arrow format.\n+\t\t// This example leverages Apache Avro.\n+\t\tFormat: bqStoragepb.DataFormat_AVRO,\n+\t\t// We use a LIQUID strategy in this example because we only\n+\t\t// read from a single stream.  Consider BALANCED if you're consuming\n+\t\t// multiple streams concurrently and want more consistent stream sizes.\n+\t\tShardingStrategy: bqStoragepb.ShardingStrategy_LIQUID,\n \t}\n \n \t// Set a snapshot time if it's been specified.",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -158,8 +165,10 @@\nfunc printDatum(d interface{}) {\n \t// Go's map implementation returns keys in a random ordering, so we sort\n \t// the keys before accessing.\n \tkeys := make([]string, len(m))\n+\ti := 0\n \tfor k := range m {\n-\t\tkeys = append(keys, k)\n+\t\tkeys[i] = k\n+\t\ti++\n \t}\n \tsort.Strings(keys)\n \tfor _, key := range keys {",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -190,9 +199,13 @@\nfunc valueFromTypeMap(field interface{}) interface{} {\n // successfully transmitted.\n func processStream(ctx context.Context, client *bqStorage.BigQueryStorageClient, st *bqStoragepb.Stream, ch chan<- *bqStoragepb.AvroRows) error {\n \tvar offset int64\n-\tstreamRetry := 3\n+\n+\t// Streams may be long-running.  Rather than using a global retry for the\n+\t// stream, implement a retry that resets once progress is made.\n+\tretryLimit := 3\n \n \tfor {\n+\t\tretries := 0\n \t\t// Send the initiating request to start streaming row blocks.\n \t\trowStream, err := client.ReadRows(ctx, &bqStoragepb.ReadRowsRequest{\n \t\t\tReadPosition: &bqStoragepb.StreamPosition{",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -38,34 +38,23 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_copy_table]\n \t// [START bigquery_copy_table_cmek]\n \t// [START bigquery_copy_table_multiple_source]\n-\t// [START bigquery_create_dataset]\n \t// [START bigquery_create_table]\n \t// [START bigquery_create_table_clustered]\n \t// [START bigquery_create_table_cmek]\n \t// [START bigquery_create_table_partitioned]\n \t// [START bigquery_create_view]\n-\t// [START bigquery_delete_dataset]\n-\t// [START bigquery_delete_label_dataset]\n \t// [START bigquery_delete_label_table]\n-\t// [START bigquery_delete_model]\n \t// [START bigquery_delete_table]\n \t// [START bigquery_extract_table]\n \t// [START bigquery_extract_table_compressed]\n \t// [START bigquery_extract_table_json]\n-\t// [START bigquery_get_dataset]\n-\t// [START bigquery_get_dataset_labels]\n \t// [START bigquery_get_job]\n-\t// [START bigquery_get_model]\n \t// [START bigquery_get_table]\n \t// [START bigquery_get_table_labels]\n \t// [START bigquery_get_view]\n \t// [START bigquery_grant_view_access]\n-\t// [START bigquery_label_dataset]\n \t// [START bigquery_label_table]\n-\t// [START bigquery_list_datasets]\n-\t// [START bigquery_list_datasets_by_label]\n \t// [START bigquery_list_jobs]\n-\t// [START bigquery_list_models]\n \t// [START bigquery_list_tables]\n \t// [START bigquery_load_from_file]\n \t// [START bigquery_load_table_clustered]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -100,11 +89,7 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_relax_column_query_append]\n \t// [START bigquery_table_insert_rows]\n \t// [START bigquery_undelete_table]\n-\t// [START bigquery_update_dataset_access]\n-\t// [START bigquery_update_dataset_description]\n-\t// [START bigquery_update_dataset_expiration]\n \t// [START bigquery_update_table_cmek]\n-\t// [START bigquery_update_model_description]\n \t// [START bigquery_update_table_description]\n \t// [START bigquery_update_table_expiration]\n \t// [START bigquery_update_view_query]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -121,34 +106,23 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_copy_table]\n \t// [END bigquery_copy_table_cmek]\n \t// [END bigquery_copy_table_multiple_source]\n-\t// [END bigquery_create_dataset]\n \t// [END bigquery_create_table]\n \t// [END bigquery_create_table_clustered]\n \t// [END bigquery_create_table_cmek]\n \t// [END bigquery_create_table_partitioned]\n \t// [END bigquery_create_view]\n-\t// [END bigquery_delete_dataset]\n-\t// [END bigquery_delete_label_dataset]\n \t// [END bigquery_delete_label_table]\n-\t// [END bigquery_delete_model]\n \t// [END bigquery_delete_table]\n \t// [END bigquery_extract_table]\n \t// [END bigquery_extract_table_compressed]\n \t// [END bigquery_extract_table_json]\n-\t// [END bigquery_get_dataset]\n-\t// [END bigquery_get_dataset_labels]\n \t// [END bigquery_get_job]\n-\t// [END bigquery_get_model]\n \t// [END bigquery_get_table]\n \t// [END bigquery_get_table_labels]\n \t// [END bigquery_get_view]\n \t// [END bigquery_grant_view_access]\n-\t// [END bigquery_label_dataset]\n \t// [END bigquery_label_table]\n-\t// [END bigquery_list_datasets]\n-\t// [END bigquery_list_datasets_by_label]\n \t// [END bigquery_list_jobs]\n-\t// [END bigquery_list_models]\n \t// [END bigquery_list_tables]\n \t// [END bigquery_load_from_file]\n \t// [END bigquery_load_table_clustered]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -183,11 +157,7 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_relax_column_query_append]\n \t// [END bigquery_table_insert_rows]\n \t// [END bigquery_undelete_table]\n-\t// [END bigquery_update_dataset_access]\n-\t// [END bigquery_update_model_description]\n \t// [END bigquery_update_table_cmek]\n-\t// [END bigquery_update_dataset_description]\n-\t// [END bigquery_update_dataset_expiration]\n \t// [END bigquery_update_table_description]\n \t// [END bigquery_update_table_expiration]\n \t// [END bigquery_update_view_query]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -204,19 +174,6 @@\nfunc cancelJob(client *bigquery.Client, jobID string) error {\n \t// [END bigquery_cancel_job]\n }\n \n-func createDataset(client *bigquery.Client, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_create_dataset]\n-\tmeta := &bigquery.DatasetMetadata{\n-\t\tLocation: \"US\", // Create the dataset in the US.\n-\t}\n-\tif err := client.Dataset(datasetID).Create(ctx, meta); err != nil {\n-\t\treturn err\n-\t}\n-\t// [END bigquery_create_dataset]\n-\treturn nil\n-}\n-\n func createView(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_create_view]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -233,199 +190,6 @@\nfunc createView(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n-func updateDatasetDescription(client *bigquery.Client, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_update_dataset_description]\n-\tds := client.Dataset(datasetID)\n-\tmeta, err := ds.Metadata(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tupdate := bigquery.DatasetMetadataToUpdate{\n-\t\tDescription: \"Updated Description.\",\n-\t}\n-\tif _, err = ds.Update(ctx, update, meta.ETag); err != nil {\n-\t\treturn err\n-\t}\n-\t// [END bigquery_update_dataset_description]\n-\treturn nil\n-}\n-\n-func updateDatasetDefaultExpiration(client *bigquery.Client, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_update_dataset_expiration]\n-\tds := client.Dataset(datasetID)\n-\tmeta, err := ds.Metadata(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tupdate := bigquery.DatasetMetadataToUpdate{\n-\t\tDefaultTableExpiration: 24 * time.Hour,\n-\t}\n-\tif _, err := client.Dataset(datasetID).Update(ctx, update, meta.ETag); err != nil {\n-\t\treturn err\n-\t}\n-\t// [END bigquery_update_dataset_expiration]\n-\treturn nil\n-}\n-\n-func updateDatasetAccessControl(client *bigquery.Client, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_update_dataset_access]\n-\tds := client.Dataset(datasetID)\n-\tmeta, err := ds.Metadata(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\t// Append a new access control entry to the existing access list.\n-\tupdate := bigquery.DatasetMetadataToUpdate{\n-\t\tAccess: append(meta.Access, &bigquery.AccessEntry{\n-\t\t\tRole:       bigquery.ReaderRole,\n-\t\t\tEntityType: bigquery.UserEmailEntity,\n-\t\t\tEntity:     \"sample.bigquery.dev@gmail.com\"},\n-\t\t),\n-\t}\n-\n-\t// Leverage the ETag for the update to assert there's been no modifications to the\n-\t// dataset since the metadata was originally read.\n-\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n-\t\treturn err\n-\t}\n-\t// [END bigquery_update_dataset_access]\n-\treturn nil\n-}\n-\n-func datasetLabels(client *bigquery.Client, w io.Writer, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_get_dataset_labels]\n-\tmeta, err := client.Dataset(datasetID).Metadata(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tfmt.Fprintf(w, \"Dataset %s labels:\\n\", datasetID)\n-\tif len(meta.Labels) == 0 {\n-\t\tfmt.Fprintln(w, \"Dataset has no labels defined.\")\n-\t\treturn nil\n-\t}\n-\tfor k, v := range meta.Labels {\n-\t\tfmt.Fprintf(w, \"\\t%s:%s\\n\", k, v)\n-\t}\n-\t// [END bigquery_get_dataset_labels]\n-\treturn nil\n-}\n-\n-func addDatasetLabel(client *bigquery.Client, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_label_dataset]\n-\tds := client.Dataset(datasetID)\n-\tmeta, err := ds.Metadata(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\tupdate := bigquery.DatasetMetadataToUpdate{}\n-\tupdate.SetLabel(\"color\", \"green\")\n-\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n-\t\treturn err\n-\t}\n-\t// [END bigquery_label_dataset]\n-\treturn nil\n-}\n-\n-func deleteDatasetLabel(client *bigquery.Client, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_delete_label_dataset]\n-\tds := client.Dataset(datasetID)\n-\tmeta, err := ds.Metadata(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tupdate := bigquery.DatasetMetadataToUpdate{}\n-\tupdate.DeleteLabel(\"color\")\n-\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n-\t\treturn err\n-\t}\n-\t// [END bigquery_delete_label_dataset]\n-\treturn nil\n-}\n-\n-func deleteEmptyDataset(client *bigquery.Client, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_delete_dataset]\n-\tif err := client.Dataset(datasetID).Delete(ctx); err != nil {\n-\t\treturn fmt.Errorf(\"Failed to delete dataset: %v\", err)\n-\t}\n-\t// [END bigquery_delete_dataset]\n-\treturn nil\n-}\n-\n-func listDatasets(client *bigquery.Client, w io.Writer) error {\n-\tctx := context.Background()\n-\t// [START bigquery_list_datasets]\n-\tit := client.Datasets(ctx)\n-\tfor {\n-\t\tdataset, err := it.Next()\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tfmt.Fprintln(w, dataset.DatasetID)\n-\t}\n-\t// [END bigquery_list_datasets]\n-\treturn nil\n-}\n-\n-func listDatasetsByLabel(client *bigquery.Client, w io.Writer) error {\n-\tctx := context.Background()\n-\t// [START bigquery_list_datasets_by_label]\n-\tit := client.Datasets(ctx)\n-\tit.Filter = \"labels.color:green\"\n-\tfor {\n-\t\tdataset, err := it.Next()\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"dataset: %s\\n\", dataset.DatasetID)\n-\t}\n-\t// [END bigquery_list_datasets_by_label]\n-\treturn nil\n-}\n-\n-func printDatasetInfo(client *bigquery.Client, w io.Writer, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_get_dataset]\n-\tmeta, err := client.Dataset(datasetID).Metadata(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\tfmt.Fprintf(w, \"Dataset ID: %s\\n\", datasetID)\n-\tfmt.Fprintf(w, \"Description: %s\\n\", meta.Description)\n-\tfmt.Fprintln(w, \"Labels:\")\n-\tfor k, v := range meta.Labels {\n-\t\tfmt.Fprintf(w, \"\\t%s: %s\", k, v)\n-\t}\n-\tfmt.Fprintln(w, \"Tables:\")\n-\tit := client.Dataset(datasetID).Tables(ctx)\n-\n-\tcnt := 0\n-\tfor {\n-\t\tt, err := it.Next()\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tcnt++\n-\t\tfmt.Fprintf(w, \"\\t%s\\n\", t.TableID)\n-\t}\n-\tif cnt == 0 {\n-\t\tfmt.Fprintln(w, \"\\tThis dataset does not contain any tables.\")\n-\t}\n-\t// [END bigquery_get_dataset]\n-\treturn nil\n-}\n-\n func listJobs(client *bigquery.Client, w io.Writer) error {\n \tctx := context.Background()\n \t// [START bigquery_list_jobs]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -825,24 +589,6 @@\nfunc updateTableChangeCMEK(client *bigquery.Client, datasetID, tableID string) e\n \treturn nil\n }\n \n-func updateModelDescription(client *bigquery.Client, datasetID, modelID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_update_model_description]\n-\tmodel := client.Dataset(datasetID).Model(modelID)\n-\toldMeta, err := model.Metadata(ctx)\n-\tif err != nil {\n-\t\treturn fmt.Errorf(\"Metadata: %v\", err)\n-\t}\n-\tupdate := bigquery.ModelMetadataToUpdate{\n-\t\tDescription: \"This model was modified from a Go program\",\n-\t}\n-\tif _, err = model.Update(ctx, update, oldMeta.ETag); err != nil {\n-\t\treturn fmt.Errorf(\"Update: %v\", err)\n-\t}\n-\t// [END bigquery_update_model_description]\n-\treturn nil\n-}\n-\n func updateTableDescription(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_table_description]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1013,25 +759,6 @@\nfunc deleteTableLabel(client *bigquery.Client, datasetID, tableID string) error\n \treturn nil\n }\n \n-func listModels(client *bigquery.Client, w io.Writer, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_list_models]\n-\tfmt.Fprintf(w, \"Models contained in dataset '%s'\\n\", datasetID)\n-\tit := client.Dataset(datasetID).Models(ctx)\n-\tfor {\n-\t\tm, err := it.Next()\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"Model: %s\\n\", m.FullyQualifiedName())\n-\t}\n-\t// [END bigquery_list_models]\n-\treturn nil\n-}\n-\n func listTables(client *bigquery.Client, w io.Writer, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_list_tables]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1370,18 +1097,6 @@\nfunc printTableInfo(client *bigquery.Client, w io.Writer, datasetID, tableID str\n \treturn nil\n }\n \n-func printModelInfo(client *bigquery.Client, w io.Writer, datasetID, modelID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_get_model]\n-\tmeta, err := client.Dataset(datasetID).Model(modelID).Metadata(ctx)\n-\tif err != nil {\n-\t\treturn fmt.Errorf(\"Metadata: %v\", err)\n-\t}\n-\tfmt.Fprintf(w, \"Got model '%q' with friendly name '%q'\\n\", modelID, meta.Name)\n-\t// [END bigquery_get_model]\n-\treturn nil\n-}\n-\n func browseTable(client *bigquery.Client, w io.Writer, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_browse_table]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -65,61 +65,14 @@\nfunc TestAll(t *testing.T) {\n \t}\n \n \tdatasetID := uniqueBQName(\"golang_example_dataset\")\n-\tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n+\tif err := client.Dataset(datasetID).Create(ctx, &bigquery.DatasetMetadata{\n+\t\tLocation: \"US\",\n+\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", datasetID, err)\n \t}\n \t// Cleanup dataset at end of test.\n \tdefer client.Dataset(datasetID).DeleteWithContents(ctx)\n \n-\tif err := updateDatasetAccessControl(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDataSetAccessControl(%q): %v\", datasetID, err)\n-\t}\n-\tif err := addDatasetLabel(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n-\t}\n-\n-\tbuf := &bytes.Buffer{}\n-\tif err := datasetLabels(client, buf, datasetID); err != nil {\n-\t\tt.Errorf(\"getDatasetLabels(%q): %v\", datasetID, err)\n-\t}\n-\twant := \"color:green\"\n-\tif got := buf.String(); !strings.Contains(got, want) {\n-\t\tt.Errorf(\"getDatasetLabel(%q) expected %q to contain %q\", datasetID, got, want)\n-\t}\n-\n-\tif err := addDatasetLabel(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n-\t}\n-\tbuf.Reset()\n-\tif err := listDatasetsByLabel(client, buf); err != nil {\n-\t\tt.Errorf(\"listDatasetsByLabel: %v\", err)\n-\t}\n-\tif got := buf.String(); !strings.Contains(got, datasetID) {\n-\t\tt.Errorf(\"listDatasetsByLabel expected %q to contain %q\", got, want)\n-\t}\n-\tif err := deleteDatasetLabel(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetDeleteLabel: %v\", err)\n-\t}\n-\n-\t// Test empty dataset creation/ttl/delete.\n-\tdeletionDatasetID := uniqueBQName(\"golang_example_quickdelete\")\n-\tif err := createDataset(client, deletionDatasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", deletionDatasetID, err)\n-\t}\n-\tif err = updateDatasetDefaultExpiration(client, deletionDatasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetDefaultExpiration(%q): %v\", deletionDatasetID, err)\n-\t}\n-\tif err := deleteEmptyDataset(client, deletionDatasetID); err != nil {\n-\t\tt.Errorf(\"deleteEmptyDataset(%q): %v\", deletionDatasetID, err)\n-\t}\n-\n-\tif err := updateDatasetDescription(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetDescription(%q): %v\", datasetID, err)\n-\t}\n-\tif err := listDatasets(client, ioutil.Discard); err != nil {\n-\t\tt.Errorf(\"listDatasets: %v\", err)\n-\t}\n-\n \tinferred := uniqueBQName(\"golang_example_table_inferred\")\n \texplicit := uniqueBQName(\"golang_example_table_explicit\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -171,7 +124,7 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"updateTableAddLabel(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n \n-\tbuf.Reset()\n+\tbuf := &bytes.Buffer{}\n \tif err := listTables(client, buf, datasetID); err != nil {\n \t\tt.Errorf(\"listTables(%q): %v\", datasetID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -183,10 +136,6 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"want table list %q to contain table %q\", got, explicit)\n \t}\n \n-\tif err := printDatasetInfo(client, ioutil.Discard, datasetID); err != nil {\n-\t\tt.Errorf(\"printDatasetInfo: %v\", err)\n-\t}\n-\n \t// Stream data, read, query the inferred schema table.\n \tif err := insertRows(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"insertRows(dataset:%q table:%q): %v\", datasetID, inferred, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -298,14 +247,22 @@\nfunc TestViews(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\n \tsrcDatasetID := uniqueBQName(\"golang_example_view_source\")\n-\tif err := createDataset(client, srcDatasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", srcDatasetID, err)\n+\tif err := client.Dataset(srcDatasetID).Create(ctx,\n+\t\t&bigquery.DatasetMetadata{\n+\t\t\tLocation: \"US\",\n+\t\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", srcDatasetID, err)\n \t}\n \tdefer client.Dataset(srcDatasetID).DeleteWithContents(ctx)\n+\n \tviewDatasetID := uniqueBQName(\"golang_example_view_container\")\n-\tif err := createDataset(client, viewDatasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", viewDatasetID, err)\n+\tif err := client.Dataset(viewDatasetID).Create(ctx,\n+\t\t&bigquery.DatasetMetadata{\n+\t\t\tLocation: \"US\",\n+\t\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", viewDatasetID, err)\n \t}\n \tdefer client.Dataset(viewDatasetID).DeleteWithContents(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -344,8 +301,11 @@\nfunc TestImportExport(t *testing.T) {\n \n \tdatasetID := uniqueBQName(\"golang_example_dataset_importexport\")\n \ttableID := uniqueBQName(\"golang_example_dataset_importexport\")\n-\tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n+\tif err := client.Dataset(datasetID).Create(ctx,\n+\t\t&bigquery.DatasetMetadata{\n+\t\t\tLocation: \"US\",\n+\t\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", datasetID, err)\n \t}\n \tdefer client.Dataset(datasetID).DeleteWithContents(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -469,8 +429,10 @@\nfunc TestPartitioningAndClustering(t *testing.T) {\n \t}\n \n \tdatasetID := uniqueBQName(\"golang_example_dataset_partition_cluster\")\n-\tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n+\tif err := client.Dataset(datasetID).Create(ctx, &bigquery.DatasetMetadata{\n+\t\tLocation: \"US\",\n+\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", datasetID, err)\n \t}\n \tdefer client.Dataset(datasetID).DeleteWithContents(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "container_registry/container_analysis/create_note.go",
        "code_diff": "@@ -29,7 +29,7 @@\nfunc createNote(noteID, projectID string) (*grafeaspb.Note, error) {\n \tctx := context.Background()\n \tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"NewClient: %v\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "container_registry/container_analysis/create_occurrence.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc createOccurrence(resourceURL, noteID, occProjectID, noteProjectID string) (\n \tctx := context.Background()\n \tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"NewClient: %v\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -220,6 +220,11 @@\nfunc TestOccurrencesForNote(t *testing.T) {\n \n func TestPubSub(t *testing.T) {\n \tv := setup(t)\n+\t// Create a new Topic if needed\n+\tclient, _ := pubsub.NewClient(v.ctx, v.projectID)\n+\ttopicID := \"container-analysis-occurrences-v1\"\n+\tclient.CreateTopic(v.ctx, topicID)\n+\n \t// Create a new subscription if it doesn't exist.\n \tcreateOccurrenceSubscription(v.subID, v.projectID)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -251,7 +256,6 @@\nfunc TestPubSub(t *testing.T) {\n \t})\n \n \t// Clean up\n-\tclient, _ := pubsub.NewClient(v.ctx, v.projectID)\n \tsub := client.Subscription(v.subID)\n \tsub.Delete(v.ctx)\n \tteardown(t, v)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -294,7 +298,7 @@\nfunc TestPollDiscoveryOccurrenceFinished(t *testing.T) {\n \tctx := context.Background()\n \tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n-\t\tt.Errorf(\"containeranalysis.NewGrafeasV1Beta1Client: %v\", err)\n+\t\tt.Errorf(\"containeranalysis.NewClient: %v\", err)\n \t}\n \tdefer client.Close()\n \t_, err = client.GetGrafeasClient().CreateNote(ctx, noteReq)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -385,10 +389,10 @@\nfunc TestFindHighVulnerabilities(t *testing.T) {\n \t\t\t\t\t\t{\n \t\t\t\t\t\t\tAffectedCpeUri:  \"your-uri-here\",\n \t\t\t\t\t\t\tAffectedPackage: \"your-package-here\",\n-\t\t\t\t\t\t\tMinAffectedVersion: &grafeaspb.Version{\n+\t\t\t\t\t\t\tAffectedVersionStart: &grafeaspb.Version{\n \t\t\t\t\t\t\t\tKind: grafeaspb.Version_MINIMUM,\n \t\t\t\t\t\t\t},\n-\t\t\t\t\t\t\tFixedVersion: &grafeaspb.Version{\n+\t\t\t\t\t\t\tAffectedVersionEnd: &grafeaspb.Version{\n \t\t\t\t\t\t\t\tKind: grafeaspb.Version_MAXIMUM,\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "dlp/dlp_snippets/deid_test.go",
        "code_diff": "@@ -46,11 +46,14 @@\nfunc TestMask(t *testing.T) {\n \t\t},\n \t}\n \tfor _, test := range tests {\n-\t\tbuf := new(bytes.Buffer)\n-\t\tmask(buf, client, projectID, test.input, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, test.maskingCharacter, test.numberToMask)\n-\t\tif got := buf.String(); got != test.want {\n-\t\t\tt.Errorf(\"mask(%q, %s, %v) = %q, want %q\", test.input, test.maskingCharacter, test.numberToMask, got, test.want)\n-\t\t}\n+\t\tt.Run(test.input, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tmask(buf, client, projectID, test.input, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, test.maskingCharacter, test.numberToMask)\n+\t\t\tif got := buf.String(); got != test.want {\n+\t\t\t\tt.Errorf(\"mask(%q, %s, %v) = %q, want %q\", test.input, test.maskingCharacter, test.numberToMask, got, test.want)\n+\t\t\t}\n+\t\t})\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -47,24 +47,27 @@\nfunc TestInspectString(t *testing.T) {\n \t\t},\n \t}\n \tfor _, test := range tests {\n-\t\tbuf := new(bytes.Buffer)\n-\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, test.s)\n-\t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n-\t\t\tif test.want {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n-\t\t\t} else {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n+\t\tt.Run(test.s, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, test.s)\n+\t\t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n+\t\t\t\tif test.want {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n+\t\t\t\t} else {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n+\t\t\t\t}\n \t\t\t}\n-\t\t}\n-\t\tbuf.Reset()\n-\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, test.s)\n-\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n-\t\t\tif test.want {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n-\t\t\t} else {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\tbuf.Reset()\n+\t\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, test.s)\n+\t\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n+\t\t\t\tif test.want {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n+\t\t\t\t} else {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\t\t}\n \t\t\t}\n-\t\t}\n+\t\t})\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -83,24 +86,27 @@\nfunc TestInspectFile(t *testing.T) {\n \t\t},\n \t}\n \tfor _, test := range tests {\n-\t\tbuf := new(bytes.Buffer)\n-\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n-\t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n-\t\t\tif test.want {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n-\t\t\t} else {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n+\t\tt.Run(test.s, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n+\t\t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n+\t\t\t\tif test.want {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n+\t\t\t\t} else {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n+\t\t\t\t}\n \t\t\t}\n-\t\t}\n-\t\tbuf.Reset()\n-\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n-\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n-\t\t\tif test.want {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n-\t\t\t} else {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\tbuf.Reset()\n+\t\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n+\t\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n+\t\t\t\tif test.want {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n+\t\t\t\t} else {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\t\t}\n \t\t\t}\n-\t\t}\n+\t\t})\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -171,11 +177,14 @@\nfunc TestInspectGCS(t *testing.T) {\n \t\t},\n \t}\n \tfor _, test := range tests {\n-\t\tbuf := new(bytes.Buffer)\n-\t\tinspectGCSFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, inspectTopicName, inspectSubscriptionName, bucketName, test.fileName)\n-\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\tt.Errorf(\"inspectString(%s) = %q, want %q substring\", test.fileName, got, test.want)\n-\t\t}\n+\t\tt.Run(test.fileName, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectGCSFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, inspectTopicName, inspectSubscriptionName, bucketName, test.fileName)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want %q substring\", test.fileName, got, test.want)\n+\t\t\t}\n+\t\t})\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -231,11 +240,14 @@\nfunc TestInspectDatastore(t *testing.T) {\n \t\t},\n \t}\n \tfor _, test := range tests {\n-\t\tbuf := new(bytes.Buffer)\n-\t\tinspectDatastore(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, inspectTopicName, inspectSubscriptionName, projectID, \"\", test.kind)\n-\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n-\t\t}\n+\t\tt.Run(test.kind, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectDatastore(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, inspectTopicName, inspectSubscriptionName, projectID, \"\", test.kind)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n+\t\t\t}\n+\t\t})\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "docs/appengine/mail/mailgun/mailgun.go",
        "code_diff": "@@ -18,8 +18,7 @@\nimport (\n \t\"fmt\"\n \t\"net/http\"\n \n-\t\"github.com/mailgun/mailgun-go\"\n-\n+\tmailgun \"github.com/mailgun/mailgun-go/v3\"\n \t\"google.golang.org/appengine\"\n \t\"google.golang.org/appengine/urlfetch\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "docs/appengine/mail/mailgun/mailgun.go",
        "code_diff": "@@ -34,7 +33,7 @@\nfunc SendSimpleMessageHandler(w http.ResponseWriter, r *http.Request) {\n \t)\n \tmg.SetClient(httpc)\n \n-\tmsg, id, err := mg.Send(mg.NewMessage(\n+\tmsg, id, err := mg.Send(appengine.NewContext(r), mg.NewMessage(\n \t\t/* From */ \"Excited User <mailgun@YOUR_DOMAIN_NAME>\",\n \t\t/* Subject */ \"Hello\",\n \t\t/* Body */ \"Testing some Mailgun awesomness!\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "functions/imagemagick/imagemagick.go",
        "code_diff": "@@ -14,8 +14,8 @@\n// [START functions_imagemagick_setup]\n \n-// Package imagemagick contains an example of using ImageMagick from a Cloud\n-// Function.\n+// Package imagemagick contains an example of using ImageMagick to process a\n+// file uploaded to Cloud Storage.\n package imagemagick\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START getting_started_background_translate]\n+// [START getting_started_background_translate_setup]\n \n // Package background contains a Cloud Function to translate text.\n // The function listens to Pub/Sub, does the translations, and stores the",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -55,8 +55,13 @@\ntype PubSubMessage struct {\n \tData []byte `json:\"data\"`\n }\n \n-// Translate translates the given message and stores the result in Firestore.\n-func Translate(ctx context.Context, m PubSubMessage) error {\n+// [END getting_started_background_translate_setup]\n+\n+// [START getting_started_background_translate_init]\n+\n+// initializeClients creates translateClient and firestoreClient if they haven't\n+// been created yet.\n+func initializeClients() error {\n \tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tif projectID == \"\" {\n \t\treturn fmt.Errorf(\"GOOGLE_CLOUD_PROJECT must be set\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -80,6 +85,42 @@\nfunc Translate(ctx context.Context, m PubSubMessage) error {\n \t\t\treturn fmt.Errorf(\"firestore.NewClient: %v\", err)\n \t\t}\n \t}\n+\treturn nil\n+}\n+\n+// [END getting_started_background_translate_init]\n+\n+// [START getting_started_background_translate_string]\n+\n+// translateString translates text to lang, returning:\n+// * the translated text,\n+// * the automatically detected source language, and\n+// * an error.\n+func translateString(ctx context.Context, text string, lang string) (translated string, originalLang string, err error) {\n+\tl, err := language.Parse(lang)\n+\tif err != nil {\n+\t\treturn \"\", \"\", fmt.Errorf(\"language.Parse: %v\", err)\n+\t}\n+\n+\touts, err := translateClient.Translate(ctx, []string{text}, l, nil)\n+\tif err != nil {\n+\t\treturn \"\", \"\", fmt.Errorf(\"Translate: %v\", err)\n+\t}\n+\n+\tif len(outs) < 1 {\n+\t\treturn \"\", \"\", fmt.Errorf(\"Translate got %d translations, need at least 1\", len(outs))\n+\t}\n+\n+\treturn outs[0].Text, outs[0].Source.String(), nil\n+}\n+\n+// [END getting_started_background_translate_string]\n+\n+// [START getting_started_background_translate]\n+\n+// Translate translates the given message and stores the result in Firestore.\n+func Translate(ctx context.Context, m PubSubMessage) error {\n+\tinitializeClients()\n \n \tt := Translation{}\n \tif err := json.Unmarshal(m.Data, &t); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -96,6 +137,7 @@\nfunc Translate(ctx context.Context, m PubSubMessage) error {\n \tdocName = strings.Replace(docName, \"/\", \"-\", -1)\n \tref := firestoreClient.Collection(\"translations\").Doc(docName)\n \n+\t// Run in a transation to prevent concurrent duplicate translations.\n \terr := firestoreClient.RunTransaction(ctx, func(ctx context.Context, tx *firestore.Transaction) error {\n \t\tdoc, err := tx.Get(ref)\n \t\tif err != nil && status.Code(err) != codes.NotFound {",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "healthcare/dataset_deidentify.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage snippets\n \n-// [START healthcare_deidentify_dataset]\n+// [START healthcare_dicom_keeplist_deidentify_dataset]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "healthcare/dicom_export.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage snippets\n \n-// [START healthcare_export_dicom_instance]\n+// [START healthcare_export_dicom_instance_gcs]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -18,13 +18,26 @@\nimport (\n \t\"bytes\"\n \t\"fmt\"\n \t\"io/ioutil\"\n+\t\"os\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n+// The studyUID, seriesUID, and instanceUID are hard-coded into\n+// the metadata of the DICOM file and make up the DicomWebPath\n+// in the requests to retrieve studies/instances/frames/rendered.\n+const (\n+\tstudyUID           = \"studies/1.3.6.1.4.1.11129.5.5.111396399361969898205364400549799252857604/\"\n+\tseriesUID          = \"series/1.3.6.1.4.1.11129.5.5.195628213694300498946760767481291263511724/\"\n+\tinstanceUID        = \"instances/1.3.6.1.4.1.11129.5.5.153751009835107614666834563294684339746480/\"\n+\tstudyOutputFile    = \"study.multipart\"\n+\tinstanceOutputFile = \"instance.dcm\"\n+\trenderedOutputFile = \"rendered_image.png\"\n+)\n+\n // TestDICOMStore runs all DICOM store tests to avoid having to\n // create/delete DICOM stores for every sample function that needs to be\n // tested.",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -74,7 +87,7 @@\nfunc TestDICOMStore(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n-\t\tif err := dicomWebStoreInstance(ioutil.Discard, tc.ProjectID, location, datasetID, dicomStoreID, \"studies/1.3.6.1.4.1.11129.5.5.111396399361969898205364400549799252857604\", \"./testdata/dicom_00000001_000.dcm\"); err != nil {\n+\t\tif err := dicomWebStoreInstance(ioutil.Discard, tc.ProjectID, location, datasetID, dicomStoreID, studyUID, \"./testdata/dicom_00000001_000.dcm\"); err != nil {\n \t\t\tr.Errorf(\"dicomStoreInstance got err: %v\", err)\n \t\t}\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "healthcare/dicomweb_study_retrieve.go",
        "code_diff": "@@ -19,14 +19,20 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n+\t\"os\"\n \n \thealthcare \"google.golang.org/api/healthcare/v1beta1\"\n )\n \n // dicomWebRetrieveStudy retrieves all instances in the given dicomWebPath\n // study.\n-func dicomWebRetrieveStudy(w io.Writer, projectID, location, datasetID, dicomStoreID, dicomWebPath string) error {\n+func dicomWebRetrieveStudy(w io.Writer, projectID, location, datasetID, dicomStoreID, dicomWebPath string, outputFile string) error {\n+\t// projectID := \"my-project\"\n+\t// location := \"us-central1\"\n+\t// datasetID := \"my-dataset\"\n+\t// dicomStoreID := \"my-dicom-store\"\n+\t// dicomWebPath := \"studies/1.3.6.1.4.1.11129.5.5.111396399857604\"\n+\t// outputFile := \"study.multipart\"\n \tctx := context.Background()\n \n \thealthcareService, err := healthcare.NewService(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "healthcare/fhir_resource_export.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage snippets\n \n-// [START healthcare_export_fhir_resources]\n+// [START healthcare_export_fhir_resources_gcs]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "jobs/v4/howto/howto_test.go",
        "code_diff": "@@ -15,12 +15,13 @@\npackage howto\n \n import (\n+\t\"bytes\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n-\t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/gofrs/uuid\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "jobs/v4/howto/howto_test.go",
        "code_diff": "@@ -30,15 +31,14 @@\nimport (\n var testCompany *talentpb.Company\n var testJob *talentpb.Job\n \n-func TestMain(m *testing.M) {\n-\ttc, ok := testutil.ContextMain(m)\n-\tif !ok {\n-\t\tlog.Fatal(\"Error getting test context\")\n-\t}\n+func TestBasicUsage(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n \n \texternalID := fmt.Sprintf(\"company-%s\", uuid.Must(uuid.NewV4()).String())\n \tdisplayName := \"Google Sample\"\n \tvar err error\n+\n+\t// Create the company.\n \ttestCompany, err = createCompany(ioutil.Discard, tc.ProjectID, externalID, displayName)\n \tif err != nil {\n \t\tlog.Fatalf(\"createCompany: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -12,6 +12,8 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// Package kms contains samples for asymmetric keys feature of Cloud Key Management Service\n+// https://cloud.google.com/kms/\n package kms\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -67,7 +69,7 @@\nfunc getTestVariables(projectID string) TestVariables {\n \n \tsym := keyRingPath + \"/cryptoKeys/\" + symID\n \tsymVersion := sym + \"/cryptoKeyVersions/1\"\n-\trsaDecrypt := keyRingPath + \"/cryptoKeys/\" + rsaDecryptID + \"/cryptoKeyVersions/2\"\n+\trsaDecryptPath := keyRingPath + \"/cryptoKeys/\" + rsaDecryptID + \"/cryptoKeyVersions/2\"\n \trsaSign := keyRingPath + \"/cryptoKeys/\" + rsaSignID + \"/cryptoKeyVersions/1\"\n \tecSign := keyRingPath + \"/cryptoKeys/\" + ecSignID + \"/cryptoKeyVersions/1\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "monitoring/irm/irm_test.go",
        "code_diff": "@@ -35,10 +35,10 @@\nfunc TestIncident(t *testing.T) {\n \n \tbuf.Reset()\n \tif err := changeStage(buf, incident.Name); err != nil {\n-\t\tt.Errorf(\"changeStage: %v\", err)\n+\t\tt.Errorf(\"changeStage(%q): %v\", incident.Name, err)\n \t}\n \tif got, want := buf.String(), \"Changed stage\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"changeStage got\\n----\\n%s\\n----\\nWant to contain\\n----\\n%s\\n\", got, want)\n+\t\tt.Errorf(\"changeStage(%q) got\\n----\\n%s\\n----\\nWant to contain\\n----\\n%s\\n\", incident.Name, got, want)\n \t}\n \n \tbuf.Reset()",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -12,9 +12,12 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+// package subscriptions is a tool to manage Google Cloud Pub/Sub subscriptions by using the Pub/Sub API.\n+// See more about Google Cloud Pub/Sub at https://cloud.google.com/pubsub/docs/overview.\n+package subscriptions\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"sync\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -26,79 +29,85 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-var topic *pubsub.Topic\n-var subID string\n+var topicName string\n+var subName string\n \n-var once sync.Once // guards cleanup related operations in setup.\n+// once guards cleanup related operations in setup. No need to set up and tear\n+// down every time, so this speeds things up.\n+var once sync.Once\n \n func setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n+\ttopicName = tc.ProjectID + \"-test-sub-topic\"\n+\tsubName = tc.ProjectID + \"-test-sub\"\n+\tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n \n-\tsubID = tc.ProjectID + \"-test-sub\"\n-\ttopicID := tc.ProjectID + \"-test-sub-topic\"\n-\n-\t// Cleanup resources from the previous failed tests.\n+\t// Cleanup resources from the previous tests.\n \tonce.Do(func() {\n-\t\t// Create a topic.\n-\t\ttopic = client.Topic(topicID)\n+\t\ttopic := client.Topic(topicName)\n \t\tok, err := topic.Exists(ctx)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t\t}\n-\t\tif !ok {\n-\t\t\tif topic, err = client.CreateTopic(ctx, topicID); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to create the topic: %v\", err)\n+\t\tif ok {\n+\t\t\tif err := topic.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicName, err)\n \t\t\t}\n \t\t}\n-\n-\t\t// Delete the sub if already exists.\n-\t\tsub := client.Subscription(subID)\n+\t\tsub := client.Subscription(subName)\n \t\tok, err = sub.Exists(ctx)\n \t\tif err != nil {\n-\t\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n+\t\t\tt.Fatalf(\"failed to check if subscription exists: %v\", err)\n \t\t}\n \t\tif ok {\n-\t\t\tif err := client.Subscription(subID).Delete(ctx); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", subID, err)\n+\t\t\tif err := sub.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the subscription (%q): %v\", subName, err)\n \t\t\t}\n \t\t}\n \t})\n+\n \treturn client\n }\n \n func TestCreate(t *testing.T) {\n-\tc := setup(t)\n-\n-\tif err := create(c, subID, topic); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\ttopic, err := client.CreateTopic(ctx, topicName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"CreateTopic: %v\", err)\n+\t}\n+\tbuf := new(bytes.Buffer)\n+\tif err := create(buf, tc.ProjectID, subName, topic); err != nil {\n \t\tt.Fatalf(\"failed to create a subscription: %v\", err)\n \t}\n-\tok, err := c.Subscription(subID).Exists(context.Background())\n+\tok, err := client.Subscription(subName).Exists(context.Background())\n \tif err != nil {\n \t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n \t}\n \tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", subID)\n+\t\tt.Fatalf(\"got none; want sub = %q\", subName)\n \t}\n }\n \n func TestList(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tsubs, err := list(c)\n+\t\tsubs, err := list(tc.ProjectID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"failed to list subscriptions: %v\", err)\n \t\t\treturn\n \t\t}\n \n \t\tfor _, sub := range subs {\n-\t\t\tif sub.ID() == subID {\n+\t\t\tif sub.ID() == subName {\n \t\t\t\treturn // PASS\n \t\t\t}\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -107,15 +116,16 @@\nfunc TestList(t *testing.T) {\n \t\tfor i, sub := range subs {\n \t\t\tsubNames[i] = sub.ID()\n \t\t}\n-\t\tr.Errorf(\"got %+v; want a list with subscription %q\", subNames, subID)\n+\t\tr.Errorf(\"got %+v; want a list with subscription %q\", subNames, subName)\n \t})\n }\n \n func TestIAM(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tperms, err := testPermissions(c, subID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tperms, err := testPermissions(buf, tc.ProjectID, subName)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"testPermissions: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -125,15 +135,16 @@\nfunc TestIAM(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := addUsers(c, subID); err != nil {\n+\t\tif err := addUsers(tc.ProjectID, subName); err != nil {\n \t\t\tr.Errorf(\"addUsers: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tpolicy, err := getPolicy(c, subID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tpolicy, err := policy(buf, tc.ProjectID, subName)\n \t\tif err != nil {\n-\t\t\tr.Errorf(\"getPolicy: %v\", err)\n+\t\t\tr.Errorf(\"policy: %v\", err)\n \t\t}\n \t\tif role, member := iam.Editor, \"group:cloud-logs@google.com\"; !policy.HasRole(member, role) {\n \t\t\tr.Errorf(\"want %q as viewer, policy=%v\", member, policy)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -12,9 +12,12 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+// Package topics is a tool to manage Google Cloud Pub/Sub topics by using the Pub/Sub API.\n+// See more about Google Cloud Pub/Sub at https://cloud.google.com/pubsub/docs/overview.package topics\n+package topics\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"sync\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -25,63 +28,67 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-var topicID string\n+var topicName string\n \n-var once sync.Once // guards cleanup related operations in setup.\n+// once guards cleanup related operations in setup. No need to set up and tear\n+// down every time, so this speeds things up.\n+var once sync.Once\n \n func setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n-\ttopicID = tc.ProjectID + \"-test-topic\"\n-\n+\ttopicName = tc.ProjectID + \"-test-topic\"\n+\tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n \n-\t// Cleanup resources from the previous failed tests.\n+\t// Cleanup resources from the previous tests.\n \tonce.Do(func() {\n-\t\ttopic := client.Topic(topicID)\n+\t\ttopic := client.Topic(topicName)\n \t\tok, err := topic.Exists(ctx)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t\t}\n-\t\tif !ok {\n-\t\t\treturn\n-\t\t}\n-\t\tif err := topic.Delete(ctx); err != nil {\n-\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicID, err)\n+\t\tif ok {\n+\t\t\tif err := topic.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicName, err)\n+\t\t\t}\n \t\t}\n \t})\n+\n \treturn client\n }\n \n func TestCreate(t *testing.T) {\n-\tc := setup(t)\n-\tif err := create(c, topicID); err != nil {\n+\tclient := setup(t)\n+\ttc := testutil.SystemTest(t)\n+\tbuf := new(bytes.Buffer)\n+\tif err := create(buf, tc.ProjectID, topicName); err != nil {\n \t\tt.Fatalf(\"failed to create a topic: %v\", err)\n \t}\n-\tok, err := c.Topic(topicID).Exists(context.Background())\n+\tok, err := client.Topic(topicName).Exists(context.Background())\n \tif err != nil {\n-\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n+\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t}\n \tif !ok {\n-\t\tt.Fatalf(\"got none; want topic = %q\", topicID)\n+\t\tt.Fatalf(\"got none; want topic = %q\", topicName)\n \t}\n }\n \n func TestList(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\ttopics, err := list(c)\n+\t\ttopics, err := list(tc.ProjectID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"failed to list topics: %v\", err)\n \t\t}\n \n \t\tfor _, t := range topics {\n-\t\t\tif t.ID() == topicID {\n+\t\t\tif t.ID() == topicName {\n \t\t\t\treturn // PASS\n \t\t\t}\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -90,38 +97,56 @@\nfunc TestList(t *testing.T) {\n \t\tfor i, t := range topics {\n \t\t\ttopicNames[i] = t.ID()\n \t\t}\n-\t\tr.Errorf(\"got %+v; want a list with topic = %q\", topicNames, topicID)\n+\t\tr.Errorf(\"got %+v; want a list with topic = %q\", topicNames, topicName)\n \t})\n }\n \n func TestPublish(t *testing.T) {\n \t// Nothing much to do here, unless we are consuming.\n \t// TODO(jbd): Merge topics and subscriptions programs maybe?\n-\tc := setup(t)\n-\tif err := publish(c, topicID, \"hello world\"); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publish(buf, tc.ProjectID, topicName, \"hello world\"); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestPublishThatScales(t *testing.T) {\n-\tc := setup(t)\n-\tif err := publishThatScales(c, topicID, 10); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tsetup(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publishThatScales(buf, tc.ProjectID, topicName, 10); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestPublishCustomAttributes(t *testing.T) {\n-\tc := setup(t)\n-\tif err := publishCustomAttributes(c, topicID); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tsetup(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publishCustomAttributes(buf, tc.ProjectID, topicName); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestIAM(t *testing.T) {\n-\tc := setup(t)\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tperms, err := testPermissions(c, topicID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tperms, err := testPermissions(buf, tc.ProjectID, topicName)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"testPermissions: %v\", err)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -131,15 +156,16 @@\nfunc TestIAM(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := addUsers(c, topicID); err != nil {\n+\t\tif err := addUsers(tc.ProjectID, topicName); err != nil {\n \t\t\tr.Errorf(\"addUsers: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tpolicy, err := getPolicy(c, topicID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tpolicy, err := policy(buf, tc.ProjectID, topicName)\n \t\tif err != nil {\n-\t\t\tr.Errorf(\"getPolicy: %v\", err)\n+\t\t\tr.Errorf(\"policy: %v\", err)\n \t\t}\n \t\tif role, member := iam.Editor, \"group:cloud-logs@google.com\"; !policy.HasRole(member, role) {\n \t\t\tr.Errorf(\"want %q as viewer, policy=%v\", member, policy)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -15,11 +15,13 @@\npackage main\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"os\"\n+\t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "trace/trace_quickstart/main.go",
        "code_diff": "@@ -38,6 +38,16 @@\nfunc main() {\n \t}\n \ttrace.RegisterExporter(exporter)\n \n+\t// By default, traces will be sampled relatively rarely. To change the\n+\t// sampling frequency for your entire program, call ApplyConfig. Use a\n+\t// ProbabilitySampler to sample a subset of traces, or use AlwaysSample to\n+\t// collect a trace on every run.\n+\t//\n+\t// Be careful about using trace.AlwaysSample in a production application\n+\t// with significant traffic: a new trace will be started and exported for\n+\t// every request.\n+\ttrace.ApplyConfig(trace.Config{DefaultSampler: trace.AlwaysSample()})\n+\n \tclient := &http.Client{\n \t\tTransport: &ochttp.Transport{\n \t\t\t// Use Google Cloud propagation format.",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "trace/trace_quickstart/main.go",
        "code_diff": "@@ -46,7 +56,7 @@\nfunc main() {\n \t}\n \n \thandler := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n-\t\treq, _ := http.NewRequest(\"GET\", \"https://metadata/users\", nil)\n+\t\treq, _ := http.NewRequest(\"GET\", \"https://www.google.com\", nil)\n \n \t\t// The trace ID from the incoming request will be\n \t\t// propagated to the outgoing request.",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-spanner-datatypes-sample",
        "commit_id": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "run/system_package: add sample",
        "pr_number": 896,
        "file_name": "run/system_package/graphviz.go",
        "code_diff": "@@ -34,7 +34,7 @@\nfunc main() {\n \t\tlog.Fatalf(\"graphviz-web: %v\", err)\n \t}\n \tif fileInfo.Mode()&0111 == 0 {\n-\t\tlog.Fatalf(\"graphviz-web: (%q) not executable\", \"/usr/bin/dot\")\n+\t\tlog.Fatal(`graphviz-web: (\"/usr/bin/dot\") not executable`)\n \t}\n \n \thttp.HandleFunc(\"/diagram.png\", diagramHandler)",
        "comments": [
            {
                "comment": "Do this branch first, return early, and don't pre-declare `input`.\r\n\r\n```\r\nif r.Method != http.MethodGet {\r\n  // ...\r\n  return\r\n}\r\nq := r.URL.Query()\r\n// ...\r\n```\r\n\r\nhttps://github.com/golang/go/wiki/CodeReviewComments#indent-error-flow",
                "position": null
            }
        ],
        "commit_message": "run,testing: fix badfiles_test, install graphviz, skip if not installed\n\nI added graphviz to the base images (we run everything in containers) so\nwe don't have to handle Docker-in-Docker or use Cloud Build for tests.\nSo, I deleted the test.Dockerfile.",
        "commit_id": "38dce95a06b57b3cdb996f6808e2233448e5aa68"
    },
    {
        "pr_title": "run/system_package: add sample",
        "pr_number": 896,
        "file_name": "run/system_package/graphviz_test.go",
        "code_diff": "@@ -17,15 +17,21 @@\npackage main\n import (\n \t\"image\"\n \t\"io/ioutil\"\n+\t\"log\"\n \t\"net/http/httptest\"\n \t\"net/url\"\n+\t\"os\"\n \t\"strings\"\n \t\"testing\"\n \n \t_ \"image/png\"\n )\n \n func TestDiagramHandlerErrors(t *testing.T) {\n+\tcheckGraphviz(t)\n+\tlog.SetOutput(ioutil.Discard)\n+\tdefer log.SetOutput(os.Stderr)\n+\n \ttests := []struct {\n \t\tlabel       string\n \t\tdata        string",
        "comments": [],
        "commit_message": "run,testing: fix badfiles_test, install graphviz, skip if not installed\n\nI added graphviz to the base images (we run everything in containers) so\nwe don't have to handle Docker-in-Docker or use Cloud Build for tests.\nSo, I deleted the test.Dockerfile.",
        "commit_id": "38dce95a06b57b3cdb996f6808e2233448e5aa68"
    },
    {
        "pr_title": "run/system_package: add sample",
        "pr_number": 896,
        "file_name": "run/system_package/graphviz_test.go",
        "code_diff": "@@ -67,6 +73,8 @@\nfunc TestDiagramHandlerErrors(t *testing.T) {\n }\n \n func TestDiagramHandlerImage(t *testing.T) {\n+\tcheckGraphviz(t)\n+\n \ttests := []struct {\n \t\tlabel        string\n \t\tdata         string",
        "comments": [],
        "commit_message": "run,testing: fix badfiles_test, install graphviz, skip if not installed\n\nI added graphviz to the base images (we run everything in containers) so\nwe don't have to handle Docker-in-Docker or use Cloud Build for tests.\nSo, I deleted the test.Dockerfile.",
        "commit_id": "38dce95a06b57b3cdb996f6808e2233448e5aa68"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "appengine/go11x/cloudsql/cloudsql.go",
        "code_diff": "@@ -53,7 +53,8 @@\nfunc DB() *sql.DB {\n \tvar (\n \t\tconnectionName = mustGetenv(\"CLOUDSQL_CONNECTION_NAME\")\n \t\tuser           = mustGetenv(\"CLOUDSQL_USER\")\n-\t\tpassword       = os.Getenv(\"CLOUDSQL_PASSWORD\") // NOTE: password may be empty\n+\t\tdbName         = os.Getenv(\"CLOUDSQL_DATABASE_NAME\") // NOTE: dbName may be empty\n+\t\tpassword       = os.Getenv(\"CLOUDSQL_PASSWORD\")      // NOTE: password may be empty\n \t\tsocket         = os.Getenv(\"CLOUDSQL_SOCKET_PREFIX\")\n \t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -90,6 +90,13 @@\nfunc main() {\n \t\tParent:         fmt.Sprintf(\"projects/%s\", *projectID),\n \t\tTableReference: readTable,\n \t\tReadOptions:    tableReadOptions,\n+\t\t// This API can also deliver data serialized in Apache Arrow format.\n+\t\t// This example leverages Apache Avro.\n+\t\tFormat: bqStoragepb.DataFormat_AVRO,\n+\t\t// We use a LIQUID strategy in this example because we only\n+\t\t// read from a single stream.  Consider BALANCED if you're consuming\n+\t\t// multiple streams concurrently and want more consistent stream sizes.\n+\t\tShardingStrategy: bqStoragepb.ShardingStrategy_LIQUID,\n \t}\n \n \t// Set a snapshot time if it's been specified.",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/dataset/bigquery_create_dataset.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/bigquery\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/dataset/bigquery_delete_label_dataset.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/bigquery\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/dataset/bigquery_label_dataset.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/bigquery\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/dataset/bigquery_update_dataset_access.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/bigquery\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/dataset/bigquery_update_dataset_default_expiration.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"time\"\n \n \t\"cloud.google.com/go/bigquery\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/dataset/bigquery_update_dataset_description.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/bigquery\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -44,20 +44,17 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_create_table_partitioned]\n \t// [START bigquery_create_view]\n \t// [START bigquery_delete_label_table]\n-\t// [START bigquery_delete_model]\n \t// [START bigquery_delete_table]\n \t// [START bigquery_extract_table]\n \t// [START bigquery_extract_table_compressed]\n \t// [START bigquery_extract_table_json]\n \t// [START bigquery_get_job]\n-\t// [START bigquery_get_model]\n \t// [START bigquery_get_table]\n \t// [START bigquery_get_table_labels]\n \t// [START bigquery_get_view]\n \t// [START bigquery_grant_view_access]\n \t// [START bigquery_label_table]\n \t// [START bigquery_list_jobs]\n-\t// [START bigquery_list_models]\n \t// [START bigquery_list_tables]\n \t// [START bigquery_load_from_file]\n \t// [START bigquery_load_table_clustered]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -93,7 +90,6 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_table_insert_rows]\n \t// [START bigquery_undelete_table]\n \t// [START bigquery_update_table_cmek]\n-\t// [START bigquery_update_model_description]\n \t// [START bigquery_update_table_description]\n \t// [START bigquery_update_table_expiration]\n \t// [START bigquery_update_view_query]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -116,20 +112,17 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_create_table_partitioned]\n \t// [END bigquery_create_view]\n \t// [END bigquery_delete_label_table]\n-\t// [END bigquery_delete_model]\n \t// [END bigquery_delete_table]\n \t// [END bigquery_extract_table]\n \t// [END bigquery_extract_table_compressed]\n \t// [END bigquery_extract_table_json]\n \t// [END bigquery_get_job]\n-\t// [END bigquery_get_model]\n \t// [END bigquery_get_table]\n \t// [END bigquery_get_table_labels]\n \t// [END bigquery_get_view]\n \t// [END bigquery_grant_view_access]\n \t// [END bigquery_label_table]\n \t// [END bigquery_list_jobs]\n-\t// [END bigquery_list_models]\n \t// [END bigquery_list_tables]\n \t// [END bigquery_load_from_file]\n \t// [END bigquery_load_table_clustered]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -164,7 +157,6 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_relax_column_query_append]\n \t// [END bigquery_table_insert_rows]\n \t// [END bigquery_undelete_table]\n-\t// [END bigquery_update_model_description]\n \t// [END bigquery_update_table_cmek]\n \t// [END bigquery_update_table_description]\n \t// [END bigquery_update_table_expiration]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -597,24 +589,6 @@\nfunc updateTableChangeCMEK(client *bigquery.Client, datasetID, tableID string) e\n \treturn nil\n }\n \n-func updateModelDescription(client *bigquery.Client, datasetID, modelID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_update_model_description]\n-\tmodel := client.Dataset(datasetID).Model(modelID)\n-\toldMeta, err := model.Metadata(ctx)\n-\tif err != nil {\n-\t\treturn fmt.Errorf(\"Metadata: %v\", err)\n-\t}\n-\tupdate := bigquery.ModelMetadataToUpdate{\n-\t\tDescription: \"This model was modified from a Go program\",\n-\t}\n-\tif _, err = model.Update(ctx, update, oldMeta.ETag); err != nil {\n-\t\treturn fmt.Errorf(\"Update: %v\", err)\n-\t}\n-\t// [END bigquery_update_model_description]\n-\treturn nil\n-}\n-\n func updateTableDescription(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_table_description]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -785,25 +759,6 @@\nfunc deleteTableLabel(client *bigquery.Client, datasetID, tableID string) error\n \treturn nil\n }\n \n-func listModels(client *bigquery.Client, w io.Writer, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_list_models]\n-\tfmt.Fprintf(w, \"Models contained in dataset '%s'\\n\", datasetID)\n-\tit := client.Dataset(datasetID).Models(ctx)\n-\tfor {\n-\t\tm, err := it.Next()\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"Model: %s\\n\", m.FullyQualifiedName())\n-\t}\n-\t// [END bigquery_list_models]\n-\treturn nil\n-}\n-\n func listTables(client *bigquery.Client, w io.Writer, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_list_tables]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1142,18 +1097,6 @@\nfunc printTableInfo(client *bigquery.Client, w io.Writer, datasetID, tableID str\n \treturn nil\n }\n \n-func printModelInfo(client *bigquery.Client, w io.Writer, datasetID, modelID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_get_model]\n-\tmeta, err := client.Dataset(datasetID).Model(modelID).Metadata(ctx)\n-\tif err != nil {\n-\t\treturn fmt.Errorf(\"Metadata: %v\", err)\n-\t}\n-\tfmt.Fprintf(w, \"Got model '%q' with friendly name '%q'\\n\", modelID, meta.Name)\n-\t// [END bigquery_get_model]\n-\treturn nil\n-}\n-\n func browseTable(client *bigquery.Client, w io.Writer, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_browse_table]",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "container_registry/container_analysis/create_note.go",
        "code_diff": "@@ -29,7 +29,7 @@\nfunc createNote(noteID, projectID string) (*grafeaspb.Note, error) {\n \tctx := context.Background()\n \tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"NewClient: %v\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "container_registry/container_analysis/create_occurrence.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc createOccurrence(resourceURL, noteID, occProjectID, noteProjectID string) (\n \tctx := context.Background()\n \tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"NewClient: %v\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -220,6 +220,11 @@\nfunc TestOccurrencesForNote(t *testing.T) {\n \n func TestPubSub(t *testing.T) {\n \tv := setup(t)\n+\t// Create a new Topic if needed\n+\tclient, _ := pubsub.NewClient(v.ctx, v.projectID)\n+\ttopicID := \"container-analysis-occurrences-v1\"\n+\tclient.CreateTopic(v.ctx, topicID)\n+\n \t// Create a new subscription if it doesn't exist.\n \tcreateOccurrenceSubscription(v.subID, v.projectID)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -251,7 +256,6 @@\nfunc TestPubSub(t *testing.T) {\n \t})\n \n \t// Clean up\n-\tclient, _ := pubsub.NewClient(v.ctx, v.projectID)\n \tsub := client.Subscription(v.subID)\n \tsub.Delete(v.ctx)\n \tteardown(t, v)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -294,7 +298,7 @@\nfunc TestPollDiscoveryOccurrenceFinished(t *testing.T) {\n \tctx := context.Background()\n \tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n-\t\tt.Errorf(\"containeranalysis.NewGrafeasV1Beta1Client: %v\", err)\n+\t\tt.Errorf(\"containeranalysis.NewClient: %v\", err)\n \t}\n \tdefer client.Close()\n \t_, err = client.GetGrafeasClient().CreateNote(ctx, noteReq)",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -385,10 +389,10 @@\nfunc TestFindHighVulnerabilities(t *testing.T) {\n \t\t\t\t\t\t{\n \t\t\t\t\t\t\tAffectedCpeUri:  \"your-uri-here\",\n \t\t\t\t\t\t\tAffectedPackage: \"your-package-here\",\n-\t\t\t\t\t\t\tMinAffectedVersion: &grafeaspb.Version{\n+\t\t\t\t\t\t\tAffectedVersionStart: &grafeaspb.Version{\n \t\t\t\t\t\t\t\tKind: grafeaspb.Version_MINIMUM,\n \t\t\t\t\t\t\t},\n-\t\t\t\t\t\t\tFixedVersion: &grafeaspb.Version{\n+\t\t\t\t\t\t\tAffectedVersionEnd: &grafeaspb.Version{\n \t\t\t\t\t\t\t\tKind: grafeaspb.Version_MAXIMUM,\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START getting_started_background_translate]\n+// [START getting_started_background_translate_setup]\n \n // Package background contains a Cloud Function to translate text.\n // The function listens to Pub/Sub, does the translations, and stores the",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -55,8 +55,13 @@\ntype PubSubMessage struct {\n \tData []byte `json:\"data\"`\n }\n \n-// Translate translates the given message and stores the result in Firestore.\n-func Translate(ctx context.Context, m PubSubMessage) error {\n+// [END getting_started_background_translate_setup]\n+\n+// [START getting_started_background_translate_init]\n+\n+// initializeClients creates translateClient and firestoreClient if they haven't\n+// been created yet.\n+func initializeClients() error {\n \tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tif projectID == \"\" {\n \t\treturn fmt.Errorf(\"GOOGLE_CLOUD_PROJECT must be set\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -80,6 +85,42 @@\nfunc Translate(ctx context.Context, m PubSubMessage) error {\n \t\t\treturn fmt.Errorf(\"firestore.NewClient: %v\", err)\n \t\t}\n \t}\n+\treturn nil\n+}\n+\n+// [END getting_started_background_translate_init]\n+\n+// [START getting_started_background_translate_string]\n+\n+// translateString translates text to lang, returning:\n+// * the translated text,\n+// * the automatically detected source language, and\n+// * an error.\n+func translateString(ctx context.Context, text string, lang string) (translated string, originalLang string, err error) {\n+\tl, err := language.Parse(lang)\n+\tif err != nil {\n+\t\treturn \"\", \"\", fmt.Errorf(\"language.Parse: %v\", err)\n+\t}\n+\n+\touts, err := translateClient.Translate(ctx, []string{text}, l, nil)\n+\tif err != nil {\n+\t\treturn \"\", \"\", fmt.Errorf(\"Translate: %v\", err)\n+\t}\n+\n+\tif len(outs) < 1 {\n+\t\treturn \"\", \"\", fmt.Errorf(\"Translate got %d translations, need at least 1\", len(outs))\n+\t}\n+\n+\treturn outs[0].Text, outs[0].Source.String(), nil\n+}\n+\n+// [END getting_started_background_translate_string]\n+\n+// [START getting_started_background_translate]\n+\n+// Translate translates the given message and stores the result in Firestore.\n+func Translate(ctx context.Context, m PubSubMessage) error {\n+\tinitializeClients()\n \n \tt := Translation{}\n \tif err := json.Unmarshal(m.Data, &t); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -96,6 +137,7 @@\nfunc Translate(ctx context.Context, m PubSubMessage) error {\n \tdocName = strings.Replace(docName, \"/\", \"-\", -1)\n \tref := firestoreClient.Collection(\"translations\").Doc(docName)\n \n+\t// Run in a transation to prevent concurrent duplicate translations.\n \terr := firestoreClient.RunTransaction(ctx, func(ctx context.Context, tx *firestore.Transaction) error {\n \t\tdoc, err := tx.Get(ref)\n \t\tif err != nil && status.Code(err) != codes.NotFound {",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "healthcare/dataset_deidentify.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage snippets\n \n-// [START healthcare_deidentify_dataset]\n+// [START healthcare_dicom_keeplist_deidentify_dataset]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "healthcare/fhir_resource_export.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage snippets\n \n-// [START healthcare_export_fhir_resources]\n+// [START healthcare_export_fhir_resources_gcs]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "run/pubsub: add sample app",
        "pr_number": 895,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -228,11 +228,10 @@\nfunc publishWithSettings(client *pubsub.Client, topic string, msg []byte) error\n \tctx := context.Background()\n \t// [START pubsub_publisher_batch_settings]\n \tt := client.Topic(topic)\n-\tt.PublishSettings = pubsub.PublishSettings{\n-\t\tByteThreshold:  5000,\n-\t\tCountThreshold: 10,\n-\t\tDelayThreshold: 100 * time.Millisecond,\n-\t}\n+\tt.PublishSettings.ByteThreshold = 5000\n+\tt.PublishSettings.CountThreshold = 10\n+\tt.PublishSettings.DelayThreshold = 100 * time.Millisecond\n+\n \tresult := t.Publish(ctx, &pubsub.Message{Data: msg})\n \t// Block until the result is returned and a server-generated\n \t// ID is returned for the published message.",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-run-pubsub",
        "commit_id": "4b1154407daaa3940b2611e5b9e0af994bdcf5cf"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -38,32 +38,24 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_copy_table]\n \t// [START bigquery_copy_table_cmek]\n \t// [START bigquery_copy_table_multiple_source]\n-\t// [START bigquery_create_dataset]\n \t// [START bigquery_create_table]\n \t// [START bigquery_create_table_clustered]\n \t// [START bigquery_create_table_cmek]\n \t// [START bigquery_create_table_partitioned]\n \t// [START bigquery_create_view]\n-\t// [START bigquery_delete_dataset]\n-\t// [START bigquery_delete_label_dataset]\n \t// [START bigquery_delete_label_table]\n \t// [START bigquery_delete_model]\n \t// [START bigquery_delete_table]\n \t// [START bigquery_extract_table]\n \t// [START bigquery_extract_table_compressed]\n \t// [START bigquery_extract_table_json]\n-\t// [START bigquery_get_dataset]\n-\t// [START bigquery_get_dataset_labels]\n \t// [START bigquery_get_job]\n \t// [START bigquery_get_model]\n \t// [START bigquery_get_table]\n \t// [START bigquery_get_table_labels]\n \t// [START bigquery_get_view]\n \t// [START bigquery_grant_view_access]\n-\t// [START bigquery_label_dataset]\n \t// [START bigquery_label_table]\n-\t// [START bigquery_list_datasets]\n-\t// [START bigquery_list_datasets_by_label]\n \t// [START bigquery_list_jobs]\n \t// [START bigquery_list_models]\n \t// [START bigquery_list_tables]",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -100,9 +92,6 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_relax_column_query_append]\n \t// [START bigquery_table_insert_rows]\n \t// [START bigquery_undelete_table]\n-\t// [START bigquery_update_dataset_access]\n-\t// [START bigquery_update_dataset_description]\n-\t// [START bigquery_update_dataset_expiration]\n \t// [START bigquery_update_table_cmek]\n \t// [START bigquery_update_model_description]\n \t// [START bigquery_update_table_description]",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -121,32 +110,24 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_copy_table]\n \t// [END bigquery_copy_table_cmek]\n \t// [END bigquery_copy_table_multiple_source]\n-\t// [END bigquery_create_dataset]\n \t// [END bigquery_create_table]\n \t// [END bigquery_create_table_clustered]\n \t// [END bigquery_create_table_cmek]\n \t// [END bigquery_create_table_partitioned]\n \t// [END bigquery_create_view]\n-\t// [END bigquery_delete_dataset]\n-\t// [END bigquery_delete_label_dataset]\n \t// [END bigquery_delete_label_table]\n \t// [END bigquery_delete_model]\n \t// [END bigquery_delete_table]\n \t// [END bigquery_extract_table]\n \t// [END bigquery_extract_table_compressed]\n \t// [END bigquery_extract_table_json]\n-\t// [END bigquery_get_dataset]\n-\t// [END bigquery_get_dataset_labels]\n \t// [END bigquery_get_job]\n \t// [END bigquery_get_model]\n \t// [END bigquery_get_table]\n \t// [END bigquery_get_table_labels]\n \t// [END bigquery_get_view]\n \t// [END bigquery_grant_view_access]\n-\t// [END bigquery_label_dataset]\n \t// [END bigquery_label_table]\n-\t// [END bigquery_list_datasets]\n-\t// [END bigquery_list_datasets_by_label]\n \t// [END bigquery_list_jobs]\n \t// [END bigquery_list_models]\n \t// [END bigquery_list_tables]",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -183,11 +164,8 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_relax_column_query_append]\n \t// [END bigquery_table_insert_rows]\n \t// [END bigquery_undelete_table]\n-\t// [END bigquery_update_dataset_access]\n \t// [END bigquery_update_model_description]\n \t// [END bigquery_update_table_cmek]\n-\t// [END bigquery_update_dataset_description]\n-\t// [END bigquery_update_dataset_expiration]\n \t// [END bigquery_update_table_description]\n \t// [END bigquery_update_table_expiration]\n \t// [END bigquery_update_view_query]",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -204,19 +182,6 @@\nfunc cancelJob(client *bigquery.Client, jobID string) error {\n \t// [END bigquery_cancel_job]\n }\n \n-func createDataset(client *bigquery.Client, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_create_dataset]\n-\tmeta := &bigquery.DatasetMetadata{\n-\t\tLocation: \"US\", // Create the dataset in the US.\n-\t}\n-\tif err := client.Dataset(datasetID).Create(ctx, meta); err != nil {\n-\t\treturn err\n-\t}\n-\t// [END bigquery_create_dataset]\n-\treturn nil\n-}\n-\n func createView(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_create_view]",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -65,61 +65,14 @@\nfunc TestAll(t *testing.T) {\n \t}\n \n \tdatasetID := uniqueBQName(\"golang_example_dataset\")\n-\tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n+\tif err := client.Dataset(datasetID).Create(ctx, &bigquery.DatasetMetadata{\n+\t\tLocation: \"US\",\n+\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", datasetID, err)\n \t}\n \t// Cleanup dataset at end of test.\n \tdefer client.Dataset(datasetID).DeleteWithContents(ctx)\n \n-\tif err := updateDatasetAccessControl(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDataSetAccessControl(%q): %v\", datasetID, err)\n-\t}\n-\tif err := addDatasetLabel(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n-\t}\n-\n-\tbuf := &bytes.Buffer{}\n-\tif err := datasetLabels(client, buf, datasetID); err != nil {\n-\t\tt.Errorf(\"getDatasetLabels(%q): %v\", datasetID, err)\n-\t}\n-\twant := \"color:green\"\n-\tif got := buf.String(); !strings.Contains(got, want) {\n-\t\tt.Errorf(\"getDatasetLabel(%q) expected %q to contain %q\", datasetID, got, want)\n-\t}\n-\n-\tif err := addDatasetLabel(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n-\t}\n-\tbuf.Reset()\n-\tif err := listDatasetsByLabel(client, buf); err != nil {\n-\t\tt.Errorf(\"listDatasetsByLabel: %v\", err)\n-\t}\n-\tif got := buf.String(); !strings.Contains(got, datasetID) {\n-\t\tt.Errorf(\"listDatasetsByLabel expected %q to contain %q\", got, want)\n-\t}\n-\tif err := deleteDatasetLabel(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetDeleteLabel: %v\", err)\n-\t}\n-\n-\t// Test empty dataset creation/ttl/delete.\n-\tdeletionDatasetID := uniqueBQName(\"golang_example_quickdelete\")\n-\tif err := createDataset(client, deletionDatasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", deletionDatasetID, err)\n-\t}\n-\tif err = updateDatasetDefaultExpiration(client, deletionDatasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetDefaultExpiration(%q): %v\", deletionDatasetID, err)\n-\t}\n-\tif err := deleteEmptyDataset(client, deletionDatasetID); err != nil {\n-\t\tt.Errorf(\"deleteEmptyDataset(%q): %v\", deletionDatasetID, err)\n-\t}\n-\n-\tif err := updateDatasetDescription(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetDescription(%q): %v\", datasetID, err)\n-\t}\n-\tif err := listDatasets(client, ioutil.Discard); err != nil {\n-\t\tt.Errorf(\"listDatasets: %v\", err)\n-\t}\n-\n \tinferred := uniqueBQName(\"golang_example_table_inferred\")\n \texplicit := uniqueBQName(\"golang_example_table_explicit\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -171,7 +124,7 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"updateTableAddLabel(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n \n-\tbuf.Reset()\n+\tbuf := &bytes.Buffer{}\n \tif err := listTables(client, buf, datasetID); err != nil {\n \t\tt.Errorf(\"listTables(%q): %v\", datasetID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -183,10 +136,6 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"want table list %q to contain table %q\", got, explicit)\n \t}\n \n-\tif err := printDatasetInfo(client, ioutil.Discard, datasetID); err != nil {\n-\t\tt.Errorf(\"printDatasetInfo: %v\", err)\n-\t}\n-\n \t// Stream data, read, query the inferred schema table.\n \tif err := insertRows(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"insertRows(dataset:%q table:%q): %v\", datasetID, inferred, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -298,14 +247,22 @@\nfunc TestViews(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\n \tsrcDatasetID := uniqueBQName(\"golang_example_view_source\")\n-\tif err := createDataset(client, srcDatasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", srcDatasetID, err)\n+\tif err := client.Dataset(srcDatasetID).Create(ctx,\n+\t\t&bigquery.DatasetMetadata{\n+\t\t\tLocation: \"US\",\n+\t\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", srcDatasetID, err)\n \t}\n \tdefer client.Dataset(srcDatasetID).DeleteWithContents(ctx)\n+\n \tviewDatasetID := uniqueBQName(\"golang_example_view_container\")\n-\tif err := createDataset(client, viewDatasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", viewDatasetID, err)\n+\tif err := client.Dataset(viewDatasetID).Create(ctx,\n+\t\t&bigquery.DatasetMetadata{\n+\t\t\tLocation: \"US\",\n+\t\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", viewDatasetID, err)\n \t}\n \tdefer client.Dataset(viewDatasetID).DeleteWithContents(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -344,8 +301,11 @@\nfunc TestImportExport(t *testing.T) {\n \n \tdatasetID := uniqueBQName(\"golang_example_dataset_importexport\")\n \ttableID := uniqueBQName(\"golang_example_dataset_importexport\")\n-\tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n+\tif err := client.Dataset(datasetID).Create(ctx,\n+\t\t&bigquery.DatasetMetadata{\n+\t\t\tLocation: \"US\",\n+\t\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", datasetID, err)\n \t}\n \tdefer client.Dataset(datasetID).DeleteWithContents(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -469,8 +429,10 @@\nfunc TestPartitioningAndClustering(t *testing.T) {\n \t}\n \n \tdatasetID := uniqueBQName(\"golang_example_dataset_partition_cluster\")\n-\tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n+\tif err := client.Dataset(datasetID).Create(ctx, &bigquery.DatasetMetadata{\n+\t\tLocation: \"US\",\n+\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", datasetID, err)\n \t}\n \tdefer client.Dataset(datasetID).DeleteWithContents(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "healthcare/dataset_deidentify.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage snippets\n \n-// [START healthcare_deidentify_dataset]\n+// [START healthcare_dicom_keeplist_deidentify_dataset]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "appengine: change runtime to go112 and add comment for go111",
        "pr_number": 893,
        "file_name": "healthcare/dicom_export.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage snippets\n \n-// [START healthcare_export_dicom_instance]\n+// [START healthcare_export_dicom_instance_gcs]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "a582b630861cfc964b67d2c5fc860cf3fb53e593"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "appengine_flexible/mailgun/mailgun.go",
        "code_diff": "@@ -56,7 +56,7 @@\nfunc mustGetenv(k string) string {\n \n // [START gae_flex_mailgun_simple_message]\n func sendSimpleMessageHandler(w http.ResponseWriter, r *http.Request) {\n-\tmsg, id, err := mailgunClient.Send(mailgunClient.NewMessage(\n+\tmsg, id, err := mailgunClient.Send(r.Context(), mailgunClient.NewMessage(\n \t\t/* From */ fmt.Sprintf(\"Excited User <mailgun@%s>\", mailgunDomain),\n \t\t/* Subject */ \"Hello\",\n \t\t/* Body */ \"Testing some Mailgun awesomness!\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor",
        "commit_id": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "dlp/dlp_snippets/deid_test.go",
        "code_diff": "@@ -46,11 +46,14 @@\nfunc TestMask(t *testing.T) {\n \t\t},\n \t}\n \tfor _, test := range tests {\n-\t\tbuf := new(bytes.Buffer)\n-\t\tmask(buf, client, projectID, test.input, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, test.maskingCharacter, test.numberToMask)\n-\t\tif got := buf.String(); got != test.want {\n-\t\t\tt.Errorf(\"mask(%q, %s, %v) = %q, want %q\", test.input, test.maskingCharacter, test.numberToMask, got, test.want)\n-\t\t}\n+\t\tt.Run(test.input, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tmask(buf, client, projectID, test.input, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, test.maskingCharacter, test.numberToMask)\n+\t\t\tif got := buf.String(); got != test.want {\n+\t\t\t\tt.Errorf(\"mask(%q, %s, %v) = %q, want %q\", test.input, test.maskingCharacter, test.numberToMask, got, test.want)\n+\t\t\t}\n+\t\t})\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor",
        "commit_id": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -47,24 +47,27 @@\nfunc TestInspectString(t *testing.T) {\n \t\t},\n \t}\n \tfor _, test := range tests {\n-\t\tbuf := new(bytes.Buffer)\n-\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, test.s)\n-\t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n-\t\t\tif test.want {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n-\t\t\t} else {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n+\t\tt.Run(test.s, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, test.s)\n+\t\t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n+\t\t\t\tif test.want {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n+\t\t\t\t} else {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n+\t\t\t\t}\n \t\t\t}\n-\t\t}\n-\t\tbuf.Reset()\n-\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, test.s)\n-\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n-\t\t\tif test.want {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n-\t\t\t} else {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\tbuf.Reset()\n+\t\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, test.s)\n+\t\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n+\t\t\t\tif test.want {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n+\t\t\t\t} else {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\t\t}\n \t\t\t}\n-\t\t}\n+\t\t})\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor",
        "commit_id": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -83,24 +86,27 @@\nfunc TestInspectFile(t *testing.T) {\n \t\t},\n \t}\n \tfor _, test := range tests {\n-\t\tbuf := new(bytes.Buffer)\n-\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n-\t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n-\t\t\tif test.want {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n-\t\t\t} else {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n+\t\tt.Run(test.s, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n+\t\t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n+\t\t\t\tif test.want {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n+\t\t\t\t} else {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n+\t\t\t\t}\n \t\t\t}\n-\t\t}\n-\t\tbuf.Reset()\n-\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n-\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n-\t\t\tif test.want {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n-\t\t\t} else {\n-\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\tbuf.Reset()\n+\t\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n+\t\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n+\t\t\t\tif test.want {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n+\t\t\t\t} else {\n+\t\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\t\t}\n \t\t\t}\n-\t\t}\n+\t\t})\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor",
        "commit_id": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -171,11 +177,14 @@\nfunc TestInspectGCS(t *testing.T) {\n \t\t},\n \t}\n \tfor _, test := range tests {\n-\t\tbuf := new(bytes.Buffer)\n-\t\tinspectGCSFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, inspectTopicName, inspectSubscriptionName, bucketName, test.fileName)\n-\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\tt.Errorf(\"inspectString(%s) = %q, want %q substring\", test.fileName, got, test.want)\n-\t\t}\n+\t\tt.Run(test.fileName, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectGCSFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, inspectTopicName, inspectSubscriptionName, bucketName, test.fileName)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want %q substring\", test.fileName, got, test.want)\n+\t\t\t}\n+\t\t})\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor",
        "commit_id": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -231,11 +240,14 @@\nfunc TestInspectDatastore(t *testing.T) {\n \t\t},\n \t}\n \tfor _, test := range tests {\n-\t\tbuf := new(bytes.Buffer)\n-\t\tinspectDatastore(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, inspectTopicName, inspectSubscriptionName, projectID, \"\", test.kind)\n-\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n-\t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n-\t\t}\n+\t\tt.Run(test.kind, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectDatastore(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, inspectTopicName, inspectSubscriptionName, projectID, \"\", test.kind)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n+\t\t\t}\n+\t\t})\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor",
        "commit_id": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "docs/appengine/mail/mailgun/mailgun.go",
        "code_diff": "@@ -34,7 +34,7 @@\nfunc SendSimpleMessageHandler(w http.ResponseWriter, r *http.Request) {\n \t)\n \tmg.SetClient(httpc)\n \n-\tmsg, id, err := mg.Send(mg.NewMessage(\n+\tmsg, id, err := mg.Send(appengine.NewContext(r), mg.NewMessage(\n \t\t/* From */ \"Excited User <mailgun@YOUR_DOMAIN_NAME>\",\n \t\t/* Subject */ \"Hello\",\n \t\t/* Body */ \"Testing some Mailgun awesomness!\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor",
        "commit_id": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "healthcare/dicom_export.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage snippets\n \n-// [START healthcare_export_dicom_instance]\n+// [START healthcare_export_dicom_instance_gcs]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into refactor",
        "commit_id": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "vision/detect: delete unused sample and add subtests",
        "pr_number": 885,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -58,12 +58,11 @@\nfunc TestDetect(t *testing.T) {\n \t\tt.Run(tt.name+\"/local\", func(t *testing.T) {\n \t\t\tt.Parallel()\n \t\t\tvar buf bytes.Buffer\n-\t\t\terr := tt.local(&buf, \"../testdata/\"+tt.path)\n-\t\t\tif err != nil {\n+\t\t\tif err := tt.local(&buf, \"../testdata/\"+tt.path); err != nil {\n \t\t\t\tt.Fatalf(\"Local %s(%q): got %v, want nil err\", tt.name, tt.path, err)\n \t\t\t}\n-\t\t\tif got := buf.String(); !strings.Contains(strings.ToLower(got), strings.ToLower(tt.wantContain)) {\n-\t\t\t\tt.Errorf(\"Local %s(%q): got %q, want to contain %q\", tt.name, tt.path, got, tt.wantContain)\n+\t\t\tif got, wantContain := strings.ToLower(buf.String()), strings.ToLower(tt.wantContain); !strings.Contains(got, wantContain) {\n+\t\t\t\tt.Errorf(\"Local %s(%q): got %q, want to contain %q\", tt.name, tt.path, got, wantContain)\n \t\t\t}\n \t\t})\n \t}",
        "comments": [
            {
                "comment": "nit: `if err := [...]; err != nil { ... }`\r\n\r\n(here and elsewhere)",
                "position": null
            },
            {
                "comment": "nit: may be nicer to do:\r\n\r\n```\r\nif got, wantContains := strings.ToLower(buf.String), strings.ToLower(tt.wantContains); !strings.Contains(got, wantContains) {\r\n    ...\r\n}\r\n```\r\n\r\n(making the assertion just about asserting, and putting all the \"munge up the data into the way I want it\" into the declaration part)",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "vision/detect: address reviewer comments",
        "commit_id": "d6f0a22a6a2b3ccda6e819149ac4003c5fb32fad"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/create_note.go",
        "code_diff": "@@ -32,7 +32,7 @@\nfunc createNote(noteID, projectID string) (*grafeaspb.Note, error) {\n \t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}\n \tdefer client.Close()\n-\t\n+\n \tprojectName := fmt.Sprintf(\"projects/%s\", projectID)\n \n \treq := &grafeaspb.CreateNoteRequest{",
        "comments": [
            {
                "comment": "Looks like you need to run `gofmt -s` (there's usually a way to have your editor run it for you every time you save). Kokoro failed the `gofmt` check.\r\n\r\nIf you're running it from command line, you'll want to run `gofmt -w -s .` (write files directly, do extra simplifications, all files in this directory (recursive)).",
                "position": null
            },
            {
                "comment": "sorry, should have caught that! fixed",
                "position": null
            }
        ],
        "commit_message": "ran gofmt",
        "commit_id": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -282,10 +282,10 @@\nfunc TestPollDiscoveryOccurrenceFinished(t *testing.T) {\n \toccReq := &grafeaspb.CreateOccurrenceRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s\", v.projectID),\n \t\tOccurrence: &grafeaspb.Occurrence{\n-\t\t\tNoteName: fmt.Sprintf(\"projects/%s/notes/%s\", v.projectID, noteID),\n+\t\t\tNoteName:    fmt.Sprintf(\"projects/%s/notes/%s\", v.projectID, noteID),\n \t\t\tResourceUri: v.imageURL,\n \t\t\tDetails: &grafeaspb.Occurrence_Discovery{\n-\t\t\t\tDiscovery: &grafeaspb.DiscoveryOccurrence {\n+\t\t\t\tDiscovery: &grafeaspb.DiscoveryOccurrence{\n \t\t\t\t\tAnalysisStatus: grafeaspb.DiscoveryOccurrence_FINISHED_SUCCESS,\n \t\t\t\t},\n \t\t\t},",
        "comments": [],
        "commit_message": "ran gofmt",
        "commit_id": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -382,8 +382,8 @@\nfunc TestFindHighVulnerabilities(t *testing.T) {\n \t\t\t\tVulnerability: &grafeaspb.VulnerabilityNote{\n \t\t\t\t\tSeverity: grafeaspb.Severity_CRITICAL,\n \t\t\t\t\tDetails: []*grafeaspb.VulnerabilityNote_Detail{\n-\t\t\t\t\t\t&grafeaspb.VulnerabilityNote_Detail{\n-\t\t\t\t\t\t\tAffectedCpeUri: \"your-uri-here\",\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tAffectedCpeUri:  \"your-uri-here\",\n \t\t\t\t\t\t\tAffectedPackage: \"your-package-here\",\n \t\t\t\t\t\t\tMinAffectedVersion: &grafeaspb.Version{\n \t\t\t\t\t\t\t\tKind: grafeaspb.Version_MINIMUM,",
        "comments": [],
        "commit_message": "ran gofmt",
        "commit_id": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -400,13 +400,13 @@\nfunc TestFindHighVulnerabilities(t *testing.T) {\n \toccReq := &grafeaspb.CreateOccurrenceRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s\", v.projectID),\n \t\tOccurrence: &grafeaspb.Occurrence{\n-\t\t\tNoteName: fmt.Sprintf(\"projects/%s/notes/%s\", v.projectID, noteID),\n+\t\t\tNoteName:    fmt.Sprintf(\"projects/%s/notes/%s\", v.projectID, noteID),\n \t\t\tResourceUri: v.imageURL,\n \t\t\tDetails: &grafeaspb.Occurrence_Vulnerability{\n \t\t\t\tVulnerability: &grafeaspb.VulnerabilityOccurrence{\n \t\t\t\t\tPackageIssue: []*grafeaspb.VulnerabilityOccurrence_PackageIssue{\n-\t\t\t\t\t\t&grafeaspb.VulnerabilityOccurrence_PackageIssue{\n-\t\t\t\t\t\t\tAffectedCpeUri: \"your-uri-here\",\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tAffectedCpeUri:  \"your-uri-here\",\n \t\t\t\t\t\t\tAffectedPackage: \"your-package-here\",\n \t\t\t\t\t\t\tMinAffectedVersion: &grafeaspb.Version{\n \t\t\t\t\t\t\t\tKind: grafeaspb.Version_MINIMUM,",
        "comments": [],
        "commit_message": "ran gofmt",
        "commit_id": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "spanner: more updates to samples that transfer money",
        "pr_number": 871,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -548,22 +548,20 @@\nfunc writeWithTransaction(ctx context.Context, w io.Writer, client *spanner.Clie\n \t\tif err != nil {\n \t\t\treturn err\n \t\t}\n-\t\tif album2Budget >= 300000 {\n+\t\tconst transferAmt = 200000\n+\t\tif album2Budget >= transferAmt {\n \t\t\talbum1Budget, err := getBudget(spanner.Key{1, 1})\n \t\t\tif err != nil {\n \t\t\t\treturn err\n \t\t\t}\n-\t\t\tconst transfer = 100000\n-\t\t\tif album1Budget >= transfer {\n-\t\t\t\talbum1Budget -= transfer\n-\t\t\t\talbum2Budget += transfer\n-\t\t\t\tcols := []string{\"SingerId\", \"AlbumId\", \"MarketingBudget\"}\n-\t\t\t\ttxn.BufferWrite([]*spanner.Mutation{\n-\t\t\t\t\tspanner.Update(\"Albums\", cols, []interface{}{1, 1, album1Budget}),\n-\t\t\t\t\tspanner.Update(\"Albums\", cols, []interface{}{2, 2, album2Budget}),\n-\t\t\t\t})\n-\t\t\t\tfmt.Fprintf(w, \"Moved %d from Album1's MarketingBudget to Album2's.\", transfer)\n-\t\t\t}\n+\t\t\talbum1Budget += transferAmt\n+\t\t\talbum2Budget -= transferAmt\n+\t\t\tcols := []string{\"SingerId\", \"AlbumId\", \"MarketingBudget\"}\n+\t\t\ttxn.BufferWrite([]*spanner.Mutation{\n+\t\t\t\tspanner.Update(\"Albums\", cols, []interface{}{1, 1, album1Budget}),\n+\t\t\t\tspanner.Update(\"Albums\", cols, []interface{}{2, 2, album2Budget}),\n+\t\t\t})\n+\t\t\tfmt.Fprintf(w, \"Moved %d from Album2's MarketingBudget to Album1's.\", transferAmt)\n \t\t}\n \t\treturn nil\n \t})",
        "comments": [
            {
                "comment": "This was already here, but it's a little weird to pre-declare `err`, `album1Budget`, and `album2Budget` so we can do an inline error check. Would probably more clear to initialize the variables outside the `if` and not pre-declare:\r\n\r\n```go\r\nconst transferAmt = 200000\r\nalbum2Budget, err := getBudget(2, 2)\r\nif err != nil {\r\n  return err\r\n}\r\nif album2Budget >= transferAmt {\r\n  album1Budget, err := getBudget(1, 1)\r\n  if err != nil {\r\n    return err\r\n  }\r\n  // ...\r\n}\r\n```",
                "position": null
            },
            {
                "comment": "Done (and thanks for the extremely clear instructions!).",
                "position": null
            }
        ],
        "commit_message": "spanner: more updates to samples that transfer money\n\nThese changes iterate on #856 to address some requests from @jsimonweb:\n\n- Move $200,000 from Album2 to Album1, rather than $100,000 from Album1 to Album2.\n- Just check the transfer amount against the Album2 budget, not another arbitrary number.\n\nThese changes reduce the scope of updates to other code samples and docs.",
        "commit_id": "61a7349cc7d6bd4d0fb96e47e67bb21fb94f2a98"
    },
    {
        "pr_title": "spanner: add queryWithParameter sample",
        "pr_number": 853,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -176,9 +176,6 @@\nfunc TestSample(t *testing.T) {\n \tout = runCommand(t, \"querywithhistory\", dbName)\n \tassertContains(out, \"1 1 Hello World 1 Updated\")\n \n-\tout = runCommand(t, \"querywithparameter\", dbName)\n-\tassertContains(out, \"12 Melissa Garcia\")\n-\n \tout = runCommand(t, \"dmlinsert\", dbName)\n \tassertContains(out, \"record(s) inserted\")",
        "comments": [],
        "commit_message": "spanner: fix bad merge",
        "commit_id": "9e9d6adbe8f45adda636d1d21eaddc0399ecf907"
    },
    {
        "pr_title": "appengine_flexible: websockets sample",
        "pr_number": 837,
        "file_name": "healthcare/dataset_deidentify.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n \n \thealthcare \"google.golang.org/api/healthcare/v1beta1\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into flex-websockets",
        "commit_id": "757e68f843d3544002e2febb64c98b1307ca8cf8"
    },
    {
        "pr_title": "run: service-to-service auth snippet",
        "pr_number": 829,
        "file_name": "run/authentication/auth.go",
        "code_diff": "@@ -15,7 +15,7 @@\n// Package authentication contains the authentication samples for Cloud Run.\n package authentication\n \n-// [START service_to_service_auth]\n+// [START run_service_to_service_auth]\n import (\n \t\"fmt\"\n \t\"net/http\"",
        "comments": [
            {
                "comment": "The region tag should be in the samples tracker, which requires the region tags to start with the product name. So, this should be something like `run_service_to_service_auth`.",
                "position": null
            },
            {
                "comment": "Thanks! just created sample number 1692 in the system with that `tag`. Any ideas what's next?",
                "position": null
            }
        ],
        "commit_message": "run: update region tag",
        "commit_id": "e855271c7c4824cc2568fe0ec23841ee49db6538"
    },
    {
        "pr_title": "CONTRIBUTING: add style guide",
        "pr_number": 827,
        "file_name": "functions/tips/lazy.go",
        "code_diff": "@@ -13,6 +13,7 @@\n// limitations under the License.\n \n // [START functions_tips_lazy_globals]\n+// [START run_tips_global_lazy]\n \n // Package tips contains tips for writing Cloud Functions in Go.\n package tips",
        "comments": [],
        "commit_message": "Merge branch 'master' into readme",
        "commit_id": "adffa5f823979d7536939ce91b031431dcf8681d"
    },
    {
        "pr_title": "CONTRIBUTING: add style guide",
        "pr_number": 827,
        "file_name": "functions/tips/scope.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n )\n \n // [START functions_tips_scopes]\n+// [START run_tips_global_scope]\n \n // h is in the global (instance-wide) scope.\n var h string",
        "comments": [],
        "commit_message": "Merge branch 'master' into readme",
        "commit_id": "adffa5f823979d7536939ce91b031431dcf8681d"
    },
    {
        "pr_title": "CONTRIBUTING: add style guide",
        "pr_number": 827,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -32,6 +32,7 @@\nimport (\n \n var (\n \tmetaProject = flag.String(\"project\", \"\", \"Meta-project that manages the pool.\")\n+\tformat      = flag.String(\"output\", \"\", \"Output format for selected operations. Options include: list\")\n \tdatastore   *ds.Client\n \n \tversion   = \"dev\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into readme",
        "commit_id": "adffa5f823979d7536939ce91b031431dcf8681d"
    },
    {
        "pr_title": "CONTRIBUTING: add style guide",
        "pr_number": 827,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -102,6 +103,7 @@\nfunc submain() error {\n \tusage := errors.New(`\n Usage:\n \tgimmeproj -project=[meta project ID] command\n+\tgimmeproj -project=[meta project ID] -output=list status\n \n Commands:\n \tlease [duration]    Leases a project for a given duration. Prints the project ID to stdout.",
        "comments": [],
        "commit_message": "Merge branch 'master' into readme",
        "commit_id": "adffa5f823979d7536939ce91b031431dcf8681d"
    },
    {
        "pr_title": "CONTRIBUTING: add style guide",
        "pr_number": 827,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -111,7 +113,7 @@\nCommands:\n Administrative commands:\n \tpool-add [project ID]       Adds a project to the pool.\n \tpool-rm  [project ID]       Removes a project from the pool.\n-\tstatus                      Displays the current status of the meta project.\n+\tstatus                      Displays the current status of the meta project. Respects -output.\n `)\n \n \tif flag.Arg(0) == \"version\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into readme",
        "commit_id": "adffa5f823979d7536939ce91b031431dcf8681d"
    },
    {
        "pr_title": "opencensus: use metric exporter interface",
        "pr_number": 825,
        "file_name": "opencensus/opencensus_spanner_quickstart/main.go",
        "code_diff": "@@ -25,7 +25,6 @@\nimport (\n \n \t\"cloud.google.com/go/spanner\"\n \t\"contrib.go.opencensus.io/exporter/stackdriver\"\n-\t\"go.opencensus.io/stats/view\"\n \t\"go.opencensus.io/trace\"\n )",
        "comments": [],
        "commit_message": "opencensus: update Spanner quickstart",
        "commit_id": "a5fc117261e43cc5f328930a7fc40d19b95bf607"
    },
    {
        "pr_title": "opencensus: use metric exporter interface",
        "pr_number": 825,
        "file_name": "opencensus/opencensus_spanner_quickstart/main.go",
        "code_diff": "@@ -37,15 +36,20 @@\nfunc main() {\n \t// Exporters use Application Default Credentials to authenticate.\n \t// See https://developers.google.com/identity/protocols/application-default-credentials\n \t// for more details.\n-\texporter, err := stackdriver.NewExporter(stackdriver.Options{\n-\t\tProjectID: \"your-project-id\",\n-\t})\n+\texporter, err := stackdriver.NewExporter(stackdriver.Options{})\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n-\tview.RegisterExporter(exporter)\n+\t// Flush must be called before main() exits to ensure metrics are recorded.\n+\tdefer exporter.Flush()\n+\n \ttrace.RegisterExporter(exporter)\n \n+\tif err := exporter.StartMetricsExporter(); err != nil {\n+\t\tlog.Fatalf(\"Error starting metric exporter: %v\", err)\n+\t}\n+\tdefer exporter.StopMetricsExporter()\n+\n \t// Use trace.AlwaysSample() to always record traces. The\n \t// default sampler skips some traces to conserve resources,\n \t// but can make it hard to debug test traffic. So, remove",
        "comments": [],
        "commit_message": "opencensus: update Spanner quickstart",
        "commit_id": "a5fc117261e43cc5f328930a7fc40d19b95bf607"
    },
    {
        "pr_title": "storage: add v4 signed URL get and put samples",
        "pr_number": 811,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -452,9 +452,9 @@\nfunc generateV4GetObjectSignedURL(w io.Writer, client *storage.Client, bucketNam\n \t}\n \n \tfmt.Fprintln(w, \"Generated GET signed URL:\")\n-\tfmt.Fprintf(w, \"'%v'\\n\", u)\n+\tfmt.Fprintf(w, \"%q\\n\", u)\n \tfmt.Fprintln(w, \"You can use this URL with any user agent, for example:\")\n-\tfmt.Fprintf(w, \"curl '%v'\\n\", u)\n+\tfmt.Fprintf(w, \"curl %q\\n\", u)\n \t// [END storage_generate_signed_url_v4]\n \treturn u, nil\n }",
        "comments": [
            {
                "comment": "s/Url/URL/\r\n\r\nhttps://github.com/golang/go/wiki/CodeReviewComments#initialisms\r\n\r\nSame below.",
                "position": null
            },
            {
                "comment": "Each function should create its own client, rather than have it passed as an argument. It might be better to stay consistent within the same set of samples, but I'm not sure.",
                "position": null
            },
            {
                "comment": "Please pass an `io.Writer` as an argument and print to it like this:\r\n```\r\nfmt.Fprintln(w, \"Generated GET signed URL:\")\r\n```",
                "position": null
            },
            {
                "comment": "No semicolons needed at the ends of the lines. :)",
                "position": null
            },
            {
                "comment": "I'd rather keep the existing format without changing the format unless it's required. ",
                "position": null
            },
            {
                "comment": "See https://github.com/GoogleCloudPlatform/golang-samples/blob/master/CONTRIBUTING.md#initialize-clients-and-services-in-every-sample (new canonical sample style guide).\r\n\r\nEventually, all samples should match this style. But, if you want to be internally consistent for these samples, that works too.",
                "position": null
            },
            {
                "comment": "Thanks for clarifying! \r\n\r\nI want to follow the format that exists in these samples to be consistent.",
                "position": null
            },
            {
                "comment": "lol... I can Go, I promise! Thanks for catching those.",
                "position": null
            },
            {
                "comment": "Mind updating this? Causes a lot of printing for tests that makes it more difficult to debug.",
                "position": null
            },
            {
                "comment": "done. PTAL, thank you!",
                "position": null
            },
            {
                "comment": "Can use `%q` to automatically include quotes around the string. Same elsewhere.",
                "position": null
            }
        ],
        "commit_message": "storage: use %q to print with quotes",
        "commit_id": "fd6845a7ba0cb2e478949c93ab76777a0a228c10"
    },
    {
        "pr_title": "tasks: add HTTP push queue sample",
        "pr_number": 799,
        "file_name": "functions/tips/lazy.go",
        "code_diff": "@@ -13,6 +13,7 @@\n// limitations under the License.\n \n // [START functions_tips_lazy_globals]\n+// [START run_tips_global_lazy]\n \n // Package tips contains tips for writing Cloud Functions in Go.\n package tips",
        "comments": [],
        "commit_message": "Merge branch 'master' into http-tasks",
        "commit_id": "1fe04ad5b6c668692b3b0bdb0c3ce426c112ef54"
    },
    {
        "pr_title": "tasks: add HTTP push queue sample",
        "pr_number": 799,
        "file_name": "functions/tips/scope.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n )\n \n // [START functions_tips_scopes]\n+// [START run_tips_global_scope]\n \n // h is in the global (instance-wide) scope.\n var h string",
        "comments": [],
        "commit_message": "Merge branch 'master' into http-tasks",
        "commit_id": "1fe04ad5b6c668692b3b0bdb0c3ce426c112ef54"
    },
    {
        "pr_title": "Add Cloud Spanner Leaderboard sample.",
        "pr_number": 793,
        "file_name": "spanner/spanner_leaderboard/leaderboard.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Command spanner_snippets contains runnable snippet code for Cloud Spanner.\n+// Command spanner_leaderboard contains runnable snippet code for Cloud Spanner.\n package main\n \n import (",
        "comments": [
            {
                "comment": "Command spanner_leaderboard contains ...",
                "position": null
            },
            {
                "comment": "Does ID have to be an int? If we can make it a string, you can just use the uuid package to generate an id.",
                "position": null
            },
            {
                "comment": "this looks like it adds 10, not 100.",
                "position": null
            },
            {
                "comment": "this looks like an actual error. insertPlayers does nothing if there are no existing Players?",
                "position": null
            },
            {
                "comment": "this is racy. should all of this be in a transaction?\r\n\r\nif it's simplified intentionally, add a comment, perhaps, saying that you'd typically use a transaction for this type of code ",
                "position": null
            },
            {
                "comment": "```suggestion\r\n\t\t\t// Generate random score between 1,000 and 1,000,000\r\n```",
                "position": null
            },
            {
                "comment": "```suggestion\r\n\t\tfor i := 0; i < 4; i++ {\r\n```",
                "position": null
            },
            {
                "comment": "```suggestion\r\n\tplayerRecordsFound := false\r\n```",
                "position": null
            },
            {
                "comment": "Fprintln here and below?",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            },
            {
                "comment": "Opted for Int64 to keep the output more condensed for displaying table values in query results.",
                "position": null
            },
            {
                "comment": "Updated.",
                "position": null
            },
            {
                "comment": "Added a comment and initialized relevant variable value to make code block's purpose more clear.",
                "position": null
            },
            {
                "comment": "Moved code into a transaction.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "Address review comments.",
        "commit_id": "a00456814aa626105ff8351ab34b66547fa2a8b7"
    },
    {
        "pr_title": "Add Cloud Spanner Leaderboard sample.",
        "pr_number": 793,
        "file_name": "spanner/spanner_leaderboard/leaderboard.go",
        "code_diff": "@@ -79,50 +79,60 @@\nfunc createDatabase(ctx context.Context, w io.Writer, adminClient *database.Data\n }\n \n func insertPlayers(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\t// Get number of Players\n+\t// Get number of players to use as an incrementing value for each PlayerName to be inserted\n \tstmt := spanner.Statement{\n \t\tSQL: `SELECT Count(PlayerId) as PlayerCount FROM Players`,\n \t}\n \titer := client.Single().Query(ctx, stmt)\n \tdefer iter.Stop()\n \trow, err := iter.Next()\n-\tif err == iterator.Done {\n-\t\treturn nil\n-\t}\n \tif err != nil {\n \t\treturn err\n \t}\n-\tvar numberOfPlayers int64\n+\tvar numberOfPlayers int64 = 0\n \tif err := row.Columns(&numberOfPlayers); err != nil {\n \t\treturn err\n \t}\n+\t// Intialize values for random PlayerId\n+\trand.Seed(time.Now().UnixNano())\n+\tmin := 1000000000\n+\tmax := 9000000000\n \t// Insert 100 player records into the Players table\n-\tfor i := 1; i <= 10; i++ {\n-\t\tnumberOfPlayers++\n-\t\trand.Seed(time.Now().UnixNano())\n-\t\tmin := 1000000000\n-\t\tmax := 9000000000\n-\t\tPlayerId := rand.Intn(max-min) + min\n-\t\tPlayerName := fmt.Sprintf(\"Player %d\", numberOfPlayers)\n-\t\tcols := []string{\"PlayerId\", \"PlayerName\"}\n-\t\tm := []*spanner.Mutation{\n-\t\t\tspanner.InsertOrUpdate(\"Players\", cols, []interface{}{PlayerId, PlayerName}),\n+\t_, err = client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\tstmts := []spanner.Statement{}\n+\t\tfor i := 1; i <= 100; i++ {\n+\t\t\tnumberOfPlayers++\n+\t\t\tplayerID := rand.Intn(max-min) + min\n+\t\t\tplayerName := fmt.Sprintf(\"Player %d\", numberOfPlayers)\n+\t\t\tstmts = append(stmts, spanner.Statement{\n+\t\t\t\tSQL: `INSERT INTO Players\n+\t\t\t\t\t\t(PlayerId, PlayerName)\n+\t\t\t\t\t\tVALUES (@playerID, @playerName)`,\n+\t\t\t\tParams: map[string]interface{}{\n+\t\t\t\t\t\"playerID\":   playerID,\n+\t\t\t\t\t\"playerName\": playerName,\n+\t\t\t\t},\n+\t\t\t})\n \t\t}\n-\t\t_, err := client.Apply(ctx, m)\n+\t\t_, err := txn.BatchUpdate(ctx, stmts)\n \t\tif err != nil {\n \t\t\treturn err\n \t\t}\n-\t}\n+\t\treturn nil\n+\t})\n \tfmt.Fprintf(w, \"Inserted players \\n\")\n \treturn nil\n }\n \n func insertScores(ctx context.Context, w io.Writer, client *spanner.Client) error {\n-\tvar playerRecordsFound bool = false\n+\tplayerRecordsFound := false\n+\t// Create slice for insert statements\n+\tstmts := []spanner.Statement{}\n \t// Select all player records\n \tstmt := spanner.Statement{SQL: `SELECT PlayerId FROM Players`}\n \titer := client.Single().Query(ctx, stmt)\n \tdefer iter.Stop()\n+\t// Insert 4 score records into the Scores table for each player in the Players table\n \tfor {\n \t\trow, err := iter.Next()\n \t\tif err == iterator.Done {",
        "comments": [
            {
                "comment": "Command spanner_leaderboard contains ...",
                "position": null
            },
            {
                "comment": "Does ID have to be an int? If we can make it a string, you can just use the uuid package to generate an id.",
                "position": null
            },
            {
                "comment": "this looks like it adds 10, not 100.",
                "position": null
            },
            {
                "comment": "this looks like an actual error. insertPlayers does nothing if there are no existing Players?",
                "position": null
            },
            {
                "comment": "this is racy. should all of this be in a transaction?\r\n\r\nif it's simplified intentionally, add a comment, perhaps, saying that you'd typically use a transaction for this type of code ",
                "position": null
            },
            {
                "comment": "```suggestion\r\n\t\t\t// Generate random score between 1,000 and 1,000,000\r\n```",
                "position": null
            },
            {
                "comment": "```suggestion\r\n\t\tfor i := 0; i < 4; i++ {\r\n```",
                "position": null
            },
            {
                "comment": "maybe split this out into a helper function?",
                "position": 156
            },
            {
                "comment": "```suggestion\r\n\tplayerRecordsFound := false\r\n```",
                "position": null
            },
            {
                "comment": "Fprintln here and below?",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            },
            {
                "comment": "Opted for Int64 to keep the output more condensed for displaying table values in query results.",
                "position": null
            },
            {
                "comment": "Updated.",
                "position": null
            },
            {
                "comment": "Added a comment and initialized relevant variable value to make code block's purpose more clear.",
                "position": null
            },
            {
                "comment": "Moved code into a transaction.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Opting to leave as is for simplicity.",
                "position": 156
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "Address review comments.",
        "commit_id": "a00456814aa626105ff8351ab34b66547fa2a8b7"
    },
    {
        "pr_title": "Add Cloud Spanner Leaderboard sample.",
        "pr_number": 793,
        "file_name": "spanner/spanner_leaderboard/leaderboard.go",
        "code_diff": "@@ -140,9 +150,8 @@\nfunc insertScores(ctx context.Context, w io.Writer, client *spanner.Client) erro\n \t\trand.Seed(time.Now().UnixNano())\n \t\tmin := 1000\n \t\tmax := 1000000\n-\t\t// Insert 4 score records into the Scores table for each player in the Players table\n-\t\tfor i := 1; i <= 4; i++ {\n-\t\t\t// Generate random score between 1,000,000 and 1,000\n+\t\tfor i := 0; i < 4; i++ {\n+\t\t\t// Generate random score between 1,000 and 1,000,000\n \t\t\tscore := rand.Intn(max-min) + min\n \t\t\t// Generate random day within the past two years\n \t\t\tnow := time.Now()",
        "comments": [
            {
                "comment": "Command spanner_leaderboard contains ...",
                "position": null
            },
            {
                "comment": "Does ID have to be an int? If we can make it a string, you can just use the uuid package to generate an id.",
                "position": null
            },
            {
                "comment": "this looks like it adds 10, not 100.",
                "position": null
            },
            {
                "comment": "this looks like an actual error. insertPlayers does nothing if there are no existing Players?",
                "position": null
            },
            {
                "comment": "this is racy. should all of this be in a transaction?\r\n\r\nif it's simplified intentionally, add a comment, perhaps, saying that you'd typically use a transaction for this type of code ",
                "position": null
            },
            {
                "comment": "```suggestion\r\n\t\t\t// Generate random score between 1,000 and 1,000,000\r\n```",
                "position": null
            },
            {
                "comment": "```suggestion\r\n\t\tfor i := 0; i < 4; i++ {\r\n```",
                "position": null
            },
            {
                "comment": "maybe split this out into a helper function?",
                "position": 156
            },
            {
                "comment": "```suggestion\r\n\tplayerRecordsFound := false\r\n```",
                "position": null
            },
            {
                "comment": "Fprintln here and below?",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            },
            {
                "comment": "Opted for Int64 to keep the output more condensed for displaying table values in query results.",
                "position": null
            },
            {
                "comment": "Updated.",
                "position": null
            },
            {
                "comment": "Added a comment and initialized relevant variable value to make code block's purpose more clear.",
                "position": null
            },
            {
                "comment": "Moved code into a transaction.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Opting to leave as is for simplicity.",
                "position": 156
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "Address review comments.",
        "commit_id": "a00456814aa626105ff8351ab34b66547fa2a8b7"
    },
    {
        "pr_title": "jobs: add v4beta1 samples",
        "pr_number": 778,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -215,7 +215,7 @@\nfunc writeTestDatastoreFiles(t *testing.T, projectID string) {\n }\n \n func TestInspectDatastore(t *testing.T) {\n-\ttestutil.SystemTest(t)\n+\ttestutil.EndToEndTest(t)\n \twriteTestDatastoreFiles(t, projectID)\n \ttests := []struct {\n \t\tkind string",
        "comments": [],
        "commit_message": "Merge branch 'master' into jobs",
        "commit_id": "f79799c904390255b93f207f362173314e78c820"
    },
    {
        "pr_title": "bigquery: add bigquery storage quickstart",
        "pr_number": 760,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -52,7 +52,7 @@\nvar rpcOpts = gax.WithGRPCOptions(\n var (\n \tprojectID = flag.String(\"project_id\", \"\",\n \t\t\"Cloud Project ID, used for session creation.\")\n-\tsnapShotMillis = flag.Int64(\"snapshot_millis\", 0,\n+\tsnapshotMillis = flag.Int64(\"snapshot_millis\", 0,\n \t\t\"Snapshot time to use for reads, represented in epoch milliseconds format.  Default behavior reads current data.\")\n )",
        "comments": [
            {
                "comment": "Need to update this following #757.",
                "position": null
            },
            {
                "comment": "May not need the newline. Not essential to be able to read when embedded.",
                "position": null
            },
            {
                "comment": "snapshotMS? Not sure if millisecond should be Ms or MS.",
                "position": null
            },
            {
                "comment": "@theacodes recently mentioned we shouldn't be using this environment variable. So, I think we should either require the flag or hard code an example project ID.",
                "position": null
            },
            {
                "comment": "Alternatively, this could overwrite the `projectID` variable as needed and not need the `parentProject` variable. Up to you.",
                "position": null
            },
            {
                "comment": "Capitalize.",
                "position": null
            },
            {
                "comment": "I'll need to amend the testutil buildmain runner to handle passing cmdline args, so that'll be in the next iteration.",
                "position": null
            },
            {
                "comment": "went with snapshotMillis",
                "position": null
            },
            {
                "comment": "Killed the environment check for project, we'll rely strictly on flags.",
                "position": null
            },
            {
                "comment": "done",
                "position": null
            }
        ],
        "commit_message": "capitalization nit",
        "commit_id": "58ad38d369c1a1730f23dbd8e15f442aa13d9f8d"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -1,6 +1,16 @@\n-// Copyright 2018 Google LLC. All rights reserved.\n-// Use of this source code is governed by the Apache 2.0\n-// license that can be found in the LICENSE file.\n+// Copyright 2019 Google LLC\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+//     https://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n \n // Command manager lets you manage Cloud IoT Core devices and registries.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into endpoints-auth",
        "commit_id": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -383,6 +393,55 @@\nfunc createUnauth(w io.Writer, projectID string, region string, registryID strin\n \n // [END iot_create_unauth_device]\n \n+// [START iot_create_device]\n+\n+// createDevice creates a device in a registry with one of the following public key formats:\n+// RSA_PEM, RSA_X509_PEM, ES256_PEM, ES256_X509_PEM, UNAUTH.\n+func createDevice(w io.Writer, projectID string, region string, registryID string, deviceID string, publicKeyFormat string, keyPath string) (*cloudiot.Device, error) {\n+\tclient, err := getClient()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tkeyBytes, err := ioutil.ReadFile(keyPath)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tvar device cloudiot.Device\n+\n+\t// If no credentials are passed in, create an unauth device.\n+\tif publicKeyFormat == \"UNAUTH\" {\n+\t\tdevice = cloudiot.Device{\n+\t\t\tId: deviceID,\n+\t\t}\n+\t} else {\n+\t\tdevice = cloudiot.Device{\n+\t\t\tId: deviceID,\n+\t\t\tCredentials: []*cloudiot.DeviceCredential{\n+\t\t\t\t{\n+\t\t\t\t\tPublicKey: &cloudiot.PublicKeyCredential{\n+\t\t\t\t\t\tFormat: publicKeyFormat,\n+\t\t\t\t\t\tKey:    string(keyBytes),\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}\n+\t}\n+\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n+\tresponse, err := client.Projects.Locations.Registries.Devices.Create(parent, &device).Do()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tfmt.Fprintf(w, \"Successfully created a device with %s public key: %s\", publicKeyFormat, deviceID)\n+\n+\treturn response, nil\n+}\n+\n+// [END iot_create_device]\n+\n // [START iot_delete_device]\n \n // deleteDevice deletes a device from a registry.",
        "comments": [],
        "commit_message": "Merge branch 'master' into endpoints-auth",
        "commit_id": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -645,7 +704,7 @@\nfunc patchDeviceRSA(w io.Writer, projectID string, region string, registryID str\n // [START iot_set_device_config]\n \n // setConfig sends a configuration change to a device.\n-func setConfig(w io.Writer, projectID string, region string, registryID string, deviceID string, configData string, format string) (*cloudiot.DeviceConfig, error) {\n+func setConfig(w io.Writer, projectID string, region string, registryID string, deviceID string, configData string) (*cloudiot.DeviceConfig, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into endpoints-auth",
        "commit_id": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "iot/manager/manager_test.go",
        "code_diff": "@@ -1,6 +1,16 @@\n-// Copyright 2018 Google LLC. All rights reserved.\n-// Use of this source code is governed by the Apache 2.0\n-// license that can be found in the LICENSE file.\n+// Copyright 2019 Google LLC\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+//     https://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n \n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into endpoints-auth",
        "commit_id": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "iot/manager/manager_test.go",
        "code_diff": "@@ -20,17 +30,18 @@\nimport (\n \t\"github.com/google/uuid\"\n )\n \n-var projectID string\n-var topicID string\n-var topicName string // topicName is the full path to the topic (e.g. project/{project}/topics/{topic})\n-var registryID string\n+var (\n+\tprojectID  string\n+\ttopicID    string\n+\ttopicName  string // topicName is the full path to the topic (e.g. project/{project}/topics/{topic}).\n+\tregistryID string\n+\tclient     *pubsub.Client\n+)\n \n const region = \"us-central1\"\n \n var pubKeyRSA = os.Getenv(\"GOLANG_SAMPLES_IOT_PUB\")\n \n-var client *pubsub.Client\n-\n // returns a v1 UUID for a resource: e.g. topic, registry, gateway, device\n func createIDForTest(resource string) string {\n \tuuid, err := uuid.NewRandom()",
        "comments": [],
        "commit_message": "Merge branch 'master' into endpoints-auth",
        "commit_id": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "iot/manager/manager_test.go",
        "code_diff": "@@ -44,9 +55,7 @@\nfunc createIDForTest(resource string) string {\n \n func TestMain(m *testing.M) {\n \tsetup(m)\n-\tlog.SetOutput(ioutil.Discard)\n \ts := m.Run()\n-\tlog.SetOutput(os.Stderr)\n \tshutdown()\n \tos.Exit(s)\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into endpoints-auth",
        "commit_id": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "iot/manager/manager_test.go",
        "code_diff": "@@ -55,17 +64,16 @@\nfunc setup(m *testing.M) {\n \tctx := context.Background()\n \ttc, ok := testutil.ContextMain(m)\n \n-\t// Retrive\n-\tif ok {\n-\t\tprojectID = tc.ProjectID\n-\t} else {\n+\t// Retrieve project ID\n+\tif !ok {\n \t\tfmt.Fprintln(os.Stderr, \"Project is not set up properly for system tests. Make sure GOLANG_SAMPLES_PROJECT_ID is set\")\n-\t\tos.Exit(1)\n+\t\treturn\n \t}\n+\tprojectID = tc.ProjectID\n \n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Could not create pubsub Client: %v\", err)\n+\t\tfmt.Printf(\"Could not create pubsub Client:\\n%v\\n\", err)\n \t}\n \tclient = pubsubClient",
        "comments": [],
        "commit_message": "Merge branch 'master' into endpoints-auth",
        "commit_id": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "license_test.go",
        "code_diff": "@@ -1,6 +1,16 @@\n-// Copyright 2016 Google Inc. All rights reserved.\n-// Use of this source code is governed by the Apache 2.0\n-// license that can be found in the LICENSE file.\n+// Copyright 2019 Google LLC\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+//     https://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n \n package samples",
        "comments": [],
        "commit_message": "Merge branch 'master' into endpoints-auth",
        "commit_id": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "spanner/spanner_quickstart/main.go",
        "code_diff": "@@ -1,6 +1,16 @@\n-// Copyright 2017 Google Inc. All rights reserved.\n-// Use of this source code is governed by the Apache 2.0\n-// license that can be found in the LICENSE file.\n+// Copyright 2019 Google LLC\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+//     https://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n \n // [START spanner_quickstart]",
        "comments": [],
        "commit_message": "Merge branch 'master' into endpoints-auth",
        "commit_id": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "spanner/spanner_quickstart/main.go",
        "code_diff": "@@ -13,6 +23,7 @@\nimport (\n \t\"log\"\n \n \t\"cloud.google.com/go/spanner\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into endpoints-auth",
        "commit_id": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "vision/detect/generated/gen.go",
        "code_diff": "@@ -1,6 +1,16 @@\n-// Copyright 2017 Google Inc. All rights reserved.\n-// Use of this source code is governed by the Apache 2.0\n-// license that can be found in the LICENSE file.\n+// Copyright 2019 Google LLC\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+//     https://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n \n //+build ignore",
        "comments": [],
        "commit_message": "Merge branch 'master' into endpoints-auth",
        "commit_id": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "iam: add quickstart and doc snippets",
        "pr_number": 754,
        "file_name": "iam/snippets/roles_test.go",
        "code_diff": "@@ -16,20 +16,20 @@\npackage snippets\n \n import (\n \t\"bytes\"\n-\t\"os\"\n \t\"strings\"\n \t\"testing\"\n \n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/gofrs/uuid\"\n )\n \n func TestRoles(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n \tbuf := &bytes.Buffer{}\n \tuuid, _ := uuid.NewV4()\n-\tproject := os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")\n \n \t// viewGrantableRoles test.\n-\tfullResourceName := \"//cloudresourcemanager.googleapis.com/projects/\" + project\n+\tfullResourceName := \"//cloudresourcemanager.googleapis.com/projects/\" + tc.ProjectID\n \tgrantable, err := viewGrantableRoles(buf, fullResourceName)\n \tif err != nil {\n \t\tt.Fatalf(\"viewGrantableRoles: %v\", err)",
        "comments": [],
        "commit_message": "use testutil instead of env var",
        "commit_id": "f0732962e370600276073473eac97c776926240c"
    },
    {
        "pr_title": "iam: add quickstart and doc snippets",
        "pr_number": 754,
        "file_name": "iam/snippets/roles_test.go",
        "code_diff": "@@ -57,7 +57,7 @@\nfunc TestRoles(t *testing.T) {\n \tstage := \"GA\"\n \n \t// createRole test.\n-\trole, err = createRole(buf, project, name, title, desc, stage, perms)\n+\trole, err = createRole(buf, tc.ProjectID, name, title, desc, stage, perms)\n \tif err != nil {\n \t\tt.Fatalf(\"createRole: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "use testutil instead of env var",
        "commit_id": "f0732962e370600276073473eac97c776926240c"
    },
    {
        "pr_title": "iam: add quickstart and doc snippets",
        "pr_number": 754,
        "file_name": "iam/snippets/roles_test.go",
        "code_diff": "@@ -68,7 +68,7 @@\nfunc TestRoles(t *testing.T) {\n \n \t// editRole test.\n \tnewTitle := \"Updated test role\"\n-\trole, err = editRole(buf, project, name, newTitle, desc, stage, perms)\n+\trole, err = editRole(buf, tc.ProjectID, name, newTitle, desc, stage, perms)\n \tif err != nil {\n \t\tt.Fatalf(\"editRole: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "use testutil instead of env var",
        "commit_id": "f0732962e370600276073473eac97c776926240c"
    },
    {
        "pr_title": "iam: add quickstart and doc snippets",
        "pr_number": 754,
        "file_name": "iam/snippets/roles_test.go",
        "code_diff": "@@ -78,7 +78,7 @@\nfunc TestRoles(t *testing.T) {\n \t}\n \n \t// listRoles test.\n-\troles, err := listRoles(buf, project)\n+\troles, err := listRoles(buf, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"listRoles: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "use testutil instead of env var",
        "commit_id": "f0732962e370600276073473eac97c776926240c"
    },
    {
        "pr_title": "iam: add quickstart and doc snippets",
        "pr_number": 754,
        "file_name": "iam/snippets/service_accounts_test.go",
        "code_diff": "@@ -16,26 +16,26 @@\npackage snippets\n \n import (\n \t\"bytes\"\n-\t\"os\"\n \t\"strings\"\n \t\"testing\"\n \n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/gofrs/uuid\"\n )\n \n func TestServiceAccounts(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n \tbuf := &bytes.Buffer{}\n \tuuid, _ := uuid.NewV4()\n \t// Name must start with a letter and be 6-30 characters.\n \tname := \"a\" + strings.Replace(uuid.String(), \"-\", \"\", -1)[:29]\n-\tproject := os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")\n \n \t// createServiceAccount test.\n-\taccount, err := createServiceAccount(buf, project, name, \"Test\")\n+\taccount, err := createServiceAccount(buf, tc.ProjectID, name, \"Test\")\n \tif err != nil {\n \t\tt.Fatalf(\"createServiceAccount: %v\", err)\n \t}\n-\twantEmail := name + \"@\" + project + \".iam.gserviceaccount.com\"\n+\twantEmail := name + \"@\" + tc.ProjectID + \".iam.gserviceaccount.com\"\n \tif wantEmail != account.Email {\n \t\tt.Fatalf(\"createServiceAccount: account.Email is %q, wanted %q\", account.Email, wantEmail)\n \t}",
        "comments": [],
        "commit_message": "use testutil instead of env var",
        "commit_id": "f0732962e370600276073473eac97c776926240c"
    },
    {
        "pr_title": "iot: add mqtt gateway snippets + test",
        "pr_number": 740,
        "file_name": "functions/helloworld/hello_pubsub_system_test.go",
        "code_diff": "@@ -5,8 +5,6 @@\n// +build ignore\n // Disabled until system tests are working on Kokoro.\n \n-// TODO: Use testutil.SystemTest and os.Setenv for GOOGLE_CLOUD_PROJECT.\n-\n // [START functions_pubsub_system_test]\n \n package helloworld",
        "comments": [],
        "commit_message": "Merge branch 'master' into iot-mqtt-gateway",
        "commit_id": "2d7f189640cf59333260ecd498b372ff7d979dbf"
    },
    {
        "pr_title": "iot: add mqtt gateway snippets + test",
        "pr_number": 740,
        "file_name": "internal/testutil/runmain.go",
        "code_diff": "@@ -5,11 +5,13 @@\npackage testutil\n \n import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"fmt\"\n \t\"io/ioutil\"\n \t\"os\"\n \t\"os/exec\"\n \t\"path/filepath\"\n-\t\"syscall\"\n \t\"testing\"\n \t\"time\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into iot-mqtt-gateway",
        "commit_id": "2d7f189640cf59333260ecd498b372ff7d979dbf"
    },
    {
        "pr_title": "iot: add mqtt gateway snippets + test",
        "pr_number": 740,
        "file_name": "internal/testutil/testutil.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc (tc Context) Path(p ...string) string {\n // Useful for initializing global variables before running parallel system tests.\n // ok is false if the project is not set up properly for system tests.\n func ContextMain(m *testing.M) (tc Context, ok bool) {\n-\tc, err := context()\n+\tc, err := testContext()\n \tif err == noProjectID {\n \t\treturn c, false\n \t} else if err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into iot-mqtt-gateway",
        "commit_id": "2d7f189640cf59333260ecd498b372ff7d979dbf"
    },
    {
        "pr_title": "iot: add mqtt gateway snippets + test",
        "pr_number": 740,
        "file_name": "internal/testutil/testutil.go",
        "code_diff": "@@ -43,7 +43,7 @@\nfunc ContextMain(m *testing.M) (tc Context, ok bool) {\n // SystemTest gets the test context.\n // The test is skipped if the GOLANG_SAMPLES_PROJECT_ID environment variable is not set.\n func SystemTest(t *testing.T) Context {\n-\ttc, err := context()\n+\ttc, err := testContext()\n \tif err == noProjectID {\n \t\tt.Skip(err)\n \t} else if err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into iot-mqtt-gateway",
        "commit_id": "2d7f189640cf59333260ecd498b372ff7d979dbf"
    },
    {
        "pr_title": "iot: add mqtt gateway snippets + test",
        "pr_number": 740,
        "file_name": "internal/testutil/testutil.go",
        "code_diff": "@@ -60,7 +60,7 @@\nfunc EndToEndTest(t *testing.T) Context {\n \t\tt.Skip(\"GOLANG_SAMPLES_E2E_TEST not set\")\n \t}\n \n-\ttc, err := context()\n+\ttc, err := testContext()\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into iot-mqtt-gateway",
        "commit_id": "2d7f189640cf59333260ecd498b372ff7d979dbf"
    },
    {
        "pr_title": "iot: add mqtt gateway snippets + test",
        "pr_number": 740,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -53,7 +53,7 @@\nfunc TestDetect(t *testing.T) {\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"Local %s(%q): got %v, want nil err\", tt.name, tt.path, err)\n \t\t}\n-\t\tif got := buf.String(); !strings.Contains(got, tt.wantContain) {\n+\t\tif got := buf.String(); !strings.Contains(strings.ToLower(got), strings.ToLower(tt.wantContain)) {\n \t\t\tt.Errorf(\"Local %s(%q): got %q, want to contain %q\", tt.name, tt.path, got, tt.wantContain)\n \t\t}\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into iot-mqtt-gateway",
        "commit_id": "2d7f189640cf59333260ecd498b372ff7d979dbf"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "getting-started/bookshelf/app/app.go",
        "code_diff": "@@ -25,8 +25,6 @@\nimport (\n \t\"github.com/gorilla/mux\"\n \tuuid \"github.com/satori/go.uuid\"\n \n-\t\"google.golang.org/appengine\"\n-\n \t\"github.com/GoogleCloudPlatform/golang-samples/getting-started/bookshelf\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into patch-1",
        "commit_id": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/auto_complete_sample.go",
        "code_diff": "@@ -2,21 +2,35 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-package sample\n+package howto\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\t\"time\"\n \n+\t\"golang.org/x/oauth2/google\"\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n // [START auto_complete_job_title]\n \n-// jobTitleAutoComplete suggests the job titles of the given companyName based on query.\n-func jobTitleAutoComplete(service *talent.Service, parent string, companyName string, query string) (*talent.CompleteQueryResponse, error) {\n+// jobTitleAutoComplete suggests the job titles of the given companyName based\n+// on query.\n+func jobTitleAutoComplete(w io.Writer, projectID, companyName, query string) (*talent.CompleteQueryResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n+\tparent := \"projects/\" + projectID\n \tcomplete := service.Projects.Complete(parent).Query(query).LanguageCode(\"en-US\").Type(\"JOB_TITLE\").PageSize(10)\n \tif companyName != \"\" {\n \t\tcomplete.CompanyName(companyName)",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -2,61 +2,38 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-package sample\n+package howto\n \n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\t\"time\"\n \n \t\"golang.org/x/oauth2/google\"\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n-// [START create_service]\n+// [START create_company]\n \n-// createCTSService creates service of Cloud Talent Solution.\n-func createCTSService() (*talent.Service, error) {\n-\t// Authorize the client using Application Default Credentials.\n-\t// See https://g.co/dv/identity/protocols/application-default-credentials\n+// createCompany creates a company as given.\n+func createCompany(w io.Writer, projectID string, companyToCreate *talent.Company) (*talent.Company, error) {\n \tctx := context.Background()\n+\n \tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n \t}\n \t// Create the jobs service client.\n-\tctsService, err := talent.New(client)\n+\tservice, err := talent.New(client)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n \t}\n-\treturn ctsService, nil\n-}\n-\n-// [END create_service]\n-\n-// [START basic_company]\n-\n-// constructCompanyWithRequiredFields constructs a company with required fields: ExternalId and DisplayName.\n-func constructCompanyWithRequiredFields() *talent.Company {\n-\texternalID := fmt.Sprintf(\"sample-company-%d\", time.Now().UnixNano())\n-\treturn &talent.Company{\n-\t\tExternalId:  externalID,\n-\t\tDisplayName: \"Google Sample\",\n-\t}\n-}\n-\n-// [END basic_company]\n-\n-// [START create_company]\n \n-// createCompany creates a company as given.\n-func createCompany(service *talent.Service, parent string, companyToCreate *talent.Company) (*talent.Company, error) {\n-\tcreateCompanyRquest := &talent.CreateCompanyRequest{\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.CreateCompanyRequest{\n \t\tCompany: companyToCreate,\n \t}\n-\tcompany, err := service.Projects.Companies.Create(parent, createCompanyRquest).Do()\n+\tcompany, err := service.Projects.Companies.Create(parent, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to create company %q: %v\", companyToCreate.DisplayName, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -69,12 +46,26 @@\nfunc createCompany(service *talent.Service, parent string, companyToCreate *tale\n // [START get_company]\n \n // getCompany gets an existing company by name.\n-func getCompany(service *talent.Service, name string) (*talent.Company, error) {\n+func getCompany(w io.Writer, name string) (*talent.Company, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n \tcompany, err := service.Projects.Companies.Get(name).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to get company %q: %v\", name, err)\n \t}\n \n+\tfmt.Fprintf(w, \"Company: %q\\n\", company.Name)\n+\n \treturn company, nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -83,7 +74,19 @@\nfunc getCompany(service *talent.Service, name string) (*talent.Company, error) {\n // [START update_company]\n \n // updateCompany update a company with all fields.\n-func updateCompany(service *talent.Service, name string, companyToUpdate *talent.Company) (*talent.Company, error) {\n+func updateCompany(w io.Writer, name string, companyToUpdate *talent.Company) (*talent.Company, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n \tupdateCompanyRequest := &talent.UpdateCompanyRequest{\n \t\tCompany: companyToUpdate,\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -100,13 +103,25 @@\nfunc updateCompany(service *talent.Service, name string, companyToUpdate *talent\n // [START update_company_with_field_mask]\n \n // updateCompanyWithMask updates a company with specific fields.\n-// mask: comma separated top-level fields of Company\n-func updateCompanyWithMask(service *talent.Service, name string, mask string, companyToUpdate *talent.Company) (*talent.Company, error) {\n-\tupdateCompanyRequest := &talent.UpdateCompanyRequest{\n+// mask is a comma separated list of top-level fields of talent.Company.\n+func updateCompanyWithMask(w io.Writer, name string, mask string, companyToUpdate *talent.Company) (*talent.Company, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n+\treq := &talent.UpdateCompanyRequest{\n \t\tCompany:    companyToUpdate,\n \t\tUpdateMask: mask,\n \t}\n-\tcompany, err := service.Projects.Companies.Patch(name, updateCompanyRequest).Do()\n+\tcompany, err := service.Projects.Companies.Patch(name, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to update company %q with mask %q: %v\", name, mask, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -2,47 +2,41 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-package sample\n+package howto\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"log\"\n-\t\"time\"\n \n+\t\"golang.org/x/oauth2/google\"\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n-// [START basic_job]\n+// [START create_job]\n+\n+// createJob create a job as given.\n+func createJob(w io.Writer, projectID string, jobToCreate *talent.Job) (*talent.Job, error) {\n+\tctx := context.Background()\n \n-// constructJobWithRequiredFields constructs a basic job with given companyName and jobTitle.\n-func constructJobWithRequiredFields(companyName string, jobTitle string) *talent.Job {\n-\trequisitionID := fmt.Sprintf(\"sample-job-required-fields-%d\", time.Now().UnixNano())\n-\tapplicationInfo := &talent.ApplicationInfo{\n-\t\tUris: []string{\"https://googlesample.com/career\"},\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n \t}\n-\tjob := &talent.Job{\n-\t\tRequisitionId:   requisitionID,\n-\t\tTitle:           jobTitle,\n-\t\tCompanyName:     companyName,\n-\t\tApplicationInfo: applicationInfo,\n-\t\tDescription:     \"Design, devolop, test, deploy, maintain and improve software.\",\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n \t}\n-\treturn job\n-}\n-\n-// [END basic_job]\n-\n-// [START create_job]\n \n-// createJob create a job as given.\n-func createJob(service *talent.Service, parent string, jobToCreate *talent.Job) (*talent.Job, error) {\n-\tcreateJobRequest := &talent.CreateJobRequest{\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.CreateJobRequest{\n \t\tJob: jobToCreate,\n \t}\n-\tjob, err := service.Projects.Jobs.Create(parent, createJobRequest).Do()\n+\tjob, err := service.Projects.Jobs.Create(parent, req).Do()\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to create job %q, Err: %v\", jobToCreate.RequisitionId, err)\n+\t\treturn nil, fmt.Errorf(\"Failed to create job %q, Err: %v\", jobToCreate.RequisitionId, err)\n \t}\n \treturn job, err\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -52,27 +46,53 @@\nfunc createJob(service *talent.Service, parent string, jobToCreate *talent.Job)\n // [START get_job]\n \n // getJob gets a job by name.\n-func getJob(service *talent.Service, jobName string) (*talent.Job, error) {\n+func getJob(w io.Writer, jobName string) (*talent.Job, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n \tjob, err := service.Projects.Jobs.Get(jobName).Do()\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to get job %s, Err: %v\", jobName, err)\n+\t\treturn nil, fmt.Errorf(\"Failed to get job %s: %v\", jobName, err)\n \t}\n \n+\tfmt.Fprintf(w, \"Job: %q\", job.Name)\n+\n \treturn job, err\n }\n \n // [END get_job]\n \n // [START update_job]\n \n-// updateJob update a job with all fields except name\n-func updateJob(service *talent.Service, jobName string, jobToUpdate *talent.Job) (*talent.Job, error) {\n-\tupdateJobRequest := &talent.UpdateJobRequest{\n+// updateJob update a job with all fields except name.\n+func updateJob(w io.Writer, jobName string, jobToUpdate *talent.Job) (*talent.Job, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n+\treq := &talent.UpdateJobRequest{\n \t\tJob: jobToUpdate,\n \t}\n-\tjob, err := service.Projects.Jobs.Patch(jobName, updateJobRequest).Do()\n+\tjob, err := service.Projects.Jobs.Patch(jobName, req).Do()\n \tif err != nil {\n-\t\tlog.Fatalf(\"Failed to update job %s, Err: %v\", jobName, err)\n+\t\treturn nil, fmt.Errorf(\"Failed to update job %s: %v\", jobName, err)\n \t}\n \n \treturn job, err",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -82,14 +102,26 @@\nfunc updateJob(service *talent.Service, jobName string, jobToUpdate *talent.Job)\n \n // [START update_job_with_field_mask]\n \n-// updateJobWithMask updates a job by name with specific fields\n-// mask: comma separated top-level fields of Job\n-func updateJobWithMask(service *talent.Service, jobName string, mask string, jobToUpdate *talent.Job) (*talent.Job, error) {\n-\tupdateJobRequest := &talent.UpdateJobRequest{\n+// updateJobWithMask updates a job by name with specific fields.\n+// mask is a comma separated list top-level fields of talent.Job.\n+func updateJobWithMask(w io.Writer, jobName string, mask string, jobToUpdate *talent.Job) (*talent.Job, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n+\treq := &talent.UpdateJobRequest{\n \t\tJob:        jobToUpdate,\n \t\tUpdateMask: mask,\n \t}\n-\tjob, err := service.Projects.Jobs.Patch(jobName, updateJobRequest).Do()\n+\tjob, err := service.Projects.Jobs.Patch(jobName, req).Do()\n \tif err != nil {\n \t\tlog.Fatalf(\"Failed to update job %s with field mask %s, Err: %v\", jobName, mask, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/commute_search_sample.go",
        "code_diff": "@@ -2,30 +2,33 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-package sample\n+package howto\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\t\"time\"\n \n+\t\"golang.org/x/oauth2/google\"\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n // [START commute_search]\n \n // commuteSearch searches for jobs within commute filter.\n-func commuteSearch(service *talent.Service, parent string, companyName string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+func commuteSearch(w io.Writer, projectID, companyName string) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n \t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tCommuteFilter: &talent.CommuteFilter{\n \t\t\tRoadTraffic:    \"TRAFFIC_FREE\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -2,14 +2,15 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-package sample\n+package howto\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"time\"\n \n+\t\"golang.org/x/oauth2/google\"\n \ttalent \"google.golang.org/api/jobs/v3\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -19,30 +20,25 @@\nimport (\n func constructJobWithCustomAttributes(companyName string, jobTitle string) *talent.Job {\n \t// requisitionID shoud be the unique ID in your system\n \trequisitionID := fmt.Sprintf(\"job-with-custom-attribute-%d\", time.Now().UnixNano())\n-\tapplicationInfo := &talent.ApplicationInfo{\n-\t\tUris: []string{\"https://googlesample.com/career\"},\n-\t}\n-\tcustomAttrStr := &talent.CustomAttribute{\n-\t\tFilterable:   true,\n-\t\tStringValues: []string{\"someStrVal\"},\n-\t}\n-\tcustomAttrLong := &talent.CustomAttribute{\n-\t\tFilterable: true,\n-\t\tLongValues: []int64{900},\n-\t}\n-\n-\tcustomAttributes := map[string]talent.CustomAttribute{\n-\t\t\"someFieldString\": *customAttrStr,\n-\t\t\"someFieldLong\":   *customAttrLong,\n-\t}\n \n \tjob := &talent.Job{\n-\t\tRequisitionId:    requisitionID,\n-\t\tTitle:            jobTitle,\n-\t\tCompanyName:      companyName,\n-\t\tApplicationInfo:  applicationInfo,\n-\t\tDescription:      \"Design, devolop, test, deploy, maintain and improve software.\",\n-\t\tCustomAttributes: customAttributes,\n+\t\tRequisitionId: requisitionID,\n+\t\tTitle:         jobTitle,\n+\t\tCompanyName:   companyName,\n+\t\tApplicationInfo: &talent.ApplicationInfo{\n+\t\t\tUris: []string{\"https://googlesample.com/career\"},\n+\t\t},\n+\t\tDescription: \"Design, devolop, test, deploy, maintain and improve software.\",\n+\t\tCustomAttributes: map[string]talent.CustomAttribute{\n+\t\t\t\"someFieldString\": {\n+\t\t\t\tFilterable:   true,\n+\t\t\t\tStringValues: []string{\"someStrVal\"},\n+\t\t\t},\n+\t\t\t\"someFieldLong\": {\n+\t\t\t\tFilterable: true,\n+\t\t\t\tLongValues: []int64{900},\n+\t\t\t},\n+\t\t},\n \t}\n \treturn job\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/featured_job_search_sample.go",
        "code_diff": "@@ -2,20 +2,21 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-package sample\n+package howto\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"time\"\n \n+\t\"golang.org/x/oauth2/google\"\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n // [START featured_job]\n \n-// constructFeaturedJob constructs a job as featured/promoted one\n+// constructFeaturedJob constructs a job as featured/promoted one.\n func constructFeaturedJob(companyName string, jobTitle string) *talent.Job {\n \trequisitionID := fmt.Sprintf(\"featured-job-required-fields-%d\", time.Now().UnixNano())\n \tapplicationInfo := &talent.ApplicationInfo{",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -2,48 +2,67 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-package sample\n+package howto\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\t\"time\"\n \n+\t\"golang.org/x/oauth2/google\"\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n // [START basic_keyword_search]\n \n // basicJobSearch searches for jobs with query.\n-func basicJobSearch(service *talent.Service, parent string, companyName string, query string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+func basicJobSearch(w io.Writer, projectID, companyName, query string) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n \t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tQuery: query,\n \t}\n \tif companyName != \"\" {\n \t\tjobQuery.CompanyNames = []string{companyName}\n \t}\n \n-\tsearchJobsRequest := &talent.SearchJobsRequest{\n-\t\tRequestMetadata: requestMetadata,\n-\t\t// Set the actual search term as defined in the jobQurey\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.SearchJobsRequest{\n+\t\t// Make sure to set the requestMetadata the same as the associated\n+\t\t// search request.\n+\t\tRequestMetadata: &talent.RequestMetadata{\n+\t\t\t// Make sure to hash your userID\n+\t\t\tUserId: \"HashedUsrId\",\n+\t\t\t// Make sure to hash the sessionID\n+\t\t\tSessionId: \"HashedSessionId\",\n+\t\t\t// Domain of the website where the search is conducted\n+\t\t\tDomain: \"www.googlesample.com\",\n+\t\t},\n+\t\t// Set the actual search term as defined in the jobQuery\n \t\tJobQuery: jobQuery,\n \t\t// Set the search mode to a regular search\n \t\tSearchMode: \"JOB_SEARCH\",\n \t}\n-\tresp, err := service.Projects.Jobs.Search(parent, searchJobsRequest).Do()\n+\tresp, err := service.Projects.Jobs.Search(parent, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to search for jobs with query %q: %v\", query, err)\n \t}\n+\n+\tfmt.Fprintln(w, \"Jobs:\")\n+\tfor _, j := range resp.MatchingJobs {\n+\t\tfmt.Fprintf(w, \"\\t%q\\n\", j.Job.Name)\n+\t}\n+\n \treturn resp, nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -52,34 +71,53 @@\nfunc basicJobSearch(service *talent.Service, parent string, companyName string,\n // [START category_filter]\n \n // categoryFilterSearch searches for jobs on category filter.\n-func categoryFilterSearch(service *talent.Service, parent string, companyName string, categories []string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+func categoryFilterSearch(w io.Writer, projectID, companyName string, categories []string) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n \t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tJobCategories: categories,\n \t}\n \tif companyName != \"\" {\n \t\tjobQuery.CompanyNames = []string{companyName}\n \t}\n \n-\tsearchJobsRequest := &talent.SearchJobsRequest{\n-\t\tRequestMetadata: requestMetadata,\n-\t\t// Set the actual search term as defined in the jobQurey\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.SearchJobsRequest{\n+\t\t// Make sure to set the RequestMetadata the same as the associated\n+\t\t// search request.\n+\t\tRequestMetadata: &talent.RequestMetadata{\n+\t\t\t// Make sure to hash your userID.\n+\t\t\tUserId: \"HashedUsrId\",\n+\t\t\t// Make sure to hash the sessionID.\n+\t\t\tSessionId: \"HashedSessionId\",\n+\t\t\t// Domain of the website where the search is conducted.\n+\t\t\tDomain: \"www.googlesample.com\",\n+\t\t},\n+\t\t// Set the actual search term as defined in the jobQuery.\n \t\tJobQuery: jobQuery,\n-\t\t// Set the search mode to a regular search\n+\t\t// Set the search mode to a regular search.\n \t\tSearchMode: \"JOB_SEARCH\",\n \t}\n-\tresp, err := service.Projects.Jobs.Search(parent, searchJobsRequest).Do()\n+\tresp, err := service.Projects.Jobs.Search(parent, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to search for jobs with categories %v: %v\", categories, err)\n \t}\n+\n+\tfmt.Fprintln(w, \"Jobs:\")\n+\tfor _, j := range resp.MatchingJobs {\n+\t\tfmt.Fprintf(w, \"\\t%q\\n\", j.Job.Name)\n+\t}\n+\n \treturn resp, nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -88,58 +126,78 @@\nfunc categoryFilterSearch(service *talent.Service, parent string, companyName st\n // [START employment_types_filter]\n \n // employmentTypesSearch searches for jobs on employment types.\n-func employmentTypesSearch(service *talent.Service, parent string, companyName string, employmentTypes []string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+func employmentTypesSearch(w io.Writer, projectID, companyName string, employmentTypes []string) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n \t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tEmploymentTypes: employmentTypes,\n \t}\n \tif companyName != \"\" {\n \t\tjobQuery.CompanyNames = []string{companyName}\n \t}\n \n-\tsearchJobsRequest := &talent.SearchJobsRequest{\n-\t\tRequestMetadata: requestMetadata,\n-\t\t// Set the actual search term as defined in the jobQurey\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.SearchJobsRequest{\n+\t\t// Make sure to set the RequestMetadata the same as the associated\n+\t\t// search request.\n+\t\tRequestMetadata: &talent.RequestMetadata{\n+\t\t\t// Make sure to hash your userID.\n+\t\t\tUserId: \"HashedUsrId\",\n+\t\t\t// Make sure to hash the sessionID.\n+\t\t\tSessionId: \"HashedSessionId\",\n+\t\t\t// Domain of the website where the search is conducted.\n+\t\t\tDomain: \"www.googlesample.com\",\n+\t\t},\n+\t\t// Set the actual search term as defined in the jobQuery.\n \t\tJobQuery: jobQuery,\n-\t\t// Set the search mode to a regular search\n+\t\t// Set the search mode to a regular search.\n \t\tSearchMode: \"JOB_SEARCH\",\n \t}\n-\tresp, err := service.Projects.Jobs.Search(parent, searchJobsRequest).Do()\n+\tresp, err := service.Projects.Jobs.Search(parent, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to search for jobs with employment types %v: %v\", employmentTypes, err)\n \t}\n+\n+\tfmt.Fprintln(w, \"Jobs:\")\n+\tfor _, j := range resp.MatchingJobs {\n+\t\tfmt.Fprintf(w, \"\\t%q\\n\", j.Job.Name)\n+\t}\n+\n \treturn resp, nil\n }\n \n // [END employment_types_filter]\n \n // [START date_range_filter]\n \n-/**\n- * SdateRangeSearch searches for jobs on date range.\n- * In JSON format, the Timestamp type is encoded as a string in the\n- * [RFC 3339](https://www.ietf.org/rfc/rfc3339.txt) format. That is, the\n- * format is \"{year}-{month}-{day}T{hour}:{min}:{sec}[.{frac_sec}]Z\"\n- * e.g. \"2017-01-15T01:30:15.01Z\"\n- */\n-func dateRangeSearch(service *talent.Service, parent string, companyName string, startTime string, endTime string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+///dateRangeSearch searches for jobs on date range.\n+// In JSON format, the Timestamp type is encoded as a string in the\n+// [RFC 3339](https://www.ietf.org/rfc/rfc3339.txt) format. That is, the\n+// format is \"{year}-{month}-{day}T{hour}:{min}:{sec}[.{frac_sec}]Z\"\n+// e.g. \"2017-01-15T01:30:15.01Z\".\n+func dateRangeSearch(w io.Writer, projectID, companyName, startTime, endTime string) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n \t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tPublishTimeRange: &talent.TimestampRange{\n \t\t\tStartTime: startTime,",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -150,17 +208,33 @@\nfunc dateRangeSearch(service *talent.Service, parent string, companyName string,\n \t\tjobQuery.CompanyNames = []string{companyName}\n \t}\n \n-\tsearchJobsRequest := &talent.SearchJobsRequest{\n-\t\tRequestMetadata: requestMetadata,\n-\t\t// Set the actual search term as defined in the jobQurey\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.SearchJobsRequest{\n+\t\t// Make sure to set the RequestMetadata the same as the associated\n+\t\t// search request.\n+\t\tRequestMetadata: &talent.RequestMetadata{\n+\t\t\t// Make sure to hash your userID.\n+\t\t\tUserId: \"HashedUsrId\",\n+\t\t\t// Make sure to hash the sessionID.\n+\t\t\tSessionId: \"HashedSessionId\",\n+\t\t\t// Domain of the website where the search is conducted.\n+\t\t\tDomain: \"www.googlesample.com\",\n+\t\t},\n+\t\t// Set the actual search term as defined in the jobQuery.\n \t\tJobQuery: jobQuery,\n-\t\t// Set the search mode to a regular search\n+\t\t// Set the search mode to a regular search.\n \t\tSearchMode: \"JOB_SEARCH\",\n \t}\n-\tresp, err := service.Projects.Jobs.Search(parent, searchJobsRequest).Do()\n+\tresp, err := service.Projects.Jobs.Search(parent, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to search for jobs with date range [%s, %s]: %v\", startTime, endTime, err)\n \t}\n+\n+\tfmt.Fprintln(w, \"Jobs:\")\n+\tfor _, j := range resp.MatchingJobs {\n+\t\tfmt.Fprintf(w, \"\\t%q\\n\", j.Job.Name)\n+\t}\n+\n \treturn resp, nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/general_search_sample.go",
        "code_diff": "@@ -169,88 +243,129 @@\nfunc dateRangeSearch(service *talent.Service, parent string, companyName string,\n // [START language_code_filter]\n \n // languageCodeSearch searches for jobs on language code.\n-func languageCodeSearch(service *talent.Service, parent string, companyName string, languageCodes []string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+func languageCodeSearch(w io.Writer, projectID, companyName string, languageCodes []string) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n \t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tLanguageCodes: languageCodes,\n \t}\n \tif companyName != \"\" {\n \t\tjobQuery.CompanyNames = []string{companyName}\n \t}\n \n-\tsearchJobsRequest := &talent.SearchJobsRequest{\n-\t\tRequestMetadata: requestMetadata,\n-\t\t// Set the actual search term as defined in the jobQurey\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.SearchJobsRequest{\n+\t\t// Make sure to set the RequestMetadata the same as the associated\n+\t\t// search request.\n+\t\tRequestMetadata: &talent.RequestMetadata{\n+\t\t\t// Make sure to hash your userID.\n+\t\t\tUserId: \"HashedUsrId\",\n+\t\t\t// Make sure to hash the sessionID.\n+\t\t\tSessionId: \"HashedSessionId\",\n+\t\t\t// Domain of the website where the search is conducted.\n+\t\t\tDomain: \"www.googlesample.com\",\n+\t\t},\n+\t\t// Set the actual search term as defined in the jobQuery.\n \t\tJobQuery: jobQuery,\n-\t\t// Set the search mode to a regular search\n+\t\t// Set the search mode to a regular search.\n \t\tSearchMode: \"JOB_SEARCH\",\n \t}\n-\tresp, err := service.Projects.Jobs.Search(parent, searchJobsRequest).Do()\n+\tresp, err := service.Projects.Jobs.Search(parent, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to search for jobs with languange codes %v: %v\", languageCodes, err)\n \t}\n+\n+\tfmt.Fprintln(w, \"Jobs:\")\n+\tfor _, j := range resp.MatchingJobs {\n+\t\tfmt.Fprintf(w, \"\\t%q\\n\", j.Job.Name)\n+\t}\n+\n \treturn resp, nil\n }\n \n // [END language_code_filter]\n \n // [START company_display_name_filter]\n \n-// companyDisplayNameSearch searches for job on company display names\n-func companyDisplayNameSearch(service *talent.Service, parent string, companyName string, companyDisplayNames []string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+// companyDisplayNameSearch searches for job on company display names.\n+func companyDisplayNameSearch(w io.Writer, projectID, companyName string, companyDisplayNames []string) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n \t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tCompanyDisplayNames: companyDisplayNames,\n \t}\n \tif companyName != \"\" {\n \t\tjobQuery.CompanyNames = []string{companyName}\n \t}\n \n-\tsearchJobsRequest := &talent.SearchJobsRequest{\n-\t\tRequestMetadata: requestMetadata,\n-\t\t// Set the actual search term as defined in the jobQurey\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.SearchJobsRequest{\n+\t\t// Make sure to set the RequestMetadata the same as the associated\n+\t\t// search request.\n+\t\tRequestMetadata: &talent.RequestMetadata{\n+\t\t\t// Make sure to hash your userID.\n+\t\t\tUserId: \"HashedUsrId\",\n+\t\t\t// Make sure to hash the sessionID.\n+\t\t\tSessionId: \"HashedSessionId\",\n+\t\t\t// Domain of the website where the search is conducted.\n+\t\t\tDomain: \"www.googlesample.com\",\n+\t\t},\n+\t\t// Set the actual search term as defined in the jobQuery.\n \t\tJobQuery: jobQuery,\n-\t\t// Set the search mode to a regular search\n+\t\t// Set the search mode to a regular search.\n \t\tSearchMode: \"JOB_SEARCH\",\n \t}\n-\tresp, err := service.Projects.Jobs.Search(parent, searchJobsRequest).Do()\n+\tresp, err := service.Projects.Jobs.Search(parent, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to search for jobs with company display names %v: %v\", companyDisplayNames, err)\n \t}\n+\n+\tfmt.Fprintln(w, \"Jobs:\")\n+\tfor _, j := range resp.MatchingJobs {\n+\t\tfmt.Fprintf(w, \"\\t%q\\n\", j.Job.Name)\n+\t}\n+\n \treturn resp, nil\n }\n \n // [END company_display_name_filter]\n \n // [START compensation_fiter]\n \n-// compensationSearch searches for job on compensation\n-func compensationSearch(service *talent.Service, parent string, companyName string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+// compensationSearch searches for job on compensation.\n+func compensationSearch(w io.Writer, projectID, companyName string) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n \t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tCompensationFilter: &talent.CompensationFilter{\n \t\t\tType:  \"UNIT_AND_AMOUNT\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -2,30 +2,33 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-package sample\n+package howto\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\t\"time\"\n \n+\t\"golang.org/x/oauth2/google\"\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n // [START basic_location_search]\n \n-// basicLocationSearch searches for jobs within distance of location\n-func basicLocationSearch(service *talent.Service, parent string, companyName string, location string, distance float64) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+// basicLocationSearch searches for jobs within distance of location.\n+func basicLocationSearch(w io.Writer, projectID, companyName, location string, distance float64) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n \t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tLocationFilters: []*talent.LocationFilter{\n \t\t\t{",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -39,17 +42,33 @@\nfunc basicLocationSearch(service *talent.Service, parent string, companyName str\n \t\tjobQuery.CompanyNames = []string{companyName}\n \t}\n \n-\tsearchJobsRequest := &talent.SearchJobsRequest{\n-\t\tRequestMetadata: requestMetadata,\n-\t\t// Set the actual search term as defined in the jobQurey\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.SearchJobsRequest{\n+\t\t// Make sure to set the RequestMetadata the same as the associated\n+\t\t// search request.\n+\t\tRequestMetadata: &talent.RequestMetadata{\n+\t\t\t// Make sure to hash your userID.\n+\t\t\tUserId: \"HashedUsrId\",\n+\t\t\t// Make sure to hash the sessionID.\n+\t\t\tSessionId: \"HashedSessionId\",\n+\t\t\t// Domain of the website where the search is conducted.\n+\t\t\tDomain: \"www.googlesample.com\",\n+\t\t},\n+\t\t// Set the actual search term as defined in the jobQuery.\n \t\tJobQuery: jobQuery,\n-\t\t// Set the search mode to a regular search\n+\t\t// Set the search mode to a regular search.\n \t\tSearchMode: \"JOB_SEARCH\",\n \t}\n-\tresp, err := service.Projects.Jobs.Search(parent, searchJobsRequest).Do()\n+\tresp, err := service.Projects.Jobs.Search(parent, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to search for jobs with basic location %s within %f miles: %v\", location, distance, err)\n \t}\n+\n+\tfmt.Fprintln(w, \"Jobs:\")\n+\tfor _, j := range resp.MatchingJobs {\n+\t\tfmt.Fprintf(w, \"\\t%q\\n\", j.Job.Name)\n+\t}\n+\n \treturn resp, nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -58,16 +77,19 @@\nfunc basicLocationSearch(service *talent.Service, parent string, companyName str\n // [START city_location_search]\n \n // cityLocationSearch searches for jobs in the same city of given location.\n-func cityLocationSearch(service *talent.Service, parent string, companyName string, location string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+func cityLocationSearch(w io.Writer, projectID, companyName, location string) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n \t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tLocationFilters: []*talent.LocationFilter{\n \t\t\t{",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -80,35 +102,55 @@\nfunc cityLocationSearch(service *talent.Service, parent string, companyName stri\n \t\tjobQuery.CompanyNames = []string{companyName}\n \t}\n \n-\tsearchJobsRequest := &talent.SearchJobsRequest{\n-\t\tRequestMetadata: requestMetadata,\n-\t\t// Set the actual search term as defined in the jobQurey\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.SearchJobsRequest{\n+\t\t// Make sure to set the RequestMetadata the same as the associated\n+\t\t// search request.\n+\t\tRequestMetadata: &talent.RequestMetadata{\n+\t\t\t// Make sure to hash your userID.\n+\t\t\tUserId: \"HashedUsrId\",\n+\t\t\t// Make sure to hash the sessionID.\n+\t\t\tSessionId: \"HashedSessionId\",\n+\t\t\t// Domain of the website where the search is conducted.\n+\t\t\tDomain: \"www.googlesample.com\",\n+\t\t},\n+\t\t// Set the actual search term as defined in the jobQuery.\n \t\tJobQuery: jobQuery,\n-\t\t// Set the search mode to a regular search\n+\t\t// Set the search mode to a regular search.\n \t\tSearchMode: \"JOB_SEARCH\",\n \t}\n-\tresp, err := service.Projects.Jobs.Search(parent, searchJobsRequest).Do()\n+\tresp, err := service.Projects.Jobs.Search(parent, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to search for jobs with city location %s: %v\", location, err)\n \t}\n+\n+\tfmt.Fprintln(w, \"Jobs:\")\n+\tfor _, j := range resp.MatchingJobs {\n+\t\tfmt.Fprintf(w, \"\\t%q\\n\", j.Job.Name)\n+\t}\n+\n \treturn resp, nil\n }\n \n // [END city_location_search]\n \n // [START broadening_location_search]\n \n-// broadeningLocationSearch searches for jobs with a broadening area of given location.\n-func broadeningLocationSearch(service *talent.Service, parent string, companyName string, location string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+// broadeningLocationSearch searches for jobs with a broadening area of given\n+// location.\n+func broadeningLocationSearch(w io.Writer, projectID, companyName, location string) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n \t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tLocationFilters: []*talent.LocationFilter{\n \t\t\t{",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -121,36 +163,56 @@\nfunc broadeningLocationSearch(service *talent.Service, parent string, companyNam\n \t\tjobQuery.CompanyNames = []string{companyName}\n \t}\n \n-\tsearchJobsRequest := &talent.SearchJobsRequest{\n-\t\tRequestMetadata: requestMetadata,\n-\t\t// Set the actual search term as defined in the jobQurey\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.SearchJobsRequest{\n+\t\t// Make sure to set the RequestMetadata the same as the associated\n+\t\t// search request.\n+\t\tRequestMetadata: &talent.RequestMetadata{\n+\t\t\t// Make sure to hash your userID.\n+\t\t\tUserId: \"HashedUsrId\",\n+\t\t\t// Make sure to hash the sessionID.\n+\t\t\tSessionId: \"HashedSessionId\",\n+\t\t\t// Domain of the website where the search is conducted.\n+\t\t\tDomain: \"www.googlesample.com\",\n+\t\t},\n+\t\t// Set the actual search term as defined in the jobQuery.\n \t\tJobQuery: jobQuery,\n-\t\t// Set the search mode to a regular search\n+\t\t// Set the search mode to a regular search.\n \t\tSearchMode:       \"JOB_SEARCH\",\n \t\tEnableBroadening: true,\n \t}\n-\tresp, err := service.Projects.Jobs.Search(parent, searchJobsRequest).Do()\n+\tresp, err := service.Projects.Jobs.Search(parent, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to search for jobs with broadening location %v: %v\", location, err)\n \t}\n+\n+\tfmt.Fprintln(w, \"Jobs:\")\n+\tfor _, j := range resp.MatchingJobs {\n+\t\tfmt.Fprintf(w, \"\\t%q\\n\", j.Job.Name)\n+\t}\n+\n \treturn resp, nil\n }\n \n // [END broadening_location_search]\n \n // [START keyword_location_search]\n \n-// keywordLocationSearch searches for jobs with given keyword and within the distance of given location.\n-func keywordLocationSearch(service *talent.Service, parent string, companyName string, location string, distance float64, keyword string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+// keywordLocationSearch searches for jobs with given keyword and within the\n+// distance of given location.\n+func keywordLocationSearch(w io.Writer, projectID, companyName, location string, distance float64, keyword string) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n+\t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n \t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tLocationFilters: []*talent.LocationFilter{\n \t\t\t{",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "appengine/tasks: create_tasks executable",
        "pr_number": 712,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -165,43 +227,64 @@\nfunc keywordLocationSearch(service *talent.Service, parent string, companyName s\n \t\tjobQuery.CompanyNames = []string{companyName}\n \t}\n \n-\tsearchJobsRequest := &talent.SearchJobsRequest{\n-\t\tRequestMetadata: requestMetadata,\n-\t\t// Set the actual search term as defined in the jobQurey\n+\tparent := \"projects/\" + projectID\n+\treq := &talent.SearchJobsRequest{\n+\t\t// Make sure to set the RequestMetadata the same as the associated\n+\t\t// search request.\n+\t\tRequestMetadata: &talent.RequestMetadata{\n+\t\t\t// Make sure to hash your userID.\n+\t\t\tUserId: \"HashedUsrId\",\n+\t\t\t// Make sure to hash the sessionID.\n+\t\t\tSessionId: \"HashedSessionId\",\n+\t\t\t// Domain of the website where the search is conducted.\n+\t\t\tDomain: \"www.googlesample.com\",\n+\t\t},\n+\t\t// Set the actual search term as defined in the jobQuery.\n \t\tJobQuery: jobQuery,\n-\t\t// Set the search mode to a regular search\n+\t\t// Set the search mode to a regular search.\n \t\tSearchMode: \"JOB_SEARCH\",\n \t}\n-\tresp, err := service.Projects.Jobs.Search(parent, searchJobsRequest).Do()\n+\tresp, err := service.Projects.Jobs.Search(parent, req).Do()\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to search for jobs with keyword %q in location %v within %f miles: %v\", keyword, location, distance, err)\n \t}\n+\n+\tfmt.Fprintln(w, \"Jobs:\")\n+\tfor _, j := range resp.MatchingJobs {\n+\t\tfmt.Fprintf(w, \"\\t%q\\n\", j.Job.Name)\n+\t}\n+\n \treturn resp, nil\n }\n \n // [END keyword_location_search]\n \n // [START multi_locations_search]\n \n-// multiLocationsSearch searches for jobs that fall in the distance of any given locations.\n-func multiLocationsSearch(service *talent.Service, parent string, companyName string, location string, distance float64, location2 string) (*talent.SearchJobsResponse, error) {\n-\t// Make sure to set the requestMetadata the same as the associated search request\n-\trequestMetadata := &talent.RequestMetadata{\n-\t\t// Make sure to hash your userID\n-\t\tUserId: \"HashedUsrId\",\n-\t\t// Make sure to hash the sessionID\n-\t\tSessionId: \"HashedSessionId\",\n-\t\t// Domain of the website where the search is conducted\n-\t\tDomain: \"www.googlesample.com\",\n+// multiLocationsSearch searches for jobs that fall in the distance of any given\n+// locations.\n+func multiLocationsSearch(w io.Writer, projectID, companyName, location, location2 string, distance float64) (*talent.SearchJobsResponse, error) {\n+\tctx := context.Background()\n+\n+\tclient, err := google.DefaultClient(ctx, talent.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"google.DefaultClient: %v\", err)\n \t}\n+\t// Create the jobs service client.\n+\tservice, err := talent.New(client)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"talent.New: %v\", err)\n+\t}\n+\n \tjobQuery := &talent.JobQuery{\n \t\tLocationFilters: []*talent.LocationFilter{\n \t\t\t{\n \t\t\t\tAddress:         location,\n \t\t\t\tDistanceInMiles: distance,\n \t\t\t},\n \t\t\t{\n-\t\t\t\tAddress: location2,\n+\t\t\t\tAddress:         location2,\n+\t\t\t\tDistanceInMiles: distance,\n \t\t\t},\n \t\t},\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/create-tasks-exec",
        "commit_id": "ed0f9dfbad7b74cae50964b0af05ac1566f8464a"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "docs/appengine/storage/app.go",
        "code_diff": "@@ -2,8 +2,6 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-//[START sample]\n-\n // Package gcsdemo is an example App Engine app using the Google Cloud Storage API.\n package gcsdemo",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "docs/appengine/storage/app.go",
        "code_diff": "@@ -210,7 +208,6 @@\nfunc (d *demo) dumpStats(obj *storage.ObjectAttrs) {\n \tfmt.Fprintf(d.w, \"Updated: %v)\\n\", obj.Updated)\n }\n \n-//[START file_metadata]\n // statFile reads the stats of the named file in Google Cloud Storage.\n func (d *demo) statFile(fileName string) {\n \tio.WriteString(d.w, \"\\nFile stat:\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "docs/appengine/storage/app.go",
        "code_diff": "@@ -224,8 +221,6 @@\nfunc (d *demo) statFile(fileName string) {\n \td.dumpStats(obj)\n }\n \n-//[END file_metadata]\n-\n // createListFiles creates files that will be used by listBucket.\n func (d *demo) createListFiles() {\n \tio.WriteString(d.w, \"\\nCreating more files for listbucket...\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2018 Google Inc. All rights reserved.\n+// Copyright 2018 Google LLC. All rights reserved.\n // Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -9,13 +9,15 @@\nimport (\n \t\"bytes\"\n \t\"flag\"\n \t\"fmt\"\n+\t\"io\"\n \t\"io/ioutil\"\n \t\"os\"\n \t\"path/filepath\"\n \t\"reflect\"\n \n \t// [START imports]\n \t\"context\"\n+\tb64 \"encoding/base64\"\n \n \t\"golang.org/x/oauth2/google\"\n \tcloudiot \"google.golang.org/api/cloudiot/v1\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -24,9 +26,10 @@\nimport (\n \n // Registry Management\n \n+// [START iot_create_registry]\n+\n // createRegistry creates a device registry.\n-func createRegistry(projectID string, region string, registryID string, topicName string) (*cloudiot.DeviceRegistry, error) {\n-\t// [START iot_create_registry]\n+func createRegistry(w io.Writer, projectID string, region string, registryID string, topicName string) (*cloudiot.DeviceRegistry, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -54,19 +57,21 @@\nfunc createRegistry(projectID string, region string, registryID string, topicNam\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Created registry:\")\n-\tfmt.Println(\"\\tID: \", response.Id)\n-\tfmt.Println(\"\\tHTTP: \", response.HttpConfig.HttpEnabledState)\n-\tfmt.Println(\"\\tMQTT: \", response.MqttConfig.MqttEnabledState)\n-\tfmt.Println(\"\\tName: \", response.Name)\n-\t// [END iot_create_registry]\n+\tfmt.Fprintln(w, \"Created registry:\")\n+\tfmt.Fprintf(w, \"\\tID: %s\\n\", response.Id)\n+\tfmt.Fprintf(w, \"\\tHTTP: %s\\n\", response.HttpConfig.HttpEnabledState)\n+\tfmt.Fprintf(w, \"\\tMQTT: %s\\n\", response.MqttConfig.MqttEnabledState)\n+\tfmt.Fprintf(w, \"\\tName: %s\\n\", response.Name)\n \n \treturn response, err\n }\n \n-// deleteRegistry deletes a device registry\n-func deleteRegistry(projectID string, region string, registryID string) (*cloudiot.Empty, error) {\n-\t// [START iot_delete_registry]\n+// [END iot_create_registry]\n+\n+// [START iot_delete_registry]\n+\n+// deleteRegistry deletes a device registry if it is empty.\n+func deleteRegistry(w io.Writer, projectID string, region string, registryID string) (*cloudiot.Empty, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -85,14 +90,17 @@\nfunc deleteRegistry(projectID string, region string, registryID string) (*cloudi\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Deleted registry\")\n-\t// [END iot_delete_registry]\n+\tfmt.Fprintln(w, \"Deleted registry\")\n \n \treturn response, err\n }\n \n-func getRegistry(projectID string, region string, registryID string) (*cloudiot.DeviceRegistry, error) {\n-\t// [START iot_get_registry]\n+// [END iot_delete_registry]\n+\n+// [START iot_get_registry]\n+\n+// getRegistry gets information about a device registry given a registryID.\n+func getRegistry(w io.Writer, projectID string, region string, registryID string) (*cloudiot.DeviceRegistry, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -110,14 +118,22 @@\nfunc getRegistry(projectID string, region string, registryID string) (*cloudiot.\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\t// [END iot_get_iam]\n+\n+\tfmt.Fprintln(w, \"Got registry:\")\n+\tfmt.Fprintf(w, \"\\tID: %s\\n\", response.Id)\n+\tfmt.Fprintf(w, \"\\tHTTP: %s\\n\", response.HttpConfig.HttpEnabledState)\n+\tfmt.Fprintf(w, \"\\tMQTT: %s\\n\", response.MqttConfig.MqttEnabledState)\n+\tfmt.Fprintf(w, \"\\tName: %s\\n\", response.Name)\n \n \treturn response, err\n }\n \n-// getRegistryIam gets the IAM policy for a device registry.\n-func getRegistryIam(projectID string, region string, registryID string) (*cloudiot.Policy, error) {\n-\t// [START iot_get_iam_policy]\n+// [END iot_get_registry]\n+\n+// [START iot_list_registries]\n+\n+// listRegistries gets the names of device registries given a project / region.\n+func listRegistries(w io.Writer, projectID string, region string) ([]*cloudiot.DeviceRegistry, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -130,29 +146,26 @@\nfunc getRegistryIam(projectID string, region string, registryID string) (*cloudi\n \t\treturn nil, err\n \t}\n \n-\tvar req cloudiot.GetIamPolicyRequest\n-\n-\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n-\tresponse, err := client.Projects.Locations.Registries.GetIamPolicy(path, &req).Do()\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", projectID, region)\n+\tresponse, err := client.Projects.Locations.Registries.List(parent).Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Policy:\")\n-\tfor _, binding := range response.Bindings {\n-\t\tfmt.Fprintf(os.Stdout, \"Role: %s\\n\", binding.Role)\n-\t\tfor _, member := range binding.Members {\n-\t\t\tfmt.Fprintf(os.Stdout, \"\\tMember: %s\\n\", member)\n-\t\t}\n+\tfmt.Fprintln(w, \"Registries:\")\n+\tfor _, registry := range response.DeviceRegistries {\n+\t\tfmt.Fprintf(w, \"\\t%s\\n\", registry.Name)\n \t}\n-\t// [END iot_get_iam_policy]\n \n-\treturn response, err\n+\treturn response.DeviceRegistries, err\n }\n \n-// listRegistries gets the names of device registries given a project / region.\n-func listRegistries(projectID string, region string) ([]*cloudiot.DeviceRegistry, error) {\n-\t// [START iot_list_registries]\n+// [END iot_list_registries]\n+\n+// [START iot_get_iam_policy]\n+\n+// getRegistryIAM gets the IAM policy for a device registry.\n+func getRegistryIAM(w io.Writer, projectID string, region string, registryID string) (*cloudiot.Policy, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -165,24 +178,31 @@\nfunc listRegistries(projectID string, region string) ([]*cloudiot.DeviceRegistry\n \t\treturn nil, err\n \t}\n \n-\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", projectID, region)\n-\tresponse, err := client.Projects.Locations.Registries.List(parent).Do()\n+\tvar req cloudiot.GetIamPolicyRequest\n+\n+\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n+\tresponse, err := client.Projects.Locations.Registries.GetIamPolicy(path, &req).Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Registries:\")\n-\tfor _, registry := range response.DeviceRegistries {\n-\t\tfmt.Println(\"\\t\", registry.Name)\n+\tfmt.Fprintln(w, \"Policy:\")\n+\tfor _, binding := range response.Bindings {\n+\t\tfmt.Fprintf(w, \"Role: %s\\n\", binding.Role)\n+\t\tfor _, member := range binding.Members {\n+\t\t\tfmt.Fprintf(w, \"\\tMember: %s\\n\", member)\n+\t\t}\n \t}\n-\t// [END iot_list_registries]\n \n-\treturn response.DeviceRegistries, err\n+\treturn response, err\n }\n \n-// setRegistryIam sets the IAM policy for a device registry\n-func setRegistryIam(projectID string, region string, registryID string, member string, role string) (*cloudiot.Policy, error) {\n-\t// [START iot_set_iam_policy]\n+// [END iot_get_iam_policy]\n+\n+// [START iot_set_iam_policy]\n+\n+// setRegistryIAM sets the IAM policy for a device registry\n+func setRegistryIAM(w io.Writer, projectID string, region string, registryID string, member string, role string) (*cloudiot.Policy, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -211,17 +231,19 @@\nfunc setRegistryIam(projectID string, region string, registryID string, member s\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Set policy!\")\n-\t// [END iot_set_iam_policy]\n+\tfmt.Fprintf(w, \"Successfully set IAM policy for registry: %s\\n\", registryID)\n \n \treturn response, err\n }\n \n+// [END iot_set_iam_policy]\n+\n // Device Management\n \n-// createEs creates a device in a registry with ES credentials\n-func createEs(projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n-\t// [START iot_create_es_device]\n+// [START iot_create_es_device]\n+\n+// createES creates a device in a registry with ES credentials.\n+func createES(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -257,15 +279,17 @@\nfunc createEs(projectID string, region string, registry string, deviceID string,\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully created device.\")\n-\t// [END iot_create_es_device]\n+\tfmt.Fprintln(w, \"Successfully created ESA device\")\n \n \treturn response, err\n }\n \n-// createRsa creates a device in a registry with RS credentials\n-func createRsa(projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n-\t// [START iot_create_rsa_device]\n+// [END iot_create_es_device]\n+\n+// [START iot_create_rsa_device]\n+\n+// createRSA creates a device in a registry with RS credentials.\n+func createRSA(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -301,15 +325,17 @@\nfunc createRsa(projectID string, region string, registry string, deviceID string\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully created device.\")\n-\t// [END iot_create_rsa_device]\n+\tfmt.Fprintln(w, \"Successfully created RSA device\")\n \n \treturn response, err\n }\n \n-// createUnauth creates a device in a registry without credentials\n-func createUnauth(projectID string, region string, registry string, deviceID string) (*cloudiot.Device, error) {\n-\t// [START iot_create_unauth_device]\n+// [END iot_create_rsa_device]\n+\n+// [START iot_create_unauth_device]\n+\n+// createUnauth creates a device in a registry without credentials.\n+func createUnauth(w io.Writer, projectID string, region string, registry string, deviceID string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -331,15 +357,17 @@\nfunc createUnauth(projectID string, region string, registry string, deviceID str\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully created device.\")\n-\t// [END iot_create_unauth_device]\n+\tfmt.Fprintln(w, \"Successfully created device without credentials\")\n \n \treturn response, err\n }\n \n-// deleteDevice deletes a device from a registry\n-func deleteDevice(projectID string, region string, registry string, deviceID string) (*cloudiot.Empty, error) {\n-\t// [START iot_delete_device]\n+// [END iot_create_unauth_device]\n+\n+// [START iot_delete_device]\n+\n+// deleteDevice deletes a device from a registry.\n+func deleteDevice(w io.Writer, projectID string, region string, registry string, deviceID string) (*cloudiot.Empty, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -358,15 +386,17 @@\nfunc deleteDevice(projectID string, region string, registry string, deviceID str\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Deleted device!\")\n-\t// [END iot_delete_device]\n+\tfmt.Fprintf(w, \"Deleted device: %s\\n\", deviceID)\n \n \treturn response, err\n }\n \n-// getDevice retrieves a specific device and prints its details\n-func getDevice(projectID string, region string, registry string, device string) (*cloudiot.Device, error) {\n-\t// [START iot_get_device]\n+// [END iot_delete_device]\n+\n+// [START iot_get_device]\n+\n+// getDevice retrieves a specific device and prints its details.\n+func getDevice(w io.Writer, projectID string, region string, registry string, device string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -385,26 +415,28 @@\nfunc getDevice(projectID string, region string, registry string, device string)\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"\\tId: \", response.Id)\n+\tfmt.Fprintf(w, \"\\tId: %s\\n\", response.Id)\n \tfor _, credential := range response.Credentials {\n-\t\tfmt.Println(\"\\t\\tCredential Expire: \", credential.ExpirationTime)\n-\t\tfmt.Println(\"\\t\\tCredential Type: \", credential.PublicKey.Format)\n-\t\tfmt.Println(\"\\t\\t--------\")\n+\t\tfmt.Fprintf(w, \"\\t\\tCredential Expire: %s\\n\", credential.ExpirationTime)\n+\t\tfmt.Fprintf(w, \"\\t\\tCredential Type: %s\\n\", credential.PublicKey.Format)\n+\t\tfmt.Fprintln(w, \"\\t\\t--------\")\n \t}\n-\tfmt.Println(\"\\tLast Config Ack: \", response.LastConfigAckTime)\n-\tfmt.Println(\"\\tLast Config Send: \", response.LastConfigSendTime)\n-\tfmt.Println(\"\\tLast Event Time: \", response.LastEventTime)\n-\tfmt.Println(\"\\tLast Heartbeat Time: \", response.LastHeartbeatTime)\n-\tfmt.Println(\"\\tLast State Time: \", response.LastStateTime)\n-\tfmt.Println(\"\\tNumId: \", response.NumId)\n+\tfmt.Fprintf(w, \"\\tLast Config Ack: %s\\n\", response.LastConfigAckTime)\n+\tfmt.Fprintf(w, \"\\tLast Config Send: %s\\n\", response.LastConfigSendTime)\n+\tfmt.Fprintf(w, \"\\tLast Event Time: %s\\n\", response.LastEventTime)\n+\tfmt.Fprintf(w, \"\\tLast Heartbeat Time: %s\\n\", response.LastHeartbeatTime)\n+\tfmt.Fprintf(w, \"\\tLast State Time: %s\\n\", response.LastStateTime)\n+\tfmt.Fprintf(w, \"\\tNumId: %d\\n\", response.NumId)\n \n \treturn response, err\n-\t// [END iot_get_device]\n }\n \n-// getDeviceConfigs retrieves and lists device configurations\n-func getDeviceConfigs(projectID string, region string, registry string, device string) ([]*cloudiot.DeviceConfig, error) {\n-\t// [START iot_get_device_configs]\n+// [END iot_get_device]\n+\n+// [START iot_get_device_configs]\n+\n+// getDeviceConfigs retrieves and lists device configurations.\n+func getDeviceConfigs(w io.Writer, projectID string, region string, registry string, device string) ([]*cloudiot.DeviceConfig, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -424,16 +456,18 @@\nfunc getDeviceConfigs(projectID string, region string, registry string, device s\n \t}\n \n \tfor _, config := range response.DeviceConfigs {\n-\t\tfmt.Println(config.Version, \" : \", config.BinaryData)\n+\t\tfmt.Fprintf(w, \"%d : %s\\n\", config.Version, config.BinaryData)\n \t}\n-\t// [END iot_get_device_configs]\n \n \treturn response.DeviceConfigs, err\n }\n \n-// getDeviceStates retrieves and lists device states\n-func getDeviceStates(projectID string, region string, registry string, device string) ([]*cloudiot.DeviceState, error) {\n-\t// [START iot_get_device_state]\n+// [END iot_get_device_configs]\n+\n+// [START iot_get_device_state]\n+\n+// getDeviceStates retrieves and lists device states.\n+func getDeviceStates(w io.Writer, projectID string, region string, registry string, device string) ([]*cloudiot.DeviceState, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -452,19 +486,21 @@\nfunc getDeviceStates(projectID string, region string, registry string, device st\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully retrieved device states!\")\n+\tfmt.Fprintln(w, \"Successfully retrieved device states!\")\n \n \tfor _, state := range response.DeviceStates {\n-\t\tfmt.Println(state.UpdateTime, \" : \", state.BinaryData)\n+\t\tfmt.Fprintf(w, \"%s : %s\\n\", state.UpdateTime, state.BinaryData)\n \t}\n-\t// [END iot_get_device_state]\n \n \treturn response.DeviceStates, err\n }\n \n-// listDevices gets the identifiers of devices given a registry name\n-func listDevices(projectID string, region string, registry string) ([]*cloudiot.Device, error) {\n-\t// [START iot_list_devices]\n+// [END iot_get_device_state]\n+\n+// [START iot_list_devices]\n+\n+// listDevices gets the identifiers of devices given a registry name.\n+func listDevices(w io.Writer, projectID string, region string, registry string) ([]*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -483,18 +519,20 @@\nfunc listDevices(projectID string, region string, registry string) ([]*cloudiot.\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Devices:\")\n+\tfmt.Fprintln(w, \"Devices:\")\n \tfor _, device := range response.Devices {\n-\t\tfmt.Println(\"\\t\", device.Id)\n+\t\tfmt.Fprintf(w, \"\\t%s\\n\", device.Id)\n \t}\n-\t// [END iot_list_devices]\n \n \treturn response.Devices, err\n }\n \n-// patchDeviceEs patches a device to use ES credentials\n-func patchDeviceEs(projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n-\t// [START iot_patch_es]\n+// [END iot_list_devices]\n+\n+// [START iot_patch_es]\n+\n+// patchDeviceES patches a device to use ES credentials.\n+func patchDeviceES(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -531,15 +569,17 @@\nfunc patchDeviceEs(projectID string, region string, registry string, deviceID st\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully patched device.\")\n-\t// [END iot_patch_es]\n+\tfmt.Fprintln(w, \"Successfully patched device with ES credentials\")\n \n \treturn response, err\n }\n \n-// patchDeviceRsa patches a device to use RSA credentials\n-func patchDeviceRsa(projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n-\t// [START iot_patch_rsa]\n+// [END iot_patch_es]\n+\n+// [START iot_patch_rsa]\n+\n+// patchDeviceRSA patches a device to use RSA credentials.\n+func patchDeviceRSA(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -576,15 +616,17 @@\nfunc patchDeviceRsa(projectID string, region string, registry string, deviceID s\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully patched device.\")\n-\t// [END iot_patch_rsa]\n+\tfmt.Fprintln(w, \"Successfully patched device\")\n \n \treturn response, err\n }\n \n+// [END iot_patch_rsa]\n+\n+// [START iot_set_device_config]\n+\n // setConfig sends a configuration change to a device.\n-func setConfig(projectID string, region string, registry string, deviceID string, configData string) (*cloudiot.DeviceConfig, error) {\n-\t// [START iot_set_device_config]\n+func setConfig(w io.Writer, projectID string, region string, registry string, deviceID string, configData string, format string) (*cloudiot.DeviceConfig, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -598,7 +640,7 @@\nfunc setConfig(projectID string, region string, registry string, deviceID string\n \t}\n \n \treq := cloudiot.ModifyCloudToDeviceConfigRequest{\n-\t\tBinaryData: configData,\n+\t\tBinaryData: b64.StdEncoding.EncodeToString([]byte(configData)),\n \t}\n \n \tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, deviceID)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -607,12 +649,47 @@\nfunc setConfig(projectID string, region string, registry string, deviceID string\n \t\treturn nil, err\n \t}\n \n-\tfmt.Fprintf(os.Stdout, \"Config set!\\nVersion now: %d\", response.Version)\n-\t// [END iot_set_device_config]\n+\tfmt.Fprintf(w, \"Config set!\\nVersion now: %d\\n\", response.Version)\n \n \treturn response, err\n }\n \n+// [END iot_set_device_config]\n+\n+// [START iot_send_command]\n+\n+// sendCommand sends a command to a device listening for commands.\n+func sendCommand(w io.Writer, projectID string, region string, registry string, deviceID string, sendData string) (*cloudiot.SendCommandToDeviceResponse, error) {\n+\t// Authorize the client using Application Default Credentials.\n+\t// See https://g.co/dv/identity/protocols/application-default-credentials\n+\tctx := context.Background()\n+\thttpClient, err := google.DefaultClient(ctx, cloudiot.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tclient, err := cloudiot.New(httpClient)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\treq := cloudiot.SendCommandToDeviceRequest{\n+\t\tBinaryData: b64.StdEncoding.EncodeToString([]byte(sendData)),\n+\t}\n+\n+\tname := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, deviceID)\n+\n+\tresponse, err := client.Projects.Locations.Registries.Devices.SendCommandToDevice(name, &req).Do()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tfmt.Fprintln(w, \"Sent command to device\")\n+\n+\treturn response, err\n+}\n+\n+// [END iot_send_command]\n+\n type command struct {\n \tname string\n \tfn   interface{}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -638,22 +715,23 @@\nfunc main() {\n \t\t{\"deleteRegistry\", deleteRegistry, []string{\"cloud-region\", \"registry-id\"}},\n \t\t{\"getRegistry\", getRegistry, []string{\"cloud-region\", \"registry-id\"}},\n \t\t{\"listRegistries\", listRegistries, []string{\"cloud-region\"}},\n-\t\t{\"getRegistryIam\", getRegistryIam, []string{\"cloud-region\", \"registry-id\"}},\n-\t\t{\"setRegistryIam\", setRegistryIam, []string{\"cloud-region\", \"registry-id\", \"member\", \"role\"}},\n+\t\t{\"getRegistryIAM\", getRegistryIAM, []string{\"cloud-region\", \"registry-id\"}},\n+\t\t{\"setRegistryIAM\", setRegistryIAM, []string{\"cloud-region\", \"registry-id\", \"member\", \"role\"}},\n \t}\n \n \tdeviceManagementCommands := []command{\n-\t\t{\"createEs\", createEs, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n-\t\t{\"createRsa\", createRsa, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n+\t\t{\"createES\", createES, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n+\t\t{\"createRSA\", createRSA, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n \t\t{\"createUnauth\", createUnauth, []string{\"cloud-region\", \"registry-id\", \"device-id\"}},\n \t\t{\"deleteDevice\", deleteDevice, []string{\"cloud-region\", \"registry-id\", \"device-id\"}},\n \t\t{\"getDevice\", getDevice, []string{\"cloud-region\", \"registry-id\", \"device-id\"}},\n \t\t{\"getDeviceConfigs\", getDeviceConfigs, []string{\"cloud-region\", \"registry-id\", \"device-id\"}},\n \t\t{\"getDeviceStates\", getDeviceStates, []string{\"cloud-region\", \"registry-id\", \"device-id\"}},\n \t\t{\"listDevices\", listDevices, []string{\"cloud-region\", \"registry-id\"}},\n-\t\t{\"patchDeviceEs\", patchDeviceEs, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n-\t\t{\"patchDeviceRsa\", patchDeviceRsa, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n+\t\t{\"patchDevice\", patchDeviceES, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n+\t\t{\"patchDeviceRSA\", patchDeviceRSA, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n \t\t{\"setConfig\", setConfig, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"config-data\"}},\n+\t\t{\"sendCommand\", sendCommand, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"send-data\"}},\n \t}\n \n \tvar commands []command",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -676,7 +754,7 @@\nfunc main() {\n \t}\n \tflag.Parse()\n \n-\t// Retrieve project ID from console\n+\t// Retrieve project ID from console.\n \tprojectID := os.Getenv(\"GCLOUD_PROJECT\")\n \tif projectID == \"\" {\n \t\tprojectID = os.Getenv(\"GOOGLE_CLOUD_PROJECT\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -29,6 +29,7 @@\ntype adminCommand func(ctx context.Context, w io.Writer, adminClient *database.D\n var (\n \tcommands = map[string]command{\n \t\t\"write\":                      write,\n+\t\t\"delete\":                     delete,\n \t\t\"query\":                      query,\n \t\t\"read\":                       read,\n \t\t\"update\":                     update,",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "vision: add product search samples",
        "pr_number": 695,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -14,6 +14,7 @@\nimport (\n )\n \n const catVideo = \"gs://demomaker/cat.mp4\"\n+const googleworkVideo = \"gs://python-docs-samples-tests/video/googlework_short.mp4\"\n \n func TestAnalyze(t *testing.T) {\n \ttestutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-ps-ga",
        "commit_id": "7c918daaad558a40c2a96194efabaec1f006845e"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "docs/appengine/storage/app.go",
        "code_diff": "@@ -2,8 +2,6 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-//[START sample]\n-\n // Package gcsdemo is an example App Engine app using the Google Cloud Storage API.\n package gcsdemo",
        "comments": [],
        "commit_message": "Merge branch 'master' into iot-commands-samples",
        "commit_id": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "docs/appengine/storage/app.go",
        "code_diff": "@@ -210,7 +208,6 @@\nfunc (d *demo) dumpStats(obj *storage.ObjectAttrs) {\n \tfmt.Fprintf(d.w, \"Updated: %v)\\n\", obj.Updated)\n }\n \n-//[START file_metadata]\n // statFile reads the stats of the named file in Google Cloud Storage.\n func (d *demo) statFile(fileName string) {\n \tio.WriteString(d.w, \"\\nFile stat:\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into iot-commands-samples",
        "commit_id": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "docs/appengine/storage/app.go",
        "code_diff": "@@ -224,8 +221,6 @@\nfunc (d *demo) statFile(fileName string) {\n \td.dumpStats(obj)\n }\n \n-//[END file_metadata]\n-\n // createListFiles creates files that will be used by listBucket.\n func (d *demo) createListFiles() {\n \tio.WriteString(d.w, \"\\nCreating more files for listbucket...\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into iot-commands-samples",
        "commit_id": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -29,6 +29,7 @@\ntype adminCommand func(ctx context.Context, w io.Writer, adminClient *database.D\n var (\n \tcommands = map[string]command{\n \t\t\"write\":                      write,\n+\t\t\"delete\":                     delete,\n \t\t\"query\":                      query,\n \t\t\"read\":                       read,\n \t\t\"update\":                     update,",
        "comments": [],
        "commit_message": "Merge branch 'master' into iot-commands-samples",
        "commit_id": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -14,6 +14,7 @@\nimport (\n )\n \n const catVideo = \"gs://demomaker/cat.mp4\"\n+const googleworkVideo = \"gs://python-docs-samples-tests/video/googlework_short.mp4\"\n \n func TestAnalyze(t *testing.T) {\n \ttestutil.SystemTest(t)",
        "comments": [],
        "commit_message": "Merge branch 'master' into iot-commands-samples",
        "commit_id": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "appengine_flexible/pubsub: verify token and log startup",
        "pr_number": 690,
        "file_name": "appengine_flexible/pubsub/pubsub.go",
        "code_diff": "@@ -16,7 +16,6 @@\nimport (\n \t\"sync\"\n \n \t\"cloud.google.com/go/pubsub\"\n-\t\"google.golang.org/appengine\"\n )\n \n var (",
        "comments": [],
        "commit_message": "appengine_flexible/pubsub: verify token and log startup",
        "commit_id": "8bbdf56ab23de9380b68c94998773a038669ed26"
    },
    {
        "pr_title": "appengine_flexible/pubsub: verify token and log startup",
        "pr_number": 690,
        "file_name": "appengine_flexible/pubsub/pubsub.go",
        "code_diff": "@@ -25,6 +24,9 @@\nvar (\n \t// Messages received by this instance.\n \tmessagesMu sync.Mutex\n \tmessages   []string\n+\n+\t// token is used to verify push requests.\n+\ttoken = mustGetenv(\"PUBSUB_VERIFICATION_TOKEN\")\n )\n \n const maxMessages = 10",
        "comments": [],
        "commit_message": "appengine_flexible/pubsub: verify token and log startup",
        "commit_id": "8bbdf56ab23de9380b68c94998773a038669ed26"
    },
    {
        "pr_title": "appengine_flexible/pubsub: verify token and log startup",
        "pr_number": 690,
        "file_name": "appengine_flexible/pubsub/pubsub.go",
        "code_diff": "@@ -37,9 +39,9 @@\nfunc main() {\n \t\tlog.Fatal(err)\n \t}\n \n-\t// Create topic if it doesn't exist.\n \ttopicName := mustGetenv(\"PUBSUB_TOPIC\")\n \ttopic = client.Topic(topicName)\n+\n \t// Create the topic if it doesn't exist.\n \texists, err := topic.Exists(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "appengine_flexible/pubsub: verify token and log startup",
        "commit_id": "8bbdf56ab23de9380b68c94998773a038669ed26"
    },
    {
        "pr_title": "appengine_flexible/pubsub: verify token and log startup",
        "pr_number": 690,
        "file_name": "appengine_flexible/pubsub/pubsub.go",
        "code_diff": "@@ -57,7 +59,14 @@\nfunc main() {\n \thttp.HandleFunc(\"/pubsub/publish\", publishHandler)\n \thttp.HandleFunc(\"/pubsub/push\", pushHandler)\n \n-\tappengine.Main()\n+\tport := os.Getenv(\"PORT\")\n+\tif port == \"\" {\n+\t\tport = \"8080\"\n+\t\tlog.Printf(\"Defaulting to port %s\", port)\n+\t}\n+\n+\tlog.Printf(\"Listening on port %s\", port)\n+\tlog.Fatal(http.ListenAndServe(fmt.Sprintf(\":%s\", port), nil))\n }\n \n func mustGetenv(k string) string {",
        "comments": [],
        "commit_message": "appengine_flexible/pubsub: verify token and log startup",
        "commit_id": "8bbdf56ab23de9380b68c94998773a038669ed26"
    },
    {
        "pr_title": "gettingstarted/bookshelf/app: don't rely on port 8080 being open in tests",
        "pr_number": 677,
        "file_name": "getting-started/bookshelf/app/app_test.go",
        "code_diff": "@@ -14,6 +14,7 @@\nimport (\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/getting-started/bookshelf\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/webtest\"\n )",
        "comments": [],
        "commit_message": "Reintroduce TestMainFunc as TestBuildable.",
        "commit_id": "ebf2964349e840a8db3dc74f6f849b7f9f5b7771"
    },
    {
        "pr_title": "monitoring: add new timeseries samples",
        "pr_number": 671,
        "file_name": "monitoring/snippets/snippets_test.go",
        "code_diff": "@@ -20,7 +20,7 @@\nfunc TestReadTimeSeriesAlign(t *testing.T) {\n \t}\n \twant := \"Done\"\n \tif got := buf.String(); !strings.Contains(got, want) {\n-\t\tt.Errorf(\"readTimeSeriesAlign got %q, want to contain %q\", got, want)\n+\t\tt.Errorf(\"readTimeSeriesAlign() = %q, want to contain %q\", got, want)\n \t}\n }",
        "comments": [
            {
                "comment": "Nit: inconsistent use of a colon after function name across t.Errorf messages",
                "position": null
            },
            {
                "comment": "Switched to `readTimeSeriesReduce() = %q, want to contain %q` per guidelines.",
                "position": null
            }
        ],
        "commit_message": "monitoring: use = instead of got for test errors",
        "commit_id": "bbb231280bb648da506b30cab3a185e403c82d2e"
    },
    {
        "pr_title": "monitoring: add new timeseries samples",
        "pr_number": 671,
        "file_name": "monitoring/snippets/snippets_test.go",
        "code_diff": "@@ -32,7 +32,7 @@\nfunc TestReadTimeSeriesReduce(t *testing.T) {\n \t}\n \twant := \"Done\"\n \tif got := buf.String(); !strings.Contains(got, want) {\n-\t\tt.Errorf(\"readTimeSeriesReduce got %q, want to contain %q\", got, want)\n+\t\tt.Errorf(\"readTimeSeriesReduce() = %q, want to contain %q\", got, want)\n \t}\n }",
        "comments": [
            {
                "comment": "Nit: inconsistent use of a colon after function name across t.Errorf messages",
                "position": null
            },
            {
                "comment": "Switched to `readTimeSeriesReduce() = %q, want to contain %q` per guidelines.",
                "position": null
            }
        ],
        "commit_message": "monitoring: use = instead of got for test errors",
        "commit_id": "bbb231280bb648da506b30cab3a185e403c82d2e"
    },
    {
        "pr_title": "profiler: add a sample simulating multiple calls to an expensive library function.",
        "pr_number": 670,
        "file_name": "profiler/hotmid/main.go",
        "code_diff": "@@ -20,9 +20,9 @@\nimport (\n )\n \n var (\n-\t// Service version to configure.\n+\t// version is the service version to configure.\n \tversion = flag.String(\"version\", \"1.0.0\", \"service version\")\n-\t// Benchmark duration or 0 to run forever.\n+\t// seconds is the benchmark duration in seconds or 0 to run forever.\n \tseconds = flag.Int(\"seconds\", 0, \"benchmark duration in seconds\")\n )",
        "comments": [
            {
                "comment": "Love these comments. Would you mind starting them with the thing being described? https://github.com/golang/go/wiki/CodeReviewComments#comment-sentences",
                "position": null
            },
            {
                "comment": "I wonder if this would be more clear as (untested):\r\n```suggestion\r\n\tduration := time.Duration(*seconds)*time.Second\r\n\tfor start := time.Now(); *seconds == 0 || time.Since(start) < duration; {\r\n```",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "Address review comments.",
        "commit_id": "7c2e844ad20a4fef231a04a548ff97b7b2d6a1db"
    },
    {
        "pr_title": "firestore: add regions sample data and two queries",
        "pr_number": 659,
        "file_name": "errorreporting/errorreporting_quickstart/main.go",
        "code_diff": "@@ -4,7 +4,6 @@\n// [START error_reporting_setup_go]\n // [START error_reporting_quickstart]\n-// [START errorreporting_quickstart]\n \n // Sample errorreporting_quickstart contains is a quickstart\n // example for the Google Cloud Error Reporting API.",
        "comments": [],
        "commit_message": "Merge branch 'master' into firestore-regions-queries",
        "commit_id": "00594c486c4f729613d1b8fd5d18da637c0ba33d"
    },
    {
        "pr_title": "firestore: add regions sample data and two queries",
        "pr_number": 659,
        "file_name": "profiler/snippets/snippets.go",
        "code_diff": "@@ -3,7 +3,6 @@\n// license that can be found in the LICENSE file.\n \n // [START profiler_setup_go_compute_engine]\n-// [START profiler_start]\n \n // snippets is an example of starting cloud.google.com/go/profiler.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into firestore-regions-queries",
        "commit_id": "00594c486c4f729613d1b8fd5d18da637c0ba33d"
    },
    {
        "pr_title": "firestore: add regions sample data and two queries",
        "pr_number": 659,
        "file_name": "trace/trace_quickstart/main.go",
        "code_diff": "@@ -3,9 +3,8 @@\n// license that can be found in the LICENSE file.\n \n // [START trace_setup_go_quickstart]\n-// [START trace_quickstart]\n \n-// Sample trace_quickstart creates traces incoming and outgoing requests.\n+// Sample trace_quickstart traces incoming and outgoing requests.\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into firestore-regions-queries",
        "commit_id": "00594c486c4f729613d1b8fd5d18da637c0ba33d"
    },
    {
        "pr_title": "appengine/warmup: initial port of warmup to go 1.11",
        "pr_number": 658,
        "file_name": "errorreporting/errorreporting_quickstart/main.go",
        "code_diff": "@@ -4,7 +4,6 @@\n// [START error_reporting_setup_go]\n // [START error_reporting_quickstart]\n-// [START errorreporting_quickstart]\n \n // Sample errorreporting_quickstart contains is a quickstart\n // example for the Google Cloud Error Reporting API.",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/warmup/111",
        "commit_id": "9755783a07778fad21d310c6132db6df5ecd6639"
    },
    {
        "pr_title": "appengine/warmup: initial port of warmup to go 1.11",
        "pr_number": 658,
        "file_name": "firestore/firestore_snippets/main.go",
        "code_diff": "@@ -15,13 +15,15 @@\nimport (\n )\n \n // [START fs_class_definition]\n+\n // City represents a city.\n type City struct {\n-\tName       string `firestore:\"name,omitempty\"`\n-\tState      string `firestore:\"state,omitempty\"`\n-\tCountry    string `firestore:\"country,omitempty\"`\n-\tCapital    bool   `firestore:\"capital,omitempty\"`\n-\tPopulation int64  `firestore:\"population,omitempty\"`\n+\tName       string   `firestore:\"name,omitempty\"`\n+\tState      string   `firestore:\"state,omitempty\"`\n+\tCountry    string   `firestore:\"country,omitempty\"`\n+\tCapital    bool     `firestore:\"capital,omitempty\"`\n+\tPopulation int64    `firestore:\"population,omitempty\"`\n+\tRegions    []string `firestore:\"regions,omitempty\"`\n }\n \n // [END fs_class_definition]",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/warmup/111",
        "commit_id": "9755783a07778fad21d310c6132db6df5ecd6639"
    },
    {
        "pr_title": "appengine/warmup: initial port of warmup to go 1.11",
        "pr_number": 658,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage main\n // [START fs_dependencies]\n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/firestore\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/warmup/111",
        "commit_id": "9755783a07778fad21d310c6132db6df5ecd6639"
    },
    {
        "pr_title": "appengine/warmup: initial port of warmup to go 1.11",
        "pr_number": 658,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -19,11 +20,36 @@\nfunc prepareQuery(ctx context.Context, client *firestore.Client) error {\n \t\tid string\n \t\tc  City\n \t}{\n-\t\t{id: \"SF\", c: City{Name: \"San Francisco\", State: \"CA\", Country: \"USA\", Capital: false, Population: 860000}},\n-\t\t{id: \"LA\", c: City{Name: \"Los Angeles\", State: \"CA\", Country: \"USA\", Capital: false, Population: 3900000}},\n-\t\t{id: \"DC\", c: City{Name: \"Washington D.C.\", Country: \"USA\", Capital: false, Population: 680000}},\n-\t\t{id: \"TOK\", c: City{Name: \"Tokyo\", Country: \"Japan\", Capital: true, Population: 9000000}},\n-\t\t{id: \"BJ\", c: City{Name: \"Beijing\", Country: \"China\", Capital: true, Population: 21500000}},\n+\t\t{\n+\t\t\tid: \"SF\",\n+\t\t\tc: City{Name: \"San Francisco\", State: \"CA\", Country: \"USA\",\n+\t\t\t\tCapital: false, Population: 860000,\n+\t\t\t\tRegions: []string{\"west_coast\", \"norcal\"}},\n+\t\t},\n+\t\t{\n+\t\t\tid: \"LA\",\n+\t\t\tc: City{Name: \"Los Angeles\", State: \"CA\", Country: \"USA\",\n+\t\t\t\tCapital: false, Population: 3900000,\n+\t\t\t\tRegions: []string{\"west_coast\", \"socal\"}},\n+\t\t},\n+\t\t{\n+\t\t\tid: \"DC\",\n+\t\t\tc: City{Name: \"Washington D.C.\", Country: \"USA\",\n+\t\t\t\tCapital: false, Population: 680000,\n+\t\t\t\tRegions: []string{\"east_coast\"}},\n+\t\t},\n+\t\t{\n+\t\t\tid: \"TOK\",\n+\t\t\tc: City{Name: \"Tokyo\", Country: \"Japan\",\n+\t\t\t\tCapital: true, Population: 9000000,\n+\t\t\t\tRegions: []string{\"kanto\", \"honshu\"}},\n+\t\t},\n+\t\t{\n+\t\t\tid: \"BJ\",\n+\t\t\tc: City{Name: \"Beijing\", Country: \"China\",\n+\t\t\t\tCapital: true, Population: 21500000,\n+\t\t\t\tRegions: []string{\"jingjinji\", \"hebei\"}},\n+\t\t},\n \t}\n \tfor _, c := range cities {\n \t\tif _, err := client.Collection(\"cities\").Doc(c.id).Set(ctx, c.c); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/warmup/111",
        "commit_id": "9755783a07778fad21d310c6132db6df5ecd6639"
    },
    {
        "pr_title": "appengine/warmup: initial port of warmup to go 1.11",
        "pr_number": 658,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -5,8 +5,6 @@\n// Samples for asymmetric keys feature of Cloud Key Management Service: https://cloud.google.com/kms/\n package samples\n \n-// [START kms_get_asymmetric_public]\n-\n import (\n \t\"context\"\n \t\"crypto\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/warmup/111",
        "commit_id": "9755783a07778fad21d310c6132db6df5ecd6639"
    },
    {
        "pr_title": "appengine/warmup: initial port of warmup to go 1.11",
        "pr_number": 658,
        "file_name": "monitoring/custommetric/custommetric_test.go",
        "code_diff": "@@ -46,9 +46,11 @@\nfunc TestCustomMetric(t *testing.T) {\n \n \ttime.Sleep(2 * time.Second)\n \n-\tif err := writeTimeSeriesValue(s, hc.ProjectID, metricType); err != nil {\n-\t\tt.Error(err)\n-\t}\n+\ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n+\t\tif err := writeTimeSeriesValue(s, hc.ProjectID, metricType); err != nil {\n+\t\t\tt.Error(err)\n+\t\t}\n+\t})\n \n \ttime.Sleep(2 * time.Second)",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/warmup/111",
        "commit_id": "9755783a07778fad21d310c6132db6df5ecd6639"
    },
    {
        "pr_title": "appengine/warmup: initial port of warmup to go 1.11",
        "pr_number": 658,
        "file_name": "profiler/snippets/snippets.go",
        "code_diff": "@@ -3,7 +3,6 @@\n// license that can be found in the LICENSE file.\n \n // [START profiler_setup_go_compute_engine]\n-// [START profiler_start]\n \n // snippets is an example of starting cloud.google.com/go/profiler.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/warmup/111",
        "commit_id": "9755783a07778fad21d310c6132db6df5ecd6639"
    },
    {
        "pr_title": "appengine/warmup: initial port of warmup to go 1.11",
        "pr_number": 658,
        "file_name": "trace/trace_quickstart/main.go",
        "code_diff": "@@ -3,9 +3,8 @@\n// license that can be found in the LICENSE file.\n \n // [START trace_setup_go_quickstart]\n-// [START trace_quickstart]\n \n-// Sample trace_quickstart creates traces incoming and outgoing requests.\n+// Sample trace_quickstart traces incoming and outgoing requests.\n package main\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into appengine/warmup/111",
        "commit_id": "9755783a07778fad21d310c6132db6df5ecd6639"
    },
    {
        "pr_title": "opencensus: add metrics quickstart",
        "pr_number": 646,
        "file_name": "opencensus/metrics_quickstart/main.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START monitoring_opencensus_metrics_quickstart]\n+\n // metrics_quickstart is an example of exporting a custom metric from\n // OpenCensus to Stackdriver.\n package main",
        "comments": [
            {
                "comment": "Create this view inline. You don't need this view elsewhere.\r\n\r\nif err := view.Register(&view.View{\r\n\t\tName:        \"demo/latency\",\r\n\t\tMeasure:     latencyMs,\r\n\t\tDescription: \"The distribution of the latencies\",\r\n \t\t// Latency in buckets:\r\n\t\t// [>=0ms, >=100ms, >=200ms, >=400ms, >=1s, >=2s, >=4s]\r\n\t\tAggregation: view.Distribution(0, 100, 200, 400, 1000, 2000, 4000),\r\n\t}); err != nil {",
                "position": null
            },
            {
                "comment": "stackdriver.NewExporter resolves the project ID from the ADC, this env var is not required.",
                "position": null
            },
            {
                "comment": "Please avoid this prefix, metric prefix is not something most users will need.",
                "position": null
            },
            {
                "comment": "The name of the metric should represent what latency this is? Request latency, task latency, etc?",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "opencensus: add region tag",
        "commit_id": "7ea61a495e8f443a0989b0c7f7035a49239515f5"
    },
    {
        "pr_title": "appengine/go11x: add example of serving static files",
        "pr_number": 638,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -93,7 +93,7 @@\nfunc encryptRSA(ctx context.Context, client *cloudkms.Service, keyPath string, p\n // [START kms_sign_asymmetric]\n \n // signAsymmetric will sign a plaintext message using a saved asymmetric private key.\n-func signAsymmetric(ctx context.Context, client *cloudkms.Service, keyPath string, message []byte) (string, error) {\n+func signAsymmetric(ctx context.Context, client *cloudkms.Service, keyPath string, message []byte) ([]byte, error) {\n \t// Note: some key algorithms will require a different hash function.\n \t// For example, EC_SIGN_P384_SHA384 requires SHA-384.\n \tdigest := sha256.New()",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9c142ff2d34a1a93d6a5845142347db434c727dd"
    },
    {
        "pr_title": "appengine/go11x: add example of serving static files",
        "pr_number": 638,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -109,36 +109,30 @@\nfunc signAsymmetric(ctx context.Context, client *cloudkms.Service, keyPath strin\n \tresponse, err := client.Projects.Locations.KeyRings.CryptoKeys.CryptoKeyVersions.\n \t\tAsymmetricSign(keyPath, asymmetricSignRequest).Context(ctx).Do()\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"asymmetric sign request failed: %+v\", err)\n+\t\treturn nil, fmt.Errorf(\"asymmetric sign request failed: %+v\", err)\n \n \t}\n-\n-\treturn response.Signature, nil\n+\treturn base64.StdEncoding.DecodeString(response.Signature)\n }\n \n // [END kms_sign_asymmetric]\n \n // [START kms_verify_signature_rsa]\n \n // verifySignatureRSA will verify that an 'RSA_SIGN_PSS_2048_SHA256' signature is valid for a given message.\n-func verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature, keyPath string, message []byte) error {\n+func verifySignatureRSA(ctx context.Context, client *cloudkms.Service, keyPath string, signature, message []byte) error {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Perform type assertion to get the RSA key.\n \trsaKey := abstractKey.(*rsa.PublicKey)\n-\tdecodedSignature, err := base64.StdEncoding.DecodeString(signature)\n-\tif err != nil {\n-\t\treturn fmt.Errorf(\"failed to decode signature string: %+v\", err)\n-\n-\t}\n \tdigest := sha256.New()\n \tdigest.Write(message)\n \thash := digest.Sum(nil)\n \n \tpssOptions := rsa.PSSOptions{SaltLength: len(hash), Hash: crypto.SHA256}\n-\terr = rsa.VerifyPSS(rsaKey, crypto.SHA256, hash, decodedSignature, &pssOptions)\n+\terr = rsa.VerifyPSS(rsaKey, crypto.SHA256, hash, signature, &pssOptions)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"signature verification failed: %+v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9c142ff2d34a1a93d6a5845142347db434c727dd"
    },
    {
        "pr_title": "appengine/go11x: add example of serving static files",
        "pr_number": 638,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -143,11 +143,8 @@\nfunc TestRSAEncryptDecrypt(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n-\tif len(ciphertext) != 344 {\n-\t\tt.Errorf(\"ciphertext length = %d; want: %d\", len(ciphertext), 344)\n-\t}\n-\tif ciphertext[len(ciphertext)-2:] != \"==\" {\n-\t\tt.Errorf(\"ciphertet ending: %s; want: %s\", ciphertext[len(ciphertext)-2:], \"==\")\n+\tif len(cipherBytes) != 256 {\n+\t\tt.Errorf(\"ciphertext length = %d; want: %d\", len(ciphertext), 256)\n \t}\n \tplainBytes, err := decryptRSA(v.ctx, v.client, v.rsaDecryptPath, cipherBytes)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9c142ff2d34a1a93d6a5845142347db434c727dd"
    },
    {
        "pr_title": "appengine/go11x: add example of serving static files",
        "pr_number": 638,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -173,17 +170,14 @@\nfunc TestRSASignVerify(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"signAsymmetric(%s, %s): %v\", v.message, v.rsaSignPath, err)\n \t}\n-\tif len(sig) != 344 {\n-\t\tt.Errorf(\"sig length = %d; want: %d\", len(sig), 344)\n-\t}\n-\tif sig[len(sig)-2:] != \"==\" {\n-\t\tt.Errorf(\"sig ending: %s; want: %s\", sig[len(sig)-2:], \"==\")\n+\tif len(sig) != 256 {\n+\t\tt.Errorf(\"sig length = %d; want: %d\", len(sig), 256)\n \t}\n-\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.rsaSignPath, []byte(v.message)); err != nil {\n+\tif err = verifySignatureRSA(v.ctx, v.client, v.rsaSignPath, sig, []byte(v.message)); err != nil {\n \t\tt.Fatalf(\"verifySignatureRSA(%s, %s, %s): %v\", sig, v.message, v.rsaSignPath, err)\n \t}\n \tchanged := v.message + \".\"\n-\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.rsaSignPath, []byte(changed)); err == nil {\n+\tif err = verifySignatureRSA(v.ctx, v.client, v.rsaSignPath, sig, []byte(changed)); err == nil {\n \t\tt.Errorf(\"verification for modified message should fail\")\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "9c142ff2d34a1a93d6a5845142347db434c727dd"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage main\n import (\n \t\"context\"\n \t\"errors\"\n+\t\"log\"\n \t\"time\"\n \n \t\"google.golang.org/api/iterator\"",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -22,10 +23,11 @@\nfunc addDocAsMap(ctx context.Context, client *firestore.Client) error {\n \t\t\"country\": \"USA\",\n \t})\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_simple_doc_as_map]\n-\treturn nil\n+\treturn err\n }\n \n func addDocDataTypes(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -44,21 +46,23 @@\nfunc addDocDataTypes(ctx context.Context, client *firestore.Client) error {\n \n \t_, err := client.Collection(\"data\").Doc(\"one\").Set(ctx, doc)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_doc_data_types]\n-\treturn nil\n+\treturn err\n }\n \n func addDocWithID(ctx context.Context, client *firestore.Client) error {\n \tvar data = make(map[string]interface{})\n \t// [START fs_add_doc_with_id]\n \t_, err := client.Collection(\"cities\").Doc(\"new-city-id\").Set(ctx, data)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_doc_with_id]\n-\treturn nil\n+\treturn err\n }\n \n func addDocWithoutID(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -68,10 +72,11 @@\nfunc addDocWithoutID(ctx context.Context, client *firestore.Client) error {\n \t\t\"country\": \"Japan\",\n \t})\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_doc_auto_id]\n-\treturn nil\n+\treturn err\n }\n \n func addDocAsEntity(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -82,10 +87,11 @@\nfunc addDocAsEntity(ctx context.Context, client *firestore.Client) error {\n \t}\n \t_, err := client.Collection(\"cities\").Doc(\"LA\").Set(ctx, city)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_simple_doc_as_entity]\n-\treturn nil\n+\treturn err\n }\n \n func addDocAfterAutoGeneratedID(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -100,10 +106,11 @@\nfunc addDocAfterAutoGeneratedID(ctx context.Context, client *firestore.Client) e\n \t// later...\n \t_, err := ref.Set(ctx, data)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_doc_data_after_auto_id]\n-\treturn nil\n+\treturn err\n }\n \n func updateDoc(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -112,10 +119,11 @@\nfunc updateDoc(ctx context.Context, client *firestore.Client) error {\n \t\t\"capital\": true,\n \t}, firestore.MergeAll)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_update_doc]\n-\treturn nil\n+\treturn err\n }\n \n func updateDocCreateIfMissing(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -125,10 +133,11 @@\nfunc updateDocCreateIfMissing(ctx context.Context, client *firestore.Client) err\n \t}, firestore.MergeAll)\n \n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_update_create_if_missing]\n-\treturn nil\n+\treturn err\n }\n \n func updateDocMultiple(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -145,10 +154,11 @@\nfunc updateDocMultiple(ctx context.Context, client *firestore.Client) error {\n \t\t\"areaInSquareMiles\": 573.0,\n \t}, firestore.MergeAll)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_update_multiple_fields]\n-\treturn nil\n+\treturn err\n }\n \n func updateDocNested(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -164,23 +174,24 @@\nfunc updateDocNested(ctx context.Context, client *firestore.Client) error {\n \t}\n \n \t// [START_EXCLUDE]\n-\t_, err := client.Collection(\"users\").Doc(\"frank\").Set(ctx, initialData)\n-\tif err != nil {\n+\n+\tif _, err := client.Collection(\"users\").Doc(\"frank\").Set(ctx, initialData); err != nil {\n \t\treturn err\n \t}\n \t// [END_EXCLUDE]\n \n-\t_, err = client.Collection(\"users\").Doc(\"frank\").Set(ctx, map[string]interface{}{\n+\t_, err := client.Collection(\"users\").Doc(\"frank\").Set(ctx, map[string]interface{}{\n \t\t\"age\": 13,\n \t\t\"favorites\": map[string]interface{}{\n \t\t\t\"color\": \"Red\",\n \t\t},\n \t}, firestore.MergeAll)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_update_nested_fields]\n-\treturn nil\n+\treturn err\n }\n \n func updateDocServerTimestamp(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -196,20 +207,22 @@\nfunc updateDocServerTimestamp(ctx context.Context, client *firestore.Client) err\n \t\t\"timestamp\": firestore.ServerTimestamp,\n \t}, firestore.MergeAll)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_update_server_timestamp]\n-\treturn nil\n+\treturn err\n }\n \n func deleteDoc(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_delete_doc]\n \t_, err := client.Collection(\"cities\").Doc(\"DC\").Delete(ctx)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_delete_doc]\n-\treturn nil\n+\treturn err\n }\n \n func deleteField(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -221,7 +234,8 @@\nfunc deleteField(ctx context.Context, client *firestore.Client) error {\n \t\t},\n \t})\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_delete_field]",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -230,7 +244,7 @@\nfunc deleteField(ctx context.Context, client *firestore.Client) error {\n \t// Set(ctx, map[string]interface{}{\n \t//\t\"capital\": firestore.Delete,\n \t//})\n-\treturn nil\n+\treturn err\n }\n \n // [START fs_delete_collection]",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -299,10 +313,11 @@\nfunc runSimpleTransaction(ctx context.Context, client *firestore.Client) error {\n \t\t}, firestore.MergeAll)\n \t})\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors appropriately in this section.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_run_simple_transaction]\n-\treturn nil\n+\treturn err\n }\n \n func infoTransaction(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -326,10 +341,11 @@\nfunc infoTransaction(ctx context.Context, client *firestore.Client) error {\n \t\treturn errors.New(\"population is too big\")\n \t})\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_return_info_transaction]\n-\treturn nil\n+\treturn err\n }\n \n func batchWrite(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -5,6 +5,8 @@\n// Samples for asymmetric keys feature of Cloud Key Management Service: https://cloud.google.com/kms/\n package samples\n \n+// [START kms_get_asymmetric_public]\n+\n import (\n \t\"context\"\n \t\"crypto\"",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -23,6 +25,8 @@\nimport (\n \t\"google.golang.org/api/cloudkms/v1\"\n )\n \n+// [END kms_get_asymmetric_public]\n+\n // [START kms_get_asymmetric_public]\n \n // getAsymmetricPublicKey retrieves the public key from a saved asymmetric key pair on KMS.",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -46,54 +50,54 @@\nfunc getAsymmetricPublicKey(ctx context.Context, client *cloudkms.Service, keyPa\n // [START kms_decrypt_rsa]\n \n // decryptRSA will attempt to decrypt a given ciphertext with an 'RSA_DECRYPT_OAEP_2048_SHA256' private key.stored on Cloud KMS\n-func decryptRSA(ctx context.Context, client *cloudkms.Service, ciphertext, keyPath string) (string, error) {\n+func decryptRSA(ctx context.Context, client *cloudkms.Service, keyPath string, ciphertext []byte) ([]byte, error) {\n \tdecryptRequest := &cloudkms.AsymmetricDecryptRequest{\n-\t\tCiphertext: ciphertext,\n+\t\tCiphertext: base64.StdEncoding.EncodeToString(ciphertext),\n \t}\n \tresponse, err := client.Projects.Locations.KeyRings.CryptoKeys.CryptoKeyVersions.\n \t\tAsymmetricDecrypt(keyPath, decryptRequest).Context(ctx).Do()\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"decryption request failed: %+v\", err)\n+\t\treturn nil, fmt.Errorf(\"decryption request failed: %+v\", err)\n \t}\n-\tmessage, err := base64.StdEncoding.DecodeString(response.Plaintext)\n+\tplaintext, err := base64.StdEncoding.DecodeString(response.Plaintext)\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"failed to decode decryted string: %+v\", err)\n+\t\treturn nil, fmt.Errorf(\"failed to decode decryted string: %+v\", err)\n \n \t}\n-\treturn string(message), nil\n+\treturn plaintext, nil\n }\n \n // [END kms_decrypt_rsa]\n \n // [START kms_encrypt_rsa]\n \n-// encryptRSA will encrypt a message locally using an 'RSA_DECRYPT_OAEP_2048_SHA256' public key retrieved from Cloud KMS\n-func encryptRSA(ctx context.Context, client *cloudkms.Service, message, keyPath string) (string, error) {\n+// encryptRSA will encrypt data locally using an 'RSA_DECRYPT_OAEP_2048_SHA256' public key retrieved from Cloud KMS\n+func encryptRSA(ctx context.Context, client *cloudkms.Service, keyPath string, plaintext []byte) ([]byte, error) {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {\n-\t\treturn \"\", err\n+\t\treturn nil, err\n \t}\n \n \t// Perform type assertion to get the RSA key.\n \trsaKey := abstractKey.(*rsa.PublicKey)\n \n-\tciphertextBytes, err := rsa.EncryptOAEP(sha256.New(), rand.Reader, rsaKey, []byte(message), nil)\n+\tciphertext, err := rsa.EncryptOAEP(sha256.New(), rand.Reader, rsaKey, plaintext, nil)\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"encryption failed: %+v\", err)\n+\t\treturn nil, fmt.Errorf(\"encryption failed: %+v\", err)\n \t}\n-\treturn base64.StdEncoding.EncodeToString(ciphertextBytes), nil\n+\treturn ciphertext, nil\n }\n \n // [END kms_encrypt_rsa]\n \n // [START kms_sign_asymmetric]\n \n // signAsymmetric will sign a plaintext message using a saved asymmetric private key.\n-func signAsymmetric(ctx context.Context, client *cloudkms.Service, message, keyPath string) (string, error) {\n+func signAsymmetric(ctx context.Context, client *cloudkms.Service, keyPath string, message []byte) (string, error) {\n \t// Note: some key algorithms will require a different hash function.\n \t// For example, EC_SIGN_P384_SHA384 requires SHA-384.\n \tdigest := sha256.New()\n-\tdigest.Write([]byte(message))\n+\tdigest.Write(message)\n \tdigestStr := base64.StdEncoding.EncodeToString(digest.Sum(nil))\n \n \tasymmetricSignRequest := &cloudkms.AsymmetricSignRequest{",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -116,8 +120,8 @@\nfunc signAsymmetric(ctx context.Context, client *cloudkms.Service, message, keyP\n \n // [START kms_verify_signature_rsa]\n \n-// verifySignatureRSA will verify that an 'RSA_SIGN_PSS_2048_SHA256' signature is valid for a given plaintext message.\n-func verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature, message, keyPath string) error {\n+// verifySignatureRSA will verify that an 'RSA_SIGN_PSS_2048_SHA256' signature is valid for a given message.\n+func verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature, keyPath string, message []byte) error {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -130,7 +134,7 @@\nfunc verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature\n \n \t}\n \tdigest := sha256.New()\n-\tdigest.Write([]byte(message))\n+\tdigest.Write(message)\n \thash := digest.Sum(nil)\n \n \tpssOptions := rsa.PSSOptions{SaltLength: len(hash), Hash: crypto.SHA256}",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -145,8 +149,8 @@\nfunc verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature\n \n // [START kms_verify_signature_ec]\n \n-// verifySignatureEC will verify that an 'EC_SIGN_P256_SHA256' signature is valid for a given plaintext message.\n-func verifySignatureEC(ctx context.Context, client *cloudkms.Service, signature, message, keyPath string) error {\n+// verifySignatureEC will verify that an 'EC_SIGN_P256_SHA256' signature is valid for a given message.\n+func verifySignatureEC(ctx context.Context, client *cloudkms.Service, signature, keyPath string, message []byte) error {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -6,9 +6,11 @@\npackage samples\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"crypto/ecdsa\"\n \t\"crypto/rsa\"\n+\t\"encoding/base64\"\n \t\"os\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -136,7 +138,8 @@\nfunc TestRSAEncryptDecrypt(t *testing.T) {\n \t\tt.Fatalf(\"intial variable setup failed: %v\", err)\n \t}\n \n-\tciphertext, err := encryptRSA(v.ctx, v.client, v.message, v.rsaDecryptPath)\n+\tcipherBytes, err := encryptRSA(v.ctx, v.client, v.rsaDecryptPath, []byte(v.message))\n+\tciphertext := base64.StdEncoding.EncodeToString(cipherBytes)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -146,12 +149,16 @@\nfunc TestRSAEncryptDecrypt(t *testing.T) {\n \tif ciphertext[len(ciphertext)-2:] != \"==\" {\n \t\tt.Errorf(\"ciphertet ending: %s; want: %s\", ciphertext[len(ciphertext)-2:], \"==\")\n \t}\n-\tplaintext, err := decryptRSA(v.ctx, v.client, ciphertext, v.rsaDecryptPath)\n+\tplainBytes, err := decryptRSA(v.ctx, v.client, v.rsaDecryptPath, cipherBytes)\n \tif err != nil {\n \t\tt.Fatalf(\"decryptRSA(%s, %s): %v\", ciphertext, v.rsaDecryptPath, err)\n \t}\n-\tif v.message != plaintext {\n-\t\tt.Errorf(\"failed to decypt expected plaintext: want %s, got %s\", plaintext, v.message)\n+\tif !bytes.Equal(plainBytes, []byte(v.message)) {\n+\t\tt.Fatalf(\"decrypted plaintext does not match input message: want %s, got %s\", []byte(v.message), plainBytes)\n+\t}\n+\tplaintext := string(plainBytes)\n+\tif plaintext != v.message {\n+\t\tt.Fatalf(\"failed to decypt expected plaintext: want %s, got %s\", v.message, plaintext)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -162,7 +169,7 @@\nfunc TestRSASignVerify(t *testing.T) {\n \t\tt.Fatalf(\"intial variable setup failed: %v\", err)\n \t}\n \n-\tsig, err := signAsymmetric(v.ctx, v.client, v.message, v.rsaSignPath)\n+\tsig, err := signAsymmetric(v.ctx, v.client, v.rsaSignPath, []byte(v.message))\n \tif err != nil {\n \t\tt.Fatalf(\"signAsymmetric(%s, %s): %v\", v.message, v.rsaSignPath, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -172,10 +179,11 @@\nfunc TestRSASignVerify(t *testing.T) {\n \tif sig[len(sig)-2:] != \"==\" {\n \t\tt.Errorf(\"sig ending: %s; want: %s\", sig[len(sig)-2:], \"==\")\n \t}\n-\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.message, v.rsaSignPath); err != nil {\n+\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.rsaSignPath, []byte(v.message)); err != nil {\n \t\tt.Fatalf(\"verifySignatureRSA(%s, %s, %s): %v\", sig, v.message, v.rsaSignPath, err)\n \t}\n-\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.message+\".\", v.rsaSignPath); err == nil {\n+\tchanged := v.message + \".\"\n+\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.rsaSignPath, []byte(changed)); err == nil {\n \t\tt.Errorf(\"verification for modified message should fail\")\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "monitoring/custommetric/custommetric_test.go",
        "code_diff": "@@ -37,16 +37,12 @@\nfunc TestCustomMetric(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \n-\tfor {\n+\ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n \t\t_, err = getCustomMetric(s, hc.ProjectID, metricType)\n-\t\tif err == nil {\n-\t\t\tbreak\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"%v\", err)\n \t\t}\n-\t\ttime.Sleep(2 * time.Second)\n-\t}\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n+\t})\n \n \ttime.Sleep(2 * time.Second)",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "speech: add model selection sample",
        "pr_number": 636,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -562,6 +562,52 @@\nfunc detectAsyncDocument(w io.Writer, gcsSourceURI, gcsDestinationURI string) er\n \n // [END vision_text_detection_pdf]\n \n+// [START vision_localize_objects]\n+\n+// localizeObjects gets objects and bounding boxes from the Vision API for an image at the given file path.\n+func localizeObjects(w io.Writer, file string) error {\n+\tctx := context.Background()\n+\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tf, err := os.Open(file)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer f.Close()\n+\n+\timage, err := vision.NewImageFromReader(f)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tannotations, err := client.LocalizeObjects(ctx, image, nil)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif len(annotations) == 0 {\n+\t\tfmt.Fprintln(w, \"No objects found.\")\n+\t\treturn nil\n+\t}\n+\n+\tfmt.Fprintln(w, \"Objects:\")\n+\tfor _, annotation := range annotations {\n+\t\tfmt.Fprintln(w, annotation.Name)\n+\t\tfmt.Fprintln(w, annotation.Score)\n+\n+\t\tfor _, v := range annotation.BoundingPoly.NormalizedVertices {\n+\t\t\tfmt.Fprintf(w, \"(%f,%f)\\n\", v.X, v.Y)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+// [END vision_localize_objects]\n+\n func init() {\n \t// Refer to these functions so that goimports is happy before boilerplate is inserted.\n \t_ = context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'speech-model-selection' of github.com:davidcavazos/golang-samples into speech-model-selection",
        "commit_id": "1bb096c76b96977d65affb7e0bb3eb31b8e2462d"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -5,6 +5,8 @@\n// Samples for asymmetric keys feature of Cloud Key Management Service: https://cloud.google.com/kms/\n package samples\n \n+// [START kms_get_asymmetric_public]\n+\n import (\n \t\"context\"\n \t\"crypto\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -23,6 +25,8 @@\nimport (\n \t\"google.golang.org/api/cloudkms/v1\"\n )\n \n+// [END kms_get_asymmetric_public]\n+\n // [START kms_get_asymmetric_public]\n \n // getAsymmetricPublicKey retrieves the public key from a saved asymmetric key pair on KMS.",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -46,54 +50,54 @@\nfunc getAsymmetricPublicKey(ctx context.Context, client *cloudkms.Service, keyPa\n // [START kms_decrypt_rsa]\n \n // decryptRSA will attempt to decrypt a given ciphertext with an 'RSA_DECRYPT_OAEP_2048_SHA256' private key.stored on Cloud KMS\n-func decryptRSA(ctx context.Context, client *cloudkms.Service, ciphertext, keyPath string) (string, error) {\n+func decryptRSA(ctx context.Context, client *cloudkms.Service, keyPath string, ciphertext []byte) ([]byte, error) {\n \tdecryptRequest := &cloudkms.AsymmetricDecryptRequest{\n-\t\tCiphertext: ciphertext,\n+\t\tCiphertext: base64.StdEncoding.EncodeToString(ciphertext),\n \t}\n \tresponse, err := client.Projects.Locations.KeyRings.CryptoKeys.CryptoKeyVersions.\n \t\tAsymmetricDecrypt(keyPath, decryptRequest).Context(ctx).Do()\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"decryption request failed: %+v\", err)\n+\t\treturn nil, fmt.Errorf(\"decryption request failed: %+v\", err)\n \t}\n-\tmessage, err := base64.StdEncoding.DecodeString(response.Plaintext)\n+\tplaintext, err := base64.StdEncoding.DecodeString(response.Plaintext)\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"failed to decode decryted string: %+v\", err)\n+\t\treturn nil, fmt.Errorf(\"failed to decode decryted string: %+v\", err)\n \n \t}\n-\treturn string(message), nil\n+\treturn plaintext, nil\n }\n \n // [END kms_decrypt_rsa]\n \n // [START kms_encrypt_rsa]\n \n-// encryptRSA will encrypt a message locally using an 'RSA_DECRYPT_OAEP_2048_SHA256' public key retrieved from Cloud KMS\n-func encryptRSA(ctx context.Context, client *cloudkms.Service, message, keyPath string) (string, error) {\n+// encryptRSA will encrypt data locally using an 'RSA_DECRYPT_OAEP_2048_SHA256' public key retrieved from Cloud KMS\n+func encryptRSA(ctx context.Context, client *cloudkms.Service, keyPath string, plaintext []byte) ([]byte, error) {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {\n-\t\treturn \"\", err\n+\t\treturn nil, err\n \t}\n \n \t// Perform type assertion to get the RSA key.\n \trsaKey := abstractKey.(*rsa.PublicKey)\n \n-\tciphertextBytes, err := rsa.EncryptOAEP(sha256.New(), rand.Reader, rsaKey, []byte(message), nil)\n+\tciphertext, err := rsa.EncryptOAEP(sha256.New(), rand.Reader, rsaKey, plaintext, nil)\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"encryption failed: %+v\", err)\n+\t\treturn nil, fmt.Errorf(\"encryption failed: %+v\", err)\n \t}\n-\treturn base64.StdEncoding.EncodeToString(ciphertextBytes), nil\n+\treturn ciphertext, nil\n }\n \n // [END kms_encrypt_rsa]\n \n // [START kms_sign_asymmetric]\n \n // signAsymmetric will sign a plaintext message using a saved asymmetric private key.\n-func signAsymmetric(ctx context.Context, client *cloudkms.Service, message, keyPath string) (string, error) {\n+func signAsymmetric(ctx context.Context, client *cloudkms.Service, keyPath string, message []byte) (string, error) {\n \t// Note: some key algorithms will require a different hash function.\n \t// For example, EC_SIGN_P384_SHA384 requires SHA-384.\n \tdigest := sha256.New()\n-\tdigest.Write([]byte(message))\n+\tdigest.Write(message)\n \tdigestStr := base64.StdEncoding.EncodeToString(digest.Sum(nil))\n \n \tasymmetricSignRequest := &cloudkms.AsymmetricSignRequest{",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -116,8 +120,8 @@\nfunc signAsymmetric(ctx context.Context, client *cloudkms.Service, message, keyP\n \n // [START kms_verify_signature_rsa]\n \n-// verifySignatureRSA will verify that an 'RSA_SIGN_PSS_2048_SHA256' signature is valid for a given plaintext message.\n-func verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature, message, keyPath string) error {\n+// verifySignatureRSA will verify that an 'RSA_SIGN_PSS_2048_SHA256' signature is valid for a given message.\n+func verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature, keyPath string, message []byte) error {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -130,7 +134,7 @@\nfunc verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature\n \n \t}\n \tdigest := sha256.New()\n-\tdigest.Write([]byte(message))\n+\tdigest.Write(message)\n \thash := digest.Sum(nil)\n \n \tpssOptions := rsa.PSSOptions{SaltLength: len(hash), Hash: crypto.SHA256}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -145,8 +149,8 @@\nfunc verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature\n \n // [START kms_verify_signature_ec]\n \n-// verifySignatureEC will verify that an 'EC_SIGN_P256_SHA256' signature is valid for a given plaintext message.\n-func verifySignatureEC(ctx context.Context, client *cloudkms.Service, signature, message, keyPath string) error {\n+// verifySignatureEC will verify that an 'EC_SIGN_P256_SHA256' signature is valid for a given message.\n+func verifySignatureEC(ctx context.Context, client *cloudkms.Service, signature, keyPath string, message []byte) error {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -6,9 +6,11 @@\npackage samples\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"crypto/ecdsa\"\n \t\"crypto/rsa\"\n+\t\"encoding/base64\"\n \t\"os\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -136,7 +138,8 @@\nfunc TestRSAEncryptDecrypt(t *testing.T) {\n \t\tt.Fatalf(\"intial variable setup failed: %v\", err)\n \t}\n \n-\tciphertext, err := encryptRSA(v.ctx, v.client, v.message, v.rsaDecryptPath)\n+\tcipherBytes, err := encryptRSA(v.ctx, v.client, v.rsaDecryptPath, []byte(v.message))\n+\tciphertext := base64.StdEncoding.EncodeToString(cipherBytes)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -146,12 +149,16 @@\nfunc TestRSAEncryptDecrypt(t *testing.T) {\n \tif ciphertext[len(ciphertext)-2:] != \"==\" {\n \t\tt.Errorf(\"ciphertet ending: %s; want: %s\", ciphertext[len(ciphertext)-2:], \"==\")\n \t}\n-\tplaintext, err := decryptRSA(v.ctx, v.client, ciphertext, v.rsaDecryptPath)\n+\tplainBytes, err := decryptRSA(v.ctx, v.client, v.rsaDecryptPath, cipherBytes)\n \tif err != nil {\n \t\tt.Fatalf(\"decryptRSA(%s, %s): %v\", ciphertext, v.rsaDecryptPath, err)\n \t}\n-\tif v.message != plaintext {\n-\t\tt.Errorf(\"failed to decypt expected plaintext: want %s, got %s\", plaintext, v.message)\n+\tif !bytes.Equal(plainBytes, []byte(v.message)) {\n+\t\tt.Fatalf(\"decrypted plaintext does not match input message: want %s, got %s\", []byte(v.message), plainBytes)\n+\t}\n+\tplaintext := string(plainBytes)\n+\tif plaintext != v.message {\n+\t\tt.Fatalf(\"failed to decypt expected plaintext: want %s, got %s\", v.message, plaintext)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -162,7 +169,7 @@\nfunc TestRSASignVerify(t *testing.T) {\n \t\tt.Fatalf(\"intial variable setup failed: %v\", err)\n \t}\n \n-\tsig, err := signAsymmetric(v.ctx, v.client, v.message, v.rsaSignPath)\n+\tsig, err := signAsymmetric(v.ctx, v.client, v.rsaSignPath, []byte(v.message))\n \tif err != nil {\n \t\tt.Fatalf(\"signAsymmetric(%s, %s): %v\", v.message, v.rsaSignPath, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -172,10 +179,11 @@\nfunc TestRSASignVerify(t *testing.T) {\n \tif sig[len(sig)-2:] != \"==\" {\n \t\tt.Errorf(\"sig ending: %s; want: %s\", sig[len(sig)-2:], \"==\")\n \t}\n-\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.message, v.rsaSignPath); err != nil {\n+\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.rsaSignPath, []byte(v.message)); err != nil {\n \t\tt.Fatalf(\"verifySignatureRSA(%s, %s, %s): %v\", sig, v.message, v.rsaSignPath, err)\n \t}\n-\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.message+\".\", v.rsaSignPath); err == nil {\n+\tchanged := v.message + \".\"\n+\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.rsaSignPath, []byte(changed)); err == nil {\n \t\tt.Errorf(\"verification for modified message should fail\")\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "monitoring/custommetric/custommetric_test.go",
        "code_diff": "@@ -37,16 +37,12 @@\nfunc TestCustomMetric(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \n-\tfor {\n+\ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n \t\t_, err = getCustomMetric(s, hc.ProjectID, metricType)\n-\t\tif err == nil {\n-\t\t\tbreak\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"%v\", err)\n \t\t}\n-\t\ttime.Sleep(2 * time.Second)\n-\t}\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n+\t})\n \n \ttime.Sleep(2 * time.Second)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-localize-objects",
        "commit_id": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "appengine/go11x/helloworld/helloworld.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)\n \n+\t// [START setting_port]\n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {\n \t\tport = \"8080\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -33,6 +33,7 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_create_table_clustered]\n \t// [START bigquery_create_table_cmek]\n \t// [START bigquery_create_table_partitioned]\n+\t// [START bigquery_create_view]\n \t// [START bigquery_delete_dataset]\n \t// [START bigquery_delete_label_dataset]\n \t// [START bigquery_delete_label_table]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -45,6 +46,8 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_get_job]\n \t// [START bigquery_get_table]\n \t// [START bigquery_get_table_labels]\n+\t// [START bigquery_get_view]\n+\t// [START bigquery_grant_view_access]\n \t// [START bigquery_label_dataset]\n \t// [START bigquery_label_table]\n \t// [START bigquery_list_datasets]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -54,9 +57,11 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_load_from_file]\n \t// [START bigquery_load_table_clustered]\n \t// [START bigquery_load_table_gcs_csv]\n+\t// [START bigquery_load_table_gcs_csv_truncate]\n \t// [START bigquery_load_table_gcs_json]\n \t// [START bigquery_load_table_gcs_json_autodetect]\n \t// [START bigquery_load_table_gcs_json_cmek]\n+\t// [START bigquery_load_table_gcs_json_truncate]\n \t// [START bigquery_load_table_gcs_orc]\n \t// [START bigquery_load_table_gcs_orc_truncate]\n \t// [START bigquery_load_table_gcs_parquet]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -88,6 +93,7 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_update_table_cmek]\n \t// [START bigquery_update_table_description]\n \t// [START bigquery_update_table_expiration]\n+\t// [START bigquery_update_view_query]\n \t// To run this sample, you will need to create (or reuse) a context and\n \t// an instance of the bigquery client.  For example:\n \t// import \"cloud.google.com/go/bigquery\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -106,6 +112,7 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_create_table_clustered]\n \t// [END bigquery_create_table_cmek]\n \t// [END bigquery_create_table_partitioned]\n+\t// [END bigquery_create_view]\n \t// [END bigquery_delete_dataset]\n \t// [END bigquery_delete_label_dataset]\n \t// [END bigquery_delete_label_table]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -118,6 +125,8 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_get_job]\n \t// [END bigquery_get_table]\n \t// [END bigquery_get_table_labels]\n+\t// [END bigquery_get_view]\n+\t// [END bigquery_grant_view_access]\n \t// [END bigquery_label_dataset]\n \t// [END bigquery_label_table]\n \t// [END bigquery_list_datasets]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -127,9 +136,11 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_load_from_file]\n \t// [END bigquery_load_table_clustered]\n \t// [END bigquery_load_table_gcs_csv]\n+\t// [END bigquery_load_table_gcs_csv_truncate]\n \t// [END bigquery_load_table_gcs_json]\n \t// [END bigquery_load_table_gcs_json_autodetect]\n \t// [END bigquery_load_table_gcs_json_cmek]\n+\t// [END bigquery_load_table_gcs_json_truncate]\n \t// [END bigquery_load_table_gcs_orc]\n \t// [END bigquery_load_table_gcs_orc_truncate]\n \t// [END bigquery_load_table_gcs_parquet]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -161,6 +172,7 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_update_dataset_expiration]\n \t// [END bigquery_update_table_description]\n \t// [END bigquery_update_table_expiration]\n+\t// [END bigquery_update_view_query]\n }\n \n func cancelJob(client *bigquery.Client, jobID string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -187,6 +199,22 @@\nfunc createDataset(client *bigquery.Client, datasetID string) error {\n \treturn nil\n }\n \n+func createView(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_create_view]\n+\tmeta := &bigquery.TableMetadata{\n+\t\t// This example shows how to create a view of the shakespeare sample dataset, which\n+\t\t// provides word frequency information.  This view restricts the results to only contain\n+\t\t// results for works that contain the \"king\" in the title, e.g. King Lear, King Henry V, etc.\n+\t\tViewQuery: \"SELECT word, word_count, corpus, corpus_date FROM `bigquery-public-data.samples.shakespeare` WHERE corpus LIKE '%king%'\",\n+\t}\n+\tif err := client.Dataset(datasetID).Table(tableID).Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_create_view]\n+\treturn nil\n+}\n+\n func updateDatasetDescription(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_description]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -535,7 +563,7 @@\nfunc relaxTableAPI(client *bigquery.Client, datasetID, tableID string) error {\n \tif _, err := tableRef.Update(ctx, newMeta, meta.ETag); err != nil {\n \t\treturn err\n \t}\n-\t// [END  bigquery_relax_column]\n+\t// [END bigquery_relax_column]\n \treturn nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -576,7 +604,7 @@\nfunc relaxTableImport(client *bigquery.Client, datasetID, tableID, filename stri\n \tif err := status.Err(); err != nil {\n \t\treturn err\n \t}\n-\t// [END  bigquery_relax_column_load_append]\n+\t// [END bigquery_relax_column_load_append]\n \treturn nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -817,6 +845,84 @@\nfunc updateTableExpiration(client *bigquery.Client, datasetID, tableID string) e\n \n }\n \n+func getView(client *bigquery.Client, datasetID, viewID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_view]\n+\tview := client.Dataset(datasetID).Table(viewID)\n+\tmeta, err := view.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Printf(\"View %s, query: %s\\n\", view.FullyQualifiedName(), meta.ViewQuery)\n+\t// [END bigquery_get_view]\n+\treturn nil\n+}\n+\n+func updateView(client *bigquery.Client, datasetID, viewID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_view_query]\n+\tview := client.Dataset(datasetID).Table(viewID)\n+\tmeta, err := view.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tnewMeta := bigquery.TableMetadataToUpdate{\n+\t\t// This example updates a view into the shakespeare dataset to exclude works named after kings.\n+\t\tViewQuery: \"SELECT word, word_count, corpus, corpus_date FROM `bigquery-public-data.samples.shakespeare` WHERE corpus NOT LIKE '%king%'\",\n+\t}\n+\n+\tif _, err := view.Update(ctx, newMeta, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_view_query]\n+\treturn nil\n+}\n+\n+func updateViewDelegated(client *bigquery.Client, srcDatasetID, viewDatasetID, viewID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_grant_view_access]\n+\tsrcDataset := client.Dataset(srcDatasetID)\n+\tviewDataset := client.Dataset(viewDatasetID)\n+\tview := viewDataset.Table(viewID)\n+\n+\t// First, we'll add a group to the ACL for the dataset containing the view.  This will allow users within\n+\t// that group to query the view, but they must have direct access to any tables referenced by the view.\n+\tvMeta, err := viewDataset.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tvUpdateMeta := bigquery.DatasetMetadataToUpdate{\n+\t\tAccess: append(vMeta.Access, &bigquery.AccessEntry{\n+\t\t\tRole:       bigquery.ReaderRole,\n+\t\t\tEntityType: bigquery.GroupEmailEntity,\n+\t\t\tEntity:     \"example-analyst-group@google.com\",\n+\t\t}),\n+\t}\n+\tif _, err := viewDataset.Update(ctx, vUpdateMeta, vMeta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Now, we'll authorize a specific view against a source dataset, delegating access enforcement.\n+\t// Once this has been completed, members of the group previously added to the view dataset's ACL\n+\t// no longer require access to the source dataset to successfully query the view.\n+\tsrcMeta, err := srcDataset.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tsrcUpdateMeta := bigquery.DatasetMetadataToUpdate{\n+\t\tAccess: append(srcMeta.Access, &bigquery.AccessEntry{\n+\t\t\tEntityType: bigquery.ViewEntity,\n+\t\t\tView:       view,\n+\t\t}),\n+\t}\n+\tif _, err := srcDataset.Update(ctx, srcUpdateMeta, srcMeta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_grant_view_access]\n+\treturn nil\n+}\n+\n func tableLabels(client *bigquery.Client, w io.Writer, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_table_labels]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1356,6 +1462,19 @@\nfunc deleteAndUndeleteTable(client *bigquery.Client, datasetID, tableID string)\n \t// Record the current time.  We'll use this as the snapshot time\n \t// for recovering the table.\n \tsnapTime := time.Now()\n+\t// [END bigquery_undelete_table]\n+\t// Because this test immediately creates the test resource and deletes it, it is sensitive\n+\t// to timing variance between the client and backend.  We correct for that by choosing the latter\n+\t// of the \"current\" local time, and the backend's report of the creation time of the table.\n+\tmeta, err := ds.Table(tableID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif snapTime.Before(meta.CreationTime) {\n+\t\tsnapTime = time.Time(meta.CreationTime)\n+\t}\n+\t// [START bigquery_undelete_table]\n \n \t// \"Accidentally\" delete the table.\n \tif err := client.Dataset(datasetID).Table(tableID).Delete(ctx); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1462,12 +1581,63 @@\nfunc importCSVExplicitSchema(client *bigquery.Client, datasetID, tableID string)\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_csv]\n \treturn nil\n }\n \n+func importCSVAutodetectSchema(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_csv_autodetect]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.csv\")\n+\tgcsRef.SourceFormat = bigquery.CSV\n+\tgcsRef.AutoDetect = true\n+\tgcsRef.SkipLeadingRows = 1\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_csv_autodetect]\n+\treturn nil\n+}\n+\n+func importCSVTruncate(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_csv_truncate]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.csv\")\n+\tgcsRef.SourceFormat = bigquery.CSV\n+\tgcsRef.AutoDetect = true\n+\tgcsRef.SkipLeadingRows = 1\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\tloader.WriteDisposition = bigquery.WriteTruncate\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_csv_truncate]\n+\treturn nil\n+}\n+\n func importJSONExplicitSchema(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_table_gcs_json]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1490,7 +1660,7 @@\nfunc importJSONExplicitSchema(client *bigquery.Client, datasetID, tableID string\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_json]\n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1515,7 +1685,7 @@\nfunc importJSONAutodetectSchema(client *bigquery.Client, datasetID, tableID stri\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_json_autodetect]\n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1544,13 +1714,39 @@\nfunc importJSONWithCMEK(client *bigquery.Client, datasetID, tableID string) erro\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \n \t// [END bigquery_load_table_gcs_json_cmek]\n \treturn nil\n }\n \n+func importJSONTruncate(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_json_truncate]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.json\")\n+\tgcsRef.SourceFormat = bigquery.JSON\n+\tgcsRef.AutoDetect = true\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\tloader.WriteDisposition = bigquery.WriteTruncate\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n+\t}\n+\n+\t// [END bigquery_load_table_gcs_json_truncate]\n+\treturn nil\n+}\n+\n func importORC(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_table_gcs_orc]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1568,7 +1764,7 @@\nfunc importORC(client *bigquery.Client, datasetID, tableID string) error {\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_orc]\n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1594,7 +1790,7 @@\nfunc importORCTruncate(client *bigquery.Client, datasetID, tableID string) error\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_orc_truncate]\n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1618,7 +1814,7 @@\nfunc importParquet(client *bigquery.Client, datasetID, tableID string) error {\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_parquet]\n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1643,7 +1839,7 @@\nfunc importParquetTruncate(client *bigquery.Client, datasetID, tableID string) e\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_parquet_truncate]\n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1676,7 +1872,7 @@\nfunc importPartitionedSampleTable(client *bigquery.Client, destDatasetID, destTa\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_partitioned]\n \treturn nil",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -278,6 +278,46 @@\nfunc TestAll(t *testing.T) {\n \n }\n \n+// Exercise BigQuery logical views.\n+func TestViews(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tsrcDatasetID := uniqueBQName(\"golang_example_view_source\")\n+\tif err := createDataset(client, srcDatasetID); err != nil {\n+\t\tt.Errorf(\"createDataset(%q): %v\", srcDatasetID, err)\n+\t}\n+\tdefer client.Dataset(srcDatasetID).DeleteWithContents(ctx)\n+\tviewDatasetID := uniqueBQName(\"golang_example_view_container\")\n+\tif err := createDataset(client, viewDatasetID); err != nil {\n+\t\tt.Errorf(\"createDataset(%q): %v\", viewDatasetID, err)\n+\t}\n+\tdefer client.Dataset(viewDatasetID).DeleteWithContents(ctx)\n+\n+\tviewID := uniqueBQName(\"golang_example_view\")\n+\n+\tif err := createView(client, viewDatasetID, viewID); err != nil {\n+\t\tt.Fatalf(\"createView(dataset:%q view:%q): %v\", viewDatasetID, viewID, err)\n+\t}\n+\n+\tif err := getView(client, viewDatasetID, viewID); err != nil {\n+\t\tt.Fatalf(\"getView(dataset:%q view:%q): %v\", viewDatasetID, viewID, err)\n+\t}\n+\n+\tif err := updateView(client, viewDatasetID, viewID); err != nil {\n+\t\tt.Fatalf(\"updateView(dataset:%q view:%q): %v\", viewDatasetID, viewID, err)\n+\t}\n+\n+\tif err := updateViewDelegated(client, srcDatasetID, viewDatasetID, viewID); err != nil {\n+\t\tt.Fatalf(\"updateViewDelegated(srcdataset:%q viewdataset:%q view:%q): %v\", srcDatasetID, viewDatasetID, viewID, err)\n+\t}\n+\n+}\n+\n func TestImportExport(t *testing.T) {\n \ttc := testutil.EndToEndTest(t)\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -303,6 +343,16 @@\nfunc TestImportExport(t *testing.T) {\n \t\tt.Fatalf(\"importCSVFromFile(dataset:%q table:%q filename:%q): %v\", datasetID, tableID, filename, err)\n \t}\n \n+\tautoCSV := uniqueBQName(\"golang_example_csv_autodetect\")\n+\tif err := importCSVAutodetectSchema(client, datasetID, autoCSV); err != nil {\n+\t\tt.Fatalf(\"importCSVAutodetectSchema(dataset:%q table:%q): %v\", datasetID, autoCSV, err)\n+\t}\n+\n+\tautoCSVTruncate := uniqueBQName(\"golang_example_csv_truncate\")\n+\tif err := importCSVTruncate(client, datasetID, autoCSVTruncate); err != nil {\n+\t\tt.Fatalf(\"importCSVTruncate(dataset:%q table:%q): %v\", datasetID, autoCSVTruncate, err)\n+\t}\n+\n \texplicitCSV := uniqueBQName(\"golang_example_dataset_importcsv_explicit\")\n \tif err := importCSVExplicitSchema(client, datasetID, explicitCSV); err != nil {\n \t\tt.Fatalf(\"importCSVExplicitSchema(dataset:%q table:%q): %v\", datasetID, explicitCSV, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "monitoring/custommetric/custommetric_test.go",
        "code_diff": "@@ -37,16 +37,12 @@\nfunc TestCustomMetric(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \n-\tfor {\n+\ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n \t\t_, err = getCustomMetric(s, hc.ProjectID, metricType)\n-\t\tif err == nil {\n-\t\t\tbreak\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"%v\", err)\n \t\t}\n-\t\ttime.Sleep(2 * time.Second)\n-\t}\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n+\t})\n \n \ttime.Sleep(2 * time.Second)",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -64,7 +64,7 @@\nfunc waitImpl() {\n // Simulates a memory-hungry function. It calls an \"impl\" function to produce\n // a bit deeper stacks in the profiler visualization, merely for illustration\n // purpose.\n-func alloc() {\n+func allocOnce() {\n \tallocImpl()\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -75,6 +75,18 @@\nfunc allocImpl() {\n \t}\n }\n \n+// allocMany simulates a function which allocates a lot of memory, but does not\n+// hold on to that memory.\n+func allocMany() {\n+\t// Allocate 1 MiB of 64 KiB chunks repeatedly.\n+\tfor {\n+\t\tfor i := 0; i < 16; i++ {\n+\t\t\t_ = make([]byte, 64*1024)\n+\t\t}\n+\t\ttime.Sleep(100 * time.Millisecond)\n+\t}\n+}\n+\n // Simulates a CPU-intensive computation.\n func busyloop() {\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-changes",
        "commit_id": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "appengine/go11x/helloworld/helloworld.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)\n \n+\t// [START setting_port]\n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {\n \t\tport = \"8080\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -64,7 +64,7 @@\nfunc waitImpl() {\n // Simulates a memory-hungry function. It calls an \"impl\" function to produce\n // a bit deeper stacks in the profiler visualization, merely for illustration\n // purpose.\n-func alloc() {\n+func allocOnce() {\n \tallocImpl()\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -75,6 +75,18 @@\nfunc allocImpl() {\n \t}\n }\n \n+// allocMany simulates a function which allocates a lot of memory, but does not\n+// hold on to that memory.\n+func allocMany() {\n+\t// Allocate 1 MiB of 64 KiB chunks repeatedly.\n+\tfor {\n+\t\tfor i := 0; i < 16; i++ {\n+\t\t\t_ = make([]byte, 64*1024)\n+\t\t}\n+\t\ttime.Sleep(100 * time.Millisecond)\n+\t}\n+}\n+\n // Simulates a CPU-intensive computation.\n func busyloop() {\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "profiler: add function to hotapp which repeatedly allocates memory",
        "pr_number": 621,
        "file_name": "appengine/go11x/helloworld/helloworld.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)\n \n+\t// [START setting_port]\n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {\n \t\tport = \"8080\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into hotapp",
        "commit_id": "a098fbee31d19f7e3c1280873c73f1650c8a42d3"
    },
    {
        "pr_title": "Speech auto punctuation and enhanced model snippets",
        "pr_number": 614,
        "file_name": "docs/appengine/taskqueue/taskqueue.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage sample\n // [START tasks_within_transactions]\n import (\n \t\"context\"\n+\t\"net/http\"\n \t\"net/url\"\n \n \t\"google.golang.org/appengine/datastore\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into transcribe_auto_punctuation",
        "commit_id": "16624d51e9612ef00498ccb2b391e92aa79b767d"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-1/main.go",
        "code_diff": "@@ -4,23 +4,23 @@\npackage main\n \n-// [START import_statements]\n+// [START gae_go_env_import]\n import (\n \t\"fmt\"\n \t\"net/http\"\n \n \t\"google.golang.org/appengine\" // Required external App Engine library\n )\n \n-// [END import_statements]\n-// [START main_func]\n+// [END gae_go_env_import]\n+// [START gae_go_env_main]\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)\n \tappengine.Main() // Starts the server to receive requests\n }\n \n-// [END main_func]\n-// [START indexHandler]\n+// [END gae_go_env_main]\n+// [START gae_go_env_index]\n func indexHandler(w http.ResponseWriter, r *http.Request) {\n \t// if statement redirects all invalid URLs to the root homepage.\n \t// Ex: if URL is http://[YOUR_PROJECT_ID].appspot.com/FOO, it will be",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-3/main.go",
        "code_diff": "@@ -5,28 +5,28 @@\npackage main\n \n import (\n-\t// [START import]\n+\t// [START gae_go_env_template_import]\n \t\"fmt\"\n \t\"html/template\"\n-\t// [END import]\n+\t// [END gae_go_env_template_import]\n \t\"net/http\"\n \n \t\"google.golang.org/appengine\"\n )\n \n-// [START templ_variable]\n+// [START gae_go_env_template_vars]\n var (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [END templ_variable]\n-// [START templ_params]\n+// [END gae_go_env_template_vars]\n+// [START gae_go_env_template_params]\n type templateParams struct {\n \tNotice string\n \tName   string\n }\n \n-// [END templ_params]\n+// [END gae_go_env_template_params]\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)\n \tappengine.Main()",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-3/main.go",
        "code_diff": "@@ -37,7 +37,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\thttp.Redirect(w, r, \"/\", http.StatusFound)\n \t\treturn\n \t}\n-\t// [START handling]\n+\t// [START gae_go_env_handling]\n \tparams := templateParams{}\n \n \tif r.Method == \"GET\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -11,36 +11,36 @@\nimport (\n \n \t\"google.golang.org/appengine\"\n \n-\t// [START imports]\n+\t// [START gae_go_env_data_imports]\n \t\"time\"\n \n \t\"google.golang.org/appengine/datastore\"\n \t\"google.golang.org/appengine/log\"\n-\t// [END imports]\n+\t// [END gae_go_env_data_imports]\n )\n \n var (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [START post_struct]\n+// [START gae_go_env_post_struct]\n type Post struct {\n \tAuthor  string\n \tMessage string\n \tPosted  time.Time\n }\n \n-// [END post_struct]\n+// [END gae_go_env_post_struct]\n \n type templateParams struct {\n \tNotice string\n \n \tName string\n-\t// [START added_templateParams_fields]\n+\t// [START gae_go_env_template_params_fields]\n \tMessage string\n \n \tPosts []Post\n-\t// [END added_templateParams_fields]\n+\t// [END gae_go_env_template_params_fields]\n \n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -54,37 +54,37 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\thttp.Redirect(w, r, \"/\", http.StatusFound)\n \t\treturn\n \t}\n-\t// [START new_context]\n+\t// [START gae_go_env_new_context]\n \tctx := appengine.NewContext(r)\n-\t// [END new_context]\n+\t// [END gae_go_env_new_context]\n \tparams := templateParams{}\n \n-\t// [START new_query]\n+\t// [START gae_go_env_new_query]\n \tq := datastore.NewQuery(\"Post\").Order(\"-Posted\").Limit(20)\n-\t// [END new_query]\n-\t// [START get_posts]\n+\t// [END gae_go_env_new_query]\n+\t// [START gae_go_env_get_posts]\n \tif _, err := q.GetAll(ctx, &params.Posts); err != nil {\n \t\tlog.Errorf(ctx, \"Getting posts: %v\", err)\n \t\tw.WriteHeader(http.StatusInternalServerError)\n \t\tparams.Notice = \"Couldn't get latest posts. Refresh?\"\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n-\t// [END get_posts]\n+\t// [END gae_go_env_get_posts]\n \n \tif r.Method == \"GET\" {\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n \n \t// It's a POST request, so handle the form submission.\n-\t// [START new_post]\n+\t// [START gae_go_env_new_post]\n \tpost := Post{\n \t\tAuthor:  r.FormValue(\"name\"),\n \t\tMessage: r.FormValue(\"message\"),\n \t\tPosted:  time.Now(),\n \t}\n-\t// [END new_post]\n+\t// [END gae_go_env_new_post]\n \tif post.Author == \"\" {\n \t\tpost.Author = \"Anonymous Gopher\"\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -96,10 +96,10 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n-\t// [START new_key]\n+\t// [START gae_go_env_new_key]\n \tkey := datastore.NewIncompleteKey(ctx, \"Post\", nil)\n-\t// [END new_key]\n-\t// [START add_post]\n+\t// [END gae_go_env_new_key]\n+\t// [START gae_go_env_add_post]\n \tif _, err := datastore.Put(ctx, key, &post); err != nil {\n \t\tlog.Errorf(ctx, \"datastore.Put: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -10,16 +10,16 @@\nimport (\n \t\"net/http\"\n \t\"time\"\n \n-\t// [START imports]\n+\t// [START gae_go_env_firebase_imports]\n \tfirebase \"firebase.google.com/go\"\n-\t// [END imports]\n+\t// [END gae_go_env_firebase_imports]\n \n \t\"google.golang.org/appengine\"\n \t\"google.golang.org/appengine/datastore\"\n \t\"google.golang.org/appengine/log\"\n )\n \n-// [START new_variable]\n+// [START gae_go_env_new_variable]\n \n var (\n \tfirebaseConfig = &firebase.Config{",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -30,9 +30,9 @@\nvar (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [END new_variable]\n+// [END gae_go_env_new_variable]\n \n-// [START new_post_field]\n+// [START gae_go_env_new_post_field]\n \n type Post struct {\n \tAuthor  string",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -41,7 +41,7 @@\ntype Post struct {\n \tPosted  time.Time\n }\n \n-// [END new_post_field]\n+// [END gae_go_env_new_post_field]\n \n type templateParams struct {\n \tNotice  string",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -78,7 +78,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t}\n \t// It's a POST request, so handle the form submission.\n \n-\t// [START firebase_token]\n+\t// [START gae_go_env_firebase_token]\n \tmessage := r.FormValue(\"message\")\n \n \t// Create a new Firebase App.",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-5/static/index.js",
        "code_diff": "@@ -3,7 +3,7 @@\nwindow.addEventListener('load', function () {\n     firebase.auth().signOut();\n   };\n \n-  // [START UIconfig_variable]\n+  // [START gae_go_env_ui_config]\n   // FirebaseUI config.\n   var uiConfig = {\n     signInSuccessUrl: '/',",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "appengine/gophers/gophers-5/static/index.js",
        "code_diff": "@@ -19,9 +19,9 @@\nwindow.addEventListener('load', function () {\n     // Terms of service url.\n     tosUrl: '<your-tos-url>'\n   };\n-  // [END UIconfig_variable]\n+  // [END gae_go_env_ui_config]\n \n-  // [START auth_request]\n+  // [START gae_go_env_auth_request]\n   firebase.auth().onAuthStateChanged(function (user) {\n     if (user) {\n       // User is signed in.",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/appidentity/appidentity.go",
        "code_diff": "@@ -4,7 +4,7 @@\npackage sample\n \n-// [START asserting_identity_to_Google_APIs]\n+// [START gae_go_app_identity]\n import (\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -14,7 +14,7 @@\nimport (\n )\n \n func sampleHandler(w http.ResponseWriter, r *http.Request) {\n-\t// [START uploading_a_blob_2]\n+\t// [START gae_blobstore_upload_form]\n \tvar rootTemplate = template.Must(template.New(\"root\").Parse(rootTemplateHTML))\n \n \tconst rootTemplateHTML = `",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -24,16 +24,16 @@\nUpload File: <input type=\"file\" name=\"file\"><br>\n <input type=\"submit\" name=\"submit\" value=\"Submit\">\n </form></body></html>\n `\n-\t// [END uploading_a_blob_2]\n+\t// [END gae_blobstore_upload_form]\n \n-\t// [START uploading_a_blob_1]\n+\t// [START gae_blobstore_upload_url]\n \tctx := appengine.NewContext(r)\n \tuploadURL, err := blobstore.UploadURL(ctx, \"/upload\", nil)\n \tif err != nil {\n \t\tserveError(ctx, w, err)\n \t\treturn\n \t}\n-\t// [END uploading_a_blob_1]\n+\t// [END gae_blobstore_upload_url]\n \n \tw.Header().Set(\"Content-Type\", \"text/html\")\n \terr = rootTemplate.Execute(w, uploadURL)",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -43,7 +43,7 @@\nUpload File: <input type=\"file\" name=\"file\"><br>\n }\n \n func sampleHandler2(w http.ResponseWriter, r *http.Request) {\n-\t// [START uploading_a_blob_3]\n+\t// [START gae_blobstore_upload_handler]\n \tctx := appengine.NewContext(r)\n \tblobs, _, err := blobstore.ParseUpload(r)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -57,16 +57,15 @@\nfunc sampleHandler2(w http.ResponseWriter, r *http.Request) {\n \t\treturn\n \t}\n \thttp.Redirect(w, r, \"/serve/?blobKey=\"+string(file[0].BlobKey), http.StatusFound)\n-\t// [END uploading_a_blob_3]\n+\t// [END gae_blobstore_upload_handler]\n \n-\t// [START serving_a_blob]\n+\t// [START gae_blobstore_serving]\n \tblobstore.Send(w, appengine.BlobKey(r.FormValue(\"blobKey\")))\n-\t// [END serving_a_blob]\n+\t// [END gae_blobstore_serving]\n }\n \n /* Requires old package (import \"appengine/blobstore\")\n \n-// [START writing_files_to_the_Blobstore]\n var k appengine.BlobKey\n bw, err := blobstore.Create(ctx, \"application/octet-stream\")\n if err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/blobstore/complete.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START complete_sample_application]\n+// [START gae_blobstore_sample]\n \n package blobstore_example",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/capabilities/capability.go",
        "code_diff": "@@ -13,7 +13,7 @@\nimport (\n \t\"google.golang.org/appengine/capability\"\n )\n \n-// [START datastore_lookup]\n+// [START gae_go_capabilities_lookup]\n func handler(w http.ResponseWriter, r *http.Request) {\n \tctx := appengine.NewContext(r)\n \tif !capability.Enabled(ctx, \"datastore_v3\", \"*\") {",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -18,7 +18,7 @@\nimport (\n var maxHeight int\n var minBirthYear, maxBirthYear int\n \n-// [START interface]\n+// [START gae_go_datastore_interface]\n type Person struct {\n \tFirstName string\n \tLastName  string",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -45,48 +45,48 @@\nfunc handle(w http.ResponseWriter, r *http.Request) {\n \t// ...\n }\n \n-// [END interface]\n+// [END gae_go_datastore_interface]\n \n func example() {\n \tvar lastSeenKey *datastore.Key\n \n-\t// [START key_filter_example]\n+\t// [START gae_go_datastore_key_filter]\n \tq := datastore.NewQuery(\"Person\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END key_filter_example]\n+\t// [END gae_go_datastore_key_filter]\n \t_ = q\n }\n \n func example2() {\n-\t// [START property_filter_example]\n+\t// [START gae_go_datastore_property_filter]\n \tq := datastore.NewQuery(\"Person\").Filter(\"Height <=\", maxHeight)\n-\t// [END property_filter_example]\n+\t// [END gae_go_datastore_property_filter]\n \t_ = q\n }\n \n func example3() {\n \tvar ancestorKey *datastore.Key\n \n-\t// [START ancestor_filter_example]\n+\t// [START gae_go_datastore_ancestor_filter]\n \tq := datastore.NewQuery(\"Person\").Ancestor(ancestorKey)\n-\t// [END ancestor_filter_example]\n+\t// [END gae_go_datastore_ancestor_filter]\n \t_ = q\n }\n \n func example4() {\n-\t// [START sort_order_example]\n+\t// [START gae_go_datastore_sort_order]\n \t// Order alphabetically by last name:\n \tq := datastore.NewQuery(\"Person\").Order(\"LastName\")\n \n \t// Order by height, tallest to shortest:\n \tq = datastore.NewQuery(\"Person\").Order(\"-Height\")\n-\t// [END sort_order_example]\n+\t// [END gae_go_datastore_sort_order]\n \t_ = q\n }\n \n func example5() {\n-\t// [START multiple_sort_orders_example]\n+\t// [START gae_go_datastore_multiple_sort_orders]\n \tq := datastore.NewQuery(\"Person\").Order(\"LastName\").Order(\"-Height\")\n-\t// [END multiple_sort_orders_example]\n+\t// [END gae_go_datastore_multiple_sort_orders]\n \t_ = q\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -96,7 +96,7 @@\nfunc example6() {\n \t}\n \tvar ctx context.Context\n \n-\t// [START ancestor_query_example]\n+\t// [START gae_go_datastore_ancestor_query]\n \t// Create two Photo entities in the datastore with a Person as their ancestor.\n \ttomKey := datastore.NewKey(ctx, \"Person\", \"Tom\", 0, nil)",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -117,101 +117,101 @@\nfunc example6() {\n \t_, err = q.GetAll(ctx, &photos)\n \t// check err\n \t// do something with photos\n-\t// [END ancestor_query_example]\n+\t// [END gae_go_datastore_ancestor_query]\n \t_ = err\n \t_ = photos\n }\n \n func example7() {\n-\t// [START keys_only_example]\n+\t// [START gae_go_datastore_keys_only]\n \tq := datastore.NewQuery(\"Person\").KeysOnly()\n-\t// [END keys_only_example]\n+\t// [END gae_go_datastore_keys_only]\n \t_ = q\n }\n \n func example8() {\n-\t// [START inequality_filters_one_property_valid_example_1]\n+\t// [START gae_go_datastore_inequality_filters_one_property_valid_1]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"BirthYear <=\", maxBirthYear)\n-\t// [END inequality_filters_one_property_valid_example_1]\n+\t// [END gae_go_datastore_inequality_filters_one_property_valid_1]\n \t_ = q\n }\n \n func example9() {\n-\t// [START inequality_filters_one_property_invalid_example]\n+\t// [START gae_go_datastore_inequality_filters_one_property_invalid]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"Height <=\", maxHeight) // ERROR\n-\t// [END inequality_filters_one_property_invalid_example]\n+\t// [END gae_go_datastore_inequality_filters_one_property_invalid]\n \t_ = q\n }\n \n func example10() {\n \tvar targetLastName, targetCity string\n \n-\t// [START inequality_filters_one_property_valid_example_2]\n+\t// [START gae_go_datastore_inequality_filters_one_property_valid_2]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"LastName =\", targetLastName).\n \t\tFilter(\"City =\", targetCity).\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"BirthYear <=\", maxBirthYear)\n-\t// [END inequality_filters_one_property_valid_example_2]\n+\t// [END gae_go_datastore_inequality_filters_one_property_valid_2]\n \t_ = q\n }\n \n func example11() {\n-\t// [START inequality_filters_sort_orders_valid_example]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_valid]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"BirthYear\").\n \t\tOrder(\"LastName\")\n-\t// [END inequality_filters_sort_orders_valid_example]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_valid]\n \t_ = q\n }\n \n func example12() {\n-\t// [START inequality_filters_sort_orders_invalid_example_1]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_invalid_1]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"LastName\") // ERROR\n-\t// [END inequality_filters_sort_orders_invalid_example_1]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_invalid_1]\n \t_ = q\n }\n \n func example13() {\n-\t// [START inequality_filters_sort_orders_invalid_example_2]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_invalid_2]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"LastName\").\n \t\tOrder(\"BirthYear\") // ERROR\n-\t// [END inequality_filters_sort_orders_invalid_example_2]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_invalid_2]\n \t_ = q\n }\n \n func example14() {\n-\t// [START surprising_behavior_example_1]\n+\t// [START gae_go_datastore_surprising_behavior_1]\n \tq := datastore.NewQuery(\"Widget\").\n \t\tFilter(\"x >\", 1).\n \t\tFilter(\"x <\", 2)\n-\t// [END surprising_behavior_example_1]\n+\t// [END gae_go_datastore_surprising_behavior_1]\n \t_ = q\n }\n \n func example15() {\n-\t// [START surprising_behavior_example_2]\n+\t// [START gae_go_datastore_surprising_behavior_2]\n \tq := datastore.NewQuery(\"Widget\").\n \t\tFilter(\"x =\", 1).\n \t\tFilter(\"x =\", 2)\n-\t// [END surprising_behavior_example_2]\n+\t// [END gae_go_datastore_surprising_behavior_2]\n \t_ = q\n }\n \n func doSomething(k *datastore.Key, p Person) {}\n \n func example16() {\n \tvar ctx context.Context\n-\t// [START retrieval_example]\n+\t// [START gae_go_datastore_retrieval]\n \tq := datastore.NewQuery(\"Person\")\n \tt := q.Run(ctx)\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -227,13 +227,13 @@\nfunc example16() {\n \t\t// Do something with Person p and Key k\n \t\tdoSomething(k, p)\n \t}\n-\t// [END retrieval_example]\n+\t// [END gae_go_datastore_retrieval]\n }\n \n func example17() {\n \tvar ctx context.Context\n \n-\t// [START all_entities_retrieval_example]\n+\t// [START gae_go_datastore_all_entities_retrieval]\n \tq := datastore.NewQuery(\"Person\")\n \tvar people []Person\n \tkeys, err := q.GetAll(ctx, &people)",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -246,13 +246,13 @@\nfunc example17() {\n \t\t// Do something with Person p and Key k\n \t\tdoSomething(k, p)\n \t}\n-\t// [END all_entities_retrieval_example]\n+\t// [END gae_go_datastore_all_entities_retrieval]\n }\n \n func example18() {\n \tvar ctx context.Context\n \n-\t// [START query_limit_example]\n+\t// [START gae_go_datastore_query_limit]\n \tq := datastore.NewQuery(\"Person\").Order(\"-Height\").Limit(5)\n \tvar people []Person\n \t_, err := q.GetAll(ctx, &people)",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -261,21 +261,19 @@\nfunc example18() {\n \tfor _, p := range people {\n \t\tlog.Infof(ctx, \"%s %s, %d inches tall\", p.FirstName, p.LastName, p.Height)\n \t}\n-\t// [END query_limit_example]\n+\t// [END gae_go_datastore_query_limit]\n \t_ = err\n }\n \n func example19() {\n-\t// [START query_offset_example]\n \tq := datastore.NewQuery(\"Person\").Order(\"-Height\").Limit(5).Offset(5)\n-\t// [END query_offset_example]\n \t_ = q\n }\n \n func example20() {\n \tvar ctx context.Context\n \n-\t// [START cursors]\n+\t// [START gae_go_datastore_cursors]\n \t// Create a query for all Person entities.\n \tq := datastore.NewQuery(\"Person\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -310,24 +308,24 @@\nfunc example20() {\n \t\t\tValue: []byte(cursor.String()),\n \t\t})\n \t}\n-\t// [END cursors]\n+\t// [END gae_go_datastore_cursors]\n }\n \n func example21() {\n \tvar lastSeenKey *datastore.Key\n \n-\t// [START kindless_query_example]\n+\t// [START gae_go_datastore_kindless_query]\n \tq := datastore.NewQuery(\"\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_query_example]\n+\t// [END gae_go_datastore_kindless_query]\n \t_ = q\n }\n \n func example22() {\n \tvar ancestorKey, lastSeenKey *datastore.Key\n \n-\t// [START kindless_ancestor_key_query_example]\n+\t// [START gae_go_datastore_kindless_ancestor_key_query]\n \tq := datastore.NewQuery(\"\").Ancestor(ancestorKey).Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_ancestor_key_query_example]\n+\t// [END gae_go_datastore_kindless_ancestor_key_query]\n \t_ = q\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -339,7 +337,7 @@\nfunc example23() {\n \tvar ctx context.Context\n \tdoSomething := func(x interface{}) {}\n \n-\t// [START kindless_ancestor_query_example]\n+\t// [START gae_go_datastore_kindless_ancestor_query]\n \ttomKey := datastore.NewKey(ctx, \"Person\", \"Tom\", 0, nil)\n \n \tweddingPhoto := &Photo{URL: \"http://example.com/some/path/to/wedding_photo.jpg\"}",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/logs/logs.go",
        "code_diff": "@@ -2,8 +2,6 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START sample_code]\n-\n // This sample gets the app displays 5 log Records at a time, including all\n // AppLogs, with a Next link to let the user page through the results using the\n // Record's Offset property.",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "docs/appengine/logs/writing_logs.go",
        "code_diff": "@@ -4,7 +4,7 @@\npackage app\n \n-// [START sample]\n+// [START gae_writing_logs]\n import (\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -45,7 +45,7 @@\nfunc getAsymmetricPublicKey(ctx context.Context, client *cloudkms.Service, keyPa\n \n // [START kms_decrypt_rsa]\n \n-// decryptRSA will attempt to decrypt a given ciphertext with saved a RSA key.\n+// decryptRSA will attempt to decrypt a given ciphertext with an 'RSA_DECRYPT_OAEP_2048_SHA256' private key.stored on Cloud KMS\n func decryptRSA(ctx context.Context, client *cloudkms.Service, ciphertext, keyPath string) (string, error) {\n \tdecryptRequest := &cloudkms.AsymmetricDecryptRequest{\n \t\tCiphertext: ciphertext,",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -67,7 +67,7 @@\nfunc decryptRSA(ctx context.Context, client *cloudkms.Service, ciphertext, keyPa\n \n // [START kms_encrypt_rsa]\n \n-// encryptRSA creates a ciphertext from a plain message using a RSA public key saved at the specified keyPath.\n+// encryptRSA will encrypt a message locally using an 'RSA_DECRYPT_OAEP_2048_SHA256' public key retrieved from Cloud KMS\n func encryptRSA(ctx context.Context, client *cloudkms.Service, message, keyPath string) (string, error) {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -90,7 +90,8 @@\nfunc encryptRSA(ctx context.Context, client *cloudkms.Service, message, keyPath\n \n // signAsymmetric will sign a plaintext message using a saved asymmetric private key.\n func signAsymmetric(ctx context.Context, client *cloudkms.Service, message, keyPath string) (string, error) {\n-\t// Find the hash of the plaintext message.\n+\t// Note: some key algorithms will require a different hash function.\n+\t// For example, EC_SIGN_P384_SHA384 requires SHA-384.\n \tdigest := sha256.New()\n \tdigest.Write([]byte(message))\n \tdigestStr := base64.StdEncoding.EncodeToString(digest.Sum(nil))",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -62,6 +62,8 @@\nfunc usage(msg string) {\n \tos.Exit(2)\n }\n \n+// [START language_entities_text]\n+\n func analyzeEntities(ctx context.Context, client *language.Client, text string) (*languagepb.AnalyzeEntitiesResponse, error) {\n \treturn client.AnalyzeEntities(ctx, &languagepb.AnalyzeEntitiesRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -74,6 +76,10 @@\nfunc analyzeEntities(ctx context.Context, client *language.Client, text string)\n \t})\n }\n \n+// [END language_entities_text]\n+\n+// [START language_sentiment_text]\n+\n func analyzeSentiment(ctx context.Context, client *language.Client, text string) (*languagepb.AnalyzeSentimentResponse, error) {\n \treturn client.AnalyzeSentiment(ctx, &languagepb.AnalyzeSentimentRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -85,6 +91,10 @@\nfunc analyzeSentiment(ctx context.Context, client *language.Client, text string)\n \t})\n }\n \n+// [END language_sentiment_text]\n+\n+// [START language_syntax_text]\n+\n func analyzeSyntax(ctx context.Context, client *language.Client, text string) (*languagepb.AnnotateTextResponse, error) {\n \treturn client.AnnotateText(ctx, &languagepb.AnnotateTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -100,6 +110,10 @@\nfunc analyzeSyntax(ctx context.Context, client *language.Client, text string) (*\n \t})\n }\n \n+// [END language_syntax_text]\n+\n+// [START language_classify_text]\n+\n func classifyText(ctx context.Context, client *language.Client, text string) (*languagepb.ClassifyTextResponse, error) {\n \treturn client.ClassifyText(ctx, &languagepb.ClassifyTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "language/analyze/entity_sentiment.go",
        "code_diff": "@@ -22,6 +22,8 @@\nfunc betaClient() *language.Client {\n \treturn client\n }\n \n+// [START language_entity_sentiment_text]\n+\n func analyzeEntitySentiment(ctx context.Context, client *language.Client, text string) (*languagepb.AnalyzeEntitySentimentResponse, error) {\n \treturn client.AnalyzeEntitySentiment(ctx, &languagepb.AnalyzeEntitySentimentRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -15,6 +15,8 @@\nimport (\n // to avoid it being included in the function signature below.\n var client *language.Client\n \n+// [START language_entities_gcs]\n+\n func analyzeEntitiesFromGCS(ctx context.Context, gcsURI string) (*languagepb.AnalyzeEntitiesResponse, error) {\n \treturn client.AnalyzeEntities(ctx, &languagepb.AnalyzeEntitiesRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -27,6 +29,10 @@\nfunc analyzeEntitiesFromGCS(ctx context.Context, gcsURI string) (*languagepb.Ana\n \t})\n }\n \n+// [END language_entities_gcs]\n+\n+// [START language_sentiment_gcs]\n+\n func analyzeSentimentFromGCS(ctx context.Context, gcsURI string) (*languagepb.AnalyzeSentimentResponse, error) {\n \treturn client.AnalyzeSentiment(ctx, &languagepb.AnalyzeSentimentRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -38,6 +44,10 @@\nfunc analyzeSentimentFromGCS(ctx context.Context, gcsURI string) (*languagepb.An\n \t})\n }\n \n+// [END language_sentiment_gcs]\n+\n+// [START language_syntax_gcs]\n+\n func analyzeSyntaxFromGCS(ctx context.Context, gcsURI string) (*languagepb.AnnotateTextResponse, error) {\n \treturn client.AnnotateText(ctx, &languagepb.AnnotateTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -53,6 +63,10 @@\nfunc analyzeSyntaxFromGCS(ctx context.Context, gcsURI string) (*languagepb.Annot\n \t})\n }\n \n+// [END language_syntax_gcs]\n+\n+// [START language_classify_gcs]\n+\n func classifyTextFromGCS(ctx context.Context, gcsURI string) (*languagepb.ClassifyTextResponse, error) {\n \treturn client.ClassifyText(ctx, &languagepb.ClassifyTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "speech/wordoffset/wordoffset.go",
        "code_diff": "@@ -54,7 +54,7 @@\nfunc main() {\n \t}\n }\n \n-// [START speech_transcribe_async_time_offsets_gcs]\n+// [START speech_transcribe_async_word_time_offsets_gcs]\n \n func asyncWords(client *speech.Client, out io.Writer, gcsURI string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "texttospeech/list_voices/list_voices.go",
        "code_diff": "@@ -17,7 +17,7 @@\nimport (\n \ttexttospeechpb \"google.golang.org/genproto/googleapis/cloud/texttospeech/v1\"\n )\n \n-// [START ListVoices]\n+// [START tts_list_voices]\n \n // ListVoices lists the available text to speech voices.\n func ListVoices(w io.Writer) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "texttospeech/quickstart/quickstart.go",
        "code_diff": "@@ -16,7 +16,7 @@\nimport (\n \ttexttospeechpb \"google.golang.org/genproto/googleapis/cloud/texttospeech/v1\"\n )\n \n-// [START quickstart]\n+// [START tts_quickstart]\n \n func main() {\n \t// Instantiates a client.",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "texttospeech/synthesize_file/synthesize_file.go",
        "code_diff": "@@ -19,7 +19,7 @@\nimport (\n \ttexttospeechpb \"google.golang.org/genproto/googleapis/cloud/texttospeech/v1\"\n )\n \n-// [START SynthesizeTextFile]\n+// [START tts_synthesize_text_file]\n \n // SynthesizeTextFile synthesizes the text in textFile and saves the output to\n // outputFile.",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "texttospeech/synthesize_file/synthesize_file.go",
        "code_diff": "@@ -64,9 +64,9 @@\nfunc SynthesizeTextFile(w io.Writer, textFile, outputFile string) error {\n \treturn nil\n }\n \n-// [END SynthesizeTextFile]\n+// [END tts_synthesize_text_file]\n \n-// [START SynthesizeSSMLFile]\n+// [START tts_synthesize_ssml_file]\n \n // SynthesizeSSMLFile synthesizes the SSML contents in ssmlFile and saves the\n // output to outputFile.",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "texttospeech/synthesize_text/synthesize_text.go",
        "code_diff": "@@ -19,7 +19,7 @@\nimport (\n \ttexttospeechpb \"google.golang.org/genproto/googleapis/cloud/texttospeech/v1\"\n )\n \n-// [START SynthesizeText]\n+// [START tts_synthesize_text]\n \n // SynthesizeText synthesizes plain text and saves the output to outputFile.\n func SynthesizeText(w io.Writer, text, outputFile string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Container Analysis Beta",
        "pr_number": 589,
        "file_name": "texttospeech/synthesize_text/synthesize_text.go",
        "code_diff": "@@ -58,9 +58,9 @@\nfunc SynthesizeText(w io.Writer, text, outputFile string) error {\n \treturn nil\n }\n \n-// [END SynthesizeText]\n+// [END tts_synthesize_text]\n \n-// [START SynthesizeSSML]\n+// [START tts_synthesize_ssml]\n \n // SynthesizeSSML synthesizes ssml and saves the output to outputFile.\n //",
        "comments": [],
        "commit_message": "Merge branch 'master' into drydock-beta",
        "commit_id": "1dec1863fb2469fa8115333ef5b1ddddf74deff0"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-1/main.go",
        "code_diff": "@@ -4,23 +4,23 @@\npackage main\n \n-// [START import_statements]\n+// [START gae_go_env_import]\n import (\n \t\"fmt\"\n \t\"net/http\"\n \n \t\"google.golang.org/appengine\" // Required external App Engine library\n )\n \n-// [END import_statements]\n-// [START main_func]\n+// [END gae_go_env_import]\n+// [START gae_go_env_main]\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)\n \tappengine.Main() // Starts the server to receive requests\n }\n \n-// [END main_func]\n-// [START indexHandler]\n+// [END gae_go_env_main]\n+// [START gae_go_env_index]\n func indexHandler(w http.ResponseWriter, r *http.Request) {\n \t// if statement redirects all invalid URLs to the root homepage.\n \t// Ex: if URL is http://[YOUR_PROJECT_ID].appspot.com/FOO, it will be",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-3/main.go",
        "code_diff": "@@ -5,28 +5,28 @@\npackage main\n \n import (\n-\t// [START import]\n+\t// [START gae_go_env_template_import]\n \t\"fmt\"\n \t\"html/template\"\n-\t// [END import]\n+\t// [END gae_go_env_template_import]\n \t\"net/http\"\n \n \t\"google.golang.org/appengine\"\n )\n \n-// [START templ_variable]\n+// [START gae_go_env_template_vars]\n var (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [END templ_variable]\n-// [START templ_params]\n+// [END gae_go_env_template_vars]\n+// [START gae_go_env_template_params]\n type templateParams struct {\n \tNotice string\n \tName   string\n }\n \n-// [END templ_params]\n+// [END gae_go_env_template_params]\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)\n \tappengine.Main()",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-3/main.go",
        "code_diff": "@@ -37,7 +37,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\thttp.Redirect(w, r, \"/\", http.StatusFound)\n \t\treturn\n \t}\n-\t// [START handling]\n+\t// [START gae_go_env_handling]\n \tparams := templateParams{}\n \n \tif r.Method == \"GET\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -11,36 +11,36 @@\nimport (\n \n \t\"google.golang.org/appengine\"\n \n-\t// [START imports]\n+\t// [START gae_go_env_data_imports]\n \t\"time\"\n \n \t\"google.golang.org/appengine/datastore\"\n \t\"google.golang.org/appengine/log\"\n-\t// [END imports]\n+\t// [END gae_go_env_data_imports]\n )\n \n var (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [START post_struct]\n+// [START gae_go_env_post_struct]\n type Post struct {\n \tAuthor  string\n \tMessage string\n \tPosted  time.Time\n }\n \n-// [END post_struct]\n+// [END gae_go_env_post_struct]\n \n type templateParams struct {\n \tNotice string\n \n \tName string\n-\t// [START added_templateParams_fields]\n+\t// [START gae_go_env_template_params_fields]\n \tMessage string\n \n \tPosts []Post\n-\t// [END added_templateParams_fields]\n+\t// [END gae_go_env_template_params_fields]\n \n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -54,37 +54,37 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\thttp.Redirect(w, r, \"/\", http.StatusFound)\n \t\treturn\n \t}\n-\t// [START new_context]\n+\t// [START gae_go_env_new_context]\n \tctx := appengine.NewContext(r)\n-\t// [END new_context]\n+\t// [END gae_go_env_new_context]\n \tparams := templateParams{}\n \n-\t// [START new_query]\n+\t// [START gae_go_env_new_query]\n \tq := datastore.NewQuery(\"Post\").Order(\"-Posted\").Limit(20)\n-\t// [END new_query]\n-\t// [START get_posts]\n+\t// [END gae_go_env_new_query]\n+\t// [START gae_go_env_get_posts]\n \tif _, err := q.GetAll(ctx, &params.Posts); err != nil {\n \t\tlog.Errorf(ctx, \"Getting posts: %v\", err)\n \t\tw.WriteHeader(http.StatusInternalServerError)\n \t\tparams.Notice = \"Couldn't get latest posts. Refresh?\"\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n-\t// [END get_posts]\n+\t// [END gae_go_env_get_posts]\n \n \tif r.Method == \"GET\" {\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n \n \t// It's a POST request, so handle the form submission.\n-\t// [START new_post]\n+\t// [START gae_go_env_new_post]\n \tpost := Post{\n \t\tAuthor:  r.FormValue(\"name\"),\n \t\tMessage: r.FormValue(\"message\"),\n \t\tPosted:  time.Now(),\n \t}\n-\t// [END new_post]\n+\t// [END gae_go_env_new_post]\n \tif post.Author == \"\" {\n \t\tpost.Author = \"Anonymous Gopher\"\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -96,10 +96,10 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n-\t// [START new_key]\n+\t// [START gae_go_env_new_key]\n \tkey := datastore.NewIncompleteKey(ctx, \"Post\", nil)\n-\t// [END new_key]\n-\t// [START add_post]\n+\t// [END gae_go_env_new_key]\n+\t// [START gae_go_env_add_post]\n \tif _, err := datastore.Put(ctx, key, &post); err != nil {\n \t\tlog.Errorf(ctx, \"datastore.Put: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -10,16 +10,16 @@\nimport (\n \t\"net/http\"\n \t\"time\"\n \n-\t// [START imports]\n+\t// [START gae_go_env_firebase_imports]\n \tfirebase \"firebase.google.com/go\"\n-\t// [END imports]\n+\t// [END gae_go_env_firebase_imports]\n \n \t\"google.golang.org/appengine\"\n \t\"google.golang.org/appengine/datastore\"\n \t\"google.golang.org/appengine/log\"\n )\n \n-// [START new_variable]\n+// [START gae_go_env_new_variable]\n \n var (\n \tfirebaseConfig = &firebase.Config{",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -30,9 +30,9 @@\nvar (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [END new_variable]\n+// [END gae_go_env_new_variable]\n \n-// [START new_post_field]\n+// [START gae_go_env_new_post_field]\n \n type Post struct {\n \tAuthor  string",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -41,7 +41,7 @@\ntype Post struct {\n \tPosted  time.Time\n }\n \n-// [END new_post_field]\n+// [END gae_go_env_new_post_field]\n \n type templateParams struct {\n \tNotice  string",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -78,13 +78,14 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t}\n \t// It's a POST request, so handle the form submission.\n \n-\t// [START firebase_token]\n+\t// [START gae_go_env_firebase_token]\n \tmessage := r.FormValue(\"message\")\n \n \t// Create a new Firebase App.\n \tapp, err := firebase.NewApp(ctx, firebaseConfig)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"firebase.NewApp: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -93,6 +94,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \tauth, err := app.Auth(ctx)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"app.Auth: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -101,6 +103,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \ttok, err := auth.VerifyIDTokenAndCheckRevoked(ctx, r.FormValue(\"token\"))\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"auth.VerifyIDAndCheckRevoked: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-5/static/index.js",
        "code_diff": "@@ -3,7 +3,7 @@\nwindow.addEventListener('load', function () {\n     firebase.auth().signOut();\n   };\n \n-  // [START UIconfig_variable]\n+  // [START gae_go_env_ui_config]\n   // FirebaseUI config.\n   var uiConfig = {\n     signInSuccessUrl: '/',",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-5/static/index.js",
        "code_diff": "@@ -19,9 +19,9 @@\nwindow.addEventListener('load', function () {\n     // Terms of service url.\n     tosUrl: '<your-tos-url>'\n   };\n-  // [END UIconfig_variable]\n+  // [END gae_go_env_ui_config]\n \n-  // [START auth_request]\n+  // [START gae_go_env_auth_request]\n   firebase.auth().onAuthStateChanged(function (user) {\n     if (user) {\n       // User is signed in.",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -217,6 +217,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \tapp, err := firebase.NewApp(ctx, firebaseConfig)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"firebase.NewApp: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -225,6 +226,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \tauth, err := app.Auth(ctx)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"app.Auth: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -233,6 +235,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \ttok, err := auth.VerifyIDTokenAndCheckRevoked(ctx, r.FormValue(\"token\"))\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"auth.VerifyIDAndCheckRevoked: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -16,115 +16,161 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n-// Use a common block to inline comments related to importing the library\n-// and constructing a client.\n-// [START bigquery_browse_table]\n-// [START bigquery_copy_table]\n-// [START bigquery_copy_table_multiple_source]\n-// [START bigquery_create_dataset]\n-// [START bigquery_create_table]\n-// [START bigquery_create_table_clustered]\n-// [START bigquery_create_table_partitioned]\n-// [START bigquery_delete_dataset]\n-// [START bigquery_delete_label_dataset]\n-// [START bigquery_delete_label_table]\n-// [START bigquery_delete_table]\n-// [START bigquery_extract_table]\n-// [START bigquery_extract_table_compressed]\n-// [START bigquery_extract_table_json]\n-// [START bigquery_get_dataset]\n-// [START bigquery_get_dataset_labels]\n-// [START bigquery_get_table]\n-// [START bigquery_get_table_labels]\n-// [START bigquery_label_dataset]\n-// [START bigquery_label_table]\n-// [START bigquery_list_datasets]\n-// [START bigquery_list_datasets_by_label]\n-// [START bigquery_list_jobs]\n-// [START bigquery_list_tables]\n-// [START bigquery_load_from_file]\n-// [START bigquery_load_table_clustered]\n-// [START bigquery_load_table_gcs_csv]\n-// [START bigquery_load_table_gcs_json]\n-// [START bigquery_load_table_gcs_json_autodetect]\n-// [START bigquery_load_table_partitioned]\n-// [START bigquery_query]\n-// [START bigquery_query_batch]\n-// [START bigquery_query_clustered_table]\n-// [START bigquery_query_destination_table]\n-// [START bigquery_query_dry_run]\n-// [START bigquery_query_legacy]\n-// [START bigquery_query_legacy_large_results]\n-// [START bigquery_query_no_cache]\n-// [START bigquery_query_params_arrays]\n-// [START bigquery_query_params_named]\n-// [START bigquery_query_params_positional]\n-// [START bigquery_query_params_structs]\n-// [START bigquery_query_params_timestamps]\n-// [START bigquery_query_partitioned_table]\n-// [START bigquery_table_insert_rows]\n-// [START bigquery_undelete_table]\n-// [START bigquery_update_dataset_access]\n-// [START bigquery_update_dataset_description]\n-// [START bigquery_update_dataset_expiration]\n-// [START bigquery_update_table_description]\n-// [START bigquery_update_table_expiration]\n-// To run this sample, you will need to create (or reuse) a context and\n-// an instance of the bigquery client.  For example:\n-// import \"cloud.google.com/go/bigquery\"\n-// ctx := context.Background()\n-// client, err := bigquery.NewClient(ctx, \"your-project-id\")\n-// [END bigquery_browse_table]\n-// [END bigquery_copy_table]\n-// [END bigquery_copy_table_multiple_source]\n-// [END bigquery_create_dataset]\n-// [END bigquery_create_table]\n-// [END bigquery_create_table_clustered]\n-// [END bigquery_create_table_partitioned]\n-// [END bigquery_delete_dataset]\n-// [END bigquery_delete_label_dataset]\n-// [END bigquery_delete_label_table]\n-// [END bigquery_delete_table]\n-// [END bigquery_extract_table]\n-// [END bigquery_extract_table_compressed]\n-// [END bigquery_extract_table_json]\n-// [END bigquery_get_dataset]\n-// [END bigquery_get_dataset_labels]\n-// [END bigquery_get_table]\n-// [END bigquery_get_table_labels]\n-// [END bigquery_label_dataset]\n-// [END bigquery_label_table]\n-// [END bigquery_list_datasets]\n-// [END bigquery_list_datasets_by_label]\n-// [END bigquery_list_jobs]\n-// [END bigquery_list_tables]\n-// [END bigquery_load_from_file]\n-// [END bigquery_load_table_clustered]\n-// [END bigquery_load_table_gcs_csv]\n-// [END bigquery_load_table_gcs_json]\n-// [END bigquery_load_table_gcs_json_autodetect]\n-// [END bigquery_load_table_partitioned]\n-// [END bigquery_query]\n-// [END bigquery_query_batch]\n-// [END bigquery_query_clustered_table]\n-// [END bigquery_query_destination_table]\n-// [END bigquery_query_dry_run]\n-// [END bigquery_query_legacy]\n-// [END bigquery_query_legacy_large_results]\n-// [END bigquery_query_no_cache]\n-// [END bigquery_query_params_arrays]\n-// [END bigquery_query_params_named]\n-// [END bigquery_query_params_positional]\n-// [END bigquery_query_params_structs]\n-// [END bigquery_query_params_timestamps]\n-// [END bigquery_query_partitioned_table]\n-// [END bigquery_table_insert_rows]\n-// [END bigquery_undelete_table]\n-// [END bigquery_update_dataset_access]\n-// [END bigquery_update_dataset_description]\n-// [END bigquery_update_dataset_expiration]\n-// [END bigquery_update_table_description]\n-// [END bigquery_update_table_expiration]\n+func noOpCommentFunc() {\n+\t// Use a common block to inline comments related to importing the library\n+\t// and constructing a client.  Inside a func to ensure the indentation is\n+\t// consistent between multiple includes.\n+\t// [START bigquery_add_empty_column]\n+\t// [START bigquery_add_column_query_append]\n+\t// [START bigquery_browse_table]\n+\t// [START bigquery_cancel_job]\n+\t// [START bigquery_copy_table]\n+\t// [START bigquery_copy_table_cmek]\n+\t// [START bigquery_copy_table_multiple_source]\n+\t// [START bigquery_create_dataset]\n+\t// [START bigquery_create_table]\n+\t// [START bigquery_create_table_clustered]\n+\t// [START bigquery_create_table_cmek]\n+\t// [START bigquery_create_table_partitioned]\n+\t// [START bigquery_delete_dataset]\n+\t// [START bigquery_delete_label_dataset]\n+\t// [START bigquery_delete_label_table]\n+\t// [START bigquery_delete_table]\n+\t// [START bigquery_extract_table]\n+\t// [START bigquery_extract_table_compressed]\n+\t// [START bigquery_extract_table_json]\n+\t// [START bigquery_get_dataset]\n+\t// [START bigquery_get_dataset_labels]\n+\t// [START bigquery_get_job]\n+\t// [START bigquery_get_table]\n+\t// [START bigquery_get_table_labels]\n+\t// [START bigquery_label_dataset]\n+\t// [START bigquery_label_table]\n+\t// [START bigquery_list_datasets]\n+\t// [START bigquery_list_datasets_by_label]\n+\t// [START bigquery_list_jobs]\n+\t// [START bigquery_list_tables]\n+\t// [START bigquery_load_from_file]\n+\t// [START bigquery_load_table_clustered]\n+\t// [START bigquery_load_table_gcs_csv]\n+\t// [START bigquery_load_table_gcs_json]\n+\t// [START bigquery_load_table_gcs_json_autodetect]\n+\t// [START bigquery_load_table_gcs_json_cmek]\n+\t// [START bigquery_load_table_gcs_orc]\n+\t// [START bigquery_load_table_gcs_orc_truncate]\n+\t// [START bigquery_load_table_gcs_parquet]\n+\t// [START bigquery_load_table_gcs_parquet_truncate]\n+\t// [START bigquery_load_table_partitioned]\n+\t// [START bigquery_nested_repeated_schema]\n+\t// [START bigquery_query]\n+\t// [START bigquery_query_batch]\n+\t// [START bigquery_query_clustered_table]\n+\t// [START bigquery_query_destination_table]\n+\t// [START bigquery_query_dry_run]\n+\t// [START bigquery_query_legacy]\n+\t// [START bigquery_query_legacy_large_results]\n+\t// [START bigquery_query_no_cache]\n+\t// [START bigquery_query_params_arrays]\n+\t// [START bigquery_query_params_named]\n+\t// [START bigquery_query_params_positional]\n+\t// [START bigquery_query_params_structs]\n+\t// [START bigquery_query_params_timestamps]\n+\t// [START bigquery_query_partitioned_table]\n+\t// [START bigquery_relax_column]\n+\t// [START bigquery_relax_column_load_append]\n+\t// [START bigquery_relax_column_query_append]\n+\t// [START bigquery_table_insert_rows]\n+\t// [START bigquery_undelete_table]\n+\t// [START bigquery_update_dataset_access]\n+\t// [START bigquery_update_dataset_description]\n+\t// [START bigquery_update_dataset_expiration]\n+\t// [START bigquery_update_table_cmek]\n+\t// [START bigquery_update_table_description]\n+\t// [START bigquery_update_table_expiration]\n+\t// To run this sample, you will need to create (or reuse) a context and\n+\t// an instance of the bigquery client.  For example:\n+\t// import \"cloud.google.com/go/bigquery\"\n+\t// ctx := context.Background()\n+\t// client, err := bigquery.NewClient(ctx, \"your-project-id\")\n+\t// [END bigquery_add_empty_column]\n+\t// [END bigquery_add_column_query_append]\n+\t// [END bigquery_browse_table]\n+\t// [END bigquery_cancel_job]\n+\t// [END bigquery_copy_table]\n+\t// [END bigquery_copy_table_cmek]\n+\t// [END bigquery_copy_table_multiple_source]\n+\t// [END bigquery_create_dataset]\n+\t// [END bigquery_create_table]\n+\t// [END bigquery_create_table_clustered]\n+\t// [END bigquery_create_table_cmek]\n+\t// [END bigquery_create_table_partitioned]\n+\t// [END bigquery_delete_dataset]\n+\t// [END bigquery_delete_label_dataset]\n+\t// [END bigquery_delete_label_table]\n+\t// [END bigquery_delete_table]\n+\t// [END bigquery_extract_table]\n+\t// [END bigquery_extract_table_compressed]\n+\t// [END bigquery_extract_table_json]\n+\t// [END bigquery_get_dataset]\n+\t// [END bigquery_get_dataset_labels]\n+\t// [END bigquery_get_job]\n+\t// [END bigquery_get_table]\n+\t// [END bigquery_get_table_labels]\n+\t// [END bigquery_label_dataset]\n+\t// [END bigquery_label_table]\n+\t// [END bigquery_list_datasets]\n+\t// [END bigquery_list_datasets_by_label]\n+\t// [END bigquery_list_jobs]\n+\t// [END bigquery_list_tables]\n+\t// [END bigquery_load_from_file]\n+\t// [END bigquery_load_table_clustered]\n+\t// [END bigquery_load_table_gcs_csv]\n+\t// [END bigquery_load_table_gcs_json]\n+\t// [END bigquery_load_table_gcs_json_autodetect]\n+\t// [END bigquery_load_table_gcs_json_cmek]\n+\t// [END bigquery_load_table_gcs_orc]\n+\t// [END bigquery_load_table_gcs_orc_truncate]\n+\t// [END bigquery_load_table_gcs_parquet]\n+\t// [END bigquery_load_table_gcs_parquet_truncate]\n+\t// [END bigquery_load_table_partitioned]\n+\t// [END bigquery_nested_repeated_schema]\n+\t// [END bigquery_query]\n+\t// [END bigquery_query_batch]\n+\t// [END bigquery_query_clustered_table]\n+\t// [END bigquery_query_destination_table]\n+\t// [END bigquery_query_dry_run]\n+\t// [END bigquery_query_legacy]\n+\t// [END bigquery_query_legacy_large_results]\n+\t// [END bigquery_query_no_cache]\n+\t// [END bigquery_query_params_arrays]\n+\t// [END bigquery_query_params_named]\n+\t// [END bigquery_query_params_positional]\n+\t// [END bigquery_query_params_structs]\n+\t// [END bigquery_query_params_timestamps]\n+\t// [END bigquery_query_partitioned_table]\n+\t// [END bigquery_relax_column]\n+\t// [END bigquery_relax_column_load_append]\n+\t// [END bigquery_relax_column_query_append]\n+\t// [END bigquery_table_insert_rows]\n+\t// [END bigquery_undelete_table]\n+\t// [END bigquery_update_dataset_access]\n+\t// [END bigquery_update_table_cmek]\n+\t// [END bigquery_update_dataset_description]\n+\t// [END bigquery_update_dataset_expiration]\n+\t// [END bigquery_update_table_description]\n+\t// [END bigquery_update_table_expiration]\n+}\n+\n+func cancelJob(client *bigquery.Client, jobID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_cancel_job]\n+\tjob, err := client.JobFromID(ctx, jobID)\n+\tif err != nil {\n+\t\treturn nil\n+\t}\n+\treturn job.Cancel(ctx)\n+\t// [END bigquery_cancel_job]\n+}\n \n func createDataset(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -407,6 +453,197 @@\nfunc createTableExplicitSchema(client *bigquery.Client, datasetID, tableID strin\n \treturn nil\n }\n \n+func createTableComplexSchema(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_nested_repeated_schema]\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"id\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"first_name\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"last_name\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"dob\", Type: bigquery.DateFieldType},\n+\t\t{Name: \"addresses\",\n+\t\t\tType:     bigquery.RecordFieldType,\n+\t\t\tRepeated: true,\n+\t\t\tSchema: bigquery.Schema{\n+\t\t\t\t{Name: \"status\", Type: bigquery.StringFieldType},\n+\t\t\t\t{Name: \"address\", Type: bigquery.StringFieldType},\n+\t\t\t\t{Name: \"city\", Type: bigquery.StringFieldType},\n+\t\t\t\t{Name: \"state\", Type: bigquery.StringFieldType},\n+\t\t\t\t{Name: \"zip\", Type: bigquery.StringFieldType},\n+\t\t\t\t{Name: \"numberOfYears\", Type: bigquery.StringFieldType},\n+\t\t\t}},\n+\t}\n+\n+\tmetaData := &bigquery.TableMetadata{\n+\t\tSchema: sampleSchema,\n+\t}\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, metaData); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Printf(\"created table %s\\n\", tableRef.FullyQualifiedName())\n+\t// [END bigquery_nested_repeated_schema]\n+\treturn nil\n+}\n+\n+func createTableWithCMEK(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_create_table_cmek]\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tmeta := &bigquery.TableMetadata{\n+\t\tEncryptionConfig: &bigquery.EncryptionConfig{\n+\t\t\t// TODO: Replace this key with a key you have created in Cloud KMS.\n+\t\t\tKMSKeyName: \"projects/cloud-samples-tests/locations/us-central1/keyRings/test/cryptoKeys/test\",\n+\t\t},\n+\t}\n+\tif err := tableRef.Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_create_table_cmek]\n+\treturn nil\n+}\n+\n+func relaxTableAPI(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"full_name\", Type: bigquery.StringFieldType, Required: true},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType, Required: true},\n+\t}\n+\toriginal := &bigquery.TableMetadata{\n+\t\tSchema: sampleSchema,\n+\t}\n+\tif err := client.Dataset(datasetID).Table(tableID).Create(ctx, original); err != nil {\n+\t\treturn err\n+\t}\n+\t// [START bigquery_relax_column]\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tableRef.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Iterate through the schema to set all Required fields to false (nullable).\n+\tvar relaxed bigquery.Schema\n+\tfor _, v := range meta.Schema {\n+\t\tv.Required = false\n+\t\trelaxed = append(relaxed, v)\n+\t}\n+\tnewMeta := bigquery.TableMetadataToUpdate{\n+\t\tSchema: relaxed,\n+\t}\n+\tif _, err := tableRef.Update(ctx, newMeta, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END  bigquery_relax_column]\n+\treturn nil\n+}\n+\n+func relaxTableImport(client *bigquery.Client, datasetID, tableID, filename string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_relax_column_load_append]\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"full_name\", Type: bigquery.StringFieldType, Required: true},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType, Required: true},\n+\t}\n+\tmeta := &bigquery.TableMetadata{\n+\t\tSchema: sampleSchema,\n+\t}\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\t// Now, import data from a local file, but specify relaxation of required\n+\t// fields as a side effect while the data is appended.\n+\tf, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tsource := bigquery.NewReaderSource(f)\n+\tsource.AutoDetect = true   // Allow BigQuery to determine schema.\n+\tsource.SkipLeadingRows = 1 // CSV has a single header line.\n+\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(source)\n+\tloader.SchemaUpdateOptions = []string{\"ALLOW_FIELD_RELAXATION\"}\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END  bigquery_relax_column_load_append]\n+\treturn nil\n+}\n+\n+func relaxTableQuery(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_relax_column_query_append]\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"full_name\", Type: bigquery.StringFieldType, Required: true},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType, Required: true},\n+\t}\n+\tmeta := &bigquery.TableMetadata{\n+\t\tSchema: sampleSchema,\n+\t}\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\t// Now, append a query result that includes nulls, but allow the job to relax\n+\t// all required columns.\n+\tq := client.Query(\"SELECT \\\"Beyonce\\\" as full_name\")\n+\tq.QueryConfig.Dst = client.Dataset(datasetID).Table(tableID)\n+\tq.SchemaUpdateOptions = []string{\"ALLOW_FIELD_RELAXATION\"}\n+\tq.WriteDisposition = bigquery.WriteAppend\n+\tq.Location = \"US\"\n+\tjob, err := q.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t_, err = job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_relax_column_query_append]\n+\treturn nil\n+}\n+\n+func createTableAndWiden(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_add_column_query_append]\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"full_name\", Type: bigquery.StringFieldType, Required: true},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType, Required: true},\n+\t}\n+\toriginal := &bigquery.TableMetadata{\n+\t\tSchema: sampleSchema,\n+\t}\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, original); err != nil {\n+\t\treturn err\n+\t}\n+\t// Our table has two columns.  We'll introduce a new favorite_color column via\n+\t// a subsequent query that appends to the table.\n+\tq := client.Query(\"SELECT \\\"Timmy\\\" as full_name, 85 as age, \\\"Blue\\\" as favorite_color\")\n+\tq.SchemaUpdateOptions = []string{\"ALLOW_FIELD_ADDITION\"}\n+\tq.QueryConfig.Dst = client.Dataset(datasetID).Table(tableID)\n+\tq.WriteDisposition = bigquery.WriteAppend\n+\tq.Location = \"US\"\n+\tjob, err := q.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t_, err = job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_add_column_query_append]\n+\treturn nil\n+}\n+\n func createTablePartitioned(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_create_table_partitioned]",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -457,6 +694,48 @@\nfunc createTableClustered(client *bigquery.Client, datasetID, tableID string) er\n \treturn nil\n }\n \n+func updateTableAddColumn(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_add_empty_column]\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tableRef.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tnewSchema := append(meta.Schema,\n+\t\t&bigquery.FieldSchema{Name: \"phone\", Type: bigquery.StringFieldType},\n+\t)\n+\tupdate := bigquery.TableMetadataToUpdate{\n+\t\tSchema: newSchema,\n+\t}\n+\tif _, err := tableRef.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_add_empty_column]\n+\treturn nil\n+}\n+\n+func updateTableChangeCMEK(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_table_cmek]\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tableRef.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tupdate := bigquery.TableMetadataToUpdate{\n+\t\tEncryptionConfig: &bigquery.EncryptionConfig{\n+\t\t\t// TODO: Replace this key with a key you have created in Cloud KMS.\n+\t\t\tKMSKeyName: \"projects/cloud-samples-tests/locations/us-central1/keyRings/test/cryptoKeys/otherkey\",\n+\t\t},\n+\t}\n+\tif _, err := tableRef.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_table_cmek]\n+\treturn nil\n+}\n+\n func updateTableDescription(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_table_description]",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -696,6 +975,21 @@\nfunc queryWithDestination(client *bigquery.Client, destDatasetID, destTableID st\n \treturn runAndRead(ctx, client, q)\n }\n \n+func queryWithDestinationCMEK(client *bigquery.Client, destDatasetID, destTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_destination_table_cmek]\n+\tq := client.Query(\"SELECT 17 as my_col\")\n+\tq.Location = \"US\" // Location must match the dataset(s) referenced in query.\n+\tq.QueryConfig.Dst = client.Dataset(destDatasetID).Table(destTableID)\n+\tq.DestinationEncryptionConfig = &bigquery.EncryptionConfig{\n+\t\t// TODO: Replace this key with a key you have created in Cloud KMS.\n+\t\tKMSKeyName: \"projects/cloud-samples-tests/locations/us-central1/keyRings/test/cryptoKeys/test\",\n+\t}\n+\treturn runAndRead(ctx, client, q)\n+\t// [END bigquery_query_destination_table_cmek]\n+\n+}\n+\n func queryLegacy(client *bigquery.Client, sqlString string) error {\n \tctx := context.Background()\n \t// [START bigquery_query_legacy]",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -913,6 +1207,30 @@\nfunc copyTable(client *bigquery.Client, datasetID, srcID, dstID string) error {\n \treturn nil\n }\n \n+func copyTableWithCMEK(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_copy_table_cmek]\n+\tsrcTable := client.DatasetInProject(\"bigquery-public-data\", \"samples\").Table(\"shakespeare\")\n+\tcopier := client.Dataset(datasetID).Table(tableID).CopierFrom(srcTable)\n+\tcopier.DestinationEncryptionConfig = &bigquery.EncryptionConfig{\n+\t\t// TODO: Replace this key with a key you have created in Cloud KMS.\n+\t\tKMSKeyName: \"projects/cloud-samples-tests/locations/us-central1/keyRings/test/cryptoKeys/test\",\n+\t}\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_copy_table_cmek]\n+\treturn nil\n+}\n+\n // generateTableCTAS creates a quick table by issuing a CREATE TABLE AS SELECT\n // query.\n func generateTableCTAS(client *bigquery.Client, datasetID, tableID string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1027,6 +1345,30 @@\nfunc deleteAndUndeleteTable(client *bigquery.Client, datasetID, tableID string)\n \n }\n \n+func getJobInfo(client *bigquery.Client, jobID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_job]\n+\tjob, err := client.JobFromID(ctx, jobID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tstatus := job.LastStatus()\n+\tstate := \"Unknown\"\n+\tswitch status.State {\n+\tcase bigquery.Pending:\n+\t\tstate = \"Pending\"\n+\tcase bigquery.Running:\n+\t\tstate = \"Running\"\n+\tcase bigquery.Done:\n+\t\tstate = \"Done\"\n+\t}\n+\tfmt.Printf(\"Job %s was created %v and is in state %s\\n\",\n+\t\tjobID, status.Statistics.CreationTime, state)\n+\t// [END bigquery_get_job]\n+\treturn nil\n+}\n+\n func importCSVFromFile(client *bigquery.Client, datasetID, tableID, filename string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_from_file]",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1136,6 +1478,134 @@\nfunc importJSONAutodetectSchema(client *bigquery.Client, datasetID, tableID stri\n \treturn nil\n }\n \n+func importJSONWithCMEK(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_json_cmek]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.json\")\n+\tgcsRef.SourceFormat = bigquery.JSON\n+\tgcsRef.AutoDetect = true\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\tloader.WriteDisposition = bigquery.WriteEmpty\n+\tloader.DestinationEncryptionConfig = &bigquery.EncryptionConfig{\n+\t\t// TODO: Replace this key with a key you have created in KMS.\n+\t\tKMSKeyName: \"projects/cloud-samples-tests/locations/us-central1/keyRings/test/cryptoKeys/test\",\n+\t}\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\n+\t// [END bigquery_load_table_gcs_json_cmek]\n+\treturn nil\n+}\n+\n+func importORC(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_orc]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.orc\")\n+\tgcsRef.SourceFormat = bigquery.ORC\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_orc]\n+\treturn nil\n+}\n+\n+func importORCTruncate(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_orc_truncate]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.orc\")\n+\tgcsRef.SourceFormat = bigquery.ORC\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\t// Default for import jobs is to append data to a table.  WriteTruncate\n+\t// specifies that existing data should instead be replaced/overwritten.\n+\tloader.WriteDisposition = bigquery.WriteTruncate\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_orc_truncate]\n+\treturn nil\n+}\n+\n+func importParquet(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_parquet]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.parquet\")\n+\tgcsRef.SourceFormat = bigquery.Parquet\n+\tgcsRef.AutoDetect = true\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_parquet]\n+\treturn nil\n+}\n+\n+func importParquetTruncate(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_parquet_truncate]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.parquet\")\n+\tgcsRef.SourceFormat = bigquery.Parquet\n+\tgcsRef.AutoDetect = true\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\tloader.WriteDisposition = bigquery.WriteTruncate\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_parquet_truncate]\n+\treturn nil\n+}\n+\n func importPartitionedSampleTable(client *bigquery.Client, destDatasetID, destTableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_table_partitioned]",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1304,6 +1774,7 @@\nfunc exportSampleTableAsJSON(client *bigquery.Client, gcsURI string) error {\n func runAndRead(ctx context.Context, client *bigquery.Client, q *bigquery.Query) error {\n \t// [START bigquery_query]\n \t// [START bigquery_query_destination_table]\n+\t// [START bigquery_query_destination_table_cmek]\n \t// [START bigquery_query_legacy]\n \t// [START bigquery_query_legacy_large_results]\n \t// [START bigquery_query_no_cache]",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -118,13 +118,35 @@\nfunc TestAll(t *testing.T) {\n \tif err := createTableExplicitSchema(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"createTableExplicitSchema(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n+\tcomplex := uniqueBQName(\"golang_example_table_complex\")\n+\tif err := createTableComplexSchema(client, datasetID, complex); err != nil {\n+\t\tt.Errorf(\"createTableComplexSchema(dataset:%q table:%q): %v\", datasetID, complex, err)\n+\t}\n+\n+\ttableCMEK := uniqueBQName(\"golang_example_table_cmek\")\n+\tif err := createTableWithCMEK(client, datasetID, tableCMEK); err != nil {\n+\t\tt.Errorf(\"createTableWithCMEK(dataset:%q table:%q): %v\", datasetID, tableCMEK, err)\n+\t}\n+\n+\trequired := uniqueBQName(\"golang_example_table_required\")\n+\tif err := relaxTableAPI(client, datasetID, required); err != nil {\n+\t\tt.Errorf(\"relaxTableApi(dataset:%q table:%q): %v\", datasetID, required, err)\n+\t}\n+\n+\twiden := uniqueBQName(\"golang_example_table_widen\")\n+\tif err := createTableAndWiden(client, datasetID, widen); err != nil {\n+\t\tt.Errorf(\"createTableAndWiden(dataset:%q table:%q): %v\", datasetID, widen, err)\n+\t}\n \n \tif err := updateTableDescription(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"updateTableDescription(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n \tif err := updateTableExpiration(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"updateTableExpiration(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n+\tif err := updateTableAddColumn(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"updateTableAddColumn(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\t}\n \tif err := addTableLabel(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"updateTableAddLabel(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -198,6 +220,23 @@\nfunc TestAll(t *testing.T) {\n \tif err := queryWithDestination(client, datasetID, persisted); err != nil {\n \t\tt.Errorf(\"queryWithDestination(dataset:%q table:%q): %v\", datasetID, persisted, err)\n \t}\n+\tpersistedCMEK := uniqueBQName(\"golang_example_table_queryresult_cmek\")\n+\tif err := queryWithDestinationCMEK(client, datasetID, persistedCMEK); err != nil {\n+\t\tt.Errorf(\"queryWithDestinationCMEK(dataset:%q table:%q): %v\", datasetID, persistedCMEK, err)\n+\t}\n+\n+\t// Control a job lifecycle explicitly: create, report status, cancel.\n+\texampleJobID := uniqueBQName(\"golang_example_job\")\n+\tq := client.Query(\"Select 17 as foo\")\n+\tq.JobID = exampleJobID\n+\tq.Priority = bigquery.BatchPriority\n+\tq.Run(ctx)\n+\tif err := getJobInfo(client, exampleJobID); err != nil {\n+\t\tt.Errorf(\"getJobInfo(%s): %v\", exampleJobID, err)\n+\t}\n+\tif err := cancelJob(client, exampleJobID); err != nil {\n+\t\tt.Errorf(\"cancelJobInfo(%s): %v\", exampleJobID, err)\n+\t}\n \n \t// Print information about tables (extended and simple).\n \tif err := printTableInfo(client, datasetID, inferred); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -222,6 +261,10 @@\nfunc TestAll(t *testing.T) {\n \tif err := copyMultiTable(client, datasetID, dstTableID); err != nil {\n \t\tt.Errorf(\"copyMultiTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n \t}\n+\tdstTableID = uniqueBQName(\"golang_example_copycmek\")\n+\tif err := copyTableWithCMEK(client, datasetID, dstTableID); err != nil {\n+\t\tt.Errorf(\"copyTableWithCMEK(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n+\t}\n \n \tif err := listJobs(client); err != nil {\n \t\tt.Errorf(\"listJobs: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/appidentity/appidentity.go",
        "code_diff": "@@ -4,7 +4,7 @@\npackage sample\n \n-// [START asserting_identity_to_Google_APIs]\n+// [START gae_go_app_identity]\n import (\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -14,7 +14,7 @@\nimport (\n )\n \n func sampleHandler(w http.ResponseWriter, r *http.Request) {\n-\t// [START uploading_a_blob_2]\n+\t// [START gae_blobstore_upload_form]\n \tvar rootTemplate = template.Must(template.New(\"root\").Parse(rootTemplateHTML))\n \n \tconst rootTemplateHTML = `",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -24,16 +24,16 @@\nUpload File: <input type=\"file\" name=\"file\"><br>\n <input type=\"submit\" name=\"submit\" value=\"Submit\">\n </form></body></html>\n `\n-\t// [END uploading_a_blob_2]\n+\t// [END gae_blobstore_upload_form]\n \n-\t// [START uploading_a_blob_1]\n+\t// [START gae_blobstore_upload_url]\n \tctx := appengine.NewContext(r)\n \tuploadURL, err := blobstore.UploadURL(ctx, \"/upload\", nil)\n \tif err != nil {\n \t\tserveError(ctx, w, err)\n \t\treturn\n \t}\n-\t// [END uploading_a_blob_1]\n+\t// [END gae_blobstore_upload_url]\n \n \tw.Header().Set(\"Content-Type\", \"text/html\")\n \terr = rootTemplate.Execute(w, uploadURL)",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -43,7 +43,7 @@\nUpload File: <input type=\"file\" name=\"file\"><br>\n }\n \n func sampleHandler2(w http.ResponseWriter, r *http.Request) {\n-\t// [START uploading_a_blob_3]\n+\t// [START gae_blobstore_upload_handler]\n \tctx := appengine.NewContext(r)\n \tblobs, _, err := blobstore.ParseUpload(r)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -57,16 +57,15 @@\nfunc sampleHandler2(w http.ResponseWriter, r *http.Request) {\n \t\treturn\n \t}\n \thttp.Redirect(w, r, \"/serve/?blobKey=\"+string(file[0].BlobKey), http.StatusFound)\n-\t// [END uploading_a_blob_3]\n+\t// [END gae_blobstore_upload_handler]\n \n-\t// [START serving_a_blob]\n+\t// [START gae_blobstore_serving]\n \tblobstore.Send(w, appengine.BlobKey(r.FormValue(\"blobKey\")))\n-\t// [END serving_a_blob]\n+\t// [END gae_blobstore_serving]\n }\n \n /* Requires old package (import \"appengine/blobstore\")\n \n-// [START writing_files_to_the_Blobstore]\n var k appengine.BlobKey\n bw, err := blobstore.Create(ctx, \"application/octet-stream\")\n if err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/blobstore/complete.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START complete_sample_application]\n+// [START gae_blobstore_sample]\n \n package blobstore_example",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/capabilities/capability.go",
        "code_diff": "@@ -13,7 +13,7 @@\nimport (\n \t\"google.golang.org/appengine/capability\"\n )\n \n-// [START datastore_lookup]\n+// [START gae_go_capabilities_lookup]\n func handler(w http.ResponseWriter, r *http.Request) {\n \tctx := appengine.NewContext(r)\n \tif !capability.Enabled(ctx, \"datastore_v3\", \"*\") {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -18,7 +18,7 @@\nimport (\n var maxHeight int\n var minBirthYear, maxBirthYear int\n \n-// [START interface]\n+// [START gae_go_datastore_interface]\n type Person struct {\n \tFirstName string\n \tLastName  string",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -45,48 +45,48 @@\nfunc handle(w http.ResponseWriter, r *http.Request) {\n \t// ...\n }\n \n-// [END interface]\n+// [END gae_go_datastore_interface]\n \n func example() {\n \tvar lastSeenKey *datastore.Key\n \n-\t// [START key_filter_example]\n+\t// [START gae_go_datastore_key_filter]\n \tq := datastore.NewQuery(\"Person\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END key_filter_example]\n+\t// [END gae_go_datastore_key_filter]\n \t_ = q\n }\n \n func example2() {\n-\t// [START property_filter_example]\n+\t// [START gae_go_datastore_property_filter]\n \tq := datastore.NewQuery(\"Person\").Filter(\"Height <=\", maxHeight)\n-\t// [END property_filter_example]\n+\t// [END gae_go_datastore_property_filter]\n \t_ = q\n }\n \n func example3() {\n \tvar ancestorKey *datastore.Key\n \n-\t// [START ancestor_filter_example]\n+\t// [START gae_go_datastore_ancestor_filter]\n \tq := datastore.NewQuery(\"Person\").Ancestor(ancestorKey)\n-\t// [END ancestor_filter_example]\n+\t// [END gae_go_datastore_ancestor_filter]\n \t_ = q\n }\n \n func example4() {\n-\t// [START sort_order_example]\n+\t// [START gae_go_datastore_sort_order]\n \t// Order alphabetically by last name:\n \tq := datastore.NewQuery(\"Person\").Order(\"LastName\")\n \n \t// Order by height, tallest to shortest:\n \tq = datastore.NewQuery(\"Person\").Order(\"-Height\")\n-\t// [END sort_order_example]\n+\t// [END gae_go_datastore_sort_order]\n \t_ = q\n }\n \n func example5() {\n-\t// [START multiple_sort_orders_example]\n+\t// [START gae_go_datastore_multiple_sort_orders]\n \tq := datastore.NewQuery(\"Person\").Order(\"LastName\").Order(\"-Height\")\n-\t// [END multiple_sort_orders_example]\n+\t// [END gae_go_datastore_multiple_sort_orders]\n \t_ = q\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -96,7 +96,7 @@\nfunc example6() {\n \t}\n \tvar ctx context.Context\n \n-\t// [START ancestor_query_example]\n+\t// [START gae_go_datastore_ancestor_query]\n \t// Create two Photo entities in the datastore with a Person as their ancestor.\n \ttomKey := datastore.NewKey(ctx, \"Person\", \"Tom\", 0, nil)",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -117,101 +117,101 @@\nfunc example6() {\n \t_, err = q.GetAll(ctx, &photos)\n \t// check err\n \t// do something with photos\n-\t// [END ancestor_query_example]\n+\t// [END gae_go_datastore_ancestor_query]\n \t_ = err\n \t_ = photos\n }\n \n func example7() {\n-\t// [START keys_only_example]\n+\t// [START gae_go_datastore_keys_only]\n \tq := datastore.NewQuery(\"Person\").KeysOnly()\n-\t// [END keys_only_example]\n+\t// [END gae_go_datastore_keys_only]\n \t_ = q\n }\n \n func example8() {\n-\t// [START inequality_filters_one_property_valid_example_1]\n+\t// [START gae_go_datastore_inequality_filters_one_property_valid_1]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"BirthYear <=\", maxBirthYear)\n-\t// [END inequality_filters_one_property_valid_example_1]\n+\t// [END gae_go_datastore_inequality_filters_one_property_valid_1]\n \t_ = q\n }\n \n func example9() {\n-\t// [START inequality_filters_one_property_invalid_example]\n+\t// [START gae_go_datastore_inequality_filters_one_property_invalid]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"Height <=\", maxHeight) // ERROR\n-\t// [END inequality_filters_one_property_invalid_example]\n+\t// [END gae_go_datastore_inequality_filters_one_property_invalid]\n \t_ = q\n }\n \n func example10() {\n \tvar targetLastName, targetCity string\n \n-\t// [START inequality_filters_one_property_valid_example_2]\n+\t// [START gae_go_datastore_inequality_filters_one_property_valid_2]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"LastName =\", targetLastName).\n \t\tFilter(\"City =\", targetCity).\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"BirthYear <=\", maxBirthYear)\n-\t// [END inequality_filters_one_property_valid_example_2]\n+\t// [END gae_go_datastore_inequality_filters_one_property_valid_2]\n \t_ = q\n }\n \n func example11() {\n-\t// [START inequality_filters_sort_orders_valid_example]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_valid]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"BirthYear\").\n \t\tOrder(\"LastName\")\n-\t// [END inequality_filters_sort_orders_valid_example]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_valid]\n \t_ = q\n }\n \n func example12() {\n-\t// [START inequality_filters_sort_orders_invalid_example_1]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_invalid_1]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"LastName\") // ERROR\n-\t// [END inequality_filters_sort_orders_invalid_example_1]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_invalid_1]\n \t_ = q\n }\n \n func example13() {\n-\t// [START inequality_filters_sort_orders_invalid_example_2]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_invalid_2]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"LastName\").\n \t\tOrder(\"BirthYear\") // ERROR\n-\t// [END inequality_filters_sort_orders_invalid_example_2]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_invalid_2]\n \t_ = q\n }\n \n func example14() {\n-\t// [START surprising_behavior_example_1]\n+\t// [START gae_go_datastore_surprising_behavior_1]\n \tq := datastore.NewQuery(\"Widget\").\n \t\tFilter(\"x >\", 1).\n \t\tFilter(\"x <\", 2)\n-\t// [END surprising_behavior_example_1]\n+\t// [END gae_go_datastore_surprising_behavior_1]\n \t_ = q\n }\n \n func example15() {\n-\t// [START surprising_behavior_example_2]\n+\t// [START gae_go_datastore_surprising_behavior_2]\n \tq := datastore.NewQuery(\"Widget\").\n \t\tFilter(\"x =\", 1).\n \t\tFilter(\"x =\", 2)\n-\t// [END surprising_behavior_example_2]\n+\t// [END gae_go_datastore_surprising_behavior_2]\n \t_ = q\n }\n \n func doSomething(k *datastore.Key, p Person) {}\n \n func example16() {\n \tvar ctx context.Context\n-\t// [START retrieval_example]\n+\t// [START gae_go_datastore_retrieval]\n \tq := datastore.NewQuery(\"Person\")\n \tt := q.Run(ctx)\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -227,13 +227,13 @@\nfunc example16() {\n \t\t// Do something with Person p and Key k\n \t\tdoSomething(k, p)\n \t}\n-\t// [END retrieval_example]\n+\t// [END gae_go_datastore_retrieval]\n }\n \n func example17() {\n \tvar ctx context.Context\n \n-\t// [START all_entities_retrieval_example]\n+\t// [START gae_go_datastore_all_entities_retrieval]\n \tq := datastore.NewQuery(\"Person\")\n \tvar people []Person\n \tkeys, err := q.GetAll(ctx, &people)",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -246,13 +246,13 @@\nfunc example17() {\n \t\t// Do something with Person p and Key k\n \t\tdoSomething(k, p)\n \t}\n-\t// [END all_entities_retrieval_example]\n+\t// [END gae_go_datastore_all_entities_retrieval]\n }\n \n func example18() {\n \tvar ctx context.Context\n \n-\t// [START query_limit_example]\n+\t// [START gae_go_datastore_query_limit]\n \tq := datastore.NewQuery(\"Person\").Order(\"-Height\").Limit(5)\n \tvar people []Person\n \t_, err := q.GetAll(ctx, &people)",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -261,21 +261,19 @@\nfunc example18() {\n \tfor _, p := range people {\n \t\tlog.Infof(ctx, \"%s %s, %d inches tall\", p.FirstName, p.LastName, p.Height)\n \t}\n-\t// [END query_limit_example]\n+\t// [END gae_go_datastore_query_limit]\n \t_ = err\n }\n \n func example19() {\n-\t// [START query_offset_example]\n \tq := datastore.NewQuery(\"Person\").Order(\"-Height\").Limit(5).Offset(5)\n-\t// [END query_offset_example]\n \t_ = q\n }\n \n func example20() {\n \tvar ctx context.Context\n \n-\t// [START cursors]\n+\t// [START gae_go_datastore_cursors]\n \t// Create a query for all Person entities.\n \tq := datastore.NewQuery(\"Person\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -310,24 +308,24 @@\nfunc example20() {\n \t\t\tValue: []byte(cursor.String()),\n \t\t})\n \t}\n-\t// [END cursors]\n+\t// [END gae_go_datastore_cursors]\n }\n \n func example21() {\n \tvar lastSeenKey *datastore.Key\n \n-\t// [START kindless_query_example]\n+\t// [START gae_go_datastore_kindless_query]\n \tq := datastore.NewQuery(\"\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_query_example]\n+\t// [END gae_go_datastore_kindless_query]\n \t_ = q\n }\n \n func example22() {\n \tvar ancestorKey, lastSeenKey *datastore.Key\n \n-\t// [START kindless_ancestor_key_query_example]\n+\t// [START gae_go_datastore_kindless_ancestor_key_query]\n \tq := datastore.NewQuery(\"\").Ancestor(ancestorKey).Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_ancestor_key_query_example]\n+\t// [END gae_go_datastore_kindless_ancestor_key_query]\n \t_ = q\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -339,7 +337,7 @@\nfunc example23() {\n \tvar ctx context.Context\n \tdoSomething := func(x interface{}) {}\n \n-\t// [START kindless_ancestor_query_example]\n+\t// [START gae_go_datastore_kindless_ancestor_query]\n \ttomKey := datastore.NewKey(ctx, \"Person\", \"Tom\", 0, nil)\n \n \tweddingPhoto := &Photo{URL: \"http://example.com/some/path/to/wedding_photo.jpg\"}",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/logs/logs.go",
        "code_diff": "@@ -2,8 +2,6 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START sample_code]\n-\n // This sample gets the app displays 5 log Records at a time, including all\n // AppLogs, with a Next link to let the user page through the results using the\n // Record's Offset property.",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "docs/appengine/logs/writing_logs.go",
        "code_diff": "@@ -4,7 +4,7 @@\npackage app\n \n-// [START sample]\n+// [START gae_writing_logs]\n import (\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into pubsub",
        "commit_id": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -62,6 +62,8 @@\nfunc usage(msg string) {\n \tos.Exit(2)\n }\n \n+// [START language_entities_text]\n+\n func analyzeEntities(ctx context.Context, client *language.Client, text string) (*languagepb.AnalyzeEntitiesResponse, error) {\n \treturn client.AnalyzeEntities(ctx, &languagepb.AnalyzeEntitiesRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-fixes",
        "commit_id": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -74,6 +76,10 @@\nfunc analyzeEntities(ctx context.Context, client *language.Client, text string)\n \t})\n }\n \n+// [END language_entities_text]\n+\n+// [START language_sentiment_text]\n+\n func analyzeSentiment(ctx context.Context, client *language.Client, text string) (*languagepb.AnalyzeSentimentResponse, error) {\n \treturn client.AnalyzeSentiment(ctx, &languagepb.AnalyzeSentimentRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-fixes",
        "commit_id": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -85,6 +91,10 @@\nfunc analyzeSentiment(ctx context.Context, client *language.Client, text string)\n \t})\n }\n \n+// [END language_sentiment_text]\n+\n+// [START language_syntax_text]\n+\n func analyzeSyntax(ctx context.Context, client *language.Client, text string) (*languagepb.AnnotateTextResponse, error) {\n \treturn client.AnnotateText(ctx, &languagepb.AnnotateTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-fixes",
        "commit_id": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -100,6 +110,10 @@\nfunc analyzeSyntax(ctx context.Context, client *language.Client, text string) (*\n \t})\n }\n \n+// [END language_syntax_text]\n+\n+// [START language_classify_text]\n+\n func classifyText(ctx context.Context, client *language.Client, text string) (*languagepb.ClassifyTextResponse, error) {\n \treturn client.ClassifyText(ctx, &languagepb.ClassifyTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-fixes",
        "commit_id": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "language/analyze/entity_sentiment.go",
        "code_diff": "@@ -22,6 +22,8 @@\nfunc betaClient() *language.Client {\n \treturn client\n }\n \n+// [START language_entity_sentiment_text]\n+\n func analyzeEntitySentiment(ctx context.Context, client *language.Client, text string) (*languagepb.AnalyzeEntitySentimentResponse, error) {\n \treturn client.AnalyzeEntitySentiment(ctx, &languagepb.AnalyzeEntitySentimentRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-fixes",
        "commit_id": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -15,6 +15,8 @@\nimport (\n // to avoid it being included in the function signature below.\n var client *language.Client\n \n+// [START language_entities_file_gcs]\n+\n func analyzeEntitiesFromGCS(ctx context.Context, gcsURI string) (*languagepb.AnalyzeEntitiesResponse, error) {\n \treturn client.AnalyzeEntities(ctx, &languagepb.AnalyzeEntitiesRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-fixes",
        "commit_id": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -27,6 +29,10 @@\nfunc analyzeEntitiesFromGCS(ctx context.Context, gcsURI string) (*languagepb.Ana\n \t})\n }\n \n+// [END language_entities_file_gcs]\n+\n+// [START language_sentiment_file_gcs]\n+\n func analyzeSentimentFromGCS(ctx context.Context, gcsURI string) (*languagepb.AnalyzeSentimentResponse, error) {\n \treturn client.AnalyzeSentiment(ctx, &languagepb.AnalyzeSentimentRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-fixes",
        "commit_id": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -38,6 +44,10 @@\nfunc analyzeSentimentFromGCS(ctx context.Context, gcsURI string) (*languagepb.An\n \t})\n }\n \n+// [END language_sentiment_file_gcs]\n+\n+// [START language_syntax_file_gcs]\n+\n func analyzeSyntaxFromGCS(ctx context.Context, gcsURI string) (*languagepb.AnnotateTextResponse, error) {\n \treturn client.AnnotateText(ctx, &languagepb.AnnotateTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-fixes",
        "commit_id": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -53,6 +63,10 @@\nfunc analyzeSyntaxFromGCS(ctx context.Context, gcsURI string) (*languagepb.Annot\n \t})\n }\n \n+// [END language_syntax_file_gcs]\n+\n+// [START language_classify_file_gcs]\n+\n func classifyTextFromGCS(ctx context.Context, gcsURI string) (*languagepb.ClassifyTextResponse, error) {\n \treturn client.ClassifyText(ctx, &languagepb.ClassifyTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-fixes",
        "commit_id": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "appengine_flexible/pubsub/pubsub.go",
        "code_diff": "@@ -6,6 +6,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"encoding/json\"\n \t\"fmt\"\n \t\"html/template\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "appengine_flexible/storage/storage.go",
        "code_diff": "@@ -8,6 +8,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"log\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -6,6 +6,7 @@\npackage snippets\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"fmt\"\n \t\"regexp\"\n \t\"strings\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "bigtable/search/search.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage main\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"flag\"\n \t\"fmt\"\n \t\"html/template\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "bigtable/search/search.go",
        "code_diff": "@@ -30,7 +31,6 @@\nimport (\n \t\"unicode\"\n \n \t\"cloud.google.com/go/bigtable\"\n-\t\"golang.org/x/net/context\"\n )\n \n var (",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "bigtable/search/search.go",
        "code_diff": "@@ -149,7 +149,8 @@\nfunc tokenize(s string) []string {\n \n // handleContent fetches the content of a document from the Bigtable and returns it.\n func handleContent(w http.ResponseWriter, r *http.Request, table *bigtable.Table) {\n-\tctx, _ := context.WithTimeout(context.Background(), 10*time.Second)\n+\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n+\tdefer cancel()\n \tname := r.FormValue(\"name\")\n \tif len(name) == 0 {\n \t\thttp.Error(w, \"No document name supplied.\", http.StatusBadRequest)",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "bigtable/search/search.go",
        "code_diff": "@@ -176,7 +177,8 @@\nfunc handleContent(w http.ResponseWriter, r *http.Request, table *bigtable.Table\n \n // handleSearch responds to search queries, returning links and snippets for matching documents.\n func handleSearch(w http.ResponseWriter, r *http.Request, table *bigtable.Table) {\n-\tctx, _ := context.WithTimeout(context.Background(), 10*time.Second)\n+\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n+\tdefer cancel()\n \tquery := r.FormValue(\"q\")\n \t// Split the query into words.\n \twords := tokenize(query)",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "bigtable/search/search.go",
        "code_diff": "@@ -269,7 +271,8 @@\nfunc handleAddDoc(w http.ResponseWriter, r *http.Request, table *bigtable.Table)\n \t\treturn\n \t}\n \n-\tctx, _ := context.WithTimeout(context.Background(), time.Minute)\n+\tctx, cancel := context.WithTimeout(context.Background(), time.Minute)\n+\tdefer cancel()\n \n \tname := r.FormValue(\"name\")\n \tif len(name) == 0 {",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "bigtable/search/search.go",
        "code_diff": "@@ -345,7 +348,9 @@\nfunc handleReset(w http.ResponseWriter, r *http.Request, table string, adminClie\n \t\thttp.Error(w, \"POST requests only\", http.StatusMethodNotAllowed)\n \t\treturn\n \t}\n-\tctx, _ := context.WithTimeout(context.Background(), 5*time.Minute)\n+\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)\n+\tdefer cancel()\n+\n \tadminClient.DeleteTable(ctx, table)\n \tif err := adminClient.CreateTable(ctx, table); err != nil {\n \t\thttp.Error(w, \"Error creating Bigtable: \"+err.Error(), http.StatusInternalServerError)",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "container_registry/container_analysis/src/sample/samples.go",
        "code_diff": "@@ -6,13 +6,13 @@\npackage sample\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"sync\"\n \t\"time\"\n \n \tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n \tpubsub \"cloud.google.com/go/pubsub\"\n-\t\"golang.org/x/net/context\"\n \t\"google.golang.org/api/iterator\"\n \tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n \t\"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/vulnerability\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "container_registry/container_analysis/src/sample/samples_test.go",
        "code_diff": "@@ -5,6 +5,7 @@\npackage sample\n \n import (\n+\t\"context\"\n \t\"math/rand\"\n \t\"strconv\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -8,6 +8,7 @@\npackage main\n \n import (\n \t\"bufio\"\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"log\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "docs/appengine/firebase/tictactoe/firebase.go",
        "code_diff": "@@ -5,6 +5,7 @@\npackage tictactoe\n \n import (\n+\t\"context\"\n \t\"encoding/base64\"\n \t\"encoding/json\"\n \t\"errors\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "getting-started/bookshelf/app/app.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"encoding/json\"\n \t\"errors\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "getting-started/bookshelf/config.go",
        "code_diff": "@@ -5,6 +5,7 @@\npackage bookshelf\n \n import (\n+\t\"context\"\n \t\"errors\"\n \t\"log\"\n \t\"os\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "getting-started/bookshelf/db_test.go",
        "code_diff": "@@ -5,6 +5,7 @@\npackage bookshelf\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"os\"\n \t\"strconv\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "getting-started/bookshelf/pubsub_worker/worker.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"encoding/json\"\n \t\"fmt\"\n \t\"log\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "internal/aeintegrate/aeintegrate.go",
        "code_diff": "@@ -34,6 +34,7 @@\npackage aeintegrate\n \n import (\n+\t\"context\"\n \t\"errors\"\n \t\"fmt\"\n \t\"io/ioutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "internal/cleanaeversions/cleanaeversions.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"flag\"\n \t\"fmt\"\n \t\"log\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "internal/e2e/flexible_test.go",
        "code_diff": "@@ -11,6 +11,7 @@\npackage e2e\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"mime/multipart\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -6,6 +6,7 @@\npackage samples\n \n import (\n+\t\"context\"\n \t\"crypto\"\n \t\"crypto/ecdsa\"\n \t\"crypto/rand\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -8,6 +8,7 @@\npackage main\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"encoding/json\"\n \t\"flag\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "monitoring/custommetric/custommetric_test.go",
        "code_diff": "@@ -5,14 +5,13 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"os\"\n \t\"testing\"\n \t\"time\"\n \n-\t\"golang.org/x/net/context\"\n-\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "monitoring/listresources/listresources_test.go",
        "code_diff": "@@ -5,14 +5,13 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"os\"\n \t\"testing\"\n \t\"time\"\n \n-\t\"golang.org/x/net/context\"\n-\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"errors\"\n \t\"fmt\"\n \t\"log\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "spanner/spanner_arrays/main.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"flag\"\n \t\"fmt\"\n \t\"log\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -6,6 +6,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"flag\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -17,7 +18,6 @@\nimport (\n \n \t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n-\t\"golang.org/x/net/context\"\n \t\"google.golang.org/api/iterator\"\n \n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "speech/caption/caption.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"flag\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "speech/livecaption_from_file/livecaption_from_file.go",
        "code_diff": "@@ -8,6 +8,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"flag\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -5,6 +5,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"os\"\n \t\"testing\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "storage/gcsupload/gcsupload.go",
        "code_diff": "@@ -25,6 +25,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"flag\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -9,6 +9,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"flag\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -6,6 +6,7 @@\npackage main\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"fmt\"\n \t\"log\"\n \t\"os\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "videointelligence/video_analyze/gen/template.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "getting-started/devflowapp: initial commit",
        "pr_number": 579,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -5,6 +5,7 @@\npackage main\n \n import (\n+\t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into basicapp",
        "commit_id": "fac656d141a32c40ab9be7ea0859993e8803caf0"
    },
    {
        "pr_title": "kms: add Asymmetric Keys samples",
        "pr_number": 563,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -80,7 +80,7 @@\nfunc list(client *pubsub.Client) ([]*pubsub.Subscription, error) {\n \treturn subs, nil\n }\n \n-func pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n+func pullMsgs(client *pubsub.Client, subName string, topic *pubsub.Topic) error {\n \tctx := context.Background()\n \n \t// Publish 10 messages on the topic.",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-asymmetric",
        "commit_id": "1929212897f7c66d9ba58f6b8802fc2d46ff3e48"
    },
    {
        "pr_title": "kms: add Asymmetric Keys samples",
        "pr_number": 563,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -105,7 +105,7 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \t// Consume 10 messages.\n \tvar mu sync.Mutex\n \treceived := 0\n-\tsub := client.Subscription(name)\n+\tsub := client.Subscription(subName)\n \tcctx, cancel := context.WithCancel(ctx)\n \terr := sub.Receive(cctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\tmsg.Ack()",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-asymmetric",
        "commit_id": "1929212897f7c66d9ba58f6b8802fc2d46ff3e48"
    },
    {
        "pr_title": "kms: add Asymmetric Keys samples",
        "pr_number": 563,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -125,12 +125,12 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \treturn nil\n }\n \n-func pullMsgsError(client *pubsub.Client, name string) error {\n+func pullMsgsError(client *pubsub.Client, subName string) error {\n \tctx := context.Background()\n \t// [START pubsub_subscriber_error_listener]\n \t// If the service returns a non-retryable error, Receive returns that error after\n \t// all of the outstanding calls to the handler have returned.\n-\terr := client.Subscription(name).Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n+\terr := client.Subscription(subName).Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\tfmt.Printf(\"Got message: %q\\n\", string(msg.Data))\n \t\tmsg.Ack()\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-asymmetric",
        "commit_id": "1929212897f7c66d9ba58f6b8802fc2d46ff3e48"
    },
    {
        "pr_title": "kms: add Asymmetric Keys samples",
        "pr_number": 563,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -141,10 +141,10 @@\nfunc pullMsgsError(client *pubsub.Client, name string) error {\n \treturn nil\n }\n \n-func pullMsgsSettings(client *pubsub.Client, name string) error {\n+func pullMsgsSettings(client *pubsub.Client, subName string) error {\n \tctx := context.Background()\n \t// [START pubsub_subscriber_flow_settings]\n-\tsub := client.Subscription(name)\n+\tsub := client.Subscription(subName)\n \tsub.ReceiveSettings.MaxOutstandingMessages = 10\n \terr := sub.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\tfmt.Printf(\"Got message: %q\\n\", string(msg.Data))",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-asymmetric",
        "commit_id": "1929212897f7c66d9ba58f6b8802fc2d46ff3e48"
    },
    {
        "pr_title": "kms: add Asymmetric Keys samples",
        "pr_number": 563,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -157,10 +157,10 @@\nfunc pullMsgsSettings(client *pubsub.Client, name string) error {\n \treturn nil\n }\n \n-func create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n+func create(client *pubsub.Client, subName string, topic *pubsub.Topic) error {\n \tctx := context.Background()\n \t// [START pubsub_create_pull_subscription]\n-\tsub, err := client.CreateSubscription(ctx, name, pubsub.SubscriptionConfig{\n+\tsub, err := client.CreateSubscription(ctx, subName, pubsub.SubscriptionConfig{\n \t\tTopic:       topic,\n \t\tAckDeadline: 20 * time.Second,\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-asymmetric",
        "commit_id": "1929212897f7c66d9ba58f6b8802fc2d46ff3e48"
    },
    {
        "pr_title": "kms: add Asymmetric Keys samples",
        "pr_number": 563,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -172,12 +172,12 @@\nfunc create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \treturn nil\n }\n \n-func createWithEndpoint(client *pubsub.Client, name string, topic *pubsub.Topic, endpoint string) error {\n+func createWithEndpoint(client *pubsub.Client, subName string, topic *pubsub.Topic, endpoint string) error {\n \tctx := context.Background()\n \t// [START pubsub_create_push_subscription]\n \n \t// For example, endpoint is \"https://my-test-project.appspot.com/push\".\n-\tsub, err := client.CreateSubscription(ctx, name, pubsub.SubscriptionConfig{\n+\tsub, err := client.CreateSubscription(ctx, subName, pubsub.SubscriptionConfig{\n \t\tTopic:       topic,\n \t\tAckDeadline: 10 * time.Second,\n \t\tPushConfig:  pubsub.PushConfig{Endpoint: endpoint},",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-asymmetric",
        "commit_id": "1929212897f7c66d9ba58f6b8802fc2d46ff3e48"
    },
    {
        "pr_title": "kms: add Asymmetric Keys samples",
        "pr_number": 563,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -190,12 +190,12 @@\nfunc createWithEndpoint(client *pubsub.Client, name string, topic *pubsub.Topic,\n \treturn nil\n }\n \n-func updateEndpoint(client *pubsub.Client, name string, endpoint string) error {\n+func updateEndpoint(client *pubsub.Client, subName string, endpoint string) error {\n \tctx := context.Background()\n \t// [START pubsub_update_push_configuration]\n \n \t// For example, endpoint is \"https://my-test-project.appspot.com/push\".\n-\tsubConfig, err := client.Subscription(name).Update(ctx, pubsub.SubscriptionConfigToUpdate{\n+\tsubConfig, err := client.Subscription(subName).Update(ctx, pubsub.SubscriptionConfigToUpdate{\n \t\tPushConfig: &pubsub.PushConfig{Endpoint: endpoint},\n \t})\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into kms-asymmetric",
        "commit_id": "1929212897f7c66d9ba58f6b8802fc2d46ff3e48"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-1/main.go",
        "code_diff": "@@ -4,23 +4,23 @@\npackage main\n \n-// [START import_statements]\n+// [START gae_go_env_import]\n import (\n \t\"fmt\"\n \t\"net/http\"\n \n \t\"google.golang.org/appengine\" // Required external App Engine library\n )\n \n-// [END import_statements]\n-// [START main_func]\n+// [END gae_go_env_import]\n+// [START gae_go_env_main]\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)\n \tappengine.Main() // Starts the server to receive requests\n }\n \n-// [END main_func]\n-// [START indexHandler]\n+// [END gae_go_env_main]\n+// [START gae_go_env_index]\n func indexHandler(w http.ResponseWriter, r *http.Request) {\n \t// if statement redirects all invalid URLs to the root homepage.\n \t// Ex: if URL is http://[YOUR_PROJECT_ID].appspot.com/FOO, it will be",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-3/main.go",
        "code_diff": "@@ -5,28 +5,28 @@\npackage main\n \n import (\n-\t// [START import]\n+\t// [START gae_go_env_template_import]\n \t\"fmt\"\n \t\"html/template\"\n-\t// [END import]\n+\t// [END gae_go_env_template_import]\n \t\"net/http\"\n \n \t\"google.golang.org/appengine\"\n )\n \n-// [START templ_variable]\n+// [START gae_go_env_template_vars]\n var (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [END templ_variable]\n-// [START templ_params]\n+// [END gae_go_env_template_vars]\n+// [START gae_go_env_template_params]\n type templateParams struct {\n \tNotice string\n \tName   string\n }\n \n-// [END templ_params]\n+// [END gae_go_env_template_params]\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)\n \tappengine.Main()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-3/main.go",
        "code_diff": "@@ -37,7 +37,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\thttp.Redirect(w, r, \"/\", http.StatusFound)\n \t\treturn\n \t}\n-\t// [START handling]\n+\t// [START gae_go_env_handling]\n \tparams := templateParams{}\n \n \tif r.Method == \"GET\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -11,36 +11,36 @@\nimport (\n \n \t\"google.golang.org/appengine\"\n \n-\t// [START imports]\n+\t// [START gae_go_env_data_imports]\n \t\"time\"\n \n \t\"google.golang.org/appengine/datastore\"\n \t\"google.golang.org/appengine/log\"\n-\t// [END imports]\n+\t// [END gae_go_env_data_imports]\n )\n \n var (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [START post_struct]\n+// [START gae_go_env_post_struct]\n type Post struct {\n \tAuthor  string\n \tMessage string\n \tPosted  time.Time\n }\n \n-// [END post_struct]\n+// [END gae_go_env_post_struct]\n \n type templateParams struct {\n \tNotice string\n \n \tName string\n-\t// [START added_templateParams_fields]\n+\t// [START gae_go_env_template_params_fields]\n \tMessage string\n \n \tPosts []Post\n-\t// [END added_templateParams_fields]\n+\t// [END gae_go_env_template_params_fields]\n \n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -54,37 +54,37 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\thttp.Redirect(w, r, \"/\", http.StatusFound)\n \t\treturn\n \t}\n-\t// [START new_context]\n+\t// [START gae_go_env_new_context]\n \tctx := appengine.NewContext(r)\n-\t// [END new_context]\n+\t// [END gae_go_env_new_context]\n \tparams := templateParams{}\n \n-\t// [START new_query]\n+\t// [START gae_go_env_new_query]\n \tq := datastore.NewQuery(\"Post\").Order(\"-Posted\").Limit(20)\n-\t// [END new_query]\n-\t// [START get_posts]\n+\t// [END gae_go_env_new_query]\n+\t// [START gae_go_env_get_posts]\n \tif _, err := q.GetAll(ctx, &params.Posts); err != nil {\n \t\tlog.Errorf(ctx, \"Getting posts: %v\", err)\n \t\tw.WriteHeader(http.StatusInternalServerError)\n \t\tparams.Notice = \"Couldn't get latest posts. Refresh?\"\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n-\t// [END get_posts]\n+\t// [END gae_go_env_get_posts]\n \n \tif r.Method == \"GET\" {\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n \n \t// It's a POST request, so handle the form submission.\n-\t// [START new_post]\n+\t// [START gae_go_env_new_post]\n \tpost := Post{\n \t\tAuthor:  r.FormValue(\"name\"),\n \t\tMessage: r.FormValue(\"message\"),\n \t\tPosted:  time.Now(),\n \t}\n-\t// [END new_post]\n+\t// [END gae_go_env_new_post]\n \tif post.Author == \"\" {\n \t\tpost.Author = \"Anonymous Gopher\"\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -96,10 +96,10 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n-\t// [START new_key]\n+\t// [START gae_go_env_new_key]\n \tkey := datastore.NewIncompleteKey(ctx, \"Post\", nil)\n-\t// [END new_key]\n-\t// [START add_post]\n+\t// [END gae_go_env_new_key]\n+\t// [START gae_go_env_add_post]\n \tif _, err := datastore.Put(ctx, key, &post); err != nil {\n \t\tlog.Errorf(ctx, \"datastore.Put: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -10,16 +10,16 @@\nimport (\n \t\"net/http\"\n \t\"time\"\n \n-\t// [START imports]\n+\t// [START gae_go_env_firebase_imports]\n \tfirebase \"firebase.google.com/go\"\n-\t// [END imports]\n+\t// [END gae_go_env_firebase_imports]\n \n \t\"google.golang.org/appengine\"\n \t\"google.golang.org/appengine/datastore\"\n \t\"google.golang.org/appengine/log\"\n )\n \n-// [START new_variable]\n+// [START gae_go_env_new_variable]\n \n var (\n \tfirebaseConfig = &firebase.Config{",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -30,9 +30,9 @@\nvar (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [END new_variable]\n+// [END gae_go_env_new_variable]\n \n-// [START new_post_field]\n+// [START gae_go_env_new_post_field]\n \n type Post struct {\n \tAuthor  string",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -41,7 +41,7 @@\ntype Post struct {\n \tPosted  time.Time\n }\n \n-// [END new_post_field]\n+// [END gae_go_env_new_post_field]\n \n type templateParams struct {\n \tNotice  string",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -78,13 +78,14 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t}\n \t// It's a POST request, so handle the form submission.\n \n-\t// [START firebase_token]\n+\t// [START gae_go_env_firebase_token]\n \tmessage := r.FormValue(\"message\")\n \n \t// Create a new Firebase App.\n \tapp, err := firebase.NewApp(ctx, firebaseConfig)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"firebase.NewApp: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -93,6 +94,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \tauth, err := app.Auth(ctx)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"app.Auth: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -101,6 +103,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \ttok, err := auth.VerifyIDTokenAndCheckRevoked(ctx, r.FormValue(\"token\"))\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"auth.VerifyIDAndCheckRevoked: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-5/static/index.js",
        "code_diff": "@@ -3,7 +3,7 @@\nwindow.addEventListener('load', function () {\n     firebase.auth().signOut();\n   };\n \n-  // [START UIconfig_variable]\n+  // [START gae_go_env_ui_config]\n   // FirebaseUI config.\n   var uiConfig = {\n     signInSuccessUrl: '/',",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-5/static/index.js",
        "code_diff": "@@ -19,9 +19,9 @@\nwindow.addEventListener('load', function () {\n     // Terms of service url.\n     tosUrl: '<your-tos-url>'\n   };\n-  // [END UIconfig_variable]\n+  // [END gae_go_env_ui_config]\n \n-  // [START auth_request]\n+  // [START gae_go_env_auth_request]\n   firebase.auth().onAuthStateChanged(function (user) {\n     if (user) {\n       // User is signed in.",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -217,6 +217,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \tapp, err := firebase.NewApp(ctx, firebaseConfig)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"firebase.NewApp: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -225,6 +226,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \tauth, err := app.Auth(ctx)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"app.Auth: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -233,6 +235,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \ttok, err := auth.VerifyIDTokenAndCheckRevoked(ctx, r.FormValue(\"token\"))\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"auth.VerifyIDAndCheckRevoked: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/analytics/analytics.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_analytics_track_event]\n+\n // Sample analytics demonstrates Google Analytics calls from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/cloudsql/cloudsql.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_mysql_app]\n+\n // Sample cloudsql demonstrates usage of Cloud SQL from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/cloudsql_postgres/cloudsql.go",
        "code_diff": "@@ -4,6 +4,8 @@\n// +build go1.8\n \n+// [START gae_flex_postgres_app]\n+\n // Sample cloudsql demonstrates usage of Cloud SQL from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/datastore/datastore.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_datastore_app]\n+\n // Sample datastore demonstrates use of the cloud.google.com/go/datastore package from App Engine flexible.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/mailgun/mailgun.go",
        "code_diff": "@@ -16,11 +16,8 @@\nimport (\n \t\"google.golang.org/appengine\"\n )\n \n-// [START import]\n import \"github.com/mailgun/mailgun-go\"\n \n-// [END import]\n-\n func main() {\n \thttp.HandleFunc(\"/send_simple\", sendSimpleMessageHandler)\n \thttp.HandleFunc(\"/send_complex\", sendComplexMessageHandler)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/mailgun/mailgun.go",
        "code_diff": "@@ -49,6 +46,7 @@\nfunc mustGetenv(k string) string {\n \treturn v\n }\n \n+// [START gae_flex_mailgun_simple_message]\n func sendSimpleMessageHandler(w http.ResponseWriter, r *http.Request) {\n \tmsg, id, err := mailgunClient.Send(mailgunClient.NewMessage(\n \t\t/* From */ fmt.Sprintf(\"Excited User <mailgun@%s>\", mailgunDomain),",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/mailgun/mailgun.go",
        "code_diff": "@@ -65,6 +63,9 @@\nfunc sendSimpleMessageHandler(w http.ResponseWriter, r *http.Request) {\n \tw.Write([]byte(\"Message sent!\"))\n }\n \n+// [END gae_flex_mailgun_simple_message]\n+\n+// [START gae_flex_mailgun_complex_message]\n func sendComplexMessageHandler(w http.ResponseWriter, r *http.Request) {\n \tmessage := mailgunClient.NewMessage(\n \t\t/* From */ fmt.Sprintf(\"Excited User <mailgun@%s>\", mailgunDomain),",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/mailjet/mailjet.go",
        "code_diff": "@@ -14,10 +14,10 @@\nimport (\n \t\"google.golang.org/appengine\"\n )\n \n-// [START import]\n+// [START gae_flex_mailjet_config]\n import \"github.com/mailjet/mailjet-apiv3-go\"\n \n-// [END import]\n+// [END gae_flex_mailjet_config]\n \n func main() {\n \thttp.HandleFunc(\"/send\", sendEmail)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/mailjet/mailjet.go",
        "code_diff": "@@ -42,6 +42,7 @@\nfunc mustGetenv(k string) string {\n \treturn v\n }\n \n+// [START gae_flex_mailjet_send_email]\n func sendEmail(w http.ResponseWriter, r *http.Request) {\n \tto := r.FormValue(\"to\")\n \tif to == \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/memcache/memcache.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_redislabs_memcache]\n+\n // Sample memcache demonstrates use of a memcached client from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/redis/redis.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_golang_redis]\n+\n // Sample redis demonstrates use of a redis client from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/sendgrid/sendgrid.go",
        "code_diff": "@@ -14,10 +14,10 @@\nimport (\n \t\"google.golang.org/appengine\"\n )\n \n-// [START import]\n+// [START gae_flex_sendgrid_import]\n import \"gopkg.in/sendgrid/sendgrid-go.v2\"\n \n-// [END import]\n+// [END gae_flex_sendgrid_import]\n \n func main() {\n \thttp.HandleFunc(\"/sendmail\", sendMailHandler)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/sendgrid/sendgrid.go",
        "code_diff": "@@ -35,6 +35,7 @@\nfunc init() {\n \tsendgridClient = sendgrid.NewSendGridClientWithApiKey(sendgridKey)\n }\n \n+// [START gae_flex_sendgrid]\n func sendMailHandler(w http.ResponseWriter, r *http.Request) {\n \tm := sendgrid.NewMail()\n \tm.AddTo(\"example@email.com\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/static_files/staticfiles.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_golang_static_files]\n+\n // Package static demonstrates a static file handler for App Engine flexible environment.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "appengine_flexible/storage/storage.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_storage_app]\n+\n // Sample storage demonstrates use of the cloud.google.com/go/storage package from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/appidentity/appidentity.go",
        "code_diff": "@@ -4,7 +4,7 @@\npackage sample\n \n-// [START asserting_identity_to_Google_APIs]\n+// [START gae_go_app_identity]\n import (\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -14,7 +14,7 @@\nimport (\n )\n \n func sampleHandler(w http.ResponseWriter, r *http.Request) {\n-\t// [START uploading_a_blob_2]\n+\t// [START gae_blobstore_upload_form]\n \tvar rootTemplate = template.Must(template.New(\"root\").Parse(rootTemplateHTML))\n \n \tconst rootTemplateHTML = `",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -24,16 +24,16 @@\nUpload File: <input type=\"file\" name=\"file\"><br>\n <input type=\"submit\" name=\"submit\" value=\"Submit\">\n </form></body></html>\n `\n-\t// [END uploading_a_blob_2]\n+\t// [END gae_blobstore_upload_form]\n \n-\t// [START uploading_a_blob_1]\n+\t// [START gae_blobstore_upload_url]\n \tctx := appengine.NewContext(r)\n \tuploadURL, err := blobstore.UploadURL(ctx, \"/upload\", nil)\n \tif err != nil {\n \t\tserveError(ctx, w, err)\n \t\treturn\n \t}\n-\t// [END uploading_a_blob_1]\n+\t// [END gae_blobstore_upload_url]\n \n \tw.Header().Set(\"Content-Type\", \"text/html\")\n \terr = rootTemplate.Execute(w, uploadURL)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -43,7 +43,7 @@\nUpload File: <input type=\"file\" name=\"file\"><br>\n }\n \n func sampleHandler2(w http.ResponseWriter, r *http.Request) {\n-\t// [START uploading_a_blob_3]\n+\t// [START gae_blobstore_upload_handler]\n \tctx := appengine.NewContext(r)\n \tblobs, _, err := blobstore.ParseUpload(r)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -57,16 +57,15 @@\nfunc sampleHandler2(w http.ResponseWriter, r *http.Request) {\n \t\treturn\n \t}\n \thttp.Redirect(w, r, \"/serve/?blobKey=\"+string(file[0].BlobKey), http.StatusFound)\n-\t// [END uploading_a_blob_3]\n+\t// [END gae_blobstore_upload_handler]\n \n-\t// [START serving_a_blob]\n+\t// [START gae_blobstore_serving]\n \tblobstore.Send(w, appengine.BlobKey(r.FormValue(\"blobKey\")))\n-\t// [END serving_a_blob]\n+\t// [END gae_blobstore_serving]\n }\n \n /* Requires old package (import \"appengine/blobstore\")\n \n-// [START writing_files_to_the_Blobstore]\n var k appengine.BlobKey\n bw, err := blobstore.Create(ctx, \"application/octet-stream\")\n if err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/blobstore/complete.go",
        "code_diff": "@@ -2,7 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START complete_sample_application]\n+// [START gae_blobstore_sample]\n+\n package blobstore_example\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/capabilities/capability.go",
        "code_diff": "@@ -13,7 +13,7 @@\nimport (\n \t\"google.golang.org/appengine/capability\"\n )\n \n-// [START datastore_lookup]\n+// [START gae_go_capabilities_lookup]\n func handler(w http.ResponseWriter, r *http.Request) {\n \tctx := appengine.NewContext(r)\n \tif !capability.Enabled(ctx, \"datastore_v3\", \"*\") {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -18,7 +18,7 @@\nimport (\n var maxHeight int\n var minBirthYear, maxBirthYear int\n \n-// [START interface]\n+// [START gae_go_datastore_interface]\n type Person struct {\n \tFirstName string\n \tLastName  string",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -45,48 +45,48 @@\nfunc handle(w http.ResponseWriter, r *http.Request) {\n \t// ...\n }\n \n-// [END interface]\n+// [END gae_go_datastore_interface]\n \n func example() {\n \tvar lastSeenKey *datastore.Key\n \n-\t// [START key_filter_example]\n+\t// [START gae_go_datastore_key_filter]\n \tq := datastore.NewQuery(\"Person\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END key_filter_example]\n+\t// [END gae_go_datastore_key_filter]\n \t_ = q\n }\n \n func example2() {\n-\t// [START property_filter_example]\n+\t// [START gae_go_datastore_property_filter]\n \tq := datastore.NewQuery(\"Person\").Filter(\"Height <=\", maxHeight)\n-\t// [END property_filter_example]\n+\t// [END gae_go_datastore_property_filter]\n \t_ = q\n }\n \n func example3() {\n \tvar ancestorKey *datastore.Key\n \n-\t// [START ancestor_filter_example]\n+\t// [START gae_go_datastore_ancestor_filter]\n \tq := datastore.NewQuery(\"Person\").Ancestor(ancestorKey)\n-\t// [END ancestor_filter_example]\n+\t// [END gae_go_datastore_ancestor_filter]\n \t_ = q\n }\n \n func example4() {\n-\t// [START sort_order_example]\n+\t// [START gae_go_datastore_sort_order]\n \t// Order alphabetically by last name:\n \tq := datastore.NewQuery(\"Person\").Order(\"LastName\")\n \n \t// Order by height, tallest to shortest:\n \tq = datastore.NewQuery(\"Person\").Order(\"-Height\")\n-\t// [END sort_order_example]\n+\t// [END gae_go_datastore_sort_order]\n \t_ = q\n }\n \n func example5() {\n-\t// [START multiple_sort_orders_example]\n+\t// [START gae_go_datastore_multiple_sort_orders]\n \tq := datastore.NewQuery(\"Person\").Order(\"LastName\").Order(\"-Height\")\n-\t// [END multiple_sort_orders_example]\n+\t// [END gae_go_datastore_multiple_sort_orders]\n \t_ = q\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -96,7 +96,7 @@\nfunc example6() {\n \t}\n \tvar ctx context.Context\n \n-\t// [START ancestor_query_example]\n+\t// [START gae_go_datastore_ancestor_query]\n \t// Create two Photo entities in the datastore with a Person as their ancestor.\n \ttomKey := datastore.NewKey(ctx, \"Person\", \"Tom\", 0, nil)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -117,101 +117,101 @@\nfunc example6() {\n \t_, err = q.GetAll(ctx, &photos)\n \t// check err\n \t// do something with photos\n-\t// [END ancestor_query_example]\n+\t// [END gae_go_datastore_ancestor_query]\n \t_ = err\n \t_ = photos\n }\n \n func example7() {\n-\t// [START keys_only_example]\n+\t// [START gae_go_datastore_keys_only]\n \tq := datastore.NewQuery(\"Person\").KeysOnly()\n-\t// [END keys_only_example]\n+\t// [END gae_go_datastore_keys_only]\n \t_ = q\n }\n \n func example8() {\n-\t// [START inequality_filters_one_property_valid_example_1]\n+\t// [START gae_go_datastore_inequality_filters_one_property_valid_1]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"BirthYear <=\", maxBirthYear)\n-\t// [END inequality_filters_one_property_valid_example_1]\n+\t// [END gae_go_datastore_inequality_filters_one_property_valid_1]\n \t_ = q\n }\n \n func example9() {\n-\t// [START inequality_filters_one_property_invalid_example]\n+\t// [START gae_go_datastore_inequality_filters_one_property_invalid]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"Height <=\", maxHeight) // ERROR\n-\t// [END inequality_filters_one_property_invalid_example]\n+\t// [END gae_go_datastore_inequality_filters_one_property_invalid]\n \t_ = q\n }\n \n func example10() {\n \tvar targetLastName, targetCity string\n \n-\t// [START inequality_filters_one_property_valid_example_2]\n+\t// [START gae_go_datastore_inequality_filters_one_property_valid_2]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"LastName =\", targetLastName).\n \t\tFilter(\"City =\", targetCity).\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"BirthYear <=\", maxBirthYear)\n-\t// [END inequality_filters_one_property_valid_example_2]\n+\t// [END gae_go_datastore_inequality_filters_one_property_valid_2]\n \t_ = q\n }\n \n func example11() {\n-\t// [START inequality_filters_sort_orders_valid_example]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_valid]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"BirthYear\").\n \t\tOrder(\"LastName\")\n-\t// [END inequality_filters_sort_orders_valid_example]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_valid]\n \t_ = q\n }\n \n func example12() {\n-\t// [START inequality_filters_sort_orders_invalid_example_1]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_invalid_1]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"LastName\") // ERROR\n-\t// [END inequality_filters_sort_orders_invalid_example_1]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_invalid_1]\n \t_ = q\n }\n \n func example13() {\n-\t// [START inequality_filters_sort_orders_invalid_example_2]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_invalid_2]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"LastName\").\n \t\tOrder(\"BirthYear\") // ERROR\n-\t// [END inequality_filters_sort_orders_invalid_example_2]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_invalid_2]\n \t_ = q\n }\n \n func example14() {\n-\t// [START surprising_behavior_example_1]\n+\t// [START gae_go_datastore_surprising_behavior_1]\n \tq := datastore.NewQuery(\"Widget\").\n \t\tFilter(\"x >\", 1).\n \t\tFilter(\"x <\", 2)\n-\t// [END surprising_behavior_example_1]\n+\t// [END gae_go_datastore_surprising_behavior_1]\n \t_ = q\n }\n \n func example15() {\n-\t// [START surprising_behavior_example_2]\n+\t// [START gae_go_datastore_surprising_behavior_2]\n \tq := datastore.NewQuery(\"Widget\").\n \t\tFilter(\"x =\", 1).\n \t\tFilter(\"x =\", 2)\n-\t// [END surprising_behavior_example_2]\n+\t// [END gae_go_datastore_surprising_behavior_2]\n \t_ = q\n }\n \n func doSomething(k *datastore.Key, p Person) {}\n \n func example16() {\n \tvar ctx context.Context\n-\t// [START retrieval_example]\n+\t// [START gae_go_datastore_retrieval]\n \tq := datastore.NewQuery(\"Person\")\n \tt := q.Run(ctx)\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -227,13 +227,13 @@\nfunc example16() {\n \t\t// Do something with Person p and Key k\n \t\tdoSomething(k, p)\n \t}\n-\t// [END retrieval_example]\n+\t// [END gae_go_datastore_retrieval]\n }\n \n func example17() {\n \tvar ctx context.Context\n \n-\t// [START all_entities_retrieval_example]\n+\t// [START gae_go_datastore_all_entities_retrieval]\n \tq := datastore.NewQuery(\"Person\")\n \tvar people []Person\n \tkeys, err := q.GetAll(ctx, &people)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -246,13 +246,13 @@\nfunc example17() {\n \t\t// Do something with Person p and Key k\n \t\tdoSomething(k, p)\n \t}\n-\t// [END all_entities_retrieval_example]\n+\t// [END gae_go_datastore_all_entities_retrieval]\n }\n \n func example18() {\n \tvar ctx context.Context\n \n-\t// [START query_limit_example]\n+\t// [START gae_go_datastore_query_limit]\n \tq := datastore.NewQuery(\"Person\").Order(\"-Height\").Limit(5)\n \tvar people []Person\n \t_, err := q.GetAll(ctx, &people)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -261,21 +261,19 @@\nfunc example18() {\n \tfor _, p := range people {\n \t\tlog.Infof(ctx, \"%s %s, %d inches tall\", p.FirstName, p.LastName, p.Height)\n \t}\n-\t// [END query_limit_example]\n+\t// [END gae_go_datastore_query_limit]\n \t_ = err\n }\n \n func example19() {\n-\t// [START query_offset_example]\n \tq := datastore.NewQuery(\"Person\").Order(\"-Height\").Limit(5).Offset(5)\n-\t// [END query_offset_example]\n \t_ = q\n }\n \n func example20() {\n \tvar ctx context.Context\n \n-\t// [START cursors]\n+\t// [START gae_go_datastore_cursors]\n \t// Create a query for all Person entities.\n \tq := datastore.NewQuery(\"Person\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -310,24 +308,24 @@\nfunc example20() {\n \t\t\tValue: []byte(cursor.String()),\n \t\t})\n \t}\n-\t// [END cursors]\n+\t// [END gae_go_datastore_cursors]\n }\n \n func example21() {\n \tvar lastSeenKey *datastore.Key\n \n-\t// [START kindless_query_example]\n+\t// [START gae_go_datastore_kindless_query]\n \tq := datastore.NewQuery(\"\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_query_example]\n+\t// [END gae_go_datastore_kindless_query]\n \t_ = q\n }\n \n func example22() {\n \tvar ancestorKey, lastSeenKey *datastore.Key\n \n-\t// [START kindless_ancestor_key_query_example]\n+\t// [START gae_go_datastore_kindless_ancestor_key_query]\n \tq := datastore.NewQuery(\"\").Ancestor(ancestorKey).Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_ancestor_key_query_example]\n+\t// [END gae_go_datastore_kindless_ancestor_key_query]\n \t_ = q\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -339,7 +337,7 @@\nfunc example23() {\n \tvar ctx context.Context\n \tdoSomething := func(x interface{}) {}\n \n-\t// [START kindless_ancestor_query_example]\n+\t// [START gae_go_datastore_kindless_ancestor_query]\n \ttomKey := datastore.NewKey(ctx, \"Person\", \"Tom\", 0, nil)\n \n \tweddingPhoto := &Photo{URL: \"http://example.com/some/path/to/wedding_photo.jpg\"}",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/logs/logs.go",
        "code_diff": "@@ -2,7 +2,6 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START sample_code]\n // This sample gets the app displays 5 log Records at a time, including all\n // AppLogs, with a Next link to let the user page through the results using the\n // Record's Offset property.",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/logs/writing_logs.go",
        "code_diff": "@@ -4,7 +4,7 @@\npackage app\n \n-// [START sample]\n+// [START gae_writing_logs]\n import (\n \t\"net/http\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/requests/helloworld.go",
        "code_diff": "@@ -2,7 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START requests_and_HTTP]\n+// [START gae_golang_request_example]\n+\n package hello\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "docs/appengine/requests/logging.go",
        "code_diff": "@@ -2,7 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START logging]\n+// [START gae_golang_logging_example]\n+\n package hello\n \n import (",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "kms/snippets/snippet_test.go",
        "code_diff": "@@ -25,7 +25,7 @@\nfunc init() {\n \t_ = google.DefaultClient\n }\n \n-func createKeyring(project, name string) error {\n+func createKeyring(project, keyRing string) error {\n \tctx := context.Background()\n \tauthedClient, err := google.DefaultClient(ctx, cloudkms.CloudPlatformScope)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "kms/snippets/snippet_test.go",
        "code_diff": "@@ -39,7 +39,7 @@\nfunc createKeyring(project, name string) error {\n \tparent := fmt.Sprintf(\"projects/%s/locations/%s\", project, location)\n \n \t_, err = client.Projects.Locations.KeyRings.Create(\n-\t\tparent, &cloudkms.KeyRing{}).KeyRingId(name).Do()\n+\t\tparent, &cloudkms.KeyRing{}).KeyRingId(keyRing).Do()\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "kms/snippets/snippet_test.go",
        "code_diff": "@@ -200,7 +200,7 @@\nfunc getRingPolicy(project, keyRing string) error {\n \treturn nil\n }\n \n-func addMemberRingPolicy(project, keyRing, role, member string) error {\n+func addMemberRingPolicy(project, location, keyRing, role, member string) error {\n \tctx := context.Background()\n \tauthedClient, err := google.DefaultClient(ctx, cloudkms.CloudPlatformScope)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -62,6 +62,8 @@\nfunc usage(msg string) {\n \tos.Exit(2)\n }\n \n+// [START language_entities_text]\n+\n func analyzeEntities(ctx context.Context, client *language.Client, text string) (*languagepb.AnalyzeEntitiesResponse, error) {\n \treturn client.AnalyzeEntities(ctx, &languagepb.AnalyzeEntitiesRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -74,6 +76,10 @@\nfunc analyzeEntities(ctx context.Context, client *language.Client, text string)\n \t})\n }\n \n+// [END language_entities_text]\n+\n+// [START language_sentiment_text]\n+\n func analyzeSentiment(ctx context.Context, client *language.Client, text string) (*languagepb.AnalyzeSentimentResponse, error) {\n \treturn client.AnalyzeSentiment(ctx, &languagepb.AnalyzeSentimentRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -85,6 +91,10 @@\nfunc analyzeSentiment(ctx context.Context, client *language.Client, text string)\n \t})\n }\n \n+// [END language_sentiment_text]\n+\n+// [START language_syntax_text]\n+\n func analyzeSyntax(ctx context.Context, client *language.Client, text string) (*languagepb.AnnotateTextResponse, error) {\n \treturn client.AnnotateText(ctx, &languagepb.AnnotateTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -100,6 +110,10 @@\nfunc analyzeSyntax(ctx context.Context, client *language.Client, text string) (*\n \t})\n }\n \n+// [END language_syntax_text]\n+\n+// [START language_classify_text]\n+\n func classifyText(ctx context.Context, client *language.Client, text string) (*languagepb.ClassifyTextResponse, error) {\n \treturn client.ClassifyText(ctx, &languagepb.ClassifyTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "language/analyze/entity_sentiment.go",
        "code_diff": "@@ -22,6 +22,8 @@\nfunc betaClient() *language.Client {\n \treturn client\n }\n \n+// [START language_entity_sentiment_text]\n+\n func analyzeEntitySentiment(ctx context.Context, client *language.Client, text string) (*languagepb.AnalyzeEntitySentimentResponse, error) {\n \treturn client.AnalyzeEntitySentiment(ctx, &languagepb.AnalyzeEntitySentimentRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -15,6 +15,8 @@\nimport (\n // to avoid it being included in the function signature below.\n var client *language.Client\n \n+// [START language_entities_gcs]\n+\n func analyzeEntitiesFromGCS(ctx context.Context, gcsURI string) (*languagepb.AnalyzeEntitiesResponse, error) {\n \treturn client.AnalyzeEntities(ctx, &languagepb.AnalyzeEntitiesRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -27,6 +29,10 @@\nfunc analyzeEntitiesFromGCS(ctx context.Context, gcsURI string) (*languagepb.Ana\n \t})\n }\n \n+// [END language_entities_gcs]\n+\n+// [START language_sentiment_gcs]\n+\n func analyzeSentimentFromGCS(ctx context.Context, gcsURI string) (*languagepb.AnalyzeSentimentResponse, error) {\n \treturn client.AnalyzeSentiment(ctx, &languagepb.AnalyzeSentimentRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -38,6 +44,10 @@\nfunc analyzeSentimentFromGCS(ctx context.Context, gcsURI string) (*languagepb.An\n \t})\n }\n \n+// [END language_sentiment_gcs]\n+\n+// [START language_syntax_gcs]\n+\n func analyzeSyntaxFromGCS(ctx context.Context, gcsURI string) (*languagepb.AnnotateTextResponse, error) {\n \treturn client.AnnotateText(ctx, &languagepb.AnnotateTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "language/snippets/snippet.go",
        "code_diff": "@@ -53,6 +63,10 @@\nfunc analyzeSyntaxFromGCS(ctx context.Context, gcsURI string) (*languagepb.Annot\n \t})\n }\n \n+// [END language_syntax_gcs]\n+\n+// [START language_classify_gcs]\n+\n func classifyTextFromGCS(ctx context.Context, gcsURI string) (*languagepb.ClassifyTextResponse, error) {\n \treturn client.ClassifyText(ctx, &languagepb.ClassifyTextRequest{\n \t\tDocument: &languagepb.Document{",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "logging/exportlogs/exportlogs.go",
        "code_diff": "@@ -63,7 +63,7 @@\nfunc main() {\n }\n \n func listSinks(client *logadmin.Client) ([]string, error) {\n-\t// [START list_log_sinks]\n+\t// [START logging_list_sinks]\n \tctx := context.Background()\n \n \tvar sinks []string",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "logging/simplelog/simplelog.go",
        "code_diff": "@@ -83,14 +83,14 @@\nfunc main() {\n }\n \n func writeEntry(client *logging.Client) {\n-\t// [START write_log_entry]\n+\t// [START logging_write_log_entry]\n \tconst name = \"log-example\"\n \tlogger := client.Logger(name)\n \tdefer logger.Flush() // Ensure the entry is written.\n \n \tinfolog := logger.StandardLogger(logging.Info)\n \tinfolog.Printf(\"infolog is a standard Go log.Logger with INFO severity.\")\n-\t// [END write_log_entry]\n+\t// [END logging_write_log_entry]\n }\n \n func structuredWrite(client *logging.Client) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "logging/simplelog/simplelog.go",
        "code_diff": "@@ -106,25 +106,25 @@\nfunc structuredWrite(client *logging.Client) {\n \t\t},\n \t\tSeverity: logging.Debug,\n \t})\n-\t// [END write_log_entry]\n+\t// [END logging_write_log_entry]\n }\n \n func deleteLog(adminClient *logadmin.Client) error {\n \tctx := context.Background()\n \n-\t// [START delete_log]\n+\t// [START logging_delete_log]\n \tconst name = \"log-example\"\n \tif err := adminClient.DeleteLog(ctx, name); err != nil {\n \t\treturn err\n \t}\n-\t// [END delete_log]\n+\t// [END logging_delete_log]\n \treturn nil\n }\n \n func getEntries(adminClient *logadmin.Client, projID string) ([]*logging.Entry, error) {\n \tctx := context.Background()\n \n-\t// [START list_log_entries]\n+\t// [START logging_list_log_entries]\n \tvar entries []*logging.Entry\n \tconst name = \"log-example\"\n \titer := adminClient.Entries(ctx,",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -80,7 +80,7 @@\nfunc list(client *pubsub.Client) ([]*pubsub.Subscription, error) {\n \treturn subs, nil\n }\n \n-func pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n+func pullMsgs(client *pubsub.Client, subName string, topic *pubsub.Topic) error {\n \tctx := context.Background()\n \n \t// Publish 10 messages on the topic.",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -105,7 +105,7 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \t// Consume 10 messages.\n \tvar mu sync.Mutex\n \treceived := 0\n-\tsub := client.Subscription(name)\n+\tsub := client.Subscription(subName)\n \tcctx, cancel := context.WithCancel(ctx)\n \terr := sub.Receive(cctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\tmsg.Ack()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -125,12 +125,12 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \treturn nil\n }\n \n-func pullMsgsError(client *pubsub.Client, name string) error {\n+func pullMsgsError(client *pubsub.Client, subName string) error {\n \tctx := context.Background()\n \t// [START pubsub_subscriber_error_listener]\n \t// If the service returns a non-retryable error, Receive returns that error after\n \t// all of the outstanding calls to the handler have returned.\n-\terr := client.Subscription(name).Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n+\terr := client.Subscription(subName).Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\tfmt.Printf(\"Got message: %q\\n\", string(msg.Data))\n \t\tmsg.Ack()\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -141,10 +141,10 @@\nfunc pullMsgsError(client *pubsub.Client, name string) error {\n \treturn nil\n }\n \n-func pullMsgsSettings(client *pubsub.Client, name string) error {\n+func pullMsgsSettings(client *pubsub.Client, subName string) error {\n \tctx := context.Background()\n \t// [START pubsub_subscriber_flow_settings]\n-\tsub := client.Subscription(name)\n+\tsub := client.Subscription(subName)\n \tsub.ReceiveSettings.MaxOutstandingMessages = 10\n \terr := sub.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\tfmt.Printf(\"Got message: %q\\n\", string(msg.Data))",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -157,10 +157,10 @@\nfunc pullMsgsSettings(client *pubsub.Client, name string) error {\n \treturn nil\n }\n \n-func create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n+func create(client *pubsub.Client, subName string, topic *pubsub.Topic) error {\n \tctx := context.Background()\n \t// [START pubsub_create_pull_subscription]\n-\tsub, err := client.CreateSubscription(ctx, name, pubsub.SubscriptionConfig{\n+\tsub, err := client.CreateSubscription(ctx, subName, pubsub.SubscriptionConfig{\n \t\tTopic:       topic,\n \t\tAckDeadline: 20 * time.Second,\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -172,12 +172,12 @@\nfunc create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \treturn nil\n }\n \n-func createWithEndpoint(client *pubsub.Client, name string, topic *pubsub.Topic, endpoint string) error {\n+func createWithEndpoint(client *pubsub.Client, subName string, topic *pubsub.Topic, endpoint string) error {\n \tctx := context.Background()\n \t// [START pubsub_create_push_subscription]\n \n \t// For example, endpoint is \"https://my-test-project.appspot.com/push\".\n-\tsub, err := client.CreateSubscription(ctx, name, pubsub.SubscriptionConfig{\n+\tsub, err := client.CreateSubscription(ctx, subName, pubsub.SubscriptionConfig{\n \t\tTopic:       topic,\n \t\tAckDeadline: 10 * time.Second,\n \t\tPushConfig:  pubsub.PushConfig{Endpoint: endpoint},",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -190,12 +190,12 @@\nfunc createWithEndpoint(client *pubsub.Client, name string, topic *pubsub.Topic,\n \treturn nil\n }\n \n-func updateEndpoint(client *pubsub.Client, name string, endpoint string) error {\n+func updateEndpoint(client *pubsub.Client, subName string, endpoint string) error {\n \tctx := context.Background()\n \t// [START pubsub_update_push_configuration]\n \n \t// For example, endpoint is \"https://my-test-project.appspot.com/push\".\n-\tsubConfig, err := client.Subscription(name).Update(ctx, pubsub.SubscriptionConfigToUpdate{\n+\tsubConfig, err := client.Subscription(subName).Update(ctx, pubsub.SubscriptionConfigToUpdate{\n \t\tPushConfig: &pubsub.PushConfig{Endpoint: endpoint},\n \t})\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/caption/caption.go",
        "code_diff": "@@ -9,17 +9,16 @@\npackage main\n import (\n \t\"flag\"\n \t\"fmt\"\n+\t\"io\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"os\"\n \t\"strings\"\n \n-\t// [START imports]\n \t\"golang.org/x/net/context\"\n \n \tspeech \"cloud.google.com/go/speech/apiv1\"\n \tspeechpb \"google.golang.org/genproto/googleapis/cloud/speech/v1\"\n-\t// [END imports]\n )\n \n const usage = `Usage: caption <audiofile>",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/caption/caption.go",
        "code_diff": "@@ -37,7 +36,7 @@\nfunc main() {\n \t\tos.Exit(2)\n \t}\n \n-\tvar runFunc func(string) (*speechpb.RecognizeResponse, error)\n+\tvar runFunc func(io.Writer, string) error\n \n \tpath := os.Args[1]\n \tif strings.Contains(path, \"://\") {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/caption/caption.go",
        "code_diff": "@@ -47,32 +46,21 @@\nfunc main() {\n \t}\n \n \t// Perform the request.\n-\tresp, err := runFunc(os.Args[1])\n-\tif err != nil {\n+\tif err := runFunc(os.Stdout, os.Args[1]); err != nil {\n \t\tlog.Fatal(err)\n \t}\n-\n-\t// [START print]\n-\t// Print the results.\n-\tfor _, result := range resp.Results {\n-\t\tfor _, alt := range result.Alternatives {\n-\t\t\tfmt.Printf(\"\\\"%v\\\" (confidence=%3f)\\n\", alt.Transcript, alt.Confidence)\n-\t\t}\n-\t}\n-\t// [END print]\n }\n \n-func recognizeGCS(gcsURI string) (*speechpb.RecognizeResponse, error) {\n+// [START speech_transcribe_sync_gcs]\n+\n+func recognizeGCS(w io.Writer, gcsURI string) error {\n \tctx := context.Background()\n \n-\t// [START init_gcs]\n \tclient, err := speech.NewClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\treturn err\n \t}\n-\t// [END init_gcs]\n \n-\t// [START request_gcs]\n \t// Send the request with the URI (gs://...)\n \t// and sample rate information to be transcripted.\n \tresp, err := client.Recognize(ctx, &speechpb.RecognizeRequest{",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/caption/caption.go",
        "code_diff": "@@ -85,24 +73,31 @@\nfunc recognizeGCS(gcsURI string) (*speechpb.RecognizeResponse, error) {\n \t\t\tAudioSource: &speechpb.RecognitionAudio_Uri{Uri: gcsURI},\n \t\t},\n \t})\n-\t// [END request_gcs]\n-\treturn resp, err\n+\n+\t// Print the results.\n+\tfor _, result := range resp.Results {\n+\t\tfor _, alt := range result.Alternatives {\n+\t\t\tfmt.Fprintf(w, \"\\\"%v\\\" (confidence=%3f)\\n\", alt.Transcript, alt.Confidence)\n+\t\t}\n+\t}\n+\treturn nil\n }\n \n-func recognize(file string) (*speechpb.RecognizeResponse, error) {\n+// [END speech_transcribe_sync_gcs]\n+\n+// [START speech_transcribe_sync]\n+\n+func recognize(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\t// [START init]\n \tclient, err := speech.NewClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\treturn err\n \t}\n-\t// [END init]\n \n-\t// [START request]\n \tdata, err := ioutil.ReadFile(file)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\treturn err\n \t}\n \n \t// Send the contents of the audio file with the encoding and",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/caption/caption_test.go",
        "code_diff": "@@ -5,6 +5,8 @@\npackage main\n \n import (\n+\t\"bytes\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/captionasync/captionasync.go",
        "code_diff": "@@ -8,6 +8,7 @@\npackage main\n \n import (\n \t\"fmt\"\n+\t\"io\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"os\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/captionasync/captionasync.go",
        "code_diff": "@@ -33,7 +34,7 @@\nfunc main() {\n \t\tos.Exit(2)\n \t}\n \n-\tvar sendFunc func(*speech.Client, string) (*speechpb.LongRunningRecognizeResponse, error)\n+\tvar sendFunc func(io.Writer, *speech.Client, string) error\n \n \tpath := os.Args[1]\n \tif strings.Contains(path, \"://\") {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/captionasync/captionasync.go",
        "code_diff": "@@ -48,26 +49,18 @@\nfunc main() {\n \t\tlog.Fatal(err)\n \t}\n \n-\tresp, err := sendFunc(client, os.Args[1])\n-\tif err != nil {\n+\tif err := sendFunc(os.Stdout, client, os.Args[1]); err != nil {\n \t\tlog.Fatal(err)\n \t}\n-\n-\t// [START print]\n-\t// Print the results.\n-\tfor _, result := range resp.Results {\n-\t\tfor _, alt := range result.Alternatives {\n-\t\t\tfmt.Printf(\"\\\"%v\\\" (confidence=%3f)\\n\", alt.Transcript, alt.Confidence)\n-\t\t}\n-\t}\n-\t// [END print]\n }\n \n-func send(client *speech.Client, filename string) (*speechpb.LongRunningRecognizeResponse, error) {\n+// [START speech_transcribe_async]\n+\n+func send(w io.Writer, client *speech.Client, filename string) error {\n \tctx := context.Background()\n \tdata, err := ioutil.ReadFile(filename)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn err\n \t}\n \n \t// Send the contents of the audio file with the encoding and",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/captionasync/captionasync.go",
        "code_diff": "@@ -85,12 +78,27 @@\nfunc send(client *speech.Client, filename string) (*speechpb.LongRunningRecogniz\n \n \top, err := client.LongRunningRecognize(ctx, req)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn err\n+\t}\n+\tresp, err := op.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n \t}\n-\treturn op.Wait(ctx)\n+\n+\t// Print the results.\n+\tfor _, result := range resp.Results {\n+\t\tfor _, alt := range result.Alternatives {\n+\t\t\tfmt.Fprintf(w, \"\\\"%v\\\" (confidence=%3f)\\n\", alt.Transcript, alt.Confidence)\n+\t\t}\n+\t}\n+\treturn nil\n }\n \n-func sendGCS(client *speech.Client, gcsURI string) (*speechpb.LongRunningRecognizeResponse, error) {\n+// [END speech_transcribe_async]\n+\n+// [START speech_transcribe_async_gcs]\n+\n+func sendGCS(w io.Writer, client *speech.Client, gcsURI string) error {\n \tctx := context.Background()\n \n \t// Send the contents of the audio file with the encoding and",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/captionasync/captionasync_test.go",
        "code_diff": "@@ -5,6 +5,8 @@\npackage main\n \n import (\n+\t\"bytes\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/captionasync/captionasync_test.go",
        "code_diff": "@@ -22,18 +24,15 @@\nfunc TestRecognize(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \n-\tresp, err := send(client, \"../testdata/quit.raw\")\n-\tif err != nil {\n+\tvar buf bytes.Buffer\n+\n+\tif err := send(&buf, client, \"../testdata/quit.raw\"); err != nil {\n \t\tt.Fatal(err)\n \t}\n-\tif len(resp.Results) == 0 {\n+\tif len(buf.String()) == 0 {\n \t\tt.Fatal(\"got no results; want at least one\")\n \t}\n-\tresult := resp.Results[0]\n-\tif len(result.Alternatives) < 1 {\n-\t\tt.Fatal(\"got no alternatives; want at least one\")\n-\t}\n-\tif got, want := result.Alternatives[0].Transcript, \"quit\"; got != want {\n+\tif got, want := buf.String(), \"quit\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"Transcript: got %q; want %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/livecaption/livecaption.go",
        "code_diff": "@@ -24,7 +24,7 @@\nimport (\n func main() {\n \tctx := context.Background()\n \n-\t// [START speech_streaming_mic_recognize]\n+\t// [START speech_transcribe_streaming_mic]\n \tclient, err := speech.NewClient(ctx)\n \tif err != nil {\n \t\tlog.Fatal(err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/livecaption_from_file/livecaption_from_file.go",
        "code_diff": "@@ -34,7 +34,6 @@\nfunc main() {\n \n \tctx := context.Background()\n \n-\t// [START speech_streaming_file_recognize]\n \tclient, err := speech.NewClient(ctx)\n \tif err != nil {\n \t\tlog.Fatal(err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "speech/wordoffset/wordoffset.go",
        "code_diff": "@@ -54,6 +54,8 @@\nfunc main() {\n \t}\n }\n \n+// [START speech_transcribe_async_word_time_offsets_gcs]\n+\n func asyncWords(client *speech.Client, out io.Writer, gcsURI string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -21,17 +21,22 @@\nvar (\n \tbucketName    string\n )\n \n-func TestCreate(t *testing.T) {\n+func setup(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tctx := context.Background()\n \n+\tctx := context.Background()\n \tvar err error\n \tstorageClient, err = storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n \n \tbucketName = tc.ProjectID + \"-storage-buckets-tests\"\n+}\n+\n+func TestCreate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tsetup(t)\n \n \t// Clean up bucket before running tests.\n \tdeleteBucket(storageClient, bucketName)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -55,6 +60,8 @@\nfunc TestCreateWithAttrs(t *testing.T) {\n \n func TestList(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n+\tsetup(t)\n+\n \tbuckets, err := list(storageClient, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatal(err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -77,6 +84,8 @@\nouter:\n \n func TestIAM(t *testing.T) {\n \ttestutil.SystemTest(t)\n+\tsetup(t)\n+\n \tif _, err := getPolicy(storageClient, bucketName); err != nil {\n \t\tt.Errorf(\"getPolicy: %#v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -90,6 +99,8 @@\nfunc TestIAM(t *testing.T) {\n \n func TestRequesterPays(t *testing.T) {\n \ttestutil.SystemTest(t)\n+\tsetup(t)\n+\n \tif err := enableRequesterPays(storageClient, bucketName); err != nil {\n \t\tt.Errorf(\"enableRequesterPays: %#v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -103,6 +114,7 @@\nfunc TestRequesterPays(t *testing.T) {\n \n func TestKMS(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n+\tsetup(t)\n \n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")\n \tcryptoKeyID := os.Getenv(\"GOLANG_SAMPLES_KMS_CRYPTOKEY\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "texttospeech/list_voices/list_voices.go",
        "code_diff": "@@ -17,7 +17,7 @@\nimport (\n \ttexttospeechpb \"google.golang.org/genproto/googleapis/cloud/texttospeech/v1\"\n )\n \n-// [START ListVoices]\n+// [START tts_list_voices]\n \n // ListVoices lists the available text to speech voices.\n func ListVoices(w io.Writer) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "texttospeech/quickstart/quickstart.go",
        "code_diff": "@@ -16,7 +16,7 @@\nimport (\n \ttexttospeechpb \"google.golang.org/genproto/googleapis/cloud/texttospeech/v1\"\n )\n \n-// [START quickstart]\n+// [START tts_quickstart]\n \n func main() {\n \t// Instantiates a client.",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "texttospeech/synthesize_file/synthesize_file.go",
        "code_diff": "@@ -19,7 +19,7 @@\nimport (\n \ttexttospeechpb \"google.golang.org/genproto/googleapis/cloud/texttospeech/v1\"\n )\n \n-// [START SynthesizeTextFile]\n+// [START tts_synthesize_text_file]\n \n // SynthesizeTextFile synthesizes the text in textFile and saves the output to\n // outputFile.",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "texttospeech/synthesize_file/synthesize_file.go",
        "code_diff": "@@ -64,9 +64,9 @@\nfunc SynthesizeTextFile(w io.Writer, textFile, outputFile string) error {\n \treturn nil\n }\n \n-// [END SynthesizeTextFile]\n+// [END tts_synthesize_text_file]\n \n-// [START SynthesizeSSMLFile]\n+// [START tts_synthesize_ssml_file]\n \n // SynthesizeSSMLFile synthesizes the SSML contents in ssmlFile and saves the\n // output to outputFile.",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "texttospeech/synthesize_text/synthesize_text.go",
        "code_diff": "@@ -19,7 +19,7 @@\nimport (\n \ttexttospeechpb \"google.golang.org/genproto/googleapis/cloud/texttospeech/v1\"\n )\n \n-// [START SynthesizeText]\n+// [START tts_synthesize_text]\n \n // SynthesizeText synthesizes plain text and saves the output to outputFile.\n func SynthesizeText(w io.Writer, text, outputFile string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "texttospeech/synthesize_text/synthesize_text.go",
        "code_diff": "@@ -58,9 +58,9 @@\nfunc SynthesizeText(w io.Writer, text, outputFile string) error {\n \treturn nil\n }\n \n-// [END SynthesizeText]\n+// [END tts_synthesize_text]\n \n-// [START SynthesizeSSML]\n+// [START tts_synthesize_ssml]\n \n // SynthesizeSSML synthesizes ssml and saves the output to outputFile.\n //",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "videointelligence/video_analyze/gen/template.go",
        "code_diff": "@@ -56,7 +56,7 @@\nfunc boilerplate() { //# omit\n \t//# enddef\n } //# omit\n \n-// [START video_analyze_labels_local] //# include if !gcs\n+// [START video_analyze_labels] //# include if !gcs\n // [START video_analyze_labels_gcs] //# include if gcs\n \n func label__SUFFIX__(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -16,7 +16,7 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n-// [START video_analyze_labels_local]\n+// [START video_analyze_labels]\n \n func label(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -31,6 +31,8 @@\nfunc init() {\n \t_ = os.Open\n }\n \n+// [START vision_face_detection]\n+\n // detectFaces gets faces from the Vision API for an image at the given file path.\n func detectFaces(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -68,6 +70,10 @@\nfunc detectFaces(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_face_detection]\n+\n+// [START vision_label_detection]\n+\n // detectLabels gets labels from the Vision API for an image at the given file path.\n func detectLabels(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -104,6 +110,10 @@\nfunc detectLabels(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_label_detection]\n+\n+// [START vision_landmark_detection]\n+\n // detectLandmarks gets landmarks from the Vision API for an image at the given file path.\n func detectLandmarks(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -140,6 +150,10 @@\nfunc detectLandmarks(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_landmark_detection]\n+\n+// [START vision_text_detection]\n+\n // detectText gets text from the Vision API for an image at the given file path.\n func detectText(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -176,7 +190,9 @@\nfunc detectText(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_document]\n+// [END vision_text_detection]\n+\n+// [START vision_fulltext_detection]\n \n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentText(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -234,7 +250,9 @@\nfunc detectDocumentText(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_document]\n+// [END vision_fulltext_detection]\n+\n+// [START vision_image_property_detection]\n \n // detectProperties gets image properties from the Vision API for an image at the given file path.\n func detectProperties(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -272,6 +290,10 @@\nfunc detectProperties(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_image_property_detection]\n+\n+// [START vision_crop_hint_detection]\n+\n // detectCropHints gets suggested croppings the Vision API for an image at the given file path.\n func detectCropHints(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -306,7 +328,9 @@\nfunc detectCropHints(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_safe_search]\n+// [END vision_crop_hint_detection]\n+\n+// [START vision_safe_search_detection]\n \n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearch(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -342,9 +366,9 @@\nfunc detectSafeSearch(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_safe_search]\n+// [END vision_safe_search_detection]\n \n-// [START vision_detect_web]\n+// [START vision_web_detection]\n \n // detectWeb gets image properties from the Vision API for an image at the given file path.\n func detectWeb(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -400,9 +424,9 @@\nfunc detectWeb(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_web]\n+// [END vision_web_detection]\n \n-// [START vision_web_entities_include_geo_results]\n+// [START vision_web_detection_include_geo]\n \n // detectWebGeo detects geographic metadata from the Vision API for an image at the given file path.\n func detectWebGeo(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -444,7 +468,9 @@\nfunc detectWebGeo(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_web_entities_include_geo_results]\n+// [END vision_web_detection_include_geo]\n+\n+// [START vision_logo_detection]\n \n // detectLogos gets logos from the Vision API for an image at the given file path.\n func detectLogos(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -482,10 +508,12 @@\nfunc detectLogos(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_async_document]\n+// [END vision_logo_detection]\n+\n+// [START vision_text_detection_pdf]\n \n-// detectAsyncDocument does Optical Character Recognition (OCR) on a PDF file\n-// stored in GCS.\n+// detectAsyncDocument performs Optical Character Recognition (OCR) on a\n+// PDF file stored in GCS.\n func detectAsyncDocument(w io.Writer, gcsSourceURI, gcsDestinationURI string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -533,7 +561,7 @@\nfunc detectAsyncDocument(w io.Writer, gcsSourceURI, gcsDestinationURI string) er\n \treturn nil\n }\n \n-// [END vision_detect_async_document]\n+// [END vision_text_detection_pdf]\n \n func init() {\n \t// Refer to these functions so that goimports is happy before boilerplate is inserted.",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -542,6 +570,8 @@\nfunc init() {\n \t_ = os.Open\n }\n \n+// [START vision_face_detection_gcs]\n+\n // detectFaces gets faces from the Vision API for an image at the given file path.\n func detectFacesURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -570,6 +600,10 @@\nfunc detectFacesURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_face_detection_gcs]\n+\n+// [START vision_label_detection_gcs]\n+\n // detectLabels gets labels from the Vision API for an image at the given file path.\n func detectLabelsURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -597,6 +631,10 @@\nfunc detectLabelsURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_label_detection_gcs]\n+\n+// [START vision_landmark_detection_gcs]\n+\n // detectLandmarks gets landmarks from the Vision API for an image at the given file path.\n func detectLandmarksURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -624,6 +662,10 @@\nfunc detectLandmarksURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_landmark_detection_gcs]\n+\n+// [START vision_text_detection_gcs]\n+\n // detectText gets text from the Vision API for an image at the given file path.\n func detectTextURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -651,7 +693,9 @@\nfunc detectTextURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_document_uri]\n+// [END vision_text_detection_gcs]\n+\n+// [START vision_fulltext_detection_gcs]\n \n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentTextURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -700,7 +744,9 @@\nfunc detectDocumentTextURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_document_uri]\n+// [END vision_fulltext_detection_gcs]\n+\n+// [START vision_image_property_detection_gcs]\n \n // detectProperties gets image properties from the Vision API for an image at the given file path.\n func detectPropertiesURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -729,6 +775,10 @@\nfunc detectPropertiesURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_image_property_detection_gcs]\n+\n+// [START vision_crop_hint_detection_gcs]\n+\n // detectCropHints gets suggested croppings the Vision API for an image at the given file path.\n func detectCropHintsURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -754,7 +804,9 @@\nfunc detectCropHintsURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_safe_search_uri]\n+// [END vision_crop_hint_detection_gcs]\n+\n+// [START vision_safe_search_detection_gcs]\n \n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearchURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -781,9 +833,9 @@\nfunc detectSafeSearchURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_safe_search_uri]\n+// [END vision_safe_search_detection_gcs]\n \n-// [START vision_detect_web_uri]\n+// [START vision_web_detection_gcs]\n \n // detectWeb gets image properties from the Vision API for an image at the given file path.\n func detectWebURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -830,9 +882,9 @@\nfunc detectWebURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_web_uri]\n+// [END vision_web_detection_gcs]\n \n-// [START vision_web_entities_include_geo_results_uri]\n+// [START vision_web_detection_include_geo_gcs]\n \n // detectWebGeo detects geographic metadata from the Vision API for an image at the given file path.\n func detectWebGeoURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -865,7 +917,9 @@\nfunc detectWebGeoURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_web_entities_include_geo_results_uri]\n+// [END vision_web_detection_include_geo_gcs]\n+\n+// [START vision_logo_detection_gcs]\n \n // detectLogos gets logos from the Vision API for an image at the given file path.\n func detectLogosURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -894,10 +948,12 @@\nfunc detectLogosURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_async_document_uri]\n+// [END vision_logo_detection_gcs]\n+\n+// [START vision_text_detection_pdf_gcs]\n \n-// detectAsyncDocument does Optical Character Recognition (OCR) on a PDF file\n-// stored in GCS.\n+// detectAsyncDocument performs Optical Character Recognition (OCR) on a\n+// PDF file stored in GCS.\n func detectAsyncDocumentURI(w io.Writer, gcsSourceURI, gcsDestinationURI string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -34,6 +34,8 @@\nfunc init() {\n \t_ = os.Open\n }\n \n+// [START vision_face_detection{REGION_TAG_PARAMETER}]\n+\n // detectFaces gets faces from the Vision API for an image at the given file path.\n func detectFaces(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -55,6 +57,10 @@\nfunc detectFaces(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_face_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_label_detection{REGION_TAG_PARAMETER}]\n+\n // detectLabels gets labels from the Vision API for an image at the given file path.\n func detectLabels(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -75,6 +81,10 @@\nfunc detectLabels(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_label_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_landmark_detection{REGION_TAG_PARAMETER}]\n+\n // detectLandmarks gets landmarks from the Vision API for an image at the given file path.\n func detectLandmarks(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -95,6 +105,10 @@\nfunc detectLandmarks(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_landmark_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_text_detection{REGION_TAG_PARAMETER}]\n+\n // detectText gets text from the Vision API for an image at the given file path.\n func detectText(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -115,7 +129,9 @@\nfunc detectText(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_document{REGION_TAG_PARAMETER}]\n+// [END vision_text_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_fulltext_detection{REGION_TAG_PARAMETER}]\n \n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentText(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -157,7 +173,9 @@\nfunc detectDocumentText(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_document{REGION_TAG_PARAMETER}]\n+// [END vision_fulltext_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_image_property_detection{REGION_TAG_PARAMETER}]\n \n // detectProperties gets image properties from the Vision API for an image at the given file path.\n func detectProperties(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -179,6 +197,10 @@\nfunc detectProperties(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_image_property_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_crop_hint_detection{REGION_TAG_PARAMETER}]\n+\n // detectCropHints gets suggested croppings the Vision API for an image at the given file path.\n func detectCropHints(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -197,7 +219,9 @@\nfunc detectCropHints(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_safe_search{REGION_TAG_PARAMETER}]\n+// [END vision_crop_hint_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_safe_search_detection{REGION_TAG_PARAMETER}]\n \n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearch(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -217,9 +241,9 @@\nfunc detectSafeSearch(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_safe_search{REGION_TAG_PARAMETER}]\n+// [END vision_safe_search_detection{REGION_TAG_PARAMETER}]\n \n-// [START vision_detect_web{REGION_TAG_PARAMETER}]\n+// [START vision_web_detection{REGION_TAG_PARAMETER}]\n \n // detectWeb gets image properties from the Vision API for an image at the given file path.\n func detectWeb(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -259,9 +283,9 @@\nfunc detectWeb(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_web{REGION_TAG_PARAMETER}]\n+// [END vision_web_detection{REGION_TAG_PARAMETER}]\n \n-// [START vision_web_entities_include_geo_results{REGION_TAG_PARAMETER}]\n+// [START vision_web_detection_include_geo{REGION_TAG_PARAMETER}]\n \n // detectWebGeo detects geographic metadata from the Vision API for an image at the given file path.\n func detectWebGeo(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -287,7 +311,9 @@\nfunc detectWebGeo(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_web_entities_include_geo_results{REGION_TAG_PARAMETER}]\n+// [END vision_web_detection_include_geo{REGION_TAG_PARAMETER}]\n+\n+// [START vision_logo_detection{REGION_TAG_PARAMETER}]\n \n // detectLogos gets logos from the Vision API for an image at the given file path.\n func detectLogos(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -309,10 +335,12 @@\nfunc detectLogos(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_async_document{REGION_TAG_PARAMETER}]\n+// [END vision_logo_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_text_detection_pdf{REGION_TAG_PARAMETER}]\n \n-// detectAsyncDocument does Optical Character Recognition (OCR) on a PDF file\n-// stored in GCS.\n+// detectAsyncDocument performs Optical Character Recognition (OCR) on a\n+// PDF file stored in GCS.\n func detectAsyncDocument(w io.Writer, gcsSourceURI, gcsDestinationURI string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into orks",
        "commit_id": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -31,6 +31,8 @@\nfunc init() {\n \t_ = os.Open\n }\n \n+// [START vision_face_detection]\n+\n // detectFaces gets faces from the Vision API for an image at the given file path.\n func detectFaces(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -68,6 +70,10 @@\nfunc detectFaces(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_face_detection]\n+\n+// [START vision_label_detection]\n+\n // detectLabels gets labels from the Vision API for an image at the given file path.\n func detectLabels(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -104,6 +110,10 @@\nfunc detectLabels(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_label_detection]\n+\n+// [START vision_landmark_detection]\n+\n // detectLandmarks gets landmarks from the Vision API for an image at the given file path.\n func detectLandmarks(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -140,6 +150,10 @@\nfunc detectLandmarks(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_landmark_detection]\n+\n+// [START vision_text_detection]\n+\n // detectText gets text from the Vision API for an image at the given file path.\n func detectText(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -176,7 +190,9 @@\nfunc detectText(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_document]\n+// [END vision_text_detection]\n+\n+// [START vision_fulltext_detection]\n \n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentText(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -234,7 +250,9 @@\nfunc detectDocumentText(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_document]\n+// [END vision_fulltext_detection]\n+\n+// [START vision_image_property_detection]\n \n // detectProperties gets image properties from the Vision API for an image at the given file path.\n func detectProperties(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -272,6 +290,10 @@\nfunc detectProperties(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_image_property_detection]\n+\n+// [START vision_crop_hint_detection]\n+\n // detectCropHints gets suggested croppings the Vision API for an image at the given file path.\n func detectCropHints(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -306,7 +328,9 @@\nfunc detectCropHints(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_safe_search]\n+// [END vision_crop_hint_detection]\n+\n+// [START vision_safe_search_detection]\n \n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearch(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -342,9 +366,9 @@\nfunc detectSafeSearch(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_safe_search]\n+// [END vision_safe_search_detection]\n \n-// [START vision_detect_web]\n+// [START vision_web_detection]\n \n // detectWeb gets image properties from the Vision API for an image at the given file path.\n func detectWeb(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -400,9 +424,9 @@\nfunc detectWeb(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_web]\n+// [END vision_web_detection]\n \n-// [START vision_web_entities_include_geo_results]\n+// [START vision_web_detection_include_geo]\n \n // detectWebGeo detects geographic metadata from the Vision API for an image at the given file path.\n func detectWebGeo(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -444,7 +468,9 @@\nfunc detectWebGeo(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_web_entities_include_geo_results]\n+// [END vision_web_detection_include_geo]\n+\n+// [START vision_logo_detection]\n \n // detectLogos gets logos from the Vision API for an image at the given file path.\n func detectLogos(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -482,10 +508,12 @@\nfunc detectLogos(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_async_document]\n+// [END vision_logo_detection]\n+\n+// [START vision_text_detection_pdf]\n \n-// detectAsyncDocument does Optical Character Recognition (OCR) on a PDF file\n-// stored in GCS.\n+// detectAsyncDocument performs Optical Character Recognition (OCR) on a\n+// PDF file stored in GCS.\n func detectAsyncDocument(w io.Writer, gcsSourceURI, gcsDestinationURI string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -533,7 +561,7 @@\nfunc detectAsyncDocument(w io.Writer, gcsSourceURI, gcsDestinationURI string) er\n \treturn nil\n }\n \n-// [END vision_detect_async_document]\n+// [END vision_text_detection_pdf]\n \n func init() {\n \t// Refer to these functions so that goimports is happy before boilerplate is inserted.",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -542,6 +570,8 @@\nfunc init() {\n \t_ = os.Open\n }\n \n+// [START vision_face_detection_gcs]\n+\n // detectFaces gets faces from the Vision API for an image at the given file path.\n func detectFacesURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -570,6 +600,10 @@\nfunc detectFacesURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_face_detection_gcs]\n+\n+// [START vision_label_detection_gcs]\n+\n // detectLabels gets labels from the Vision API for an image at the given file path.\n func detectLabelsURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -597,6 +631,10 @@\nfunc detectLabelsURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_label_detection_gcs]\n+\n+// [START vision_landmark_detection_gcs]\n+\n // detectLandmarks gets landmarks from the Vision API for an image at the given file path.\n func detectLandmarksURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -624,6 +662,10 @@\nfunc detectLandmarksURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_landmark_detection_gcs]\n+\n+// [START vision_text_detection_gcs]\n+\n // detectText gets text from the Vision API for an image at the given file path.\n func detectTextURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -651,7 +693,9 @@\nfunc detectTextURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_document_uri]\n+// [END vision_text_detection_gcs]\n+\n+// [START vision_fulltext_detection_gcs]\n \n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentTextURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -700,7 +744,9 @@\nfunc detectDocumentTextURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_document_uri]\n+// [END vision_fulltext_detection_gcs]\n+\n+// [START vision_image_property_detection_gcs]\n \n // detectProperties gets image properties from the Vision API for an image at the given file path.\n func detectPropertiesURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -729,6 +775,10 @@\nfunc detectPropertiesURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_image_property_detection_gcs]\n+\n+// [START vision_crop_hint_detection_gcs]\n+\n // detectCropHints gets suggested croppings the Vision API for an image at the given file path.\n func detectCropHintsURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -754,7 +804,9 @@\nfunc detectCropHintsURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_safe_search_uri]\n+// [END vision_crop_hint_detection_gcs]\n+\n+// [START vision_safe_search_detection_gcs]\n \n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearchURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -781,9 +833,9 @@\nfunc detectSafeSearchURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_safe_search_uri]\n+// [END vision_safe_search_detection_gcs]\n \n-// [START vision_detect_web_uri]\n+// [START vision_web_detection_gcs]\n \n // detectWeb gets image properties from the Vision API for an image at the given file path.\n func detectWebURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -830,9 +882,9 @@\nfunc detectWebURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_web_uri]\n+// [END vision_web_detection_gcs]\n \n-// [START vision_web_entities_include_geo_results_uri]\n+// [START vision_web_detection_include_geo_gcs]\n \n // detectWebGeo detects geographic metadata from the Vision API for an image at the given file path.\n func detectWebGeoURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -865,7 +917,9 @@\nfunc detectWebGeoURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_web_entities_include_geo_results_uri]\n+// [END vision_web_detection_include_geo_gcs]\n+\n+// [START vision_logo_detection_gcs]\n \n // detectLogos gets logos from the Vision API for an image at the given file path.\n func detectLogosURI(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -894,10 +948,12 @@\nfunc detectLogosURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_async_document_uri]\n+// [END vision_logo_detection_gcs]\n+\n+// [START vision_text_detection_pdf_gcs]\n \n-// detectAsyncDocument does Optical Character Recognition (OCR) on a PDF file\n-// stored in GCS.\n+// detectAsyncDocument performs Optical Character Recognition (OCR) on a\n+// PDF file stored in GCS.\n func detectAsyncDocumentURI(w io.Writer, gcsSourceURI, gcsDestinationURI string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -34,6 +34,8 @@\nfunc init() {\n \t_ = os.Open\n }\n \n+// [START vision_face_detection{REGION_TAG_PARAMETER}]\n+\n // detectFaces gets faces from the Vision API for an image at the given file path.\n func detectFaces(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -55,6 +57,10 @@\nfunc detectFaces(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_face_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_label_detection{REGION_TAG_PARAMETER}]\n+\n // detectLabels gets labels from the Vision API for an image at the given file path.\n func detectLabels(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -75,6 +81,10 @@\nfunc detectLabels(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_label_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_landmark_detection{REGION_TAG_PARAMETER}]\n+\n // detectLandmarks gets landmarks from the Vision API for an image at the given file path.\n func detectLandmarks(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -95,6 +105,10 @@\nfunc detectLandmarks(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_landmark_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_text_detection{REGION_TAG_PARAMETER}]\n+\n // detectText gets text from the Vision API for an image at the given file path.\n func detectText(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -115,7 +129,9 @@\nfunc detectText(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_document{REGION_TAG_PARAMETER}]\n+// [END vision_text_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_fulltext_detection{REGION_TAG_PARAMETER}]\n \n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentText(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -157,7 +173,9 @@\nfunc detectDocumentText(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_document{REGION_TAG_PARAMETER}]\n+// [END vision_fulltext_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_image_property_detection{REGION_TAG_PARAMETER}]\n \n // detectProperties gets image properties from the Vision API for an image at the given file path.\n func detectProperties(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -179,6 +197,10 @@\nfunc detectProperties(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END vision_image_property_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_crop_hint_detection{REGION_TAG_PARAMETER}]\n+\n // detectCropHints gets suggested croppings the Vision API for an image at the given file path.\n func detectCropHints(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -197,7 +219,9 @@\nfunc detectCropHints(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_safe_search{REGION_TAG_PARAMETER}]\n+// [END vision_crop_hint_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_safe_search_detection{REGION_TAG_PARAMETER}]\n \n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearch(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -217,9 +241,9 @@\nfunc detectSafeSearch(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_safe_search{REGION_TAG_PARAMETER}]\n+// [END vision_safe_search_detection{REGION_TAG_PARAMETER}]\n \n-// [START vision_detect_web{REGION_TAG_PARAMETER}]\n+// [START vision_web_detection{REGION_TAG_PARAMETER}]\n \n // detectWeb gets image properties from the Vision API for an image at the given file path.\n func detectWeb(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -259,9 +283,9 @@\nfunc detectWeb(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_detect_web{REGION_TAG_PARAMETER}]\n+// [END vision_web_detection{REGION_TAG_PARAMETER}]\n \n-// [START vision_web_entities_include_geo_results{REGION_TAG_PARAMETER}]\n+// [START vision_web_detection_include_geo{REGION_TAG_PARAMETER}]\n \n // detectWebGeo detects geographic metadata from the Vision API for an image at the given file path.\n func detectWebGeo(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -287,7 +311,9 @@\nfunc detectWebGeo(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [END vision_web_entities_include_geo_results{REGION_TAG_PARAMETER}]\n+// [END vision_web_detection_include_geo{REGION_TAG_PARAMETER}]\n+\n+// [START vision_logo_detection{REGION_TAG_PARAMETER}]\n \n // detectLogos gets logos from the Vision API for an image at the given file path.\n func detectLogos(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -309,10 +335,12 @@\nfunc detectLogos(w io.Writer, file string) error {\n \treturn nil\n }\n \n-// [START vision_detect_async_document{REGION_TAG_PARAMETER}]\n+// [END vision_logo_detection{REGION_TAG_PARAMETER}]\n+\n+// [START vision_text_detection_pdf{REGION_TAG_PARAMETER}]\n \n-// detectAsyncDocument does Optical Character Recognition (OCR) on a PDF file\n-// stored in GCS.\n+// detectAsyncDocument performs Optical Character Recognition (OCR) on a\n+// PDF file stored in GCS.\n func detectAsyncDocument(w io.Writer, gcsSourceURI, gcsDestinationURI string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into region-tags",
        "commit_id": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "BigQuery: snippets for partitioning and clustering.",
        "pr_number": 553,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -69,7 +69,10 @@\nimport (\n // [START bigquery_update_dataset_expiration]\n // [START bigquery_update_table_description]\n // [START bigquery_update_table_expiration]\n+// To run this sample, you will need to create (or reuse) a context and\n+// an instance of the bigquery client.  For example:\n // import \"cloud.google.com/go/bigquery\"\n+// ctx := context.Background()\n // client, err := bigquery.NewClient(ctx, \"your-project-id\")\n // [END bigquery_browse_table]\n // [END bigquery_copy_table]",
        "comments": [
            {
                "comment": "s/metaData/metadata/g\r\n\r\nI think it's one word?",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments.",
        "commit_id": "b76562f688074064ce858b227efb815a6de9f30f"
    },
    {
        "pr_title": "tasks: add tasks pull_queue sample snippets",
        "pr_number": 550,
        "file_name": "tasks/pull_queue/create_task.go",
        "code_diff": "@@ -5,6 +5,8 @@\n// Package snippets is a collection of sample code snippets.\n package snippets\n \n+// [START cloud_tasks_create_task]\n+\n import (\n \t\"encoding/base64\"\n \t\"fmt\"",
        "comments": [],
        "commit_message": "tasks: include import statement in snippets",
        "commit_id": "4117923b8cbc31139a5db48b185dc821fa589417"
    },
    {
        "pr_title": "tasks: add tasks pull_queue sample snippets",
        "pr_number": 550,
        "file_name": "tasks/pull_queue/lease_task.go",
        "code_diff": "@@ -5,6 +5,8 @@\n// Package snippets is a collection of sample code snippets.\n package snippets\n \n+// [START cloud_tasks_lease_and_acknowledge_task]\n+\n import (\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_message": "tasks: include import statement in snippets",
        "commit_id": "4117923b8cbc31139a5db48b185dc821fa589417"
    },
    {
        "pr_title": "monitoring/uptime: add update sample",
        "pr_number": 547,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -111,17 +111,13 @@\nfunc TestAll(t *testing.T) {\n \n \tinferred := uniqueBQName(\"golang_example_table_inferred\")\n \texplicit := uniqueBQName(\"golang_example_table_explicit\")\n-\tempty := uniqueBQName(\"golang_example_table_emptyschema\")\n \n \tif err := createTableInferredSchema(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"createTableInferredSchema(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n \tif err := createTableExplicitSchema(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"createTableExplicitSchema(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n-\tif err := createTableEmptySchema(client, datasetID, empty); err != nil {\n-\t\tt.Errorf(\"createTableEmptySchema(dataset:%q table:%q): %v\", datasetID, empty, err)\n-\t}\n \n \tif err := updateTableDescription(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"updateTableDescription(dataset:%q table:%q): %v\", datasetID, explicit, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into uptime",
        "commit_id": "6e780460158d21afb673c90ab816411ddc5a1573"
    },
    {
        "pr_title": "testing: add test for spurious region tags in go docs",
        "pr_number": 543,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -80,7 +80,7 @@\nfunc list(client *pubsub.Client) ([]*pubsub.Subscription, error) {\n \treturn subs, nil\n }\n \n-func pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n+func pullMsgs(client *pubsub.Client, subName string, topic *pubsub.Topic) error {\n \tctx := context.Background()\n \n \t// Publish 10 messages on the topic.",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix-docs",
        "commit_id": "8f5c5403c1a487345e4a463b2df21ee26fc265ef"
    },
    {
        "pr_title": "testing: add test for spurious region tags in go docs",
        "pr_number": 543,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -105,7 +105,7 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \t// Consume 10 messages.\n \tvar mu sync.Mutex\n \treceived := 0\n-\tsub := client.Subscription(name)\n+\tsub := client.Subscription(subName)\n \tcctx, cancel := context.WithCancel(ctx)\n \terr := sub.Receive(cctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\tmsg.Ack()",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix-docs",
        "commit_id": "8f5c5403c1a487345e4a463b2df21ee26fc265ef"
    },
    {
        "pr_title": "testing: add test for spurious region tags in go docs",
        "pr_number": 543,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -125,12 +125,12 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \treturn nil\n }\n \n-func pullMsgsError(client *pubsub.Client, name string) error {\n+func pullMsgsError(client *pubsub.Client, subName string) error {\n \tctx := context.Background()\n \t// [START pubsub_subscriber_error_listener]\n \t// If the service returns a non-retryable error, Receive returns that error after\n \t// all of the outstanding calls to the handler have returned.\n-\terr := client.Subscription(name).Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n+\terr := client.Subscription(subName).Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\tfmt.Printf(\"Got message: %q\\n\", string(msg.Data))\n \t\tmsg.Ack()\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix-docs",
        "commit_id": "8f5c5403c1a487345e4a463b2df21ee26fc265ef"
    },
    {
        "pr_title": "testing: add test for spurious region tags in go docs",
        "pr_number": 543,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -141,10 +141,10 @@\nfunc pullMsgsError(client *pubsub.Client, name string) error {\n \treturn nil\n }\n \n-func pullMsgsSettings(client *pubsub.Client, name string) error {\n+func pullMsgsSettings(client *pubsub.Client, subName string) error {\n \tctx := context.Background()\n \t// [START pubsub_subscriber_flow_settings]\n-\tsub := client.Subscription(name)\n+\tsub := client.Subscription(subName)\n \tsub.ReceiveSettings.MaxOutstandingMessages = 10\n \terr := sub.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\tfmt.Printf(\"Got message: %q\\n\", string(msg.Data))",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix-docs",
        "commit_id": "8f5c5403c1a487345e4a463b2df21ee26fc265ef"
    },
    {
        "pr_title": "testing: add test for spurious region tags in go docs",
        "pr_number": 543,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -157,10 +157,10 @@\nfunc pullMsgsSettings(client *pubsub.Client, name string) error {\n \treturn nil\n }\n \n-func create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n+func create(client *pubsub.Client, subName string, topic *pubsub.Topic) error {\n \tctx := context.Background()\n \t// [START pubsub_create_pull_subscription]\n-\tsub, err := client.CreateSubscription(ctx, name, pubsub.SubscriptionConfig{\n+\tsub, err := client.CreateSubscription(ctx, subName, pubsub.SubscriptionConfig{\n \t\tTopic:       topic,\n \t\tAckDeadline: 20 * time.Second,\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix-docs",
        "commit_id": "8f5c5403c1a487345e4a463b2df21ee26fc265ef"
    },
    {
        "pr_title": "testing: add test for spurious region tags in go docs",
        "pr_number": 543,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -172,12 +172,12 @@\nfunc create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \treturn nil\n }\n \n-func createWithEndpoint(client *pubsub.Client, name string, topic *pubsub.Topic, endpoint string) error {\n+func createWithEndpoint(client *pubsub.Client, subName string, topic *pubsub.Topic, endpoint string) error {\n \tctx := context.Background()\n \t// [START pubsub_create_push_subscription]\n \n \t// For example, endpoint is \"https://my-test-project.appspot.com/push\".\n-\tsub, err := client.CreateSubscription(ctx, name, pubsub.SubscriptionConfig{\n+\tsub, err := client.CreateSubscription(ctx, subName, pubsub.SubscriptionConfig{\n \t\tTopic:       topic,\n \t\tAckDeadline: 10 * time.Second,\n \t\tPushConfig:  pubsub.PushConfig{Endpoint: endpoint},",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix-docs",
        "commit_id": "8f5c5403c1a487345e4a463b2df21ee26fc265ef"
    },
    {
        "pr_title": "testing: add test for spurious region tags in go docs",
        "pr_number": 543,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -190,12 +190,12 @@\nfunc createWithEndpoint(client *pubsub.Client, name string, topic *pubsub.Topic,\n \treturn nil\n }\n \n-func updateEndpoint(client *pubsub.Client, name string, endpoint string) error {\n+func updateEndpoint(client *pubsub.Client, subName string, endpoint string) error {\n \tctx := context.Background()\n \t// [START pubsub_update_push_configuration]\n \n \t// For example, endpoint is \"https://my-test-project.appspot.com/push\".\n-\tsubConfig, err := client.Subscription(name).Update(ctx, pubsub.SubscriptionConfigToUpdate{\n+\tsubConfig, err := client.Subscription(subName).Update(ctx, pubsub.SubscriptionConfigToUpdate{\n \t\tPushConfig: &pubsub.PushConfig{Endpoint: endpoint},\n \t})\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix-docs",
        "commit_id": "8f5c5403c1a487345e4a463b2df21ee26fc265ef"
    },
    {
        "pr_title": "testing: add test for spurious region tags in go docs",
        "pr_number": 543,
        "file_name": "videointelligence/video_analyze/gen/template.go",
        "code_diff": "@@ -56,7 +56,7 @@\nfunc boilerplate() { //# omit\n \t//# enddef\n } //# omit\n \n-// [START video_analyze_labels_local] //# include if !gcs\n+// [START video_analyze_labels] //# include if !gcs\n // [START video_analyze_labels_gcs] //# include if gcs\n \n func label__SUFFIX__(w io.Writer, file string) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix-docs",
        "commit_id": "8f5c5403c1a487345e4a463b2df21ee26fc265ef"
    },
    {
        "pr_title": "testing: add test for spurious region tags in go docs",
        "pr_number": 543,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -16,7 +16,7 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n-// [START video_analyze_labels_local]\n+// [START video_analyze_labels]\n \n func label(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into fix-docs",
        "commit_id": "8f5c5403c1a487345e4a463b2df21ee26fc265ef"
    },
    {
        "pr_title": "profiler: Add flags to configure version and function skew",
        "pr_number": 527,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -480,6 +480,59 @@\nfunc detectLogos(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [START vision_detect_async_document]\n+\n+// detectAsyncDocument does Optical Character Recognition (OCR) on a PDF file\n+// stored in GCS.\n+func detectAsyncDocument(w io.Writer, gcsSourceURI, gcsDestinationURI string) error {\n+\tctx := context.Background()\n+\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\trequest := &visionpb.AsyncBatchAnnotateFilesRequest{\n+\t\tRequests: []*visionpb.AsyncAnnotateFileRequest{\n+\t\t\t{\n+\t\t\t\tFeatures: []*visionpb.Feature{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tType: visionpb.Feature_DOCUMENT_TEXT_DETECTION,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tInputConfig: &visionpb.InputConfig{\n+\t\t\t\t\tGcsSource: &visionpb.GcsSource{Uri: gcsSourceURI},\n+\t\t\t\t\t// Supported MimeTypes are: \"application/pdf\" and \"image/tiff\".\n+\t\t\t\t\tMimeType: \"application/pdf\",\n+\t\t\t\t},\n+\t\t\t\tOutputConfig: &visionpb.OutputConfig{\n+\t\t\t\t\tGcsDestination: &visionpb.GcsDestination{Uri: gcsDestinationURI},\n+\t\t\t\t\t// How many pages should be grouped into each json output file.\n+\t\t\t\t\tBatchSize: 2,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\toperation, err := client.AsyncBatchAnnotateFiles(ctx, request)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Fprintf(w, \"Waiting for the operation to finish.\")\n+\n+\tresp, err := operation.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Fprintf(w, \"%v\", resp)\n+\n+\treturn nil\n+}\n+\n+// [END vision_detect_async_document]\n+\n func init() {\n \t// Refer to these functions so that goimports is happy before boilerplate is inserted.\n \t_ = context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-flags",
        "commit_id": "1102060fbd30f21e3f13b72e76d8bd6baaaac1e0"
    },
    {
        "pr_title": "profiler: Add flags to configure version and function skew",
        "pr_number": 527,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -6,9 +6,15 @@\npackage main\n \n import (\n \t\"bytes\"\n+\t\"fmt\"\n \t\"io\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n+\n+\t\"cloud.google.com/go/storage\"\n+\t\"golang.org/x/net/context\"\n+\t\"google.golang.org/api/iterator\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into add-flags",
        "commit_id": "1102060fbd30f21e3f13b72e76d8bd6baaaac1e0"
    },
    {
        "pr_title": "jobs: check in Cloud Job Discovery quick start ",
        "pr_number": 526,
        "file_name": "jobs/quickstart/main.go",
        "code_diff": "@@ -4,7 +4,7 @@\n// [START quick_start]\n \n-// This is a quickstart sample of using the Google Cloud Job Discovery API.\n+// Command quickstart is an example of using the Google Cloud Job Discovery API.\n package main\n \n import (",
        "comments": [
            {
                "comment": "Would you mind adding a package comment? It will show up in GoDoc (godoc.org). It should go on the line immediately before `package main`. For example,\r\n\r\n```\r\n// Sample quickstart is an example of using the Google Cloud Platform Jobs API.\r\npackage main\r\n```\r\n\r\nSee https://github.com/golang/go/wiki/CodeReviewComments#package-comments.",
                "position": null
            }
        ],
        "commit_message": "jobs: style updates",
        "commit_id": "89e7b0c486999fa22cb7386f8cab114b32d8539a"
    },
    {
        "pr_title": "jobs: check in Cloud Job Discovery quick start ",
        "pr_number": 526,
        "file_name": "jobs/quickstart/main_test.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2016 Google Inc. All rights reserved.\n+// Copyright 2018 Google Inc. All rights reserved.\n // Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.",
        "comments": [],
        "commit_message": "jobs: style updates",
        "commit_id": "89e7b0c486999fa22cb7386f8cab114b32d8539a"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -7,22 +7,25 @@\npackage main\n import (\n \t\"fmt\"\n \t\"html/template\"\n-\t\"io\"\n \t\"net/http\"\n-\t\"path\"\n-\t\"strings\"\n \t\"time\"\n \n-\t\"golang.org/x/net/context\"\n+\tfirebase \"firebase.google.com/go\"\n \t\"google.golang.org/appengine\"\n \t\"google.golang.org/appengine/datastore\"\n-\t\"google.golang.org/appengine/delay\"\n \t\"google.golang.org/appengine/log\"\n \n+\t// [START new_imports]\n+\t\"io\"\n+\t\"path\"\n+\t\"strings\"\n+\n \t\"cloud.google.com/go/storage\"\n \tvision \"cloud.google.com/go/vision/apiv1\"\n-\tfirebase \"firebase.google.com/go\"\n \tuuid \"github.com/satori/go.uuid\"\n+\t\"golang.org/x/net/context\"\n+\t\"google.golang.org/appengine/delay\"\n+\t// [END new_imports]\n )\n \n var (",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -34,12 +37,18 @@\nvar (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n+// [START label_struct]\n+\n // A Label is a description for a post's image.\n type Label struct {\n \tDescription string\n \tScore       float32\n }\n \n+// [END label_struct]\n+\n+// [START new_post_fields]\n+\n type Post struct {\n \tAuthor   string\n \tUserID   string",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -49,6 +58,8 @@\ntype Post struct {\n \tLabels   []Label\n }\n \n+// [END new_post_fields]\n+\n type templateParams struct {\n \tNotice  string\n \tName    string",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -61,6 +72,8 @@\nfunc main() {\n \tappengine.Main()\n }\n \n+// [START var_label_func]\n+\n // labelFunc will be called asynchronously as a Cloud Task. labelFunc can\n // be executed by calling labelFunc.Call(ctx, postID). If an error is returned\n // the function will be retried.",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -108,6 +121,10 @@\nvar labelFunc = delay.Func(\"label-image\", func(ctx context.Context, id int64) er\n \treturn nil\n })\n \n+// [END var_label_func]\n+\n+// [START upload_image]\n+\n // uploadFileFromForm uploads a file if it's present in the \"image\" form field.\n func uploadFileFromForm(ctx context.Context, r *http.Request) (url string, err error) {\n \t// Read the file from the form.",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -163,6 +180,8 @@\nfunc uploadFileFromForm(ctx context.Context, r *http.Request) (url string, err e\n \treturn fmt.Sprintf(publicURL, firebaseConfig.StorageBucket, name), nil\n }\n \n+// [END upload_image]\n+\n func indexHandler(w http.ResponseWriter, r *http.Request) {\n \tif r.URL.Path != \"/\" {\n \t\thttp.Redirect(w, r, \"/\", http.StatusFound)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -235,6 +254,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t}\n \tparams.Name = post.Author\n \n+\t// [START image_URL]\n \t// Get the image if there is one.\n \timageURL, err := uploadFileFromForm(ctx, r)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -244,7 +264,11 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n+\t// [END image_URL]\n+\n+\t// [START add_image_URL]\n \tpost.ImageURL = imageURL\n+\t// [END add_image_URL]\n \n \tkey := datastore.NewIncompleteKey(ctx, \"Post\", nil)\n \tif key, err = datastore.Put(ctx, key, &post); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "appengine/gophers/gophers-6/static/index.js",
        "code_diff": "@@ -23,7 +23,7 @@\nwindow.addEventListener('load', function () {\n       // User is signed in.\n       document.getElementById('sign-out').hidden = false;\n       document.getElementById('post-form').hidden = false;\n-      var account = document.getElementById('account-details').textContent =\n+      document.getElementById('account-details').textContent =\n           'Signed in as ' + user.displayName + ' (' + user.email + ')';\n       user.getIdToken().then(function (accessToken) {\n         // Add the token to the post form. The user info will be extracted",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "auth/snippets.go",
        "code_diff": "@@ -14,12 +14,14 @@\nimport (\n \t\"golang.org/x/oauth2/google\"\n \tcloudkms \"google.golang.org/api/cloudkms/v1\"\n \t\"google.golang.org/api/iterator\"\n+\t\"google.golang.org/api/option\"\n )\n \n-func adc() {\n-\tctx := context.Background()\n+// [START auth_cloud_implicit]\n \n-\t// [START auth_cloud_implicit]\n+// implicit uses Application Default Credentials to authenticate.\n+func implicit() {\n+\tctx := context.Background()\n \n \t// For API packages whose import path is starting with \"cloud.google.com/go\",\n \t// such as cloud.google.com/go/storage in this case, if there are no credentials",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -33,14 +33,14 @@\nfunc updateDatasetDescription(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_description]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n \t\tDescription: \"Updated Description.\",\n \t}\n-\tif _, err = ds.Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err = ds.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_description]",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -51,14 +51,14 @@\nfunc updateDatasetDefaultExpiration(client *bigquery.Client, datasetID string) e\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_expiration]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n \t\tDefaultTableExpiration: 24 * time.Hour,\n \t}\n-\tif _, err := client.Dataset(datasetID).Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err := client.Dataset(datasetID).Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_expiration]",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -69,13 +69,13 @@\nfunc updateDatasetAccessControl(client *bigquery.Client, datasetID string) error\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_access]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Append a new access control entry to the existing access list.\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n-\t\tAccess: append(original.Access, &bigquery.AccessEntry{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n+\t\tAccess: append(meta.Access, &bigquery.AccessEntry{\n \t\t\tRole:       bigquery.ReaderRole,\n \t\t\tEntityType: bigquery.UserEmailEntity,\n \t\t\tEntity:     \"sample.bigquery.dev@gmail.com\"},",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -84,13 +84,67 @@\nfunc updateDatasetAccessControl(client *bigquery.Client, datasetID string) error\n \n \t// Leverage the ETag for the update to assert there's been no modifications to the\n \t// dataset since the metadata was originally read.\n-\tif _, err := ds.Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_access]\n \treturn nil\n }\n \n+func datasetLabels(client *bigquery.Client, w io.Writer, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_dataset_labels]\n+\tmeta, err := client.Dataset(datasetID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Dataset %s labels:\\n\", datasetID)\n+\tif len(meta.Labels) == 0 {\n+\t\tfmt.Fprintln(w, \"Dataset has no labels defined.\")\n+\t\treturn nil\n+\t}\n+\tfor k, v := range meta.Labels {\n+\t\tfmt.Fprintf(w, \"\\t%s:%s\\n\", k, v)\n+\t}\n+\t// [END bigquery_get_dataset_labels]\n+\treturn nil\n+}\n+\n+func addDatasetLabel(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_label_dataset]\n+\tds := client.Dataset(datasetID)\n+\tmeta, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tupdate := bigquery.DatasetMetadataToUpdate{}\n+\tupdate.SetLabel(\"color\", \"green\")\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_label_dataset]\n+\treturn nil\n+}\n+\n+func deleteDatasetLabel(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_delete_label_dataset]\n+\tds := client.Dataset(datasetID)\n+\tmeta, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tupdate := bigquery.DatasetMetadataToUpdate{}\n+\tupdate.DeleteLabel(\"color\")\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_delete_label_dataset]\n+\treturn nil\n+}\n+\n func deleteEmptyDataset(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_delete_dataset]",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -116,6 +170,85 @@\nfunc listDatasets(client *bigquery.Client) error {\n \treturn nil\n }\n \n+func listDatasetsByLabel(client *bigquery.Client, w io.Writer) error {\n+\tctx := context.Background()\n+\t// [START bigquery_list_datasets_by_label]\n+\tit := client.Datasets(ctx)\n+\tit.Filter = \"labels.color:green\"\n+\tfor {\n+\t\tdataset, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"dataset: %s\\n\", dataset.DatasetID)\n+\t}\n+\t// [END bigquery_list_datasets_by_label]\n+\treturn nil\n+}\n+\n+func printDatasetInfo(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_dataset]\n+\tmeta, err := client.Dataset(datasetID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Printf(\"Dataset ID: %s\\n\", datasetID)\n+\tfmt.Printf(\"Description: %s\\n\", meta.Description)\n+\tfmt.Println(\"Labels:\")\n+\tfor k, v := range meta.Labels {\n+\t\tfmt.Printf(\"\\t%s: %s\", k, v)\n+\t}\n+\tfmt.Println(\"Tables:\")\n+\tit := client.Dataset(datasetID).Tables(ctx)\n+\n+\tcnt := 0\n+\tfor {\n+\t\tt, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tcnt++\n+\t\tfmt.Printf(\"\\t%s\\n\", t.TableID)\n+\t}\n+\tif cnt == 0 {\n+\t\tfmt.Println(\"\\tThis dataset does not contain any tables.\")\n+\t}\n+\t// [END bigquery_get_dataset]\n+\treturn nil\n+}\n+\n+func listJobs(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_list_jobs]\n+\tit := client.Jobs(ctx)\n+\tfor i := 0; i < 10; i++ {\n+\t\tj, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tstate := \"Unknown\"\n+\t\tswitch j.LastStatus().State {\n+\t\tcase bigquery.Pending:\n+\t\t\tstate = \"Pending\"\n+\t\tcase bigquery.Running:\n+\t\t\tstate = \"Running\"\n+\t\tcase bigquery.Done:\n+\t\t\tstate = \"Done\"\n+\t\t}\n+\t\tfmt.Printf(\"Job %s in state %s\\n\", j.ID(), state)\n+\t}\n+\t// [END bigquery_list_jobs]\n+\treturn nil\n+}\n+\n // Item represents a row item.\n type Item struct {\n \tName string",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -178,14 +311,14 @@\nfunc updateTableDescription(client *bigquery.Client, datasetID, tableID string)\n \tctx := context.Background()\n \t// [START bigquery_update_table_description]\n \ttableRef := client.Dataset(datasetID).Table(tableID)\n-\toriginal, err := tableRef.Metadata(ctx)\n+\tmeta, err := tableRef.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tnewMeta := bigquery.TableMetadataToUpdate{\n+\tupdate := bigquery.TableMetadataToUpdate{\n \t\tDescription: \"Updated description.\",\n \t}\n-\tif _, err = tableRef.Update(ctx, newMeta, original.ETag); err != nil {\n+\tif _, err = tableRef.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_table_description]",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -197,21 +330,75 @@\nfunc updateTableExpiration(client *bigquery.Client, datasetID, tableID string) e\n \tctx := context.Background()\n \t// [START bigquery_update_table_expiration]\n \ttableRef := client.Dataset(datasetID).Table(tableID)\n-\toriginal, err := tableRef.Metadata(ctx)\n+\tmeta, err := tableRef.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tnewMeta := bigquery.TableMetadataToUpdate{\n+\tupdate := bigquery.TableMetadataToUpdate{\n \t\tExpirationTime: time.Now().Add(time.Duration(5*24) * time.Hour), // table expiration in 5 days.\n \t}\n-\tif _, err = tableRef.Update(ctx, newMeta, original.ETag); err != nil {\n+\tif _, err = tableRef.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_table_expiration]\n \treturn nil\n \n }\n \n+func tableLabels(client *bigquery.Client, w io.Writer, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_table_labels]\n+\tmeta, err := client.Dataset(datasetID).Table(tableID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Table %s labels:\\n\", datasetID)\n+\tif len(meta.Labels) == 0 {\n+\t\tfmt.Println(\"Table has no labels defined.\")\n+\t\treturn nil\n+\t}\n+\tfor k, v := range meta.Labels {\n+\t\tfmt.Fprintf(w, \"\\t%s:%s\\n\", k, v)\n+\t}\n+\t// [END bigquery_get_table_labels]\n+\treturn nil\n+}\n+\n+func addTableLabel(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_label_table]\n+\ttbl := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tbl.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tupdate := bigquery.TableMetadataToUpdate{}\n+\tupdate.SetLabel(\"color\", \"green\")\n+\tif _, err := tbl.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_label_table]\n+\treturn nil\n+}\n+\n+func deleteTableLabel(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_delete_label_table]\n+\ttbl := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tbl.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tupdate := bigquery.TableMetadataToUpdate{}\n+\tupdate.DeleteLabel(\"color\")\n+\tif _, err := tbl.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_delete_label_table]\n+\treturn nil\n+}\n+\n func listTables(client *bigquery.Client, w io.Writer, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_list_tables]",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -246,73 +433,250 @@\nfunc insertRows(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n-func listRows(client *bigquery.Client, datasetID, tableID string) error {\n-\tctx := context.Background()\n-\tq := client.Query(fmt.Sprintf(`\n-\t\tSELECT name, age\n-\t\tFROM %s.%s\n-\t\tWHERE age >= 20\n-\t`, datasetID, tableID))\n-\tit, err := q.Read(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\tfor {\n-\t\tvar row []bigquery.Value\n-\t\terr := it.Next(&row)\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Println(row)\n-\t}\n-\treturn nil\n-}\n-\n-func basicQuery(client *bigquery.Client, datasetID, tableID string) error {\n+func queryBasic(client *bigquery.Client) error {\n \tctx := context.Background()\n \t// [START bigquery_query]\n+\n \tq := client.Query(\n \t\t\"SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` \" +\n \t\t\t\"WHERE state = \\\"TX\\\" \" +\n \t\t\t\"LIMIT 100\")\n \t// Location must match that of the dataset(s) referenced in the query.\n \tq.Location = \"US\"\n+\t// [END bigquery_query]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryDisableCache(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_no_cache]\n+\n+\tq := client.Query(\n+\t\t\"SELECT corpus FROM `bigquery-public-data.samples.shakespeare` GROUP BY corpus;\")\n+\tq.DisableQueryCache = true\n+\t// Location must match that of the dataset(s) referenced in the query.\n+\tq.Location = \"US\"\n+\t// [END bigquery_query_no_cache]\n \n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryBatch(client *bigquery.Client, dstDatasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_batch]\n+\t// Build an aggregate table.\n+\tq := client.Query(`\n+\t\tSELECT\n+  \t\t\tcorpus,\n+  \t\t\tSUM(word_count) as total_words,\n+  \t\t\tCOUNT(1) as unique_words\n+\t\tFROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+\t\tGROUP BY corpus;`)\n+\tq.Priority = bigquery.BatchPriority\n+\tq.QueryConfig.Dst = client.Dataset(dstDatasetID).Table(dstTableID)\n+\n+\t// Start the job.\n \tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n+\t// Job is started and will progress without interaction.\n+\t// To simulate other work being done, sleep a few seconds.\n+\ttime.Sleep(5 * time.Second)\n+\tstatus, err := job.Status(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n \n-\t// Wait until async querying is done.\n-\tstatus, err := job.Wait(ctx)\n+\tstate := \"Unknown\"\n+\tswitch status.State {\n+\tcase bigquery.Pending:\n+\t\tstate = \"Pending\"\n+\tcase bigquery.Running:\n+\t\tstate = \"Running\"\n+\tcase bigquery.Done:\n+\t\tstate = \"Done\"\n+\t}\n+\t// You can continue to monitor job progress until it reaches\n+\t// the Done state by polling periodically.  In this example,\n+\t// we print the latest status.\n+\tfmt.Printf(\"Job %s in Location %s currently in state: %s\\n\", job.ID(), job.Location(), state)\n+\n+\t// [END bigquery_query_batch]\n+\tjob.Cancel(ctx)\n+\treturn nil\n+}\n+\n+func queryDryRun(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_dry_run]\n+\tq := client.Query(`\n+\tSELECT\n+\t\tname,\n+\t\tCOUNT(*) as name_count\n+\tFROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n+\tWHERE state = 'WA'\n+\tGROUP BY name`)\n+\tq.DryRun = true\n+\t// Location must match that of the dataset(s) referenced in the query.\n+\tq.Location = \"US\"\n+\n+\tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tif err := status.Err(); err != nil {\n+\t// Dry run is not asynchronous, so get the latest status and statistics.\n+\tstatus := job.LastStatus()\n+\tif err != nil {\n \t\treturn err\n \t}\n+\tfmt.Printf(\"This query will process %d bytes\\n\", status.Statistics.TotalBytesProcessed)\n+\t// [END bigquery_query_dry_run]\n+\treturn nil\n+}\n \n-\tit, err := job.Read(ctx)\n-\tfor {\n-\t\tvar row []bigquery.Value\n-\t\terr := it.Next(&row)\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Println(row)\n+func queryWithDestination(client *bigquery.Client, destDatasetID, destTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_destination_table]\n+\n+\tq := client.Query(\"SELECT 17 as my_col\")\n+\tq.Location = \"US\" // Location must match the dataset(s) referenced in query.\n+\tq.QueryConfig.Dst = client.Dataset(destDatasetID).Table(destTableID)\n+\t// [END bigquery_query_destination_table]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryLegacy(client *bigquery.Client, sqlString string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_legacy]\n+\tq := client.Query(sqlString)\n+\tq.UseLegacySQL = true\n+\n+\t// [END bigquery_query_legacy]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryLegacyLargeResults(client *bigquery.Client, dstDatasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_legacy_large_results]\n+\tq := client.Query(\n+\t\t\"SELECT corpus FROM [bigquery-public-data:samples.shakespeare] GROUP BY corpus;\")\n+\tq.UseLegacySQL = true\n+\tq.AllowLargeResults = true\n+\tq.QueryConfig.Dst = client.Dataset(dstDatasetID).Table(dstTableID)\n+\t// [END bigquery_query_legacy_large_results]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithArrayParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_arrays]\n+\tq := client.Query(\n+\t\t`SELECT\n+\t\t\tname,\n+\t\t\tsum(number) as count \n+        FROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n+\t\tWHERE\n+\t\t\tgender = @gender\n+        \tAND state IN UNNEST(@states)\n+\t\tGROUP BY\n+\t\t\tname\n+\t\tORDER BY\n+\t\t\tcount DESC\n+\t\tLIMIT 10;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"gender\",\n+\t\t\tValue: \"M\",\n+\t\t},\n+\t\t{\n+\t\t\tName:  \"states\",\n+\t\t\tValue: []string{\"WA\", \"WI\", \"WV\", \"WY\"},\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_arrays]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithNamedParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_named]\n+\tq := client.Query(\n+\t\t`SELECT word, word_count\n+        FROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+        WHERE corpus = @corpus\n+        AND word_count >= @min_word_count\n+        ORDER BY word_count DESC;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"corpus\",\n+\t\t\tValue: \"romeoandjuliet\",\n+\t\t},\n+\t\t{\n+\t\t\tName:  \"min_word_count\",\n+\t\t\tValue: 250,\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_named]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithPositionalParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_positional]\n+\tq := client.Query(\n+\t\t`SELECT word, word_count\n+        FROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+        WHERE corpus = ?\n+        AND word_count >= ?\n+        ORDER BY word_count DESC;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tValue: \"romeoandjuliet\",\n+\t\t},\n+\t\t{\n+\t\t\tValue: 250,\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_positional]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithTimestampParam(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_timestamps]\n+\tq := client.Query(\n+\t\t`SELECT TIMESTAMP_ADD(@ts_value, INTERVAL 1 HOUR);`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"ts_value\",\n+\t\t\tValue: time.Date(2016, 12, 7, 8, 0, 0, 0, time.UTC),\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_timestamps]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithStructParam(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_structs]\n+\ttype MyStruct struct {\n+\t\tX int64\n+\t\tY string\n \t}\n-\t// [END bigquery_query]\n-\treturn nil\n+\tq := client.Query(\n+\t\t`SELECT @struct_value as s;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"struct_value\",\n+\t\t\tValue: MyStruct{X: 1, Y: \"foo\"},\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_structs]\n+\treturn runAndRead(ctx, client, q)\n }\n \n-func printTableMetadataSimple(client *bigquery.Client, datasetID, tableID string) error {\n+func printTableInfo(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_table]\n \tmeta, err := client.Dataset(datasetID).Table(tableID).Metadata(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -322,7 +686,7 @@\nfunc printTableMetadataSimple(client *bigquery.Client, datasetID, tableID string\n \t// Print basic information about the table.\n \tfmt.Printf(\"Schema has %d top-level fields\\n\", len(meta.Schema))\n \tfmt.Printf(\"Description: %s\\n\", meta.Description)\n-\tfmt.Printf(\"Row in managed storage: %d\\n\", meta.NumRows)\n+\tfmt.Printf(\"Rows in managed storage: %d\\n\", meta.NumRows)\n \t// [END bigquery_get_table]\n \treturn nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -368,6 +732,66 @@\nfunc copyTable(client *bigquery.Client, datasetID, srcID, dstID string) error {\n \treturn nil\n }\n \n+// generateTableCTAS creates a quick table by issuing a CREATE TABLE AS SELECT\n+// query.\n+func generateTableCTAS(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\tq := client.Query(\n+\t\tfmt.Sprintf(\n+\t\t\t`CREATE TABLE %s.%s \n+\t\tAS\n+\t\tSELECT\n+\t\t  2000 + CAST(18 * RAND() as INT64) as year,\n+\t\t  IF(RAND() > 0.5,\"foo\",\"bar\") as token\n+\t\tFROM\n+\t\t  UNNEST(GENERATE_ARRAY(0,5,1)) as r`, datasetID, tableID))\n+\tjob, err := q.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\treturn nil\n+}\n+\n+func copyMultiTable(client *bigquery.Client, datasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// Generate some dummy tables via a quick CTAS.\n+\tif err := generateTableCTAS(client, datasetID, \"table1\"); err != nil {\n+\t\treturn err\n+\t}\n+\tif err := generateTableCTAS(client, datasetID, \"table2\"); err != nil {\n+\t\treturn err\n+\t}\n+\t// [START bigquery_copy_table_multiple_source]\n+\tdataset := client.Dataset(datasetID)\n+\n+\tsrcTableIDs := []string{\"table1\", \"table2\"}\n+\tvar tableRefs []*bigquery.Table\n+\tfor _, v := range srcTableIDs {\n+\t\ttableRefs = append(tableRefs, dataset.Table(v))\n+\t}\n+\tcopier := dataset.Table(dstTableID).CopierFrom(tableRefs...)\n+\tcopier.WriteDisposition = bigquery.WriteTruncate\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_copy_table_multiple_source]\n+\treturn nil\n+}\n func deleteTable(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_delete_table]",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -379,6 +803,49 @@\nfunc deleteTable(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n+func deleteAndUndeleteTable(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_undelete_table]\n+\n+\tds := client.Dataset(datasetID)\n+\tif _, err := ds.Table(tableID).Metadata(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\t// Record the current time.  We'll use this as the snapshot time\n+\t// for recovering the table.\n+\tsnapTime := time.Now()\n+\n+\t// \"Accidentally\" delete the table.\n+\tif err := client.Dataset(datasetID).Table(tableID).Delete(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Construct the restore-from tableID using a snapshot decorator.\n+\tsnapshotTableID := fmt.Sprintf(\"%s@%d\", tableID, snapTime.UnixNano()/1e6)\n+\t// Choose a new table ID for the recovered table data.\n+\trecoverTableID := fmt.Sprintf(\"%s_recovered\", tableID)\n+\n+\t// Construct and run a copy job.\n+\tcopier := ds.Table(recoverTableID).CopierFrom(ds.Table(snapshotTableID))\n+\tcopier.WriteDisposition = bigquery.WriteTruncate\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// [END bigquery_undelete_table]\n+\tds.Table(recoverTableID).Delete(ctx)\n+\treturn nil\n+\n+}\n+\n func importCSVFromFile(client *bigquery.Client, datasetID, tableID, filename string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_from_file]",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -7,8 +7,7 @@\npackage snippets\n import (\n \t\"bytes\"\n \t\"fmt\"\n-\t\"log\"\n-\t\"os\"\n+\t\"regexp\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -17,24 +16,34 @@\nimport (\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"golang.org/x/net/context\"\n-\t\"golang.org/x/oauth2/google\"\n-\trawbq \"google.golang.org/api/bigquery/v2\"\n \t\"google.golang.org/api/iterator\"\n )\n \n-func init() {\n-\t// Workaround for Travis:\n-\t// https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received\n-\tif os.Getenv(\"TRAVIS\") == \"true\" {\n-\t\tgo func() {\n-\t\t\tfor {\n-\t\t\t\ttime.Sleep(5 * time.Minute)\n-\t\t\t\tlog.Print(\"Still testing. Don't kill me!\")\n-\t\t\t}\n-\t\t}()\n+// uniqueBQName returns a more unique name for a BigQuery resource.\n+func uniqueBQName(prefix string) string {\n+\tt := time.Now()\n+\treturn fmt.Sprintf(\"%s_%d\", sanitize(prefix, '_'), t.Unix())\n+}\n+\n+// uniqueBucketName returns a more unique name cloud storage bucket.\n+func uniqueBucketName(prefix, projectID string) string {\n+\tt := time.Now()\n+\tf := fmt.Sprintf(\"%s-%s-%d\", sanitize(prefix, '-'), sanitize(projectID, '-'), t.Unix())\n+\t// bucket max name length is 63 chars, so we truncate.\n+\tif len(f) > 63 {\n+\t\treturn f[:63]\n \t}\n+\treturn f\n }\n \n+func sanitize(s string, allowedSeparator rune) string {\n+\tpattern := fmt.Sprintf(\"[^a-zA-Z0-9%s]\", string(allowedSeparator))\n+\treg, err := regexp.Compile(pattern)\n+\tif err != nil {\n+\t\treturn s\n+\t}\n+\treturn reg.ReplaceAllString(s, \"\")\n+}\n func TestAll(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -44,17 +53,45 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \n-\tdatasetID := fmt.Sprintf(\"golang_example_dataset_%d\", time.Now().Unix())\n+\tdatasetID := uniqueBQName(\"golang_example_dataset\")\n \tif err := createDataset(client, datasetID); err != nil {\n \t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n \t}\n+\t// Cleanup dataset at end of test.\n+\tdefer client.Dataset(datasetID).DeleteWithContents(ctx)\n \n \tif err := updateDatasetAccessControl(client, datasetID); err != nil {\n \t\tt.Errorf(\"updateDataSetAccessControl(%q): %v\", datasetID, err)\n \t}\n+\tif err := addDatasetLabel(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n+\t}\n+\n+\tbuf := &bytes.Buffer{}\n+\tif err := datasetLabels(client, buf, datasetID); err != nil {\n+\t\tt.Errorf(\"getDatasetLabels(%q): %v\", datasetID, err)\n+\t}\n+\twant := \"color:green\"\n+\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\tt.Errorf(\"getDatasetLabel(%q) expected %q to contain %q\", datasetID, got, want)\n+\t}\n+\n+\tif err := addDatasetLabel(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n+\t}\n+\tbuf.Reset()\n+\tif err := listDatasetsByLabel(client, buf); err != nil {\n+\t\tt.Errorf(\"listDatasetsByLabel: %v\", err)\n+\t}\n+\tif got := buf.String(); !strings.Contains(got, datasetID) {\n+\t\tt.Errorf(\"listDatasetsByLabel expected %q to contain %q\", got, want)\n+\t}\n+\tif err := deleteDatasetLabel(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetDeleteLabel: %v\", err)\n+\t}\n \n \t// Test empty dataset creation/ttl/delete.\n-\tdeletionDatasetID := fmt.Sprintf(\"%s_quickdelete\", datasetID)\n+\tdeletionDatasetID := uniqueBQName(\"golang_example_quickdelete\")\n \tif err := createDataset(client, deletionDatasetID); err != nil {\n \t\tt.Errorf(\"createDataset(%q): %v\", deletionDatasetID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -72,9 +109,9 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"listDatasets: %v\", err)\n \t}\n \n-\tinferred := fmt.Sprintf(\"golang_example_table_inferred_%d\", time.Now().Unix())\n-\texplicit := fmt.Sprintf(\"golang_example_table_explicit_%d\", time.Now().Unix())\n-\tempty := fmt.Sprintf(\"golang_example_table_emptyschema_%d\", time.Now().Unix())\n+\tinferred := uniqueBQName(\"golang_example_table_inferred\")\n+\texplicit := uniqueBQName(\"golang_example_table_explicit\")\n+\tempty := uniqueBQName(\"golang_example_table_emptyschema\")\n \n \tif err := createTableInferredSchema(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"createTableInferredSchema(dataset:%q table:%q): %v\", datasetID, inferred, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -92,8 +129,14 @@\nfunc TestAll(t *testing.T) {\n \tif err := updateTableExpiration(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"updateTableExpiration(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n+\tif err := addTableLabel(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"updateTableAddLabel(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\t}\n+\tif err := deleteTableLabel(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"updateTableAddLabel(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\t}\n \n-\tbuf := &bytes.Buffer{}\n+\tbuf.Reset()\n \tif err := listTables(client, buf, datasetID); err != nil {\n \t\tt.Errorf(\"listTables(%q): %v\", datasetID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -108,58 +151,89 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"want table list %q to contain table %q\", got, empty)\n \t}\n \n+\tif err := printDatasetInfo(client, datasetID); err != nil {\n+\t\tt.Errorf(\"printDatasetInfo: %v\", err)\n+\t}\n+\n \t// Stream data, read, query the inferred schema table.\n \tif err := insertRows(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"insertRows(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := listRows(client, datasetID, inferred); err != nil {\n-\t\tt.Errorf(\"listRows(dataset:%q table:%q): %v\", datasetID, inferred, err)\n-\t}\n \tif err := browseTable(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"browseTable(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := basicQuery(client, datasetID, inferred); err != nil {\n-\t\tt.Errorf(\"basicQuery(dataset:%q table:%q): %v\", datasetID, inferred, err)\n+\n+\tif err := queryBasic(client); err != nil {\n+\t\tt.Errorf(\"queryBasic: %v\", err)\n+\t}\n+\tbatchTable := uniqueBQName(\"golang_example_batchresults\")\n+\tif err := queryBatch(client, datasetID, batchTable); err != nil {\n+\t\tt.Errorf(\"queryBatch(dataset:%q table:%q): %v\", datasetID, batchTable, err)\n+\t}\n+\tif err := queryDisableCache(client); err != nil {\n+\t\tt.Errorf(\"queryBasicDisableCache: %v\", err)\n+\t}\n+\tif err := queryDryRun(client); err != nil {\n+\t\tt.Errorf(\"queryDryRun: %v\", err)\n+\t}\n+\tsql := \"SELECT 17 as foo\"\n+\tif err := queryLegacy(client, sql); err != nil {\n+\t\tt.Errorf(\"queryLegacy: %v\", err)\n+\t}\n+\tlargeResults := uniqueBQName(\"golang_example_legacy_largeresults\")\n+\tif err := queryLegacyLargeResults(client, datasetID, largeResults); err != nil {\n+\t\tt.Errorf(\"queryLegacyLargeResults(dataset:%q table:%q): %v\", datasetID, largeResults, err)\n+\t}\n+\tif err := queryWithArrayParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithArrayParams: %v\", err)\n+\t}\n+\tif err := queryWithNamedParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithNamedParams: %v\", err)\n+\t}\n+\tif err := queryWithPositionalParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithPositionalParams: %v\", err)\n+\t}\n+\tif err := queryWithTimestampParam(client); err != nil {\n+\t\tt.Errorf(\"queryWithTimestampParam: %v\", err)\n+\t}\n+\tif err := queryWithStructParam(client); err != nil {\n+\t\tt.Errorf(\"queryWithStructParam: %v\", err)\n+\t}\n+\n+\t// Run query variations\n+\tpersisted := uniqueBQName(\"golang_example_table_queryresult\")\n+\tif err := queryWithDestination(client, datasetID, persisted); err != nil {\n+\t\tt.Errorf(\"queryWithDestination(dataset:%q table:%q): %v\", datasetID, persisted, err)\n \t}\n \n \t// Print information about tables (extended and simple).\n-\tif err := printTableMetadataSimple(client, datasetID, inferred); err != nil {\n-\t\tt.Errorf(\"printTableMetadata(dataset:%q table:%q): %v\", datasetID, inferred, err)\n+\tif err := printTableInfo(client, datasetID, inferred); err != nil {\n+\t\tt.Errorf(\"printTableInfo(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := printTableMetadataSimple(client, datasetID, explicit); err != nil {\n-\t\tt.Errorf(\"printTableMetadata(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\tif err := printTableInfo(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"printTableInfo(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n \n-\tdstTableID := fmt.Sprintf(\"golang_example_tabledst_%d\", time.Now().Unix())\n+\tdstTableID := uniqueBQName(\"golang_example_tabledst\")\n \tif err := copyTable(client, datasetID, inferred, dstTableID); err != nil {\n \t\tt.Errorf(\"copyTable(dataset:%q src:%q dst:%q): %v\", datasetID, inferred, dstTableID, err)\n \t}\n \tif err := deleteTable(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := deleteTable(client, datasetID, dstTableID); err != nil {\n-\t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n+\tif err := deleteAndUndeleteTable(client, datasetID, dstTableID); err != nil {\n+\t\tt.Errorf(\"undeleteTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n \t}\n \n-\tdeleteDataset(t, ctx, datasetID)\n-}\n-\n-func deleteDataset(t *testing.T, ctx context.Context, datasetID string) {\n-\ttc := testutil.SystemTest(t)\n-\thc, err := google.DefaultClient(ctx, rawbq.CloudPlatformScope)\n-\tif err != nil {\n-\t\tt.Errorf(\"DefaultClient: %v\", err)\n-\t}\n-\ts, err := rawbq.New(hc)\n-\tif err != nil {\n-\t\tt.Errorf(\"bigquery.New: %v\", err)\n+\tdstTableID = uniqueBQName(\"golang_multicopydest\")\n+\tif err := copyMultiTable(client, datasetID, dstTableID); err != nil {\n+\t\tt.Errorf(\"copyMultiTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n \t}\n-\tcall := s.Datasets.Delete(tc.ProjectID, datasetID)\n-\tcall.DeleteContents(true)\n-\tcall.Context(ctx)\n-\tif err := call.Do(); err != nil {\n-\t\tt.Errorf(\"deleteDataset(%q): %v\", datasetID, err)\n+\n+\tif err := listJobs(client); err != nil {\n+\t\tt.Errorf(\"listJobs: %v\", err)\n \t}\n+\n }\n \n func TestImportExport(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -28,40 +28,40 @@\ntype Task struct {\n }\n \n func SnippetNewIncompleteKey() {\n-\t// [START incomplete_key]\n+\t// [START datastore_incomplete_key]\n \ttaskKey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [END incomplete_key]\n+\t// [END datastore_incomplete_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey() {\n-\t// [START named_key]\n+\t// [START datastore_named_key]\n \ttaskKey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [END named_key]\n+\t// [END datastore_named_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withParent() {\n-\t// [START key_with_parent]\n+\t// [START datastore_key_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_parent]\n+\t// [END datastore_key_with_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withMultipleParents() {\n-\t// [START key_with_multilevel_parent]\n+\t// [START datastore_key_with_multilevel_parent]\n \tuserKey := datastore.NameKey(\"User\", \"alice\", nil)\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", userKey)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_multilevel_parent]\n+\t// [END datastore_key_with_multilevel_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetClient_Put() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START entity_with_parent]\n+\t// [START datastore_entity_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tkey := datastore.IncompleteKey(\"Task\", parentKey)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -75,12 +75,12 @@\nfunc SnippetClient_Put() {\n \t// A complete key is assigned to the entity when it is Put.\n \tvar err error\n \tkey, err = client.Put(ctx, key, &task)\n-\t// [END entity_with_parent]\n+\t// [END datastore_entity_with_parent]\n \t_ = err // Make sure you check err.\n }\n \n func Snippet_properties() {\n-\t// [START properties]\n+\t// [START datastore_properties]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -97,12 +97,12 @@\nfunc Snippet_properties() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END properties]\n+\t// [END datastore_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_sliceProperties() {\n-\t// [START array_value]\n+\t// [START datastore_array_value]\n \ttype Task struct {\n \t\tTags          []string\n \t\tCollaborators []string",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -111,12 +111,12 @@\nfunc Snippet_sliceProperties() {\n \t\tTags:          []string{\"fun\", \"programming\"},\n \t\tCollaborators: []string{\"alice\", \"bob\"},\n \t}\n-\t// [END array_value]\n+\t// [END datastore_array_value]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_basicEntity() {\n-\t// [START basic_entity]\n+\t// [START datastore_basic_entity]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -133,7 +133,7 @@\nfunc Snippet_basicEntity() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END basic_entity]\n+\t// [END datastore_basic_entity]\n \t_ = task // Use the task in a datastore Put operation.\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -142,9 +142,9 @@\nfunc SnippetClient_Put_upsert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := &Task{} // Populated with appropriate data.\n \tkey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [START upsert]\n+\t// [START datastore_upsert]\n \tkey, err := client.Put(ctx, key, task)\n-\t// [END upsert]\n+\t// [END datastore_upsert]\n \t_ = err // Make sure you check err.\n \t_ = key // key is the complete key for the newly stored task\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -154,7 +154,7 @@\nfunc SnippetTransaction_insert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := Task{} // Populated with appropriate data.\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START insert]\n+\t// [START datastore_insert]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\t// We first check that there is no entity stored with the given key.\n \t\tvar empty Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -165,26 +165,26 @@\nfunc SnippetTransaction_insert() {\n \t\t_, err := tx.Put(taskKey, &task)\n \t\treturn err\n \t})\n-\t// [END insert]\n+\t// [END datastore_insert]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_Get() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START lookup]\n+\t// [START datastore_lookup]\n \tvar task Task\n \terr := client.Get(ctx, taskKey, &task)\n-\t// [END lookup]\n+\t// [END datastore_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetTransaction_update() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START update]\n+\t// [START datastore_update]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -200,23 +200,23 @@\nfunc SnippetTransaction_update() {\n \tif _, err := tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END update]\n+\t// [END datastore_update]\n }\n \n func SnippetClient_Delete() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START delete]\n+\t// [START datastore_delete]\n \terr := client.Delete(ctx, key)\n-\t// [END delete]\n+\t// [END datastore_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_PutMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START batch_upsert]\n+\t// [START datastore_batch_upsert]\n \ttasks := []*Task{\n \t\t{\n \t\t\tCategory:    \"Personal\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -237,7 +237,7 @@\nfunc SnippetClient_PutMulti() {\n \t}\n \n \tkeys, err := client.PutMulti(ctx, keys, tasks)\n-\t// [END batch_upsert]\n+\t// [END datastore_batch_upsert]\n \t_ = err  // Make sure you check err.\n \t_ = keys // keys now has the complete keys for the newly stored tasks.\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -246,33 +246,33 @@\nfunc SnippetClient_GetMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_lookup]\n+\t// [START datastore_batch_lookup]\n \tvar tasks []*Task\n \terr := client.GetMulti(ctx, taskKeys, &tasks)\n-\t// [END batch_lookup]\n+\t// [END datastore_batch_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_DeleteMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_delete]\n+\t// [START datastore_batch_delete]\n \terr := client.DeleteMulti(ctx, taskKeys)\n-\t// [END batch_delete]\n+\t// [END datastore_batch_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetQuery_basic() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START basic_query]\n+\t// [START datastore_basic_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Priority >=\", 4).\n \t\tOrder(\"-Priority\")\n-\t// [END basic_query]\n-\t// [START run_query]\n+\t// [END datastore_basic_query]\n+\t// [START datastore_run_query]\n \tit := client.Run(ctx, query)\n \tfor {\n \t\tvar task Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -285,75 +285,75 @@\nfunc SnippetQuery_basic() {\n \t\t}\n \t\tfmt.Printf(\"Task %q, Priority %d\\n\", task.Description, task.Priority)\n \t}\n-\t// [END run_query]\n+\t// [END datastore_run_query]\n }\n \n func SnippetQuery_propertyFilter() {\n-\t// [START property_filter]\n+\t// [START datastore_property_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false)\n-\t// [END property_filter]\n+\t// [END datastore_property_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_compositeFilter() {\n-\t// [START composite_filter]\n+\t// [START datastore_composite_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false).Filter(\"Priority =\", 4)\n-\t// [END composite_filter]\n+\t// [END datastore_composite_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_keyFilter() {\n-\t// [START key_filter]\n+\t// [START datastore_key_filter]\n \tkey := datastore.NameKey(\"Task\", \"someTask\", nil)\n \tquery := datastore.NewQuery(\"Task\").Filter(\"__key__ >\", key)\n-\t// [END key_filter]\n+\t// [END datastore_key_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortAscending() {\n-\t// [START ascending_sort]\n+\t// [START datastore_ascending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"created\")\n-\t// [END ascending_sort]\n+\t// [END datastore_ascending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortDescending() {\n-\t// [START descending_sort]\n+\t// [START datastore_descending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-created\")\n-\t// [END descending_sort]\n+\t// [END datastore_descending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortMulti() {\n-\t// [START multi_sort]\n+\t// [START datastore_multi_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-priority\").Order(\"created\")\n-\t// [END multi_sort]\n+\t// [END datastore_multi_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_kindless() {\n \tvar lastSeenKey *datastore.Key\n-\t// [START kindless_query]\n+\t// [START datastore_kindless_query]\n \tquery := datastore.NewQuery(\"\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_query]\n+\t// [END datastore_kindless_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Ancestor() {\n-\t// [START ancestor_query]\n+\t// [START datastore_ancestor_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor)\n-\t// [END ancestor_query]\n+\t// [END datastore_ancestor_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Project() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START projection_query]\n+\t// [START datastore_projection_query]\n \tquery := datastore.NewQuery(\"Task\").Project(\"Priority\", \"PercentComplete\")\n-\t// [END projection_query]\n-\t// [START run_query_projection]\n+\t// [END datastore_projection_query]\n+\t// [START datastore_run_query_projection]\n \tvar priorities []int\n \tvar percents []float64\n \tit := client.Run(ctx, query)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -367,130 +367,119 @@\nfunc SnippetQuery_Project() {\n \t\tpriorities = append(priorities, task.Priority)\n \t\tpercents = append(percents, task.PercentComplete)\n \t}\n-\t// [END run_query_projection]\n+\t// [END datastore_run_query_projection]\n }\n \n func SnippetQuery_KeysOnly() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START keys_only_query]\n+\t// [START datastore_keys_only_query]\n \tquery := datastore.NewQuery(\"Task\").KeysOnly()\n-\t// [END keys_only_query]\n-\t// [START run_keys_only_query]\n+\t// [END datastore_keys_only_query]\n+\n \tkeys, err := client.GetAll(ctx, query, nil)\n-\t// [END run_keys_only_query]\n \t_ = err  // Make sure you check err.\n \t_ = keys // Keys contains keys for all stored tasks.\n }\n \n-func SnippetQuery_Distinct() {\n-\t// [START distinct_query]\n-\tquery := datastore.NewQuery(\"Task\").\n-\t\tProject(\"Priority\", \"PercentComplete\").\n-\t\tDistinct().\n-\t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_query]\n-\t_ = query // Use client.Run or client.GetAll to execute the query.\n-}\n-\n func SnippetQuery_DistinctOn() {\n-\t// [START distinct_on_query]\n+\t// [START datastore_distinct_on_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tProject(\"Priority\", \"Category\").\n \t\tDistinctOn(\"Category\").\n \t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_on_query]\n+\t// [END datastore_distinct_on_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayInequality() {\n-\t// [START array_value_inequality_range]\n+\t// [START datastore_array_value_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag >\", \"learn\").\n \t\tFilter(\"Tag <\", \"math\")\n-\t// [END array_value_inequality_range]\n+\t// [END datastore_array_value_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayEquality() {\n-\t// [START array_value_equality]\n+\t// [START datastore_array_value_equality]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag =\", \"fun\").\n \t\tFilter(\"Tag =\", \"programming\")\n-\t// [END array_value_equality]\n+\t// [END datastore_array_value_equality]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_inequality() {\n-\t// [START inequality_range]\n+\t// [START datastore_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END inequality_range]\n+\t// [END datastore_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_invalidInequality() {\n-\t// [START inequality_invalid]\n+\t// [START datastore_inequality_invalid]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Priority >\", 3)\n-\t// [END inequality_invalid]\n+\t// [END datastore_inequality_invalid]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Filter_mixed() {\n-\t// [START equal_and_inequality_range]\n+\t// [START datastore_equal_and_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority =\", 4).\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END equal_and_inequality_range]\n+\t// [END datastore_equal_and_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_inequalitySort() {\n-\t// [START inequality_sort]\n+\t// [START datastore_inequality_sort]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Priority\").\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort]\n+\t// [END datastore_inequality_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_invalidInequalitySortA() {\n-\t// [START inequality_sort_invalid_not_same]\n+\t// [START datastore_inequality_sort_invalid_not_same]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort_invalid_not_same]\n+\t// [END datastore_inequality_sort_invalid_not_same]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_invalidInequalitySortB() {\n-\t// [START inequality_sort_invalid_not_first]\n+\t// [START datastore_inequality_sort_invalid_not_first]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\").\n \t\tOrder(\"Priority\")\n-\t// [END inequality_sort_invalid_not_first]\n+\t// [END datastore_inequality_sort_invalid_not_first]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Limit() {\n-\t// [START limit]\n+\t// [START datastore_limit]\n \tquery := datastore.NewQuery(\"Task\").Limit(5)\n-\t// [END limit]\n+\t// [END datastore_limit]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetIterator_Cursor() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tcursorStr := \"\"\n-\t// [START cursor_paging]\n+\t// [START datastore_cursor_paging]\n \tconst pageSize = 5\n \tquery := datastore.NewQuery(\"Tasks\").Limit(pageSize)\n \tif cursorStr != \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -516,42 +505,42 @@\nfunc SnippetIterator_Cursor() {\n \n \t// Get the cursor for the next page of results.\n \tnextCursor, err := it.Cursor()\n-\t// [END cursor_paging]\n+\t// [END datastore_cursor_paging]\n \t_ = err        // Check the error.\n \t_ = nextCursor // Use nextCursor.String as the next page's token.\n }\n \n func SnippetQuery_EventualConsistency() {\n-\t// [START eventual_consistent_query]\n+\t// [START datastore_eventual_consistent_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).EventualConsistency()\n-\t// [END eventual_consistent_query]\n+\t// [END datastore_eventual_consistent_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_unindexed() {\n-\t// [START unindexed_property_query]\n+\t// [START datastore_unindexed_property_query]\n \tquery := datastore.NewQuery(\"Tasks\").Filter(\"Description =\", \"A task description\")\n-\t// [END unindexed_property_query]\n+\t// [END datastore_unindexed_property_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func Snippet_explodingProperties() {\n-\t// [START exploding_properties]\n+\t// [START datastore_exploding_properties]\n \ttask := &Task{\n \t\tTags:          []string{\"fun\", \"programming\", \"learn\"},\n \t\tCollaborators: []string{\"alice\", \"bob\", \"charlie\"},\n \t\tCreated:       time.Now(),\n \t}\n-\t// [END exploding_properties]\n+\t// [END datastore_exploding_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_Transaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_update]\n+\t// [START datastore_transactional_update]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -576,14 +565,14 @@\nfunc Snippet_Transaction() {\n \tif _, err = tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END transactional_update]\n+\t// [END datastore_transactional_update]\n }\n \n func Snippet_Client_RunInTransaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_retry]\n+\t// [START datastore_transactional_retry]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -600,15 +589,15 @@\nfunc Snippet_Client_RunInTransaction() {\n \t\t_, err := tx.PutMulti(keys, accs)\n \t\treturn err\n \t})\n-\t// [END transactional_retry]\n+\t// [END datastore_transactional_retry]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_getOrCreate() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START transactional_get_or_create]\n+\t// [START datastore_transactional_get_or_create]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\tvar task Task\n \t\tif err := tx.Get(key, &task); err != datastore.ErrNoSuchEntity {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -622,14 +611,14 @@\nfunc SnippetTransaction_getOrCreate() {\n \t\t})\n \t\treturn err\n \t})\n-\t// [END transactional_get_or_create]\n+\t// [END datastore_transactional_get_or_create]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_runQuery() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START transactional_single_entity_group_read_only]\n+\t// [START datastore_transactional_single_entity_group_read_only]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -640,14 +629,14 @@\nfunc SnippetTransaction_runQuery() {\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).Transaction(tx)\n \tvar tasks []Task\n \t_, err = client.GetAll(ctx, query, &tasks)\n-\t// [END transactional_single_entity_group_read_only]\n+\t// [END datastore_transactional_single_entity_group_read_only]\n \t_ = err // Check error.\n }\n \n func Snippet_metadataNamespaces() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START namespace_run_query]\n+\t// [START datastore_namespace_run_query]\n \tconst (\n \t\tstartNamespace = \"g\"\n \t\tendNamespace   = \"h\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -665,13 +654,13 @@\nfunc Snippet_metadataNamespaces() {\n \tfor _, k := range keys {\n \t\tnamespaces = append(namespaces, k.Name)\n \t}\n-\t// [END namespace_run_query]\n+\t// [END datastore_namespace_run_query]\n }\n \n func Snippet_metadataKinds() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START kind_run_query]\n+\t// [START datastore_kind_run_query]\n \tquery := datastore.NewQuery(\"__kind__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -682,13 +671,13 @@\nfunc Snippet_metadataKinds() {\n \tfor _, k := range keys {\n \t\tkinds = append(kinds, k.Name)\n \t}\n-\t// [END kind_run_query]\n+\t// [END datastore_kind_run_query]\n }\n \n func Snippet_metadataProperties() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_run_query]\n+\t// [START datastore_property_run_query]\n \tquery := datastore.NewQuery(\"__property__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -701,13 +690,13 @@\nfunc Snippet_metadataProperties() {\n \t\tkind := k.Parent.Name\n \t\tprops[kind] = append(props[kind], prop)\n \t}\n-\t// [END property_run_query]\n+\t// [END datastore_property_run_query]\n }\n \n func Snippet_metadataPropertiesForKind() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_by_kind_run_query]\n+\t// [START datastore_property_by_kind_run_query]\n \tkindKey := datastore.NameKey(\"__kind__\", \"Task\", nil)\n \tquery := datastore.NewQuery(\"__property__\").Ancestor(kindKey)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -2,8 +2,6 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START all]\n-\n // A simple command-line task list manager to demonstrate using the\n // cloud.google.com/go/datastore package.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -29,10 +27,10 @@\nfunc main() {\n \tif projID == \"\" {\n \t\tlog.Fatal(`You need to set the environment variable \"DATASTORE_PROJECT_ID\"`)\n \t}\n-\t// [START build_service]\n+\t// [START datastore_build_service]\n \tctx := context.Background()\n \tclient, err := datastore.NewClient(ctx, projID)\n-\t// [END build_service]\n+\t// [END datastore_build_service]\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create datastore client: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -107,7 +105,7 @@\nfunc main() {\n \t}\n }\n \n-// [START add_entity]\n+// [START datastore_add_entity]\n // Task is the model used to store tasks in the datastore.\n type Task struct {\n \tDesc    string    `datastore:\"description\"`",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -127,9 +125,9 @@\nfunc AddTask(ctx context.Context, client *datastore.Client, desc string) (*datas\n \treturn client.Put(ctx, key, task)\n }\n \n-// [END add_entity]\n+// [END datastore_add_entity]\n \n-// [START update_entity]\n+// [START datastore_update_entity]\n // MarkDone marks the task done with the given ID.\n func MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error {\n \t// Create a key using the given integer ID.",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -148,9 +146,9 @@\nfunc MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error\n \treturn err\n }\n \n-// [END update_entity]\n+// [END datastore_update_entity]\n \n-// [START retrieve_entities]\n+// [START datastore_retrieve_entities]\n // ListTasks returns all the tasks in ascending order of creation time.\n func ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \tvar tasks []*Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -170,17 +168,16 @@\nfunc ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \treturn tasks, nil\n }\n \n-// [END retrieve_entities]\n+// [END datastore_retrieve_entities]\n \n-// [START delete_entity]\n+// [START datastore_delete_entity]\n // DeleteTask deletes the task with the given ID.\n func DeleteTask(ctx context.Context, client *datastore.Client, taskID int64) error {\n \treturn client.Delete(ctx, datastore.IDKey(\"Task\", taskID, nil))\n }\n \n-// [END delete_entity]\n+// [END datastore_delete_entity]\n \n-// [START format_results]\n // PrintTasks prints the tasks to the given writer.\n func PrintTasks(w io.Writer, tasks []*Task) {\n \t// Use a tab writer to help make results pretty.",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -196,8 +193,6 @@\nfunc PrintTasks(w io.Writer, tasks []*Task) {\n \ttw.Flush()\n }\n \n-// [END format_results]\n-\n func usage() {\n \tfmt.Print(`Usage:",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dialogflow/intent_management/intent_management.go",
        "code_diff": "@@ -109,6 +109,8 @@\nfunc main() {\n \t}\n }\n \n+// [START dialogflow_list_intents]\n+\n func ListIntents(projectID string) ([]*dialogflowpb.Intent, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/deid.go",
        "code_diff": "@@ -18,12 +18,20 @@\nimport (\n \n // [START dlp_deidentify_masking]\n \n-// mask deidentifies the input by masking all info types with maskingCharacter and\n-// prints the result to w.\n-func mask(w io.Writer, client *dlp.Client, project, input, maskingCharacter string, numberToMask int32) {\n+// mask deidentifies the input by masking all provided info types with maskingCharacter\n+// and prints the result to w.\n+func mask(w io.Writer, client *dlp.Client, project, input string, infoTypes []string, maskingCharacter string, numberToMask int32) {\n+\t// Convert the info type strings to a list of InfoTypes.\n+\tvar i []*dlppb.InfoType\n+\tfor _, it := range infoTypes {\n+\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\t}\n \t// Create a configured request.\n \treq := &dlppb.DeidentifyContentRequest{\n \t\tParent: \"projects/\" + project,\n+\t\tInspectConfig: &dlppb.InspectConfig{\n+\t\t\tInfoTypes: i,\n+\t\t},\n \t\tDeidentifyConfig: &dlppb.DeidentifyConfig{\n \t\t\tTransformation: &dlppb.DeidentifyConfig_InfoTypeTransformations{\n \t\t\t\tInfoTypeTransformations: &dlppb.InfoTypeTransformations{",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/deid.go",
        "code_diff": "@@ -121,7 +129,12 @@\nfunc deidentifyDateShift(w io.Writer, client *dlp.Client, project string, lowerB\n // full KMS key resource name used to wrap the key. surrogateInfoType is an\n // optional identifier needed for reidentification. surrogateInfoType can be any\n // value not found in your input.\n-func deidentifyFPE(w io.Writer, client *dlp.Client, project, input, keyFileName, cryptoKeyName, surrogateInfoType string) {\n+func deidentifyFPE(w io.Writer, client *dlp.Client, project, input string, infoTypes []string, keyFileName, cryptoKeyName, surrogateInfoType string) {\n+\t// Convert the info type strings to a list of InfoTypes.\n+\tvar i []*dlppb.InfoType\n+\tfor _, it := range infoTypes {\n+\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\t}\n \t// Read the key file.\n \tkeyBytes, err := ioutil.ReadFile(keyFileName)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/deid.go",
        "code_diff": "@@ -130,6 +143,9 @@\nfunc deidentifyFPE(w io.Writer, client *dlp.Client, project, input, keyFileName,\n \t// Create a configured request.\n \treq := &dlppb.DeidentifyContentRequest{\n \t\tParent: \"projects/\" + project,\n+\t\tInspectConfig: &dlppb.InspectConfig{\n+\t\t\tInfoTypes: i,\n+\t\t},\n \t\tDeidentifyConfig: &dlppb.DeidentifyConfig{\n \t\t\tTransformation: &dlppb.DeidentifyConfig_InfoTypeTransformations{\n \t\t\t\tInfoTypeTransformations: &dlppb.InfoTypeTransformations{",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/deid.go",
        "code_diff": "@@ -181,9 +197,9 @@\nfunc deidentifyFPE(w io.Writer, client *dlp.Client, project, input, keyFileName,\n \n // [END dlp_deidentify_fpe]\n \n-// [START reidentify_fpe]\n+// [START dlp_reidentify_fpe]\n \n-// reidentify_fpe reidentifies the input with FPE (Format Preserving Encryption).\n+// reidentifyFPE reidentifies the input with FPE (Format Preserving Encryption).\n // keyFileName is the file name with the KMS wrapped key and cryptoKeyName is the\n // full KMS key resource name used to wrap the key. surrogateInfoType is an\n // the identifier used during deidentification.",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -9,6 +9,7 @@\nimport (\n \t\"io\"\n \t\"io/ioutil\"\n \t\"log\"\n+\t\"strings\"\n \n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -20,18 +21,49 @@\nimport (\n // [START dlp_inspect_string]\n \n // inspectString searches for the given infoTypes in the input.\n-func inspectString(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, input string) {\n+func inspectString(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, input string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \t// Create a configured request.\n \treq := &dlppb.InspectContentRequest{\n \t\tParent: \"projects/\" + project,\n \t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\tInfoTypes:     i,\n-\t\t\tMinLikelihood: minLikelihood,\n+\t\t\tInfoTypes:       i,\n+\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\tMinLikelihood:   minLikelihood,\n \t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -58,12 +90,42 @@\nfunc inspectString(w io.Writer, client *dlp.Client, project string, minLikelihoo\n // [START dlp_inspect_file]\n \n // inspectFile searches for the given info types in the given Reader (with the given bytesType).\n-func inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, bytesType dlppb.ByteContentItem_BytesType, input io.Reader) {\n+func inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, bytesType dlppb.ByteContentItem_BytesType, input io.Reader) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \tb, err := ioutil.ReadAll(input)\n \tif err != nil {\n \t\tlog.Fatalf(\"error reading file: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -72,8 +134,9 @@\nfunc inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood\n \treq := &dlppb.InspectContentRequest{\n \t\tParent: \"projects/\" + project,\n \t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\tInfoTypes:     i,\n-\t\t\tMinLikelihood: minLikelihood,\n+\t\t\tInfoTypes:       i,\n+\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\tMinLikelihood:   minLikelihood,\n \t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -103,12 +166,42 @@\nfunc inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood\n // [START dlp_inspect_gcs]\n \n // inspectGCSFile searches for the given info types in the given file.\n-func inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, pubSubTopic, pubSubSub, bucketName, fileName string) {\n+func inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, pubSubTopic, pubSubSub, bucketName, fileName string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -145,8 +238,9 @@\nfunc inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikeliho\n \t\t\t\t},\n \t\t\t\t// InspectConfig describes what fields to look for.\n \t\t\t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\t\t\tInfoTypes:     i,\n-\t\t\t\t\tMinLikelihood: minLikelihood,\n+\t\t\t\t\tInfoTypes:       i,\n+\t\t\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\t\t\tMinLikelihood:   minLikelihood,\n \t\t\t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -207,12 +301,42 @@\nfunc inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikeliho\n // [START dlp_inspect_datastore]\n \n // inspectDatastore searches for the given info types in the given dataset kind.\n-func inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, pubSubTopic, pubSubSub, dataProject, namespaceID, kind string) {\n+func inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, pubSubTopic, pubSubSub, dataProject, namespaceID, kind string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -253,8 +377,9 @@\nfunc inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikeli\n \t\t\t\t},\n \t\t\t\t// InspectConfig describes what fields to look for.\n \t\t\t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\t\t\tInfoTypes:     i,\n-\t\t\t\t\tMinLikelihood: minLikelihood,\n+\t\t\t\t\tInfoTypes:       i,\n+\t\t\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\t\t\tMinLikelihood:   minLikelihood,\n \t\t\t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -315,12 +440,42 @@\nfunc inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikeli\n // [START dlp_inspect_bigquery]\n \n // inspectBigquery searches for the given info types in the given Bigquery dataset table.\n-func inspectBigquery(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, pubSubTopic, pubSubSub, dataProject, datasetID, tableID string) {\n+func inspectBigquery(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, pubSubTopic, pubSubSub, dataProject, datasetID, tableID string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -33,14 +33,23 @@\nfunc TestInspectString(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, test.s)\n+\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, test.s)\n \t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n \t\t\tif test.want {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n \t\t\t} else {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n \t\t\t}\n \t\t}\n+\t\tbuf.Reset()\n+\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, test.s)\n+\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n+\t\t\tif test.want {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n+\t\t\t} else {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\t}\n+\t\t}\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -60,14 +69,23 @@\nfunc TestInspectFile(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n+\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n \t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n \t\t\tif test.want {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n \t\t\t} else {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n \t\t\t}\n \t\t}\n+\t\tbuf.Reset()\n+\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n+\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n+\t\t\tif test.want {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n+\t\t\t} else {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\t}\n+\t\t}\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -139,7 +157,7 @@\nfunc TestInspectGCS(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectGCSFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, \"test-topic\", \"test-sub\", bucketName, test.fileName)\n+\t\tinspectGCSFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, \"test-topic\", \"test-sub\", bucketName, test.fileName)\n \t\tif got := buf.String(); !strings.Contains(got, test.want) {\n \t\t\tt.Errorf(\"inspectString(%s) = %q, want %q substring\", test.fileName, got, test.want)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -199,7 +217,7 @@\nfunc TestInspectDatastore(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectDatastore(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, \"test-topic\", \"test-sub\", projectID, \"\", test.kind)\n+\t\tinspectDatastore(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, \"test-topic\", \"test-sub\", projectID, \"\", test.kind)\n \t\tif got := buf.String(); !strings.Contains(got, test.want) {\n \t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -37,13 +37,16 @@\nfunc bytesTypeValues() string {\n }\n \n var (\n-\tproject           = flag.String(\"project\", \"\", \"Project ID (required)\")\n-\tlanguageCode      = flag.String(\"languageCode\", \"en-US\", \"Language code for infoTypes\")\n-\tinfoTypesString   = flag.String(\"infoTypes\", \"PHONE_NUMBER,EMAIL_ADDRESS,CREDIT_CARD_NUMBER,US_SOCIAL_SECURITY_NUMBER\", \"Info types to inspect*, redactImage, createTrigger, and createInspectTemplate\")\n-\tminLikelihoodFlag = flag.String(\"minLikelihood\", \"LIKELIHOOD_UNSPECIFIED\", fmt.Sprintf(\"Minimum likelihood value for inspect*, redactImage, createTrigger, and createInspectTemplate [%v]\", minLikelihoodValues()))\n-\tbytesTypeFlag     = flag.String(\"bytesType\", \"BYTES_TYPE_UNSPECIFIED\", fmt.Sprintf(\"Bytes type of input file for inspectFile and redactImage [%v]\", bytesTypeValues()))\n-\tmaxFindings       = flag.Int(\"maxFindings\", 0, \"Number of results for inspect*, createTrigger, and createInspectTemplate (default 0 (no limit))\")\n-\tincludeQuote      = flag.Bool(\"includeQuote\", false, \"Include a quote of findings for inspect* (default false)\")\n+\tproject                = flag.String(\"project\", \"\", \"Project ID (required)\")\n+\tlanguageCode           = flag.String(\"languageCode\", \"en-US\", \"Language code for infoTypes\")\n+\tinfoTypesString        = flag.String(\"infoTypes\", \"PHONE_NUMBER,EMAIL_ADDRESS,CREDIT_CARD_NUMBER,US_SOCIAL_SECURITY_NUMBER\", \"Info types to inspect*, redactImage, createTrigger, and createInspectTemplate\")\n+\tcustomDictionaryString = flag.String(\"customDictionary\", \"\", \"Custom dictionary for inspect*\")\n+\tcustomRegexString      = flag.String(\"customRegex\", \"\", \"Custom regex for inspect*\")\n+\tminLikelihoodFlag      = flag.String(\"minLikelihood\", \"LIKELIHOOD_UNSPECIFIED\", fmt.Sprintf(\"Minimum likelihood value for inspect*, redactImage, createTrigger, and createInspectTemplate [%v]\", minLikelihoodValues()))\n+\tbytesTypeFlag          = flag.String(\"bytesType\", \"BYTES_TYPE_UNSPECIFIED\", fmt.Sprintf(\"Bytes type of input file for inspectFile and redactImage [%v]\", bytesTypeValues()))\n+\tmaxFindings            = flag.Int(\"maxFindings\", 0, \"Number of results for inspect*, createTrigger, and createInspectTemplate (default 0 (no limit))\")\n+\tautoPopulateTimespan   = flag.Bool(\"autoPopulateTimespan\", false, \"Limit scan to new content only (default false)\")\n+\tincludeQuote           = flag.Bool(\"includeQuote\", false, \"Include a quote of findings for inspect* (default false)\")\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -57,6 +60,14 @@\nfunc main() {\n \tflag.Parse()\n \n \tinfoTypesList := strings.Split(*infoTypesString, \",\")\n+\tvar customDictionariesList []string\n+\tif *customDictionaryString != \"\" {\n+\t\tcustomDictionariesList = []string{*customDictionaryString}\n+\t}\n+\tvar customRegexesList []string\n+\tif *customRegexString != \"\" {\n+\t\tcustomRegexesList = []string{*customRegexString}\n+\t}\n \n \tif *project == \"\" {\n \t\tfmt.Fprintf(os.Stderr, \"Must provide a -project\\n\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -87,23 +98,23 @@\nfunc main() {\n \t\tos.Exit(1)\n \tcase \"inspect\":\n \t\tcheckNArg(1)\n-\t\tinspectString(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1))\n+\t\tinspectString(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1))\n \tcase \"inspectFile\":\n \t\tcheckNArg(1)\n \t\tf, err := os.Open(flag.Arg(1))\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"error opening file: %v\", err)\n \t\t}\n-\t\tinspectFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, bytesType, f)\n+\t\tinspectFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, bytesType, f)\n \tcase \"inspectGCSFile\":\n \t\tcheckNArg(4)\n-\t\tinspectGCSFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4))\n+\t\tinspectGCSFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4))\n \tcase \"inspectDatastore\":\n \t\tcheckNArg(5)\n-\t\tinspectDatastore(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n+\t\tinspectDatastore(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n \tcase \"inspectBigquery\":\n \t\tcheckNArg(5)\n-\t\tinspectBigquery(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n+\t\tinspectBigquery(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n \n \tcase \"redactImage\":\n \t\tcheckNArg(2)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -115,13 +126,13 @@\nfunc main() {\n \n \tcase \"mask\":\n \t\tcheckNArg(1)\n-\t\tmask(os.Stdout, client, *project, flag.Arg(1), \"*\", 0)\n+\t\tmask(os.Stdout, client, *project, flag.Arg(1), infoTypesList, \"*\", 0)\n \tcase \"dateShift\":\n \t\tcheckNArg(1)\n \t\tdeidentifyDateShift(os.Stdout, client, *project, -2000, 2000, flag.Arg(1))\n \tcase \"fpe\":\n \t\tcheckNArg(4)\n-\t\tdeidentifyFPE(os.Stdout, client, *project, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4))\n+\t\tdeidentifyFPE(os.Stdout, client, *project, flag.Arg(1), infoTypesList, flag.Arg(2), flag.Arg(3), flag.Arg(4))\n \tcase \"reidentifyFPE\":\n \t\tcheckNArg(4)\n \t\treidentifyFPE(os.Stdout, client, *project, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4))",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -461,7 +461,7 @@\nfunc riskLDiversity(w io.Writer, client *dlp.Client, project, dataProject, pubSu\n \n // [END dlp_l_diversity]\n \n-// [START k_map]\n+// [START dlp_k_map]\n \n // riskKMap runs K Map on the given data.\n func riskKMap(w io.Writer, client *dlp.Client, project, dataProject, pubSubTopic, pubSubSub, datasetID, tableID, region string, columnNames ...string) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/templates.go",
        "code_diff": "@@ -17,7 +17,7 @@\nimport (\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )\n \n-// [START dlp_create_template]\n+// [START dlp_create_inspect_template]\n \n // createInspectTemplate creates a template with the given configuration.\n func createInspectTemplate(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, templateID, displayName, description string, infoTypes []string) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/templates.go",
        "code_diff": "@@ -52,9 +52,9 @@\nfunc createInspectTemplate(w io.Writer, client *dlp.Client, project string, minL\n \tfmt.Fprintf(w, \"Successfully created inspect template: %v\", resp.GetName())\n }\n \n-// [END dlp_create_template]\n+// [END dlp_create_inspect_template]\n \n-// [START dlp_list_templates]\n+// [START dlp_list_inspect_templates]\n \n // listInspectTemplates lists the inspect templates in the project.\n func listInspectTemplates(w io.Writer, client *dlp.Client, project string) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/templates.go",
        "code_diff": "@@ -82,9 +82,9 @@\nfunc listInspectTemplates(w io.Writer, client *dlp.Client, project string) {\n \t}\n }\n \n-// [END dlp_list_templates]\n+// [END dlp_list_inspect_templates]\n \n-// [START dlp_delete_template]\n+// [START dlp_delete_inspect_template]\n \n // deleteInspectTemplate deletes the given template.\n func deleteInspectTemplate(w io.Writer, client *dlp.Client, templateID string) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/triggers.go",
        "code_diff": "@@ -22,7 +22,7 @@\nimport (\n // [START dlp_create_trigger]\n \n // createTrigger creates a trigger with the given configuration.\n-func createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, triggerID, displayName, description, bucketName string, scanPeriod int64, infoTypes []string) {\n+func createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, triggerID, displayName, description, bucketName string, autoPopulateTimespan bool, scanPeriodDays int64, infoTypes []string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "dlp/dlp_snippets/triggers.go",
        "code_diff": "@@ -40,11 +40,11 @@\nfunc createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihoo\n \t\t\t// Triggers control when the job will start.\n \t\t\tTriggers: []*dlppb.JobTrigger_Trigger{\n \t\t\t\t{\n-\t\t\t\t\t&dlppb.JobTrigger_Trigger_Schedule{\n+\t\t\t\t\tTrigger: &dlppb.JobTrigger_Trigger_Schedule{\n \t\t\t\t\t\tSchedule: &dlppb.Schedule{\n \t\t\t\t\t\t\tOption: &dlppb.Schedule_RecurrencePeriodDuration{\n \t\t\t\t\t\t\t\tRecurrencePeriodDuration: &duration.Duration{\n-\t\t\t\t\t\t\t\t\tSeconds: scanPeriod * 60 * 60 * 24, // Trigger the scan daily\n+\t\t\t\t\t\t\t\t\tSeconds: scanPeriodDays * 60 * 60 * 24, // Days to seconds.\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -29,6 +29,8 @@\nfunc projectResource(projectID string) string {\n \treturn \"projects/\" + projectID\n }\n \n+// [START monitoring_create_metric]\n+\n // createCustomMetric creates a custom metric specified by the metric type.\n func createCustomMetric(s *monitoring.Service, projectID, metricType string) error {\n \tld := monitoring.LabelDescriptor{Key: \"environment\", ValueType: \"STRING\", Description: \"An arbitrary measurement\"}",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -50,6 +52,10 @@\nfunc createCustomMetric(s *monitoring.Service, projectID, metricType string) err\n \treturn nil\n }\n \n+// [END monitoring_create_metric]\n+\n+// [START monitoring_list_descriptors]\n+\n // getCustomMetric reads the custom metric created.\n func getCustomMetric(s *monitoring.Service, projectID, metricType string) (*monitoring.ListMetricDescriptorsResponse, error) {\n \tresp, err := s.Projects.MetricDescriptors.List(projectResource(projectID)).",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -62,6 +68,10 @@\nfunc getCustomMetric(s *monitoring.Service, projectID, metricType string) (*moni\n \treturn resp, nil\n }\n \n+// [END monitoring_list_descriptors]\n+\n+// [START monitoring_write_timeseries]\n+\n // writeTimeSeriesValue writes a value for the custom metric created\n func writeTimeSeriesValue(s *monitoring.Service, projectID, metricType string) error {\n \tnow := time.Now().UTC().Format(time.RFC3339Nano)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -105,6 +115,10 @@\nfunc writeTimeSeriesValue(s *monitoring.Service, projectID, metricType string) e\n \treturn nil\n }\n \n+// [END monitoring_write_timeseries]\n+\n+// [START monitoring_read_timeseries_simple]\n+\n // readTimeSeriesValue reads the TimeSeries for the value specified by metric type in a time window from the last 5 minutes.\n func readTimeSeriesValue(s *monitoring.Service, projectID, metricType string) error {\n \tstartTime := time.Now().UTC().Add(time.Minute * -5)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/pubsub_quickstart/main.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START pubsub_quickstart]\n+// [START pubsub_quickstart_create_topic]\n // Sample pubsub-quickstart creates a Google Cloud Pub/Sub topic.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -13,18 +13,15 @@\nimport (\n \t\"sync\"\n \t\"time\"\n \n-\t// [START imports]\n \t\"golang.org/x/net/context\"\n \n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"google.golang.org/api/iterator\"\n-\t// [END imports]\n )\n \n func main() {\n \tctx := context.Background()\n-\t// [START auth]\n \tproj := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tif proj == \"\" {\n \t\tfmt.Fprintf(os.Stderr, \"GOOGLE_CLOUD_PROJECT environment variable must be set.\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -34,7 +31,6 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create pubsub Client: %v\", err)\n \t}\n-\t// [END auth]\n \n \t// Print all the subscriptions in the project.\n \tfmt.Println(\"Listing all subscriptions from the project:\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -67,7 +63,7 @@\nfunc main() {\n \n func list(client *pubsub.Client) ([]*pubsub.Subscription, error) {\n \tctx := context.Background()\n-\t// [START get_all_subscriptions]\n+\t// [START pubsub_list_subscriptions]\n \tvar subs []*pubsub.Subscription\n \tit := client.Subscriptions(ctx)\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -80,7 +76,7 @@\nfunc list(client *pubsub.Client) ([]*pubsub.Subscription, error) {\n \t\t}\n \t\tsubs = append(subs, s)\n \t}\n-\t// [END get_all_subscriptions]\n+\t// [END pubsub_list_subscriptions]\n \treturn subs, nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -104,7 +100,8 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \t\t}\n \t}\n \n-\t// [START pull_messages]\n+\t// [START pubsub_subscriber_async_pull]\n+\t// [START pubsub_quickstart_subscriber]\n \t// Consume 10 messages.\n \tvar mu sync.Mutex\n \treceived := 0",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -123,13 +120,14 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\t// [END pull_messages]\n+\t// [END pubsub_subscriber_async_pull]\n+\t// [END pubsub_quickstart_subscriber]\n \treturn nil\n }\n \n func pullMsgsError(client *pubsub.Client, name string) error {\n \tctx := context.Background()\n-\t// [START pull_messages_error]\n+\t// [START pubsub_subscriber_error_listener]\n \t// If the service returns a non-retryable error, Receive returns that error after\n \t// all of the outstanding calls to the handler have returned.\n \terr := client.Subscription(name).Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -139,13 +137,13 @@\nfunc pullMsgsError(client *pubsub.Client, name string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\t// [END pull_messages_error]\n+\t// [END pubsub_subscriber_error_listener]\n \treturn nil\n }\n \n func pullMsgsSettings(client *pubsub.Client, name string) error {\n \tctx := context.Background()\n-\t// [START pull_messages_settings]\n+\t// [START pubsub_subscriber_flow_settings]\n \tsub := client.Subscription(name)\n \tsub.ReceiveSettings.MaxOutstandingMessages = 10\n \terr := sub.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -155,13 +153,13 @@\nfunc pullMsgsSettings(client *pubsub.Client, name string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\t// [END pull_messages_settings]\n+\t// [END pubsub_subscriber_flow_settings]\n \treturn nil\n }\n \n func create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \tctx := context.Background()\n-\t// [START create_subscription]\n+\t// [START pubsub_create_pull_subscription]\n \tsub, err := client.CreateSubscription(ctx, name, pubsub.SubscriptionConfig{\n \t\tTopic:       topic,\n \t\tAckDeadline: 20 * time.Second,",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -170,13 +168,13 @@\nfunc create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \t\treturn err\n \t}\n \tfmt.Printf(\"Created subscription: %v\\n\", sub)\n-\t// [END create_subscription]\n+\t// [END pubsub_create_pull_subscription]\n \treturn nil\n }\n \n func createWithEndpoint(client *pubsub.Client, name string, topic *pubsub.Topic, endpoint string) error {\n \tctx := context.Background()\n-\t// [START create_push_subscription]\n+\t// [START pubsub_create_push_subscription]\n \n \t// For example, endpoint is \"https://my-test-project.appspot.com/push\".\n \tsub, err := client.CreateSubscription(ctx, name, pubsub.SubscriptionConfig{",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -188,13 +186,13 @@\nfunc createWithEndpoint(client *pubsub.Client, name string, topic *pubsub.Topic,\n \t\treturn err\n \t}\n \tfmt.Printf(\"Created subscription: %v\\n\", sub)\n-\t// [END create_push_subscription]\n+\t// [END pubsub_create_push_subscription]\n \treturn nil\n }\n \n func updateEndpoint(client *pubsub.Client, name string, endpoint string) error {\n \tctx := context.Background()\n-\t// [START update_push_subscription]\n+\t// [START pubsub_update_push_configuration]\n \n \t// For example, endpoint is \"https://my-test-project.appspot.com/push\".\n \tsubConfig, err := client.Subscription(name).Update(ctx, pubsub.SubscriptionConfigToUpdate{",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -12,18 +12,15 @@\nimport (\n \t\"os\"\n \t\"time\"\n \n-\t// [START imports]\n \t\"golang.org/x/net/context\"\n \n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"google.golang.org/api/iterator\"\n-\t// [END imports]\n )\n \n func main() {\n \tctx := context.Background()\n-\t// [START auth]\n \tproj := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tif proj == \"\" {\n \t\tfmt.Fprintf(os.Stderr, \"GOOGLE_CLOUD_PROJECT environment variable must be set.\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -33,7 +30,6 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create pubsub Client: %v\", err)\n \t}\n-\t// [END auth]\n \n \t// List all the topics from the project.\n \tfmt.Println(\"Listing all topics from the project:\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -64,20 +60,20 @@\nfunc main() {\n \n func create(client *pubsub.Client, topic string) error {\n \tctx := context.Background()\n-\t// [START create_topic]\n+\t// [START pubsub_create_topic]\n \tt, err := client.CreateTopic(ctx, topic)\n \tif err != nil {\n \t\treturn err\n \t}\n \tfmt.Printf(\"Topic created: %v\\n\", t)\n-\t// [END create_topic]\n+\t// [END pubsub_create_topic]\n \treturn nil\n }\n \n func list(client *pubsub.Client) ([]*pubsub.Topic, error) {\n \tctx := context.Background()\n \n-\t// [START list_topics]\n+\t// [START pubsub_list_topics]\n \tvar topics []*pubsub.Topic\n \n \tit := client.Topics(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -93,13 +89,13 @@\nfunc list(client *pubsub.Client) ([]*pubsub.Topic, error) {\n \t}\n \n \treturn topics, nil\n-\t// [END list_topics]\n+\t// [END pubsub_list_topics]\n }\n \n func listSubscriptions(client *pubsub.Client, topicID string) ([]*pubsub.Subscription, error) {\n \tctx := context.Background()\n \n-\t// [START list_topic_subscriptions]\n+\t// [START pubsub_list_topic_subscriptions]\n \tvar subs []*pubsub.Subscription\n \n \tit := client.Topic(topicID).Subscriptions(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -113,25 +109,26 @@\nfunc listSubscriptions(client *pubsub.Client, topicID string) ([]*pubsub.Subscri\n \t\t}\n \t\tsubs = append(subs, sub)\n \t}\n-\t// [END list_topic_subscriptions]\n+\t// [END pubsub_list_topic_subscriptions]\n \treturn subs, nil\n }\n \n func delete(client *pubsub.Client, topic string) error {\n \tctx := context.Background()\n-\t// [START delete_topic]\n+\t// [START pubsub_delete_topic]\n \tt := client.Topic(topic)\n \tif err := t.Delete(ctx); err != nil {\n \t\treturn err\n \t}\n \tfmt.Printf(\"Deleted topic: %v\\n\", t)\n-\t// [END delete_topic]\n+\t// [END pubsub_delete_topic]\n \treturn nil\n }\n \n func publish(client *pubsub.Client, topic, msg string) error {\n \tctx := context.Background()\n-\t// [START publish]\n+\t// [START pubsub_publish]\n+\t// [START pubsub_quickstart_publisher]\n \tt := client.Topic(topic)\n \tresult := t.Publish(ctx, &pubsub.Message{\n \t\tData: []byte(msg),",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -143,13 +140,14 @@\nfunc publish(client *pubsub.Client, topic, msg string) error {\n \t\treturn err\n \t}\n \tfmt.Printf(\"Published a message; msg ID: %v\\n\", id)\n-\t// [END publish]\n+\t// [END pubsub_publish]\n+\t// [END pubsub_quickstart_publisher]\n \treturn nil\n }\n \n func publishWithSettings(client *pubsub.Client, topic string, msg []byte) error {\n \tctx := context.Background()\n-\t// [START publish_settings]\n+\t// [START pubsub_publisher_batch_settings]\n \tt := client.Topic(topic)\n \tt.PublishSettings = pubsub.PublishSettings{\n \t\tByteThreshold:  5000,",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -164,13 +162,13 @@\nfunc publishWithSettings(client *pubsub.Client, topic string, msg []byte) error\n \t\treturn err\n \t}\n \tfmt.Printf(\"Published a message; msg ID: %v\\n\", id)\n-\t// [END publish_settings]\n+\t// [END pubsub_publisher_batch_settings]\n \treturn nil\n }\n \n func publishSingleGoroutine(client *pubsub.Client, topic string, msg []byte) error {\n \tctx := context.Background()\n-\t// [START publish_single_goroutine]\n+\t// [START pubsub_publisher_concurrency_control]\n \tt := client.Topic(topic)\n \tt.PublishSettings = pubsub.PublishSettings{\n \t\tNumGoroutines: 1,",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -28,28 +28,33 @@\ntype adminCommand func(ctx context.Context, w io.Writer, adminClient *database.D\n \n var (\n \tcommands = map[string]command{\n-\t\t\"write\":               write,\n-\t\t\"query\":               query,\n-\t\t\"read\":                read,\n-\t\t\"update\":              update,\n-\t\t\"writetransaction\":    writeWithTransaction,\n-\t\t\"querynewcolumn\":      queryNewColumn,\n-\t\t\"queryindex\":          queryUsingIndex,\n-\t\t\"readindex\":           readUsingIndex,\n-\t\t\"readstoringindex\":    readStoringIndex,\n-\t\t\"readonlytransaction\": readOnlyTransaction,\n-\t\t\"readstaledata\":       readStaleData,\n-\t\t\"readbatchdata\":       readBatchData,\n-\t\t\"updatewithtimestamp\": updateWithTimestamp,\n-\t\t\"querywithtimestamp\":  queryWithTimestamp,\n-\t\t\"writewithtimestamp\":  writeWithTimestamp,\n-\t\t\"querynewtable\":       queryNewTable,\n-\t\t\"writetodocstable\":    writeToDocumentsTable,\n-\t\t\"updatedocstable\":     updateDocumentsTable,\n-\t\t\"querydocstable\":      queryDocumentsTable,\n-\t\t\"writewithhistory\":    writeWithHistory,\n-\t\t\"updatewithhistory\":   updateWithHistory,\n-\t\t\"querywithhistory\":    queryWithHistory,\n+\t\t\"write\":                      write,\n+\t\t\"query\":                      query,\n+\t\t\"read\":                       read,\n+\t\t\"update\":                     update,\n+\t\t\"writetransaction\":           writeWithTransaction,\n+\t\t\"querynewcolumn\":             queryNewColumn,\n+\t\t\"queryindex\":                 queryUsingIndex,\n+\t\t\"readindex\":                  readUsingIndex,\n+\t\t\"readstoringindex\":           readStoringIndex,\n+\t\t\"readonlytransaction\":        readOnlyTransaction,\n+\t\t\"readstaledata\":              readStaleData,\n+\t\t\"readbatchdata\":              readBatchData,\n+\t\t\"updatewithtimestamp\":        updateWithTimestamp,\n+\t\t\"querywithtimestamp\":         queryWithTimestamp,\n+\t\t\"writewithtimestamp\":         writeWithTimestamp,\n+\t\t\"querynewtable\":              queryNewTable,\n+\t\t\"writetodocstable\":           writeToDocumentsTable,\n+\t\t\"updatedocstable\":            updateDocumentsTable,\n+\t\t\"querydocstable\":             queryDocumentsTable,\n+\t\t\"writewithhistory\":           writeWithHistory,\n+\t\t\"updatewithhistory\":          updateWithHistory,\n+\t\t\"querywithhistory\":           queryWithHistory,\n+\t\t\"writestructdata\":            writeStructData,\n+\t\t\"querywithstruct\":            queryWithStruct,\n+\t\t\"querywitharrayofstruct\":     queryWithArrayOfStruct,\n+\t\t\"querywithstructfield\":       queryWithStructField,\n+\t\t\"querywithnestedstructfield\": queryWithNestedStructField,\n \t}\n \n \tadminCommands = map[string]adminCommand{",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -216,6 +221,188 @@\nfunc writeWithTimestamp(ctx context.Context, w io.Writer, client *spanner.Client\n \n // [END spanner_insert_data_with_timestamp_column]\n \n+// [START spanner_write_data_for_struct_queries]\n+\n+func writeStructData(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tsingerColumns := []string{\"SingerId\", \"FirstName\", \"LastName\"}\n+\tm := []*spanner.Mutation{\n+\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{6, \"Elena\", \"Campbell\"}),\n+\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{7, \"Gabriel\", \"Wright\"}),\n+\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{8, \"Benjamin\", \"Martinez\"}),\n+\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{9, \"Hannah\", \"Harris\"}),\n+\t}\n+\t_, err := client.Apply(ctx, m)\n+\treturn err\n+}\n+\n+// [END spanner_write_data_for_struct_queries]\n+\n+func queryWithStruct(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\n+\t// [START spanner_create_struct_with_data]\n+\n+\ttype nameStruct struct {\n+\t\tFirstName string\n+\t\tLastName  string\n+\t}\n+\tvar singerInfo = nameStruct{\"Elena\", \"Campbell\"}\n+\n+\t// [END spanner_create_struct_with_data]\n+\n+\t// [START spanner_query_data_with_struct]\n+\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT SingerId FROM SINGERS\n+\t\t\t\tWHERE (FirstName, LastName) = @singerinfo`,\n+\t\tParams: map[string]interface{}{\"singerinfo\": singerInfo},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar singerID int64\n+\t\tif err := row.Columns(&singerID); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d\\n\", singerID)\n+\t}\n+\n+\t// [END spanner_query_data_with_struct]\n+}\n+\n+func queryWithArrayOfStruct(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\n+\t// [START spanner_create_user_defined_struct]\n+\n+\ttype nameType struct {\n+\t\tFirstName string\n+\t\tLastName  string\n+\t}\n+\n+\t// [END spanner_create_user_defined_struct]\n+\n+\t// [START spanner_create_array_of_struct_with_data]\n+\n+\tvar bandMembers = []nameType{\n+\t\t{\"Elena\", \"Campbell\"},\n+\t\t{\"Gabriel\", \"Wright\"},\n+\t\t{\"Benjamin\", \"Martinez\"},\n+\t}\n+\n+\t// [END spanner_create_array_of_struct_with_data]\n+\n+\t// [START spanner_query_data_with_array_of_struct]\n+\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT SingerId FROM SINGERS\n+\t\t\tWHERE STRUCT<FirstName STRING, LastName STRING>(FirstName, LastName)\n+\t\t\tIN UNNEST(@names)`,\n+\t\tParams: map[string]interface{}{\"names\": bandMembers},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar singerID int64\n+\t\tif err := row.Columns(&singerID); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d\\n\", singerID)\n+\t}\n+\n+\t// [END spanner_query_data_with_array_of_struct]\n+}\n+\n+// [START spanner_field_access_on_struct_parameters]\n+\n+func queryWithStructField(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\ttype structParam struct {\n+\t\tFirstName string\n+\t\tLastName  string\n+\t}\n+\tvar singerInfo = structParam{\"Elena\", \"Campbell\"}\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT SingerId FROM SINGERS\n+\t\t\tWHERE FirstName = @name.FirstName`,\n+\t\tParams: map[string]interface{}{\"name\": singerInfo},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar singerID int64\n+\t\tif err := row.Columns(&singerID); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d\\n\", singerID)\n+\t}\n+}\n+\n+// [END spanner_field_access_on_struct_parameters]\n+\n+// [START spanner_field_access_on_nested_struct_parameters]\n+\n+func queryWithNestedStructField(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\ttype nameType struct {\n+\t\tFirstName string\n+\t\tLastName  string\n+\t}\n+\ttype songInfoStruct struct {\n+\t\tSongName    string\n+\t\tArtistNames []nameType\n+\t}\n+\tvar songInfo = songInfoStruct{\n+\t\tSongName: \"Imagination\",\n+\t\tArtistNames: []nameType{\n+\t\t\t{FirstName: \"Elena\", LastName: \"Campbell\"},\n+\t\t\t{FirstName: \"Hannah\", LastName: \"Harris\"},\n+\t\t},\n+\t}\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT SingerId, @songinfo.SongName FROM Singers\n+\t\t\tWHERE STRUCT<FirstName STRING, LastName STRING>(FirstName, LastName)\n+\t\t\tIN UNNEST(@songinfo.ArtistNames)`,\n+\t\tParams: map[string]interface{}{\"songinfo\": songInfo},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar singerID int64\n+\t\tvar songName string\n+\t\tif err := row.Columns(&singerID, &songName); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s\\n\", singerID, songName)\n+\t}\n+}\n+\n+// [END spanner_field_access_on_nested_struct_parameters]\n+\n // [START spanner_query_data]\n \n func query(ctx context.Context, w io.Writer, client *spanner.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -5,6 +5,8 @@\npackage main\n \n import (\n+\t\"fmt\"\n+\t\"os\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -30,6 +32,7 @@\nfunc TestCreate(t *testing.T) {\n \t}\n \n \tbucketName = tc.ProjectID + \"-storage-buckets-tests\"\n+\n \t// Clean up bucket before running tests.\n \tdeleteBucket(storageClient, bucketName)\n \tif err := create(storageClient, tc.ProjectID, bucketName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -236,6 +236,7 @@\nfunc delete(client *storage.Client, bucket, object string) error {\n \treturn nil\n }\n \n+// writeEncryptedObject writes an object encrypted with user-provided AES key to a bucket.\n func writeEncryptedObject(client *storage.Client, bucket, object string, secretKey []byte) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -6,7 +6,9 @@\npackage main\n \n import (\n \t\"bytes\"\n+\t\"fmt\"\n \t\"log\"\n+\t\"os\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -38,6 +38,8 @@\nfunc createClientWithKey() {\n \tfmt.Printf(\"%#v\", resp)\n }\n \n+// [START translate_translate_text]\n+\n func translateText(targetLanguage, text string) (string, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -59,6 +61,9 @@\nfunc translateText(targetLanguage, text string) (string, error) {\n \treturn resp[0].Text, nil\n }\n \n+// [END translate_translate_text]\n+// [START translate_detect_language]\n+\n func detectLanguage(text string) (*translate.Detection, error) {\n \tctx := context.Background()\n \tclient, err := translate.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -74,6 +79,10 @@\nfunc detectLanguage(text string) (*translate.Detection, error) {\n \treturn &lang[0][0], nil\n }\n \n+// [END translate_detect_language]\n+// [START translate_list_codes]\n+// [START translate_list_language_names]\n+\n func listSupportedLanguages(w io.Writer, targetLanguage string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -100,6 +109,11 @@\nfunc listSupportedLanguages(w io.Writer, targetLanguage string) error {\n \treturn nil\n }\n \n+// [END translate_list_language_names]\n+// [END translate_list_codes]\n+\n+// [START translate_text_with_model]\n+\n func translateTextWithModel(targetLanguage, text, model string) (string, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "videointelligence/video_analyze/gen/template.go",
        "code_diff": "@@ -56,6 +56,9 @@\nfunc boilerplate() { //# omit\n \t//# enddef\n } //# omit\n \n+// [START video_analyze_labels_local] //# include if !gcs\n+// [START video_analyze_labels_gcs] //# include if gcs\n+\n func label__SUFFIX__(w io.Writer, file string) error {\n \t//# replace __req.feature__ videopb.Feature_LABEL_DETECTION\n \tvar resp *videopb.AnnotateVideoResponse //# template dorequest",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "videointelligence/video_analyze/gen/template.go",
        "code_diff": "@@ -87,6 +90,11 @@\nfunc label__SUFFIX__(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END video_analyze_labels_local] //# include if !gcs\n+// [END video_analyze_labels_gcs] //# include if gcs\n+\n+// [START video_analyze_shots] //# include if gcs\n+\n func shotChange__SUFFIX__(w io.Writer, file string) error {\n \t//# replace __req.feature__ videopb.Feature_SHOT_CHANGE_DETECTION\n \tvar resp *videopb.AnnotateVideoResponse //# template dorequest",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "videointelligence/video_analyze/gen/template.go",
        "code_diff": "@@ -104,6 +112,10 @@\nfunc shotChange__SUFFIX__(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END video_analyze_shots] //# include if gcs\n+\n+// [START video_analyze_explicit_content] //# include if gcs\n+\n func explicitContent__SUFFIX__(w io.Writer, file string) error {\n \t//# replace __req.feature__ videopb.Feature_EXPLICIT_CONTENT_DETECTION\n \tvar resp *videopb.AnnotateVideoResponse //# template dorequest",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -16,6 +16,8 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n+// [START video_analyze_labels_local]\n+\n func label(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -15,6 +15,8 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n+// [START video_analyze_labels_gcs]\n+\n func labelURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -63,6 +65,10 @@\nfunc labelURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END video_analyze_labels_gcs]\n+\n+// [START video_analyze_shots]\n+\n func shotChangeURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -97,6 +103,10 @@\nfunc shotChangeURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END video_analyze_shots]\n+\n+// [START video_analyze_explicit_content]\n+\n func explicitContentURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into vision-pdf-samples",
        "commit_id": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -7,22 +7,25 @@\npackage main\n import (\n \t\"fmt\"\n \t\"html/template\"\n-\t\"io\"\n \t\"net/http\"\n-\t\"path\"\n-\t\"strings\"\n \t\"time\"\n \n-\t\"golang.org/x/net/context\"\n+\tfirebase \"firebase.google.com/go\"\n \t\"google.golang.org/appengine\"\n \t\"google.golang.org/appengine/datastore\"\n-\t\"google.golang.org/appengine/delay\"\n \t\"google.golang.org/appengine/log\"\n \n+\t// [START new_imports]\n+\t\"io\"\n+\t\"path\"\n+\t\"strings\"\n+\n \t\"cloud.google.com/go/storage\"\n \tvision \"cloud.google.com/go/vision/apiv1\"\n-\tfirebase \"firebase.google.com/go\"\n \tuuid \"github.com/satori/go.uuid\"\n+\t\"golang.org/x/net/context\"\n+\t\"google.golang.org/appengine/delay\"\n+\t// [END new_imports]\n )\n \n var (",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -34,12 +37,18 @@\nvar (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n+// [START label_struct]\n+\n // A Label is a description for a post's image.\n type Label struct {\n \tDescription string\n \tScore       float32\n }\n \n+// [END label_struct]\n+\n+// [START new_post_fields]\n+\n type Post struct {\n \tAuthor   string\n \tUserID   string",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -49,6 +58,8 @@\ntype Post struct {\n \tLabels   []Label\n }\n \n+// [END new_post_fields]\n+\n type templateParams struct {\n \tNotice  string\n \tName    string",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -61,6 +72,8 @@\nfunc main() {\n \tappengine.Main()\n }\n \n+// [START var_label_func]\n+\n // labelFunc will be called asynchronously as a Cloud Task. labelFunc can\n // be executed by calling labelFunc.Call(ctx, postID). If an error is returned\n // the function will be retried.",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -108,6 +121,10 @@\nvar labelFunc = delay.Func(\"label-image\", func(ctx context.Context, id int64) er\n \treturn nil\n })\n \n+// [END var_label_func]\n+\n+// [START upload_image]\n+\n // uploadFileFromForm uploads a file if it's present in the \"image\" form field.\n func uploadFileFromForm(ctx context.Context, r *http.Request) (url string, err error) {\n \t// Read the file from the form.",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -163,6 +180,8 @@\nfunc uploadFileFromForm(ctx context.Context, r *http.Request) (url string, err e\n \treturn fmt.Sprintf(publicURL, firebaseConfig.StorageBucket, name), nil\n }\n \n+// [END upload_image}\n+\n func indexHandler(w http.ResponseWriter, r *http.Request) {\n \tif r.URL.Path != \"/\" {\n \t\thttp.Redirect(w, r, \"/\", http.StatusFound)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -235,6 +254,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t}\n \tparams.Name = post.Author\n \n+\t// [START image_URL]\n \t// Get the image if there is one.\n \timageURL, err := uploadFileFromForm(ctx, r)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -244,7 +264,11 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n+\t// [END image_URL]\n+\n+\t// [START add_image_URL]\n \tpost.ImageURL = imageURL\n+\t// [END add_image_URL]\n \n \tkey := datastore.NewIncompleteKey(ctx, \"Post\", nil)\n \tif key, err = datastore.Put(ctx, key, &post); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "appengine/gophers/gophers-6/static/index.js",
        "code_diff": "@@ -23,7 +23,7 @@\nwindow.addEventListener('load', function () {\n       // User is signed in.\n       document.getElementById('sign-out').hidden = false;\n       document.getElementById('post-form').hidden = false;\n-      var account = document.getElementById('account-details').textContent =\n+      document.getElementById('account-details').textContent =\n           'Signed in as ' + user.displayName + ' (' + user.email + ')';\n       user.getIdToken().then(function (accessToken) {\n         // Add the token to the post form. The user info will be extracted",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "auth/snippets.go",
        "code_diff": "@@ -14,12 +14,14 @@\nimport (\n \t\"golang.org/x/oauth2/google\"\n \tcloudkms \"google.golang.org/api/cloudkms/v1\"\n \t\"google.golang.org/api/iterator\"\n+\t\"google.golang.org/api/option\"\n )\n \n-func adc() {\n-\tctx := context.Background()\n+// [START auth_cloud_implicit]\n \n-\t// [START auth_cloud_implicit]\n+// implicit uses Application Default Credentials to authenticate.\n+func implicit() {\n+\tctx := context.Background()\n \n \t// For API packages whose import path is starting with \"cloud.google.com/go\",\n \t// such as cloud.google.com/go/storage in this case, if there are no credentials",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -33,14 +33,14 @@\nfunc updateDatasetDescription(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_description]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n \t\tDescription: \"Updated Description.\",\n \t}\n-\tif _, err = ds.Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err = ds.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_description]",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -51,14 +51,14 @@\nfunc updateDatasetDefaultExpiration(client *bigquery.Client, datasetID string) e\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_expiration]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n \t\tDefaultTableExpiration: 24 * time.Hour,\n \t}\n-\tif _, err := client.Dataset(datasetID).Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err := client.Dataset(datasetID).Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_expiration]",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -69,13 +69,13 @@\nfunc updateDatasetAccessControl(client *bigquery.Client, datasetID string) error\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_access]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Append a new access control entry to the existing access list.\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n-\t\tAccess: append(original.Access, &bigquery.AccessEntry{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n+\t\tAccess: append(meta.Access, &bigquery.AccessEntry{\n \t\t\tRole:       bigquery.ReaderRole,\n \t\t\tEntityType: bigquery.UserEmailEntity,\n \t\t\tEntity:     \"sample.bigquery.dev@gmail.com\"},",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -84,13 +84,67 @@\nfunc updateDatasetAccessControl(client *bigquery.Client, datasetID string) error\n \n \t// Leverage the ETag for the update to assert there's been no modifications to the\n \t// dataset since the metadata was originally read.\n-\tif _, err := ds.Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_access]\n \treturn nil\n }\n \n+func datasetLabels(client *bigquery.Client, w io.Writer, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_dataset_labels]\n+\tmeta, err := client.Dataset(datasetID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Dataset %s labels:\\n\", datasetID)\n+\tif len(meta.Labels) == 0 {\n+\t\tfmt.Fprintln(w, \"Dataset has no labels defined.\")\n+\t\treturn nil\n+\t}\n+\tfor k, v := range meta.Labels {\n+\t\tfmt.Fprintf(w, \"\\t%s:%s\\n\", k, v)\n+\t}\n+\t// [END bigquery_get_dataset_labels]\n+\treturn nil\n+}\n+\n+func addDatasetLabel(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_label_dataset]\n+\tds := client.Dataset(datasetID)\n+\tmeta, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tupdate := bigquery.DatasetMetadataToUpdate{}\n+\tupdate.SetLabel(\"color\", \"green\")\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_label_dataset]\n+\treturn nil\n+}\n+\n+func deleteDatasetLabel(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_delete_label_dataset]\n+\tds := client.Dataset(datasetID)\n+\tmeta, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tupdate := bigquery.DatasetMetadataToUpdate{}\n+\tupdate.DeleteLabel(\"color\")\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_delete_label_dataset]\n+\treturn nil\n+}\n+\n func deleteEmptyDataset(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_delete_dataset]",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -116,6 +170,85 @@\nfunc listDatasets(client *bigquery.Client) error {\n \treturn nil\n }\n \n+func listDatasetsByLabel(client *bigquery.Client, w io.Writer) error {\n+\tctx := context.Background()\n+\t// [START bigquery_list_datasets_by_label]\n+\tit := client.Datasets(ctx)\n+\tit.Filter = \"labels.color:green\"\n+\tfor {\n+\t\tdataset, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"dataset: %s\\n\", dataset.DatasetID)\n+\t}\n+\t// [END bigquery_list_datasets_by_label]\n+\treturn nil\n+}\n+\n+func printDatasetInfo(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_dataset]\n+\tmeta, err := client.Dataset(datasetID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Printf(\"Dataset ID: %s\\n\", datasetID)\n+\tfmt.Printf(\"Description: %s\\n\", meta.Description)\n+\tfmt.Println(\"Labels:\")\n+\tfor k, v := range meta.Labels {\n+\t\tfmt.Printf(\"\\t%s: %s\", k, v)\n+\t}\n+\tfmt.Println(\"Tables:\")\n+\tit := client.Dataset(datasetID).Tables(ctx)\n+\n+\tcnt := 0\n+\tfor {\n+\t\tt, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tcnt++\n+\t\tfmt.Printf(\"\\t%s\\n\", t.TableID)\n+\t}\n+\tif cnt == 0 {\n+\t\tfmt.Println(\"\\tThis dataset does not contain any tables.\")\n+\t}\n+\t// [END bigquery_get_dataset]\n+\treturn nil\n+}\n+\n+func listJobs(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_list_jobs]\n+\tit := client.Jobs(ctx)\n+\tfor i := 0; i < 10; i++ {\n+\t\tj, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tstate := \"Unknown\"\n+\t\tswitch j.LastStatus().State {\n+\t\tcase bigquery.Pending:\n+\t\t\tstate = \"Pending\"\n+\t\tcase bigquery.Running:\n+\t\t\tstate = \"Running\"\n+\t\tcase bigquery.Done:\n+\t\t\tstate = \"Done\"\n+\t\t}\n+\t\tfmt.Printf(\"Job %s in state %s\\n\", j.ID(), state)\n+\t}\n+\t// [END bigquery_list_jobs]\n+\treturn nil\n+}\n+\n // Item represents a row item.\n type Item struct {\n \tName string",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -178,14 +311,14 @@\nfunc updateTableDescription(client *bigquery.Client, datasetID, tableID string)\n \tctx := context.Background()\n \t// [START bigquery_update_table_description]\n \ttableRef := client.Dataset(datasetID).Table(tableID)\n-\toriginal, err := tableRef.Metadata(ctx)\n+\tmeta, err := tableRef.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tnewMeta := bigquery.TableMetadataToUpdate{\n+\tupdate := bigquery.TableMetadataToUpdate{\n \t\tDescription: \"Updated description.\",\n \t}\n-\tif _, err = tableRef.Update(ctx, newMeta, original.ETag); err != nil {\n+\tif _, err = tableRef.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_table_description]",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -197,21 +330,75 @@\nfunc updateTableExpiration(client *bigquery.Client, datasetID, tableID string) e\n \tctx := context.Background()\n \t// [START bigquery_update_table_expiration]\n \ttableRef := client.Dataset(datasetID).Table(tableID)\n-\toriginal, err := tableRef.Metadata(ctx)\n+\tmeta, err := tableRef.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tnewMeta := bigquery.TableMetadataToUpdate{\n+\tupdate := bigquery.TableMetadataToUpdate{\n \t\tExpirationTime: time.Now().Add(time.Duration(5*24) * time.Hour), // table expiration in 5 days.\n \t}\n-\tif _, err = tableRef.Update(ctx, newMeta, original.ETag); err != nil {\n+\tif _, err = tableRef.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_table_expiration]\n \treturn nil\n \n }\n \n+func tableLabels(client *bigquery.Client, w io.Writer, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_table_labels]\n+\tmeta, err := client.Dataset(datasetID).Table(tableID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Table %s labels:\\n\", datasetID)\n+\tif len(meta.Labels) == 0 {\n+\t\tfmt.Println(\"Table has no labels defined.\")\n+\t\treturn nil\n+\t}\n+\tfor k, v := range meta.Labels {\n+\t\tfmt.Fprintf(w, \"\\t%s:%s\\n\", k, v)\n+\t}\n+\t// [END bigquery_get_table_labels]\n+\treturn nil\n+}\n+\n+func addTableLabel(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_label_table]\n+\ttbl := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tbl.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tupdate := bigquery.TableMetadataToUpdate{}\n+\tupdate.SetLabel(\"color\", \"green\")\n+\tif _, err := tbl.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_label_table]\n+\treturn nil\n+}\n+\n+func deleteTableLabel(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_delete_label_table]\n+\ttbl := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tbl.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tupdate := bigquery.TableMetadataToUpdate{}\n+\tupdate.DeleteLabel(\"color\")\n+\tif _, err := tbl.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_delete_label_table]\n+\treturn nil\n+}\n+\n func listTables(client *bigquery.Client, w io.Writer, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_list_tables]",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -246,73 +433,250 @@\nfunc insertRows(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n-func listRows(client *bigquery.Client, datasetID, tableID string) error {\n-\tctx := context.Background()\n-\tq := client.Query(fmt.Sprintf(`\n-\t\tSELECT name, age\n-\t\tFROM %s.%s\n-\t\tWHERE age >= 20\n-\t`, datasetID, tableID))\n-\tit, err := q.Read(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\tfor {\n-\t\tvar row []bigquery.Value\n-\t\terr := it.Next(&row)\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Println(row)\n-\t}\n-\treturn nil\n-}\n-\n-func basicQuery(client *bigquery.Client, datasetID, tableID string) error {\n+func queryBasic(client *bigquery.Client) error {\n \tctx := context.Background()\n \t// [START bigquery_query]\n+\n \tq := client.Query(\n \t\t\"SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` \" +\n \t\t\t\"WHERE state = \\\"TX\\\" \" +\n \t\t\t\"LIMIT 100\")\n \t// Location must match that of the dataset(s) referenced in the query.\n \tq.Location = \"US\"\n+\t// [END bigquery_query]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryDisableCache(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_no_cache]\n+\n+\tq := client.Query(\n+\t\t\"SELECT corpus FROM `bigquery-public-data.samples.shakespeare` GROUP BY corpus;\")\n+\tq.DisableQueryCache = true\n+\t// Location must match that of the dataset(s) referenced in the query.\n+\tq.Location = \"US\"\n+\t// [END bigquery_query_no_cache]\n \n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryBatch(client *bigquery.Client, dstDatasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_batch]\n+\t// Build an aggregate table.\n+\tq := client.Query(`\n+\t\tSELECT\n+  \t\t\tcorpus,\n+  \t\t\tSUM(word_count) as total_words,\n+  \t\t\tCOUNT(1) as unique_words\n+\t\tFROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+\t\tGROUP BY corpus;`)\n+\tq.Priority = bigquery.BatchPriority\n+\tq.QueryConfig.Dst = client.Dataset(dstDatasetID).Table(dstTableID)\n+\n+\t// Start the job.\n \tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n+\t// Job is started and will progress without interaction.\n+\t// To simulate other work being done, sleep a few seconds.\n+\ttime.Sleep(5 * time.Second)\n+\tstatus, err := job.Status(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n \n-\t// Wait until async querying is done.\n-\tstatus, err := job.Wait(ctx)\n+\tstate := \"Unknown\"\n+\tswitch status.State {\n+\tcase bigquery.Pending:\n+\t\tstate = \"Pending\"\n+\tcase bigquery.Running:\n+\t\tstate = \"Running\"\n+\tcase bigquery.Done:\n+\t\tstate = \"Done\"\n+\t}\n+\t// You can continue to monitor job progress until it reaches\n+\t// the Done state by polling periodically.  In this example,\n+\t// we print the latest status.\n+\tfmt.Printf(\"Job %s in Location %s currently in state: %s\\n\", job.ID(), job.Location(), state)\n+\n+\t// [END bigquery_query_batch]\n+\tjob.Cancel(ctx)\n+\treturn nil\n+}\n+\n+func queryDryRun(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_dry_run]\n+\tq := client.Query(`\n+\tSELECT\n+\t\tname,\n+\t\tCOUNT(*) as name_count\n+\tFROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n+\tWHERE state = 'WA'\n+\tGROUP BY name`)\n+\tq.DryRun = true\n+\t// Location must match that of the dataset(s) referenced in the query.\n+\tq.Location = \"US\"\n+\n+\tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tif err := status.Err(); err != nil {\n+\t// Dry run is not asynchronous, so get the latest status and statistics.\n+\tstatus := job.LastStatus()\n+\tif err != nil {\n \t\treturn err\n \t}\n+\tfmt.Printf(\"This query will process %d bytes\\n\", status.Statistics.TotalBytesProcessed)\n+\t// [END bigquery_query_dry_run]\n+\treturn nil\n+}\n \n-\tit, err := job.Read(ctx)\n-\tfor {\n-\t\tvar row []bigquery.Value\n-\t\terr := it.Next(&row)\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Println(row)\n+func queryWithDestination(client *bigquery.Client, destDatasetID, destTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_destination_table]\n+\n+\tq := client.Query(\"SELECT 17 as my_col\")\n+\tq.Location = \"US\" // Location must match the dataset(s) referenced in query.\n+\tq.QueryConfig.Dst = client.Dataset(destDatasetID).Table(destTableID)\n+\t// [END bigquery_query_destination_table]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryLegacy(client *bigquery.Client, sqlString string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_legacy]\n+\tq := client.Query(sqlString)\n+\tq.UseLegacySQL = true\n+\n+\t// [END bigquery_query_legacy]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryLegacyLargeResults(client *bigquery.Client, dstDatasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_legacy_large_results]\n+\tq := client.Query(\n+\t\t\"SELECT corpus FROM [bigquery-public-data:samples.shakespeare] GROUP BY corpus;\")\n+\tq.UseLegacySQL = true\n+\tq.AllowLargeResults = true\n+\tq.QueryConfig.Dst = client.Dataset(dstDatasetID).Table(dstTableID)\n+\t// [END bigquery_query_legacy_large_results]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithArrayParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_arrays]\n+\tq := client.Query(\n+\t\t`SELECT\n+\t\t\tname,\n+\t\t\tsum(number) as count \n+        FROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n+\t\tWHERE\n+\t\t\tgender = @gender\n+        \tAND state IN UNNEST(@states)\n+\t\tGROUP BY\n+\t\t\tname\n+\t\tORDER BY\n+\t\t\tcount DESC\n+\t\tLIMIT 10;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"gender\",\n+\t\t\tValue: \"M\",\n+\t\t},\n+\t\t{\n+\t\t\tName:  \"states\",\n+\t\t\tValue: []string{\"WA\", \"WI\", \"WV\", \"WY\"},\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_arrays]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithNamedParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_named]\n+\tq := client.Query(\n+\t\t`SELECT word, word_count\n+        FROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+        WHERE corpus = @corpus\n+        AND word_count >= @min_word_count\n+        ORDER BY word_count DESC;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"corpus\",\n+\t\t\tValue: \"romeoandjuliet\",\n+\t\t},\n+\t\t{\n+\t\t\tName:  \"min_word_count\",\n+\t\t\tValue: 250,\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_named]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithPositionalParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_positional]\n+\tq := client.Query(\n+\t\t`SELECT word, word_count\n+        FROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+        WHERE corpus = ?\n+        AND word_count >= ?\n+        ORDER BY word_count DESC;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tValue: \"romeoandjuliet\",\n+\t\t},\n+\t\t{\n+\t\t\tValue: 250,\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_positional]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithTimestampParam(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_timestamps]\n+\tq := client.Query(\n+\t\t`SELECT TIMESTAMP_ADD(@ts_value, INTERVAL 1 HOUR);`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"ts_value\",\n+\t\t\tValue: time.Date(2016, 12, 7, 8, 0, 0, 0, time.UTC),\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_timestamps]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithStructParam(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_structs]\n+\ttype MyStruct struct {\n+\t\tX int64\n+\t\tY string\n \t}\n-\t// [END bigquery_query]\n-\treturn nil\n+\tq := client.Query(\n+\t\t`SELECT @struct_value as s;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"struct_value\",\n+\t\t\tValue: MyStruct{X: 1, Y: \"foo\"},\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_structs]\n+\treturn runAndRead(ctx, client, q)\n }\n \n-func printTableMetadataSimple(client *bigquery.Client, datasetID, tableID string) error {\n+func printTableInfo(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_table]\n \tmeta, err := client.Dataset(datasetID).Table(tableID).Metadata(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -322,7 +686,7 @@\nfunc printTableMetadataSimple(client *bigquery.Client, datasetID, tableID string\n \t// Print basic information about the table.\n \tfmt.Printf(\"Schema has %d top-level fields\\n\", len(meta.Schema))\n \tfmt.Printf(\"Description: %s\\n\", meta.Description)\n-\tfmt.Printf(\"Row in managed storage: %d\\n\", meta.NumRows)\n+\tfmt.Printf(\"Rows in managed storage: %d\\n\", meta.NumRows)\n \t// [END bigquery_get_table]\n \treturn nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -368,6 +732,66 @@\nfunc copyTable(client *bigquery.Client, datasetID, srcID, dstID string) error {\n \treturn nil\n }\n \n+// generateTableCTAS creates a quick table by issuing a CREATE TABLE AS SELECT\n+// query.\n+func generateTableCTAS(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\tq := client.Query(\n+\t\tfmt.Sprintf(\n+\t\t\t`CREATE TABLE %s.%s \n+\t\tAS\n+\t\tSELECT\n+\t\t  2000 + CAST(18 * RAND() as INT64) as year,\n+\t\t  IF(RAND() > 0.5,\"foo\",\"bar\") as token\n+\t\tFROM\n+\t\t  UNNEST(GENERATE_ARRAY(0,5,1)) as r`, datasetID, tableID))\n+\tjob, err := q.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\treturn nil\n+}\n+\n+func copyMultiTable(client *bigquery.Client, datasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// Generate some dummy tables via a quick CTAS.\n+\tif err := generateTableCTAS(client, datasetID, \"table1\"); err != nil {\n+\t\treturn err\n+\t}\n+\tif err := generateTableCTAS(client, datasetID, \"table2\"); err != nil {\n+\t\treturn err\n+\t}\n+\t// [START bigquery_copy_table_multiple_source]\n+\tdataset := client.Dataset(datasetID)\n+\n+\tsrcTableIDs := []string{\"table1\", \"table2\"}\n+\tvar tableRefs []*bigquery.Table\n+\tfor _, v := range srcTableIDs {\n+\t\ttableRefs = append(tableRefs, dataset.Table(v))\n+\t}\n+\tcopier := dataset.Table(dstTableID).CopierFrom(tableRefs...)\n+\tcopier.WriteDisposition = bigquery.WriteTruncate\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_copy_table_multiple_source]\n+\treturn nil\n+}\n func deleteTable(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_delete_table]",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -379,6 +803,49 @@\nfunc deleteTable(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n+func deleteAndUndeleteTable(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_undelete_table]\n+\n+\tds := client.Dataset(datasetID)\n+\tif _, err := ds.Table(tableID).Metadata(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\t// Record the current time.  We'll use this as the snapshot time\n+\t// for recovering the table.\n+\tsnapTime := time.Now()\n+\n+\t// \"Accidentally\" delete the table.\n+\tif err := client.Dataset(datasetID).Table(tableID).Delete(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Construct the restore-from tableID using a snapshot decorator.\n+\tsnapshotTableID := fmt.Sprintf(\"%s@%d\", tableID, snapTime.UnixNano()/1e6)\n+\t// Choose a new table ID for the recovered table data.\n+\trecoverTableID := fmt.Sprintf(\"%s_recovered\", tableID)\n+\n+\t// Construct and run a copy job.\n+\tcopier := ds.Table(recoverTableID).CopierFrom(ds.Table(snapshotTableID))\n+\tcopier.WriteDisposition = bigquery.WriteTruncate\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// [END bigquery_undelete_table]\n+\tds.Table(recoverTableID).Delete(ctx)\n+\treturn nil\n+\n+}\n+\n func importCSVFromFile(client *bigquery.Client, datasetID, tableID, filename string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_from_file]",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -7,8 +7,7 @@\npackage snippets\n import (\n \t\"bytes\"\n \t\"fmt\"\n-\t\"log\"\n-\t\"os\"\n+\t\"regexp\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -17,24 +16,34 @@\nimport (\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"golang.org/x/net/context\"\n-\t\"golang.org/x/oauth2/google\"\n-\trawbq \"google.golang.org/api/bigquery/v2\"\n \t\"google.golang.org/api/iterator\"\n )\n \n-func init() {\n-\t// Workaround for Travis:\n-\t// https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received\n-\tif os.Getenv(\"TRAVIS\") == \"true\" {\n-\t\tgo func() {\n-\t\t\tfor {\n-\t\t\t\ttime.Sleep(5 * time.Minute)\n-\t\t\t\tlog.Print(\"Still testing. Don't kill me!\")\n-\t\t\t}\n-\t\t}()\n+// uniqueBQName returns a more unique name for a BigQuery resource.\n+func uniqueBQName(prefix string) string {\n+\tt := time.Now()\n+\treturn fmt.Sprintf(\"%s_%d\", sanitize(prefix, '_'), t.Unix())\n+}\n+\n+// uniqueBucketName returns a more unique name cloud storage bucket.\n+func uniqueBucketName(prefix, projectID string) string {\n+\tt := time.Now()\n+\tf := fmt.Sprintf(\"%s-%s-%d\", sanitize(prefix, '-'), sanitize(projectID, '-'), t.Unix())\n+\t// bucket max name length is 63 chars, so we truncate.\n+\tif len(f) > 63 {\n+\t\treturn f[:63]\n \t}\n+\treturn f\n }\n \n+func sanitize(s string, allowedSeparator rune) string {\n+\tpattern := fmt.Sprintf(\"[^a-zA-Z0-9%s]\", string(allowedSeparator))\n+\treg, err := regexp.Compile(pattern)\n+\tif err != nil {\n+\t\treturn s\n+\t}\n+\treturn reg.ReplaceAllString(s, \"\")\n+}\n func TestAll(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -44,17 +53,45 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \n-\tdatasetID := fmt.Sprintf(\"golang_example_dataset_%d\", time.Now().Unix())\n+\tdatasetID := uniqueBQName(\"golang_example_dataset\")\n \tif err := createDataset(client, datasetID); err != nil {\n \t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n \t}\n+\t// Cleanup dataset at end of test.\n+\tdefer client.Dataset(datasetID).DeleteWithContents(ctx)\n \n \tif err := updateDatasetAccessControl(client, datasetID); err != nil {\n \t\tt.Errorf(\"updateDataSetAccessControl(%q): %v\", datasetID, err)\n \t}\n+\tif err := addDatasetLabel(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n+\t}\n+\n+\tbuf := &bytes.Buffer{}\n+\tif err := datasetLabels(client, buf, datasetID); err != nil {\n+\t\tt.Errorf(\"getDatasetLabels(%q): %v\", datasetID, err)\n+\t}\n+\twant := \"color:green\"\n+\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\tt.Errorf(\"getDatasetLabel(%q) expected %q to contain %q\", datasetID, got, want)\n+\t}\n+\n+\tif err := addDatasetLabel(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n+\t}\n+\tbuf.Reset()\n+\tif err := listDatasetsByLabel(client, buf); err != nil {\n+\t\tt.Errorf(\"listDatasetsByLabel: %v\", err)\n+\t}\n+\tif got := buf.String(); !strings.Contains(got, datasetID) {\n+\t\tt.Errorf(\"listDatasetsByLabel expected %q to contain %q\", got, want)\n+\t}\n+\tif err := deleteDatasetLabel(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetDeleteLabel: %v\", err)\n+\t}\n \n \t// Test empty dataset creation/ttl/delete.\n-\tdeletionDatasetID := fmt.Sprintf(\"%s_quickdelete\", datasetID)\n+\tdeletionDatasetID := uniqueBQName(\"golang_example_quickdelete\")\n \tif err := createDataset(client, deletionDatasetID); err != nil {\n \t\tt.Errorf(\"createDataset(%q): %v\", deletionDatasetID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -72,9 +109,9 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"listDatasets: %v\", err)\n \t}\n \n-\tinferred := fmt.Sprintf(\"golang_example_table_inferred_%d\", time.Now().Unix())\n-\texplicit := fmt.Sprintf(\"golang_example_table_explicit_%d\", time.Now().Unix())\n-\tempty := fmt.Sprintf(\"golang_example_table_emptyschema_%d\", time.Now().Unix())\n+\tinferred := uniqueBQName(\"golang_example_table_inferred\")\n+\texplicit := uniqueBQName(\"golang_example_table_explicit\")\n+\tempty := uniqueBQName(\"golang_example_table_emptyschema\")\n \n \tif err := createTableInferredSchema(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"createTableInferredSchema(dataset:%q table:%q): %v\", datasetID, inferred, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -92,8 +129,14 @@\nfunc TestAll(t *testing.T) {\n \tif err := updateTableExpiration(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"updateTableExpiration(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n+\tif err := addTableLabel(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"updateTableAddLabel(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\t}\n+\tif err := deleteTableLabel(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"updateTableAddLabel(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\t}\n \n-\tbuf := &bytes.Buffer{}\n+\tbuf.Reset()\n \tif err := listTables(client, buf, datasetID); err != nil {\n \t\tt.Errorf(\"listTables(%q): %v\", datasetID, err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -108,58 +151,89 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"want table list %q to contain table %q\", got, empty)\n \t}\n \n+\tif err := printDatasetInfo(client, datasetID); err != nil {\n+\t\tt.Errorf(\"printDatasetInfo: %v\", err)\n+\t}\n+\n \t// Stream data, read, query the inferred schema table.\n \tif err := insertRows(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"insertRows(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := listRows(client, datasetID, inferred); err != nil {\n-\t\tt.Errorf(\"listRows(dataset:%q table:%q): %v\", datasetID, inferred, err)\n-\t}\n \tif err := browseTable(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"browseTable(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := basicQuery(client, datasetID, inferred); err != nil {\n-\t\tt.Errorf(\"basicQuery(dataset:%q table:%q): %v\", datasetID, inferred, err)\n+\n+\tif err := queryBasic(client); err != nil {\n+\t\tt.Errorf(\"queryBasic: %v\", err)\n+\t}\n+\tbatchTable := uniqueBQName(\"golang_example_batchresults\")\n+\tif err := queryBatch(client, datasetID, batchTable); err != nil {\n+\t\tt.Errorf(\"queryBatch(dataset:%q table:%q): %v\", datasetID, batchTable, err)\n+\t}\n+\tif err := queryDisableCache(client); err != nil {\n+\t\tt.Errorf(\"queryBasicDisableCache: %v\", err)\n+\t}\n+\tif err := queryDryRun(client); err != nil {\n+\t\tt.Errorf(\"queryDryRun: %v\", err)\n+\t}\n+\tsql := \"SELECT 17 as foo\"\n+\tif err := queryLegacy(client, sql); err != nil {\n+\t\tt.Errorf(\"queryLegacy: %v\", err)\n+\t}\n+\tlargeResults := uniqueBQName(\"golang_example_legacy_largeresults\")\n+\tif err := queryLegacyLargeResults(client, datasetID, largeResults); err != nil {\n+\t\tt.Errorf(\"queryLegacyLargeResults(dataset:%q table:%q): %v\", datasetID, largeResults, err)\n+\t}\n+\tif err := queryWithArrayParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithArrayParams: %v\", err)\n+\t}\n+\tif err := queryWithNamedParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithNamedParams: %v\", err)\n+\t}\n+\tif err := queryWithPositionalParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithPositionalParams: %v\", err)\n+\t}\n+\tif err := queryWithTimestampParam(client); err != nil {\n+\t\tt.Errorf(\"queryWithTimestampParam: %v\", err)\n+\t}\n+\tif err := queryWithStructParam(client); err != nil {\n+\t\tt.Errorf(\"queryWithStructParam: %v\", err)\n+\t}\n+\n+\t// Run query variations\n+\tpersisted := uniqueBQName(\"golang_example_table_queryresult\")\n+\tif err := queryWithDestination(client, datasetID, persisted); err != nil {\n+\t\tt.Errorf(\"queryWithDestination(dataset:%q table:%q): %v\", datasetID, persisted, err)\n \t}\n \n \t// Print information about tables (extended and simple).\n-\tif err := printTableMetadataSimple(client, datasetID, inferred); err != nil {\n-\t\tt.Errorf(\"printTableMetadata(dataset:%q table:%q): %v\", datasetID, inferred, err)\n+\tif err := printTableInfo(client, datasetID, inferred); err != nil {\n+\t\tt.Errorf(\"printTableInfo(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := printTableMetadataSimple(client, datasetID, explicit); err != nil {\n-\t\tt.Errorf(\"printTableMetadata(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\tif err := printTableInfo(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"printTableInfo(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n \n-\tdstTableID := fmt.Sprintf(\"golang_example_tabledst_%d\", time.Now().Unix())\n+\tdstTableID := uniqueBQName(\"golang_example_tabledst\")\n \tif err := copyTable(client, datasetID, inferred, dstTableID); err != nil {\n \t\tt.Errorf(\"copyTable(dataset:%q src:%q dst:%q): %v\", datasetID, inferred, dstTableID, err)\n \t}\n \tif err := deleteTable(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := deleteTable(client, datasetID, dstTableID); err != nil {\n-\t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n+\tif err := deleteAndUndeleteTable(client, datasetID, dstTableID); err != nil {\n+\t\tt.Errorf(\"undeleteTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n \t}\n \n-\tdeleteDataset(t, ctx, datasetID)\n-}\n-\n-func deleteDataset(t *testing.T, ctx context.Context, datasetID string) {\n-\ttc := testutil.SystemTest(t)\n-\thc, err := google.DefaultClient(ctx, rawbq.CloudPlatformScope)\n-\tif err != nil {\n-\t\tt.Errorf(\"DefaultClient: %v\", err)\n-\t}\n-\ts, err := rawbq.New(hc)\n-\tif err != nil {\n-\t\tt.Errorf(\"bigquery.New: %v\", err)\n+\tdstTableID = uniqueBQName(\"golang_multicopydest\")\n+\tif err := copyMultiTable(client, datasetID, dstTableID); err != nil {\n+\t\tt.Errorf(\"copyMultiTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n \t}\n-\tcall := s.Datasets.Delete(tc.ProjectID, datasetID)\n-\tcall.DeleteContents(true)\n-\tcall.Context(ctx)\n-\tif err := call.Do(); err != nil {\n-\t\tt.Errorf(\"deleteDataset(%q): %v\", datasetID, err)\n+\n+\tif err := listJobs(client); err != nil {\n+\t\tt.Errorf(\"listJobs: %v\", err)\n \t}\n+\n }\n \n func TestImportExport(t *testing.T) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -28,40 +28,40 @@\ntype Task struct {\n }\n \n func SnippetNewIncompleteKey() {\n-\t// [START incomplete_key]\n+\t// [START datastore_incomplete_key]\n \ttaskKey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [END incomplete_key]\n+\t// [END datastore_incomplete_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey() {\n-\t// [START named_key]\n+\t// [START datastore_named_key]\n \ttaskKey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [END named_key]\n+\t// [END datastore_named_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withParent() {\n-\t// [START key_with_parent]\n+\t// [START datastore_key_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_parent]\n+\t// [END datastore_key_with_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withMultipleParents() {\n-\t// [START key_with_multilevel_parent]\n+\t// [START datastore_key_with_multilevel_parent]\n \tuserKey := datastore.NameKey(\"User\", \"alice\", nil)\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", userKey)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_multilevel_parent]\n+\t// [END datastore_key_with_multilevel_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetClient_Put() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START entity_with_parent]\n+\t// [START datastore_entity_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tkey := datastore.IncompleteKey(\"Task\", parentKey)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -75,12 +75,12 @@\nfunc SnippetClient_Put() {\n \t// A complete key is assigned to the entity when it is Put.\n \tvar err error\n \tkey, err = client.Put(ctx, key, &task)\n-\t// [END entity_with_parent]\n+\t// [END datastore_entity_with_parent]\n \t_ = err // Make sure you check err.\n }\n \n func Snippet_properties() {\n-\t// [START properties]\n+\t// [START datastore_properties]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -97,12 +97,12 @@\nfunc Snippet_properties() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END properties]\n+\t// [END datastore_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_sliceProperties() {\n-\t// [START array_value]\n+\t// [START datastore_array_value]\n \ttype Task struct {\n \t\tTags          []string\n \t\tCollaborators []string",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -111,12 +111,12 @@\nfunc Snippet_sliceProperties() {\n \t\tTags:          []string{\"fun\", \"programming\"},\n \t\tCollaborators: []string{\"alice\", \"bob\"},\n \t}\n-\t// [END array_value]\n+\t// [END datastore_array_value]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_basicEntity() {\n-\t// [START basic_entity]\n+\t// [START datastore_basic_entity]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -133,7 +133,7 @@\nfunc Snippet_basicEntity() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END basic_entity]\n+\t// [END datastore_basic_entity]\n \t_ = task // Use the task in a datastore Put operation.\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -142,9 +142,9 @@\nfunc SnippetClient_Put_upsert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := &Task{} // Populated with appropriate data.\n \tkey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [START upsert]\n+\t// [START datastore_upsert]\n \tkey, err := client.Put(ctx, key, task)\n-\t// [END upsert]\n+\t// [END datastore_upsert]\n \t_ = err // Make sure you check err.\n \t_ = key // key is the complete key for the newly stored task\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -154,7 +154,7 @@\nfunc SnippetTransaction_insert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := Task{} // Populated with appropriate data.\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START insert]\n+\t// [START datastore_insert]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\t// We first check that there is no entity stored with the given key.\n \t\tvar empty Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -165,26 +165,26 @@\nfunc SnippetTransaction_insert() {\n \t\t_, err := tx.Put(taskKey, &task)\n \t\treturn err\n \t})\n-\t// [END insert]\n+\t// [END datastore_insert]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_Get() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START lookup]\n+\t// [START datastore_lookup]\n \tvar task Task\n \terr := client.Get(ctx, taskKey, &task)\n-\t// [END lookup]\n+\t// [END datastore_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetTransaction_update() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START update]\n+\t// [START datastore_update]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -200,23 +200,23 @@\nfunc SnippetTransaction_update() {\n \tif _, err := tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END update]\n+\t// [END datastore_update]\n }\n \n func SnippetClient_Delete() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START delete]\n+\t// [START datastore_delete]\n \terr := client.Delete(ctx, key)\n-\t// [END delete]\n+\t// [END datastore_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_PutMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START batch_upsert]\n+\t// [START datastore_batch_upsert]\n \ttasks := []*Task{\n \t\t{\n \t\t\tCategory:    \"Personal\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -237,7 +237,7 @@\nfunc SnippetClient_PutMulti() {\n \t}\n \n \tkeys, err := client.PutMulti(ctx, keys, tasks)\n-\t// [END batch_upsert]\n+\t// [END datastore_batch_upsert]\n \t_ = err  // Make sure you check err.\n \t_ = keys // keys now has the complete keys for the newly stored tasks.\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -246,33 +246,33 @@\nfunc SnippetClient_GetMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_lookup]\n+\t// [START datastore_batch_lookup]\n \tvar tasks []*Task\n \terr := client.GetMulti(ctx, taskKeys, &tasks)\n-\t// [END batch_lookup]\n+\t// [END datastore_batch_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_DeleteMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_delete]\n+\t// [START datastore_batch_delete]\n \terr := client.DeleteMulti(ctx, taskKeys)\n-\t// [END batch_delete]\n+\t// [END datastore_batch_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetQuery_basic() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START basic_query]\n+\t// [START datastore_basic_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Priority >=\", 4).\n \t\tOrder(\"-Priority\")\n-\t// [END basic_query]\n-\t// [START run_query]\n+\t// [END datastore_basic_query]\n+\t// [START datastore_run_query]\n \tit := client.Run(ctx, query)\n \tfor {\n \t\tvar task Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -285,75 +285,75 @@\nfunc SnippetQuery_basic() {\n \t\t}\n \t\tfmt.Printf(\"Task %q, Priority %d\\n\", task.Description, task.Priority)\n \t}\n-\t// [END run_query]\n+\t// [END datastore_run_query]\n }\n \n func SnippetQuery_propertyFilter() {\n-\t// [START property_filter]\n+\t// [START datastore_property_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false)\n-\t// [END property_filter]\n+\t// [END datastore_property_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_compositeFilter() {\n-\t// [START composite_filter]\n+\t// [START datastore_composite_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false).Filter(\"Priority =\", 4)\n-\t// [END composite_filter]\n+\t// [END datastore_composite_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_keyFilter() {\n-\t// [START key_filter]\n+\t// [START datastore_key_filter]\n \tkey := datastore.NameKey(\"Task\", \"someTask\", nil)\n \tquery := datastore.NewQuery(\"Task\").Filter(\"__key__ >\", key)\n-\t// [END key_filter]\n+\t// [END datastore_key_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortAscending() {\n-\t// [START ascending_sort]\n+\t// [START datastore_ascending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"created\")\n-\t// [END ascending_sort]\n+\t// [END datastore_ascending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortDescending() {\n-\t// [START descending_sort]\n+\t// [START datastore_descending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-created\")\n-\t// [END descending_sort]\n+\t// [END datastore_descending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortMulti() {\n-\t// [START multi_sort]\n+\t// [START datastore_multi_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-priority\").Order(\"created\")\n-\t// [END multi_sort]\n+\t// [END datastore_multi_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_kindless() {\n \tvar lastSeenKey *datastore.Key\n-\t// [START kindless_query]\n+\t// [START datastore_kindless_query]\n \tquery := datastore.NewQuery(\"\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_query]\n+\t// [END datastore_kindless_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Ancestor() {\n-\t// [START ancestor_query]\n+\t// [START datastore_ancestor_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor)\n-\t// [END ancestor_query]\n+\t// [END datastore_ancestor_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Project() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START projection_query]\n+\t// [START datastore_projection_query]\n \tquery := datastore.NewQuery(\"Task\").Project(\"Priority\", \"PercentComplete\")\n-\t// [END projection_query]\n-\t// [START run_query_projection]\n+\t// [END datastore_projection_query]\n+\t// [START datastore_run_query_projection]\n \tvar priorities []int\n \tvar percents []float64\n \tit := client.Run(ctx, query)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -367,130 +367,119 @@\nfunc SnippetQuery_Project() {\n \t\tpriorities = append(priorities, task.Priority)\n \t\tpercents = append(percents, task.PercentComplete)\n \t}\n-\t// [END run_query_projection]\n+\t// [END datastore_run_query_projection]\n }\n \n func SnippetQuery_KeysOnly() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START keys_only_query]\n+\t// [START datastore_keys_only_query]\n \tquery := datastore.NewQuery(\"Task\").KeysOnly()\n-\t// [END keys_only_query]\n-\t// [START run_keys_only_query]\n+\t// [END datastore_keys_only_query]\n+\n \tkeys, err := client.GetAll(ctx, query, nil)\n-\t// [END run_keys_only_query]\n \t_ = err  // Make sure you check err.\n \t_ = keys // Keys contains keys for all stored tasks.\n }\n \n-func SnippetQuery_Distinct() {\n-\t// [START distinct_query]\n-\tquery := datastore.NewQuery(\"Task\").\n-\t\tProject(\"Priority\", \"PercentComplete\").\n-\t\tDistinct().\n-\t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_query]\n-\t_ = query // Use client.Run or client.GetAll to execute the query.\n-}\n-\n func SnippetQuery_DistinctOn() {\n-\t// [START distinct_on_query]\n+\t// [START datastore_distinct_on_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tProject(\"Priority\", \"Category\").\n \t\tDistinctOn(\"Category\").\n \t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_on_query]\n+\t// [END datastore_distinct_on_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayInequality() {\n-\t// [START array_value_inequality_range]\n+\t// [START datastore_array_value_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag >\", \"learn\").\n \t\tFilter(\"Tag <\", \"math\")\n-\t// [END array_value_inequality_range]\n+\t// [END datastore_array_value_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayEquality() {\n-\t// [START array_value_equality]\n+\t// [START datastore_array_value_equality]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag =\", \"fun\").\n \t\tFilter(\"Tag =\", \"programming\")\n-\t// [END array_value_equality]\n+\t// [END datastore_array_value_equality]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_inequality() {\n-\t// [START inequality_range]\n+\t// [START datastore_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END inequality_range]\n+\t// [END datastore_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_invalidInequality() {\n-\t// [START inequality_invalid]\n+\t// [START datastore_inequality_invalid]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Priority >\", 3)\n-\t// [END inequality_invalid]\n+\t// [END datastore_inequality_invalid]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Filter_mixed() {\n-\t// [START equal_and_inequality_range]\n+\t// [START datastore_equal_and_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority =\", 4).\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END equal_and_inequality_range]\n+\t// [END datastore_equal_and_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_inequalitySort() {\n-\t// [START inequality_sort]\n+\t// [START datastore_inequality_sort]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Priority\").\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort]\n+\t// [END datastore_inequality_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_invalidInequalitySortA() {\n-\t// [START inequality_sort_invalid_not_same]\n+\t// [START datastore_inequality_sort_invalid_not_same]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort_invalid_not_same]\n+\t// [END datastore_inequality_sort_invalid_not_same]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_invalidInequalitySortB() {\n-\t// [START inequality_sort_invalid_not_first]\n+\t// [START datastore_inequality_sort_invalid_not_first]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\").\n \t\tOrder(\"Priority\")\n-\t// [END inequality_sort_invalid_not_first]\n+\t// [END datastore_inequality_sort_invalid_not_first]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Limit() {\n-\t// [START limit]\n+\t// [START datastore_limit]\n \tquery := datastore.NewQuery(\"Task\").Limit(5)\n-\t// [END limit]\n+\t// [END datastore_limit]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetIterator_Cursor() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tcursorStr := \"\"\n-\t// [START cursor_paging]\n+\t// [START datastore_cursor_paging]\n \tconst pageSize = 5\n \tquery := datastore.NewQuery(\"Tasks\").Limit(pageSize)\n \tif cursorStr != \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -516,42 +505,42 @@\nfunc SnippetIterator_Cursor() {\n \n \t// Get the cursor for the next page of results.\n \tnextCursor, err := it.Cursor()\n-\t// [END cursor_paging]\n+\t// [END datastore_cursor_paging]\n \t_ = err        // Check the error.\n \t_ = nextCursor // Use nextCursor.String as the next page's token.\n }\n \n func SnippetQuery_EventualConsistency() {\n-\t// [START eventual_consistent_query]\n+\t// [START datastore_eventual_consistent_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).EventualConsistency()\n-\t// [END eventual_consistent_query]\n+\t// [END datastore_eventual_consistent_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_unindexed() {\n-\t// [START unindexed_property_query]\n+\t// [START datastore_unindexed_property_query]\n \tquery := datastore.NewQuery(\"Tasks\").Filter(\"Description =\", \"A task description\")\n-\t// [END unindexed_property_query]\n+\t// [END datastore_unindexed_property_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func Snippet_explodingProperties() {\n-\t// [START exploding_properties]\n+\t// [START datastore_exploding_properties]\n \ttask := &Task{\n \t\tTags:          []string{\"fun\", \"programming\", \"learn\"},\n \t\tCollaborators: []string{\"alice\", \"bob\", \"charlie\"},\n \t\tCreated:       time.Now(),\n \t}\n-\t// [END exploding_properties]\n+\t// [END datastore_exploding_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_Transaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_update]\n+\t// [START datastore_transactional_update]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -576,14 +565,14 @@\nfunc Snippet_Transaction() {\n \tif _, err = tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END transactional_update]\n+\t// [END datastore_transactional_update]\n }\n \n func Snippet_Client_RunInTransaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_retry]\n+\t// [START datastore_transactional_retry]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -600,15 +589,15 @@\nfunc Snippet_Client_RunInTransaction() {\n \t\t_, err := tx.PutMulti(keys, accs)\n \t\treturn err\n \t})\n-\t// [END transactional_retry]\n+\t// [END datastore_transactional_retry]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_getOrCreate() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START transactional_get_or_create]\n+\t// [START datastore_transactional_get_or_create]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\tvar task Task\n \t\tif err := tx.Get(key, &task); err != datastore.ErrNoSuchEntity {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -622,14 +611,14 @@\nfunc SnippetTransaction_getOrCreate() {\n \t\t})\n \t\treturn err\n \t})\n-\t// [END transactional_get_or_create]\n+\t// [END datastore_transactional_get_or_create]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_runQuery() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START transactional_single_entity_group_read_only]\n+\t// [START datastore_transactional_single_entity_group_read_only]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -640,14 +629,14 @@\nfunc SnippetTransaction_runQuery() {\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).Transaction(tx)\n \tvar tasks []Task\n \t_, err = client.GetAll(ctx, query, &tasks)\n-\t// [END transactional_single_entity_group_read_only]\n+\t// [END datastore_transactional_single_entity_group_read_only]\n \t_ = err // Check error.\n }\n \n func Snippet_metadataNamespaces() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START namespace_run_query]\n+\t// [START datastore_namespace_run_query]\n \tconst (\n \t\tstartNamespace = \"g\"\n \t\tendNamespace   = \"h\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -665,13 +654,13 @@\nfunc Snippet_metadataNamespaces() {\n \tfor _, k := range keys {\n \t\tnamespaces = append(namespaces, k.Name)\n \t}\n-\t// [END namespace_run_query]\n+\t// [END datastore_namespace_run_query]\n }\n \n func Snippet_metadataKinds() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START kind_run_query]\n+\t// [START datastore_kind_run_query]\n \tquery := datastore.NewQuery(\"__kind__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -682,13 +671,13 @@\nfunc Snippet_metadataKinds() {\n \tfor _, k := range keys {\n \t\tkinds = append(kinds, k.Name)\n \t}\n-\t// [END kind_run_query]\n+\t// [END datastore_kind_run_query]\n }\n \n func Snippet_metadataProperties() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_run_query]\n+\t// [START datastore_property_run_query]\n \tquery := datastore.NewQuery(\"__property__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -701,13 +690,13 @@\nfunc Snippet_metadataProperties() {\n \t\tkind := k.Parent.Name\n \t\tprops[kind] = append(props[kind], prop)\n \t}\n-\t// [END property_run_query]\n+\t// [END datastore_property_run_query]\n }\n \n func Snippet_metadataPropertiesForKind() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_by_kind_run_query]\n+\t// [START datastore_property_by_kind_run_query]\n \tkindKey := datastore.NameKey(\"__kind__\", \"Task\", nil)\n \tquery := datastore.NewQuery(\"__property__\").Ancestor(kindKey)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -2,8 +2,6 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START all]\n-\n // A simple command-line task list manager to demonstrate using the\n // cloud.google.com/go/datastore package.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -29,10 +27,10 @@\nfunc main() {\n \tif projID == \"\" {\n \t\tlog.Fatal(`You need to set the environment variable \"DATASTORE_PROJECT_ID\"`)\n \t}\n-\t// [START build_service]\n+\t// [START datastore_build_service]\n \tctx := context.Background()\n \tclient, err := datastore.NewClient(ctx, projID)\n-\t// [END build_service]\n+\t// [END datastore_build_service]\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create datastore client: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -107,7 +105,7 @@\nfunc main() {\n \t}\n }\n \n-// [START add_entity]\n+// [START datastore_add_entity]\n // Task is the model used to store tasks in the datastore.\n type Task struct {\n \tDesc    string    `datastore:\"description\"`",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -127,9 +125,9 @@\nfunc AddTask(ctx context.Context, client *datastore.Client, desc string) (*datas\n \treturn client.Put(ctx, key, task)\n }\n \n-// [END add_entity]\n+// [END datastore_add_entity]\n \n-// [START update_entity]\n+// [START datastore_update_entity]\n // MarkDone marks the task done with the given ID.\n func MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error {\n \t// Create a key using the given integer ID.",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -148,9 +146,9 @@\nfunc MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error\n \treturn err\n }\n \n-// [END update_entity]\n+// [END datastore_update_entity]\n \n-// [START retrieve_entities]\n+// [START datastore_retrieve_entities]\n // ListTasks returns all the tasks in ascending order of creation time.\n func ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \tvar tasks []*Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -170,17 +168,16 @@\nfunc ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \treturn tasks, nil\n }\n \n-// [END retrieve_entities]\n+// [END datastore_retrieve_entities]\n \n-// [START delete_entity]\n+// [START datastore_delete_entity]\n // DeleteTask deletes the task with the given ID.\n func DeleteTask(ctx context.Context, client *datastore.Client, taskID int64) error {\n \treturn client.Delete(ctx, datastore.IDKey(\"Task\", taskID, nil))\n }\n \n-// [END delete_entity]\n+// [END datastore_delete_entity]\n \n-// [START format_results]\n // PrintTasks prints the tasks to the given writer.\n func PrintTasks(w io.Writer, tasks []*Task) {\n \t// Use a tab writer to help make results pretty.",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -196,8 +193,6 @@\nfunc PrintTasks(w io.Writer, tasks []*Task) {\n \ttw.Flush()\n }\n \n-// [END format_results]\n-\n func usage() {\n \tfmt.Print(`Usage:",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dialogflow/intent_management/intent_management.go",
        "code_diff": "@@ -109,6 +109,8 @@\nfunc main() {\n \t}\n }\n \n+// [START dialogflow_list_intents]\n+\n func ListIntents(projectID string) ([]*dialogflowpb.Intent, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/deid.go",
        "code_diff": "@@ -18,12 +18,20 @@\nimport (\n \n // [START dlp_deidentify_masking]\n \n-// mask deidentifies the input by masking all info types with maskingCharacter and\n-// prints the result to w.\n-func mask(w io.Writer, client *dlp.Client, project, input, maskingCharacter string, numberToMask int32) {\n+// mask deidentifies the input by masking all provided info types with maskingCharacter\n+// and prints the result to w.\n+func mask(w io.Writer, client *dlp.Client, project, input string, infoTypes []string, maskingCharacter string, numberToMask int32) {\n+\t// Convert the info type strings to a list of InfoTypes.\n+\tvar i []*dlppb.InfoType\n+\tfor _, it := range infoTypes {\n+\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\t}\n \t// Create a configured request.\n \treq := &dlppb.DeidentifyContentRequest{\n \t\tParent: \"projects/\" + project,\n+\t\tInspectConfig: &dlppb.InspectConfig{\n+\t\t\tInfoTypes: i,\n+\t\t},\n \t\tDeidentifyConfig: &dlppb.DeidentifyConfig{\n \t\t\tTransformation: &dlppb.DeidentifyConfig_InfoTypeTransformations{\n \t\t\t\tInfoTypeTransformations: &dlppb.InfoTypeTransformations{",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/deid.go",
        "code_diff": "@@ -121,7 +129,12 @@\nfunc deidentifyDateShift(w io.Writer, client *dlp.Client, project string, lowerB\n // full KMS key resource name used to wrap the key. surrogateInfoType is an\n // optional identifier needed for reidentification. surrogateInfoType can be any\n // value not found in your input.\n-func deidentifyFPE(w io.Writer, client *dlp.Client, project, input, keyFileName, cryptoKeyName, surrogateInfoType string) {\n+func deidentifyFPE(w io.Writer, client *dlp.Client, project, input string, infoTypes []string, keyFileName, cryptoKeyName, surrogateInfoType string) {\n+\t// Convert the info type strings to a list of InfoTypes.\n+\tvar i []*dlppb.InfoType\n+\tfor _, it := range infoTypes {\n+\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\t}\n \t// Read the key file.\n \tkeyBytes, err := ioutil.ReadFile(keyFileName)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/deid.go",
        "code_diff": "@@ -130,6 +143,9 @@\nfunc deidentifyFPE(w io.Writer, client *dlp.Client, project, input, keyFileName,\n \t// Create a configured request.\n \treq := &dlppb.DeidentifyContentRequest{\n \t\tParent: \"projects/\" + project,\n+\t\tInspectConfig: &dlppb.InspectConfig{\n+\t\t\tInfoTypes: i,\n+\t\t},\n \t\tDeidentifyConfig: &dlppb.DeidentifyConfig{\n \t\t\tTransformation: &dlppb.DeidentifyConfig_InfoTypeTransformations{\n \t\t\t\tInfoTypeTransformations: &dlppb.InfoTypeTransformations{",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/deid.go",
        "code_diff": "@@ -181,9 +197,9 @@\nfunc deidentifyFPE(w io.Writer, client *dlp.Client, project, input, keyFileName,\n \n // [END dlp_deidentify_fpe]\n \n-// [START reidentify_fpe]\n+// [START dlp_reidentify_fpe]\n \n-// reidentify_fpe reidentifies the input with FPE (Format Preserving Encryption).\n+// reidentifyFPE reidentifies the input with FPE (Format Preserving Encryption).\n // keyFileName is the file name with the KMS wrapped key and cryptoKeyName is the\n // full KMS key resource name used to wrap the key. surrogateInfoType is an\n // the identifier used during deidentification.",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -9,6 +9,7 @@\nimport (\n \t\"io\"\n \t\"io/ioutil\"\n \t\"log\"\n+\t\"strings\"\n \n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -20,18 +21,49 @@\nimport (\n // [START dlp_inspect_string]\n \n // inspectString searches for the given infoTypes in the input.\n-func inspectString(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, input string) {\n+func inspectString(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, input string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \t// Create a configured request.\n \treq := &dlppb.InspectContentRequest{\n \t\tParent: \"projects/\" + project,\n \t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\tInfoTypes:     i,\n-\t\t\tMinLikelihood: minLikelihood,\n+\t\t\tInfoTypes:       i,\n+\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\tMinLikelihood:   minLikelihood,\n \t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -58,12 +90,42 @@\nfunc inspectString(w io.Writer, client *dlp.Client, project string, minLikelihoo\n // [START dlp_inspect_file]\n \n // inspectFile searches for the given info types in the given Reader (with the given bytesType).\n-func inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, bytesType dlppb.ByteContentItem_BytesType, input io.Reader) {\n+func inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, bytesType dlppb.ByteContentItem_BytesType, input io.Reader) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \tb, err := ioutil.ReadAll(input)\n \tif err != nil {\n \t\tlog.Fatalf(\"error reading file: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -72,8 +134,9 @@\nfunc inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood\n \treq := &dlppb.InspectContentRequest{\n \t\tParent: \"projects/\" + project,\n \t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\tInfoTypes:     i,\n-\t\t\tMinLikelihood: minLikelihood,\n+\t\t\tInfoTypes:       i,\n+\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\tMinLikelihood:   minLikelihood,\n \t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -103,12 +166,42 @@\nfunc inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood\n // [START dlp_inspect_gcs]\n \n // inspectGCSFile searches for the given info types in the given file.\n-func inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, pubSubTopic, pubSubSub, bucketName, fileName string) {\n+func inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, pubSubTopic, pubSubSub, bucketName, fileName string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -145,8 +238,9 @@\nfunc inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikeliho\n \t\t\t\t},\n \t\t\t\t// InspectConfig describes what fields to look for.\n \t\t\t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\t\t\tInfoTypes:     i,\n-\t\t\t\t\tMinLikelihood: minLikelihood,\n+\t\t\t\t\tInfoTypes:       i,\n+\t\t\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\t\t\tMinLikelihood:   minLikelihood,\n \t\t\t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -207,12 +301,42 @@\nfunc inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikeliho\n // [START dlp_inspect_datastore]\n \n // inspectDatastore searches for the given info types in the given dataset kind.\n-func inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, pubSubTopic, pubSubSub, dataProject, namespaceID, kind string) {\n+func inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, pubSubTopic, pubSubSub, dataProject, namespaceID, kind string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -253,8 +377,9 @@\nfunc inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikeli\n \t\t\t\t},\n \t\t\t\t// InspectConfig describes what fields to look for.\n \t\t\t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\t\t\tInfoTypes:     i,\n-\t\t\t\t\tMinLikelihood: minLikelihood,\n+\t\t\t\t\tInfoTypes:       i,\n+\t\t\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\t\t\tMinLikelihood:   minLikelihood,\n \t\t\t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -315,12 +440,42 @@\nfunc inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikeli\n // [START dlp_inspect_bigquery]\n \n // inspectBigquery searches for the given info types in the given Bigquery dataset table.\n-func inspectBigquery(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, pubSubTopic, pubSubSub, dataProject, datasetID, tableID string) {\n+func inspectBigquery(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, pubSubTopic, pubSubSub, dataProject, datasetID, tableID string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -33,14 +33,23 @@\nfunc TestInspectString(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, test.s)\n+\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, test.s)\n \t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n \t\t\tif test.want {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n \t\t\t} else {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n \t\t\t}\n \t\t}\n+\t\tbuf.Reset()\n+\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, test.s)\n+\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n+\t\t\tif test.want {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n+\t\t\t} else {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\t}\n+\t\t}\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -60,14 +69,23 @@\nfunc TestInspectFile(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n+\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n \t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n \t\t\tif test.want {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n \t\t\t} else {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n \t\t\t}\n \t\t}\n+\t\tbuf.Reset()\n+\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n+\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n+\t\t\tif test.want {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n+\t\t\t} else {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\t}\n+\t\t}\n \t}\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -139,7 +157,7 @@\nfunc TestInspectGCS(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectGCSFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, \"test-topic\", \"test-sub\", bucketName, test.fileName)\n+\t\tinspectGCSFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, \"test-topic\", \"test-sub\", bucketName, test.fileName)\n \t\tif got := buf.String(); !strings.Contains(got, test.want) {\n \t\t\tt.Errorf(\"inspectString(%s) = %q, want %q substring\", test.fileName, got, test.want)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -199,7 +217,7 @@\nfunc TestInspectDatastore(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectDatastore(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, \"test-topic\", \"test-sub\", projectID, \"\", test.kind)\n+\t\tinspectDatastore(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, \"test-topic\", \"test-sub\", projectID, \"\", test.kind)\n \t\tif got := buf.String(); !strings.Contains(got, test.want) {\n \t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n \t\t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -37,13 +37,16 @@\nfunc bytesTypeValues() string {\n }\n \n var (\n-\tproject           = flag.String(\"project\", \"\", \"Project ID (required)\")\n-\tlanguageCode      = flag.String(\"languageCode\", \"en-US\", \"Language code for infoTypes\")\n-\tinfoTypesString   = flag.String(\"infoTypes\", \"PHONE_NUMBER,EMAIL_ADDRESS,CREDIT_CARD_NUMBER,US_SOCIAL_SECURITY_NUMBER\", \"Info types to inspect*, redactImage, createTrigger, and createInspectTemplate\")\n-\tminLikelihoodFlag = flag.String(\"minLikelihood\", \"LIKELIHOOD_UNSPECIFIED\", fmt.Sprintf(\"Minimum likelihood value for inspect*, redactImage, createTrigger, and createInspectTemplate [%v]\", minLikelihoodValues()))\n-\tbytesTypeFlag     = flag.String(\"bytesType\", \"BYTES_TYPE_UNSPECIFIED\", fmt.Sprintf(\"Bytes type of input file for inspectFile and redactImage [%v]\", bytesTypeValues()))\n-\tmaxFindings       = flag.Int(\"maxFindings\", 0, \"Number of results for inspect*, createTrigger, and createInspectTemplate (default 0 (no limit))\")\n-\tincludeQuote      = flag.Bool(\"includeQuote\", false, \"Include a quote of findings for inspect* (default false)\")\n+\tproject                = flag.String(\"project\", \"\", \"Project ID (required)\")\n+\tlanguageCode           = flag.String(\"languageCode\", \"en-US\", \"Language code for infoTypes\")\n+\tinfoTypesString        = flag.String(\"infoTypes\", \"PHONE_NUMBER,EMAIL_ADDRESS,CREDIT_CARD_NUMBER,US_SOCIAL_SECURITY_NUMBER\", \"Info types to inspect*, redactImage, createTrigger, and createInspectTemplate\")\n+\tcustomDictionaryString = flag.String(\"customDictionary\", \"\", \"Custom dictionary for inspect*\")\n+\tcustomRegexString      = flag.String(\"customRegex\", \"\", \"Custom regex for inspect*\")\n+\tminLikelihoodFlag      = flag.String(\"minLikelihood\", \"LIKELIHOOD_UNSPECIFIED\", fmt.Sprintf(\"Minimum likelihood value for inspect*, redactImage, createTrigger, and createInspectTemplate [%v]\", minLikelihoodValues()))\n+\tbytesTypeFlag          = flag.String(\"bytesType\", \"BYTES_TYPE_UNSPECIFIED\", fmt.Sprintf(\"Bytes type of input file for inspectFile and redactImage [%v]\", bytesTypeValues()))\n+\tmaxFindings            = flag.Int(\"maxFindings\", 0, \"Number of results for inspect*, createTrigger, and createInspectTemplate (default 0 (no limit))\")\n+\tautoPopulateTimespan   = flag.Bool(\"autoPopulateTimespan\", false, \"Limit scan to new content only (default false)\")\n+\tincludeQuote           = flag.Bool(\"includeQuote\", false, \"Include a quote of findings for inspect* (default false)\")\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -57,6 +60,14 @@\nfunc main() {\n \tflag.Parse()\n \n \tinfoTypesList := strings.Split(*infoTypesString, \",\")\n+\tvar customDictionariesList []string\n+\tif *customDictionaryString != \"\" {\n+\t\tcustomDictionariesList = []string{*customDictionaryString}\n+\t}\n+\tvar customRegexesList []string\n+\tif *customRegexString != \"\" {\n+\t\tcustomRegexesList = []string{*customRegexString}\n+\t}\n \n \tif *project == \"\" {\n \t\tfmt.Fprintf(os.Stderr, \"Must provide a -project\\n\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -87,23 +98,23 @@\nfunc main() {\n \t\tos.Exit(1)\n \tcase \"inspect\":\n \t\tcheckNArg(1)\n-\t\tinspectString(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1))\n+\t\tinspectString(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1))\n \tcase \"inspectFile\":\n \t\tcheckNArg(1)\n \t\tf, err := os.Open(flag.Arg(1))\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"error opening file: %v\", err)\n \t\t}\n-\t\tinspectFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, bytesType, f)\n+\t\tinspectFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, bytesType, f)\n \tcase \"inspectGCSFile\":\n \t\tcheckNArg(4)\n-\t\tinspectGCSFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4))\n+\t\tinspectGCSFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4))\n \tcase \"inspectDatastore\":\n \t\tcheckNArg(5)\n-\t\tinspectDatastore(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n+\t\tinspectDatastore(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n \tcase \"inspectBigquery\":\n \t\tcheckNArg(5)\n-\t\tinspectBigquery(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n+\t\tinspectBigquery(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n \n \tcase \"redactImage\":\n \t\tcheckNArg(2)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -115,13 +126,13 @@\nfunc main() {\n \n \tcase \"mask\":\n \t\tcheckNArg(1)\n-\t\tmask(os.Stdout, client, *project, flag.Arg(1), \"*\", 0)\n+\t\tmask(os.Stdout, client, *project, flag.Arg(1), infoTypesList, \"*\", 0)\n \tcase \"dateShift\":\n \t\tcheckNArg(1)\n \t\tdeidentifyDateShift(os.Stdout, client, *project, -2000, 2000, flag.Arg(1))\n \tcase \"fpe\":\n \t\tcheckNArg(4)\n-\t\tdeidentifyFPE(os.Stdout, client, *project, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4))\n+\t\tdeidentifyFPE(os.Stdout, client, *project, flag.Arg(1), infoTypesList, flag.Arg(2), flag.Arg(3), flag.Arg(4))\n \tcase \"reidentifyFPE\":\n \t\tcheckNArg(4)\n \t\treidentifyFPE(os.Stdout, client, *project, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4))",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -461,7 +461,7 @@\nfunc riskLDiversity(w io.Writer, client *dlp.Client, project, dataProject, pubSu\n \n // [END dlp_l_diversity]\n \n-// [START k_map]\n+// [START dlp_k_map]\n \n // riskKMap runs K Map on the given data.\n func riskKMap(w io.Writer, client *dlp.Client, project, dataProject, pubSubTopic, pubSubSub, datasetID, tableID, region string, columnNames ...string) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/templates.go",
        "code_diff": "@@ -17,7 +17,7 @@\nimport (\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )\n \n-// [START dlp_create_template]\n+// [START dlp_create_inspect_template]\n \n // createInspectTemplate creates a template with the given configuration.\n func createInspectTemplate(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, templateID, displayName, description string, infoTypes []string) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/templates.go",
        "code_diff": "@@ -52,9 +52,9 @@\nfunc createInspectTemplate(w io.Writer, client *dlp.Client, project string, minL\n \tfmt.Fprintf(w, \"Successfully created inspect template: %v\", resp.GetName())\n }\n \n-// [END dlp_create_template]\n+// [END dlp_create_inspect_template]\n \n-// [START dlp_list_templates]\n+// [START dlp_list_inspect_templates]\n \n // listInspectTemplates lists the inspect templates in the project.\n func listInspectTemplates(w io.Writer, client *dlp.Client, project string) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/templates.go",
        "code_diff": "@@ -82,9 +82,9 @@\nfunc listInspectTemplates(w io.Writer, client *dlp.Client, project string) {\n \t}\n }\n \n-// [END dlp_list_templates]\n+// [END dlp_list_inspect_templates]\n \n-// [START dlp_delete_template]\n+// [START dlp_delete_inspect_template]\n \n // deleteInspectTemplate deletes the given template.\n func deleteInspectTemplate(w io.Writer, client *dlp.Client, templateID string) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/triggers.go",
        "code_diff": "@@ -22,7 +22,7 @@\nimport (\n // [START dlp_create_trigger]\n \n // createTrigger creates a trigger with the given configuration.\n-func createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, triggerID, displayName, description, bucketName string, scanPeriod int64, infoTypes []string) {\n+func createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, triggerID, displayName, description, bucketName string, autoPopulateTimespan bool, scanPeriodDays int64, infoTypes []string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "dlp/dlp_snippets/triggers.go",
        "code_diff": "@@ -40,11 +40,11 @@\nfunc createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihoo\n \t\t\t// Triggers control when the job will start.\n \t\t\tTriggers: []*dlppb.JobTrigger_Trigger{\n \t\t\t\t{\n-\t\t\t\t\t&dlppb.JobTrigger_Trigger_Schedule{\n+\t\t\t\t\tTrigger: &dlppb.JobTrigger_Trigger_Schedule{\n \t\t\t\t\t\tSchedule: &dlppb.Schedule{\n \t\t\t\t\t\t\tOption: &dlppb.Schedule_RecurrencePeriodDuration{\n \t\t\t\t\t\t\t\tRecurrencePeriodDuration: &duration.Duration{\n-\t\t\t\t\t\t\t\t\tSeconds: scanPeriod * 60 * 60 * 24, // Trigger the scan daily\n+\t\t\t\t\t\t\t\t\tSeconds: scanPeriodDays * 60 * 60 * 24, // Days to seconds.\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -29,6 +29,8 @@\nfunc projectResource(projectID string) string {\n \treturn \"projects/\" + projectID\n }\n \n+// [START monitoring_create_metric]\n+\n // createCustomMetric creates a custom metric specified by the metric type.\n func createCustomMetric(s *monitoring.Service, projectID, metricType string) error {\n \tld := monitoring.LabelDescriptor{Key: \"environment\", ValueType: \"STRING\", Description: \"An arbitrary measurement\"}",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -50,6 +52,10 @@\nfunc createCustomMetric(s *monitoring.Service, projectID, metricType string) err\n \treturn nil\n }\n \n+// [END monitoring_create_metric]\n+\n+// [START monitoring_list_descriptors]\n+\n // getCustomMetric reads the custom metric created.\n func getCustomMetric(s *monitoring.Service, projectID, metricType string) (*monitoring.ListMetricDescriptorsResponse, error) {\n \tresp, err := s.Projects.MetricDescriptors.List(projectResource(projectID)).",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -62,6 +68,10 @@\nfunc getCustomMetric(s *monitoring.Service, projectID, metricType string) (*moni\n \treturn resp, nil\n }\n \n+// [END monitoring_list_descriptors]\n+\n+// [START monitoring_write_timeseries]\n+\n // writeTimeSeriesValue writes a value for the custom metric created\n func writeTimeSeriesValue(s *monitoring.Service, projectID, metricType string) error {\n \tnow := time.Now().UTC().Format(time.RFC3339Nano)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -105,6 +115,10 @@\nfunc writeTimeSeriesValue(s *monitoring.Service, projectID, metricType string) e\n \treturn nil\n }\n \n+// [END monitoring_write_timeseries]\n+\n+// [START monitoring_read_timeseries_simple]\n+\n // readTimeSeriesValue reads the TimeSeries for the value specified by metric type in a time window from the last 5 minutes.\n func readTimeSeriesValue(s *monitoring.Service, projectID, metricType string) error {\n \tstartTime := time.Now().UTC().Add(time.Minute * -5)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/pubsub_quickstart/main.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START pubsub_quickstart]\n+// [START pubsub_quickstart_create_topic]\n // Sample pubsub-quickstart creates a Google Cloud Pub/Sub topic.\n package main",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -13,18 +13,15 @@\nimport (\n \t\"sync\"\n \t\"time\"\n \n-\t// [START imports]\n \t\"golang.org/x/net/context\"\n \n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"google.golang.org/api/iterator\"\n-\t// [END imports]\n )\n \n func main() {\n \tctx := context.Background()\n-\t// [START auth]\n \tproj := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tif proj == \"\" {\n \t\tfmt.Fprintf(os.Stderr, \"GOOGLE_CLOUD_PROJECT environment variable must be set.\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -34,7 +31,6 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create pubsub Client: %v\", err)\n \t}\n-\t// [END auth]\n \n \t// Print all the subscriptions in the project.\n \tfmt.Println(\"Listing all subscriptions from the project:\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -67,7 +63,7 @@\nfunc main() {\n \n func list(client *pubsub.Client) ([]*pubsub.Subscription, error) {\n \tctx := context.Background()\n-\t// [START get_all_subscriptions]\n+\t// [START pubsub_list_subscriptions]\n \tvar subs []*pubsub.Subscription\n \tit := client.Subscriptions(ctx)\n \tfor {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -80,7 +76,7 @@\nfunc list(client *pubsub.Client) ([]*pubsub.Subscription, error) {\n \t\t}\n \t\tsubs = append(subs, s)\n \t}\n-\t// [END get_all_subscriptions]\n+\t// [END pubsub_list_subscriptions]\n \treturn subs, nil\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -104,7 +100,8 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \t\t}\n \t}\n \n-\t// [START pull_messages]\n+\t// [START pubsub_subscriber_async_pull]\n+\t// [START pubsub_quickstart_subscriber]\n \t// Consume 10 messages.\n \tvar mu sync.Mutex\n \treceived := 0",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -123,13 +120,14 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\t// [END pull_messages]\n+\t// [END pubsub_subscriber_async_pull]\n+\t// [END pubsub_quickstart_subscriber]\n \treturn nil\n }\n \n func pullMsgsError(client *pubsub.Client, name string) error {\n \tctx := context.Background()\n-\t// [START pull_messages_error]\n+\t// [START pubsub_subscriber_error_listener]\n \t// If the service returns a non-retryable error, Receive returns that error after\n \t// all of the outstanding calls to the handler have returned.\n \terr := client.Subscription(name).Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -139,13 +137,13 @@\nfunc pullMsgsError(client *pubsub.Client, name string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\t// [END pull_messages_error]\n+\t// [END pubsub_subscriber_error_listener]\n \treturn nil\n }\n \n func pullMsgsSettings(client *pubsub.Client, name string) error {\n \tctx := context.Background()\n-\t// [START pull_messages_settings]\n+\t// [START pubsub_subscriber_flow_settings]\n \tsub := client.Subscription(name)\n \tsub.ReceiveSettings.MaxOutstandingMessages = 10\n \terr := sub.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -155,13 +153,13 @@\nfunc pullMsgsSettings(client *pubsub.Client, name string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\t// [END pull_messages_settings]\n+\t// [END pubsub_subscriber_flow_settings]\n \treturn nil\n }\n \n func create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \tctx := context.Background()\n-\t// [START create_subscription]\n+\t// [START pubsub_create_pull_subscription]\n \tsub, err := client.CreateSubscription(ctx, name, pubsub.SubscriptionConfig{\n \t\tTopic:       topic,\n \t\tAckDeadline: 20 * time.Second,",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -170,13 +168,13 @@\nfunc create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \t\treturn err\n \t}\n \tfmt.Printf(\"Created subscription: %v\\n\", sub)\n-\t// [END create_subscription]\n+\t// [END pubsub_create_pull_subscription]\n \treturn nil\n }\n \n func createWithEndpoint(client *pubsub.Client, name string, topic *pubsub.Topic, endpoint string) error {\n \tctx := context.Background()\n-\t// [START create_push_subscription]\n+\t// [START pubsub_create_push_subscription]\n \n \t// For example, endpoint is \"https://my-test-project.appspot.com/push\".\n \tsub, err := client.CreateSubscription(ctx, name, pubsub.SubscriptionConfig{",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -188,13 +186,13 @@\nfunc createWithEndpoint(client *pubsub.Client, name string, topic *pubsub.Topic,\n \t\treturn err\n \t}\n \tfmt.Printf(\"Created subscription: %v\\n\", sub)\n-\t// [END create_push_subscription]\n+\t// [END pubsub_create_push_subscription]\n \treturn nil\n }\n \n func updateEndpoint(client *pubsub.Client, name string, endpoint string) error {\n \tctx := context.Background()\n-\t// [START update_push_subscription]\n+\t// [START pubsub_update_push_configuration]\n \n \t// For example, endpoint is \"https://my-test-project.appspot.com/push\".\n \tsubConfig, err := client.Subscription(name).Update(ctx, pubsub.SubscriptionConfigToUpdate{",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -12,18 +12,15 @@\nimport (\n \t\"os\"\n \t\"time\"\n \n-\t// [START imports]\n \t\"golang.org/x/net/context\"\n \n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"google.golang.org/api/iterator\"\n-\t// [END imports]\n )\n \n func main() {\n \tctx := context.Background()\n-\t// [START auth]\n \tproj := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tif proj == \"\" {\n \t\tfmt.Fprintf(os.Stderr, \"GOOGLE_CLOUD_PROJECT environment variable must be set.\\n\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -33,7 +30,6 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create pubsub Client: %v\", err)\n \t}\n-\t// [END auth]\n \n \t// List all the topics from the project.\n \tfmt.Println(\"Listing all topics from the project:\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -64,20 +60,20 @@\nfunc main() {\n \n func create(client *pubsub.Client, topic string) error {\n \tctx := context.Background()\n-\t// [START create_topic]\n+\t// [START pubsub_create_topic]\n \tt, err := client.CreateTopic(ctx, topic)\n \tif err != nil {\n \t\treturn err\n \t}\n \tfmt.Printf(\"Topic created: %v\\n\", t)\n-\t// [END create_topic]\n+\t// [END pubsub_create_topic]\n \treturn nil\n }\n \n func list(client *pubsub.Client) ([]*pubsub.Topic, error) {\n \tctx := context.Background()\n \n-\t// [START list_topics]\n+\t// [START pubsub_list_topics]\n \tvar topics []*pubsub.Topic\n \n \tit := client.Topics(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -93,13 +89,13 @@\nfunc list(client *pubsub.Client) ([]*pubsub.Topic, error) {\n \t}\n \n \treturn topics, nil\n-\t// [END list_topics]\n+\t// [END pubsub_list_topics]\n }\n \n func listSubscriptions(client *pubsub.Client, topicID string) ([]*pubsub.Subscription, error) {\n \tctx := context.Background()\n \n-\t// [START list_topic_subscriptions]\n+\t// [START pubsub_list_topic_subscriptions]\n \tvar subs []*pubsub.Subscription\n \n \tit := client.Topic(topicID).Subscriptions(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -113,25 +109,26 @@\nfunc listSubscriptions(client *pubsub.Client, topicID string) ([]*pubsub.Subscri\n \t\t}\n \t\tsubs = append(subs, sub)\n \t}\n-\t// [END list_topic_subscriptions]\n+\t// [END pubsub_list_topic_subscriptions]\n \treturn subs, nil\n }\n \n func delete(client *pubsub.Client, topic string) error {\n \tctx := context.Background()\n-\t// [START delete_topic]\n+\t// [START pubsub_delete_topic]\n \tt := client.Topic(topic)\n \tif err := t.Delete(ctx); err != nil {\n \t\treturn err\n \t}\n \tfmt.Printf(\"Deleted topic: %v\\n\", t)\n-\t// [END delete_topic]\n+\t// [END pubsub_delete_topic]\n \treturn nil\n }\n \n func publish(client *pubsub.Client, topic, msg string) error {\n \tctx := context.Background()\n-\t// [START publish]\n+\t// [START pubsub_publish]\n+\t// [START pubsub_quickstart_publisher]\n \tt := client.Topic(topic)\n \tresult := t.Publish(ctx, &pubsub.Message{\n \t\tData: []byte(msg),",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -143,13 +140,14 @@\nfunc publish(client *pubsub.Client, topic, msg string) error {\n \t\treturn err\n \t}\n \tfmt.Printf(\"Published a message; msg ID: %v\\n\", id)\n-\t// [END publish]\n+\t// [END pubsub_publish]\n+\t// [END pubsub_quickstart_publisher]\n \treturn nil\n }\n \n func publishWithSettings(client *pubsub.Client, topic string, msg []byte) error {\n \tctx := context.Background()\n-\t// [START publish_settings]\n+\t// [START pubsub_publisher_batch_settings]\n \tt := client.Topic(topic)\n \tt.PublishSettings = pubsub.PublishSettings{\n \t\tByteThreshold:  5000,",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -164,13 +162,13 @@\nfunc publishWithSettings(client *pubsub.Client, topic string, msg []byte) error\n \t\treturn err\n \t}\n \tfmt.Printf(\"Published a message; msg ID: %v\\n\", id)\n-\t// [END publish_settings]\n+\t// [END pubsub_publisher_batch_settings]\n \treturn nil\n }\n \n func publishSingleGoroutine(client *pubsub.Client, topic string, msg []byte) error {\n \tctx := context.Background()\n-\t// [START publish_single_goroutine]\n+\t// [START pubsub_publisher_concurrency_control]\n \tt := client.Topic(topic)\n \tt.PublishSettings = pubsub.PublishSettings{\n \t\tNumGoroutines: 1,",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -28,28 +28,33 @@\ntype adminCommand func(ctx context.Context, w io.Writer, adminClient *database.D\n \n var (\n \tcommands = map[string]command{\n-\t\t\"write\":               write,\n-\t\t\"query\":               query,\n-\t\t\"read\":                read,\n-\t\t\"update\":              update,\n-\t\t\"writetransaction\":    writeWithTransaction,\n-\t\t\"querynewcolumn\":      queryNewColumn,\n-\t\t\"queryindex\":          queryUsingIndex,\n-\t\t\"readindex\":           readUsingIndex,\n-\t\t\"readstoringindex\":    readStoringIndex,\n-\t\t\"readonlytransaction\": readOnlyTransaction,\n-\t\t\"readstaledata\":       readStaleData,\n-\t\t\"readbatchdata\":       readBatchData,\n-\t\t\"updatewithtimestamp\": updateWithTimestamp,\n-\t\t\"querywithtimestamp\":  queryWithTimestamp,\n-\t\t\"writewithtimestamp\":  writeWithTimestamp,\n-\t\t\"querynewtable\":       queryNewTable,\n-\t\t\"writetodocstable\":    writeToDocumentsTable,\n-\t\t\"updatedocstable\":     updateDocumentsTable,\n-\t\t\"querydocstable\":      queryDocumentsTable,\n-\t\t\"writewithhistory\":    writeWithHistory,\n-\t\t\"updatewithhistory\":   updateWithHistory,\n-\t\t\"querywithhistory\":    queryWithHistory,\n+\t\t\"write\":                      write,\n+\t\t\"query\":                      query,\n+\t\t\"read\":                       read,\n+\t\t\"update\":                     update,\n+\t\t\"writetransaction\":           writeWithTransaction,\n+\t\t\"querynewcolumn\":             queryNewColumn,\n+\t\t\"queryindex\":                 queryUsingIndex,\n+\t\t\"readindex\":                  readUsingIndex,\n+\t\t\"readstoringindex\":           readStoringIndex,\n+\t\t\"readonlytransaction\":        readOnlyTransaction,\n+\t\t\"readstaledata\":              readStaleData,\n+\t\t\"readbatchdata\":              readBatchData,\n+\t\t\"updatewithtimestamp\":        updateWithTimestamp,\n+\t\t\"querywithtimestamp\":         queryWithTimestamp,\n+\t\t\"writewithtimestamp\":         writeWithTimestamp,\n+\t\t\"querynewtable\":              queryNewTable,\n+\t\t\"writetodocstable\":           writeToDocumentsTable,\n+\t\t\"updatedocstable\":            updateDocumentsTable,\n+\t\t\"querydocstable\":             queryDocumentsTable,\n+\t\t\"writewithhistory\":           writeWithHistory,\n+\t\t\"updatewithhistory\":          updateWithHistory,\n+\t\t\"querywithhistory\":           queryWithHistory,\n+\t\t\"writestructdata\":            writeStructData,\n+\t\t\"querywithstruct\":            queryWithStruct,\n+\t\t\"querywitharrayofstruct\":     queryWithArrayOfStruct,\n+\t\t\"querywithstructfield\":       queryWithStructField,\n+\t\t\"querywithnestedstructfield\": queryWithNestedStructField,\n \t}\n \n \tadminCommands = map[string]adminCommand{",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -216,6 +221,188 @@\nfunc writeWithTimestamp(ctx context.Context, w io.Writer, client *spanner.Client\n \n // [END spanner_insert_data_with_timestamp_column]\n \n+// [START spanner_write_data_for_struct_queries]\n+\n+func writeStructData(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tsingerColumns := []string{\"SingerId\", \"FirstName\", \"LastName\"}\n+\tm := []*spanner.Mutation{\n+\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{6, \"Elena\", \"Campbell\"}),\n+\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{7, \"Gabriel\", \"Wright\"}),\n+\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{8, \"Benjamin\", \"Martinez\"}),\n+\t\tspanner.InsertOrUpdate(\"Singers\", singerColumns, []interface{}{9, \"Hannah\", \"Harris\"}),\n+\t}\n+\t_, err := client.Apply(ctx, m)\n+\treturn err\n+}\n+\n+// [END spanner_write_data_for_struct_queries]\n+\n+func queryWithStruct(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\n+\t// [START spanner_create_struct_with_data]\n+\n+\ttype nameStruct struct {\n+\t\tFirstName string\n+\t\tLastName  string\n+\t}\n+\tvar singerInfo = nameStruct{\"Elena\", \"Campbell\"}\n+\n+\t// [END spanner_create_struct_with_data]\n+\n+\t// [START spanner_query_data_with_struct]\n+\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT SingerId FROM SINGERS\n+\t\t\t\tWHERE (FirstName, LastName) = @singerinfo`,\n+\t\tParams: map[string]interface{}{\"singerinfo\": singerInfo},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar singerID int64\n+\t\tif err := row.Columns(&singerID); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d\\n\", singerID)\n+\t}\n+\n+\t// [END spanner_query_data_with_struct]\n+}\n+\n+func queryWithArrayOfStruct(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\n+\t// [START spanner_create_user_defined_struct]\n+\n+\ttype nameType struct {\n+\t\tFirstName string\n+\t\tLastName  string\n+\t}\n+\n+\t// [END spanner_create_user_defined_struct]\n+\n+\t// [START spanner_create_array_of_struct_with_data]\n+\n+\tvar bandMembers = []nameType{\n+\t\t{\"Elena\", \"Campbell\"},\n+\t\t{\"Gabriel\", \"Wright\"},\n+\t\t{\"Benjamin\", \"Martinez\"},\n+\t}\n+\n+\t// [END spanner_create_array_of_struct_with_data]\n+\n+\t// [START spanner_query_data_with_array_of_struct]\n+\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT SingerId FROM SINGERS\n+\t\t\tWHERE STRUCT<FirstName STRING, LastName STRING>(FirstName, LastName)\n+\t\t\tIN UNNEST(@names)`,\n+\t\tParams: map[string]interface{}{\"names\": bandMembers},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar singerID int64\n+\t\tif err := row.Columns(&singerID); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d\\n\", singerID)\n+\t}\n+\n+\t// [END spanner_query_data_with_array_of_struct]\n+}\n+\n+// [START spanner_field_access_on_struct_parameters]\n+\n+func queryWithStructField(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\ttype structParam struct {\n+\t\tFirstName string\n+\t\tLastName  string\n+\t}\n+\tvar singerInfo = structParam{\"Elena\", \"Campbell\"}\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT SingerId FROM SINGERS\n+\t\t\tWHERE FirstName = @name.FirstName`,\n+\t\tParams: map[string]interface{}{\"name\": singerInfo},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar singerID int64\n+\t\tif err := row.Columns(&singerID); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d\\n\", singerID)\n+\t}\n+}\n+\n+// [END spanner_field_access_on_struct_parameters]\n+\n+// [START spanner_field_access_on_nested_struct_parameters]\n+\n+func queryWithNestedStructField(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\ttype nameType struct {\n+\t\tFirstName string\n+\t\tLastName  string\n+\t}\n+\ttype songInfoStruct struct {\n+\t\tSongName    string\n+\t\tArtistNames []nameType\n+\t}\n+\tvar songInfo = songInfoStruct{\n+\t\tSongName: \"Imagination\",\n+\t\tArtistNames: []nameType{\n+\t\t\t{FirstName: \"Elena\", LastName: \"Campbell\"},\n+\t\t\t{FirstName: \"Hannah\", LastName: \"Harris\"},\n+\t\t},\n+\t}\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT SingerId, @songinfo.SongName FROM Singers\n+\t\t\tWHERE STRUCT<FirstName STRING, LastName STRING>(FirstName, LastName)\n+\t\t\tIN UNNEST(@songinfo.ArtistNames)`,\n+\t\tParams: map[string]interface{}{\"songinfo\": songInfo},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar singerID int64\n+\t\tvar songName string\n+\t\tif err := row.Columns(&singerID, &songName); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s\\n\", singerID, songName)\n+\t}\n+}\n+\n+// [END spanner_field_access_on_nested_struct_parameters]\n+\n // [START spanner_query_data]\n \n func query(ctx context.Context, w io.Writer, client *spanner.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -5,6 +5,8 @@\npackage main\n \n import (\n+\t\"fmt\"\n+\t\"os\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -30,6 +32,7 @@\nfunc TestCreate(t *testing.T) {\n \t}\n \n \tbucketName = tc.ProjectID + \"-storage-buckets-tests\"\n+\n \t// Clean up bucket before running tests.\n \tdeleteBucket(storageClient, bucketName)\n \tif err := create(storageClient, tc.ProjectID, bucketName); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -236,6 +236,7 @@\nfunc delete(client *storage.Client, bucket, object string) error {\n \treturn nil\n }\n \n+// writeEncryptedObject writes an object encrypted with user-provided AES key to a bucket.\n func writeEncryptedObject(client *storage.Client, bucket, object string, secretKey []byte) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -6,7 +6,9 @@\npackage main\n \n import (\n \t\"bytes\"\n+\t\"fmt\"\n \t\"log\"\n+\t\"os\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -38,6 +38,8 @@\nfunc createClientWithKey() {\n \tfmt.Printf(\"%#v\", resp)\n }\n \n+// [START translate_translate_text]\n+\n func translateText(targetLanguage, text string) (string, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -59,6 +61,9 @@\nfunc translateText(targetLanguage, text string) (string, error) {\n \treturn resp[0].Text, nil\n }\n \n+// [END translate_translate_text]\n+// [START translate_detect_language]\n+\n func detectLanguage(text string) (*translate.Detection, error) {\n \tctx := context.Background()\n \tclient, err := translate.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -74,6 +79,10 @@\nfunc detectLanguage(text string) (*translate.Detection, error) {\n \treturn &lang[0][0], nil\n }\n \n+// [END translate_detect_language]\n+// [START translate_list_codes]\n+// [START translate_list_language_names]\n+\n func listSupportedLanguages(w io.Writer, targetLanguage string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -100,6 +109,11 @@\nfunc listSupportedLanguages(w io.Writer, targetLanguage string) error {\n \treturn nil\n }\n \n+// [END translate_list_language_names]\n+// [END translate_list_codes]\n+\n+// [START translate_text_with_model]\n+\n func translateTextWithModel(targetLanguage, text, model string) (string, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "videointelligence/video_analyze/gen/template.go",
        "code_diff": "@@ -56,6 +56,9 @@\nfunc boilerplate() { //# omit\n \t//# enddef\n } //# omit\n \n+// [START video_analyze_labels_local] //# include if !gcs\n+// [START video_analyze_labels_gcs] //# include if gcs\n+\n func label__SUFFIX__(w io.Writer, file string) error {\n \t//# replace __req.feature__ videopb.Feature_LABEL_DETECTION\n \tvar resp *videopb.AnnotateVideoResponse //# template dorequest",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "videointelligence/video_analyze/gen/template.go",
        "code_diff": "@@ -87,6 +90,11 @@\nfunc label__SUFFIX__(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END video_analyze_labels_local] //# include if !gcs\n+// [END video_analyze_labels_gcs] //# include if gcs\n+\n+// [START video_analyze_shots] //# include if gcs\n+\n func shotChange__SUFFIX__(w io.Writer, file string) error {\n \t//# replace __req.feature__ videopb.Feature_SHOT_CHANGE_DETECTION\n \tvar resp *videopb.AnnotateVideoResponse //# template dorequest",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "videointelligence/video_analyze/gen/template.go",
        "code_diff": "@@ -104,6 +112,10 @@\nfunc shotChange__SUFFIX__(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END video_analyze_shots] //# include if gcs\n+\n+// [START video_analyze_explicit_content] //# include if gcs\n+\n func explicitContent__SUFFIX__(w io.Writer, file string) error {\n \t//# replace __req.feature__ videopb.Feature_EXPLICIT_CONTENT_DETECTION\n \tvar resp *videopb.AnnotateVideoResponse //# template dorequest",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -16,6 +16,8 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n+// [START video_analyze_labels_local]\n+\n func label(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -15,6 +15,8 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n+// [START video_analyze_labels_gcs]\n+\n func labelURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -63,6 +65,10 @@\nfunc labelURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END video_analyze_labels_gcs]\n+\n+// [START video_analyze_shots]\n+\n func shotChangeURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "Add samples for Text-To-Speech V1 GA",
        "pr_number": 512,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -97,6 +103,10 @@\nfunc shotChangeURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END video_analyze_shots]\n+\n+// [START video_analyze_explicit_content]\n+\n func explicitContentURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_message": "Merge branch 'master' into tts-samples",
        "commit_id": "72cd33a9e6490adf5233de15946ce5144944a92b"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -41,7 +41,7 @@\nvar (\n \tlanguageCode           = flag.String(\"languageCode\", \"en-US\", \"Language code for infoTypes\")\n \tinfoTypesString        = flag.String(\"infoTypes\", \"PHONE_NUMBER,EMAIL_ADDRESS,CREDIT_CARD_NUMBER,US_SOCIAL_SECURITY_NUMBER\", \"Info types to inspect*, redactImage, createTrigger, and createInspectTemplate\")\n \tcustomDictionaryString = flag.String(\"customDictionary\", \"\", \"Custom dictionary for inspect*\")\n-\tcustomRegexesString    = flag.String(\"customRegexes\", \"\", \"Custom regexes for inspect*\")\n+\tcustomRegexString      = flag.String(\"customRegex\", \"\", \"Custom regex for inspect*\")\n \tminLikelihoodFlag      = flag.String(\"minLikelihood\", \"LIKELIHOOD_UNSPECIFIED\", fmt.Sprintf(\"Minimum likelihood value for inspect*, redactImage, createTrigger, and createInspectTemplate [%v]\", minLikelihoodValues()))\n \tbytesTypeFlag          = flag.String(\"bytesType\", \"BYTES_TYPE_UNSPECIFIED\", fmt.Sprintf(\"Bytes type of input file for inspectFile and redactImage [%v]\", bytesTypeValues()))\n \tmaxFindings            = flag.Int(\"maxFindings\", 0, \"Number of results for inspect*, createTrigger, and createInspectTemplate (default 0 (no limit))\")",
        "comments": [
            {
                "comment": "This might cause problems if someone has a comma in their regex. So, maybe only allow a single regex?",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "Only use one custom regex in CLI to allow commas.",
        "commit_id": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -33,14 +33,14 @@\nfunc updateDatasetDescription(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_description]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n \t\tDescription: \"Updated Description.\",\n \t}\n-\tif _, err = ds.Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err = ds.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_description]",
        "comments": [
            {
                "comment": "Maybe do `if len(meta.Labels) == 0`, in case it's every an empty list?\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Nit: Please capitalize \"dataset.\"\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Maybe delete `update` from the function names? For example, `addDatasetLabel` and `deleteDatasetLabel`.",
                "position": null
            },
            {
                "comment": "It seems a little awkward to have the original metadata and the update one. Could `SetLabel` be called on the original one?",
                "position": null
            },
            {
                "comment": "The variable names for the original and the update are inconsistent between the functions. Maybe they could be `meta` and `update`?",
                "position": null
            },
            {
                "comment": "In Go, we generally avoid the prefix `get`. This would be `datasetLabels`.",
                "position": null
            },
            {
                "comment": "Same `get` comment.",
                "position": null
            },
            {
                "comment": "Nit: Capitalize.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Side effect of naming according to region tags.  Corrected.",
                "position": null
            },
            {
                "comment": "unified naming, including older samples.",
                "position": null
            },
            {
                "comment": "I'm also not a huge fan of how the label mutations are done in the client library, but that's the structure defined and shared by multiple services (see the same semantics in the GCS library, for example).",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments",
        "commit_id": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -51,14 +51,14 @@\nfunc updateDatasetDefaultExpiration(client *bigquery.Client, datasetID string) e\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_expiration]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n \t\tDefaultTableExpiration: 24 * time.Hour,\n \t}\n-\tif _, err := client.Dataset(datasetID).Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err := client.Dataset(datasetID).Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_expiration]",
        "comments": [
            {
                "comment": "Maybe do `if len(meta.Labels) == 0`, in case it's every an empty list?\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Nit: Please capitalize \"dataset.\"\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Maybe delete `update` from the function names? For example, `addDatasetLabel` and `deleteDatasetLabel`.",
                "position": null
            },
            {
                "comment": "It seems a little awkward to have the original metadata and the update one. Could `SetLabel` be called on the original one?",
                "position": null
            },
            {
                "comment": "The variable names for the original and the update are inconsistent between the functions. Maybe they could be `meta` and `update`?",
                "position": null
            },
            {
                "comment": "In Go, we generally avoid the prefix `get`. This would be `datasetLabels`.",
                "position": null
            },
            {
                "comment": "Same `get` comment.",
                "position": null
            },
            {
                "comment": "Nit: Capitalize.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Side effect of naming according to region tags.  Corrected.",
                "position": null
            },
            {
                "comment": "unified naming, including older samples.",
                "position": null
            },
            {
                "comment": "I'm also not a huge fan of how the label mutations are done in the client library, but that's the structure defined and shared by multiple services (see the same semantics in the GCS library, for example).",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments",
        "commit_id": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -69,13 +69,13 @@\nfunc updateDatasetAccessControl(client *bigquery.Client, datasetID string) error\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_access]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Append a new access control entry to the existing access list.\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n-\t\tAccess: append(original.Access, &bigquery.AccessEntry{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n+\t\tAccess: append(meta.Access, &bigquery.AccessEntry{\n \t\t\tRole:       bigquery.ReaderRole,\n \t\t\tEntityType: bigquery.UserEmailEntity,\n \t\t\tEntity:     \"sample.bigquery.dev@gmail.com\"},",
        "comments": [
            {
                "comment": "Maybe do `if len(meta.Labels) == 0`, in case it's every an empty list?\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Nit: Please capitalize \"dataset.\"\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Maybe delete `update` from the function names? For example, `addDatasetLabel` and `deleteDatasetLabel`.",
                "position": null
            },
            {
                "comment": "It seems a little awkward to have the original metadata and the update one. Could `SetLabel` be called on the original one?",
                "position": null
            },
            {
                "comment": "The variable names for the original and the update are inconsistent between the functions. Maybe they could be `meta` and `update`?",
                "position": null
            },
            {
                "comment": "In Go, we generally avoid the prefix `get`. This would be `datasetLabels`.",
                "position": null
            },
            {
                "comment": "Same `get` comment.",
                "position": null
            },
            {
                "comment": "Nit: Capitalize.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Side effect of naming according to region tags.  Corrected.",
                "position": null
            },
            {
                "comment": "unified naming, including older samples.",
                "position": null
            },
            {
                "comment": "I'm also not a huge fan of how the label mutations are done in the client library, but that's the structure defined and shared by multiple services (see the same semantics in the GCS library, for example).",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments",
        "commit_id": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -84,23 +84,23 @@\nfunc updateDatasetAccessControl(client *bigquery.Client, datasetID string) error\n \n \t// Leverage the ETag for the update to assert there's been no modifications to the\n \t// dataset since the metadata was originally read.\n-\tif _, err := ds.Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_access]\n \treturn nil\n }\n \n-func getDatasetLabels(client *bigquery.Client, w io.Writer, datasetID string) error {\n+func datasetLabels(client *bigquery.Client, w io.Writer, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_dataset_labels]\n \tmeta, err := client.Dataset(datasetID).Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \tfmt.Fprintf(w, \"Dataset %s labels:\\n\", datasetID)\n-\tif meta.Labels == nil {\n-\t\tfmt.Fprintln(w, \"dataset has no labels defined.\")\n+\tif len(meta.Labels) == 0 {\n+\t\tfmt.Fprintln(w, \"Dataset has no labels defined.\")\n \t\treturn nil\n \t}\n \tfor k, v := range meta.Labels {",
        "comments": [
            {
                "comment": "Maybe do `if len(meta.Labels) == 0`, in case it's every an empty list?\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Nit: Please capitalize \"dataset.\"\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Maybe delete `update` from the function names? For example, `addDatasetLabel` and `deleteDatasetLabel`.",
                "position": null
            },
            {
                "comment": "It seems a little awkward to have the original metadata and the update one. Could `SetLabel` be called on the original one?",
                "position": null
            },
            {
                "comment": "The variable names for the original and the update are inconsistent between the functions. Maybe they could be `meta` and `update`?",
                "position": null
            },
            {
                "comment": "In Go, we generally avoid the prefix `get`. This would be `datasetLabels`.",
                "position": null
            },
            {
                "comment": "Same `get` comment.",
                "position": null
            },
            {
                "comment": "Nit: Capitalize.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Side effect of naming according to region tags.  Corrected.",
                "position": null
            },
            {
                "comment": "unified naming, including older samples.",
                "position": null
            },
            {
                "comment": "I'm also not a huge fan of how the label mutations are done in the client library, but that's the structure defined and shared by multiple services (see the same semantics in the GCS library, for example).",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments",
        "commit_id": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -110,35 +110,35 @@\nfunc getDatasetLabels(client *bigquery.Client, w io.Writer, datasetID string) er\n \treturn nil\n }\n \n-func updateDatasetAddLabel(client *bigquery.Client, datasetID string) error {\n+func addDatasetLabel(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_label_dataset]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \n-\tmeta := bigquery.DatasetMetadataToUpdate{}\n-\tmeta.SetLabel(\"color\", \"green\")\n-\tif _, err := ds.Update(ctx, meta, original.ETag); err != nil {\n+\tupdate := bigquery.DatasetMetadataToUpdate{}\n+\tupdate.SetLabel(\"color\", \"green\")\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_label_dataset]\n \treturn nil\n }\n \n-func updateDatasetDeleteLabel(client *bigquery.Client, datasetID string) error {\n+func deleteDatasetLabel(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_delete_label_dataset]\n \tds := client.Dataset(datasetID)\n-\toriginalMeta, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tnewMeta := bigquery.DatasetMetadataToUpdate{}\n-\tnewMeta.DeleteLabel(\"color\")\n-\tif _, err := ds.Update(ctx, newMeta, originalMeta.ETag); err != nil {\n+\tupdate := bigquery.DatasetMetadataToUpdate{}\n+\tupdate.DeleteLabel(\"color\")\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_delete_label_dataset]",
        "comments": [
            {
                "comment": "Maybe do `if len(meta.Labels) == 0`, in case it's every an empty list?\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Nit: Please capitalize \"dataset.\"\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Maybe delete `update` from the function names? For example, `addDatasetLabel` and `deleteDatasetLabel`.",
                "position": null
            },
            {
                "comment": "It seems a little awkward to have the original metadata and the update one. Could `SetLabel` be called on the original one?",
                "position": null
            },
            {
                "comment": "The variable names for the original and the update are inconsistent between the functions. Maybe they could be `meta` and `update`?",
                "position": null
            },
            {
                "comment": "In Go, we generally avoid the prefix `get`. This would be `datasetLabels`.",
                "position": null
            },
            {
                "comment": "Same `get` comment.",
                "position": null
            },
            {
                "comment": "Nit: Capitalize.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Side effect of naming according to region tags.  Corrected.",
                "position": null
            },
            {
                "comment": "unified naming, including older samples.",
                "position": null
            },
            {
                "comment": "I'm also not a huge fan of how the label mutations are done in the client library, but that's the structure defined and shared by multiple services (see the same semantics in the GCS library, for example).",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments",
        "commit_id": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -311,14 +311,14 @@\nfunc updateTableDescription(client *bigquery.Client, datasetID, tableID string)\n \tctx := context.Background()\n \t// [START bigquery_update_table_description]\n \ttableRef := client.Dataset(datasetID).Table(tableID)\n-\toriginal, err := tableRef.Metadata(ctx)\n+\tmeta, err := tableRef.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tnewMeta := bigquery.TableMetadataToUpdate{\n+\tupdate := bigquery.TableMetadataToUpdate{\n \t\tDescription: \"Updated description.\",\n \t}\n-\tif _, err = tableRef.Update(ctx, newMeta, original.ETag); err != nil {\n+\tif _, err = tableRef.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_table_description]",
        "comments": [
            {
                "comment": "Maybe do `if len(meta.Labels) == 0`, in case it's every an empty list?\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Nit: Please capitalize \"dataset.\"\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Maybe delete `update` from the function names? For example, `addDatasetLabel` and `deleteDatasetLabel`.",
                "position": null
            },
            {
                "comment": "It seems a little awkward to have the original metadata and the update one. Could `SetLabel` be called on the original one?",
                "position": null
            },
            {
                "comment": "The variable names for the original and the update are inconsistent between the functions. Maybe they could be `meta` and `update`?",
                "position": null
            },
            {
                "comment": "In Go, we generally avoid the prefix `get`. This would be `datasetLabels`.",
                "position": null
            },
            {
                "comment": "Same `get` comment.",
                "position": null
            },
            {
                "comment": "Nit: Capitalize.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Side effect of naming according to region tags.  Corrected.",
                "position": null
            },
            {
                "comment": "unified naming, including older samples.",
                "position": null
            },
            {
                "comment": "I'm also not a huge fan of how the label mutations are done in the client library, but that's the structure defined and shared by multiple services (see the same semantics in the GCS library, for example).",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments",
        "commit_id": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -330,31 +330,31 @@\nfunc updateTableExpiration(client *bigquery.Client, datasetID, tableID string) e\n \tctx := context.Background()\n \t// [START bigquery_update_table_expiration]\n \ttableRef := client.Dataset(datasetID).Table(tableID)\n-\toriginal, err := tableRef.Metadata(ctx)\n+\tmeta, err := tableRef.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tnewMeta := bigquery.TableMetadataToUpdate{\n+\tupdate := bigquery.TableMetadataToUpdate{\n \t\tExpirationTime: time.Now().Add(time.Duration(5*24) * time.Hour), // table expiration in 5 days.\n \t}\n-\tif _, err = tableRef.Update(ctx, newMeta, original.ETag); err != nil {\n+\tif _, err = tableRef.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_table_expiration]\n \treturn nil\n \n }\n \n-func getTableLabels(client *bigquery.Client, w io.Writer, datasetID, tableID string) error {\n+func tableLabels(client *bigquery.Client, w io.Writer, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_table_labels]\n \tmeta, err := client.Dataset(datasetID).Table(tableID).Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \tfmt.Fprintf(w, \"Table %s labels:\\n\", datasetID)\n-\tif meta.Labels == nil {\n-\t\tfmt.Println(\"dataset has no labels defined.\")\n+\tif len(meta.Labels) == 0 {\n+\t\tfmt.Println(\"Table has no labels defined.\")\n \t\treturn nil\n \t}\n \tfor k, v := range meta.Labels {",
        "comments": [
            {
                "comment": "Maybe do `if len(meta.Labels) == 0`, in case it's every an empty list?\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Nit: Please capitalize \"dataset.\"\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Maybe delete `update` from the function names? For example, `addDatasetLabel` and `deleteDatasetLabel`.",
                "position": null
            },
            {
                "comment": "It seems a little awkward to have the original metadata and the update one. Could `SetLabel` be called on the original one?",
                "position": null
            },
            {
                "comment": "The variable names for the original and the update are inconsistent between the functions. Maybe they could be `meta` and `update`?",
                "position": null
            },
            {
                "comment": "In Go, we generally avoid the prefix `get`. This would be `datasetLabels`.",
                "position": null
            },
            {
                "comment": "Same `get` comment.",
                "position": null
            },
            {
                "comment": "Nit: Capitalize.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Side effect of naming according to region tags.  Corrected.",
                "position": null
            },
            {
                "comment": "unified naming, including older samples.",
                "position": null
            },
            {
                "comment": "I'm also not a huge fan of how the label mutations are done in the client library, but that's the structure defined and shared by multiple services (see the same semantics in the GCS library, for example).",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments",
        "commit_id": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -364,35 +364,35 @@\nfunc getTableLabels(client *bigquery.Client, w io.Writer, datasetID, tableID str\n \treturn nil\n }\n \n-func updateTableAddLabel(client *bigquery.Client, datasetID, tableID string) error {\n+func addTableLabel(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_label_table]\n \ttbl := client.Dataset(datasetID).Table(tableID)\n-\toriginal, err := tbl.Metadata(ctx)\n+\tmeta, err := tbl.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \n-\tmeta := bigquery.TableMetadataToUpdate{}\n-\tmeta.SetLabel(\"color\", \"green\")\n-\tif _, err := tbl.Update(ctx, meta, original.ETag); err != nil {\n+\tupdate := bigquery.TableMetadataToUpdate{}\n+\tupdate.SetLabel(\"color\", \"green\")\n+\tif _, err := tbl.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_label_table]\n \treturn nil\n }\n \n-func updateTableDeleteLabel(client *bigquery.Client, datasetID, tableID string) error {\n+func deleteTableLabel(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_delete_label_table]\n \ttbl := client.Dataset(datasetID).Table(tableID)\n-\toriginalMeta, err := tbl.Metadata(ctx)\n+\tmeta, err := tbl.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tnewMeta := bigquery.TableMetadataToUpdate{}\n-\tnewMeta.DeleteLabel(\"color\")\n-\tif _, err := tbl.Update(ctx, newMeta, originalMeta.ETag); err != nil {\n+\tupdate := bigquery.TableMetadataToUpdate{}\n+\tupdate.DeleteLabel(\"color\")\n+\tif _, err := tbl.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_delete_label_table]",
        "comments": [
            {
                "comment": "Maybe do `if len(meta.Labels) == 0`, in case it's every an empty list?\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Nit: Please capitalize \"dataset.\"\r\n\r\nBelow, too.",
                "position": null
            },
            {
                "comment": "Maybe delete `update` from the function names? For example, `addDatasetLabel` and `deleteDatasetLabel`.",
                "position": null
            },
            {
                "comment": "It seems a little awkward to have the original metadata and the update one. Could `SetLabel` be called on the original one?",
                "position": null
            },
            {
                "comment": "The variable names for the original and the update are inconsistent between the functions. Maybe they could be `meta` and `update`?",
                "position": null
            },
            {
                "comment": "In Go, we generally avoid the prefix `get`. This would be `datasetLabels`.",
                "position": null
            },
            {
                "comment": "Same `get` comment.",
                "position": null
            },
            {
                "comment": "Nit: Capitalize.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Side effect of naming according to region tags.  Corrected.",
                "position": null
            },
            {
                "comment": "unified naming, including older samples.",
                "position": null
            },
            {
                "comment": "I'm also not a huge fan of how the label mutations are done in the client library, but that's the structure defined and shared by multiple services (see the same semantics in the GCS library, for example).",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments",
        "commit_id": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -48,8 +48,6 @@\nfunc TestAll(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbuf := &bytes.Buffer{}\n-\n \tclient, err := bigquery.NewClient(ctx, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatal(err)",
        "comments": [
            {
                "comment": "Maybe move this below, closer to where it's used?",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments",
        "commit_id": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -65,18 +63,20 @@\nfunc TestAll(t *testing.T) {\n \tif err := updateDatasetAccessControl(client, datasetID); err != nil {\n \t\tt.Errorf(\"updateDataSetAccessControl(%q): %v\", datasetID, err)\n \t}\n-\tif err := updateDatasetAddLabel(client, datasetID); err != nil {\n+\tif err := addDatasetLabel(client, datasetID); err != nil {\n \t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n \t}\n-\tif err := getDatasetLabels(client, buf, datasetID); err != nil {\n+\n+\tbuf := &bytes.Buffer{}\n+\tif err := datasetLabels(client, buf, datasetID); err != nil {\n \t\tt.Errorf(\"getDatasetLabels(%q): %v\", datasetID, err)\n \t}\n \twant := \"color:green\"\n \tif got := buf.String(); !strings.Contains(got, want) {\n \t\tt.Errorf(\"getDatasetLabel(%q) expected %q to contain %q\", datasetID, got, want)\n \t}\n \n-\tif err := updateDatasetAddLabel(client, datasetID); err != nil {\n+\tif err := addDatasetLabel(client, datasetID); err != nil {\n \t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n \t}\n \tbuf.Reset()",
        "comments": [
            {
                "comment": "Maybe move this below, closer to where it's used?",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments",
        "commit_id": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -86,7 +86,7 @@\nfunc TestAll(t *testing.T) {\n \tif got := buf.String(); !strings.Contains(got, datasetID) {\n \t\tt.Errorf(\"listDatasetsByLabel expected %q to contain %q\", got, want)\n \t}\n-\tif err := updateDatasetDeleteLabel(client, datasetID); err != nil {\n+\tif err := deleteDatasetLabel(client, datasetID); err != nil {\n \t\tt.Errorf(\"updateDatasetDeleteLabel: %v\", err)\n \t}",
        "comments": [
            {
                "comment": "Maybe move this below, closer to where it's used?",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments",
        "commit_id": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -7,8 +7,6 @@\npackage snippets\n import (\n \t\"bytes\"\n \t\"fmt\"\n-\t\"log\"\n-\t\"os\"\n \t\"regexp\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [
            {
                "comment": "Bucket names need to be globally unique. Maybe this should use `tc.ProjectID`?",
                "position": null
            },
            {
                "comment": "I think we can drop the nanosecond. I know bucket name lengths can be limited. Not sure about BQ.",
                "position": null
            },
            {
                "comment": "Nit: newline before this.",
                "position": null
            },
            {
                "comment": "bucket names are bounded at 63 chars except for the dns-style name cases, so I added a check that truncates.",
                "position": null
            },
            {
                "comment": "BQ references can be up to 1k chars, so not worrying about that.",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'master' into cleanup, address reviewer comments.",
        "commit_id": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -21,30 +19,23 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n-func init() {\n-\t// Workaround for Travis:\n-\t// https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received\n-\tif os.Getenv(\"TRAVIS\") == \"true\" {\n-\t\tgo func() {\n-\t\t\tfor {\n-\t\t\t\ttime.Sleep(5 * time.Minute)\n-\t\t\t\tlog.Print(\"Still testing. Don't kill me!\")\n-\t\t\t}\n-\t\t}()\n-\t}\n-}\n-\n // uniqueBQName returns a more unique name for a BigQuery resource.\n func uniqueBQName(prefix string) string {\n \tt := time.Now()\n-\treturn fmt.Sprintf(\"%s_%d_%d\", sanitize(prefix, '_'), t.Unix(), t.Nanosecond())\n+\treturn fmt.Sprintf(\"%s_%d\", sanitize(prefix, '_'), t.Unix())\n }\n \n // uniqueBucketName returns a more unique name cloud storage bucket.\n func uniqueBucketName(prefix, projectID string) string {\n \tt := time.Now()\n-\treturn fmt.Sprintf(\"%s-%s-%d%d\", sanitize(prefix, '-'), sanitize(projectID, '-'), t.Unix(), t.Nanosecond())\n+\tf := fmt.Sprintf(\"%s-%s-%d\", sanitize(prefix, '-'), sanitize(projectID, '-'), t.Unix())\n+\t// bucket max name length is 63 chars, so we truncate.\n+\tif len(f) > 63 {\n+\t\treturn f[:63]\n+\t}\n+\treturn f\n }\n+\n func sanitize(s string, allowedSeparator rune) string {\n \tpattern := fmt.Sprintf(\"[^a-zA-Z0-9%s]\", string(allowedSeparator))\n \treg, err := regexp.Compile(pattern)",
        "comments": [
            {
                "comment": "Bucket names need to be globally unique. Maybe this should use `tc.ProjectID`?",
                "position": null
            },
            {
                "comment": "I think we can drop the nanosecond. I know bucket name lengths can be limited. Not sure about BQ.",
                "position": null
            },
            {
                "comment": "Nit: newline before this.",
                "position": null
            },
            {
                "comment": "bucket names are bounded at 63 chars except for the dns-style name cases, so I added a check that truncates.",
                "position": null
            },
            {
                "comment": "BQ references can be up to 1k chars, so not worrying about that.",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'master' into cleanup, address reviewer comments.",
        "commit_id": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -53,7 +44,6 @@\nfunc sanitize(s string, allowedSeparator rune) string {\n \t}\n \treturn reg.ReplaceAllString(s, \"\")\n }\n-\n func TestAll(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()",
        "comments": [
            {
                "comment": "Bucket names need to be globally unique. Maybe this should use `tc.ProjectID`?",
                "position": null
            },
            {
                "comment": "I think we can drop the nanosecond. I know bucket name lengths can be limited. Not sure about BQ.",
                "position": null
            },
            {
                "comment": "Nit: newline before this.",
                "position": null
            },
            {
                "comment": "bucket names are bounded at 63 chars except for the dns-style name cases, so I added a check that truncates.",
                "position": null
            },
            {
                "comment": "BQ references can be up to 1k chars, so not worrying about that.",
                "position": null
            }
        ],
        "commit_message": "Merge branch 'master' into cleanup, address reviewer comments.",
        "commit_id": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -28,40 +28,40 @@\ntype Task struct {\n }\n \n func SnippetNewIncompleteKey() {\n-\t// [START incomplete_key]\n+\t// [START datastore_incomplete_key]\n \ttaskKey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [END incomplete_key]\n+\t// [END datastore_incomplete_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey() {\n-\t// [START named_key]\n+\t// [START datastore_named_key]\n \ttaskKey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [END named_key]\n+\t// [END datastore_named_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withParent() {\n-\t// [START key_with_parent]\n+\t// [START datastore_key_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_parent]\n+\t// [END datastore_key_with_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withMultipleParents() {\n-\t// [START key_with_multilevel_parent]\n+\t// [START datastore_key_with_multilevel_parent]\n \tuserKey := datastore.NameKey(\"User\", \"alice\", nil)\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", userKey)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_multilevel_parent]\n+\t// [END datastore_key_with_multilevel_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetClient_Put() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START entity_with_parent]\n+\t// [START datastore_entity_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tkey := datastore.IncompleteKey(\"Task\", parentKey)",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -75,12 +75,12 @@\nfunc SnippetClient_Put() {\n \t// A complete key is assigned to the entity when it is Put.\n \tvar err error\n \tkey, err = client.Put(ctx, key, &task)\n-\t// [END entity_with_parent]\n+\t// [END datastore_entity_with_parent]\n \t_ = err // Make sure you check err.\n }\n \n func Snippet_properties() {\n-\t// [START properties]\n+\t// [START datastore_properties]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -97,12 +97,12 @@\nfunc Snippet_properties() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END properties]\n+\t// [END datastore_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_sliceProperties() {\n-\t// [START array_value]\n+\t// [START datastore_array_value]\n \ttype Task struct {\n \t\tTags          []string\n \t\tCollaborators []string",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -111,12 +111,12 @@\nfunc Snippet_sliceProperties() {\n \t\tTags:          []string{\"fun\", \"programming\"},\n \t\tCollaborators: []string{\"alice\", \"bob\"},\n \t}\n-\t// [END array_value]\n+\t// [END datastore_array_value]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_basicEntity() {\n-\t// [START basic_entity]\n+\t// [START datastore_basic_entity]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -133,7 +133,7 @@\nfunc Snippet_basicEntity() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END basic_entity]\n+\t// [END datastore_basic_entity]\n \t_ = task // Use the task in a datastore Put operation.\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -142,9 +142,9 @@\nfunc SnippetClient_Put_upsert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := &Task{} // Populated with appropriate data.\n \tkey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [START upsert]\n+\t// [START datastore_upsert]\n \tkey, err := client.Put(ctx, key, task)\n-\t// [END upsert]\n+\t// [END datastore_upsert]\n \t_ = err // Make sure you check err.\n \t_ = key // key is the complete key for the newly stored task\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -154,7 +154,7 @@\nfunc SnippetTransaction_insert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := Task{} // Populated with appropriate data.\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START insert]\n+\t// [START datastore_insert]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\t// We first check that there is no entity stored with the given key.\n \t\tvar empty Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -165,26 +165,26 @@\nfunc SnippetTransaction_insert() {\n \t\t_, err := tx.Put(taskKey, &task)\n \t\treturn err\n \t})\n-\t// [END insert]\n+\t// [END datastore_insert]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_Get() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START lookup]\n+\t// [START datastore_lookup]\n \tvar task Task\n \terr := client.Get(ctx, taskKey, &task)\n-\t// [END lookup]\n+\t// [END datastore_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetTransaction_update() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START update]\n+\t// [START datastore_update]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -200,23 +200,23 @@\nfunc SnippetTransaction_update() {\n \tif _, err := tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END update]\n+\t// [END datastore_update]\n }\n \n func SnippetClient_Delete() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START delete]\n+\t// [START datastore_delete]\n \terr := client.Delete(ctx, key)\n-\t// [END delete]\n+\t// [END datastore_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_PutMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START batch_upsert]\n+\t// [START datastore_batch_upsert]\n \ttasks := []*Task{\n \t\t{\n \t\t\tCategory:    \"Personal\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -237,7 +237,7 @@\nfunc SnippetClient_PutMulti() {\n \t}\n \n \tkeys, err := client.PutMulti(ctx, keys, tasks)\n-\t// [END batch_upsert]\n+\t// [END datastore_batch_upsert]\n \t_ = err  // Make sure you check err.\n \t_ = keys // keys now has the complete keys for the newly stored tasks.\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -246,33 +246,33 @@\nfunc SnippetClient_GetMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_lookup]\n+\t// [START datastore_batch_lookup]\n \tvar tasks []*Task\n \terr := client.GetMulti(ctx, taskKeys, &tasks)\n-\t// [END batch_lookup]\n+\t// [END datastore_batch_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_DeleteMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_delete]\n+\t// [START datastore_batch_delete]\n \terr := client.DeleteMulti(ctx, taskKeys)\n-\t// [END batch_delete]\n+\t// [END datastore_batch_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetQuery_basic() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START basic_query]\n+\t// [START datastore_basic_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Priority >=\", 4).\n \t\tOrder(\"-Priority\")\n-\t// [END basic_query]\n-\t// [START run_query]\n+\t// [END datastore_basic_query]\n+\t// [START datastore_run_query]\n \tit := client.Run(ctx, query)\n \tfor {\n \t\tvar task Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -285,75 +285,75 @@\nfunc SnippetQuery_basic() {\n \t\t}\n \t\tfmt.Printf(\"Task %q, Priority %d\\n\", task.Description, task.Priority)\n \t}\n-\t// [END run_query]\n+\t// [END datastore_run_query]\n }\n \n func SnippetQuery_propertyFilter() {\n-\t// [START property_filter]\n+\t// [START datastore_property_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false)\n-\t// [END property_filter]\n+\t// [END datastore_property_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_compositeFilter() {\n-\t// [START composite_filter]\n+\t// [START datastore_composite_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false).Filter(\"Priority =\", 4)\n-\t// [END composite_filter]\n+\t// [END datastore_composite_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_keyFilter() {\n-\t// [START key_filter]\n+\t// [START datastore_key_filter]\n \tkey := datastore.NameKey(\"Task\", \"someTask\", nil)\n \tquery := datastore.NewQuery(\"Task\").Filter(\"__key__ >\", key)\n-\t// [END key_filter]\n+\t// [END datastore_key_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortAscending() {\n-\t// [START ascending_sort]\n+\t// [START datastore_ascending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"created\")\n-\t// [END ascending_sort]\n+\t// [END datastore_ascending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortDescending() {\n-\t// [START descending_sort]\n+\t// [START datastore_descending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-created\")\n-\t// [END descending_sort]\n+\t// [END datastore_descending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortMulti() {\n-\t// [START multi_sort]\n+\t// [START datastore_multi_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-priority\").Order(\"created\")\n-\t// [END multi_sort]\n+\t// [END datastore_multi_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_kindless() {\n \tvar lastSeenKey *datastore.Key\n-\t// [START kindless_query]\n+\t// [START datastore_kindless_query]\n \tquery := datastore.NewQuery(\"\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_query]\n+\t// [END datastore_kindless_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Ancestor() {\n-\t// [START ancestor_query]\n+\t// [START datastore_ancestor_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor)\n-\t// [END ancestor_query]\n+\t// [END datastore_ancestor_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Project() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START projection_query]\n+\t// [START datastore_projection_query]\n \tquery := datastore.NewQuery(\"Task\").Project(\"Priority\", \"PercentComplete\")\n-\t// [END projection_query]\n-\t// [START run_query_projection]\n+\t// [END datastore_projection_query]\n+\t// [START datastore_run_query_projection]\n \tvar priorities []int\n \tvar percents []float64\n \tit := client.Run(ctx, query)",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -367,130 +367,130 @@\nfunc SnippetQuery_Project() {\n \t\tpriorities = append(priorities, task.Priority)\n \t\tpercents = append(percents, task.PercentComplete)\n \t}\n-\t// [END run_query_projection]\n+\t// [END datastore_run_query_projection]\n }\n \n func SnippetQuery_KeysOnly() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START keys_only_query]\n+\t// [START datastore_keys_only_query]\n \tquery := datastore.NewQuery(\"Task\").KeysOnly()\n-\t// [END keys_only_query]\n-\t// [START run_keys_only_query]\n+\t// [END datastore_keys_only_query]\n+\t// [START datastore_run_keys_only_query]\n \tkeys, err := client.GetAll(ctx, query, nil)\n-\t// [END run_keys_only_query]\n+\t// [END datastore_run_keys_only_query]\n \t_ = err  // Make sure you check err.\n \t_ = keys // Keys contains keys for all stored tasks.\n }\n \n func SnippetQuery_Distinct() {\n-\t// [START distinct_query]\n+\t// [START datastore_distinct_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tProject(\"Priority\", \"PercentComplete\").\n \t\tDistinct().\n \t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_query]\n+\t// [END datastore_distinct_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_DistinctOn() {\n-\t// [START distinct_on_query]\n+\t// [START datastore_distinct_on_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tProject(\"Priority\", \"Category\").\n \t\tDistinctOn(\"Category\").\n \t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_on_query]\n+\t// [END datastore_distinct_on_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayInequality() {\n-\t// [START array_value_inequality_range]\n+\t// [START datastore_array_value_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag >\", \"learn\").\n \t\tFilter(\"Tag <\", \"math\")\n-\t// [END array_value_inequality_range]\n+\t// [END datastore_array_value_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayEquality() {\n-\t// [START array_value_equality]\n+\t// [START datastore_array_value_equality]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag =\", \"fun\").\n \t\tFilter(\"Tag =\", \"programming\")\n-\t// [END array_value_equality]\n+\t// [END datastore_array_value_equality]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_inequality() {\n-\t// [START inequality_range]\n+\t// [START datastore_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END inequality_range]\n+\t// [END datastore_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_invalidInequality() {\n-\t// [START inequality_invalid]\n+\t// [START datastore_inequality_invalid]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Priority >\", 3)\n-\t// [END inequality_invalid]\n+\t// [END datastore_inequality_invalid]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Filter_mixed() {\n-\t// [START equal_and_inequality_range]\n+\t// [START datastore_equal_and_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority =\", 4).\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END equal_and_inequality_range]\n+\t// [END datastore_equal_and_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_inequalitySort() {\n-\t// [START inequality_sort]\n+\t// [START datastore_inequality_sort]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Priority\").\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort]\n+\t// [END datastore_inequality_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_invalidInequalitySortA() {\n-\t// [START inequality_sort_invalid_not_same]\n+\t// [START datastore_inequality_sort_invalid_not_same]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort_invalid_not_same]\n+\t// [END datastore_inequality_sort_invalid_not_same]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_invalidInequalitySortB() {\n-\t// [START inequality_sort_invalid_not_first]\n+\t// [START datastore_inequality_sort_invalid_not_first]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\").\n \t\tOrder(\"Priority\")\n-\t// [END inequality_sort_invalid_not_first]\n+\t// [END datastore_inequality_sort_invalid_not_first]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Limit() {\n-\t// [START limit]\n+\t// [START datastore_limit]\n \tquery := datastore.NewQuery(\"Task\").Limit(5)\n-\t// [END limit]\n+\t// [END datastore_limit]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetIterator_Cursor() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tcursorStr := \"\"\n-\t// [START cursor_paging]\n+\t// [START datastore_cursor_paging]\n \tconst pageSize = 5\n \tquery := datastore.NewQuery(\"Tasks\").Limit(pageSize)\n \tif cursorStr != \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -516,42 +516,42 @@\nfunc SnippetIterator_Cursor() {\n \n \t// Get the cursor for the next page of results.\n \tnextCursor, err := it.Cursor()\n-\t// [END cursor_paging]\n+\t// [END datastore_cursor_paging]\n \t_ = err        // Check the error.\n \t_ = nextCursor // Use nextCursor.String as the next page's token.\n }\n \n func SnippetQuery_EventualConsistency() {\n-\t// [START eventual_consistent_query]\n+\t// [START datastore_eventual_consistent_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).EventualConsistency()\n-\t// [END eventual_consistent_query]\n+\t// [END datastore_eventual_consistent_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_unindexed() {\n-\t// [START unindexed_property_query]\n+\t// [START datastore_unindexed_property_query]\n \tquery := datastore.NewQuery(\"Tasks\").Filter(\"Description =\", \"A task description\")\n-\t// [END unindexed_property_query]\n+\t// [END datastore_unindexed_property_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func Snippet_explodingProperties() {\n-\t// [START exploding_properties]\n+\t// [START datastore_exploding_properties]\n \ttask := &Task{\n \t\tTags:          []string{\"fun\", \"programming\", \"learn\"},\n \t\tCollaborators: []string{\"alice\", \"bob\", \"charlie\"},\n \t\tCreated:       time.Now(),\n \t}\n-\t// [END exploding_properties]\n+\t// [END datastore_exploding_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_Transaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_update]\n+\t// [START datastore_transactional_update]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -576,14 +576,14 @@\nfunc Snippet_Transaction() {\n \tif _, err = tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END transactional_update]\n+\t// [END datastore_transactional_update]\n }\n \n func Snippet_Client_RunInTransaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_retry]\n+\t// [START datastore_transactional_retry]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -600,15 +600,15 @@\nfunc Snippet_Client_RunInTransaction() {\n \t\t_, err := tx.PutMulti(keys, accs)\n \t\treturn err\n \t})\n-\t// [END transactional_retry]\n+\t// [END datastore_transactional_retry]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_getOrCreate() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START transactional_get_or_create]\n+\t// [START datastore_transactional_get_or_create]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\tvar task Task\n \t\tif err := tx.Get(key, &task); err != datastore.ErrNoSuchEntity {",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -622,14 +622,14 @@\nfunc SnippetTransaction_getOrCreate() {\n \t\t})\n \t\treturn err\n \t})\n-\t// [END transactional_get_or_create]\n+\t// [END datastore_transactional_get_or_create]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_runQuery() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START transactional_single_entity_group_read_only]\n+\t// [START datastore_transactional_single_entity_group_read_only]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -640,14 +640,14 @@\nfunc SnippetTransaction_runQuery() {\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).Transaction(tx)\n \tvar tasks []Task\n \t_, err = client.GetAll(ctx, query, &tasks)\n-\t// [END transactional_single_entity_group_read_only]\n+\t// [END datastore_transactional_single_entity_group_read_only]\n \t_ = err // Check error.\n }\n \n func Snippet_metadataNamespaces() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START namespace_run_query]\n+\t// [START datastore_namespace_run_query]\n \tconst (\n \t\tstartNamespace = \"g\"\n \t\tendNamespace   = \"h\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -665,13 +665,13 @@\nfunc Snippet_metadataNamespaces() {\n \tfor _, k := range keys {\n \t\tnamespaces = append(namespaces, k.Name)\n \t}\n-\t// [END namespace_run_query]\n+\t// [END datastore_namespace_run_query]\n }\n \n func Snippet_metadataKinds() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START kind_run_query]\n+\t// [START datastore_kind_run_query]\n \tquery := datastore.NewQuery(\"__kind__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -682,13 +682,13 @@\nfunc Snippet_metadataKinds() {\n \tfor _, k := range keys {\n \t\tkinds = append(kinds, k.Name)\n \t}\n-\t// [END kind_run_query]\n+\t// [END datastore_kind_run_query]\n }\n \n func Snippet_metadataProperties() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_run_query]\n+\t// [START datastore_property_run_query]\n \tquery := datastore.NewQuery(\"__property__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -701,13 +701,13 @@\nfunc Snippet_metadataProperties() {\n \t\tkind := k.Parent.Name\n \t\tprops[kind] = append(props[kind], prop)\n \t}\n-\t// [END property_run_query]\n+\t// [END datastore_property_run_query]\n }\n \n func Snippet_metadataPropertiesForKind() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_by_kind_run_query]\n+\t// [START datastore_property_by_kind_run_query]\n \tkindKey := datastore.NameKey(\"__kind__\", \"Task\", nil)\n \tquery := datastore.NewQuery(\"__property__\").Ancestor(kindKey)",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START all]\n+// [START datastore_all]\n \n // A simple command-line task list manager to demonstrate using the\n // cloud.google.com/go/datastore package.",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -29,10 +29,10 @@\nfunc main() {\n \tif projID == \"\" {\n \t\tlog.Fatal(`You need to set the environment variable \"DATASTORE_PROJECT_ID\"`)\n \t}\n-\t// [START build_service]\n+\t// [START datastore_build_service]\n \tctx := context.Background()\n \tclient, err := datastore.NewClient(ctx, projID)\n-\t// [END build_service]\n+\t// [END datastore_build_service]\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create datastore client: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -107,7 +107,7 @@\nfunc main() {\n \t}\n }\n \n-// [START add_entity]\n+// [START datastore_add_entity]\n // Task is the model used to store tasks in the datastore.\n type Task struct {\n \tDesc    string    `datastore:\"description\"`",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -127,9 +127,9 @@\nfunc AddTask(ctx context.Context, client *datastore.Client, desc string) (*datas\n \treturn client.Put(ctx, key, task)\n }\n \n-// [END add_entity]\n+// [END datastore_add_entity]\n \n-// [START update_entity]\n+// [START datastore_update_entity]\n // MarkDone marks the task done with the given ID.\n func MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error {\n \t// Create a key using the given integer ID.",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -148,9 +148,9 @@\nfunc MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error\n \treturn err\n }\n \n-// [END update_entity]\n+// [END datastore_update_entity]\n \n-// [START retrieve_entities]\n+// [START datastore_retrieve_entities]\n // ListTasks returns all the tasks in ascending order of creation time.\n func ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \tvar tasks []*Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -170,17 +170,17 @@\nfunc ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \treturn tasks, nil\n }\n \n-// [END retrieve_entities]\n+// [END datastore_retrieve_entities]\n \n-// [START delete_entity]\n+// [START datastore_delete_entity]\n // DeleteTask deletes the task with the given ID.\n func DeleteTask(ctx context.Context, client *datastore.Client, taskID int64) error {\n \treturn client.Delete(ctx, datastore.IDKey(\"Task\", taskID, nil))\n }\n \n-// [END delete_entity]\n+// [END datastore_delete_entity]\n \n-// [START format_results]\n+// [START datastore_format_results]\n // PrintTasks prints the tasks to the given writer.\n func PrintTasks(w io.Writer, tasks []*Task) {\n \t// Use a tab writer to help make results pretty.",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -196,7 +196,7 @@\nfunc PrintTasks(w io.Writer, tasks []*Task) {\n \ttw.Flush()\n }\n \n-// [END format_results]\n+// [END datastore_format_results]\n \n func usage() {\n \tfmt.Print(`Usage:",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipz",
        "commit_id": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -305,15 +305,29 @@\nfunc listRows(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n-func basicQuery(client *bigquery.Client, datasetID, tableID string) error {\n+func queryBasic(client *bigquery.Client) error {\n \tctx := context.Background()\n \t// [START bigquery_query]\n+\n \tq := client.Query(\n \t\t\"SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` \" +\n \t\t\t\"WHERE state = \\\"TX\\\" \" +\n \t\t\t\"LIMIT 100\")\n \t// Location must match that of the dataset(s) referenced in the query.\n \tq.Location = \"US\"\n+\t// [END bigquery_query]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryDisableCache(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_no_cache]\n+\n+\tq := client.Query(\n+\t\t\"SELECT corpus FROM `bigquery-public-data.samples.shakespeare` GROUP BY corpus;\")\n+\tq.DisableQueryCache = true\n+\t// Location must match that of the dataset(s) referenced in the query.\n+\tq.Location = \"US\"\n \n \tjob, err := q.Run(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -341,70 +355,227 @@\nfunc basicQuery(client *bigquery.Client, datasetID, tableID string) error {\n \t\t}\n \t\tfmt.Println(row)\n \t}\n-\t// [END bigquery_query]\n+\t// [END bigquery_query_no_cache]\n \treturn nil\n }\n \n-func queryWithDestination(client *bigquery.Client, destDatasetID, destTableID string) error {\n+func queryBatch(client *bigquery.Client, dstDatasetID, dstTableID string) error {\n \tctx := context.Background()\n-\t// [START bigquery_query_destination_table]\n-\tdestRef := client.Dataset(destDatasetID).Table(destTableID)\n-\tq := client.Query(\"SELECT 17 as my_col\")\n-\tq.Location = \"US\" // Location must match the dataset(s) referenced in query.\n-\tq.QueryConfig.Dst = destRef\n-\n-\t// Run job, then wait until asyncronous execution is complete.\n+\t// [START bigquery_query_batch]\n+\t// Build an aggregate table.\n+\tq := client.Query(`\n+\t\tSELECT\n+  \t\t\tcorpus,\n+  \t\t\tSUM(word_count) as total_words,\n+  \t\t\tCOUNT(1) as unique_words\n+\t\tFROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+\t\tGROUP BY corpus;`)\n+\tq.Priority = bigquery.BatchPriority\n+\tq.QueryConfig.Dst = client.Dataset(dstDatasetID).Table(dstTableID)\n+\n+\t// Start the job.\n \tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tstatus, err := job.Wait(ctx)\n+\t// Job is started and will progress without interaction.\n+\t// To simulate other work being done, sleep a few seconds.\n+\ttime.Sleep(5 * time.Second)\n+\tstatus, err := job.Status(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tif err := status.Err(); err != nil {\n-\t\treturn err\n-\t}\n-\t// At this point, the query has completed and results are persisted to the\n-\t// destination table.  You can also choose to read from the table.\n-\tit, err := job.Read(ctx)\n-\tfor {\n-\t\tvar row []bigquery.Value\n-\t\terr := it.Next(&row)\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Println(row)\n+\n+\tstate := \"Unknown\"\n+\tswitch status.State {\n+\tcase bigquery.Pending:\n+\t\tstate = \"Pending\"\n+\tcase bigquery.Running:\n+\t\tstate = \"Running\"\n+\tcase bigquery.Done:\n+\t\tstate = \"Done\"\n \t}\n-\t// [END bigquery_query_destination_table]\n+\t// You can continue to monitor job progress until it reaches\n+\t// the Done state by polling periodically.  In this example,\n+\t// we print the latest status.\n+\tfmt.Printf(\"Job %s in Location %s currently in state: %s\\n\", job.ID(), job.Location(), state)\n+\n+\t// [END bigquery_query_batch]\n+\tjob.Cancel(ctx)\n \treturn nil\n }\n \n-func queryLegacy(client *bigquery.Client, sqlString string) error {\n+func queryDryRun(client *bigquery.Client) error {\n \tctx := context.Background()\n-\t// [START bigquery_query_legacy]\n-\tq := client.Query(sqlString)\n-\tq.UseLegacySQL = true\n+\t// [START bigquery_query_dry_run]\n+\tq := client.Query(`\n+\t\tSELECT \n+\t\t   name,\n+\t\t   COUNT(*) as name_count\n+\t\tFROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n+\t\tWHERE state = 'WA' \n+\t\tGROUP BY name\n+\t\t`)\n+\tq.DryRun = true\n+\t// Location must match that of the dataset(s) referenced in the query.\n+\tq.Location = \"US\"\n \n-\t// Run job, then wait until asyncronous execution is complete.\n \tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tstatus, err := job.Wait(ctx)\n+\t// Dry run is not asynchronous, so get the latest status and statistics.\n+\tstatus := job.LastStatus()\n \tif err != nil {\n \t\treturn err\n \t}\n-\tif err := status.Err(); err != nil {\n-\t\treturn err\n-\t}\n-\t// [END bigquery_query_legacy]\n+\tfmt.Printf(\"This query will process %d bytes\\n\", status.Statistics.TotalBytesProcessed)\n+\n+\t// [END bigquery_query_dry_run]\n \treturn nil\n }\n \n+func queryWithDestination(client *bigquery.Client, destDatasetID, destTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_destination_table]\n+\n+\tq := client.Query(\"SELECT 17 as my_col\")\n+\tq.Location = \"US\" // Location must match the dataset(s) referenced in query.\n+\tq.QueryConfig.Dst = client.Dataset(destDatasetID).Table(destTableID)\n+\t// [END bigquery_query_destination_table]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryLegacy(client *bigquery.Client, sqlString string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_legacy]\n+\tq := client.Query(sqlString)\n+\tq.UseLegacySQL = true\n+\n+\t// [END bigquery_query_legacy]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryLegacyLargeResults(client *bigquery.Client, dstDatasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_legacy_large_results]\n+\tq := client.Query(\n+\t\t\"SELECT corpus FROM [bigquery-public-data:samples.shakespeare] GROUP BY corpus;\")\n+\tq.UseLegacySQL = true\n+\tq.AllowLargeResults = true\n+\tq.QueryConfig.Dst = client.Dataset(dstDatasetID).Table(dstTableID)\n+\t// [END bigquery_query_legacy_large_results]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithArrayParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_arrays]\n+\tq := client.Query(\n+\t\t`SELECT\n+\t\t\tname,\n+\t\t\tsum(number) as count \n+        FROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n+\t\tWHERE\n+\t\t\tgender = @gender\n+        \tAND state IN UNNEST(@states)\n+\t\tGROUP BY\n+\t\t\tname\n+\t\tORDER BY\n+\t\t\tcount DESC\n+\t\tLIMIT 10;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"gender\",\n+\t\t\tValue: \"M\",\n+\t\t},\n+\t\t{\n+\t\t\tName:  \"states\",\n+\t\t\tValue: []string{\"WA\", \"WI\", \"WV\", \"WY\"},\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_arrays]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithNamedParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_named]\n+\tq := client.Query(\n+\t\t`SELECT word, word_count\n+        FROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+        WHERE corpus = @corpus\n+        AND word_count >= @min_word_count\n+        ORDER BY word_count DESC;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"corpus\",\n+\t\t\tValue: \"romeoandjuliet\",\n+\t\t},\n+\t\t{\n+\t\t\tName:  \"min_word_count\",\n+\t\t\tValue: 250,\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_named]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithPositionalParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_positional]\n+\tq := client.Query(\n+\t\t`SELECT word, word_count\n+        FROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+        WHERE corpus = ?\n+        AND word_count >= ?\n+        ORDER BY word_count DESC;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tValue: \"romeoandjuliet\",\n+\t\t},\n+\t\t{\n+\t\t\tValue: 250,\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_positional]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithTimestampParam(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_timestamps]\n+\tq := client.Query(\n+\t\t`SELECT TIMESTAMP_ADD(@ts_value, INTERVAL 1 HOUR);`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"ts_value\",\n+\t\t\tValue: time.Date(2016, 12, 7, 8, 0, 0, 0, time.UTC),\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_timestamps]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithStructParam(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_structs]\n+\ttype MyStruct struct {\n+\t\tX int64\n+\t\tY string\n+\t}\n+\tq := client.Query(\n+\t\t`SELECT @struct_value as s;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"struct_value\",\n+\t\t\tValue: MyStruct{X: 1, Y: \"foo\"},\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_structs]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n func printTableInfo(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_table]",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -461,6 +632,66 @@\nfunc copyTable(client *bigquery.Client, datasetID, srcID, dstID string) error {\n \treturn nil\n }\n \n+// generateTableCTAS creates a quick table by issuing a CREATE TABLE AS SELECT\n+// query.\n+func generateTableCTAS(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\tq := client.Query(\n+\t\tfmt.Sprintf(\n+\t\t\t`CREATE TABLE %s.%s \n+\t\tAS\n+\t\tSELECT\n+\t\t  2000 + CAST(18 * RAND() as INT64) as year,\n+\t\t  IF(RAND() > 0.5,\"foo\",\"bar\") as token\n+\t\tFROM\n+\t\t  UNNEST(GENERATE_ARRAY(0,5,1)) as r`, datasetID, tableID))\n+\tjob, err := q.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\treturn nil\n+}\n+\n+func copyMultiTable(client *bigquery.Client, datasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// Generate some dummy tables via a quick CTAS.\n+\tif err := generateTableCTAS(client, datasetID, \"table1\"); err != nil {\n+\t\treturn err\n+\t}\n+\tif err := generateTableCTAS(client, datasetID, \"table2\"); err != nil {\n+\t\treturn err\n+\t}\n+\t// [START bigquery_copy_table_multiple_source]\n+\tdataset := client.Dataset(datasetID)\n+\n+\tsrcTableIDs := []string{\"table1\", \"table2\"}\n+\tvar tableRefs []*bigquery.Table\n+\tfor _, v := range srcTableIDs {\n+\t\ttableRefs = append(tableRefs, dataset.Table(v))\n+\t}\n+\tcopier := dataset.Table(dstTableID).CopierFrom(tableRefs...)\n+\tcopier.WriteDisposition = bigquery.WriteTruncate\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_copy_table_multiple_source]\n+\treturn nil\n+}\n func deleteTable(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_delete_table]",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -472,6 +703,49 @@\nfunc deleteTable(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n+func deleteAndUndeleteTable(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_undelete_table]\n+\n+\tds := client.Dataset(datasetID)\n+\tif _, err := ds.Table(tableID).Metadata(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\t// Record the current time.  We'll use this as the snapshot time\n+\t// for recovering the table.\n+\tsnapTime := time.Now()\n+\n+\t// \"Accidentally\" delete the table.\n+\tif err := client.Dataset(datasetID).Table(tableID).Delete(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Construct the restore-from tableID using a snapshot decorator.\n+\tsnapshotTableID := fmt.Sprintf(\"%s@%d\", tableID, snapTime.UnixNano()/1e6)\n+\t// Choose a new table ID for the recovered table data.\n+\trecoverTableID := fmt.Sprintf(\"%s_recovered\", tableID)\n+\n+\t// Construct and run a copy job.\n+\tcopier := ds.Table(recoverTableID).CopierFrom(ds.Table(snapshotTableID))\n+\tcopier.WriteDisposition = bigquery.WriteTruncate\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// [END bigquery_undelete_table]\n+\tds.Table(recoverTableID).Delete(ctx)\n+\treturn nil\n+\n+}\n+\n func importCSVFromFile(client *bigquery.Client, datasetID, tableID, filename string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_from_file]",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -122,8 +122,42 @@\nfunc TestAll(t *testing.T) {\n \tif err := browseTable(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"browseTable(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := basicQuery(client, datasetID, inferred); err != nil {\n-\t\tt.Errorf(\"basicQuery(dataset:%q table:%q): %v\", datasetID, inferred, err)\n+\n+\tif err := queryBasic(client); err != nil {\n+\t\tt.Errorf(\"queryBasic: %v\", err)\n+\t}\n+\tbatchTable := fmt.Sprintf(\"golang_example_batchresults_%d\", time.Now().Unix())\n+\tif err := queryBatch(client, datasetID, batchTable); err != nil {\n+\t\tt.Errorf(\"queryBatch(dataset:%q table:%q): %v\", datasetID, batchTable, err)\n+\t}\n+\tif err := queryDisableCache(client); err != nil {\n+\t\tt.Errorf(\"queryBasicDisableCache: %v\", err)\n+\t}\n+\tif err := queryDryRun(client); err != nil {\n+\t\tt.Errorf(\"queryDryRun: %v\", err)\n+\t}\n+\tsql := \"SELECT 17 as foo\"\n+\tif err := queryLegacy(client, sql); err != nil {\n+\t\tt.Errorf(\"queryLegacy: %v\", err)\n+\t}\n+\tlargeResults := fmt.Sprintf(\"golang_example_legacy_largeresults_%d\", time.Now().Unix())\n+\tif err := queryLegacyLargeResults(client, datasetID, largeResults); err != nil {\n+\t\tt.Errorf(\"queryLegacyLargeResults(dataset:%q table:%q): %v\", datasetID, largeResults, err)\n+\t}\n+\tif err := queryWithArrayParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithArrayParams: %v\", err)\n+\t}\n+\tif err := queryWithNamedParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithNamedParams: %v\", err)\n+\t}\n+\tif err := queryWithPositionalParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithPositionalParams: %v\", err)\n+\t}\n+\tif err := queryWithTimestampParam(client); err != nil {\n+\t\tt.Errorf(\"queryWithTimestampParam: %v\", err)\n+\t}\n+\tif err := queryWithStructParam(client); err != nil {\n+\t\tt.Errorf(\"queryWithStructParam: %v\", err)\n \t}\n \n \t// Run query variations",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -132,11 +166,6 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"queryWithDestination(dataset:%q table:%q): %v\", datasetID, persisted, err)\n \t}\n \n-\tsql := \"SELECT 17 as foo\"\n-\tif err := queryLegacy(client, sql); err != nil {\n-\t\tt.Errorf(\"queryLegacy: %v\", err)\n-\t}\n-\n \t// Print information about tables (extended and simple).\n \tif err := printTableInfo(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"printTableInfo(dataset:%q table:%q): %v\", datasetID, inferred, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -28,40 +28,40 @@\ntype Task struct {\n }\n \n func SnippetNewIncompleteKey() {\n-\t// [START incomplete_key]\n+\t// [START datastore_incomplete_key]\n \ttaskKey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [END incomplete_key]\n+\t// [END datastore_incomplete_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey() {\n-\t// [START named_key]\n+\t// [START datastore_named_key]\n \ttaskKey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [END named_key]\n+\t// [END datastore_named_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withParent() {\n-\t// [START key_with_parent]\n+\t// [START datastore_key_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_parent]\n+\t// [END datastore_key_with_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withMultipleParents() {\n-\t// [START key_with_multilevel_parent]\n+\t// [START datastore_key_with_multilevel_parent]\n \tuserKey := datastore.NameKey(\"User\", \"alice\", nil)\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", userKey)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_multilevel_parent]\n+\t// [END datastore_key_with_multilevel_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetClient_Put() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START entity_with_parent]\n+\t// [START datastore_entity_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tkey := datastore.IncompleteKey(\"Task\", parentKey)",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -75,12 +75,12 @@\nfunc SnippetClient_Put() {\n \t// A complete key is assigned to the entity when it is Put.\n \tvar err error\n \tkey, err = client.Put(ctx, key, &task)\n-\t// [END entity_with_parent]\n+\t// [END datastore_entity_with_parent]\n \t_ = err // Make sure you check err.\n }\n \n func Snippet_properties() {\n-\t// [START properties]\n+\t// [START datastore_properties]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -97,12 +97,12 @@\nfunc Snippet_properties() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END properties]\n+\t// [END datastore_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_sliceProperties() {\n-\t// [START array_value]\n+\t// [START datastore_array_value]\n \ttype Task struct {\n \t\tTags          []string\n \t\tCollaborators []string",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -111,12 +111,12 @@\nfunc Snippet_sliceProperties() {\n \t\tTags:          []string{\"fun\", \"programming\"},\n \t\tCollaborators: []string{\"alice\", \"bob\"},\n \t}\n-\t// [END array_value]\n+\t// [END datastore_array_value]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_basicEntity() {\n-\t// [START basic_entity]\n+\t// [START datastore_basic_entity]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -133,7 +133,7 @@\nfunc Snippet_basicEntity() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END basic_entity]\n+\t// [END datastore_basic_entity]\n \t_ = task // Use the task in a datastore Put operation.\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -142,9 +142,9 @@\nfunc SnippetClient_Put_upsert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := &Task{} // Populated with appropriate data.\n \tkey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [START upsert]\n+\t// [START datastore_upsert]\n \tkey, err := client.Put(ctx, key, task)\n-\t// [END upsert]\n+\t// [END datastore_upsert]\n \t_ = err // Make sure you check err.\n \t_ = key // key is the complete key for the newly stored task\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -154,7 +154,7 @@\nfunc SnippetTransaction_insert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := Task{} // Populated with appropriate data.\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START insert]\n+\t// [START datastore_insert]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\t// We first check that there is no entity stored with the given key.\n \t\tvar empty Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -165,26 +165,26 @@\nfunc SnippetTransaction_insert() {\n \t\t_, err := tx.Put(taskKey, &task)\n \t\treturn err\n \t})\n-\t// [END insert]\n+\t// [END datastore_insert]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_Get() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START lookup]\n+\t// [START datastore_lookup]\n \tvar task Task\n \terr := client.Get(ctx, taskKey, &task)\n-\t// [END lookup]\n+\t// [END datastore_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetTransaction_update() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START update]\n+\t// [START datastore_update]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -200,23 +200,23 @@\nfunc SnippetTransaction_update() {\n \tif _, err := tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END update]\n+\t// [END datastore_update]\n }\n \n func SnippetClient_Delete() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START delete]\n+\t// [START datastore_delete]\n \terr := client.Delete(ctx, key)\n-\t// [END delete]\n+\t// [END datastore_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_PutMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START batch_upsert]\n+\t// [START datastore_batch_upsert]\n \ttasks := []*Task{\n \t\t{\n \t\t\tCategory:    \"Personal\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -237,7 +237,7 @@\nfunc SnippetClient_PutMulti() {\n \t}\n \n \tkeys, err := client.PutMulti(ctx, keys, tasks)\n-\t// [END batch_upsert]\n+\t// [END datastore_batch_upsert]\n \t_ = err  // Make sure you check err.\n \t_ = keys // keys now has the complete keys for the newly stored tasks.\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -246,33 +246,33 @@\nfunc SnippetClient_GetMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_lookup]\n+\t// [START datastore_batch_lookup]\n \tvar tasks []*Task\n \terr := client.GetMulti(ctx, taskKeys, &tasks)\n-\t// [END batch_lookup]\n+\t// [END datastore_batch_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_DeleteMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_delete]\n+\t// [START datastore_batch_delete]\n \terr := client.DeleteMulti(ctx, taskKeys)\n-\t// [END batch_delete]\n+\t// [END datastore_batch_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetQuery_basic() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START basic_query]\n+\t// [START datastore_basic_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Priority >=\", 4).\n \t\tOrder(\"-Priority\")\n-\t// [END basic_query]\n-\t// [START run_query]\n+\t// [END datastore_basic_query]\n+\t// [START datastore_run_query]\n \tit := client.Run(ctx, query)\n \tfor {\n \t\tvar task Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -285,75 +285,75 @@\nfunc SnippetQuery_basic() {\n \t\t}\n \t\tfmt.Printf(\"Task %q, Priority %d\\n\", task.Description, task.Priority)\n \t}\n-\t// [END run_query]\n+\t// [END datastore_run_query]\n }\n \n func SnippetQuery_propertyFilter() {\n-\t// [START property_filter]\n+\t// [START datastore_property_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false)\n-\t// [END property_filter]\n+\t// [END datastore_property_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_compositeFilter() {\n-\t// [START composite_filter]\n+\t// [START datastore_composite_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false).Filter(\"Priority =\", 4)\n-\t// [END composite_filter]\n+\t// [END datastore_composite_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_keyFilter() {\n-\t// [START key_filter]\n+\t// [START datastore_key_filter]\n \tkey := datastore.NameKey(\"Task\", \"someTask\", nil)\n \tquery := datastore.NewQuery(\"Task\").Filter(\"__key__ >\", key)\n-\t// [END key_filter]\n+\t// [END datastore_key_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortAscending() {\n-\t// [START ascending_sort]\n+\t// [START datastore_ascending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"created\")\n-\t// [END ascending_sort]\n+\t// [END datastore_ascending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortDescending() {\n-\t// [START descending_sort]\n+\t// [START datastore_descending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-created\")\n-\t// [END descending_sort]\n+\t// [END datastore_descending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortMulti() {\n-\t// [START multi_sort]\n+\t// [START datastore_multi_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-priority\").Order(\"created\")\n-\t// [END multi_sort]\n+\t// [END datastore_multi_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_kindless() {\n \tvar lastSeenKey *datastore.Key\n-\t// [START kindless_query]\n+\t// [START datastore_kindless_query]\n \tquery := datastore.NewQuery(\"\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_query]\n+\t// [END datastore_kindless_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Ancestor() {\n-\t// [START ancestor_query]\n+\t// [START datastore_ancestor_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor)\n-\t// [END ancestor_query]\n+\t// [END datastore_ancestor_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Project() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START projection_query]\n+\t// [START datastore_projection_query]\n \tquery := datastore.NewQuery(\"Task\").Project(\"Priority\", \"PercentComplete\")\n-\t// [END projection_query]\n-\t// [START run_query_projection]\n+\t// [END datastore_projection_query]\n+\t// [START datastore_run_query_projection]\n \tvar priorities []int\n \tvar percents []float64\n \tit := client.Run(ctx, query)",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -367,130 +367,130 @@\nfunc SnippetQuery_Project() {\n \t\tpriorities = append(priorities, task.Priority)\n \t\tpercents = append(percents, task.PercentComplete)\n \t}\n-\t// [END run_query_projection]\n+\t// [END datastore_run_query_projection]\n }\n \n func SnippetQuery_KeysOnly() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START keys_only_query]\n+\t// [START datastore_keys_only_query]\n \tquery := datastore.NewQuery(\"Task\").KeysOnly()\n-\t// [END keys_only_query]\n-\t// [START run_keys_only_query]\n+\t// [END datastore_keys_only_query]\n+\t// [START datastore_run_keys_only_query]\n \tkeys, err := client.GetAll(ctx, query, nil)\n-\t// [END run_keys_only_query]\n+\t// [END datastore_run_keys_only_query]\n \t_ = err  // Make sure you check err.\n \t_ = keys // Keys contains keys for all stored tasks.\n }\n \n func SnippetQuery_Distinct() {\n-\t// [START distinct_query]\n+\t// [START datastore_distinct_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tProject(\"Priority\", \"PercentComplete\").\n \t\tDistinct().\n \t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_query]\n+\t// [END datastore_distinct_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_DistinctOn() {\n-\t// [START distinct_on_query]\n+\t// [START datastore_distinct_on_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tProject(\"Priority\", \"Category\").\n \t\tDistinctOn(\"Category\").\n \t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_on_query]\n+\t// [END datastore_distinct_on_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayInequality() {\n-\t// [START array_value_inequality_range]\n+\t// [START datastore_array_value_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag >\", \"learn\").\n \t\tFilter(\"Tag <\", \"math\")\n-\t// [END array_value_inequality_range]\n+\t// [END datastore_array_value_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayEquality() {\n-\t// [START array_value_equality]\n+\t// [START datastore_array_value_equality]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag =\", \"fun\").\n \t\tFilter(\"Tag =\", \"programming\")\n-\t// [END array_value_equality]\n+\t// [END datastore_array_value_equality]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_inequality() {\n-\t// [START inequality_range]\n+\t// [START datastore_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END inequality_range]\n+\t// [END datastore_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_invalidInequality() {\n-\t// [START inequality_invalid]\n+\t// [START datastore_inequality_invalid]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Priority >\", 3)\n-\t// [END inequality_invalid]\n+\t// [END datastore_inequality_invalid]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Filter_mixed() {\n-\t// [START equal_and_inequality_range]\n+\t// [START datastore_equal_and_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority =\", 4).\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END equal_and_inequality_range]\n+\t// [END datastore_equal_and_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_inequalitySort() {\n-\t// [START inequality_sort]\n+\t// [START datastore_inequality_sort]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Priority\").\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort]\n+\t// [END datastore_inequality_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_invalidInequalitySortA() {\n-\t// [START inequality_sort_invalid_not_same]\n+\t// [START datastore_inequality_sort_invalid_not_same]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort_invalid_not_same]\n+\t// [END datastore_inequality_sort_invalid_not_same]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_invalidInequalitySortB() {\n-\t// [START inequality_sort_invalid_not_first]\n+\t// [START datastore_inequality_sort_invalid_not_first]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\").\n \t\tOrder(\"Priority\")\n-\t// [END inequality_sort_invalid_not_first]\n+\t// [END datastore_inequality_sort_invalid_not_first]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Limit() {\n-\t// [START limit]\n+\t// [START datastore_limit]\n \tquery := datastore.NewQuery(\"Task\").Limit(5)\n-\t// [END limit]\n+\t// [END datastore_limit]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetIterator_Cursor() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tcursorStr := \"\"\n-\t// [START cursor_paging]\n+\t// [START datastore_cursor_paging]\n \tconst pageSize = 5\n \tquery := datastore.NewQuery(\"Tasks\").Limit(pageSize)\n \tif cursorStr != \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -516,42 +516,42 @@\nfunc SnippetIterator_Cursor() {\n \n \t// Get the cursor for the next page of results.\n \tnextCursor, err := it.Cursor()\n-\t// [END cursor_paging]\n+\t// [END datastore_cursor_paging]\n \t_ = err        // Check the error.\n \t_ = nextCursor // Use nextCursor.String as the next page's token.\n }\n \n func SnippetQuery_EventualConsistency() {\n-\t// [START eventual_consistent_query]\n+\t// [START datastore_eventual_consistent_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).EventualConsistency()\n-\t// [END eventual_consistent_query]\n+\t// [END datastore_eventual_consistent_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_unindexed() {\n-\t// [START unindexed_property_query]\n+\t// [START datastore_unindexed_property_query]\n \tquery := datastore.NewQuery(\"Tasks\").Filter(\"Description =\", \"A task description\")\n-\t// [END unindexed_property_query]\n+\t// [END datastore_unindexed_property_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func Snippet_explodingProperties() {\n-\t// [START exploding_properties]\n+\t// [START datastore_exploding_properties]\n \ttask := &Task{\n \t\tTags:          []string{\"fun\", \"programming\", \"learn\"},\n \t\tCollaborators: []string{\"alice\", \"bob\", \"charlie\"},\n \t\tCreated:       time.Now(),\n \t}\n-\t// [END exploding_properties]\n+\t// [END datastore_exploding_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_Transaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_update]\n+\t// [START datastore_transactional_update]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -576,14 +576,14 @@\nfunc Snippet_Transaction() {\n \tif _, err = tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END transactional_update]\n+\t// [END datastore_transactional_update]\n }\n \n func Snippet_Client_RunInTransaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_retry]\n+\t// [START datastore_transactional_retry]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -600,15 +600,15 @@\nfunc Snippet_Client_RunInTransaction() {\n \t\t_, err := tx.PutMulti(keys, accs)\n \t\treturn err\n \t})\n-\t// [END transactional_retry]\n+\t// [END datastore_transactional_retry]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_getOrCreate() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START transactional_get_or_create]\n+\t// [START datastore_transactional_get_or_create]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\tvar task Task\n \t\tif err := tx.Get(key, &task); err != datastore.ErrNoSuchEntity {",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -622,14 +622,14 @@\nfunc SnippetTransaction_getOrCreate() {\n \t\t})\n \t\treturn err\n \t})\n-\t// [END transactional_get_or_create]\n+\t// [END datastore_transactional_get_or_create]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_runQuery() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START transactional_single_entity_group_read_only]\n+\t// [START datastore_transactional_single_entity_group_read_only]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -640,14 +640,14 @@\nfunc SnippetTransaction_runQuery() {\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).Transaction(tx)\n \tvar tasks []Task\n \t_, err = client.GetAll(ctx, query, &tasks)\n-\t// [END transactional_single_entity_group_read_only]\n+\t// [END datastore_transactional_single_entity_group_read_only]\n \t_ = err // Check error.\n }\n \n func Snippet_metadataNamespaces() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START namespace_run_query]\n+\t// [START datastore_namespace_run_query]\n \tconst (\n \t\tstartNamespace = \"g\"\n \t\tendNamespace   = \"h\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -665,13 +665,13 @@\nfunc Snippet_metadataNamespaces() {\n \tfor _, k := range keys {\n \t\tnamespaces = append(namespaces, k.Name)\n \t}\n-\t// [END namespace_run_query]\n+\t// [END datastore_namespace_run_query]\n }\n \n func Snippet_metadataKinds() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START kind_run_query]\n+\t// [START datastore_kind_run_query]\n \tquery := datastore.NewQuery(\"__kind__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -682,13 +682,13 @@\nfunc Snippet_metadataKinds() {\n \tfor _, k := range keys {\n \t\tkinds = append(kinds, k.Name)\n \t}\n-\t// [END kind_run_query]\n+\t// [END datastore_kind_run_query]\n }\n \n func Snippet_metadataProperties() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_run_query]\n+\t// [START datastore_property_run_query]\n \tquery := datastore.NewQuery(\"__property__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -701,13 +701,13 @@\nfunc Snippet_metadataProperties() {\n \t\tkind := k.Parent.Name\n \t\tprops[kind] = append(props[kind], prop)\n \t}\n-\t// [END property_run_query]\n+\t// [END datastore_property_run_query]\n }\n \n func Snippet_metadataPropertiesForKind() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_by_kind_run_query]\n+\t// [START datastore_property_by_kind_run_query]\n \tkindKey := datastore.NameKey(\"__kind__\", \"Task\", nil)\n \tquery := datastore.NewQuery(\"__property__\").Ancestor(kindKey)",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START all]\n+// [START datastore_all]\n \n // A simple command-line task list manager to demonstrate using the\n // cloud.google.com/go/datastore package.",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -29,10 +29,10 @@\nfunc main() {\n \tif projID == \"\" {\n \t\tlog.Fatal(`You need to set the environment variable \"DATASTORE_PROJECT_ID\"`)\n \t}\n-\t// [START build_service]\n+\t// [START datastore_build_service]\n \tctx := context.Background()\n \tclient, err := datastore.NewClient(ctx, projID)\n-\t// [END build_service]\n+\t// [END datastore_build_service]\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create datastore client: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -107,7 +107,7 @@\nfunc main() {\n \t}\n }\n \n-// [START add_entity]\n+// [START datastore_add_entity]\n // Task is the model used to store tasks in the datastore.\n type Task struct {\n \tDesc    string    `datastore:\"description\"`",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -127,9 +127,9 @@\nfunc AddTask(ctx context.Context, client *datastore.Client, desc string) (*datas\n \treturn client.Put(ctx, key, task)\n }\n \n-// [END add_entity]\n+// [END datastore_add_entity]\n \n-// [START update_entity]\n+// [START datastore_update_entity]\n // MarkDone marks the task done with the given ID.\n func MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error {\n \t// Create a key using the given integer ID.",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -148,9 +148,9 @@\nfunc MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error\n \treturn err\n }\n \n-// [END update_entity]\n+// [END datastore_update_entity]\n \n-// [START retrieve_entities]\n+// [START datastore_retrieve_entities]\n // ListTasks returns all the tasks in ascending order of creation time.\n func ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \tvar tasks []*Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -170,17 +170,17 @@\nfunc ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \treturn tasks, nil\n }\n \n-// [END retrieve_entities]\n+// [END datastore_retrieve_entities]\n \n-// [START delete_entity]\n+// [START datastore_delete_entity]\n // DeleteTask deletes the task with the given ID.\n func DeleteTask(ctx context.Context, client *datastore.Client, taskID int64) error {\n \treturn client.Delete(ctx, datastore.IDKey(\"Task\", taskID, nil))\n }\n \n-// [END delete_entity]\n+// [END datastore_delete_entity]\n \n-// [START format_results]\n+// [START datastore_format_results]\n // PrintTasks prints the tasks to the given writer.\n func PrintTasks(w io.Writer, tasks []*Task) {\n \t// Use a tab writer to help make results pretty.",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -196,7 +196,7 @@\nfunc PrintTasks(w io.Writer, tasks []*Task) {\n \ttw.Flush()\n }\n \n-// [END format_results]\n+// [END datastore_format_results]\n \n func usage() {\n \tfmt.Print(`Usage:",
        "comments": [],
        "commit_message": "Merge branch 'master' into auth",
        "commit_id": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "auth/snippets.go",
        "code_diff": "@@ -14,12 +14,14 @@\nimport (\n \t\"golang.org/x/oauth2/google\"\n \tcloudkms \"google.golang.org/api/cloudkms/v1\"\n \t\"google.golang.org/api/iterator\"\n+\t\"google.golang.org/api/option\"\n )\n \n-func adc() {\n-\tctx := context.Background()\n+// [START auth_cloud_implicit]\n \n-\t// [START auth_cloud_implicit]\n+// implicit uses Application Default Credentials to authenticate.\n+func implicit() {\n+\tctx := context.Background()\n \n \t// For API packages whose import path is starting with \"cloud.google.com/go\",\n \t// such as cloud.google.com/go/storage in this case, if there are no credentials",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -305,15 +305,29 @@\nfunc listRows(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n-func basicQuery(client *bigquery.Client, datasetID, tableID string) error {\n+func queryBasic(client *bigquery.Client) error {\n \tctx := context.Background()\n \t// [START bigquery_query]\n+\n \tq := client.Query(\n \t\t\"SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` \" +\n \t\t\t\"WHERE state = \\\"TX\\\" \" +\n \t\t\t\"LIMIT 100\")\n \t// Location must match that of the dataset(s) referenced in the query.\n \tq.Location = \"US\"\n+\t// [END bigquery_query]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryDisableCache(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_no_cache]\n+\n+\tq := client.Query(\n+\t\t\"SELECT corpus FROM `bigquery-public-data.samples.shakespeare` GROUP BY corpus;\")\n+\tq.DisableQueryCache = true\n+\t// Location must match that of the dataset(s) referenced in the query.\n+\tq.Location = \"US\"\n \n \tjob, err := q.Run(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -341,70 +355,227 @@\nfunc basicQuery(client *bigquery.Client, datasetID, tableID string) error {\n \t\t}\n \t\tfmt.Println(row)\n \t}\n-\t// [END bigquery_query]\n+\t// [END bigquery_query_no_cache]\n \treturn nil\n }\n \n-func queryWithDestination(client *bigquery.Client, destDatasetID, destTableID string) error {\n+func queryBatch(client *bigquery.Client, dstDatasetID, dstTableID string) error {\n \tctx := context.Background()\n-\t// [START bigquery_query_destination_table]\n-\tdestRef := client.Dataset(destDatasetID).Table(destTableID)\n-\tq := client.Query(\"SELECT 17 as my_col\")\n-\tq.Location = \"US\" // Location must match the dataset(s) referenced in query.\n-\tq.QueryConfig.Dst = destRef\n-\n-\t// Run job, then wait until asyncronous execution is complete.\n+\t// [START bigquery_query_batch]\n+\t// Build an aggregate table.\n+\tq := client.Query(`\n+\t\tSELECT\n+  \t\t\tcorpus,\n+  \t\t\tSUM(word_count) as total_words,\n+  \t\t\tCOUNT(1) as unique_words\n+\t\tFROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+\t\tGROUP BY corpus;`)\n+\tq.Priority = bigquery.BatchPriority\n+\tq.QueryConfig.Dst = client.Dataset(dstDatasetID).Table(dstTableID)\n+\n+\t// Start the job.\n \tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tstatus, err := job.Wait(ctx)\n+\t// Job is started and will progress without interaction.\n+\t// To simulate other work being done, sleep a few seconds.\n+\ttime.Sleep(5 * time.Second)\n+\tstatus, err := job.Status(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tif err := status.Err(); err != nil {\n-\t\treturn err\n-\t}\n-\t// At this point, the query has completed and results are persisted to the\n-\t// destination table.  You can also choose to read from the table.\n-\tit, err := job.Read(ctx)\n-\tfor {\n-\t\tvar row []bigquery.Value\n-\t\terr := it.Next(&row)\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Println(row)\n+\n+\tstate := \"Unknown\"\n+\tswitch status.State {\n+\tcase bigquery.Pending:\n+\t\tstate = \"Pending\"\n+\tcase bigquery.Running:\n+\t\tstate = \"Running\"\n+\tcase bigquery.Done:\n+\t\tstate = \"Done\"\n \t}\n-\t// [END bigquery_query_destination_table]\n+\t// You can continue to monitor job progress until it reaches\n+\t// the Done state by polling periodically.  In this example,\n+\t// we print the latest status.\n+\tfmt.Printf(\"Job %s in Location %s currently in state: %s\\n\", job.ID(), job.Location(), state)\n+\n+\t// [END bigquery_query_batch]\n+\tjob.Cancel(ctx)\n \treturn nil\n }\n \n-func queryLegacy(client *bigquery.Client, sqlString string) error {\n+func queryDryRun(client *bigquery.Client) error {\n \tctx := context.Background()\n-\t// [START bigquery_query_legacy]\n-\tq := client.Query(sqlString)\n-\tq.UseLegacySQL = true\n+\t// [START bigquery_query_dry_run]\n+\tq := client.Query(`\n+\t\tSELECT \n+\t\t   name,\n+\t\t   COUNT(*) as name_count\n+\t\tFROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n+\t\tWHERE state = 'WA' \n+\t\tGROUP BY name\n+\t\t`)\n+\tq.DryRun = true\n+\t// Location must match that of the dataset(s) referenced in the query.\n+\tq.Location = \"US\"\n \n-\t// Run job, then wait until asyncronous execution is complete.\n \tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tstatus, err := job.Wait(ctx)\n+\t// Dry run is not asynchronous, so get the latest status and statistics.\n+\tstatus := job.LastStatus()\n \tif err != nil {\n \t\treturn err\n \t}\n-\tif err := status.Err(); err != nil {\n-\t\treturn err\n-\t}\n-\t// [END bigquery_query_legacy]\n+\tfmt.Printf(\"This query will process %d bytes\\n\", status.Statistics.TotalBytesProcessed)\n+\n+\t// [END bigquery_query_dry_run]\n \treturn nil\n }\n \n+func queryWithDestination(client *bigquery.Client, destDatasetID, destTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_destination_table]\n+\n+\tq := client.Query(\"SELECT 17 as my_col\")\n+\tq.Location = \"US\" // Location must match the dataset(s) referenced in query.\n+\tq.QueryConfig.Dst = client.Dataset(destDatasetID).Table(destTableID)\n+\t// [END bigquery_query_destination_table]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryLegacy(client *bigquery.Client, sqlString string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_legacy]\n+\tq := client.Query(sqlString)\n+\tq.UseLegacySQL = true\n+\n+\t// [END bigquery_query_legacy]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryLegacyLargeResults(client *bigquery.Client, dstDatasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_legacy_large_results]\n+\tq := client.Query(\n+\t\t\"SELECT corpus FROM [bigquery-public-data:samples.shakespeare] GROUP BY corpus;\")\n+\tq.UseLegacySQL = true\n+\tq.AllowLargeResults = true\n+\tq.QueryConfig.Dst = client.Dataset(dstDatasetID).Table(dstTableID)\n+\t// [END bigquery_query_legacy_large_results]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithArrayParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_arrays]\n+\tq := client.Query(\n+\t\t`SELECT\n+\t\t\tname,\n+\t\t\tsum(number) as count \n+        FROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n+\t\tWHERE\n+\t\t\tgender = @gender\n+        \tAND state IN UNNEST(@states)\n+\t\tGROUP BY\n+\t\t\tname\n+\t\tORDER BY\n+\t\t\tcount DESC\n+\t\tLIMIT 10;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"gender\",\n+\t\t\tValue: \"M\",\n+\t\t},\n+\t\t{\n+\t\t\tName:  \"states\",\n+\t\t\tValue: []string{\"WA\", \"WI\", \"WV\", \"WY\"},\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_arrays]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithNamedParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_named]\n+\tq := client.Query(\n+\t\t`SELECT word, word_count\n+        FROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+        WHERE corpus = @corpus\n+        AND word_count >= @min_word_count\n+        ORDER BY word_count DESC;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"corpus\",\n+\t\t\tValue: \"romeoandjuliet\",\n+\t\t},\n+\t\t{\n+\t\t\tName:  \"min_word_count\",\n+\t\t\tValue: 250,\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_named]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithPositionalParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_positional]\n+\tq := client.Query(\n+\t\t`SELECT word, word_count\n+        FROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+        WHERE corpus = ?\n+        AND word_count >= ?\n+        ORDER BY word_count DESC;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tValue: \"romeoandjuliet\",\n+\t\t},\n+\t\t{\n+\t\t\tValue: 250,\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_positional]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithTimestampParam(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_timestamps]\n+\tq := client.Query(\n+\t\t`SELECT TIMESTAMP_ADD(@ts_value, INTERVAL 1 HOUR);`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"ts_value\",\n+\t\t\tValue: time.Date(2016, 12, 7, 8, 0, 0, 0, time.UTC),\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_timestamps]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithStructParam(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_structs]\n+\ttype MyStruct struct {\n+\t\tX int64\n+\t\tY string\n+\t}\n+\tq := client.Query(\n+\t\t`SELECT @struct_value as s;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"struct_value\",\n+\t\t\tValue: MyStruct{X: 1, Y: \"foo\"},\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_structs]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n func printTableInfo(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_table]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -461,6 +632,66 @@\nfunc copyTable(client *bigquery.Client, datasetID, srcID, dstID string) error {\n \treturn nil\n }\n \n+// generateTableCTAS creates a quick table by issuing a CREATE TABLE AS SELECT\n+// query.\n+func generateTableCTAS(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\tq := client.Query(\n+\t\tfmt.Sprintf(\n+\t\t\t`CREATE TABLE %s.%s \n+\t\tAS\n+\t\tSELECT\n+\t\t  2000 + CAST(18 * RAND() as INT64) as year,\n+\t\t  IF(RAND() > 0.5,\"foo\",\"bar\") as token\n+\t\tFROM\n+\t\t  UNNEST(GENERATE_ARRAY(0,5,1)) as r`, datasetID, tableID))\n+\tjob, err := q.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\treturn nil\n+}\n+\n+func copyMultiTable(client *bigquery.Client, datasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// Generate some dummy tables via a quick CTAS.\n+\tif err := generateTableCTAS(client, datasetID, \"table1\"); err != nil {\n+\t\treturn err\n+\t}\n+\tif err := generateTableCTAS(client, datasetID, \"table2\"); err != nil {\n+\t\treturn err\n+\t}\n+\t// [START bigquery_copy_table_multiple_source]\n+\tdataset := client.Dataset(datasetID)\n+\n+\tsrcTableIDs := []string{\"table1\", \"table2\"}\n+\tvar tableRefs []*bigquery.Table\n+\tfor _, v := range srcTableIDs {\n+\t\ttableRefs = append(tableRefs, dataset.Table(v))\n+\t}\n+\tcopier := dataset.Table(dstTableID).CopierFrom(tableRefs...)\n+\tcopier.WriteDisposition = bigquery.WriteTruncate\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_copy_table_multiple_source]\n+\treturn nil\n+}\n func deleteTable(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_delete_table]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -472,6 +703,49 @@\nfunc deleteTable(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n+func deleteAndUndeleteTable(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_undelete_table]\n+\n+\tds := client.Dataset(datasetID)\n+\tif _, err := ds.Table(tableID).Metadata(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\t// Record the current time.  We'll use this as the snapshot time\n+\t// for recovering the table.\n+\tsnapTime := time.Now()\n+\n+\t// \"Accidentally\" delete the table.\n+\tif err := client.Dataset(datasetID).Table(tableID).Delete(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Construct the restore-from tableID using a snapshot decorator.\n+\tsnapshotTableID := fmt.Sprintf(\"%s@%d\", tableID, snapTime.UnixNano()/1e6)\n+\t// Choose a new table ID for the recovered table data.\n+\trecoverTableID := fmt.Sprintf(\"%s_recovered\", tableID)\n+\n+\t// Construct and run a copy job.\n+\tcopier := ds.Table(recoverTableID).CopierFrom(ds.Table(snapshotTableID))\n+\tcopier.WriteDisposition = bigquery.WriteTruncate\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// [END bigquery_undelete_table]\n+\tds.Table(recoverTableID).Delete(ctx)\n+\treturn nil\n+\n+}\n+\n func importCSVFromFile(client *bigquery.Client, datasetID, tableID, filename string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_from_file]",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -122,8 +122,42 @@\nfunc TestAll(t *testing.T) {\n \tif err := browseTable(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"browseTable(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := basicQuery(client, datasetID, inferred); err != nil {\n-\t\tt.Errorf(\"basicQuery(dataset:%q table:%q): %v\", datasetID, inferred, err)\n+\n+\tif err := queryBasic(client); err != nil {\n+\t\tt.Errorf(\"queryBasic: %v\", err)\n+\t}\n+\tbatchTable := fmt.Sprintf(\"golang_example_batchresults_%d\", time.Now().Unix())\n+\tif err := queryBatch(client, datasetID, batchTable); err != nil {\n+\t\tt.Errorf(\"queryBatch(dataset:%q table:%q): %v\", datasetID, batchTable, err)\n+\t}\n+\tif err := queryDisableCache(client); err != nil {\n+\t\tt.Errorf(\"queryBasicDisableCache: %v\", err)\n+\t}\n+\tif err := queryDryRun(client); err != nil {\n+\t\tt.Errorf(\"queryDryRun: %v\", err)\n+\t}\n+\tsql := \"SELECT 17 as foo\"\n+\tif err := queryLegacy(client, sql); err != nil {\n+\t\tt.Errorf(\"queryLegacy: %v\", err)\n+\t}\n+\tlargeResults := fmt.Sprintf(\"golang_example_legacy_largeresults_%d\", time.Now().Unix())\n+\tif err := queryLegacyLargeResults(client, datasetID, largeResults); err != nil {\n+\t\tt.Errorf(\"queryLegacyLargeResults(dataset:%q table:%q): %v\", datasetID, largeResults, err)\n+\t}\n+\tif err := queryWithArrayParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithArrayParams: %v\", err)\n+\t}\n+\tif err := queryWithNamedParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithNamedParams: %v\", err)\n+\t}\n+\tif err := queryWithPositionalParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithPositionalParams: %v\", err)\n+\t}\n+\tif err := queryWithTimestampParam(client); err != nil {\n+\t\tt.Errorf(\"queryWithTimestampParam: %v\", err)\n+\t}\n+\tif err := queryWithStructParam(client); err != nil {\n+\t\tt.Errorf(\"queryWithStructParam: %v\", err)\n \t}\n \n \t// Run query variations",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -132,11 +166,6 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"queryWithDestination(dataset:%q table:%q): %v\", datasetID, persisted, err)\n \t}\n \n-\tsql := \"SELECT 17 as foo\"\n-\tif err := queryLegacy(client, sql); err != nil {\n-\t\tt.Errorf(\"queryLegacy: %v\", err)\n-\t}\n-\n \t// Print information about tables (extended and simple).\n \tif err := printTableInfo(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"printTableInfo(dataset:%q table:%q): %v\", datasetID, inferred, err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -28,40 +28,40 @@\ntype Task struct {\n }\n \n func SnippetNewIncompleteKey() {\n-\t// [START incomplete_key]\n+\t// [START datastore_incomplete_key]\n \ttaskKey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [END incomplete_key]\n+\t// [END datastore_incomplete_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey() {\n-\t// [START named_key]\n+\t// [START datastore_named_key]\n \ttaskKey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [END named_key]\n+\t// [END datastore_named_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withParent() {\n-\t// [START key_with_parent]\n+\t// [START datastore_key_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_parent]\n+\t// [END datastore_key_with_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withMultipleParents() {\n-\t// [START key_with_multilevel_parent]\n+\t// [START datastore_key_with_multilevel_parent]\n \tuserKey := datastore.NameKey(\"User\", \"alice\", nil)\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", userKey)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_multilevel_parent]\n+\t// [END datastore_key_with_multilevel_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetClient_Put() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START entity_with_parent]\n+\t// [START datastore_entity_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tkey := datastore.IncompleteKey(\"Task\", parentKey)",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -75,12 +75,12 @@\nfunc SnippetClient_Put() {\n \t// A complete key is assigned to the entity when it is Put.\n \tvar err error\n \tkey, err = client.Put(ctx, key, &task)\n-\t// [END entity_with_parent]\n+\t// [END datastore_entity_with_parent]\n \t_ = err // Make sure you check err.\n }\n \n func Snippet_properties() {\n-\t// [START properties]\n+\t// [START datastore_properties]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -97,12 +97,12 @@\nfunc Snippet_properties() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END properties]\n+\t// [END datastore_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_sliceProperties() {\n-\t// [START array_value]\n+\t// [START datastore_array_value]\n \ttype Task struct {\n \t\tTags          []string\n \t\tCollaborators []string",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -111,12 +111,12 @@\nfunc Snippet_sliceProperties() {\n \t\tTags:          []string{\"fun\", \"programming\"},\n \t\tCollaborators: []string{\"alice\", \"bob\"},\n \t}\n-\t// [END array_value]\n+\t// [END datastore_array_value]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_basicEntity() {\n-\t// [START basic_entity]\n+\t// [START datastore_basic_entity]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -133,7 +133,7 @@\nfunc Snippet_basicEntity() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END basic_entity]\n+\t// [END datastore_basic_entity]\n \t_ = task // Use the task in a datastore Put operation.\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -142,9 +142,9 @@\nfunc SnippetClient_Put_upsert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := &Task{} // Populated with appropriate data.\n \tkey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [START upsert]\n+\t// [START datastore_upsert]\n \tkey, err := client.Put(ctx, key, task)\n-\t// [END upsert]\n+\t// [END datastore_upsert]\n \t_ = err // Make sure you check err.\n \t_ = key // key is the complete key for the newly stored task\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -154,7 +154,7 @@\nfunc SnippetTransaction_insert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := Task{} // Populated with appropriate data.\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START insert]\n+\t// [START datastore_insert]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\t// We first check that there is no entity stored with the given key.\n \t\tvar empty Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -165,26 +165,26 @@\nfunc SnippetTransaction_insert() {\n \t\t_, err := tx.Put(taskKey, &task)\n \t\treturn err\n \t})\n-\t// [END insert]\n+\t// [END datastore_insert]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_Get() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START lookup]\n+\t// [START datastore_lookup]\n \tvar task Task\n \terr := client.Get(ctx, taskKey, &task)\n-\t// [END lookup]\n+\t// [END datastore_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetTransaction_update() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START update]\n+\t// [START datastore_update]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -200,23 +200,23 @@\nfunc SnippetTransaction_update() {\n \tif _, err := tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END update]\n+\t// [END datastore_update]\n }\n \n func SnippetClient_Delete() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START delete]\n+\t// [START datastore_delete]\n \terr := client.Delete(ctx, key)\n-\t// [END delete]\n+\t// [END datastore_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_PutMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START batch_upsert]\n+\t// [START datastore_batch_upsert]\n \ttasks := []*Task{\n \t\t{\n \t\t\tCategory:    \"Personal\",",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -237,7 +237,7 @@\nfunc SnippetClient_PutMulti() {\n \t}\n \n \tkeys, err := client.PutMulti(ctx, keys, tasks)\n-\t// [END batch_upsert]\n+\t// [END datastore_batch_upsert]\n \t_ = err  // Make sure you check err.\n \t_ = keys // keys now has the complete keys for the newly stored tasks.\n }",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -246,33 +246,33 @@\nfunc SnippetClient_GetMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_lookup]\n+\t// [START datastore_batch_lookup]\n \tvar tasks []*Task\n \terr := client.GetMulti(ctx, taskKeys, &tasks)\n-\t// [END batch_lookup]\n+\t// [END datastore_batch_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_DeleteMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_delete]\n+\t// [START datastore_batch_delete]\n \terr := client.DeleteMulti(ctx, taskKeys)\n-\t// [END batch_delete]\n+\t// [END datastore_batch_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetQuery_basic() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START basic_query]\n+\t// [START datastore_basic_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Priority >=\", 4).\n \t\tOrder(\"-Priority\")\n-\t// [END basic_query]\n-\t// [START run_query]\n+\t// [END datastore_basic_query]\n+\t// [START datastore_run_query]\n \tit := client.Run(ctx, query)\n \tfor {\n \t\tvar task Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -285,75 +285,75 @@\nfunc SnippetQuery_basic() {\n \t\t}\n \t\tfmt.Printf(\"Task %q, Priority %d\\n\", task.Description, task.Priority)\n \t}\n-\t// [END run_query]\n+\t// [END datastore_run_query]\n }\n \n func SnippetQuery_propertyFilter() {\n-\t// [START property_filter]\n+\t// [START datastore_property_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false)\n-\t// [END property_filter]\n+\t// [END datastore_property_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_compositeFilter() {\n-\t// [START composite_filter]\n+\t// [START datastore_composite_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false).Filter(\"Priority =\", 4)\n-\t// [END composite_filter]\n+\t// [END datastore_composite_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_keyFilter() {\n-\t// [START key_filter]\n+\t// [START datastore_key_filter]\n \tkey := datastore.NameKey(\"Task\", \"someTask\", nil)\n \tquery := datastore.NewQuery(\"Task\").Filter(\"__key__ >\", key)\n-\t// [END key_filter]\n+\t// [END datastore_key_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortAscending() {\n-\t// [START ascending_sort]\n+\t// [START datastore_ascending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"created\")\n-\t// [END ascending_sort]\n+\t// [END datastore_ascending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortDescending() {\n-\t// [START descending_sort]\n+\t// [START datastore_descending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-created\")\n-\t// [END descending_sort]\n+\t// [END datastore_descending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortMulti() {\n-\t// [START multi_sort]\n+\t// [START datastore_multi_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-priority\").Order(\"created\")\n-\t// [END multi_sort]\n+\t// [END datastore_multi_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_kindless() {\n \tvar lastSeenKey *datastore.Key\n-\t// [START kindless_query]\n+\t// [START datastore_kindless_query]\n \tquery := datastore.NewQuery(\"\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_query]\n+\t// [END datastore_kindless_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Ancestor() {\n-\t// [START ancestor_query]\n+\t// [START datastore_ancestor_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor)\n-\t// [END ancestor_query]\n+\t// [END datastore_ancestor_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Project() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START projection_query]\n+\t// [START datastore_projection_query]\n \tquery := datastore.NewQuery(\"Task\").Project(\"Priority\", \"PercentComplete\")\n-\t// [END projection_query]\n-\t// [START run_query_projection]\n+\t// [END datastore_projection_query]\n+\t// [START datastore_run_query_projection]\n \tvar priorities []int\n \tvar percents []float64\n \tit := client.Run(ctx, query)",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -367,130 +367,130 @@\nfunc SnippetQuery_Project() {\n \t\tpriorities = append(priorities, task.Priority)\n \t\tpercents = append(percents, task.PercentComplete)\n \t}\n-\t// [END run_query_projection]\n+\t// [END datastore_run_query_projection]\n }\n \n func SnippetQuery_KeysOnly() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START keys_only_query]\n+\t// [START datastore_keys_only_query]\n \tquery := datastore.NewQuery(\"Task\").KeysOnly()\n-\t// [END keys_only_query]\n-\t// [START run_keys_only_query]\n+\t// [END datastore_keys_only_query]\n+\t// [START datastore_run_keys_only_query]\n \tkeys, err := client.GetAll(ctx, query, nil)\n-\t// [END run_keys_only_query]\n+\t// [END datastore_run_keys_only_query]\n \t_ = err  // Make sure you check err.\n \t_ = keys // Keys contains keys for all stored tasks.\n }\n \n func SnippetQuery_Distinct() {\n-\t// [START distinct_query]\n+\t// [START datastore_distinct_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tProject(\"Priority\", \"PercentComplete\").\n \t\tDistinct().\n \t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_query]\n+\t// [END datastore_distinct_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_DistinctOn() {\n-\t// [START distinct_on_query]\n+\t// [START datastore_distinct_on_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tProject(\"Priority\", \"Category\").\n \t\tDistinctOn(\"Category\").\n \t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_on_query]\n+\t// [END datastore_distinct_on_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayInequality() {\n-\t// [START array_value_inequality_range]\n+\t// [START datastore_array_value_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag >\", \"learn\").\n \t\tFilter(\"Tag <\", \"math\")\n-\t// [END array_value_inequality_range]\n+\t// [END datastore_array_value_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayEquality() {\n-\t// [START array_value_equality]\n+\t// [START datastore_array_value_equality]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag =\", \"fun\").\n \t\tFilter(\"Tag =\", \"programming\")\n-\t// [END array_value_equality]\n+\t// [END datastore_array_value_equality]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_inequality() {\n-\t// [START inequality_range]\n+\t// [START datastore_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END inequality_range]\n+\t// [END datastore_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_invalidInequality() {\n-\t// [START inequality_invalid]\n+\t// [START datastore_inequality_invalid]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Priority >\", 3)\n-\t// [END inequality_invalid]\n+\t// [END datastore_inequality_invalid]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Filter_mixed() {\n-\t// [START equal_and_inequality_range]\n+\t// [START datastore_equal_and_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority =\", 4).\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END equal_and_inequality_range]\n+\t// [END datastore_equal_and_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_inequalitySort() {\n-\t// [START inequality_sort]\n+\t// [START datastore_inequality_sort]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Priority\").\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort]\n+\t// [END datastore_inequality_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_invalidInequalitySortA() {\n-\t// [START inequality_sort_invalid_not_same]\n+\t// [START datastore_inequality_sort_invalid_not_same]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort_invalid_not_same]\n+\t// [END datastore_inequality_sort_invalid_not_same]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_invalidInequalitySortB() {\n-\t// [START inequality_sort_invalid_not_first]\n+\t// [START datastore_inequality_sort_invalid_not_first]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\").\n \t\tOrder(\"Priority\")\n-\t// [END inequality_sort_invalid_not_first]\n+\t// [END datastore_inequality_sort_invalid_not_first]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Limit() {\n-\t// [START limit]\n+\t// [START datastore_limit]\n \tquery := datastore.NewQuery(\"Task\").Limit(5)\n-\t// [END limit]\n+\t// [END datastore_limit]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetIterator_Cursor() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tcursorStr := \"\"\n-\t// [START cursor_paging]\n+\t// [START datastore_cursor_paging]\n \tconst pageSize = 5\n \tquery := datastore.NewQuery(\"Tasks\").Limit(pageSize)\n \tif cursorStr != \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -516,42 +516,42 @@\nfunc SnippetIterator_Cursor() {\n \n \t// Get the cursor for the next page of results.\n \tnextCursor, err := it.Cursor()\n-\t// [END cursor_paging]\n+\t// [END datastore_cursor_paging]\n \t_ = err        // Check the error.\n \t_ = nextCursor // Use nextCursor.String as the next page's token.\n }\n \n func SnippetQuery_EventualConsistency() {\n-\t// [START eventual_consistent_query]\n+\t// [START datastore_eventual_consistent_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).EventualConsistency()\n-\t// [END eventual_consistent_query]\n+\t// [END datastore_eventual_consistent_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_unindexed() {\n-\t// [START unindexed_property_query]\n+\t// [START datastore_unindexed_property_query]\n \tquery := datastore.NewQuery(\"Tasks\").Filter(\"Description =\", \"A task description\")\n-\t// [END unindexed_property_query]\n+\t// [END datastore_unindexed_property_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func Snippet_explodingProperties() {\n-\t// [START exploding_properties]\n+\t// [START datastore_exploding_properties]\n \ttask := &Task{\n \t\tTags:          []string{\"fun\", \"programming\", \"learn\"},\n \t\tCollaborators: []string{\"alice\", \"bob\", \"charlie\"},\n \t\tCreated:       time.Now(),\n \t}\n-\t// [END exploding_properties]\n+\t// [END datastore_exploding_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_Transaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_update]\n+\t// [START datastore_transactional_update]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -576,14 +576,14 @@\nfunc Snippet_Transaction() {\n \tif _, err = tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END transactional_update]\n+\t// [END datastore_transactional_update]\n }\n \n func Snippet_Client_RunInTransaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_retry]\n+\t// [START datastore_transactional_retry]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -600,15 +600,15 @@\nfunc Snippet_Client_RunInTransaction() {\n \t\t_, err := tx.PutMulti(keys, accs)\n \t\treturn err\n \t})\n-\t// [END transactional_retry]\n+\t// [END datastore_transactional_retry]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_getOrCreate() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START transactional_get_or_create]\n+\t// [START datastore_transactional_get_or_create]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\tvar task Task\n \t\tif err := tx.Get(key, &task); err != datastore.ErrNoSuchEntity {",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -622,14 +622,14 @@\nfunc SnippetTransaction_getOrCreate() {\n \t\t})\n \t\treturn err\n \t})\n-\t// [END transactional_get_or_create]\n+\t// [END datastore_transactional_get_or_create]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_runQuery() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START transactional_single_entity_group_read_only]\n+\t// [START datastore_transactional_single_entity_group_read_only]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -640,14 +640,14 @@\nfunc SnippetTransaction_runQuery() {\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).Transaction(tx)\n \tvar tasks []Task\n \t_, err = client.GetAll(ctx, query, &tasks)\n-\t// [END transactional_single_entity_group_read_only]\n+\t// [END datastore_transactional_single_entity_group_read_only]\n \t_ = err // Check error.\n }\n \n func Snippet_metadataNamespaces() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START namespace_run_query]\n+\t// [START datastore_namespace_run_query]\n \tconst (\n \t\tstartNamespace = \"g\"\n \t\tendNamespace   = \"h\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -665,13 +665,13 @@\nfunc Snippet_metadataNamespaces() {\n \tfor _, k := range keys {\n \t\tnamespaces = append(namespaces, k.Name)\n \t}\n-\t// [END namespace_run_query]\n+\t// [END datastore_namespace_run_query]\n }\n \n func Snippet_metadataKinds() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START kind_run_query]\n+\t// [START datastore_kind_run_query]\n \tquery := datastore.NewQuery(\"__kind__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -682,13 +682,13 @@\nfunc Snippet_metadataKinds() {\n \tfor _, k := range keys {\n \t\tkinds = append(kinds, k.Name)\n \t}\n-\t// [END kind_run_query]\n+\t// [END datastore_kind_run_query]\n }\n \n func Snippet_metadataProperties() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_run_query]\n+\t// [START datastore_property_run_query]\n \tquery := datastore.NewQuery(\"__property__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -701,13 +701,13 @@\nfunc Snippet_metadataProperties() {\n \t\tkind := k.Parent.Name\n \t\tprops[kind] = append(props[kind], prop)\n \t}\n-\t// [END property_run_query]\n+\t// [END datastore_property_run_query]\n }\n \n func Snippet_metadataPropertiesForKind() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_by_kind_run_query]\n+\t// [START datastore_property_by_kind_run_query]\n \tkindKey := datastore.NameKey(\"__kind__\", \"Task\", nil)\n \tquery := datastore.NewQuery(\"__property__\").Ancestor(kindKey)",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START all]\n+// [START datastore_all]\n \n // A simple command-line task list manager to demonstrate using the\n // cloud.google.com/go/datastore package.",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -29,10 +29,10 @@\nfunc main() {\n \tif projID == \"\" {\n \t\tlog.Fatal(`You need to set the environment variable \"DATASTORE_PROJECT_ID\"`)\n \t}\n-\t// [START build_service]\n+\t// [START datastore_build_service]\n \tctx := context.Background()\n \tclient, err := datastore.NewClient(ctx, projID)\n-\t// [END build_service]\n+\t// [END datastore_build_service]\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create datastore client: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -107,7 +107,7 @@\nfunc main() {\n \t}\n }\n \n-// [START add_entity]\n+// [START datastore_add_entity]\n // Task is the model used to store tasks in the datastore.\n type Task struct {\n \tDesc    string    `datastore:\"description\"`",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -127,9 +127,9 @@\nfunc AddTask(ctx context.Context, client *datastore.Client, desc string) (*datas\n \treturn client.Put(ctx, key, task)\n }\n \n-// [END add_entity]\n+// [END datastore_add_entity]\n \n-// [START update_entity]\n+// [START datastore_update_entity]\n // MarkDone marks the task done with the given ID.\n func MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error {\n \t// Create a key using the given integer ID.",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -148,9 +148,9 @@\nfunc MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error\n \treturn err\n }\n \n-// [END update_entity]\n+// [END datastore_update_entity]\n \n-// [START retrieve_entities]\n+// [START datastore_retrieve_entities]\n // ListTasks returns all the tasks in ascending order of creation time.\n func ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \tvar tasks []*Task",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -170,17 +170,17 @@\nfunc ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \treturn tasks, nil\n }\n \n-// [END retrieve_entities]\n+// [END datastore_retrieve_entities]\n \n-// [START delete_entity]\n+// [START datastore_delete_entity]\n // DeleteTask deletes the task with the given ID.\n func DeleteTask(ctx context.Context, client *datastore.Client, taskID int64) error {\n \treturn client.Delete(ctx, datastore.IDKey(\"Task\", taskID, nil))\n }\n \n-// [END delete_entity]\n+// [END datastore_delete_entity]\n \n-// [START format_results]\n+// [START datastore_format_results]\n // PrintTasks prints the tasks to the given writer.\n func PrintTasks(w io.Writer, tasks []*Task) {\n \t// Use a tab writer to help make results pretty.",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -196,7 +196,7 @@\nfunc PrintTasks(w io.Writer, tasks []*Task) {\n \ttw.Flush()\n }\n \n-// [END format_results]\n+// [END datastore_format_results]\n \n func usage() {\n \tfmt.Print(`Usage:",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -122,6 +122,7 @@\nfunc writeObject(ctx context.Context, bucket *storage.BucketHandle, fileName, co\n }\n \n func TestInspectGCS(t *testing.T) {\n+\tt.Skip(\"flaky due to timeout\")\n \ttestutil.SystemTest(t)\n \twriteTestGCSFiles(t, projectID)\n \ttests := []struct {",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -182,6 +183,7 @@\nfunc writeTestDatastoreFiles(t *testing.T, projectID string) {\n }\n \n func TestInspectDatastore(t *testing.T) {\n+\tt.Skip(\"flaky due to timeout\")\n \ttestutil.SystemTest(t)\n \twriteTestDatastoreFiles(t, projectID)\n \ttests := []struct {",
        "comments": [],
        "commit_message": "Merge branch 'master' into kurtisvg-patch-1",
        "commit_id": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "translate: Add region tags for Translate samples",
        "pr_number": 492,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -38,6 +38,8 @@\nfunc createClientWithKey() {\n \tfmt.Printf(\"%#v\", resp)\n }\n \n+// [START translate_translate_text]\n+\n func translateText(targetLanguage, text string) (string, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "translate: add region tags",
        "commit_id": "922fe1ef4e1a9ae64844c71bebf53c70af6cf10f"
    },
    {
        "pr_title": "translate: Add region tags for Translate samples",
        "pr_number": 492,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -59,6 +61,9 @@\nfunc translateText(targetLanguage, text string) (string, error) {\n \treturn resp[0].Text, nil\n }\n \n+// [END translate_translate_text]\n+// [START translate_detect_language]\n+\n func detectLanguage(text string) (*translate.Detection, error) {\n \tctx := context.Background()\n \tclient, err := translate.NewClient(ctx)",
        "comments": [],
        "commit_message": "translate: add region tags",
        "commit_id": "922fe1ef4e1a9ae64844c71bebf53c70af6cf10f"
    },
    {
        "pr_title": "translate: Add region tags for Translate samples",
        "pr_number": 492,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -74,6 +79,10 @@\nfunc detectLanguage(text string) (*translate.Detection, error) {\n \treturn &lang[0][0], nil\n }\n \n+// [END translate_detect_language]\n+// [START translate_list_codes]\n+// [START translate_list_language_names]\n+\n func listSupportedLanguages(w io.Writer, targetLanguage string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "translate: add region tags",
        "commit_id": "922fe1ef4e1a9ae64844c71bebf53c70af6cf10f"
    },
    {
        "pr_title": "translate: Add region tags for Translate samples",
        "pr_number": 492,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -100,6 +109,11 @@\nfunc listSupportedLanguages(w io.Writer, targetLanguage string) error {\n \treturn nil\n }\n \n+// [END translate_list_language_names]\n+// [END translate_list_codes]\n+\n+// [START translate_text_with_model]\n+\n func translateTextWithModel(targetLanguage, text, model string) (string, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "translate: add region tags",
        "commit_id": "922fe1ef4e1a9ae64844c71bebf53c70af6cf10f"
    },
    {
        "pr_title": "BigQuery:  more snippets",
        "pr_number": 476,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -116,7 +116,7 @@\nfunc listDatasets(client *bigquery.Client) error {\n \treturn nil\n }\n \n-func printDatasetSimple(client *bigquery.Client, datasetID string) error {\n+func printDatasetInfo(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_dataset]\n \tmeta, err := client.Dataset(datasetID).Metadata(ctx)",
        "comments": [
            {
                "comment": "Delete this newline.",
                "position": null
            },
            {
                "comment": "Delete this newline.",
                "position": null
            },
            {
                "comment": "Delete this newline.",
                "position": null
            },
            {
                "comment": "Nit: Add a period at the end.",
                "position": null
            },
            {
                "comment": "Sorry, maybe this should be something like printCoreDatasetInfo or printDatasetInfo, to avoid using \"simple\"?",
                "position": null
            }
        ],
        "commit_message": "rename methods for printing table and dataset metadata information.",
        "commit_id": "badab496b6d78c5b1296af6aa014b562b316c0c0"
    },
    {
        "pr_title": "BigQuery:  more snippets",
        "pr_number": 476,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -108,8 +108,8 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"want table list %q to contain table %q\", got, empty)\n \t}\n \n-\tif err := printDatasetSimple(client, datasetID); err != nil {\n-\t\tt.Errorf(\"printDatasetSimple: %v\", err)\n+\tif err := printDatasetInfo(client, datasetID); err != nil {\n+\t\tt.Errorf(\"printDatasetInfo: %v\", err)\n \t}\n \n \t// Stream data, read, query the inferred schema table.",
        "comments": [
            {
                "comment": "Nit: make this a complete sentence.",
                "position": null
            },
            {
                "comment": "Is there an error to check from this?",
                "position": null
            },
            {
                "comment": "Not sure this comment is needed? If so, please add a period at the end. Same with \"Run query variations.\"",
                "position": null
            },
            {
                "comment": "Moving this to a defer after dataset creation to make it clearer this isn't behavior under test, but test cleanup.",
                "position": null
            }
        ],
        "commit_message": "rename methods for printing table and dataset metadata information.",
        "commit_id": "badab496b6d78c5b1296af6aa014b562b316c0c0"
    },
    {
        "pr_title": "Add more Go samples for BigQuery:",
        "pr_number": 469,
        "file_name": "getting-started/bookshelf/app/app_test.go",
        "code_diff": "@@ -81,7 +81,6 @@\nfunc TestEditBook(t *testing.T) {\n \tm := multipart.NewWriter(&body)\n \tm.WriteField(\"title\", \"simpsons\")\n \tm.WriteField(\"author\", \"homer\")\n-\tm.CreateFormFile(\"image\", \"\")\n \tm.Close()\n \n \tresp, err := wt.Post(bookPath, \"multipart/form-data; boundary=\"+m.Boundary(), &body)",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipsnipsnip",
        "commit_id": "45ffa09ac36bc8d1e9c2853df9d7c2d3826295d7"
    },
    {
        "pr_title": "Add more Go samples for BigQuery:",
        "pr_number": 469,
        "file_name": "getting-started/bookshelf/app/app_test.go",
        "code_diff": "@@ -109,7 +108,6 @@\nfunc TestAddAndDelete(t *testing.T) {\n \tm := multipart.NewWriter(&body)\n \tm.WriteField(\"title\", \"simpsons\")\n \tm.WriteField(\"author\", \"homer\")\n-\tm.CreateFormFile(\"image\", \"\")\n \tm.Close()\n \n \tresp, err := wt.Post(bookPath, \"multipart/form-data; boundary=\"+m.Boundary(), &body)",
        "comments": [],
        "commit_message": "Merge branch 'master' into snipsnipsnip",
        "commit_id": "45ffa09ac36bc8d1e9c2853df9d7c2d3826295d7"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -9,6 +9,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"os\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/bigquery\"\n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -25,6 +26,78 @@\nfunc createDataset(client *bigquery.Client, datasetID string) error {\n \treturn nil\n }\n \n+func updateDatasetDescription(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_dataset_description]\n+\tds := client.Dataset(datasetID)\n+\toriginal, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tchanges := bigquery.DatasetMetadataToUpdate{\n+\t\tDescription: \"Updated Description.\",\n+\t}\n+\tif _, err = ds.Update(ctx, changes, original.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_dataset_description]\n+\treturn nil\n+}\n+\n+func updateDatasetDefaultExpiration(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_dataset_expiration]\n+\tds := client.Dataset(datasetID)\n+\toriginal, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tchanges := bigquery.DatasetMetadataToUpdate{\n+\t\tDefaultTableExpiration: 24 * time.Hour,\n+\t}\n+\tif _, err := client.Dataset(datasetID).Update(ctx, changes, original.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_dataset_expiration]\n+\treturn nil\n+}\n+\n+func updateDatasetAccessControl(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_dataset_access]\n+\tds := client.Dataset(datasetID)\n+\toriginal, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Append a new access control entry to the existing access list\n+\tchanges := bigquery.DatasetMetadataToUpdate{\n+\t\tAccess: append(original.Access, &bigquery.AccessEntry{\n+\t\t\tRole:       bigquery.ReaderRole,\n+\t\t\tEntityType: bigquery.UserEmailEntity,\n+\t\t\tEntity:     \"sample.bigquery.dev@gmail.com\"},\n+\t\t),\n+\t}\n+\n+\t// Leverage the ETag for the update to assert there's been no modifications to the\n+\t// dataset since the metadata was originally read.\n+\tif _, err := ds.Update(ctx, changes, original.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_dataset_access]\n+\treturn nil\n+}\n+\n+func deleteEmptyDataset(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_delete_dataset]\n+\tif err := client.Dataset(datasetID).Delete(ctx); err != nil {\n+\t\treturn fmt.Errorf(\"Failed to delete dataset: %v\", err)\n+\t}\n+\t// [END bigquery_delete_dataset]\n+\treturn nil\n+}\n+\n func listDatasets(client *bigquery.Client) error {\n \tctx := context.Background()\n \t// [START bigquery_list_datasets]",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -306,7 +379,7 @@\nfunc exportToGCS(client *bigquery.Client, datasetID, tableID, gcsURI string) err\n \treturn nil\n }\n \n-func importJsonExplicitSchema(client *bigquery.Client, datasetID, tableID string) error {\n+func importJSONExplicitSchema(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_table_gcs_json]\n \tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.json\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -42,47 +42,68 @@\nfunc TestAll(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\n \tdatasetID := fmt.Sprintf(\"golang_example_dataset_%d\", time.Now().Unix())\n \tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"failed to create dataset: %v\", err)\n+\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n+\t}\n+\n+\tif err := updateDatasetAccessControl(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDataSetAccessControl(%q): %v\", datasetID, err)\n+\t}\n+\n+\t// test empty dataset creation/ttl/delete\n+\tdeletionDatasetID := fmt.Sprintf(\"%s_quickdelete\", datasetID)\n+\tif err := createDataset(client, deletionDatasetID); err != nil {\n+\t\tt.Errorf(\"createDataset(%q): %v\", deletionDatasetID, err)\n+\t}\n+\tif err = updateDatasetDefaultExpiration(client, deletionDatasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetDefaultExpiration(%q): %v\", deletionDatasetID, err)\n+\t}\n+\tif err := deleteEmptyDataset(client, deletionDatasetID); err != nil {\n+\t\tt.Errorf(\"deleteEmptyDataset(%q): %v\", deletionDatasetID, err)\n+\t}\n+\n+\tif err := updateDatasetDescription(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetDescription(%q): %v\", datasetID, err)\n \t}\n \tif err := listDatasets(client); err != nil {\n-\t\tt.Errorf(\"failed to create dataset: %v\", err)\n+\t\tt.Errorf(\"listDatasets: %v\", err)\n \t}\n \n \ttableID := fmt.Sprintf(\"golang_example_table_%d\", time.Now().Unix())\n \tif err := createTable(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"failed to create table: %v\", err)\n+\t\tt.Errorf(\"createTable(dataset:%q  table:%q): %v\", datasetID, tableID, err)\n \t}\n \tbuf := &bytes.Buffer{}\n \tif err := listTables(client, buf, datasetID); err != nil {\n-\t\tt.Errorf(\"failed to list tables: %v\", err)\n+\t\tt.Errorf(\"listTables(%q): %v\", datasetID, err)\n \t}\n \tif got := buf.String(); !strings.Contains(got, tableID) {\n \t\tt.Errorf(\"want table list %q to contain table %q\", got, tableID)\n \t}\n \tif err := insertRows(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"failed to insert rows: %v\", err)\n+\t\tt.Errorf(\"insertRows(dataset:%q table:%q): %v\", datasetID, tableID, err)\n \t}\n \tif err := listRows(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"failed to list rows: %v\", err)\n+\t\tt.Errorf(\"listRows(dataset:%q table:%q): %v\", datasetID, tableID, err)\n \t}\n \tif err := browseTable(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"failed to list rows: %v\", err)\n+\t\tt.Errorf(\"browseTable(dataset:%q table:%q): %v\", datasetID, tableID, err)\n \t}\n \tif err := asyncQuery(client, datasetID, tableID); err != nil {\n \t\tt.Errorf(\"failed to async query: %v\", err)\n \t}\n \n \tdstTableID := fmt.Sprintf(\"golang_example_tabledst_%d\", time.Now().Unix())\n \tif err := copyTable(client, datasetID, tableID, dstTableID); err != nil {\n-\t\tt.Errorf(\"failed to copy table: %v\", err)\n+\t\tt.Errorf(\"failed to copy table (dataset:%q src:%q dst:%q): %v\", datasetID, tableID, dstTableID, err)\n \t}\n \tif err := deleteTable(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"failed to delete table: %v\", err)\n+\t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, tableID, err)\n \t}\n \tif err := deleteTable(client, datasetID, dstTableID); err != nil {\n-\t\tt.Errorf(\"failed to delete table: %v\", err)\n+\t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n \t}\n \n \tdeleteDataset(t, ctx, datasetID)",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -9,6 +9,7 @@\nimport (\n \t\"io\"\n \t\"log\"\n \t\"strings\"\n+\t\"time\"\n \n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -115,6 +116,7 @@\nfunc riskNumerical(w io.Writer, client *dlp.Client, project, dataProject, pubSub\n \t\t\treturn\n \t\t}\n \t\tmsg.Ack()\n+\t\ttime.Sleep(500 * time.Millisecond)\n \t\tresp, err := client.GetDlpJob(ctx, &dlppb.GetDlpJobRequest{\n \t\t\tName: j.GetName(),\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -212,6 +214,7 @@\nfunc riskCategorical(w io.Writer, client *dlp.Client, project, dataProject, pubS\n \t\t\treturn\n \t\t}\n \t\tmsg.Ack()\n+\t\ttime.Sleep(500 * time.Millisecond)\n \t\tresp, err := client.GetDlpJob(ctx, &dlppb.GetDlpJobRequest{\n \t\t\tName: j.GetName(),\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -314,6 +317,7 @@\nfunc riskKAnonymity(w io.Writer, client *dlp.Client, project, dataProject, pubSu\n \t\t\treturn\n \t\t}\n \t\tmsg.Ack()\n+\t\ttime.Sleep(500 * time.Millisecond)\n \t\tj, err := client.GetDlpJob(ctx, &dlppb.GetDlpJobRequest{\n \t\t\tName: j.GetName(),\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -423,6 +427,7 @@\nfunc riskLDiversity(w io.Writer, client *dlp.Client, project, dataProject, pubSu\n \t\t\treturn\n \t\t}\n \t\tmsg.Ack()\n+\t\ttime.Sleep(500 * time.Millisecond)\n \t\tj, err := client.GetDlpJob(ctx, &dlppb.GetDlpJobRequest{\n \t\t\tName: j.GetName(),\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -78,7 +78,7 @@\nfunc main() {\n \t}\n \n \t// delete the bucket\n-\tif err := delete(client, name); err != nil {\n+\tif err := deleteBucket(client, name); err != nil {\n \t\tlog.Fatal(err)\n \t}\n \tfmt.Printf(\"deleted bucket: %v\\n\", name)",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -5,7 +5,6 @@\npackage main\n \n import (\n-\t\"fmt\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -15,42 +14,45 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n-var bucketName = fmt.Sprintf(\"golang-example-buckets-%d\", time.Now().Unix())\n+var (\n+\tstorageClient *storage.Client\n+\tbucketName    string\n+)\n \n-func setup(t *testing.T) *storage.Client {\n+func TestCreate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tclient, err := storage.NewClient(ctx)\n+\tvar err error\n+\tstorageClient, err = storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n-\treturn client\n-}\n \n-func TestCreate(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n-\tif err := create(c, tc.ProjectID, bucketName); err != nil {\n+\tbucketName = tc.ProjectID + \"-storage-buckets-tests\"\n+\t// Clean up bucket before running tests.\n+\tdeleteBucket(storageClient, bucketName)\n+\tif err := create(storageClient, tc.ProjectID, bucketName); err != nil {\n \t\tt.Fatalf(\"failed to create bucket (%q): %v\", bucketName, err)\n \t}\n }\n \n func TestCreateWithAttrs(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n \tname := bucketName + \"-attrs\"\n-\tif err := createWithAttrs(c, tc.ProjectID, name); err != nil {\n-\t\tt.Fatalf(\"failed to create bucket (%q): %v\", bucketName, err)\n+\t// Clean up bucket before running test.\n+\tdeleteBucket(storageClient, name)\n+\tif err := createWithAttrs(storageClient, tc.ProjectID, name); err != nil {\n+\t\tt.Fatalf(\"failed to create bucket (%q): %v\", name, err)\n \t}\n-\tif err := delete(c, name); err != nil {\n-\t\tt.Fatalf(\"failed to delete bucket (%q): %v\", bucketName, err)\n+\tif err := deleteBucket(storageClient, name); err != nil {\n+\t\tt.Fatalf(\"failed to delete bucket (%q): %v\", name, err)\n \t}\n }\n \n func TestList(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n-\tbuckets, err := list(c, tc.ProjectID)\n+\tbuckets, err := list(storageClient, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into addChangeLogSample",
        "commit_id": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "storage/buckets: use ProjectID for test buckets",
        "pr_number": 457,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -41,7 +41,7 @@\nfunc TestCreateWithAttrs(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tname := bucketName + \"-attrs\"\n \t// Clean up bucket before running test.\n-\tdeleteBucket(storageClient, bucketName+\"-attrs\")\n+\tdeleteBucket(storageClient, name)\n \tif err := createWithAttrs(storageClient, tc.ProjectID, name); err != nil {\n \t\tt.Fatalf(\"failed to create bucket (%q): %v\", name, err)\n \t}",
        "comments": [
            {
                "comment": "delete is a built-in function, can we find a better name?\r\n\r\noh, is this the name of the function in the same? :/",
                "position": null
            },
            {
                "comment": "i think this cleanup can be moved into TestCreate, removing the need for TestMain?",
                "position": null
            },
            {
                "comment": "s/c/storageClient/\r\n\r\nVariables names should approximately scale with the scope they're used in",
                "position": null
            },
            {
                "comment": "this might conflict with some other storage tests. \"-storage-buckets-tests\" maybe?\r\n\r\nnot sure if that ends up being too long (there's a limit on bucket name length)",
                "position": null
            },
            {
                "comment": "Changed to `deleteBucket`. Sample*? Yes.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "storage/buckets: call SystemTest in all tests",
        "commit_id": "b459d675cb467596926bb1c8f62f99a93341a670"
    },
    {
        "pr_title": "storage/buckets: use ProjectID for test buckets",
        "pr_number": 457,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -73,6 +73,7 @@\nouter:\n }\n \n func TestIAM(t *testing.T) {\n+\ttestutil.SystemTest(t)\n \tif _, err := getPolicy(storageClient, bucketName); err != nil {\n \t\tt.Errorf(\"getPolicy: %#v\", err)\n \t}",
        "comments": [
            {
                "comment": "delete is a built-in function, can we find a better name?\r\n\r\noh, is this the name of the function in the same? :/",
                "position": null
            },
            {
                "comment": "i think this cleanup can be moved into TestCreate, removing the need for TestMain?",
                "position": null
            },
            {
                "comment": "s/c/storageClient/\r\n\r\nVariables names should approximately scale with the scope they're used in",
                "position": null
            },
            {
                "comment": "this might conflict with some other storage tests. \"-storage-buckets-tests\" maybe?\r\n\r\nnot sure if that ends up being too long (there's a limit on bucket name length)",
                "position": null
            },
            {
                "comment": "Changed to `deleteBucket`. Sample*? Yes.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "storage/buckets: call SystemTest in all tests",
        "commit_id": "b459d675cb467596926bb1c8f62f99a93341a670"
    },
    {
        "pr_title": "storage/buckets: use ProjectID for test buckets",
        "pr_number": 457,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -85,6 +86,7 @@\nfunc TestIAM(t *testing.T) {\n }\n \n func TestRequesterPays(t *testing.T) {\n+\ttestutil.SystemTest(t)\n \tif err := enableRequesterPays(storageClient, bucketName); err != nil {\n \t\tt.Errorf(\"enableRequesterPay: %#v\", err)\n \t}",
        "comments": [
            {
                "comment": "delete is a built-in function, can we find a better name?\r\n\r\noh, is this the name of the function in the same? :/",
                "position": null
            },
            {
                "comment": "i think this cleanup can be moved into TestCreate, removing the need for TestMain?",
                "position": null
            },
            {
                "comment": "s/c/storageClient/\r\n\r\nVariables names should approximately scale with the scope they're used in",
                "position": null
            },
            {
                "comment": "this might conflict with some other storage tests. \"-storage-buckets-tests\" maybe?\r\n\r\nnot sure if that ends up being too long (there's a limit on bucket name length)",
                "position": null
            },
            {
                "comment": "Changed to `deleteBucket`. Sample*? Yes.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "storage/buckets: call SystemTest in all tests",
        "commit_id": "b459d675cb467596926bb1c8f62f99a93341a670"
    },
    {
        "pr_title": "Add three new BigQuery snippets, and address minor nits.",
        "pr_number": 449,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -78,7 +78,7 @@\nfunc main() {\n \t}\n \n \t// delete the bucket\n-\tif err := delete(client, name); err != nil {\n+\tif err := deleteBucket(client, name); err != nil {\n \t\tlog.Fatal(err)\n \t}\n \tfmt.Printf(\"deleted bucket: %v\\n\", name)",
        "comments": [],
        "commit_message": "Merge branch 'master' into moarsnippets",
        "commit_id": "8f5beae5bb9890974d57b6878e8b5a57f81661c4"
    },
    {
        "pr_title": "Add three new BigQuery snippets, and address minor nits.",
        "pr_number": 449,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -5,7 +5,6 @@\npackage main\n \n import (\n-\t\"fmt\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into moarsnippets",
        "commit_id": "8f5beae5bb9890974d57b6878e8b5a57f81661c4"
    },
    {
        "pr_title": "Add three new BigQuery snippets, and address minor nits.",
        "pr_number": 449,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -15,42 +14,45 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n-var bucketName = fmt.Sprintf(\"golang-example-buckets-%d\", time.Now().Unix())\n+var (\n+\tstorageClient *storage.Client\n+\tbucketName    string\n+)\n \n-func setup(t *testing.T) *storage.Client {\n+func TestCreate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tclient, err := storage.NewClient(ctx)\n+\tvar err error\n+\tstorageClient, err = storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n-\treturn client\n-}\n \n-func TestCreate(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n-\tif err := create(c, tc.ProjectID, bucketName); err != nil {\n+\tbucketName = tc.ProjectID + \"-storage-buckets-tests\"\n+\t// Clean up bucket before running tests.\n+\tdeleteBucket(storageClient, bucketName)\n+\tif err := create(storageClient, tc.ProjectID, bucketName); err != nil {\n \t\tt.Fatalf(\"failed to create bucket (%q): %v\", bucketName, err)\n \t}\n }\n \n func TestCreateWithAttrs(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n \tname := bucketName + \"-attrs\"\n-\tif err := createWithAttrs(c, tc.ProjectID, name); err != nil {\n-\t\tt.Fatalf(\"failed to create bucket (%q): %v\", bucketName, err)\n+\t// Clean up bucket before running test.\n+\tdeleteBucket(storageClient, name)\n+\tif err := createWithAttrs(storageClient, tc.ProjectID, name); err != nil {\n+\t\tt.Fatalf(\"failed to create bucket (%q): %v\", name, err)\n \t}\n-\tif err := delete(c, name); err != nil {\n-\t\tt.Fatalf(\"failed to delete bucket (%q): %v\", bucketName, err)\n+\tif err := deleteBucket(storageClient, name); err != nil {\n+\t\tt.Fatalf(\"failed to delete bucket (%q): %v\", name, err)\n \t}\n }\n \n func TestList(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n-\tbuckets, err := list(c, tc.ProjectID)\n+\tbuckets, err := list(storageClient, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into moarsnippets",
        "commit_id": "8f5beae5bb9890974d57b6878e8b5a57f81661c4"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -9,6 +9,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"os\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/bigquery\"\n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -25,6 +26,78 @@\nfunc createDataset(client *bigquery.Client, datasetID string) error {\n \treturn nil\n }\n \n+func updateDatasetDescription(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_dataset_description]\n+\tds := client.Dataset(datasetID)\n+\toriginal, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tchanges := bigquery.DatasetMetadataToUpdate{\n+\t\tDescription: \"Updated Description.\",\n+\t}\n+\tif _, err = ds.Update(ctx, changes, original.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_dataset_description]\n+\treturn nil\n+}\n+\n+func updateDatasetDefaultExpiration(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_dataset_expiration]\n+\tds := client.Dataset(datasetID)\n+\toriginal, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tchanges := bigquery.DatasetMetadataToUpdate{\n+\t\tDefaultTableExpiration: 24 * time.Hour,\n+\t}\n+\tif _, err := client.Dataset(datasetID).Update(ctx, changes, original.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_dataset_expiration]\n+\treturn nil\n+}\n+\n+func updateDatasetAccessControl(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_dataset_access]\n+\tds := client.Dataset(datasetID)\n+\toriginal, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Append a new access control entry to the existing access list\n+\tchanges := bigquery.DatasetMetadataToUpdate{\n+\t\tAccess: append(original.Access, &bigquery.AccessEntry{\n+\t\t\tRole:       bigquery.ReaderRole,\n+\t\t\tEntityType: bigquery.UserEmailEntity,\n+\t\t\tEntity:     \"sample.bigquery.dev@gmail.com\"},\n+\t\t),\n+\t}\n+\n+\t// Leverage the ETag for the update to assert there's been no modifications to the\n+\t// dataset since the metadata was originally read.\n+\tif _, err := ds.Update(ctx, changes, original.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_dataset_access]\n+\treturn nil\n+}\n+\n+func deleteEmptyDataset(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_delete_dataset]\n+\tif err := client.Dataset(datasetID).Delete(ctx); err != nil {\n+\t\treturn fmt.Errorf(\"Failed to delete dataset: %v\", err)\n+\t}\n+\t// [END bigquery_delete_dataset]\n+\treturn nil\n+}\n+\n func listDatasets(client *bigquery.Client) error {\n \tctx := context.Background()\n \t// [START bigquery_list_datasets]",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -306,7 +379,7 @@\nfunc exportToGCS(client *bigquery.Client, datasetID, tableID, gcsURI string) err\n \treturn nil\n }\n \n-func importJsonExplicitSchema(client *bigquery.Client, datasetID, tableID string) error {\n+func importJSONExplicitSchema(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_table_gcs_json]\n \tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.json\")",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -42,47 +42,68 @@\nfunc TestAll(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\n \tdatasetID := fmt.Sprintf(\"golang_example_dataset_%d\", time.Now().Unix())\n \tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"failed to create dataset: %v\", err)\n+\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n+\t}\n+\n+\tif err := updateDatasetAccessControl(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDataSetAccessControl(%q): %v\", datasetID, err)\n+\t}\n+\n+\t// test empty dataset creation/ttl/delete\n+\tdeletionDatasetID := fmt.Sprintf(\"%s_quickdelete\", datasetID)\n+\tif err := createDataset(client, deletionDatasetID); err != nil {\n+\t\tt.Errorf(\"createDataset(%q): %v\", deletionDatasetID, err)\n+\t}\n+\tif err = updateDatasetDefaultExpiration(client, deletionDatasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetDefaultExpiration(%q): %v\", deletionDatasetID, err)\n+\t}\n+\tif err := deleteEmptyDataset(client, deletionDatasetID); err != nil {\n+\t\tt.Errorf(\"deleteEmptyDataset(%q): %v\", deletionDatasetID, err)\n+\t}\n+\n+\tif err := updateDatasetDescription(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetDescription(%q): %v\", datasetID, err)\n \t}\n \tif err := listDatasets(client); err != nil {\n-\t\tt.Errorf(\"failed to create dataset: %v\", err)\n+\t\tt.Errorf(\"listDatasets: %v\", err)\n \t}\n \n \ttableID := fmt.Sprintf(\"golang_example_table_%d\", time.Now().Unix())\n \tif err := createTable(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"failed to create table: %v\", err)\n+\t\tt.Errorf(\"createTable(dataset:%q  table:%q): %v\", datasetID, tableID, err)\n \t}\n \tbuf := &bytes.Buffer{}\n \tif err := listTables(client, buf, datasetID); err != nil {\n-\t\tt.Errorf(\"failed to list tables: %v\", err)\n+\t\tt.Errorf(\"listTables(%q): %v\", datasetID, err)\n \t}\n \tif got := buf.String(); !strings.Contains(got, tableID) {\n \t\tt.Errorf(\"want table list %q to contain table %q\", got, tableID)\n \t}\n \tif err := insertRows(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"failed to insert rows: %v\", err)\n+\t\tt.Errorf(\"insertRows(dataset:%q table:%q): %v\", datasetID, tableID, err)\n \t}\n \tif err := listRows(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"failed to list rows: %v\", err)\n+\t\tt.Errorf(\"listRows(dataset:%q table:%q): %v\", datasetID, tableID, err)\n \t}\n \tif err := browseTable(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"failed to list rows: %v\", err)\n+\t\tt.Errorf(\"browseTable(dataset:%q table:%q): %v\", datasetID, tableID, err)\n \t}\n \tif err := asyncQuery(client, datasetID, tableID); err != nil {\n \t\tt.Errorf(\"failed to async query: %v\", err)\n \t}\n \n \tdstTableID := fmt.Sprintf(\"golang_example_tabledst_%d\", time.Now().Unix())\n \tif err := copyTable(client, datasetID, tableID, dstTableID); err != nil {\n-\t\tt.Errorf(\"failed to copy table: %v\", err)\n+\t\tt.Errorf(\"failed to copy table (dataset:%q src:%q dst:%q): %v\", datasetID, tableID, dstTableID, err)\n \t}\n \tif err := deleteTable(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"failed to delete table: %v\", err)\n+\t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, tableID, err)\n \t}\n \tif err := deleteTable(client, datasetID, dstTableID); err != nil {\n-\t\tt.Errorf(\"failed to delete table: %v\", err)\n+\t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n \t}\n \n \tdeleteDataset(t, ctx, datasetID)",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -9,6 +9,7 @@\nimport (\n \t\"io\"\n \t\"log\"\n \t\"strings\"\n+\t\"time\"\n \n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -115,6 +116,7 @@\nfunc riskNumerical(w io.Writer, client *dlp.Client, project, dataProject, pubSub\n \t\t\treturn\n \t\t}\n \t\tmsg.Ack()\n+\t\ttime.Sleep(500 * time.Millisecond)\n \t\tresp, err := client.GetDlpJob(ctx, &dlppb.GetDlpJobRequest{\n \t\t\tName: j.GetName(),\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -212,6 +214,7 @@\nfunc riskCategorical(w io.Writer, client *dlp.Client, project, dataProject, pubS\n \t\t\treturn\n \t\t}\n \t\tmsg.Ack()\n+\t\ttime.Sleep(500 * time.Millisecond)\n \t\tresp, err := client.GetDlpJob(ctx, &dlppb.GetDlpJobRequest{\n \t\t\tName: j.GetName(),\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -314,6 +317,7 @@\nfunc riskKAnonymity(w io.Writer, client *dlp.Client, project, dataProject, pubSu\n \t\t\treturn\n \t\t}\n \t\tmsg.Ack()\n+\t\ttime.Sleep(500 * time.Millisecond)\n \t\tj, err := client.GetDlpJob(ctx, &dlppb.GetDlpJobRequest{\n \t\t\tName: j.GetName(),\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "dlp/dlp_snippets/risk.go",
        "code_diff": "@@ -423,6 +427,7 @@\nfunc riskLDiversity(w io.Writer, client *dlp.Client, project, dataProject, pubSu\n \t\t\treturn\n \t\t}\n \t\tmsg.Ack()\n+\t\ttime.Sleep(500 * time.Millisecond)\n \t\tj, err := client.GetDlpJob(ctx, &dlppb.GetDlpJobRequest{\n \t\t\tName: j.GetName(),\n \t\t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -44,15 +44,23 @@\nvar (\n \t\t\"querywithtimestamp\":  queryWithTimestamp,\n \t\t\"writewithtimestamp\":  writeWithTimestamp,\n \t\t\"querynewtable\":       queryNewTable,\n+\t\t\"writetodocstable\":    writeToDocumentsTable,\n+\t\t\"updatedocstable\":     updateDocumentsTable,\n+\t\t\"querydocstable\":      queryDocumentsTable,\n+\t\t\"writewithhistory\":    writeWithHistory,\n+\t\t\"updatewithhistory\":   updateWithHistory,\n+\t\t\"querywithhistory\":    queryWithHistory,\n \t}\n \n \tadminCommands = map[string]adminCommand{\n-\t\t\"createdatabase\":           createDatabase,\n-\t\t\"addnewcolumn\":             addNewColumn,\n-\t\t\"addindex\":                 addIndex,\n-\t\t\"addstoringindex\":          addStoringIndex,\n-\t\t\"addcommittimestamp\":       addCommitTimestamp,\n-\t\t\"createtablewithtimestamp\": createTableWithTimestamp,\n+\t\t\"createdatabase\":                  createDatabase,\n+\t\t\"addnewcolumn\":                    addNewColumn,\n+\t\t\"addindex\":                        addIndex,\n+\t\t\"addstoringindex\":                 addStoringIndex,\n+\t\t\"addcommittimestamp\":              addCommitTimestamp,\n+\t\t\"createtablewithtimestamp\":        createTableWithTimestamp,\n+\t\t\"createtabledocswithtimestamp\":    createTableDocumentsWithTimestamp,\n+\t\t\"createtabledocswithhistorytable\": createTableDocumentsWithHistoryTable,\n \t}\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -121,6 +129,55 @@\nfunc createTableWithTimestamp(ctx context.Context, w io.Writer, adminClient *dat\n \n // [END spanner_create_table_with_timestamp_column]\n \n+func createTableDocumentsWithTimestamp(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t`CREATE TABLE DocumentsWithTimestamp(\n+\t\t\t\tUserId INT64 NOT NULL,\n+\t\t\t\tDocumentId INT64 NOT NULL,\n+\t\t\t    Timestamp TIMESTAMP NOT NULL OPTIONS(allow_commit_timestamp=true),\n+\t\t\t\tContents STRING(MAX) NOT NULL\n+\t\t\t) PRIMARY KEY(UserId, DocumentId)`,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Created DocumentsWithTimestamp table in database [%s]\\n\", database)\n+\treturn nil\n+}\n+\n+func createTableDocumentsWithHistoryTable(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t`CREATE TABLE Documents(\n+\t\t\t\tUserId INT64 NOT NULL,\n+\t\t\t\tDocumentId INT64 NOT NULL,\n+\t\t\t\tContents STRING(MAX) NOT NULL\n+\t\t\t) PRIMARY KEY(UserId, DocumentId)`,\n+\t\t\t`CREATE TABLE DocumentHistory(\n+\t\t\t\tUserId INT64 NOT NULL,\n+\t\t\t\tDocumentId INT64 NOT NULL,\n+\t\t\t\tTimestamp TIMESTAMP NOT NULL OPTIONS(allow_commit_timestamp=true),\n+\t\t\t\tPreviousContents STRING(MAX)\n+\t\t\t) PRIMARY KEY(UserId, DocumentId, Timestamp), INTERLEAVE IN PARENT Documents ON DELETE NO ACTION`,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Created Documents and DocumentHistory tables in database [%s]\\n\", database)\n+\treturn nil\n+}\n+\n // [START spanner_insert_data]\n \n func write(ctx context.Context, w io.Writer, client *spanner.Client) error {",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -703,6 +760,185 @@\nfunc queryNewTable(ctx context.Context, w io.Writer, client *spanner.Client) err\n \t}\n }\n \n+func writeToDocumentsTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tdocumentsColumns := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"Contents\"}\n+\tm := []*spanner.Mutation{\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, \"Hello World 1\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{1, 2, spanner.CommitTimestamp, \"Hello World 2\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, \"Hello World 3\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{2, 4, spanner.CommitTimestamp, \"Hello World 4\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, \"Hello World 5\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{3, 6, spanner.CommitTimestamp, \"Hello World 6\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{3, 7, spanner.CommitTimestamp, \"Hello World 7\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{3, 8, spanner.CommitTimestamp, \"Hello World 8\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{3, 9, spanner.CommitTimestamp, \"Hello World 9\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{3, 10, spanner.CommitTimestamp, \"Hello World 10\"}),\n+\t}\n+\t_, err := client.Apply(ctx, m)\n+\treturn err\n+}\n+\n+func updateDocumentsTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tcols := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"Contents\"}\n+\t_, err := client.Apply(ctx, []*spanner.Mutation{\n+\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n+\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, \"Hello World 1 Updated\"}),\n+\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n+\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, \"Hello World 3 Updated\"}),\n+\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n+\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, \"Hello World 5 Updated\"}),\n+\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n+\t\t\t[]interface{}{3, 7, spanner.CommitTimestamp, \"Hello World 7 Updated\"}),\n+\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n+\t\t\t[]interface{}{3, 9, spanner.CommitTimestamp, \"Hello World 9 Updated\"}),\n+\t})\n+\treturn err\n+}\n+\n+func queryDocumentsTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tstmt := spanner.Statement{SQL: `SELECT UserId, DocumentId, Timestamp, Contents FROM DocumentsWithTimestamp\n+\t\tORDER BY Timestamp DESC Limit 5`}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar userID, documentID int64\n+\t\tvar timestamp time.Time\n+\t\tvar contents string\n+\t\tif err := row.Columns(&userID, &documentID, &timestamp, &contents); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %d %s %s\\n\", userID, documentID, timestamp, contents)\n+\t}\n+}\n+\n+func writeWithHistory(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\tdocumentsColumns := []string{\"UserId\", \"DocumentId\", \"Contents\"}\n+\t\tdocumentHistoryColumns := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"PreviousContents\"}\n+\t\ttxn.BufferWrite([]*spanner.Mutation{\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{1, 1, \"Hello World 1\"}),\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{1, 2, \"Hello World 2\"}),\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{1, 3, \"Hello World 3\"}),\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{2, 4, \"Hello World 4\"}),\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{2, 5, \"Hello World 5\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, \"Hello World 1\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{1, 2, spanner.CommitTimestamp, \"Hello World 2\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, \"Hello World 3\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{2, 4, spanner.CommitTimestamp, \"Hello World 4\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, \"Hello World 5\"}),\n+\t\t})\n+\t\treturn nil\n+\t})\n+\treturn err\n+}\n+\n+func updateWithHistory(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\t// Create anonymous function \"getContents\" to read the current value of the Contents column for a given row.\n+\t\tgetContents := func(key spanner.Key) (string, error) {\n+\t\t\trow, err := txn.ReadRow(ctx, \"Documents\", key, []string{\"Contents\"})\n+\t\t\tif err != nil {\n+\t\t\t\treturn \"\", err\n+\t\t\t}\n+\t\t\tvar content string\n+\t\t\tif err := row.Column(0, &content); err != nil {\n+\t\t\t\treturn \"\", err\n+\t\t\t}\n+\t\t\treturn content, nil\n+\t\t}\n+\t\t// Create two string arrays corresponding to the columns in each table.\n+\t\tdocumentsColumns := []string{\"UserId\", \"DocumentId\", \"Contents\"}\n+\t\tdocumentHistoryColumns := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"PreviousContents\"}\n+\t\t// Get row's Contents before updating.\n+\t\tpreviousContents, err := getContents(spanner.Key{1, 1})\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\t// Update row's Contents while saving previous Contents in DocumentHistory table.\n+\t\ttxn.BufferWrite([]*spanner.Mutation{\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{1, 1, \"Hello World 1 Updated\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, previousContents}),\n+\t\t})\n+\t\tpreviousContents, err = getContents(spanner.Key{1, 3})\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\ttxn.BufferWrite([]*spanner.Mutation{\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{1, 3, \"Hello World 3 Updated\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, previousContents}),\n+\t\t})\n+\t\tpreviousContents, err = getContents(spanner.Key{2, 5})\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\ttxn.BufferWrite([]*spanner.Mutation{\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{2, 5, \"Hello World 5 Updated\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, previousContents}),\n+\t\t})\n+\t\treturn nil\n+\t})\n+\treturn err\n+}\n+\n+func queryWithHistory(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT d.UserId, d.DocumentId, d.Contents, dh.Timestamp, dh.PreviousContents\n+\t\t\t\tFROM Documents d JOIN DocumentHistory dh\n+\t\t\t\tON dh.UserId = d.UserId AND dh.DocumentId = d.DocumentId\n+\t\t\t\tORDER BY dh.Timestamp DESC LIMIT 3`}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar userID, documentID int64\n+\t\tvar timestamp time.Time\n+\t\tvar contents, previousContents string\n+\t\tif err := row.Columns(&userID, &documentID, &contents, &timestamp, &previousContents); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %d %s %s %s\\n\", userID, documentID, contents, timestamp, previousContents)\n+\t}\n+}\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -78,7 +78,7 @@\nfunc main() {\n \t}\n \n \t// delete the bucket\n-\tif err := delete(client, name); err != nil {\n+\tif err := deleteBucket(client, name); err != nil {\n \t\tlog.Fatal(err)\n \t}\n \tfmt.Printf(\"deleted bucket: %v\\n\", name)",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -5,7 +5,6 @@\npackage main\n \n import (\n-\t\"fmt\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "testing: add gimmeproj command",
        "pr_number": 443,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -15,42 +14,45 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n-var bucketName = fmt.Sprintf(\"golang-example-buckets-%d\", time.Now().Unix())\n+var (\n+\tstorageClient *storage.Client\n+\tbucketName    string\n+)\n \n-func setup(t *testing.T) *storage.Client {\n+func TestCreate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tclient, err := storage.NewClient(ctx)\n+\tvar err error\n+\tstorageClient, err = storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n-\treturn client\n-}\n \n-func TestCreate(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n-\tif err := create(c, tc.ProjectID, bucketName); err != nil {\n+\tbucketName = tc.ProjectID + \"-storage-buckets-tests\"\n+\t// Clean up bucket before running tests.\n+\tdeleteBucket(storageClient, bucketName)\n+\tif err := create(storageClient, tc.ProjectID, bucketName); err != nil {\n \t\tt.Fatalf(\"failed to create bucket (%q): %v\", bucketName, err)\n \t}\n }\n \n func TestCreateWithAttrs(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n \tname := bucketName + \"-attrs\"\n-\tif err := createWithAttrs(c, tc.ProjectID, name); err != nil {\n-\t\tt.Fatalf(\"failed to create bucket (%q): %v\", bucketName, err)\n+\t// Clean up bucket before running test.\n+\tdeleteBucket(storageClient, name)\n+\tif err := createWithAttrs(storageClient, tc.ProjectID, name); err != nil {\n+\t\tt.Fatalf(\"failed to create bucket (%q): %v\", name, err)\n \t}\n-\tif err := delete(c, name); err != nil {\n-\t\tt.Fatalf(\"failed to delete bucket (%q): %v\", bucketName, err)\n+\tif err := deleteBucket(storageClient, name); err != nil {\n+\t\tt.Fatalf(\"failed to delete bucket (%q): %v\", name, err)\n \t}\n }\n \n func TestList(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n-\tbuckets, err := list(c, tc.ProjectID)\n+\tbuckets, err := list(storageClient, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into gimmeproj",
        "commit_id": "c93203a3c983efcaaa45633efcad4f7f6a95fdd9"
    },
    {
        "pr_title": "Add example of using Spanner arrays in a query",
        "pr_number": 442,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -78,7 +78,7 @@\nfunc main() {\n \t}\n \n \t// delete the bucket\n-\tif err := delete(client, name); err != nil {\n+\tif err := deleteBucket(client, name); err != nil {\n \t\tlog.Fatal(err)\n \t}\n \tfmt.Printf(\"deleted bucket: %v\\n\", name)",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "6c0be5ebc3706ac4f16b6792e6251c4255ed3007"
    },
    {
        "pr_title": "Add example of using Spanner arrays in a query",
        "pr_number": 442,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -5,7 +5,6 @@\npackage main\n \n import (\n-\t\"fmt\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "6c0be5ebc3706ac4f16b6792e6251c4255ed3007"
    },
    {
        "pr_title": "Add example of using Spanner arrays in a query",
        "pr_number": 442,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -15,42 +14,45 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n-var bucketName = fmt.Sprintf(\"golang-example-buckets-%d\", time.Now().Unix())\n+var (\n+\tstorageClient *storage.Client\n+\tbucketName    string\n+)\n \n-func setup(t *testing.T) *storage.Client {\n+func TestCreate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tclient, err := storage.NewClient(ctx)\n+\tvar err error\n+\tstorageClient, err = storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n-\treturn client\n-}\n \n-func TestCreate(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n-\tif err := create(c, tc.ProjectID, bucketName); err != nil {\n+\tbucketName = tc.ProjectID + \"-storage-buckets-tests\"\n+\t// Clean up bucket before running tests.\n+\tdeleteBucket(storageClient, bucketName)\n+\tif err := create(storageClient, tc.ProjectID, bucketName); err != nil {\n \t\tt.Fatalf(\"failed to create bucket (%q): %v\", bucketName, err)\n \t}\n }\n \n func TestCreateWithAttrs(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n \tname := bucketName + \"-attrs\"\n-\tif err := createWithAttrs(c, tc.ProjectID, name); err != nil {\n-\t\tt.Fatalf(\"failed to create bucket (%q): %v\", bucketName, err)\n+\t// Clean up bucket before running test.\n+\tdeleteBucket(storageClient, name)\n+\tif err := createWithAttrs(storageClient, tc.ProjectID, name); err != nil {\n+\t\tt.Fatalf(\"failed to create bucket (%q): %v\", name, err)\n \t}\n-\tif err := delete(c, name); err != nil {\n-\t\tt.Fatalf(\"failed to delete bucket (%q): %v\", bucketName, err)\n+\tif err := deleteBucket(storageClient, name); err != nil {\n+\t\tt.Fatalf(\"failed to delete bucket (%q): %v\", name, err)\n \t}\n }\n \n func TestList(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n-\tbuckets, err := list(c, tc.ProjectID)\n+\tbuckets, err := list(storageClient, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into master",
        "commit_id": "6c0be5ebc3706ac4f16b6792e6251c4255ed3007"
    },
    {
        "pr_title": "vision/detect: add web entity geo sample",
        "pr_number": 431,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -16,8 +16,10 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \n-\tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"golang.org/x/net/context\"\n+\n+\tvision \"cloud.google.com/go/vision/apiv1\"\n+\tvisionpb \"google.golang.org/genproto/googleapis/cloud/vision/v1\"\n )\n \n // [END imports]",
        "comments": [
            {
                "comment": "Add `defer client.Close()`?",
                "position": 26
            },
            {
                "comment": "Add `defer client.Close()`?",
                "position": 26
            },
            {
                "comment": "Tests?",
                "position": 19
            },
            {
                "comment": "yep, there's a test (see detect_test.go)",
                "position": 19
            },
            {
                "comment": "hm, good point. could you file a bug - if this is what we want, we should do this for all of the samples.",
                "position": 26
            }
        ],
        "commit_message": "vision/detect: add web entity geo sample",
        "commit_id": "20e25c8ef82d741c9df0e13b974934fdf190c8ec"
    },
    {
        "pr_title": "vision/detect: add web entity geo sample",
        "pr_number": 431,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -399,6 +401,49 @@\nfunc detectWeb(w io.Writer, file string) error {\n \n // [END vision_detect_web]\n \n+// [START vision_web_entities_include_geo_results]\n+\n+// detectWebGeo detects geographic metadata from the Vision API for an image at the given file path.\n+func detectWebGeo(w io.Writer, file string) error {\n+\tctx := context.Background()\n+\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tf, err := os.Open(file)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer f.Close()\n+\n+\timage, err := vision.NewImageFromReader(f)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\timageContext := &visionpb.ImageContext{\n+\t\tWebDetectionParams: &visionpb.WebDetectionParams{\n+\t\t\tIncludeGeoResults: true,\n+\t\t},\n+\t}\n+\tweb, err := client.DetectWeb(ctx, image, imageContext)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif len(web.WebEntities) != 0 {\n+\t\tfmt.Fprintln(w, \"Entities:\")\n+\t\tfor _, entity := range web.WebEntities {\n+\t\t\tfmt.Fprintf(w, \"\\t%-12s %s\\n\", entity.EntityId, entity.Description)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+// [END vision_web_entities_include_geo_results]\n+\n // detectLogos gets logos from the Vision API for an image at the given file path.\n func detectLogos(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "vision/detect: add web entity geo sample",
        "commit_id": "20e25c8ef82d741c9df0e13b974934fdf190c8ec"
    },
    {
        "pr_title": "vision/detect: add web entity geo sample",
        "pr_number": 431,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -19,8 +19,10 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \n-\tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"golang.org/x/net/context\"\n+\n+\tvision \"cloud.google.com/go/vision/apiv1\"\n+\tvisionpb \"google.golang.org/genproto/googleapis/cloud/vision/v1\"\n )\n \n // [END imports]",
        "comments": [],
        "commit_message": "vision/detect: add web entity geo sample",
        "commit_id": "20e25c8ef82d741c9df0e13b974934fdf190c8ec"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -175,6 +175,7 @@\nfunc detectText(w io.Writer, file string) error {\n }\n \n // [START vision_detect_document]\n+\n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentText(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Newlines after region tag STARTs",
        "commit_id": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -304,6 +305,7 @@\nfunc detectCropHints(w io.Writer, file string) error {\n }\n \n // [START vision_detect_safe_search]\n+\n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearch(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Newlines after region tag STARTs",
        "commit_id": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -341,6 +343,7 @@\nfunc detectSafeSearch(w io.Writer, file string) error {\n // [END vision_detect_safe_search]\n \n // [START vision_detect_web]\n+\n // detectWeb gets image properties from the Vision API for an image at the given file path.\n func detectWeb(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Newlines after region tag STARTs",
        "commit_id": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -549,6 +552,7 @@\nfunc detectTextURI(w io.Writer, file string) error {\n }\n \n // [START vision_detect_document_uri]\n+\n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentTextURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Newlines after region tag STARTs",
        "commit_id": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -651,6 +655,7 @@\nfunc detectCropHintsURI(w io.Writer, file string) error {\n }\n \n // [START vision_detect_safe_search_uri]\n+\n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearchURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Newlines after region tag STARTs",
        "commit_id": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -114,6 +114,7 @@\nfunc detectText(w io.Writer, file string) error {\n }\n \n // [START vision_detect_document{REGION_TAG_PARAMETER}]\n+\n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentText(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Newlines after region tag STARTs",
        "commit_id": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -195,6 +196,7 @@\nfunc detectCropHints(w io.Writer, file string) error {\n }\n \n // [START vision_detect_safe_search{REGION_TAG_PARAMETER}]\n+\n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearch(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_message": "Newlines after region tag STARTs",
        "commit_id": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "BigQuery JSON Snippets",
        "pr_number": 387,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -316,8 +316,8 @@\nfunc importJsonExplicitSchema(client *bigquery.Client, datasetID, tableID string\n \t\t{Name: \"post_abbr\", Type: bigquery.StringFieldType},\n \t}\n \tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n-\n \tloader.WriteDisposition = bigquery.WriteEmpty\n+\n \tjob, err := loader.Run(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [
            {
                "comment": "nit: move to the previous line. the newline after is fine.\r\n\r\nexplanation: the WriteDisposition is part creating the loader, so it should belong with the code that created it. It doesn't seem to be part of the call to loader.Run, so shouldn't be next to that piece of code.",
                "position": null
            },
            {
                "comment": "return an error, like the other error handling code.\r\n\r\nYou might want to just change this to `return fmt.Errorf(...)`",
                "position": null
            },
            {
                "comment": "Same comments here.",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments.\n\n*  switch to returning a formatted error\n*  placement/grouping of loader options",
        "commit_id": "4b498b1a97d93d11ad63a70a630a2ce1bee3ff5f"
    },
    {
        "pr_title": "BigQuery JSON Snippets",
        "pr_number": 387,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -328,7 +328,7 @@\nfunc importJsonExplicitSchema(client *bigquery.Client, datasetID, tableID string\n \t}\n \n \tif status.Err() != nil {\n-\t\tfmt.Printf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_json]\n \treturn nil",
        "comments": [
            {
                "comment": "nit: move to the previous line. the newline after is fine.\r\n\r\nexplanation: the WriteDisposition is part creating the loader, so it should belong with the code that created it. It doesn't seem to be part of the call to loader.Run, so shouldn't be next to that piece of code.",
                "position": null
            },
            {
                "comment": "return an error, like the other error handling code.\r\n\r\nYou might want to just change this to `return fmt.Errorf(...)`",
                "position": null
            },
            {
                "comment": "Same comments here.",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments.\n\n*  switch to returning a formatted error\n*  placement/grouping of loader options",
        "commit_id": "4b498b1a97d93d11ad63a70a630a2ce1bee3ff5f"
    },
    {
        "pr_title": "BigQuery JSON Snippets",
        "pr_number": 387,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -341,8 +341,8 @@\nfunc importJsonAutodetectSchema(client *bigquery.Client, datasetID, tableID stri\n \tgcsRef.SourceFormat = bigquery.JSON\n \tgcsRef.AutoDetect = true\n \tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n-\n \tloader.WriteDisposition = bigquery.WriteEmpty\n+\n \tjob, err := loader.Run(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [
            {
                "comment": "nit: move to the previous line. the newline after is fine.\r\n\r\nexplanation: the WriteDisposition is part creating the loader, so it should belong with the code that created it. It doesn't seem to be part of the call to loader.Run, so shouldn't be next to that piece of code.",
                "position": null
            },
            {
                "comment": "return an error, like the other error handling code.\r\n\r\nYou might want to just change this to `return fmt.Errorf(...)`",
                "position": null
            },
            {
                "comment": "Same comments here.",
                "position": null
            }
        ],
        "commit_message": "Address reviewer comments.\n\n*  switch to returning a formatted error\n*  placement/grouping of loader options",
        "commit_id": "4b498b1a97d93d11ad63a70a630a2ce1bee3ff5f"
    },
    {
        "pr_title": "trace: add trace quickstart",
        "pr_number": 289,
        "file_name": "trace/trace_quickstart/main.go",
        "code_diff": "@@ -3,6 +3,7 @@\n// license that can be found in the LICENSE file.\n \n // [START trace_quickstart]\n+\n // Sample trace_quickstart creates traces incoming and outgoing requests.\n package main",
        "comments": [
            {
                "comment": "add a newline so it doesn't show in package doc",
                "position": 5
            },
            {
                "comment": "&http.Client",
                "position": null
            },
            {
                "comment": "A comment for this line, perhaps? This is the part that propagates the Trace ID, right?",
                "position": null
            },
            {
                "comment": "Done",
                "position": 5
            },
            {
                "comment": "Done",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "address review",
        "commit_id": "666567fdea9fd36ec07f395a38a208f39b839753"
    },
    {
        "pr_title": "auth: add implicit auth snippet",
        "pr_number": 285,
        "file_name": "auth/snippets.go",
        "code_diff": "@@ -2,25 +2,28 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// Package snippets contain Google Cloud authentication snippets.\n-package snippets\n+// Package authsnippets contains Google Cloud authentication snippets.\n+package authsnippets\n \n import (\n \t\"fmt\"\n \t\"log\"\n \n \t\"cloud.google.com/go/storage\"\n \t\"golang.org/x/net/context\"\n+\t\"golang.org/x/oauth2/google\"\n+\tcloudkms \"google.golang.org/api/cloudkms/v1\"\n \t\"google.golang.org/api/iterator\"\n )\n \n func adc() {\n \tctx := context.Background()\n \n \t// [START auth_cloud_implicit]\n-\t// Instantiate a client. If you don't specify credentials\n-\t// when constructing the client, the client library will look\n-\t// for credentials in the environment.\n+\n+\t// For API packages whose import path is starting with \"cloud.google.com/go\",\n+\t// such as cloud.google.com/go/storage in this case, if there are no credentials\n+\t// provided, the client library will look for credentials in the environment.\n \tstorageClient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tlog.Fatal(err)",
        "comments": [
            {
                "comment": "auth_snippets?",
                "position": null
            },
            {
                "comment": "s/contain/contains/",
                "position": null
            },
            {
                "comment": "Get rid of \"instantiate\". We're not Java.",
                "position": null
            },
            {
                "comment": "underscore in package names is a lint error, used authsnippets instead.",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "address feedback",
        "commit_id": "1a79f82d691c863f98d6cb5493cefbce79cfc77a"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -129,6 +129,38 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \treturn nil\n }\n \n+func pullMsgsError(client *pubsub.Client, name string) error {\n+\tctx := context.Background()\n+\t// [START pull_messages_error]\n+\t// If the service returns a non-retryable error, Receive returns that error after\n+\t// all of the outstanding calls to the handler have returned.\n+\terr := client.Subscription(name).Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n+\t\tfmt.Printf(\"Got message: %q\\n\", string(msg.Data))\n+\t\tmsg.Ack()\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// [END pull_messages_error]\n+\treturn nil\n+}\n+\n+func pullMsgsSettings(client *pubsub.Client, name string) error {\n+\tctx := context.Background()\n+\t// [START pull_messages_settings]\n+\tsub := client.Subscription(name)\n+\tsub.ReceiveSettings.MaxOutstandingMessages = 10\n+\terr := sub.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n+\t\tfmt.Printf(\"Got message: %q\\n\", string(msg.Data))\n+\t\tmsg.Ack()\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// [END pull_messages_settings]\n+\treturn nil\n+}\n+\n func create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \tctx := context.Background()\n \t// [START create_subscription]",
        "comments": [],
        "commit_message": "Merge branch 'master' into m",
        "commit_id": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -10,6 +10,7 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \t\"os\"\n+\t\"time\"\n \n \t// [START imports]\n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into m",
        "commit_id": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -95,6 +96,27 @@\nfunc list(client *pubsub.Client) ([]*pubsub.Topic, error) {\n \t// [END list_topics]\n }\n \n+func listSubscriptions(client *pubsub.Client, topicID string) ([]*pubsub.Subscription, error) {\n+\tctx := context.Background()\n+\n+\t// [START list_topic_subscriptions]\n+\tvar subs []*pubsub.Subscription\n+\n+\tit := client.Topic(topicID).Subscriptions(ctx)\n+\tfor {\n+\t\tsub, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\tsubs = append(subs, sub)\n+\t}\n+\t// [END list_topic_subscriptions]\n+\treturn subs, nil\n+}\n+\n func delete(client *pubsub.Client, topic string) error {\n \tctx := context.Background()\n \t// [START delete_topic]",
        "comments": [],
        "commit_message": "Merge branch 'master' into m",
        "commit_id": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -98,7 +98,7 @@\nfunc write(client *storage.Client, bucket, object string) error {\n \treturn nil\n }\n \n-func list(client *storage.Client, bucket string) error {\n+func list(w io.Writer, client *storage.Client, bucket string) error {\n \tctx := context.Background()\n \t// [START storage_list_files]\n \tit := client.Bucket(bucket).Objects(ctx, nil)",
        "comments": [],
        "commit_message": "Merge branch 'master' into m",
        "commit_id": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -110,13 +110,13 @@\nfunc list(client *storage.Client, bucket string) error {\n \t\tif err != nil {\n \t\t\treturn err\n \t\t}\n-\t\tfmt.Println(attrs.Name)\n+\t\tfmt.Fprintln(w, attrs.Name)\n \t}\n \t// [END storage_list_files]\n \treturn nil\n }\n \n-func listByPrefix(client *storage.Client, bucket, prefix, delim string) error {\n+func listByPrefix(w io.Writer, client *storage.Client, bucket, prefix, delim string) error {\n \tctx := context.Background()\n \t// [START storage_list_files_with_prefix]\n \t// Prefixes and delimiters can be used to emulate directory listings.",
        "comments": [],
        "commit_message": "Merge branch 'master' into m",
        "commit_id": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -5,11 +5,14 @@\npackage main\n \n import (\n-\t\"fmt\"\n+\t\"bytes\"\n \t\"log\"\n+\t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"google.golang.org/api/iterator\"\n+\n \t\"cloud.google.com/go/storage\"\n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_message": "Merge branch 'master' into m",
        "commit_id": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -24,45 +27,75 @@\nfunc TestObjects(t *testing.T) {\n \t\tlog.Fatal(err)\n \t}\n \n-\tobject := fmt.Sprintf(\"golang-example-objects-object-%d\", time.Now().Unix())\n+\tvar (\n+\t\tbucket    = tc.ProjectID + \"-samples-object-bucket-1\"\n+\t\tdstBucket = tc.ProjectID + \"-samples-object-bucket-2\"\n \n-\t// TODO(jbd): Clean garbage buckets that are older than 1 day.\n-\tbucket := fmt.Sprintf(\"golang-example-objects-bucket-%d\", time.Now().Unix())\n-\tdstBucket := fmt.Sprintf(\"golang-example-objects-dstbucket-%d\", time.Now().Unix())\n+\t\tobject1 = \"foo.txt\"\n+\t\tobject2 = \"foo/a.txt\"\n+\t)\n \n-\tensureBucketExists(ctx, client, tc.ProjectID, bucket)\n-\tensureBucketExists(ctx, client, tc.ProjectID, dstBucket)\n+\tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n+\tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n \n-\tif err := list(client, bucket); err != nil {\n-\t\tt.Fatalf(\"cannot list objects: %v\", err)\n+\tif err := write(client, bucket, object1); err != nil {\n+\t\tt.Fatalf(\"write(%q): %v\", object1, err)\n \t}\n-\tif err := listByPrefix(client, bucket, \"golang-example\", \"\"); err != nil {\n-\t\tt.Fatalf(\"cannot list objects by prefix: %v\", err)\n+\tif err := write(client, bucket, object2); err != nil {\n+\t\tt.Fatalf(\"write(%q): %v\", object2, err)\n \t}\n-\tif err := write(client, bucket, object); err != nil {\n-\t\tt.Fatalf(\"cannot write object: %v\", err)\n+\n+\t{\n+\t\t// Should only show \"foo/a.txt\", not \"foo.txt\"\n+\t\tvar buf bytes.Buffer\n+\t\tif err := list(&buf, client, bucket); err != nil {\n+\t\t\tt.Fatalf(\"cannot list objects: %v\", err)\n+\t\t}\n+\t\tif got, want := buf.String(), object1; !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"List() got %q; want to contain %q\", got, want)\n+\t\t}\n+\t\tif got, want := buf.String(), object2; !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"List() got %q; want to contain %q\", got, want)\n+\t\t}\n+\t}\n+\n+\t{\n+\t\t// Should only show \"foo/a.txt\", not \"foo.txt\"\n+\t\tconst prefix = \"foo/\"\n+\t\tvar buf bytes.Buffer\n+\t\tif err := listByPrefix(&buf, client, bucket, prefix, \"\"); err != nil {\n+\t\t\tt.Fatalf(\"cannot list objects by prefix: %v\", err)\n+\t\t}\n+\t\tif got, want := buf.String(), object1; strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"List(%q) got %q; want NOT to contain %q\", prefix, got, want)\n+\t\t}\n+\t\tif got, want := buf.String(), object2; !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"List(%q) got %q; want to contain %q\", prefix, got, want)\n+\t\t}\n \t}\n-\tdata, err := read(client, bucket, object)\n+\n+\tdata, err := read(client, bucket, object1)\n \tif err != nil {\n \t\tt.Fatalf(\"cannot read object: %v\", err)\n \t}\n \tif got, want := string(data), \"Hello\\nworld\"; got != want {\n \t\tt.Errorf(\"contents = %q; want %q\", got, want)\n \t}\n-\t_, err = attrs(client, bucket, object)\n+\t_, err = attrs(client, bucket, object1)\n \tif err != nil {\n \t\tt.Errorf(\"cannot get object metadata: %v\", err)\n \t}\n-\tif err := makePublic(client, bucket, object); err != nil {\n+\tif err := makePublic(client, bucket, object1); err != nil {\n \t\tt.Errorf(\"cannot to make object public: %v\", err)\n \t}\n-\terr = move(client, bucket, object)\n+\terr = move(client, bucket, object1)\n \tif err != nil {\n \t\tt.Fatalf(\"cannot move object: %v\", err)\n \t}\n-\tobject += \"-rename\"\n-\terr = copyToBucket(client, dstBucket, bucket, object)\n-\tif err != nil {\n+\t// object1's new name.\n+\tobject1 = object1 + \"-rename\"\n+\n+\tif err := copyToBucket(client, dstBucket, bucket, object1); err != nil {\n \t\tt.Errorf(\"cannot copy object to bucket: %v\", err)\n \t}\n \tif err := addBucketACL(client, bucket); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into m",
        "commit_id": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -83,36 +116,39 @@\nfunc TestObjects(t *testing.T) {\n \tif err := deleteBucketACL(client, bucket); err != nil {\n \t\tt.Errorf(\"cannot delete bucket acl: %v\", err)\n \t}\n-\tif err := addObjectACL(client, bucket, object); err != nil {\n+\tif err := addObjectACL(client, bucket, object1); err != nil {\n \t\tt.Errorf(\"cannot add object acl: %v\", err)\n \t}\n-\tif err := objectACL(client, bucket, object); err != nil {\n+\tif err := objectACL(client, bucket, object1); err != nil {\n \t\tt.Errorf(\"cannot get object acl: %v\", err)\n \t}\n-\tif err := objectACLFiltered(client, bucket, object, storage.AllAuthenticatedUsers); err != nil {\n+\tif err := objectACLFiltered(client, bucket, object1, storage.AllAuthenticatedUsers); err != nil {\n \t\tt.Errorf(\"cannot filter object acl: %v\", err)\n \t}\n-\tif err := deleteObjectACL(client, bucket, object); err != nil {\n+\tif err := deleteObjectACL(client, bucket, object1); err != nil {\n \t\tt.Errorf(\"cannot delete object acl: %v\", err)\n \t}\n \n \tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \tnewKey := []byte(\"My-secret-AES-256-encryption-key\")\n \n-\tif err := writeEncryptedObject(client, bucket, object, key); err != nil {\n+\tif err := writeEncryptedObject(client, bucket, object1, key); err != nil {\n \t\tt.Errorf(\"cannot write an encrypted object: %v\", err)\n \t}\n-\tdata, err = readEncryptedObject(client, bucket, object, key)\n+\tdata, err = readEncryptedObject(client, bucket, object1, key)\n \tif err != nil {\n \t\tt.Errorf(\"cannot read the encrypted object: %v\", err)\n \t}\n \tif got, want := string(data), \"top secret\"; got != want {\n \t\tt.Errorf(\"object content = %q; want %q\", got, want)\n \t}\n-\tif err := rotateEncryptionKey(client, bucket, object, key, newKey); err != nil {\n+\tif err := rotateEncryptionKey(client, bucket, object1, key, newKey); err != nil {\n \t\tt.Errorf(\"cannot encrypt the object with the new key: %v\", err)\n \t}\n-\tif err := delete(client, bucket, object); err != nil {\n+\tif err := delete(client, bucket, object1); err != nil {\n+\t\tt.Errorf(\"cannot to delete object: %v\", err)\n+\t}\n+\tif err := delete(client, bucket, object2); err != nil {\n \t\tt.Errorf(\"cannot to delete object: %v\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into m",
        "commit_id": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -125,7 +161,7 @@\nfunc TestObjects(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := delete(client, dstBucket, object+\"-copy\"); err != nil {\n+\t\tif err := delete(client, dstBucket, object1+\"-copy\"); err != nil {\n \t\t\tr.Errorf(\"cannot to delete copy object: %v\", err)\n \t\t}\n \t})",
        "comments": [],
        "commit_message": "Merge branch 'master' into m",
        "commit_id": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "pubsub: add samples for PushConfig, PublishSettings, and ReceiveSettings",
        "pr_number": 253,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -157,8 +157,14 @@\nfunc publishWithSettings(client *pubsub.Client, topic string, msg []byte) error\n \t\tDelayThreshold: 100 * time.Millisecond,\n \t}\n \tresult := t.Publish(ctx, &pubsub.Message{Data: msg})\n+\t// Block until the result is returned and a server-generated\n+\t// ID is returned for the published message.\n+\tid, err := result.Get(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Printf(\"Published a message; msg ID: %v\\n\", id)\n \t// [END publish_settings]\n-\t_ = result\n \treturn nil\n }",
        "comments": [
            {
                "comment": "same question",
                "position": null
            },
            {
                "comment": "Done.",
                "position": null
            }
        ],
        "commit_message": "addressed feedback, added Receive flow control samples.\n\nChange-Id: I4f846bcaf07b1a6cd8d4423322830fbc68a4b119",
        "commit_id": "afbcb595dd8f29ad7cafae30604d2f30e6f98439"
    },
    {
        "pr_title": "pubsub: use new Subscription.Receive interface",
        "pr_number": 209,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -10,6 +10,7 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \t\"os\"\n+\t\"sync\"\n \t\"time\"\n \n \t// [START imports]",
        "comments": [
            {
                "comment": "You should still check for error. It could be that the service failed, and you'd want to know.",
                "position": null
            },
            {
                "comment": "Done",
                "position": null
            }
        ],
        "commit_message": "pubsub: use new Subscription.Receive interface",
        "commit_id": "3f7aa979fc6083f5a2928a930a16aee835fa13b7"
    },
    {
        "pr_title": "kms: add crypter sample program",
        "pr_number": 195,
        "file_name": "kms/crypter/crypter.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// Command simpleapp encrypts and decrypts a file.\n+// Command crypter encrypts and decrypts a file.\n package main\n \n import (",
        "comments": [
            {
                "comment": "Command crypter",
                "position": null
            },
            {
                "comment": "Remove",
                "position": null
            },
            {
                "comment": "s/cloudScope/cloudkms.CloudPlatformScope/g",
                "position": null
            },
            {
                "comment": "s/out/output for symmetry with \"input\"",
                "position": null
            },
            {
                "comment": "I think just \"resp\" is fine for the return variable. Same for decrypt.",
                "position": null
            },
            {
                "comment": "You can omit the region tags. `go_function=decrypt` is equivalent to this.\r\n\r\nThis'll result in some weird godoc :)",
                "position": null
            }
        ],
        "commit_message": "kms: code style updates",
        "commit_id": "f191f5628f39ae06801f43bd104b29b18749ec71"
    },
    {
        "pr_title": "kms: add crypter sample program",
        "pr_number": 195,
        "file_name": "kms/crypter/crypter.go",
        "code_diff": "@@ -17,8 +17,6 @@\nimport (\n \tcloudkms \"google.golang.org/api/cloudkms/v1beta1\"\n )\n \n-const cloudScope = \"https://www.googleapis.com/auth/cloud-platform\"\n-\n func main() {\n \tif len(os.Args) < 7 {\n \t\tlog.Fatal(\"usage: go run crypter.go {encrypt,decrypt} PROJECTID KEYRING CRYPTOKEY INFILE OUTFILE\")",
        "comments": [
            {
                "comment": "Command crypter",
                "position": null
            },
            {
                "comment": "Remove",
                "position": null
            },
            {
                "comment": "s/cloudScope/cloudkms.CloudPlatformScope/g",
                "position": null
            },
            {
                "comment": "s/out/output for symmetry with \"input\"",
                "position": null
            },
            {
                "comment": "I think just \"resp\" is fine for the return variable. Same for decrypt.",
                "position": null
            },
            {
                "comment": "You can omit the region tags. `go_function=decrypt` is equivalent to this.\r\n\r\nThis'll result in some weird godoc :)",
                "position": null
            }
        ],
        "commit_message": "kms: code style updates",
        "commit_id": "f191f5628f39ae06801f43bd104b29b18749ec71"
    },
    {
        "pr_title": "kms: add crypter sample program",
        "pr_number": 195,
        "file_name": "kms/crypter/crypter.go",
        "code_diff": "@@ -37,29 +35,30 @@\nfunc main() {\n \t\tlog.Fatalf(\"Error reading file %q: %v\", inPath, err)\n \t}\n \n-\tvar out []byte\n-\tif command == \"encrypt\" {\n-\t\tout, err = encrypt(projectID, keyRing, cryptoKey, input)\n+\tvar output []byte\n+\tswitch command {\n+\tcase \"encrypt\":\n+\t\toutput, err = encrypt(projectID, keyRing, cryptoKey, input)\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"Error while encrypting: %v\", err)\n \t\t}\n-\t} else if command == \"decrypt\" {\n-\t\tout, err = decrypt(projectID, keyRing, cryptoKey, input)\n+\tcase \"decrypt\":\n+\t\toutput, err = decrypt(projectID, keyRing, cryptoKey, input)\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"Error while decrypting: %v\", err)\n \t\t}\n-\t} else {\n+\tdefault:\n \t\tlog.Fatalf(\"Invalid command: %s. Must be 'encrypt' or 'decrypt'.\", command)\n \t}\n-\tif err := ioutil.WriteFile(outPath, out, 0666); err != nil {\n+\n+\tif err := ioutil.WriteFile(outPath, output, 0600); err != nil {\n \t\tlog.Fatalf(\"Error writing to file %q: %v\", outPath, err)\n \t}\n }\n \n-// [START kms_encrypt]\n func encrypt(projectID, keyRing, cryptoKey string, plainText []byte) ([]byte, error) {\n \tctx := context.Background()\n-\tclient, err := google.DefaultClient(ctx, cloudScope)\n+\tclient, err := google.DefaultClient(ctx, cloudkms.CloudPlatformScope)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}",
        "comments": [
            {
                "comment": "Command crypter",
                "position": null
            },
            {
                "comment": "Remove",
                "position": null
            },
            {
                "comment": "s/cloudScope/cloudkms.CloudPlatformScope/g",
                "position": null
            },
            {
                "comment": "s/out/output for symmetry with \"input\"",
                "position": null
            },
            {
                "comment": "I think just \"resp\" is fine for the return variable. Same for decrypt.",
                "position": null
            },
            {
                "comment": "You can omit the region tags. `go_function=decrypt` is equivalent to this.\r\n\r\nThis'll result in some weird godoc :)",
                "position": null
            }
        ],
        "commit_message": "kms: code style updates",
        "commit_id": "f191f5628f39ae06801f43bd104b29b18749ec71"
    },
    {
        "pr_title": "kms: add crypter sample program",
        "pr_number": 195,
        "file_name": "kms/crypter/crypter.go",
        "code_diff": "@@ -72,23 +71,20 @@\nfunc encrypt(projectID, keyRing, cryptoKey string, plainText []byte) ([]byte, er\n \tparentName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\",\n \t\tprojectID, \"global\", keyRing, cryptoKey)\n \n-\tencryptResponse, err := cloudkmsService.Projects.Locations.KeyRings.CryptoKeys.\n+\tresp, err := cloudkmsService.Projects.Locations.KeyRings.CryptoKeys.\n \t\tEncrypt(parentName, &cloudkms.EncryptRequest{\n \t\t\tPlaintext: base64.StdEncoding.EncodeToString(plainText),\n \t\t}).Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n-\treturn base64.StdEncoding.DecodeString(encryptResponse.Ciphertext)\n+\treturn base64.StdEncoding.DecodeString(resp.Ciphertext)\n }\n \n-// [END kms_encrypt]\n-\n-// [START kms_decrypt]\n func decrypt(projectID, keyRing, cryptoKey string, cipherText []byte) ([]byte, error) {\n \tctx := context.Background()\n-\tclient, err := google.DefaultClient(ctx, cloudScope)\n+\tclient, err := google.DefaultClient(ctx, cloudkms.CloudPlatformScope)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}",
        "comments": [
            {
                "comment": "Command crypter",
                "position": null
            },
            {
                "comment": "Remove",
                "position": null
            },
            {
                "comment": "s/cloudScope/cloudkms.CloudPlatformScope/g",
                "position": null
            },
            {
                "comment": "s/out/output for symmetry with \"input\"",
                "position": null
            },
            {
                "comment": "I think just \"resp\" is fine for the return variable. Same for decrypt.",
                "position": null
            },
            {
                "comment": "You can omit the region tags. `go_function=decrypt` is equivalent to this.\r\n\r\nThis'll result in some weird godoc :)",
                "position": null
            }
        ],
        "commit_message": "kms: code style updates",
        "commit_id": "f191f5628f39ae06801f43bd104b29b18749ec71"
    },
    {
        "pr_title": "bigquery: add simpleapp example",
        "pr_number": 148,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -7,32 +7,33 @@\npackage main\n \n import (\n-\t\"encoding/json\"\n \t\"fmt\"\n \t\"log\"\n \t\"os\"\n \t\"strings\"\n \n+\t\"github.com/golang/protobuf/proto\"\n+\n \t\"golang.org/x/net/context\"\n-\t\"golang.org/x/oauth2/google\"\n \n-\tlanguage \"google.golang.org/api/language/v1beta1\"\n+\t// [START imports]\n+\tlanguage \"cloud.google.com/go/language/apiv1beta1\"\n+\tlanguagepb \"google.golang.org/genproto/googleapis/cloud/language/v1beta1\"\n+\t// [END imports]\n )\n \n func main() {\n \tif len(os.Args) < 2 {\n \t\tusage(\"Missing command.\")\n \t}\n \n+\t// [START init]\n \tctx := context.Background()\n-\thc, err := google.DefaultClient(ctx, language.CloudPlatformScope)\n-\tif err != nil {\n-\t\tlog.Fatal(err)\n-\t}\n-\tclient, err := language.New(hc)\n+\tclient, err := language.NewClient(ctx)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n+\t// [END init]\n \n \ttext := strings.Join(os.Args[2:], \" \")\n \tif text == \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into tswast-bq",
        "commit_id": "0daa37d44c2a6884d5a01d3c2ce72cb03bf66c77"
    },
    {
        "pr_title": "bigquery: add simpleapp example",
        "pr_number": 148,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -41,11 +42,11 @@\nfunc main() {\n \n \tswitch os.Args[1] {\n \tcase \"entities\":\n-\t\tprintResp(analyzeEntities(client, text))\n+\t\tprintResp(analyzeEntities(ctx, client, text))\n \tcase \"sentiment\":\n-\t\tprintResp(analyzeSentiment(client, text))\n+\t\tprintResp(analyzeSentiment(ctx, client, text))\n \tcase \"syntax\":\n-\t\tprintResp(analyzeSyntax(client, text))\n+\t\tprintResp(analyzeSyntax(ctx, client, text))\n \tdefault:\n \t\tusage(\"Unknown command.\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into tswast-bq",
        "commit_id": "0daa37d44c2a6884d5a01d3c2ce72cb03bf66c77"
    },
    {
        "pr_title": "bigquery: add simpleapp example",
        "pr_number": 148,
        "file_name": "language/analyze/analyze_test.go",
        "code_diff": "@@ -8,18 +8,18 @@\nimport (\n \t\"testing\"\n \n \t\"golang.org/x/net/context\"\n-\t\"golang.org/x/oauth2/google\"\n \n-\tlanguage \"google.golang.org/api/language/v1beta1\"\n+\tlanguage \"cloud.google.com/go/language/apiv1beta1\"\n+\tlanguagepb \"google.golang.org/genproto/googleapis/cloud/language/v1beta1\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n func TestSentiment(t *testing.T) {\n \ttestutil.SystemTest(t)\n-\tc := newClient(t)\n+\tctx, c := newClient(t)\n \n-\tres, err := analyzeSentiment(c, \"I am very happy.\")\n+\tres, err := analyzeSentiment(ctx, c, \"I am very happy.\")\n \tif err != nil {\n \t\tt.Fatalf(\"got %v, want nil err\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into tswast-bq",
        "commit_id": "0daa37d44c2a6884d5a01d3c2ce72cb03bf66c77"
    },
    {
        "pr_title": "bigquery: add simpleapp example",
        "pr_number": 148,
        "file_name": "language/analyze/analyze_test.go",
        "code_diff": "@@ -30,9 +30,9 @@\nfunc TestSentiment(t *testing.T) {\n \n func TestEntity(t *testing.T) {\n \ttestutil.SystemTest(t)\n-\tc := newClient(t)\n+\tctx, c := newClient(t)\n \n-\tres, err := analyzeEntities(c, \"Homer Simpson likes donuts.\")\n+\tres, err := analyzeEntities(ctx, c, \"Homer Simpson likes donuts.\")\n \tif err != nil {\n \t\tt.Fatalf(\"got %v, want nil err\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into tswast-bq",
        "commit_id": "0daa37d44c2a6884d5a01d3c2ce72cb03bf66c77"
    },
    {
        "pr_title": "bigquery: add simpleapp example",
        "pr_number": 148,
        "file_name": "language/analyze/analyze_test.go",
        "code_diff": "@@ -46,16 +46,16 @@\nfunc TestEntity(t *testing.T) {\n \n func TestSyntax(t *testing.T) {\n \ttestutil.SystemTest(t)\n-\tc := newClient(t)\n+\tctx, c := newClient(t)\n \n-\tres, err := analyzeSyntax(c, \"If you bend the gopher, his belly folds.\")\n+\tres, err := analyzeSyntax(ctx, c, \"If you bend the gopher, his belly folds.\")\n \tif err != nil {\n \t\tt.Fatalf(\"got %v, want nil err\", err)\n \t}\n \n \tfor _, tok := range res.Tokens {\n \t\tif tok.Lemma == \"gopher\" {\n-\t\t\tif tok.PartOfSpeech.Tag != \"NOUN\" {\n+\t\t\tif tok.PartOfSpeech.Tag != languagepb.PartOfSpeech_NOUN {\n \t\t\t\tt.Errorf(\"PartOfSpeech: got %+v, want NOUN\", tok.PartOfSpeech.Tag)\n \t\t\t}\n \t\t\treturn // found",
        "comments": [],
        "commit_message": "Merge branch 'master' into tswast-bq",
        "commit_id": "0daa37d44c2a6884d5a01d3c2ce72cb03bf66c77"
    },
    {
        "pr_title": "iotkit: initial commit of the hello world",
        "pr_number": 144,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -13,6 +13,7 @@\nimport (\n \n \t\"cloud.google.com/go/datastore\"\n \t\"golang.org/x/net/context\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n type Task struct {",
        "comments": [],
        "commit_message": "Merge branch 'master' into iotkit",
        "commit_id": "843a37e0a26db43e82451876f88a679bf88a5d57"
    },
    {
        "pr_title": "iotkit: initial commit of the hello world",
        "pr_number": 144,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -280,7 +281,7 @@\nfunc ExampleQuery_basic() {\n \tfor {\n \t\tvar task Task\n \t\t_, err := it.Next(&task)\n-\t\tif err == datastore.Done {\n+\t\tif err == iterator.Done {\n \t\t\tbreak\n \t\t}\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into iotkit",
        "commit_id": "843a37e0a26db43e82451876f88a679bf88a5d57"
    },
    {
        "pr_title": "iotkit: initial commit of the hello world",
        "pr_number": 144,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -364,7 +365,7 @@\nfunc ExampleQuery_Project() {\n \tit := client.Run(ctx, query)\n \tfor {\n \t\tvar task Task\n-\t\tif _, err := it.Next(&task); err == datastore.Done {\n+\t\tif _, err := it.Next(&task); err == iterator.Done {\n \t\t\tbreak\n \t\t} else if err != nil {\n \t\t\tlog.Fatal(err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into iotkit",
        "commit_id": "843a37e0a26db43e82451876f88a679bf88a5d57"
    },
    {
        "pr_title": "iotkit: initial commit of the hello world",
        "pr_number": 144,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -7,32 +7,33 @@\npackage main\n \n import (\n-\t\"encoding/json\"\n \t\"fmt\"\n \t\"log\"\n \t\"os\"\n \t\"strings\"\n \n+\t\"github.com/golang/protobuf/proto\"\n+\n \t\"golang.org/x/net/context\"\n-\t\"golang.org/x/oauth2/google\"\n \n-\tlanguage \"google.golang.org/api/language/v1beta1\"\n+\t// [START imports]\n+\tlanguage \"cloud.google.com/go/language/apiv1beta1\"\n+\tlanguagepb \"google.golang.org/genproto/googleapis/cloud/language/v1beta1\"\n+\t// [END imports]\n )\n \n func main() {\n \tif len(os.Args) < 2 {\n \t\tusage(\"Missing command.\")\n \t}\n \n+\t// [START init]\n \tctx := context.Background()\n-\thc, err := google.DefaultClient(ctx, language.CloudPlatformScope)\n-\tif err != nil {\n-\t\tlog.Fatal(err)\n-\t}\n-\tclient, err := language.New(hc)\n+\tclient, err := language.NewClient(ctx)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n+\t// [END init]\n \n \ttext := strings.Join(os.Args[2:], \" \")\n \tif text == \"\" {",
        "comments": [],
        "commit_message": "Merge branch 'master' into iotkit",
        "commit_id": "843a37e0a26db43e82451876f88a679bf88a5d57"
    },
    {
        "pr_title": "iotkit: initial commit of the hello world",
        "pr_number": 144,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -41,11 +42,11 @@\nfunc main() {\n \n \tswitch os.Args[1] {\n \tcase \"entities\":\n-\t\tprintResp(analyzeEntities(client, text))\n+\t\tprintResp(analyzeEntities(ctx, client, text))\n \tcase \"sentiment\":\n-\t\tprintResp(analyzeSentiment(client, text))\n+\t\tprintResp(analyzeSentiment(ctx, client, text))\n \tcase \"syntax\":\n-\t\tprintResp(analyzeSyntax(client, text))\n+\t\tprintResp(analyzeSyntax(ctx, client, text))\n \tdefault:\n \t\tusage(\"Unknown command.\")\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into iotkit",
        "commit_id": "843a37e0a26db43e82451876f88a679bf88a5d57"
    },
    {
        "pr_title": "iotkit: initial commit of the hello world",
        "pr_number": 144,
        "file_name": "language/analyze/analyze_test.go",
        "code_diff": "@@ -8,18 +8,18 @@\nimport (\n \t\"testing\"\n \n \t\"golang.org/x/net/context\"\n-\t\"golang.org/x/oauth2/google\"\n \n-\tlanguage \"google.golang.org/api/language/v1beta1\"\n+\tlanguage \"cloud.google.com/go/language/apiv1beta1\"\n+\tlanguagepb \"google.golang.org/genproto/googleapis/cloud/language/v1beta1\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n func TestSentiment(t *testing.T) {\n \ttestutil.SystemTest(t)\n-\tc := newClient(t)\n+\tctx, c := newClient(t)\n \n-\tres, err := analyzeSentiment(c, \"I am very happy.\")\n+\tres, err := analyzeSentiment(ctx, c, \"I am very happy.\")\n \tif err != nil {\n \t\tt.Fatalf(\"got %v, want nil err\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into iotkit",
        "commit_id": "843a37e0a26db43e82451876f88a679bf88a5d57"
    },
    {
        "pr_title": "iotkit: initial commit of the hello world",
        "pr_number": 144,
        "file_name": "language/analyze/analyze_test.go",
        "code_diff": "@@ -30,9 +30,9 @@\nfunc TestSentiment(t *testing.T) {\n \n func TestEntity(t *testing.T) {\n \ttestutil.SystemTest(t)\n-\tc := newClient(t)\n+\tctx, c := newClient(t)\n \n-\tres, err := analyzeEntities(c, \"Homer Simpson likes donuts.\")\n+\tres, err := analyzeEntities(ctx, c, \"Homer Simpson likes donuts.\")\n \tif err != nil {\n \t\tt.Fatalf(\"got %v, want nil err\", err)\n \t}",
        "comments": [],
        "commit_message": "Merge branch 'master' into iotkit",
        "commit_id": "843a37e0a26db43e82451876f88a679bf88a5d57"
    },
    {
        "pr_title": "iotkit: initial commit of the hello world",
        "pr_number": 144,
        "file_name": "language/analyze/analyze_test.go",
        "code_diff": "@@ -46,16 +46,16 @@\nfunc TestEntity(t *testing.T) {\n \n func TestSyntax(t *testing.T) {\n \ttestutil.SystemTest(t)\n-\tc := newClient(t)\n+\tctx, c := newClient(t)\n \n-\tres, err := analyzeSyntax(c, \"If you bend the gopher, his belly folds.\")\n+\tres, err := analyzeSyntax(ctx, c, \"If you bend the gopher, his belly folds.\")\n \tif err != nil {\n \t\tt.Fatalf(\"got %v, want nil err\", err)\n \t}\n \n \tfor _, tok := range res.Tokens {\n \t\tif tok.Lemma == \"gopher\" {\n-\t\t\tif tok.PartOfSpeech.Tag != \"NOUN\" {\n+\t\t\tif tok.PartOfSpeech.Tag != languagepb.PartOfSpeech_NOUN {\n \t\t\t\tt.Errorf(\"PartOfSpeech: got %+v, want NOUN\", tok.PartOfSpeech.Tag)\n \t\t\t}\n \t\t\treturn // found",
        "comments": [],
        "commit_message": "Merge branch 'master' into iotkit",
        "commit_id": "843a37e0a26db43e82451876f88a679bf88a5d57"
    },
    {
        "pr_title": "logging: add exportlogs sample",
        "pr_number": 128,
        "file_name": "logging/exportlogs/exportlogs.go",
        "code_diff": "@@ -6,11 +6,11 @@\npackage main\n \n import (\n-\t\"context\"\n \t\"fmt\"\n \t\"log\"\n \t\"os\"\n \n+\t\"golang.org/x/net/context\"\n \t\"google.golang.org/api/iterator\"\n \n \t\"cloud.google.com/go/logging/logadmin\"",
        "comments": [
            {
                "comment": "`sinks = append(sinks, sink.ID)` perhaps?\n\nreturn a `[]string`\n\nDemonstrates a small amount of manipulation\n",
                "position": null
            },
            {
                "comment": "wrong context\n",
                "position": null
            }
        ],
        "commit_message": "address more feedback",
        "commit_id": "7a7e358399ca2fae93f6b9be813c50846469b7b1"
    },
    {
        "pr_title": "logging: add exportlogs sample",
        "pr_number": 128,
        "file_name": "logging/exportlogs/exportlogs.go",
        "code_diff": "@@ -43,7 +43,7 @@\nfunc main() {\n \t\t\tlog.Fatalf(\"Could not list log sinks: %v\", err)\n \t\t}\n \t\tfor _, sink := range sinks {\n-\t\t\tfmt.Printf(\"Sink: %v\\n\", sink.ID)\n+\t\t\tfmt.Printf(\"Sink: %v\\n\", sink)\n \t\t}\n \tcase \"create\":\n \t\tif err := createSink(client); err != nil {",
        "comments": [
            {
                "comment": "`sinks = append(sinks, sink.ID)` perhaps?\n\nreturn a `[]string`\n\nDemonstrates a small amount of manipulation\n",
                "position": null
            },
            {
                "comment": "wrong context\n",
                "position": null
            }
        ],
        "commit_message": "address more feedback",
        "commit_id": "7a7e358399ca2fae93f6b9be813c50846469b7b1"
    },
    {
        "pr_title": "logging: add exportlogs sample",
        "pr_number": 128,
        "file_name": "logging/exportlogs/exportlogs.go",
        "code_diff": "@@ -62,11 +62,11 @@\nfunc main() {\n \t}\n }\n \n-func listSinks(client *logadmin.Client) ([]*logadmin.Sink, error) {\n+func listSinks(client *logadmin.Client) ([]string, error) {\n \t// [START list_log_sinks]\n \tctx := context.Background()\n \n-\tvar sinks []*logadmin.Sink\n+\tvar sinks []string\n \tit := client.Sinks(ctx)\n \tfor {\n \t\tsink, err := it.Next()",
        "comments": [
            {
                "comment": "`sinks = append(sinks, sink.ID)` perhaps?\n\nreturn a `[]string`\n\nDemonstrates a small amount of manipulation\n",
                "position": null
            },
            {
                "comment": "wrong context\n",
                "position": null
            }
        ],
        "commit_message": "address more feedback",
        "commit_id": "7a7e358399ca2fae93f6b9be813c50846469b7b1"
    },
    {
        "pr_title": "speech: add speech API sample with the async req/resp",
        "pr_number": 125,
        "file_name": "speech/captionasync/captionasync.go",
        "code_diff": "@@ -2,13 +2,13 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// Command captionasync sends an audio data to the Google Speech API\n+// Command captionasync sends audio data to the Google Speech API\n // and pulls the operation status and the transcript.\n package main\n \n import (\n \t\"context\"\n-\t\"flag\"\n+\t\"errors\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"",
        "comments": [
            {
                "comment": "delete \"an\"\n",
                "position": null
            },
            {
                "comment": "Why, if there are no flags?\n",
                "position": null
            },
            {
                "comment": "I can think of many places in this code where I wish there were comments, but this is not one of them!\n\nI think the async nature of this API, and the use of long-running ops, are more unusual and worthy of comment.\n\nNot that you should remove this -- it's OK.\n",
                "position": null
            },
            {
                "comment": "You could avoid this by writing\n\nif err := op.GetError(); err != nil {\n    return ...\n}\n[proceed here assuming op.GetResponse() != nil]\n\nI'd prefer that. ymmv\n",
                "position": null
            },
            {
                "comment": "Removed!\n",
                "position": null
            },
            {
                "comment": "Removed.\n",
                "position": null
            },
            {
                "comment": "I have seen the defacto style is to use the switch.\n\nI can return an error rather than panic'ing.\n",
                "position": null
            },
            {
                "comment": "Up to you.\n",
                "position": null
            }
        ],
        "commit_message": "speech/captionasync: address jba comments",
        "commit_id": "e829a27c99859f81be5de9cd9c6256b6aafaa4e1"
    },
    {
        "pr_title": "speech: add speech API sample with the async req/resp",
        "pr_number": 125,
        "file_name": "speech/captionasync/captionasync.go",
        "code_diff": "@@ -29,7 +29,6 @@\nwith a sample rate of 16000.\n `\n \n func main() {\n-\tflag.Parse()\n \tif len(os.Args) < 2 {\n \t\tfmt.Fprintln(os.Stderr, usage)\n \t\tos.Exit(2)",
        "comments": [
            {
                "comment": "delete \"an\"\n",
                "position": null
            },
            {
                "comment": "Why, if there are no flags?\n",
                "position": null
            },
            {
                "comment": "I can think of many places in this code where I wish there were comments, but this is not one of them!\n\nI think the async nature of this API, and the use of long-running ops, are more unusual and worthy of comment.\n\nNot that you should remove this -- it's OK.\n",
                "position": null
            },
            {
                "comment": "You could avoid this by writing\n\nif err := op.GetError(); err != nil {\n    return ...\n}\n[proceed here assuming op.GetResponse() != nil]\n\nI'd prefer that. ymmv\n",
                "position": null
            },
            {
                "comment": "Removed!\n",
                "position": null
            },
            {
                "comment": "Removed.\n",
                "position": null
            },
            {
                "comment": "I have seen the defacto style is to use the switch.\n\nI can return an error rather than panic'ing.\n",
                "position": null
            },
            {
                "comment": "Up to you.\n",
                "position": null
            }
        ],
        "commit_message": "speech/captionasync: address jba comments",
        "commit_id": "e829a27c99859f81be5de9cd9c6256b6aafaa4e1"
    },
    {
        "pr_title": "speech: add speech API sample with the async req/resp",
        "pr_number": 125,
        "file_name": "speech/captionasync/captionasync.go",
        "code_diff": "@@ -99,7 +98,7 @@\nfunc wait(client *speech.Client, opName string) (*speechpb.AsyncRecognizeRespons\n \t\t\treturn nil, err\n \t\t}\n \t\tif op.Done {\n-\t\t\tbreak // operation done\n+\t\t\tbreak\n \t\t}\n \t\ttime.Sleep(500 * time.Millisecond)\n \t}",
        "comments": [
            {
                "comment": "delete \"an\"\n",
                "position": null
            },
            {
                "comment": "Why, if there are no flags?\n",
                "position": null
            },
            {
                "comment": "I can think of many places in this code where I wish there were comments, but this is not one of them!\n\nI think the async nature of this API, and the use of long-running ops, are more unusual and worthy of comment.\n\nNot that you should remove this -- it's OK.\n",
                "position": null
            },
            {
                "comment": "You could avoid this by writing\n\nif err := op.GetError(); err != nil {\n    return ...\n}\n[proceed here assuming op.GetResponse() != nil]\n\nI'd prefer that. ymmv\n",
                "position": null
            },
            {
                "comment": "Removed!\n",
                "position": null
            },
            {
                "comment": "Removed.\n",
                "position": null
            },
            {
                "comment": "I have seen the defacto style is to use the switch.\n\nI can return an error rather than panic'ing.\n",
                "position": null
            },
            {
                "comment": "Up to you.\n",
                "position": null
            }
        ],
        "commit_message": "speech/captionasync: address jba comments",
        "commit_id": "e829a27c99859f81be5de9cd9c6256b6aafaa4e1"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "bigquery/syncquery/syncquery.go",
        "code_diff": "@@ -11,6 +11,7 @@\nimport (\n \t\"os\"\n \n \t\"cloud.google.com/go/bigquery\"\n+\t\"google.golang.org/api/iterator\"\n \n \t\"golang.org/x/net/context\"\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into nlvkit",
        "commit_id": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "bigquery/syncquery/syncquery.go",
        "code_diff": "@@ -35,7 +36,7 @@\nfunc main() {\n \t}\n }\n \n-// Query returns a slice of the reults of a query.\n+// Query returns a slice of the results of a query.\n func Query(proj, q string) ([]bigquery.ValueList, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_message": "Merge branch 'master' into nlvkit",
        "commit_id": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -13,6 +13,7 @@\nimport (\n \n \t\"cloud.google.com/go/datastore\"\n \t\"golang.org/x/net/context\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n type Task struct {",
        "comments": [],
        "commit_message": "Merge branch 'master' into nlvkit",
        "commit_id": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -280,7 +281,7 @@\nfunc ExampleQuery_basic() {\n \tfor {\n \t\tvar task Task\n \t\t_, err := it.Next(&task)\n-\t\tif err == datastore.Done {\n+\t\tif err == iterator.Done {\n \t\t\tbreak\n \t\t}\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into nlvkit",
        "commit_id": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -364,7 +365,7 @@\nfunc ExampleQuery_Project() {\n \tit := client.Run(ctx, query)\n \tfor {\n \t\tvar task Task\n-\t\tif _, err := it.Next(&task); err == datastore.Done {\n+\t\tif _, err := it.Next(&task); err == iterator.Done {\n \t\t\tbreak\n \t\t} else if err != nil {\n \t\t\tlog.Fatal(err)",
        "comments": [],
        "commit_message": "Merge branch 'master' into nlvkit",
        "commit_id": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -16,6 +16,7 @@\nimport (\n \t\"golang.org/x/net/context\"\n \n \t\"cloud.google.com/go/pubsub\"\n+\t\"google.golang.org/api/iterator\"\n \t// [END imports]\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into nlvkit",
        "commit_id": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -69,7 +70,7 @@\nfunc list(client *pubsub.Client) ([]*pubsub.Subscription, error) {\n \tit := client.Subscriptions(ctx)\n \tfor {\n \t\ts, err := it.Next()\n-\t\tif err == pubsub.Done {\n+\t\tif err == iterator.Done {\n \t\t\tbreak\n \t\t}\n \t\tif err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into nlvkit",
        "commit_id": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -15,6 +15,7 @@\nimport (\n \t\"golang.org/x/net/context\"\n \n \t\"cloud.google.com/go/pubsub\"\n+\t\"google.golang.org/api/iterator\"\n \t// [END imports]\n )",
        "comments": [],
        "commit_message": "Merge branch 'master' into nlvkit",
        "commit_id": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -16,6 +16,7 @@\nimport (\n \t\"golang.org/x/net/context\"\n \n \t\"cloud.google.com/go/storage\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n func main() {",
        "comments": [],
        "commit_message": "Merge branch 'master' into nlvkit",
        "commit_id": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -144,7 +144,7 @@\nfunc move(client *storage.Client, bucket, object string) error {\n \tsrc := client.Bucket(bucket).Object(object)\n \tdst := client.Bucket(bucket).Object(dstName)\n \n-\tif _, err := src.CopyTo(ctx, dst, nil); err != nil {\n+\tif _, err := dst.CopierFrom(src).Run(ctx); err != nil {\n \t\treturn err\n \t}\n \tif err := src.Delete(ctx); err != nil {",
        "comments": [],
        "commit_message": "Merge branch 'master' into nlvkit",
        "commit_id": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "speech/caption: use cloud.google.com/go/speech/apiv1beta1 package",
        "pr_number": 120,
        "file_name": "speech/caption/caption.go",
        "code_diff": "@@ -12,10 +12,12 @@\nimport (\n \t\"log\"\n \t\"os\"\n \n+\t// [START imports]\n \t\"golang.org/x/net/context\"\n-\t\"google.golang.org/api/option\"\n-\t\"google.golang.org/api/transport\"\n-\tspeech \"google.golang.org/genproto/googleapis/cloud/speech/v1beta1\"\n+\n+\tspeech \"cloud.google.com/go/speech/apiv1beta1\"\n+\tspeechpb \"google.golang.org/genproto/googleapis/cloud/speech/v1beta1\"\n+\t// [END imports]\n )\n \n const usage = `Usage: caption <audiofile>",
        "comments": [],
        "commit_message": "speech/caption: use cloud.google.com/go/speech/apiv1beta1 package",
        "commit_id": "91e2123fb5be0bc08a23d10078db6c4f6a0e02a1"
    }
]