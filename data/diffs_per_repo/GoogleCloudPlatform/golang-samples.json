[
    {
        "pr_title": "feat: added annotations samples for SM",
        "pr_number": 4432,
        "file_name": "secretmanager/regional_samples/regional_secretmanager_test.go",
        "code_diff": "@@ -82,6 +82,9 @@\nfunc testRegionalSecret(tb testing.TB, projectID string) (*secretmanagerpb.Secre\n \t\tParent:   fmt.Sprintf(\"projects/%s/locations/%s\", projectID, locationID),\n \t\tSecretId: secretID,\n \t\tSecret: &secretmanagerpb.Secret{\n+\t\t\tAnnotations: map[string]string{\n+\t\t\t\t\"annotationkey\": \"annotationvalue\",\n+\t\t\t},\n \t\t\tLabels: map[string]string{\n \t\t\t\t\"labelkey\": \"labelvalue\",\n \t\t\t},",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9ce0f2f2960ff40d0722db073a4dab01cfbc3dd3"
    },
    {
        "pr_title": "feat: added annotations samples for SM",
        "pr_number": 4432,
        "file_name": "secretmanager/regional_samples/regional_secretmanager_test.go",
        "code_diff": "@@ -107,7 +110,6 @@\nfunc testCleanupRegionalSecret(tb testing.TB, name string) {\n \t\t}\n \t}\n }\n-\n func TestCreateRegionalSecretWithLabels(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9ce0f2f2960ff40d0722db073a4dab01cfbc3dd3"
    },
    {
        "pr_title": "feat: added annotations samples for SM",
        "pr_number": 4432,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -101,6 +101,9 @@\nfunc testSecret(tb testing.TB, projectID string) *secretmanagerpb.Secret {\n \t\t\tLabels: map[string]string{\n \t\t\t\t\"labelkey\": \"labelvalue\",\n \t\t\t},\n+\t\t\tAnnotations: map[string]string{\n+\t\t\t\t\"annotationkey\": \"annotationvalue\",\n+\t\t\t},\n \t\t},\n \t})\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9ce0f2f2960ff40d0722db073a4dab01cfbc3dd3"
    },
    {
        "pr_title": "feat: added annotations samples for SM",
        "pr_number": 4432,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -121,6 +124,9 @@\nfunc testRegionalSecret(tb testing.TB, projectID string) (*secretmanagerpb.Secre\n \t\tParent:   fmt.Sprintf(\"projects/%s/locations/%s\", projectID, locationID),\n \t\tSecretId: secretID,\n \t\tSecret: &secretmanagerpb.Secret{\n+\t\t\tAnnotations: map[string]string{\n+\t\t\t\t\"annotationkey\": \"annotationvalue\",\n+\t\t\t},\n \t\t\tLabels: map[string]string{\n \t\t\t\t\"labelkey\": \"labelvalue\",\n \t\t\t},",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9ce0f2f2960ff40d0722db073a4dab01cfbc3dd3"
    },
    {
        "pr_title": "feat: added annotations samples for SM",
        "pr_number": 4432,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -333,6 +339,24 @@\nfunc TestCreateSecretWithLabels(t *testing.T) {\n \t}\n }\n \n+func TestCreateSecretWithAnnotations(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecretID := \"createSecretWithAnnotations\"\n+\n+\tparent := fmt.Sprintf(\"projects/%s\", tc.ProjectID)\n+\n+\tvar b bytes.Buffer\n+\tif err := createSecretWithAnnotations(&b, parent, secretID); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tdefer testCleanupSecret(t, fmt.Sprintf(\"projects/%s/secrets/%s\", tc.ProjectID, secretID))\n+\n+\tif got, want := b.String(), \"Created secret with annotations:\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"createSecretWithAnnotations: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestCreateRegionalSecret(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9ce0f2f2960ff40d0722db073a4dab01cfbc3dd3"
    },
    {
        "pr_title": "feat: added annotations samples for SM",
        "pr_number": 4432,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -1099,6 +1123,34 @@\nfunc TestViewSecretLabels(t *testing.T) {\n \t}\n }\n \n+func TestViewSecretAnnotations(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n+\tvar b bytes.Buffer\n+\tif err := viewSecretAnnotations(&b, secret.Name); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Found secret\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"viewSecretAnnotations: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tclient, ctx := testClient(t)\n+\ts, err := client.GetSecret(ctx, &secretmanagerpb.GetSecretRequest{\n+\t\tName: secret.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := s.Annotations, map[string]string{\"annotationkey\": \"annotationvalue\"}; !reflect.DeepEqual(got, want) {\n+\t\tt.Errorf(\"viewSecretAnnotations: expected %q to be %q\", got, want)\n+\t}\n+}\n+\n func TestListRegionalSecrets(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9ce0f2f2960ff40d0722db073a4dab01cfbc3dd3"
    },
    {
        "pr_title": "feat: add samples for labels, regional SM",
        "pr_number": 4431,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -120,6 +120,11 @@\nfunc testRegionalSecret(tb testing.TB, projectID string) (*secretmanagerpb.Secre\n \tsecret, err := client.CreateSecret(ctx, &secretmanagerpb.CreateSecretRequest{\n \t\tParent:   fmt.Sprintf(\"projects/%s/locations/%s\", projectID, locationID),\n \t\tSecretId: secretID,\n+\t\tSecret: &secretmanagerpb.Secret{\n+\t\t\tLabels: map[string]string{\n+\t\t\t\t\"labelkey\": \"labelvalue\",\n+\t\t\t},\n+\t\t},\n \t})\n \tif err != nil {\n \t\ttb.Fatalf(\"testSecret: failed to create secret: %v\", err)",
        "comments": [],
        "commit_messages": [
            "fix: fix tests"
        ],
        "last_commit_sha": "4017db736db76f16a773baad79454de6ec046169"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage ingestion topic",
        "pr_number": 4428,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -297,7 +297,7 @@\nfunc TestDelete(t *testing.T) {\n \t}\n }\n \n-func TestTopicKinesis(t *testing.T) {\n+func TestTopicKinesisIngestion(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "feat(pubsub): add cloud storage ingestion topic"
        ],
        "last_commit_sha": "de474bcfca11881a18c5bde85148c5fcccf2cb8d"
    },
    {
        "pr_title": "feat: regional template operations samples",
        "pr_number": 4412,
        "file_name": "compute/instance-templates/create-instance-templates/create_instance_templates_test.go",
        "code_diff": "@@ -34,6 +34,7 @@\nfunc TestCreateInstanceTemplatesSnippets(t *testing.T) {\n \tvar seededRand *rand.Rand = rand.New(\n \t\trand.NewSource(time.Now().UnixNano()))\n \ttc := testutil.SystemTest(t)\n+\tregion := \"eu-central2\"\n \tzone := \"europe-central2-b\"\n \tinstanceName := \"test-instance-\" + fmt.Sprint(seededRand.Int())\n \ttemplateName1 := \"test-template-\" + fmt.Sprint(seededRand.Int())",
        "comments": [],
        "commit_messages": [
            "split tests into smaller pieces"
        ],
        "last_commit_sha": "86726c0f4e2a47eb273d62de881b6d4ac06a0cbc"
    },
    {
        "pr_title": "feat: created reservation samples for update and create",
        "pr_number": 4402,
        "file_name": "compute/reservations/get_reservation.go",
        "code_diff": "@@ -25,15 +25,15 @@\nimport (\n )\n \n // Get certain reservation for given project and zone\n-func getReservation(w io.Writer, projectID, zone, reservationName string) error {\n+func getReservation(w io.Writer, projectID, zone, reservationName string) (*computepb.Reservation, error) {\n \t// projectID := \"your_project_id\"\n \t// zone := \"us-west3-a\"\n \t// reservationName := \"your_reservation_name\"\n \n \tctx := context.Background()\n \treservationsClient, err := compute.NewReservationsRESTClient(ctx)\n \tif err != nil {\n-\t\treturn err\n+\t\treturn nil, err\n \t}\n \tdefer reservationsClient.Close()",
        "comments": [],
        "commit_messages": [
            "feat: created reservartion samples for update and create"
        ],
        "last_commit_sha": "00a3d5bd95ad23a7025787071de357020515cb8e"
    },
    {
        "pr_title": "feat: created reservation samples for update and create",
        "pr_number": 4402,
        "file_name": "compute/reservations/reservations_test.go",
        "code_diff": "@@ -103,7 +103,6 @@\nfunc TestReservations(t *testing.T) {\n \t\trand.NewSource(time.Now().UnixNano()))\n \ttc := testutil.SystemTest(t)\n \tzone := \"europe-west2-b\"\n-\treservationName := fmt.Sprintf(\"test-reservation-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \ttemplateName := fmt.Sprintf(\"test-template-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_messages": [
            "feat: created reservartion samples for update and create"
        ],
        "last_commit_sha": "00a3d5bd95ad23a7025787071de357020515cb8e"
    },
    {
        "pr_title": "chore(samples): Add samples for Cloud Spanner Scheduled Backups",
        "pr_number": 4393,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -47,6 +47,7 @@\ntype sampleFuncWithContext func(ctx context.Context, w io.Writer, dbName string)\n type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string) error\n type backupSampleFuncWithoutContext func(w io.Writer, dbName, backupID string) error\n+type backupScheduleSampleFunc func(w io.Writer, dbName string, scheduleId string) error\n type createBackupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string, versionTime time.Time) error\n type instancePartitionSampleFunc func(w io.Writer, projectID, instanceID, instancePartitionID string) error",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3635de277bcaf70202097d6d379ea95bf83064d8"
    },
    {
        "pr_title": "chore(samples): Add samples for Cloud Spanner Scheduled Backups",
        "pr_number": 4393,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -488,6 +489,40 @@\nfunc TestBackupSample(t *testing.T) {\n \tassertContains(t, out, fmt.Sprintf(\"Deleted backup %s\", backupID))\n }\n \n+func TestBackupScheduleSample(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\n+\t// Set up the database for testing backup schedule operations.\n+\tmustRunSample(t, createDatabase, dbName, \"failed to create a database\")\n+\n+\tvar out string\n+\tout = runBackupScheduleSample(t, createFullBackupSchedule, dbName, \"full-backup-schedule\", \"failed to create full backup schedule\")\n+\tassertContains(t, out, \"Created full backup schedule\")\n+\tassertContains(t, out, fmt.Sprintf(\"%s/backupSchedules/%s\", dbName, \"full-backup-schedule\"))\n+\n+\tout = runBackupScheduleSample(t, createIncrementalBackupSchedule, dbName, \"incremental-backup-schedule\", \"failed to create incremental backup schedule\")\n+\tassertContains(t, out, \"Created incremental backup schedule\")\n+\tassertContains(t, out, fmt.Sprintf(\"%s/backupSchedules/%s\", dbName, \"incremental-backup-schedule\"))\n+\n+\tout = runSample(t, listBackupSchedules, dbName, \"failed to list backup schedule\")\n+\tassertContains(t, out, fmt.Sprintf(\"%s/backupSchedules/%s\", dbName, \"full-backup-schedule\"))\n+\tassertContains(t, out, fmt.Sprintf(\"%s/backupSchedules/%s\", dbName, \"incremental-backup-schedule\"))\n+\n+\tout = runBackupScheduleSample(t, getBackupSchedule, dbName, \"full-backup-schedule\", \"failed to get backup schedule\")\n+\tassertContains(t, out, fmt.Sprintf(\"%s/backupSchedules/%s\", dbName, \"full-backup-schedule\"))\n+\n+\tout = runBackupScheduleSample(t, updateBackupSchedule, dbName, \"full-backup-schedule\", \"failed to update backup schedule\")\n+\tassertContains(t, out, \"Updated backup schedule\")\n+\tassertContains(t, out, fmt.Sprintf(\"%s/backupSchedules/%s\", dbName, \"full-backup-schedule\"))\n+\n+\tout = runBackupScheduleSample(t, deleteBackupSchedule, dbName, \"full-backup-schedule\", \"failed to delete backup schedule\")\n+\tassertContains(t, out, \"Deleted backup schedule\")\n+}\n+\n func TestInstancePartitionSample(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n \tt.Parallel()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3635de277bcaf70202097d6d379ea95bf83064d8"
    },
    {
        "pr_title": "feat: create shared reservation",
        "pr_number": 4378,
        "file_name": "compute/reservations/reservations_test.go",
        "code_diff": "@@ -106,7 +106,6 @@\nfunc TestReservations(t *testing.T) {\n \ttemplateName := fmt.Sprintf(\"test-template-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \n \tvar buf bytes.Buffer\n-\n \terr := createTemplate(tc.ProjectID, templateName)\n \tif err != nil {\n \t\tt.Errorf(\"createTemplate got err: %v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "52ce7d7df01996d7c7ad15eb9511fa2026f34e03"
    },
    {
        "pr_title": "feat(firestore): Query explain and explain analyze",
        "pr_number": 4352,
        "file_name": "firestore/query_multiple_inequality_test.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage firestore\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "feat(firestore): Query explain and explain analyze"
        ],
        "last_commit_sha": "55c855d4ac5736fd80843db1da6e42701d9b63da"
    },
    {
        "pr_title": "feat(firestore): Query explain and explain analyze",
        "pr_number": 4352,
        "file_name": "firestore/query_multiple_inequality_test.go",
        "code_diff": "@@ -26,21 +27,12 @@\nimport (\n \t\"cloud.google.com/go/firestore/apiv1/admin/adminpb\"\n )\n \n-func TestMultipleInequalitiesQuery(t *testing.T) {\n-\tprojectID := os.Getenv(\"GOLANG_SAMPLES_FIRESTORE_PROJECT\")\n-\tif projectID == \"\" {\n-\t\tt.Skip(\"Skipping firestore test. Set GOLANG_SAMPLES_FIRESTORE_PROJECT.\")\n-\t}\n-\n+func setupClientAndCities(t *testing.T, projectID string) (*firestore.Client, func()) {\n \tctx := context.Background()\n \tclient, err := firestore.NewClient(ctx, projectID)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n-\tt.Cleanup(func() {\n-\t\tclient.Close()\n-\t})\n-\n \tcities := []City{\n \t\t{\n \t\t\tName:       \"San Francisco\",",
        "comments": [],
        "commit_messages": [
            "feat(firestore): Query explain and explain analyze"
        ],
        "last_commit_sha": "55c855d4ac5736fd80843db1da6e42701d9b63da"
    },
    {
        "pr_title": "fix: refactoring aiplatform samples",
        "pr_number": 4326,
        "file_name": "aiplatform/snippets/embeddings.go",
        "code_diff": "@@ -19,7 +19,7 @@\npackage snippets\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"regexp\"\n+\t\"io\"\n \n \taiplatform \"cloud.google.com/go/aiplatform/apiv1\"\n \t\"cloud.google.com/go/aiplatform/apiv1/aiplatformpb\"",
        "comments": [
            {
                "comment": "question: why are we passing in the model as a string but hard-coding the prompt in the sample?",
                "position": 25
            },
            {
                "comment": "Good catch! Just noticed that in those samples used 2 different models in test, which is not straightforward.\r\nI will move it into the sample and leave a comment",
                "position": 25
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "93c421ad3d013e0fda7f098a11494e72b89553fc"
    },
    {
        "pr_title": "fix: refactoring aiplatform samples",
        "pr_number": 4326,
        "file_name": "aiplatform/snippets/embeddings.go",
        "code_diff": "@@ -28,40 +28,37 @@\nimport (\n \t\"google.golang.org/protobuf/types/known/structpb\"\n )\n \n-func embedTexts(\n-\tproject, location string, texts []string) ([][]float32, error) {\n+// embedTexts shows how embeddings are set for text-embedding-preview-0409 model\n+func embedTexts(w io.Writer, project, location string) error {\n+\t// location := \"us-central1\"\n \tctx := context.Background()\n \n \tapiEndpoint := fmt.Sprintf(\"%s-aiplatform.googleapis.com:443\", location)\n+\tdimensionality := 5\n \tmodel := \"text-embedding-004\"\n-\ttask := \"QUESTION_ANSWERING\"\n-\tcustomOutputDimensionality := 5\n+\ttexts := []string{\"banana muffins? \", \"banana bread? banana muffins?\"}\n \n \tclient, err := aiplatform.NewPredictionClient(ctx, option.WithEndpoint(apiEndpoint))\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn err\n \t}\n \tdefer client.Close()\n \n-\tmatch := regexp.MustCompile(`^(\\w+-\\w+)`).FindStringSubmatch(apiEndpoint)\n-\tif match != nil {\n-\t\tlocation = match[1]\n-\t}\n \tendpoint := fmt.Sprintf(\"projects/%s/locations/%s/publishers/google/models/%s\", project, location, model)\n \tinstances := make([]*structpb.Value, len(texts))\n \tfor i, text := range texts {\n \t\tinstances[i] = structpb.NewStructValue(&structpb.Struct{\n \t\t\tFields: map[string]*structpb.Value{\n \t\t\t\t\"content\":   structpb.NewStringValue(text),\n-\t\t\t\t\"task_type\": structpb.NewStringValue(task),\n+\t\t\t\t\"task_type\": structpb.NewStringValue(\"QUESTION_ANSWERING\"),\n \t\t\t},\n \t\t})\n \t}\n-\toutputDimensionality := structpb.NewNullValue()\n-\toutputDimensionality = structpb.NewNumberValue(float64(customOutputDimensionality))\n \n \tparams := structpb.NewStructValue(&structpb.Struct{\n-\t\tFields: map[string]*structpb.Value{\"outputDimensionality\": outputDimensionality},\n+\t\tFields: map[string]*structpb.Value{\n+\t\t\t\"outputDimensionality\": structpb.NewNumberValue(float64(dimensionality)),\n+\t\t},\n \t})\n \n \treq := &aiplatformpb.PredictRequest{",
        "comments": [
            {
                "comment": "nit: I would keep the task_type as a string literal initialized outside of this object. Up to you!",
                "position": 45
            },
            {
                "comment": "Thanks, for your comments! \r\nIn this case I don't have strong preference, but received comments in previous PRs, to not create variables, which used only once. Therefore I am trying to follow consistent pattern",
                "position": 45
            },
            {
                "comment": "Okay, fair enough. I'll chat with the other Golang reviewers about what our preferred style should be.",
                "position": 45
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "93c421ad3d013e0fda7f098a11494e72b89553fc"
    },
    {
        "pr_title": "fix: refactoring aiplatform samples",
        "pr_number": 4326,
        "file_name": "aiplatform/snippets/embeddings.go",
        "code_diff": "@@ -71,7 +68,7 @@\nfunc embedTexts(\n \t}\n \tresp, err := client.Predict(ctx, req)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn err\n \t}\n \tembeddings := make([][]float32, len(resp.Predictions))\n \tfor i, prediction := range resp.Predictions {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "93c421ad3d013e0fda7f098a11494e72b89553fc"
    },
    {
        "pr_title": "fix: refactoring aiplatform samples",
        "pr_number": 4326,
        "file_name": "aiplatform/snippets/embeddings_preview.go",
        "code_diff": "@@ -18,7 +18,7 @@\npackage snippets\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"regexp\"\n+\t\"io\"\n \n \taiplatform \"cloud.google.com/go/aiplatform/apiv1\"\n \t\"cloud.google.com/go/aiplatform/apiv1/aiplatformpb\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "93c421ad3d013e0fda7f098a11494e72b89553fc"
    },
    {
        "pr_title": "fix: refactoring aiplatform samples",
        "pr_number": 4326,
        "file_name": "aiplatform/snippets/embeddings_preview.go",
        "code_diff": "@@ -29,38 +29,37 @@\nimport (\n \n // Embeds code query with a pre-trained, foundational model by specifying the task type as 'CODE_RETRIEVAL_QUERY'. e.g. 'Retrieve a function that adds two numbers'.\n // Embeds code block with a pre-trained, foundational model by specifying the task type as 'RETRIEVAL_DOCUMENT'. e.g. 'texts := []string{\"def func(a, b): return a + b\", \"def func(a, b): return a - b\", \"def func(a, b): return (a ** 2 + b ** 2) ** 0.5\"}'.\n-func embedTextsPreview(\n-\tapiEndpoint, project, model string, texts []string,\n-\ttask string, dimensionality *int) ([][]float32, error) {\n+// embedTextsPreview shows how embeddings are set for text-embedding-preview-0815 model\n+func embedTextsPreview(w io.Writer, projectID, location string) error {\n+\t// location := \"us-central1\"\n \tctx := context.Background()\n \n+\tapiEndpoint := fmt.Sprintf(\"%s-aiplatform.googleapis.com:443\", location)\n+\tdimensionality := 5\n+\tmodel := \"text-embedding-preview-0815\"\n+\ttexts := []string{\"banana muffins? \", \"banana bread? banana muffins?\"}\n+\n \tclient, err := aiplatform.NewPredictionClient(ctx, option.WithEndpoint(apiEndpoint))\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn err\n \t}\n \tdefer client.Close()\n \n-\tmatch := regexp.MustCompile(`^(\\w+-\\w+)`).FindStringSubmatch(apiEndpoint)\n-\tlocation := \"us-central1\"\n-\tif match != nil {\n-\t\tlocation = match[1]\n-\t}\n-\tendpoint := fmt.Sprintf(\"projects/%s/locations/%s/publishers/google/models/%s\", project, location, model)\n+\tendpoint := fmt.Sprintf(\"projects/%s/locations/%s/publishers/google/models/%s\", projectID, location, model)\n \tinstances := make([]*structpb.Value, len(texts))\n \tfor i, text := range texts {\n \t\tinstances[i] = structpb.NewStructValue(&structpb.Struct{\n \t\t\tFields: map[string]*structpb.Value{\n \t\t\t\t\"content\":   structpb.NewStringValue(text),\n-\t\t\t\t\"task_type\": structpb.NewStringValue(task),\n+\t\t\t\t\"task_type\": structpb.NewStringValue(\"CODE_RETRIEVAL_QUERY\"),\n \t\t\t},\n \t\t})\n \t}\n-\toutputDimensionality := structpb.NewNullValue()\n-\tif dimensionality != nil {\n-\t\toutputDimensionality = structpb.NewNumberValue(float64(*dimensionality))\n-\t}\n+\n \tparams := structpb.NewStructValue(&structpb.Struct{\n-\t\tFields: map[string]*structpb.Value{\"outputDimensionality\": outputDimensionality},\n+\t\tFields: map[string]*structpb.Value{\n+\t\t\t\"outputDimensionality\": structpb.NewNumberValue(float64(dimensionality)),\n+\t\t},\n \t})\n \n \treq := &aiplatformpb.PredictRequest{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "93c421ad3d013e0fda7f098a11494e72b89553fc"
    },
    {
        "pr_title": "fix: refactoring aiplatform samples",
        "pr_number": 4326,
        "file_name": "aiplatform/snippets/embeddings_preview.go",
        "code_diff": "@@ -70,7 +69,7 @@\nfunc embedTextsPreview(\n \t}\n \tresp, err := client.Predict(ctx, req)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn err\n \t}\n \tembeddings := make([][]float32, len(resp.Predictions))\n \tfor i, prediction := range resp.Predictions {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "93c421ad3d013e0fda7f098a11494e72b89553fc"
    },
    {
        "pr_title": "fix: refactoring aiplatform samples",
        "pr_number": 4326,
        "file_name": "aiplatform/snippets/embeddings_test.go",
        "code_diff": "@@ -15,6 +15,8 @@\npackage snippets\n \n import (\n+\t\"bytes\"\n+\t\"fmt\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [
            "Refactoring: getting rid of variable return"
        ],
        "last_commit_sha": "93c421ad3d013e0fda7f098a11494e72b89553fc"
    },
    {
        "pr_title": "Fix: moving function attributes inside samples, to make them self-descriptive",
        "pr_number": 4325,
        "file_name": "vertexai/function-calling/functioncalling_basic.go",
        "code_diff": "@@ -36,8 +36,7 @@\nimport (\n // - first, to convert a text into a structured function call request\n // - second, to convert a structured function call response into natural language.\n // Writes output of second call to w.\n-func functionCallsBasic(w io.Writer, prompt, projectID, location, modelName string) error {\n-\t// prompt := \"What's the weather like in Boston?\"\n+func functionCallsBasic(w io.Writer, projectID, location, modelName string) error {\n \t// location := \"us-central1\"\n \t// modelName := \"gemini-1.5-flash-001\"\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "Fix: moving function attributes inside samples, to make them self descriptive"
        ],
        "last_commit_sha": "a5eec03f8305855faccb02fcf9dc86f2b866c363"
    },
    {
        "pr_title": "Fix: moving function attributes inside samples, to make them self-descriptive",
        "pr_number": 4325,
        "file_name": "vertexai/multimodal-video-with-audio/multimodalvideoaudio.go",
        "code_diff": "@@ -27,10 +27,9 @@\nimport (\n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-// generateMultimodalContent shows how to send video to a model, writing the response to the provided io.Writer.\n-// video is a Google Cloud Storage path starting with \"gs://\"\n-func generateMultimodalContent(w io.Writer, video, projectID, location, modelName string) error {\n-\t// video := \"gs://cloud-samples-data/generative-ai/video/pixel8.mp4\"\n+// generateMultimodalContent shows how to send video and text prompts to a model, writing the response to\n+// the provided io.Writer.\n+func generateMultimodalContent(w io.Writer, projectID, location, modelName string) error {\n \t// location := \"us-central1\"\n \t// modelName := \"gemini-1.5-flash-001\"\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "a5eec03f8305855faccb02fcf9dc86f2b866c363"
    },
    {
        "pr_title": "Fix: moving function attributes inside samples, to make them self-descriptive",
        "pr_number": 4325,
        "file_name": "vertexai/multimodal-video-with-audio/multimodalvideoaudio_test.go",
        "code_diff": "@@ -26,11 +26,10 @@\nfunc Test_generateMultimodalContent(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)\n-\tvideo := \"gs://cloud-samples-data/generative-ai/video/pixel8.mp4\"\n \tlocation := \"us-central1\"\n \tmodelName := \"gemini-1.5-flash-001\"\n \n-\terr := generateMultimodalContent(buf, video, tc.ProjectID, location, modelName)\n+\terr := generateMultimodalContent(buf, tc.ProjectID, location, modelName)\n \tif err != nil {\n \t\tt.Errorf(\"Test_generateMultimodalContent: %v\", err.Error())\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "a5eec03f8305855faccb02fcf9dc86f2b866c363"
    },
    {
        "pr_title": "Fix: moving function attributes inside samples, to make them self-descriptive",
        "pr_number": 4325,
        "file_name": "vertexai/multimodal-video/multimodalvideo.go",
        "code_diff": "@@ -28,12 +28,8 @@\nimport (\n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-// generateMultimodalContent generates a response into w, based upon the prompt\n-// and video provided.\n-// video is a Google Cloud Storage path starting with \"gs://\"\n-func generateMultimodalContent(w io.Writer, prompt, video, projectID, location, modelName string) error {\n-\t// prompt := \"What is in this video?\"\n-\t// video := \"gs://cloud-samples-data/video/animals.mp4\"\n+// generateMultimodalContent generates a response into w, based upon the prompt and video.\n+func generateMultimodalContent(w io.Writer, projectID, location, modelName string) error {\n \t// location := \"us-central1\"\n \t// modelName := \"gemini-1.5-flash-001\"\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "Fix: moving function attributes inside samples, to make them self descriptive"
        ],
        "last_commit_sha": "a5eec03f8305855faccb02fcf9dc86f2b866c363"
    },
    {
        "pr_title": "Fix: moving function attributes inside samples, to make them self-descriptive",
        "pr_number": 4325,
        "file_name": "vertexai/multimodal-video/multimodalvideo_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage multimodalvideo\n \n import (\n \t\"bytes\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [
            {
                "comment": "fix: please update the test to check the generation response ([example](https://github.com/GoogleCloudPlatform/golang-samples/blob/main/vertexai/multimodal-video-with-audio/multimodalvideoaudio_test.go#L42-L52))",
                "position": 18
            }
        ],
        "commit_messages": [
            "fix: adding tests to check the output"
        ],
        "last_commit_sha": "a5eec03f8305855faccb02fcf9dc86f2b866c363"
    },
    {
        "pr_title": "Fix: moving function attributes inside samples, to make them self-descriptive",
        "pr_number": 4325,
        "file_name": "vertexai/multimodal/multimodal.go",
        "code_diff": "@@ -32,7 +32,6 @@\nfunc generateMultimodalContent(w io.Writer, projectID, location, modelName strin\n \t// location := \"us-central1\"\n \t// modelName := \"gemini-1.5-flash-001\"\n \tctx := context.Background()\n-\timage := \"gs://generativeai-downloads/images/scones.jpg\"\n \n \tclient, err := genai.NewClient(ctx, projectID, location)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "a5eec03f8305855faccb02fcf9dc86f2b866c363"
    },
    {
        "pr_title": "Fix: moving function attributes inside samples, to make them self-descriptive",
        "pr_number": 4325,
        "file_name": "vertexai/multimodal/multimodal_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage multimodal\n \n import (\n \t\"bytes\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [
            "fix: adding tests to check the output"
        ],
        "last_commit_sha": "a5eec03f8305855faccb02fcf9dc86f2b866c363"
    },
    {
        "pr_title": "Fix: moving function attributes inside samples, to make them self-descriptive",
        "pr_number": 4325,
        "file_name": "vertexai/safety-settings-multimodal/safety-settings-multimodal.go",
        "code_diff": "@@ -27,10 +27,9 @@\nimport (\n )\n \n // generateMultimodalContent generates a response into w, based upon the  provided image.\n-func generateMultimodalContent(w io.Writer, image, projectID, location, modelName string) error {\n+func generateMultimodalContent(w io.Writer, projectID, location, modelName string) error {\n \t// location := \"us-central1\"\n \t// model := \"gemini-1.5-flash-001\"\n-\t// image := \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\"\n \tctx := context.Background()\n \n \tclient, err := genai.NewClient(ctx, projectID, location)",
        "comments": [],
        "commit_messages": [
            "Fix: moving function attributes inside samples, to make them self descriptive"
        ],
        "last_commit_sha": "a5eec03f8305855faccb02fcf9dc86f2b866c363"
    },
    {
        "pr_title": "Fix: moving function attributes inside samples, to make them self-descriptive",
        "pr_number": 4325,
        "file_name": "vertexai/safety-settings/safety-settings.go",
        "code_diff": "@@ -24,11 +24,9 @@\nimport (\n )\n \n // generateContent generates text from prompt and configurations provided.\n-func generateContent(w io.Writer, prompt, projectID, location, modelName string, temperature float32) error {\n-\t// prompt := \"hello, say something mean to me.\"\n+func generateContent(w io.Writer, projectID, location, modelName string) error {\n \t// location := \"us-central1\"\n \t// model := \"gemini-1.5-flash-001\"\n-\t// temp := float32(0.8)\n \tctx := context.Background()\n \n \tclient, err := genai.NewClient(ctx, projectID, location)",
        "comments": [],
        "commit_messages": [
            "Fix: moving function attributes inside samples, to make them self descriptive"
        ],
        "last_commit_sha": "a5eec03f8305855faccb02fcf9dc86f2b866c363"
    },
    {
        "pr_title": "Fix: moving function attributes inside samples, to make them self-descriptive",
        "pr_number": 4325,
        "file_name": "vertexai/safety-settings/safety-settings.go",
        "code_diff": "@@ -38,7 +36,7 @@\nfunc generateContent(w io.Writer, prompt, projectID, location, modelName string,\n \tdefer client.Close()\n \n \tmodel := client.GenerativeModel(modelName)\n-\tmodel.SetTemperature(temperature)\n+\tmodel.SetTemperature(0.8)\n \n \t// configure the safety settings thresholds\n \tmodel.SafetySettings = []*genai.SafetySetting{",
        "comments": [],
        "commit_messages": [
            "Fix: moving function attributes inside samples, to make them self descriptive"
        ],
        "last_commit_sha": "a5eec03f8305855faccb02fcf9dc86f2b866c363"
    },
    {
        "pr_title": "fix: moved attributes inside sample",
        "pr_number": 4315,
        "file_name": "vertexai/multimodal/multimodal.go",
        "code_diff": "@@ -27,15 +27,12 @@\nimport (\n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-// generateMultimodalContent generates a response into w, based upon the prompt\n-// and image provided.\n-// image is a Google Cloud Storage path starting with \"gs://\"\n-func generateMultimodalContent(w io.Writer, prompt, image, projectID, location, modelName string) error {\n-\t// prompt := \"describe what is in this picture\"\n-\t// image := \"gs://generativeai-downloads/images/scones.jpg\"\n+// generateMultimodalContent generates a response into w, based upon the prompt and image.\n+func generateMultimodalContent(w io.Writer, projectID, location, modelName string) error {\n \t// location := \"us-central1\"\n \t// modelName := \"gemini-1.5-flash-001\"\n \tctx := context.Background()\n+\timage := \"gs://generativeai-downloads/images/scones.jpg\"\n \n \tclient, err := genai.NewClient(ctx, projectID, location)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "12caac81be12ef0f819e9e68e5ced6695f82b1ce"
    },
    {
        "pr_title": "feat(datastore): Multiple inequalities",
        "pr_number": 4311,
        "file_name": "datastore/snippets/query_test.go",
        "code_diff": "@@ -21,10 +21,14 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"log\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"cloud.google.com/go/datastore\"\n+\tadmin \"cloud.google.com/go/datastore/admin/apiv1\"\n+\t\"cloud.google.com/go/datastore/admin/apiv1/adminpb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n )\n \n var projectID string",
        "comments": [],
        "commit_messages": [
            "feat(datastore): Multiple inequalities"
        ],
        "last_commit_sha": "ecdb56d65473e97a92c3395cd36769846f384240"
    },
    {
        "pr_title": "docs: Create set_mute_undefined_finding sample",
        "pr_number": 4309,
        "file_name": "securitycenter/muteconfig/mute_config_test.go",
        "code_diff": "@@ -252,6 +252,9 @@\nfunc TestSetMuteFinding(t *testing.T) {\n \n func TestSetUnmuteFinding(t *testing.T) {\n \tt.Skip(\"see https://github.com/GoogleCloudPlatform/golang-samples/issues/3793\")\n+\t// Needs more investigation (doesn't match on missing `locations/global`)\n+\t// got:       Mute value for the finding: organizations/688851828130/sources/14743348522722609714/locations/global/findings/updated is UNDEFINED\n+\t// expected:  Mute value for the finding: organizations/688851828130/sources/14743348522722609714/findings/updated is UNDEFINED\n \ttestutil.SystemTest(t)\n \n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_messages": [
            "chore: skip test possibly related to #3793"
        ],
        "last_commit_sha": "1b927c69578b52763bd5c32afb0f06dbfdee73a0"
    },
    {
        "pr_title": "fix: moving prompt inside sample",
        "pr_number": 4305,
        "file_name": "vertexai/token-count/tokencount.go",
        "code_diff": "@@ -27,12 +27,12 @@\nimport (\n )\n \n // countTokens returns the number of tokens for this prompt.\n-func countTokens(w io.Writer, prompt, projectID, location, modelName string) error {\n-\t// prompt := \"why is the sky blue?\"\n+func countTokens(w io.Writer, projectID, location, modelName string) error {\n \t// location := \"us-central1\"\n \t// modelName := \"gemini-1.5-flash-001\"\n \n \tctx := context.Background()\n+\tprompt := genai.Text(\"Why is the sky blue?\")\n \n \tclient, err := genai.NewClient(ctx, projectID, location)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2f6557fa55bee99b74b66a49acdc3d6264d7e07f"
    },
    {
        "pr_title": "fix: Adding more complex context for weather and corresponding test",
        "pr_number": 4300,
        "file_name": "vertexai/function-calling/functioncalling_basic.go",
        "code_diff": "@@ -34,7 +34,8 @@\nimport (\n \n // functionCallsBasic opens a chat session and sends 2 messages to the model:\n // - first, to convert a text into a structured function call request\n-// - second, to convert a structured function call response into natural language\n+// - second, to convert a structured function call response into natural language.\n+// Writes output of second call to w.\n func functionCallsBasic(w io.Writer, prompt, projectID, location, modelName string) error {\n \t// prompt := \"What's the weather like in Boston?\"\n \t// location := \"us-central1\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7523ab3fc9bdbf1701b3f97c5ecc45b25f066161"
    },
    {
        "pr_title": "fix: Adding more complex context for weather and corresponding test",
        "pr_number": 4300,
        "file_name": "vertexai/function-calling/functioncalling_basic.go",
        "code_diff": "@@ -69,7 +70,6 @@\nfunc functionCallsBasic(w io.Writer, prompt, projectID, location, modelName stri\n \n \tchat := model.StartChat()\n \n-\tfmt.Fprintf(w, \"Question: %s\\n\", prompt)\n \tresp, err := chat.SendMessage(ctx, genai.Text(prompt))\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [
            "fix: Adding more complex context for weather and corresponding test"
        ],
        "last_commit_sha": "7523ab3fc9bdbf1701b3f97c5ecc45b25f066161"
    },
    {
        "pr_title": "fix: Adding more complex context for weather and corresponding test",
        "pr_number": 4300,
        "file_name": "vertexai/function-calling/functioncalling_basic.go",
        "code_diff": "@@ -81,25 +81,34 @@\nfunc functionCallsBasic(w io.Writer, prompt, projectID, location, modelName stri\n \n \t// The model has returned a function call to the declared function `getCurrentWeather`\n \t// with a value for the argument `location`.\n-\tjsondata, err := json.MarshalIndent(resp.Candidates[0].Content.Parts[0], \"\", \"  \")\n+\t_, err = json.MarshalIndent(resp.Candidates[0].Content.Parts[0], \"\", \"  \")\n \tif err != nil {\n \t\treturn fmt.Errorf(\"json.MarshalIndent: %w\", err)\n \t}\n-\tfmt.Fprintf(w, \"function call generated by the model:\\n%s\\n\\n\", string(jsondata))\n+\n+\t// In this example, we'll use synthetic data to simulate a response payload from an external API\n+\tweather := map[string]string{\n+\t\t\"location\":    \"Boston\",\n+\t\t\"temperature\": \"38\",\n+\t\t\"description\": \"Partly Cloudy\",\n+\t\t\"icon\":        \"partly-cloudy\",\n+\t\t\"humidity\":    \"65\",\n+\t\t\"wind\":        \"{\\\"speed\\\": \\\"10\\\", \\\"direction\\\": \\\"NW\\\"}\",\n+\t}\n+\tweather_json, _ := json.Marshal(weather)\n \n \t// Create a function call response, to simulate the result of a call to a\n \t// real service\n \tfunresp := &genai.FunctionResponse{\n \t\tName: \"getCurrentWeather\",\n \t\tResponse: map[string]any{\n-\t\t\t\"currentWeather\": \"sunny\",\n+\t\t\t\"currentWeather\": weather_json,\n \t\t},\n \t}\n-\tjsondata, err = json.MarshalIndent(funresp, \"\", \"  \")\n+\t_, err = json.MarshalIndent(funresp, \"\", \"  \")\n \tif err != nil {\n \t\treturn fmt.Errorf(\"json.MarshalIndent: %w\", err)\n \t}\n-\tfmt.Fprintf(w, \"function call response sent to the model:\\n%s\\n\\n\", string(jsondata))\n \n \t// And provide the function call response to the model\n \tresp, err = chat.SendMessage(ctx, funresp)",
        "comments": [],
        "commit_messages": [
            "fix: Adding more complex context for weather and corresponding test"
        ],
        "last_commit_sha": "7523ab3fc9bdbf1701b3f97c5ecc45b25f066161"
    },
    {
        "pr_title": "fix: Adding more complex context for weather and corresponding test",
        "pr_number": 4300,
        "file_name": "vertexai/function-calling/functioncalling_test.go",
        "code_diff": "@@ -15,7 +15,8 @@\npackage functioncalling\n \n import (\n-\t\"io\"\n+\t\"bytes\"\n+\t\"strings\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7523ab3fc9bdbf1701b3f97c5ecc45b25f066161"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "vertexai/multimodal-pdf/pdf.go",
        "code_diff": "@@ -25,26 +25,11 @@\nimport (\n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-// pdfPrompt is a sample prompt type consisting of one PDF asset, and a text question.\n-type pdfPrompt struct {\n-\t// pdfPath is a Google Cloud Storage path starting with \"gs://\"\n-\tpdfPath string\n-\t// question asked to the model\n-\tquestion string\n-}\n-\n // generateContentFromPDF generates a response into the provided io.Writer, based upon the PDF\n-// asset and the question provided in the multimodal prompt.\n-func generateContentFromPDF(w io.Writer, prompt pdfPrompt, projectID, location, modelName string) error {\n-\t// prompt := pdfPrompt{\n-\t// \tpdfPath: \"gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf\",\n-\t// \tquestion: `\n-\t// \t\tYou are a very professional document summarization specialist.\n-\t// \t\tPlease summarize the given document.\n-\t// \t`,\n-\t// }\n+func generateContentFromPDF(w io.Writer, projectID, location, modelName string) error {\n \t// location := \"us-central1\"\n \t// modelName := \"gemini-1.5-flash-001\"\n+\n \tctx := context.Background()\n \n \tclient, err := genai.NewClient(ctx, projectID, location)",
        "comments": [],
        "commit_messages": [
            "fix: simpify sample structure"
        ],
        "last_commit_sha": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: simpify sample structure",
        "pr_number": 4298,
        "file_name": "vertexai/multimodal-pdf/pdf_test.go",
        "code_diff": "@@ -25,18 +25,11 @@\nimport (\n func Test_generateContentFromPDF(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n-\tprompt := pdfPrompt{\n-\t\tpdfPath: \"gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf\",\n-\t\tquestion: `\n-\t\t\tYou are a very professional document summarization specialist.\n-    \t\tPlease summarize the given document.\n-\t\t`,\n-\t}\n+\tvar buf bytes.Buffer\n \tlocation := \"us-central1\"\n \tmodelName := \"gemini-1.5-flash-001\"\n \n-\terr := generateContentFromPDF(buf, prompt, tc.ProjectID, location, modelName)\n+\terr := generateContentFromPDF(&buf, tc.ProjectID, location, modelName)\n \tif err != nil {\n \t\tt.Errorf(\"Test_generateContentFromPDF: %v\", err.Error())\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1e67e4da24ee76fea5986af3c794f26ca987f5ef"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/auto_punctuation.go",
        "code_diff": "@@ -31,7 +31,7 @@\nimport (\n \n // [START speech_transcribe_auto_punctuation]\n \n-func autoPunctuation(w io.Writer, path string) error {\n+func autoPunctuation(w io.Writer) error {\n \tctx := context.Background()\n \n \tclient, err := speech.NewClient(ctx)",
        "comments": [],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/context_classes.go",
        "code_diff": "@@ -29,7 +29,7 @@\nimport (\n \n // contextClasses provides \"hints\" to the speech recognizer\n // to favour specific classes of words in the results.\n-func contextClasses(w io.Writer, gcsURI string) error {\n+func contextClasses(w io.Writer) error {\n \tctx := context.Background()\n \n \tclient, err := speech.NewClient(ctx)",
        "comments": [],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/enhanced_model.go",
        "code_diff": "@@ -31,7 +31,7 @@\nimport (\n \n // [START speech_transcribe_enhanced_model]\n \n-func enhancedModel(w io.Writer, path string) error {\n+func enhancedModel(w io.Writer) error {\n \tctx := context.Background()\n \n \tclient, err := speech.NewClient(ctx)",
        "comments": [],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/model_selection.go",
        "code_diff": "@@ -31,7 +31,7 @@\nimport (\n \n // [START speech_transcribe_model_selection]\n \n-func modelSelection(w io.Writer, path string) error {\n+func modelSelection(w io.Writer) error {\n \tctx := context.Background()\n \n \tclient, err := speech.NewClient(ctx)",
        "comments": [],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/multichannel.go",
        "code_diff": "@@ -28,7 +28,7 @@\nimport (\n // [START speech_transcribe_multichannel_beta]\n \n // transcribeMultichannel generates a transcript from a multichannel speech file and tags the speech from each channel.\n-func transcribeMultichannel(w io.Writer, path string) error {\n+func transcribeMultichannel(w io.Writer) error {\n \tctx := context.Background()\n \n \tclient, err := speech.NewClient(ctx)",
        "comments": [],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/transcribe_diarization.go",
        "code_diff": "@@ -27,9 +27,8 @@\nimport (\n )\n \n // transcribe_diarization_gcs_beta Transcribes a remote audio file using speaker diarization.\n-func transcribe_diarization_gcs_beta(w io.Writer, gcsUri string) error {\n+func transcribe_diarization_gcs_beta(w io.Writer) error {\n \t// Google Cloud Storage URI pointing to the audio content.\n-\t// gcsUri := \"gs://bucket-name/path_to_audio_file\"\n \n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/transcribe_diarization_beta.go",
        "code_diff": "@@ -28,8 +28,7 @@\nimport (\n )\n \n // transcribe_diarization_gcs_beta Transcribes a remote audio file using speaker diarization.\n-func transcribe_diarization(w io.Writer, filename string) error {\n-\t// filename := \"path-to-an-audio-file\"\n+func transcribe_diarization(w io.Writer) error {\n \n \tctx := context.Background()\n \tclient, err := speech.NewClient(ctx)",
        "comments": [],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/transcribe_model_selection_gcs.go",
        "code_diff": "@@ -28,13 +28,7 @@\nimport (\n \n // transcribe_model_selection_gcs Transcribes the given audio file asynchronously with\n // the selected model.\n-func transcribe_model_selection_gcs(w io.Writer, gcsUri string, model string) error {\n-\t// Google Cloud Storage URI pointing to the audio content.\n-\t// gcsUri := \"gs://bucket-name/path_to_audio_file\"\n-\n-\t// The speech recognition model to use\n-\t// See, https://cloud.google.com/speech-to-text/docs/speech-to-text-requests#select-model\n-\t// model := \"default\"\n+func transcribe_model_selection_gcs(w io.Writer) error {\n \tctx := context.Background()\n \n \tclient, err := speech.NewClient(ctx)",
        "comments": [
            {
                "comment": "Nice \ud83d\udc4d ",
                "position": 30
            }
        ],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/transcribe_streaming_v2_test.go",
        "code_diff": "@@ -16,7 +16,6 @@\npackage snippets\n \n import (\n \t\"bytes\"\n-\t\"os\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/transcribe_test.go",
        "code_diff": "@@ -24,9 +24,7 @@\nimport (\n )\n \n var bucket = \"cloud-samples-tests\"\n-var gcsVideoPath = \"gs://\" + bucket + \"/speech/Google_Gnome.wav\"\n var recognitionAudioFile = \"../resources/commercial_mono.wav\"\n-var gcsDiarizationAudioPath = \"gs://\" + bucket + \"/speech/commercial_mono.wav\"\n \n func TestMain(m *testing.M) {\n \texitCode := m.Run()",
        "comments": [],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/transcribe_test.go",
        "code_diff": "@@ -37,7 +35,7 @@\nfunc TestTranscribeModelSelectionGcs(t *testing.T) {\n \ttestutil.SystemTest(t)\n \n \tvar buf bytes.Buffer\n-\tif err := transcribe_model_selection_gcs(&buf, gcsVideoPath, \"video\"); err != nil {\n+\tif err := transcribe_model_selection_gcs(&buf); err != nil {\n \t\tt.Fatalf(\"error in transcribe model selection gcs %v\", err)\n \t}\n \tif got := buf.String(); !strings.Contains(got, \"Transcript:\") {",
        "comments": [],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "fix: refactor variables to make samples more self-descriptive",
        "pr_number": 4287,
        "file_name": "speech/snippets/transcribe_test.go",
        "code_diff": "@@ -49,7 +47,7 @@\nfunc TestTranscribeDiarizationBeta(t *testing.T) {\n \ttestutil.SystemTest(t)\n \n \tvar buf bytes.Buffer\n-\tif err := transcribe_diarization(&buf, recognitionAudioFile); err != nil {\n+\tif err := transcribe_diarization(&buf); err != nil {\n \t\tt.Fatalf(\"error in transcribe diarization %v\", err)\n \t}\n \tif got := buf.String(); !strings.Contains(got, \"Speaker\") {",
        "comments": [],
        "commit_messages": [
            "fix: refactor variables to make samples more self-descriptive"
        ],
        "last_commit_sha": "39f5a0df5f4cc3fcceffa8873b5cb02425336713"
    },
    {
        "pr_title": "feat(findings): Add findings v2 resources",
        "pr_number": 4270,
        "file_name": "securitycenter/findingsv2/findings_test.go",
        "code_diff": "@@ -79,46 +79,97 @@\nfunc createTestFinding(ctx context.Context, client *securitycenter.Client, findi\n \treturn finding, nil\n }\n \n+func disableTestFinding(ctx context.Context, client *securitycenter.Client, findingName string) error {\n+\n+\treq := &securitycenterpb.UpdateFindingRequest{\n+\t\tFinding: &securitycenterpb.Finding{\n+\t\t\tName:  findingName,\n+\t\t\tState: securitycenterpb.Finding_INACTIVE,\n+\t\t},\n+\t}\n+\t_, err := client.UpdateFinding(ctx, req)\n+\treturn err\n+}\n+\n+func clearSecurityMarks(ctx context.Context, client *securitycenter.Client, findingName string) error {\n+\treq := &securitycenterpb.UpdateSecurityMarksRequest{\n+\t\tSecurityMarks: &securitycenterpb.SecurityMarks{\n+\t\t\tName: findingName + \"/securityMarks\",\n+\t\t},\n+\t}\n+\t_, err := client.UpdateSecurityMarks(ctx, req)\n+\treturn err\n+}\n+\n // setupEntities initializes variables in this file with entityNames to\n // use for testing.\n-func setupEntities() (func(), error) {\n+func setupEntities() error {\n \torgID = os.Getenv(\"GCLOUD_ORGANIZATION\")\n \tif orgID == \"\" {\n \t\t// Each test checks for GCLOUD_ORGANIZATION. Return nil so we see every skip.\n-\t\treturn nil, nil\n+\t\treturn nil\n \t}\n \tctx := context.Background()\n \tclient, err := securitycenter.NewClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"securitycenter.NewClient: %w\", err)\n+\t\treturn fmt.Errorf(\"securitycenter.NewClient: %w\", err)\n \t}\n-\tdefer client.Close()\n-\n-\tsource, err := client.CreateSource(ctx, &securitycenterpb.CreateSourceRequest{\n-\t\tSource: &securitycenterpb.Source{\n-\t\t\tDisplayName: \"Customized Display Name\",\n-\t\t\tDescription: \"A new custom source that does X\",\n-\t\t},\n-\t\tParent: fmt.Sprintf(\"organizations/%s\", orgID),\n-\t})\n+\tdefer client.Close() // Closing the client safely cleans up background resources.\n \n-\tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"CreateSource: %w\", err)\n+\tvar buf bytes.Buffer\n+\tif err := createSource(&buf, orgID); err != nil {\n+\t\treturn fmt.Errorf(\"createSource: %w\", err)\n \t}\n-\tsourceName = source.Name\n+\n+\tsourceInfo := strings.Split(buf.String(), \":\")[1]\n+\tsourceName = strings.TrimSpace(strings.Split(sourceInfo, \"\\n\")[0])\n \n \tfinding, err := createTestFinding(ctx, client, \"updated\", \"MEDIUM_RISK_ONE\")\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"createTestFinding: %w\", err)\n+\t\treturn fmt.Errorf(\"createTestFinding: %w\", err)\n \t}\n \tfindingName = finding.Name\n \tfinding, err = createTestFinding(ctx, client, \"untouched\", \"XSS\")\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"createTestFinding: %w\", err)\n+\t\treturn fmt.Errorf(\"createTestFinding: %w\", err)\n \t}\n \tuntouchedFindingName = finding.Name\n+\treturn nil\n+}\n+\n+func cleanupEntities() error {\n+\tif orgID == \"\" || sourceName == \"\" {\n+\t\treturn nil\n+\t}\n+\tctx := context.Background()\n+\tclient, err := securitycenter.NewClient(ctx)\n+\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"securitycenter.NewClient: %w\", err)\n+\t}\n \n-\treturn nil, nil\n+\tdefer client.Close()\n+\n+\tif findingName != \"\" {\n+\t\tif err := disableTestFinding(ctx, client, findingName); err != nil {\n+\t\t\treturn fmt.Errorf(\"disableTestFinding: %w\", err)\n+\t\t}\n+\n+\t\tif err := clearSecurityMarks(ctx, client, findingName); err != nil {\n+\t\t\treturn fmt.Errorf(\"clearSecurityMarks: %w\", err)\n+\t\t}\n+\t}\n+\n+\tif untouchedFindingName != \"\" {\n+\t\tif err := disableTestFinding(ctx, client, untouchedFindingName); err != nil {\n+\t\t\treturn fmt.Errorf(\"disableTestFinding: %w\", err)\n+\t\t}\n+\n+\t\tif err := clearSecurityMarks(ctx, client, untouchedFindingName); err != nil {\n+\t\t\treturn fmt.Errorf(\"clearSecurityMarks: %w\", err)\n+\t\t}\n+\t}\n+\treturn nil\n }\n \n func setup(t *testing.T) string {",
        "comments": [
            {
                "comment": "Please delete the objects created in setupEntities before exiting from TestMain.",
                "position": 135
            },
            {
                "comment": "Addressed",
                "position": 135
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "a0ff30c5a5484683b5dd91cfe8f0804aa487b1d0"
    },
    {
        "pr_title": "feat(findings): Add findings v2 resources",
        "pr_number": 4270,
        "file_name": "securitycenter/findingsv2/findings_test.go",
        "code_diff": "@@ -133,17 +184,132 @@\nfunc setup(t *testing.T) string {\n }\n \n func TestMain(m *testing.M) {\n-\t_, err := setupEntities()\n-\tif err != nil {\n+\tif err := setupEntities(); err != nil {\n \t\tfmt.Fprintf(os.Stderr, \"Unable to initialize findings test environment: %v\\n\", err)\n+\t\treturn\n \t}\n \tcode := m.Run()\n-\n-\tif err != nil {\n-\t\tos.Exit(1)\n-\t} else {\n-\t\tos.Exit(code)\n+\tif err := cleanupEntities(); err != nil {\n+\t\tfmt.Fprintf(os.Stderr, \"Unable to clean up findings test environment: %v\\n\", err)\n \t}\n+\tos.Exit(code)\n+}\n+\n+func TestCreateSource(t *testing.T) {\n+\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\t\torgID := setup(t)\n+\t\tvar buf bytes.Buffer\n+\n+\t\terr := createSource(&buf, orgID)\n+\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"createSource(%s) had error: %v\", orgID, err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"New source created\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"createSource(%s) got: %s want %s\", orgID, got, want)\n+\t\t}\n+\t\tif !strings.Contains(got, orgID) {\n+\t\t\tr.Errorf(\"createSource(%s) got: %s want %s\", orgID, got, orgID)\n+\t\t}\n+\t})\n+}\n+\n+func TestGetSource(t *testing.T) {\n+\tsetup(t)\n+\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\t\tvar buf bytes.Buffer\n+\n+\t\terr := getSource(&buf, sourceName)\n+\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getSource(%s) had error: %v\", sourceName, err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"Description: A new custom source that does X\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"getSource(%s) got: %s want %s\", sourceName, got, want)\n+\t\t}\n+\t\tif !strings.Contains(got, orgID) {\n+\t\t\tr.Errorf(\"getSource(%s) got: %s want %s\", sourceName, got, sourceName)\n+\t\t}\n+\t})\n+}\n+\n+func TestListSources(t *testing.T) {\n+\tsetup(t)\n+\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\t\tvar buf bytes.Buffer\n+\n+\t\terr := listSources(&buf, orgID)\n+\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"listSource(%s) had error: %v\", orgID, err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"Description: A new custom source that does X\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"listSource(%s) got: %s want %s\", orgID, got, want)\n+\t\t}\n+\t\tif !strings.Contains(got, sourceName) {\n+\t\t\tr.Errorf(\"listSource(%s) got: %s want %s\", orgID, got, sourceName)\n+\t\t}\n+\t})\n+}\n+\n+func TestUpdateSource(t *testing.T) {\n+\tsetup(t)\n+\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\t\tvar buf bytes.Buffer\n+\n+\t\terr := updateSource(&buf, sourceName)\n+\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"updateSource(%s) had error: %v\", sourceName, err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"Display name: New Display Name\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"updateSource(%s) got: %s want %s\", sourceName, got, want)\n+\t\t}\n+\t\tif !strings.Contains(got, sourceName) {\n+\t\t\tr.Errorf(\"updateSource(%s) got: %s want %s\", sourceName, got, sourceName)\n+\t\t}\n+\t\tif want := \"does X\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"updateSource(%s) got: %s want %s\", sourceName, got, want)\n+\t\t}\n+\n+\t})\n+}\n+\n+func TestListAllFindings(t *testing.T) {\n+\t// issue #3260 tracks this test skip.\u00df\n+\tt.Skip()\n+\ttestutil.Retry(t, 5, 20*time.Second, func(r *testutil.R) {\n+\t\torgID := setup(t)\n+\t\tvar buf bytes.Buffer\n+\n+\t\terr := listFindings(&buf, orgID)\n+\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"listFindings(%s) had error: %v\", orgID, err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\tif !strings.Contains(got, findingName) {\n+\t\t\tr.Errorf(\"listFindings(%s) got: %s want %s\", orgID, got, findingName)\n+\t\t}\n+\n+\t\tif !strings.Contains(got, untouchedFindingName) {\n+\t\t\tr.Errorf(\"listFindings(%s) got: %s want %s\", orgID, got, untouchedFindingName)\n+\t\t}\n+\t})\n }\n \n func TestCreateFinding(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "a0ff30c5a5484683b5dd91cfe8f0804aa487b1d0"
    },
    {
        "pr_title": "feat(findings): Add findings v2 resources",
        "pr_number": 4270,
        "file_name": "securitycenter/findingsv2/findings_test.go",
        "code_diff": "@@ -157,7 +323,6 @@\nfunc TestCreateFinding(t *testing.T) {\n \t\t\tr.Errorf(\"createFinding(%s) had error: %v\", sourceName, err)\n \t\t\treturn\n \t\t}\n-\n \t\tgot := buf.String()\n \t\tif want := fmt.Sprintf(\"%s/locations/global/findings/samplefindingid\", sourceName); !strings.Contains(got, want) {\n \t\t\tr.Errorf(\"createFinding(%s) got: %s want %s\", sourceName, got, want)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "a0ff30c5a5484683b5dd91cfe8f0804aa487b1d0"
    },
    {
        "pr_title": "feat(findings): Add findings v2 resources",
        "pr_number": 4270,
        "file_name": "securitycenter/findingsv2/findings_test.go",
        "code_diff": "@@ -199,6 +364,101 @@\nfunc TestUpdateFindingSourceProperties(t *testing.T) {\n \t})\n }\n \n+func TestListFilteredFindings(t *testing.T) {\n+\tsetup(t)\n+\ttestutil.Retry(t, 5, 20*time.Second, func(r *testutil.R) {\n+\t\tvar buf bytes.Buffer\n+\n+\t\terr := listFilteredFindings(&buf, sourceName)\n+\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"listFilteredFindings(%s) had error: %v\", sourceName, err)\n+\t\t\treturn\n+\t\t}\n+\t\tgot := buf.String()\n+\t\tif !strings.Contains(got, findingName) {\n+\t\t\tr.Errorf(\"listFilteredFindings(%s) got: %s want %s\", sourceName, got, findingName)\n+\t\t}\n+\n+\t\tif strings.Contains(got, untouchedFindingName) {\n+\t\t\tr.Errorf(\"listFilteredFindings(%s) got: %s didn't want %s\", sourceName, got, untouchedFindingName)\n+\t\t}\n+\t})\n+}\n+\n+func TestAddSecurityMarks(t *testing.T) {\n+\tsetup(t)\n+\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\t\tvar buf bytes.Buffer\n+\n+\t\terr := addSecurityMarks(&buf, findingName)\n+\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"addSecurityMarks(%s) adding marks had error: %v\", findingName, err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"key_a = value_a\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"addSecurityMarks(%s) got: %s want %s\", findingName, got, want)\n+\t\t}\n+\n+\t\tif want := \"key_b = value_b\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"addSecurityMarks(%s) got: %s want %s\", findingName, got, want)\n+\t\t}\n+\t})\n+}\n+\n+func TestListFindingsWithMarks(t *testing.T) {\n+\ttestutil.Retry(t, 5, 20*time.Second, func(r *testutil.R) {\n+\t\torgID := setup(t)\n+\t\tvar buf bytes.Buffer\n+\t\t// Ensure security marks have been added so filter is effective.\n+\t\terr := addSecurityMarks(&buf, findingName)\n+\t\tbuf.Reset()\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"listFindingsWithMark(%s) adding marks had error: %v\", findingName, err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\terr = listFindingsWithMarks(&buf, sourceName)\n+\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"listFindingsWithMark(%s) had error: %v\", sourceName, err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\tif !strings.Contains(got, untouchedFindingName) {\n+\t\t\tr.Errorf(\"listFindingWithMarks(%s) got: %s want %s\", sourceName, got, untouchedFindingName)\n+\t\t}\n+\n+\t\tif strings.Contains(got, findingName) {\n+\t\t\tr.Errorf(\"listFindingWithMarks(%s) got: %s didn't want %s\", orgID, got, findingName)\n+\t\t}\n+\n+\t})\n+}\n+\n+func TestGroupFindings(t *testing.T) {\n+\torgID := setup(t)\n+\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\t\tvar buf bytes.Buffer\n+\n+\t\terr := groupFindings(&buf, orgID)\n+\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"groupFindings(%s) had error: %v\", orgID, err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"Grouped Finding\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"groupFindings(%s) got: %s want %s\", orgID, got, want)\n+\t\t}\n+\t})\n+}\n+\n func TestSetFindingState(t *testing.T) {\n \tsetup(t)\n \ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "a0ff30c5a5484683b5dd91cfe8f0804aa487b1d0"
    },
    {
        "pr_title": "feat: create job with notification sample",
        "pr_number": 4266,
        "file_name": "batch/job_basics_test.go",
        "code_diff": "@@ -22,6 +22,7 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/batch/apiv1/batchpb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_messages": [
            "feat: create job with notification sample"
        ],
        "last_commit_sha": "b1105451d6abac3e0cea804d2d63df43a5162966"
    },
    {
        "pr_title": "feat: added labels samples for secret manager",
        "pr_number": 4253,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -98,6 +98,9 @@\nfunc testSecret(tb testing.TB, projectID string) *secretmanagerpb.Secret {\n \t\t\t\t\tAutomatic: &secretmanagerpb.Replication_Automatic{},\n \t\t\t\t},\n \t\t\t},\n+\t\t\tLabels: map[string]string{\n+\t\t\t\t\"labelkey\": \"labelvalue\",\n+\t\t\t},\n \t\t},\n \t})\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "34880db369ef13be7a10500e59bc08ac470ab402"
    },
    {
        "pr_title": "feat: added labels samples for secret manager",
        "pr_number": 4253,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -295,30 +298,46 @@\nfunc TestCreateSecret(t *testing.T) {\n \tsecretID := \"createSecret\"\n \n \tparent := fmt.Sprintf(\"projects/%s\", tc.ProjectID)\n-\tdefer testCleanupSecret(t, fmt.Sprintf(\"projects/%s/secrets/%s\", tc.ProjectID, secretID))\n \n \tvar b bytes.Buffer\n \tif err := createSecret(&b, parent, secretID); err != nil {\n \t\tt.Fatal(err)\n \t}\n+\tdefer testCleanupSecret(t, fmt.Sprintf(\"projects/%s/secrets/%s\", tc.ProjectID, secretID))\n \n \tif got, want := b.String(), \"Created secret:\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"createSecret: expected %q to contain %q\", got, want)\n \t}\n }\n \n+func TestCreateSecretWithLabels(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecretID := \"createSecretWithLabels\"\n+\n+\tparent := fmt.Sprintf(\"projects/%s\", tc.ProjectID)\n+\n+\tvar b bytes.Buffer\n+\tif err := createSecretWithLabels(&b, parent, secretID); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tdefer testCleanupSecret(t, fmt.Sprintf(\"projects/%s/secrets/%s\", tc.ProjectID, secretID))\n+\n+\tif got, want := b.String(), \"Created secret with labels:\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"createSecretWithLabels: expected %q to contain %q\", got, want)\n+\t}\n+}\n func TestCreateRegionalSecret(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n \tsecretID := \"createRegionalSecret\"\n \tlocationID := testLocation(t)\n \n-\tdefer testCleanupRegionalSecret(t, fmt.Sprintf(\"projects/%s/locations/%s/secrets/%s\", tc.ProjectID, locationID, secretID))\n-\n \tvar b bytes.Buffer\n \tif err := regional_secretmanager.CreateRegionalSecret(&b, tc.ProjectID, locationID, secretID); err != nil {\n \t\tt.Fatal(err)\n \t}\n+\tdefer testCleanupRegionalSecret(t, fmt.Sprintf(\"projects/%s/locations/%s/secrets/%s\", tc.ProjectID, locationID, secretID))\n \n \tif got, want := b.String(), \"Created regional secret:\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"createSecret: expected %q to contain %q\", got, want)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "34880db369ef13be7a10500e59bc08ac470ab402"
    },
    {
        "pr_title": "feat: added labels samples for secret manager",
        "pr_number": 4253,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -332,12 +351,12 @@\nfunc TestCreateUserManagedReplicationSecret(t *testing.T) {\n \tlocations := []string{\"us-east1\", \"us-east4\", \"us-west1\"}\n \n \tparent := fmt.Sprintf(\"projects/%s\", tc.ProjectID)\n-\tdefer testCleanupSecret(t, fmt.Sprintf(\"projects/%s/secrets/%s\", tc.ProjectID, secretID))\n \n \tvar b bytes.Buffer\n \tif err := createUserManagedReplicationSecret(&b, parent, secretID, locations); err != nil {\n \t\tt.Fatal(err)\n \t}\n+\tdefer testCleanupSecret(t, fmt.Sprintf(\"projects/%s/secrets/%s\", tc.ProjectID, secretID))\n \n \tif got, want := b.String(), \"Created secret with user managed replication:\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"createUserManagedReplicationSecret: expected %q to contain %q\", got, want)",
        "comments": [],
        "commit_messages": [
            "fix: reoslved comments"
        ],
        "last_commit_sha": "34880db369ef13be7a10500e59bc08ac470ab402"
    },
    {
        "pr_title": "feat: added labels samples for secret manager",
        "pr_number": 4253,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -363,6 +382,30 @@\nfunc TestDeleteSecret(t *testing.T) {\n \t}\n }\n \n+func TestDeleteSecretLabel(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n+\tvar b bytes.Buffer\n+\tif err := deleteSecretLabel(&b, secret.Name); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testClient(t)\n+\ts, err := client.GetSecret(ctx, &secretmanagerpb.GetSecretRequest{\n+\t\tName: secret.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := s.Labels, map[string]string{}; reflect.DeepEqual(got, want) {\n+\t\tt.Errorf(\"deleteSecretLabel: expected %q to be %q\", got, want)\n+\t}\n+}\n+\n func TestDeleteRegionalSecret(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "34880db369ef13be7a10500e59bc08ac470ab402"
    },
    {
        "pr_title": "feat: added labels samples for secret manager",
        "pr_number": 4253,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -382,6 +425,7 @@\nfunc TestDeleteRegionalSecret(t *testing.T) {\n \tif terr, ok := grpcstatus.FromError(err); !ok || terr.Code() != grpccodes.NotFound {\n \t\tt.Errorf(\"deleteRegionalSecret: expected %v to be not found\", err)\n \t}\n+\n }\n \n func TestDeleteSecretWithEtag(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "34880db369ef13be7a10500e59bc08ac470ab402"
    },
    {
        "pr_title": "feat: added labels samples for secret manager",
        "pr_number": 4253,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -1021,6 +1065,34 @@\nfunc TestListSecrets(t *testing.T) {\n \t}\n }\n \n+func TestViewSecretLabels(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n+\tvar b bytes.Buffer\n+\tif err := viewSecretLabels(&b, secret.Name); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Found secret\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"viewSecretLabels: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tclient, ctx := testClient(t)\n+\ts, err := client.GetSecret(ctx, &secretmanagerpb.GetSecretRequest{\n+\t\tName: secret.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := s.Labels, map[string]string{\"labelkey\": \"labelvalue\"}; !reflect.DeepEqual(got, want) {\n+\t\tt.Errorf(\"viewSecretLabels: expected %q to be %q\", got, want)\n+\t}\n+}\n+\n func TestListRegionalSecrets(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "34880db369ef13be7a10500e59bc08ac470ab402"
    },
    {
        "pr_title": "feat: added labels samples for secret manager",
        "pr_number": 4253,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -1122,6 +1194,35 @@\nfunc TestUpdateSecret(t *testing.T) {\n \t}\n }\n \n+func TestCreateUpdateSecretLabel(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n+\tvar b bytes.Buffer\n+\tif err := createUpdateSecretLabel(&b, secret.Name); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Updated secret\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"updateSecret: expected %q to contain %q\", got, want)\n+\t}\n+\n+\tclient, ctx := testClient(t)\n+\n+\ts, err := client.GetSecret(ctx, &secretmanagerpb.GetSecretRequest{\n+\t\tName: secret.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := s.Labels, map[string]string{\"labelkey\": \"updatedlabelvalue\"}; !reflect.DeepEqual(got, want) {\n+\t\tt.Errorf(\"createUpdateSecretLabel: expected %q to be %q\", got, want)\n+\t}\n+}\n+\n func TestRegionalUpdateSecret(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "34880db369ef13be7a10500e59bc08ac470ab402"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -24,7 +24,6 @@\nimport (\n )\n \n // [START job_create_company]\n-// [START create_company]\n \n // createCompany creates a company as given.\n func createCompany(w io.Writer, projectID string, companyToCreate *talent.Company) (*talent.Company, error) {",
        "comments": [],
        "commit_messages": [
            "Merge branch 'main' into jobs/basic_company_sample"
        ],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -52,11 +51,9 @@\nfunc createCompany(w io.Writer, projectID string, companyToCreate *talent.Compan\n \treturn company, nil\n }\n \n-// [END create_company]\n // [END job_create_company]\n \n // [START job_get_company]\n-// [START get_company]\n \n // getCompany gets an existing company by name.\n func getCompany(w io.Writer, name string) (*talent.Company, error) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -82,11 +79,9 @@\nfunc getCompany(w io.Writer, name string) (*talent.Company, error) {\n \treturn company, nil\n }\n \n-// [END get_company]\n // [END job_get_company]\n \n // [START job_update_company]\n-// [START update_company]\n \n // updateCompany update a company with all fields.\n func updateCompany(w io.Writer, name string, companyToUpdate *talent.Company) (*talent.Company, error) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -113,11 +108,9 @@\nfunc updateCompany(w io.Writer, name string, companyToUpdate *talent.Company) (*\n \treturn company, nil\n }\n \n-// [END update_company]\n // [END job_update_company]\n \n // [START job_update_company_with_field_mask]\n-// [START update_company_with_field_mask]\n \n // updateCompanyWithMask updates a company with specific fields.\n // mask is a comma separated list of top-level fields of talent.Company.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -146,11 +139,9 @@\nfunc updateCompanyWithMask(w io.Writer, name string, mask string, companyToUpdat\n \treturn company, nil\n }\n \n-// [END update_company_with_field_mask]\n // [END job_update_company_with_field_mask]\n \n // [START job_delete_company]\n-// [START delete_company]\n \n // deleteCompany deletes an existing company by name.\n func deleteCompany(w io.Writer, name string) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/basic_company_sample.go",
        "code_diff": "@@ -173,11 +164,9 @@\nfunc deleteCompany(w io.Writer, name string) error {\n \treturn nil\n }\n \n-// [END delete_company]\n // [END job_delete_company]\n \n // [START job_list_companies]\n-// [START list_companies]\n \n // listCompanies lists all companies in the project.\n func listCompanies(w io.Writer, projectID string) (*talent.ListCompaniesResponse, error) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -84,7 +84,6 @@\nfunc getJob(w io.Writer, jobName string) (*talent.Job, error) {\n // [END job_get_job]\n \n // [START job_update_job]\n-// [START update_job]\n \n // updateJob update a job with all fields except name.\n func updateJob(w io.Writer, jobName string, jobToUpdate *talent.Job) (*talent.Job, error) {",
        "comments": [],
        "commit_messages": [
            "fix: delete obsolete region tag"
        ],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -111,11 +110,9 @@\nfunc updateJob(w io.Writer, jobName string, jobToUpdate *talent.Job) (*talent.Jo\n \treturn job, err\n }\n \n-// [END update_job]\n // [END job_update_job]\n \n // [START job_update_job_with_field_mask]\n-// [START update_job_with_field_mask]\n \n // updateJobWithMask updates a job by name with specific fields.\n // mask is a comma separated list top-level fields of talent.Job.",
        "comments": [],
        "commit_messages": [
            "fix: delete obsolete region tag"
        ],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -144,11 +141,9 @@\nfunc updateJobWithMask(w io.Writer, jobName string, mask string, jobToUpdate *ta\n \treturn job, err\n }\n \n-// [END update_job_with_field_mask]\n // [END job_update_job_with_field_mask]\n \n // [START job_delete_job]\n-// [START delete_job]\n \n // deleteJob deletes an existing job by name.\n func deleteJob(w io.Writer, jobName string) error {",
        "comments": [],
        "commit_messages": [
            "fix: delete obsolete region tag"
        ],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/basic_job_sample.go",
        "code_diff": "@@ -171,11 +166,9 @@\nfunc deleteJob(w io.Writer, jobName string) error {\n \treturn err\n }\n \n-// [END delete_job]\n // [END job_delete_job]\n \n // [START job_list_jobs]\n-// [START list_jobs]\n \n // listJobs lists jobs with a filter, for example\n // `companyName=\"projects/my-project/companies/123\"`.",
        "comments": [],
        "commit_messages": [
            "fix: delete obsolete region tag"
        ],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -25,7 +25,6 @@\nimport (\n )\n \n // [START job_custom_attribute_job]\n-// [START custom_attribute_job]\n \n // constructJobWithCustomAttributes constructs a job with custom attributes.\n func constructJobWithCustomAttributes(companyName string, jobTitle string) *talent.Job {",
        "comments": [],
        "commit_messages": [
            "fix: migrate to new region tag in custom_attribute_sample.go"
        ],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -54,11 +53,9 @@\nfunc constructJobWithCustomAttributes(companyName string, jobTitle string) *tale\n \treturn job\n }\n \n-// [END custom_attribute_job]\n // [END job_custom_attribute_job]\n \n // [START job_custom_attribute_filter_string_value]\n-// [START custom_attribute_filter_string_value]\n \n // filterOnStringValueCustomAttribute searches for jobs on a string value custom\n // atrribute.",
        "comments": [],
        "commit_messages": [
            "fix: migrate to new region tag in custom_attribute_sample.go"
        ],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -105,11 +102,9 @@\nfunc filterOnStringValueCustomAttribute(w io.Writer, projectID string) (*talent.\n \treturn resp, nil\n }\n \n-// [END custom_attribute_filter_string_value]\n // [END job_custom_attribute_filter_string_value]\n \n // [START job_custom_attribute_filter_long_value]\n-// [START custom_attribute_filter_long_value]\n \n // filterOnLongValueCustomAttribute searches for jobs on a long value custom\n // atrribute.",
        "comments": [],
        "commit_messages": [
            "fix: migrate to new region tag in custom_attribute_sample.go"
        ],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/custom_attribute_sample.go",
        "code_diff": "@@ -157,10 +152,8 @@\nfunc filterOnLongValueCustomAttribute(w io.Writer, projectID string) (*talent.Se\n }\n \n // [END job_custom_attribute_filter_long_value]\n-// [END custom_attribute_filter_long_value]\n \n // [START job_custom_attribute_filter_multi_attributes]\n-// [START custom_attribute_filter_multi_attributes]\n \n // filterOnLongValueCustomAttribute searches for jobs on multiple custom\n // atrributes.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \ttalent \"google.golang.org/api/jobs/v3\"\n )\n \n-// [START basic_location_search]\n+// [START job_basic_location_search]\n \n // basicLocationSearch searches for jobs within distance of location.\n func basicLocationSearch(w io.Writer, projectID, companyName, location string, distance float64) (*talent.SearchJobsResponse, error) {",
        "comments": [
            {
                "comment": "you need to leave broadening_location_search here (both the start and end tags) until the new region tag has been merged in docs. ",
                "position": 26
            },
            {
                "comment": "Thank you for catching this. I revered this tag for now.",
                "position": 26
            }
        ],
        "commit_messages": [
            "fix: migrate to new region tag in location_based_search_sample.go"
        ],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -82,8 +82,9 @@\nfunc basicLocationSearch(w io.Writer, projectID, companyName, location string, d\n \treturn resp, nil\n }\n \n-// [END basic_location_search]\n+// [END job_basic_location_search]\n \n+// [START job_city_location_search]\n // [START city_location_search]\n \n // cityLocationSearch searches for jobs in the same city of given location.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -143,7 +144,9 @@\nfunc cityLocationSearch(w io.Writer, projectID, companyName, location string) (*\n }\n \n // [END city_location_search]\n+// [END job_city_location_search]\n \n+// [START job_broadening_location_search]\n // [START broadening_location_search]\n \n // broadeningLocationSearch searches for jobs with a broadening area of given",
        "comments": [],
        "commit_messages": [
            "fix: add new region tags and left old tags for migration"
        ],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -205,8 +208,9 @@\nfunc broadeningLocationSearch(w io.Writer, projectID, companyName, location stri\n }\n \n // [END broadening_location_search]\n+// [END job_broadening_location_search]\n \n-// [START keyword_location_search]\n+// [START job_keyword_location_search]\n \n // keywordLocationSearch searches for jobs with given keyword and within the\n // distance of given location.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "fixit: migrate to new region tag with prefix 'job_'",
        "pr_number": 4227,
        "file_name": "jobs/v3/howto/location_based_search_sample.go",
        "code_diff": "@@ -267,9 +271,9 @@\nfunc keywordLocationSearch(w io.Writer, projectID, companyName, location string,\n \treturn resp, nil\n }\n \n-// [END keyword_location_search]\n+// [END job_keyword_location_search]\n \n-// [START multi_locations_search]\n+// [START job_multi_locations_search]\n \n // multiLocationsSearch searches for jobs that fall in the distance of any given\n // locations.",
        "comments": [],
        "commit_messages": [
            "fix: migrate to new region tag in location_based_search_sample.go"
        ],
        "last_commit_sha": "41f87e0e5bd73ca5f0f9a0854132615a116cdd57"
    },
    {
        "pr_title": "feat(gimmeproj): blocking retry on lease operations",
        "pr_number": 4223,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \t\"errors\"\n \t\"flag\"\n \t\"fmt\"\n+\t\"log\"\n \t\"os\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "feat: enable blocking retries on gimmeproj"
        ],
        "last_commit_sha": "b7fcf522e5947f8c5035de6d77b55cc096f83f64"
    },
    {
        "pr_title": "feat(gimmeproj): blocking retry on lease operations",
        "pr_number": 4223,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -33,10 +34,12 @@\nimport (\n var (\n \tmetaProject = flag.String(\"project\", \"\", \"Meta-project that manages the pool.\")\n \tformat      = flag.String(\"output\", \"\", \"Output format for selected operations. Options include: list\")\n+\twaitTime    = flag.Duration(\"timeout\", 30*time.Minute, \"maximum wait time for leasing a project\")\n \tdatastore   *ds.Client\n \n-\tversion   = \"dev\"\n-\tbuildDate = \"unknown\"\n+\tversion       = \"dev\"\n+\tbuildDate     = \"unknown\"\n+\tErrNoProjects = errors.New(\"could not find a free project\")\n )\n \n type Pool struct {",
        "comments": [
            {
                "comment": "suggestion: It would be good to provide some guidance on what the wait might be, such as \"trying every 30 seconds until 30 minutes\".",
                "position": 36
            },
            {
                "comment": "future: Is 30 seconds the right delay? My experience is that Go testing currently takes longer than a minute. Thinking this through, this is probably a fairly cheap poll.\r\n\r\nIf we wanted to make it smarter, getting a retry-after direction from the lease function would be interesting, where we can add estimated test runtime to the oldest runner lease time. ",
                "position": 37
            },
            {
                "comment": "there's certainly room for improvement here, but i hesitate to add complexity to this tool directly. I think we'd be better served by building a server-side API component for this, which will also give us better visibility into client issues.",
                "position": 37
            },
            {
                "comment": "Fair. I should have explained a bit more: I started with a real, optional feedback for right now but switched it to the \"future\" prefix when I realized I went too far, but still thought the notion worth sharing.",
                "position": 37
            }
        ],
        "commit_messages": [
            "feat: enable blocking retries on gimmeproj"
        ],
        "last_commit_sha": "b7fcf522e5947f8c5035de6d77b55cc096f83f64"
    },
    {
        "pr_title": "feat(gimmeproj): blocking retry on lease operations",
        "pr_number": 4223,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -142,7 +145,21 @@\nAdministrative commands:\n \t\tfmt.Fprintln(os.Stderr, usage.Error())\n \t\treturn nil\n \tcase \"lease\":\n-\t\treturn lease(ctx, flag.Arg(1))\n+\t\t// When leasing, keep trying until we reach our configured timeout\n+\t\tctx, cancel := context.WithTimeout(ctx, *waitTime)\n+\t\tdefer cancel()\n+\t\tfor ctx.Err() == nil {\n+\t\t\terr := lease(ctx, flag.Arg(1))\n+\t\t\tif err == nil {\n+\t\t\t\treturn err\n+\t\t\t} else if errors.Is(err, ErrNoProjects) {\n+\t\t\t\tlog.Printf(\"Temporary error: %v\\n\", err)\n+\t\t\t\ttime.Sleep(30 * time.Second)\n+\t\t\t} else {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t}\n+\t\treturn ctx.Err()\n \tcase \"pool-add\":\n \t\treturn addToPool(ctx, flag.Arg(1))\n \tcase \"pool-rm\":",
        "comments": [],
        "commit_messages": [
            "feat: enable blocking retries on gimmeproj"
        ],
        "last_commit_sha": "b7fcf522e5947f8c5035de6d77b55cc096f83f64"
    },
    {
        "pr_title": "feat(gimmeproj): blocking retry on lease operations",
        "pr_number": 4223,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -199,7 +216,7 @@\nfunc lease(ctx context.Context, duration string) error {\n \t\tvar ok bool\n \t\tproj, ok = pool.Lease(d)\n \t\tif !ok {\n-\t\t\treturn errors.New(\"Could not find a free project. Try again soon.\")\n+\t\t\treturn ErrNoProjects\n \t\t}\n \t\treturn nil\n \t})",
        "comments": [],
        "commit_messages": [
            "feat: enable blocking retries on gimmeproj"
        ],
        "last_commit_sha": "b7fcf522e5947f8c5035de6d77b55cc096f83f64"
    },
    {
        "pr_title": "feat(compute): compute_ip_address_unassign_static_address sample",
        "pr_number": 4196,
        "file_name": "compute/address/address_test.go",
        "code_diff": "@@ -551,7 +551,7 @@\nfunc TestGetRegionalExternal(t *testing.T) {\n \n }\n \n-func TestAssignStaticAddressToExistingVM(t *testing.T) {\n+func TestAssignUnassignStaticAddressToExistingVM(t *testing.T) {\n \tctx := context.Background()\n \tvar seededRand = rand.New(\n \t\trand.NewSource(time.Now().UnixNano()))",
        "comments": [],
        "commit_messages": [
            "fix: merge two assign tests"
        ],
        "last_commit_sha": "6c85e887a0dda9658c47a5cd6482935fba9afc5d"
    },
    {
        "pr_title": "feat(compute): hyperdisk_create/hyperdisk_pool_create/hyperdisk_create_from_pool samples",
        "pr_number": 4191,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -194,6 +194,36 @@\nfunc errorIfNot404(t *testing.T, msg string, err error) {\n \t}\n }\n \n+// deleteStoragePool deletes the specified storage pool in the given project and zone.\n+func deleteStoragePool(projectId, zone, storagePoolName string) error {\n+\tctx := context.Background()\n+\tclient, err := compute.NewStoragePoolsRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"NewStoragePoolsRESTClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\t// Create the delete storage pool request\n+\treq := &computepb.DeleteStoragePoolRequest{\n+\t\tProject:     projectId,\n+\t\tZone:        zone,\n+\t\tStoragePool: storagePoolName,\n+\t}\n+\n+\t// Send the delete storage pool request\n+\top, err := client.Delete(ctx, req)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"Delete storage pool request failed: %v\", err)\n+\t}\n+\n+\t// Wait for the delete storage pool operation to complete\n+\tif err = op.Wait(ctx); err != nil {\n+\t\treturn fmt.Errorf(\"unable to wait for the operation: %w\", err)\n+\t}\n+\n+\treturn nil\n+}\n+\n func TestComputeDisksSnippets(t *testing.T) {\n \tctx := context.Background()\n \tvar r *rand.Rand = rand.New(",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4e10b0d2470c3877a91e827b654a39d1f751c38c"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "compute/disk-images/disk_image_test.go",
        "code_diff": "@@ -72,6 +72,74 @@\nfunc deleteDisk(ctx context.Context, projectId, zone, diskName string) error {\n \treturn op.Wait(ctx)\n }\n \n+func getDisk(ctx context.Context, projectID, diskName, zone string) (*computepb.Disk, error) {\n+\tdiskClient, err := compute.NewDisksRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tdefer diskClient.Close()\n+\n+\treq := &computepb.GetDiskRequest{\n+\t\tProject: projectID,\n+\t\tDisk:    diskName,\n+\t\tZone:    zone,\n+\t}\n+\tdisk, err := diskClient.Get(ctx, req)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\treturn disk, nil\n+}\n+\n+func createSnapshot(\n+\tctx context.Context,\n+\tprojectID, snapshotName string,\n+\tdisk *computepb.Disk,\n+\tlocations *[]string,\n+) error {\n+\tsnapshotsClient, err := compute.NewSnapshotsRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer snapshotsClient.Close()\n+\n+\treq := &computepb.InsertSnapshotRequest{\n+\t\tProject: projectID,\n+\t\tSnapshotResource: &computepb.Snapshot{\n+\t\t\tName:             proto.String(snapshotName),\n+\t\t\tSourceDisk:       proto.String(disk.GetSelfLink()),\n+\t\t\tStorageLocations: *locations,\n+\t\t},\n+\t}\n+\n+\top, err := snapshotsClient.Insert(ctx, req)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn op.Wait(ctx)\n+}\n+\n+func deleteSnapshot(ctx context.Context, projectID, snapshotName string) error {\n+\tsnapshotsClient, err := compute.NewSnapshotsRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer snapshotsClient.Close()\n+\n+\treq := &computepb.DeleteSnapshotRequest{\n+\t\tProject:  projectID,\n+\t\tSnapshot: snapshotName,\n+\t}\n+\n+\top, err := snapshotsClient.Delete(ctx, req)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn op.Wait(ctx)\n+}\n+\n func TestComputeDiskImageSnippets(t *testing.T) {\n \tctx := context.Background()\n \tvar r *rand.Rand = rand.New(",
        "comments": [
            {
                "comment": "this needs to be a `Errorf`, to allow the delete to run. otherwise test failures here will orphan the snapshot resource.",
                "position": 121
            }
        ],
        "commit_messages": [
            "feat: Added create image from snapshot sample"
        ],
        "last_commit_sha": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "compute/disk-images/disk_image_test.go",
        "code_diff": "@@ -81,14 +149,13 @@\nfunc TestComputeDiskImageSnippets(t *testing.T) {\n \timageName := fmt.Sprintf(\"test-image-go-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tdiskName := fmt.Sprintf(\"test-disk-go-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tsourceImage := \"projects/debian-cloud/global/images/family/debian-11\"\n-\tsourceProjectId := \"debian-cloud\"\n-\tsourceImageName := \"debian-11\"\n+\tsnapshotName := fmt.Sprintf(\"test-snapshot-go-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \n \tbuf := &bytes.Buffer{}\n \n \terr := createDisk(ctx, tc.ProjectID, zone, diskName, sourceImage)\n \tif err != nil {\n-\t\tt.Fatalf(\"createDisk got err: %v\", err)\n+\t\tt.Errorf(\"createDisk got err: %v\", err)\n \t}\n \n \tt.Run(\"Test snapshot creation and deletion\", func(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Added create image from snapshot sample",
        "pr_number": 4186,
        "file_name": "compute/disk-images/disk_image_test.go",
        "code_diff": "@@ -144,24 +211,23 @@\nfunc TestComputeDiskImageSnippets(t *testing.T) {\n \t\t}\n \t})\n \n-\terr = deleteDisk(ctx, tc.ProjectID, zone, diskName)\n-\tif err != nil {\n-\t\tt.Errorf(\"deleteDisk got err: %v\", err)\n-\t}\n+\tt.Run(\"Test image creation and deletion from snapshot\", func(t *testing.T) {\n+\t\tdisk, err := getDisk(ctx, tc.ProjectID, diskName, zone)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"getDisk got err: %v\", err)\n+\t\t}\n \n-\tt.Run(\"Test creation and deletion from image\", func(t *testing.T) {\n-\t\tbuf.Reset()\n-\t\twant := \"created\"\n-\t\timage, err2 := getDiskImageFromFamily(buf, sourceProjectId, sourceImageName)\n-\t\tif err2 != nil {\n-\t\t\tt.Fatalf(\"getDiskImageFromFamily got err: %v\", err2)\n+\t\terr = createSnapshot(ctx, tc.ProjectID, snapshotName, disk, &[]string{})\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"getDisk got err: %v\", err)\n \t\t}\n \n-\t\tif err := createImageFromImage(buf, tc.ProjectID, sourceProjectId, *image.Name, imageName); err != nil {\n-\t\t\tt.Errorf(\"createImageFromImage got err: %v\", err)\n+\t\twant := \"created\"\n+\t\tif err := createImageFromSnapshot(buf, tc.ProjectID, snapshotName, imageName); err != nil {\n+\t\t\tt.Fatalf(\"createImageFromDisk got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n-\t\t\tt.Errorf(\"createImageFromImage got %q, want %q\", got, want)\n+\t\t\tt.Errorf(\"createImageFromDisk got %q, want %q\", got, want)\n \t\t}\n \n \t\tbuf.Reset()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "23c9e94ada0459a523d76b74264b79957ddabbf7"
    },
    {
        "pr_title": "feat: Compute images create from image",
        "pr_number": 4180,
        "file_name": "compute/disk-images/disk_image_test.go",
        "code_diff": "@@ -81,6 +81,8 @@\nfunc TestComputeDiskImageSnippets(t *testing.T) {\n \timageName := fmt.Sprintf(\"test-image-go-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tdiskName := fmt.Sprintf(\"test-disk-go-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tsourceImage := \"projects/debian-cloud/global/images/family/debian-11\"\n+\tsourceProjectId := \"debian-cloud\"\n+\tsourceImageName := \"debian-11\"\n \n \tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "365b5cb5c195b2faf688d181b95b4c4c2ed9de78"
    },
    {
        "pr_title": "feat: Compute images create from image",
        "pr_number": 4180,
        "file_name": "compute/disk-images/disk_image_test.go",
        "code_diff": "@@ -123,7 +125,7 @@\nfunc TestComputeDiskImageSnippets(t *testing.T) {\n \t\tbuf.Reset()\n \t\twant = \"Newest disk image was found\"\n \n-\t\terr = getDiskImageFromFamily(buf, \"debian-cloud\", \"debian-11\")\n+\t\t_, err = getDiskImageFromFamily(buf, \"debian-cloud\", \"debian-11\")\n \t\tif err != nil {\n \t\t\tt.Errorf(\"getDiskImageFromFamily got err: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "feat: create image from image sample"
        ],
        "last_commit_sha": "365b5cb5c195b2faf688d181b95b4c4c2ed9de78"
    },
    {
        "pr_title": "feat: Compute images create from image",
        "pr_number": 4180,
        "file_name": "compute/disk-images/get_disk_image_from_family.go",
        "code_diff": "@@ -28,14 +28,14 @@\nimport (\n func getDiskImageFromFamily(\n \tw io.Writer,\n \tprojectID, family string,\n-) error {\n+) (*computepb.Image, error) {\n \t// projectID := \"your_project_id\"\n \t// family := \"my_family\"\n \n \tctx := context.Background()\n \timagesClient, err := compute.NewImagesRESTClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewImagesRESTClient: %w\", err)\n+\t\treturn nil, fmt.Errorf(\"NewImagesRESTClient: %w\", err)\n \t}\n \tdefer imagesClient.Close()",
        "comments": [],
        "commit_messages": [
            "feat: create image from image sample"
        ],
        "last_commit_sha": "365b5cb5c195b2faf688d181b95b4c4c2ed9de78"
    },
    {
        "pr_title": "feat(compute): compute_ip_address_assign_static_existing_vm sample",
        "pr_number": 4166,
        "file_name": "compute/address/address_test.go",
        "code_diff": "@@ -23,6 +23,8 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"google.golang.org/protobuf/proto\"\n+\n \tcompute \"cloud.google.com/go/compute/apiv1\"\n \t\"google.golang.org/api/iterator\"",
        "comments": [],
        "commit_messages": [
            "feat(compute): compute_ip_address_assign_static_existing_vm sample"
        ],
        "last_commit_sha": "21b9257faef0f2743161fdac719a318da5311347"
    },
    {
        "pr_title": "feat(compute): compute_ip_address_assign_static_existing_vm sample",
        "pr_number": 4166,
        "file_name": "compute/address/address_test.go",
        "code_diff": "@@ -31,6 +33,107 @@\nimport (\n )\n \n // helper functions\n+\n+func createTestInstance(projectID, zone, instanceName string) error {\n+\t// projectID := \"your_project_id\"\n+\t// zone := \"europe-central2-b\"\n+\t// instanceName := \"your_instance_name\"\n+\n+\tctx := context.Background()\n+\tinstancesClient, err := compute.NewInstancesRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"NewInstancesRESTClient: %w\", err)\n+\t}\n+\tdefer instancesClient.Close()\n+\n+\timagesClient, err := compute.NewImagesRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"NewImagesRESTClient: %w\", err)\n+\t}\n+\tdefer imagesClient.Close()\n+\n+\t// List of public operating system (OS) images: https://cloud.google.com/compute/docs/images/os-details.\n+\tnewestDebianReq := &computepb.GetFromFamilyImageRequest{\n+\t\tProject: \"debian-cloud\",\n+\t\tFamily:  \"debian-12\",\n+\t}\n+\tnewestDebian, err := imagesClient.GetFromFamily(ctx, newestDebianReq)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"unable to get image from family: %w\", err)\n+\t}\n+\n+\treq := &computepb.InsertInstanceRequest{\n+\t\tProject: projectID,\n+\t\tZone:    zone,\n+\t\tInstanceResource: &computepb.Instance{\n+\t\t\tName: proto.String(instanceName),\n+\t\t\tDisks: []*computepb.AttachedDisk{\n+\t\t\t\t{\n+\t\t\t\t\tInitializeParams: &computepb.AttachedDiskInitializeParams{\n+\t\t\t\t\t\tDiskSizeGb:  proto.Int64(10),\n+\t\t\t\t\t\tSourceImage: newestDebian.SelfLink,\n+\t\t\t\t\t\tDiskType:    proto.String(fmt.Sprintf(\"zones/%s/diskTypes/pd-standard\", zone)),\n+\t\t\t\t\t},\n+\t\t\t\t\tAutoDelete: proto.Bool(true),\n+\t\t\t\t\tBoot:       proto.Bool(true),\n+\t\t\t\t\tType:       proto.String(computepb.AttachedDisk_PERSISTENT.String()),\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tMachineType: proto.String(fmt.Sprintf(\"zones/%s/machineTypes/n1-standard-1\", zone)),\n+\t\t\tNetworkInterfaces: []*computepb.NetworkInterface{\n+\t\t\t\t{\n+\t\t\t\t\t//Name: proto.String(\"global/networks/default\"),\n+\t\t\t\t\tAccessConfigs: []*computepb.AccessConfig{\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tType:        proto.String(computepb.AccessConfig_ONE_TO_ONE_NAT.String()),\n+\t\t\t\t\t\t\tName:        proto.String(\"External NAT\"),\n+\t\t\t\t\t\t\tNetworkTier: proto.String(computepb.AccessConfig_PREMIUM.String()),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\top, err := instancesClient.Insert(ctx, req)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"unable to create instance: %w\", err)\n+\t}\n+\n+\tif err = op.Wait(ctx); err != nil {\n+\t\treturn fmt.Errorf(\"unable to wait for the operation: %w\", err)\n+\t}\n+\n+\treturn nil\n+}\n+\n+func deleteInstance(projectID, zone, instanceName string) error {\n+\tctx := context.Background()\n+\tclient, err := compute.NewInstancesRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"NewInstancesRESTClient: %w\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\treq := &computepb.DeleteInstanceRequest{\n+\t\tProject:  projectID,\n+\t\tZone:     zone,\n+\t\tInstance: instanceName,\n+\t}\n+\n+\top, err := client.Delete(ctx, req)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"DeleteInstance: %w\", err)\n+\t}\n+\n+\terr = op.Wait(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"Wait for DeleteInstance operation: %w\", err)\n+\t}\n+\n+\treturn nil\n+}\n+\n func listIPAddresses(ctx context.Context, projectID, region string) ([]string, error) {\n \tvar addresses []string\n \tvar err error",
        "comments": [],
        "commit_messages": [
            "feat(compute): compute_ip_address_assign_static_existing_vm sample"
        ],
        "last_commit_sha": "21b9257faef0f2743161fdac719a318da5311347"
    },
    {
        "pr_title": "feat(compute): compute_ip_address_assign_static_existing_vm sample",
        "pr_number": 4166,
        "file_name": "compute/address/address_test.go",
        "code_diff": "@@ -159,6 +262,8 @@\nfunc _deleteRegionalIPAddress(ctx context.Context, projectID, region, addressNam\n \treturn nil\n }\n \n+// end helper functions\n+\n func TestReserveNewRegionalExternal(t *testing.T) {\n \tctx := context.Background()\n \tvar seededRand = rand.New(",
        "comments": [],
        "commit_messages": [
            "feat(compute): compute_ip_address_assign_static_existing_vm sample"
        ],
        "last_commit_sha": "21b9257faef0f2743161fdac719a318da5311347"
    },
    {
        "pr_title": "feat(compute): compute_ip_address_get_static_address sample",
        "pr_number": 4154,
        "file_name": "compute/address/address_test.go",
        "code_diff": "@@ -159,8 +159,6 @@\nfunc _deleteRegionalIPAddress(ctx context.Context, projectID, region, addressNam\n \treturn nil\n }\n \n-// end helper functions\n-\n func TestReserveNewRegionalExternal(t *testing.T) {\n \tctx := context.Background()\n \tvar seededRand = rand.New(",
        "comments": [],
        "commit_messages": [
            "feat(compute): compute_ip_address_get_static_external sample"
        ],
        "last_commit_sha": "993c48e1be7848422487d2aac443e77284dc55e9"
    },
    {
        "pr_title": "feat(otel-instrumentation): Add custom instrumentation ",
        "pr_number": 4149,
        "file_name": "opentelemetry/instrumentation/app/server.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"log/slog\"\n \t\"math/rand\"\n \t\"net/http\"\n-\t\"time\"\n \n \t\"go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp\"\n )",
        "comments": [],
        "commit_messages": [
            "Add custom metrics"
        ],
        "last_commit_sha": "2ad16542a974e9c4aedca133c34141e74682343d"
    },
    {
        "pr_title": "feat(otel-instrumentation): Add custom instrumentation ",
        "pr_number": 4149,
        "file_name": "opentelemetry/instrumentation/app/server.go",
        "code_diff": "@@ -28,11 +27,8 @@\nimport (\n // the number of milliseconds slept as its response.\n // [START opentelemetry_instrumentation_handle_single]\n func handleSingle(w http.ResponseWriter, r *http.Request) {\n-\tsleepTime := time.Duration(100+rand.Intn(100)) * time.Millisecond\n-\n-\ttime.Sleep(sleepTime)\n-\n-\tfmt.Fprintf(w, \"slept %v\\n\", sleepTime)\n+\tsleepTime := randomSleep(r)\n+\tfmt.Fprintf(w, \"work completed in %v\\n\", sleepTime)\n }\n \n // [END opentelemetry_instrumentation_handle_single]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2ad16542a974e9c4aedca133c34141e74682343d"
    },
    {
        "pr_title": "feat(spanner): add samples for proto columns",
        "pr_number": 4136,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -1072,6 +1072,46 @@\nfunc TestPgOrderNulls(t *testing.T) {\n \tassertContains(t, out, \"Singers ORDER BY Name DESC NULLS LAST\\n\\tBruce\\n\\tAlice\\n\\t<null>\")\n }\n \n+func TestProtoColumnSample(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\n+\tctx, cancel := context.WithTimeout(context.Background(), time.Hour)\n+\tdefer cancel()\n+\n+\tstatements := []string{\n+\t\t`CREATE TABLE Singers (\n+\t\t\t\tSingerId   INT64 NOT NULL,\n+\t\t\t\tFirstName  STRING(1024),\n+\t\t\t\tLastName   STRING(1024),\n+\t\t\t) PRIMARY KEY (SingerId)`,\n+\t\t`CREATE TABLE Albums (\n+\t\t\t\tSingerId     INT64 NOT NULL,\n+\t\t\t\tAlbumId      INT64 NOT NULL,\n+\t\t\t\tAlbumTitle   STRING(MAX)\n+\t\t\t) PRIMARY KEY (SingerId, AlbumId),\n+\t\t\tINTERLEAVE IN PARENT Singers ON DELETE CASCADE`,\n+\t}\n+\tdbCleanup, err := createTestDatabase(dbName, statements...)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tvar out string\n+\trunSample(t, write, dbName, \"failed to insert data\")\n+\trunSampleWithContext(ctx, t, addProtoColumn, dbName, \"failed to update db for proto columns\")\n+\tout = runSample(t, updateDataWithProtoColumn, dbName, \"failed to update data with proto columns\")\n+\tassertContains(t, out, \"Data updated\\n\")\n+\tout = runSample(t, updateDataWithProtoColumnWithDml, dbName, \"failed to update data with proto columns using dml\")\n+\tassertContains(t, out, \"record(s) updated.\")\n+\tout = runSample(t, queryWithProtoParameter, dbName, \"failed to query with proto parameter\")\n+\tassertContains(t, out, \"2 singer_id:2\")\n+}\n+\n func maybeCreateKey(projectId, locationId, keyRingId, keyId string) error {\n \tclient, err := kms.NewKeyManagementClient(context.Background())\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "feat(spanner): add samples for proto columns"
        ],
        "last_commit_sha": "8d60467f9f95dff79a0cc1405ff2917490d6fab1"
    },
    {
        "pr_title": "feat(vertexai): Elastic Text-Embedding Model demo.",
        "pr_number": 4127,
        "file_name": "aiplatform/snippets/embeddings.go",
        "code_diff": "@@ -28,17 +28,21 @@\nimport (\n )\n \n func embedTexts(\n-\tapiEndpoint, project, model string, texts []string, task string) ([][]float32, error) {\n+\tproject, location string, texts []string) ([][]float32, error) {\n \tctx := context.Background()\n \n+\tapiEndpoint := fmt.Sprintf(\"%s-aiplatform.googleapis.com:443\", location)\n+\tmodel := \"text-embedding-004\"\n+\ttask := \"QUESTION_ANSWERING\"\n+\tcustomOutputDimensionality := 5\n+\n \tclient, err := aiplatform.NewPredictionClient(ctx, option.WithEndpoint(apiEndpoint))\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \tdefer client.Close()\n \n \tmatch := regexp.MustCompile(`^(\\w+-\\w+)`).FindStringSubmatch(apiEndpoint)\n-\tlocation := \"us-central1\"\n \tif match != nil {\n \t\tlocation = match[1]\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b73ded9238e7affe8350cc30e0ffdf5b07dc06d8"
    },
    {
        "pr_title": "test(testutil): add new function for creating a test bucket",
        "pr_number": 4001,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -28,15 +28,43 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n-// CreateTestBucket creates a new bucket with the given prefix\n-func CreateTestBucket(ctx context.Context, t *testing.T, client *storage.Client, projectID, prefix string) (string, error) {\n+// TestBucket creates a new bucket with the given prefix and registers a cleanup\n+// function to delete the bucket and any objects it contains when the test finishes.\n+// TestBucket returns the bucket name. It fails the test if bucket creation fails.\n+func TestBucket(ctx context.Context, t *testing.T, projectID, prefix string) string {\n+\tt.Helper()\n+\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tt.Cleanup(func() { client.Close() })\n+\treturn CreateTestBucket(ctx, t, client, projectID, prefix)\n+}\n+\n+// CreateTestBucket creates a new bucket with the given prefix and registers a\n+// cleanup function to delete the bucket and any objects it contains.\n+// It is equivalent to TestBucket but allows Storage Client re-use.\n+func CreateTestBucket(ctx context.Context, t *testing.T, client *storage.Client, projectID, prefix string) string {\n \tt.Helper()\n \tbucketName := UniqueBucketName(prefix)\n-\treturn bucketName, cleanBucketWithClient(ctx, t, client, projectID, bucketName)\n+\n+\tb := client.Bucket(bucketName)\n+\tif err := b.Create(ctx, projectID, nil); err != nil {\n+\t\tt.Fatalf(\"Bucket.Create(%q): %v\", bucketName, err)\n+\t}\n+\n+\tt.Cleanup(func() {\n+\t\tif err := DeleteBucketIfExists(ctx, client, bucketName); err != nil {\n+\t\t\tlog.Printf(\"Bucket.Delete(%q): %v\", bucketName, err)\n+\t\t}\n+\t})\n+\treturn bucketName\n }\n \n // CleanBucket creates a new bucket. If the bucket already exists, it will be\n // deleted and recreated.\n+// Deprecated: use TestBucket or CreateTestBucket instead.\n func CleanBucket(ctx context.Context, t *testing.T, projectID, bucket string) error {\n \tt.Helper()",
        "comments": [
            {
                "comment": "Just FYI, there are a bunch of uses of this outside of GCS samples -- those will have to be replaced as well.",
                "position": 43
            },
            {
                "comment": "Yes, I have a follow up ready to replace those.",
                "position": 43
            }
        ],
        "commit_messages": [
            "test(testutil): add new function for creating a test bucket\n\nPart 1 to bucket creation cleanup.\n\nDeprecates CleanBucket; a followup PR will remove all references to this function.\nCleanBucket can run into problems of availability due to fast creation after deletion. Instead,\nunique randomly generated bucket names should be used.\n\nTestBucket provides a simple way to create a bucket for testing, creating this random name\nand taking charge of the cleanup."
        ],
        "last_commit_sha": "e1a4af397cc8deabc03391e5896c126f2c116ff8"
    },
    {
        "pr_title": "test(testutil): add new function for creating a test bucket",
        "pr_number": 4001,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -78,7 +106,7 @@\nfunc cleanBucketWithClient(ctx context.Context, t *testing.T, client *storage.Cl\n \treturn nil\n }\n \n-// DeleteBucketIfExists deletes a bucket and all its objects\n+// DeleteBucketIfExists deletes a bucket and all its objects.\n func DeleteBucketIfExists(ctx context.Context, client *storage.Client, bucket string) error {\n \tb := client.Bucket(bucket)",
        "comments": [],
        "commit_messages": [
            "test(testutil): add new function for creating a test bucket\n\nPart 1 to bucket creation cleanup.\n\nDeprecates CleanBucket; a followup PR will remove all references to this function.\nCleanBucket can run into problems of availability due to fast creation after deletion. Instead,\nunique randomly generated bucket names should be used.\n\nTestBucket provides a simple way to create a bucket for testing, creating this random name\nand taking charge of the cleanup."
        ],
        "last_commit_sha": "e1a4af397cc8deabc03391e5896c126f2c116ff8"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "dataproc/quickstart/quickstart_test.go",
        "code_diff": "@@ -49,15 +49,15 @@\nfunc setup(t *testing.T, projectID string) {\n \tuuid := uuid.New().String()\n \n \tclusterName = \"go-qs-test-\" + uuid\n-\tbktName = \"go-dataproc-qs-test-\" + uuid\n \tjobFilePath = fmt.Sprintf(\"gs://%s/%s\", bktName, jobFName)\n \n \tsc, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Errorf(\"storage.NewClient: %v\", err)\n \t}\n+\tt.Cleanup(func() { sc.Close() })\n \n-\ttestutil.CleanBucket(ctx, t, projectID, bktName)\n+\tbktName = testutil.CreateTestBucket(ctx, t, sc, projectID, \"go-dataproc-qs-test\")\n \tbkt := sc.Bucket(bktName)\n \n \tobj := bkt.Object(jobFName)",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "datastore/admin/datastore_admin_test.go",
        "code_diff": "@@ -16,7 +16,7 @@\npackage samples\n \n import (\n \t\"context\"\n-\t\"io/ioutil\"\n+\t\"io\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "datastore/admin/datastore_admin_test.go",
        "code_diff": "@@ -30,13 +30,13 @@\nfunc TestAdmin(t *testing.T) {\n \t// See https://cloud.google.com/datastore/docs/export-import-entities#permissions for full details\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n-\tclient, err := clientCreate(ioutil.Discard)\n+\tclient, err := clientCreate(io.Discard)\n \tif err != nil {\n \t\tt.Fatalf(\"clientCreate: %v\", err)\n \t}\n \tdefer client.Close()\n \n-\tindices, err := indexList(ioutil.Discard, tc.ProjectID)\n+\tindices, err := indexList(io.Discard, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"indexList: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -24,7 +24,6 @@\nimport (\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/google/uuid\"\n-\t\"google.golang.org/api/googleapi\"\n \t\"google.golang.org/api/iterator\"\n )",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -62,50 +61,6 @@\nfunc CreateTestBucket(ctx context.Context, t *testing.T, client *storage.Client,\n \treturn bucketName\n }\n \n-// CleanBucket creates a new bucket. If the bucket already exists, it will be\n-// deleted and recreated.\n-// Deprecated: use TestBucket or CreateTestBucket instead.\n-func CleanBucket(ctx context.Context, t *testing.T, projectID, bucket string) error {\n-\tt.Helper()\n-\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n-\t}\n-\treturn cleanBucketWithClient(ctx, t, client, projectID, bucket)\n-}\n-\n-// cleanBucketWithClient creates a new bucket. If the bucket already exists, it will be\n-// deleted and recreated.\n-// Like CleanBucket but you must provide the storage client.\n-func cleanBucketWithClient(ctx context.Context, t *testing.T, client *storage.Client, projectID, bucket string) error {\n-\tt.Helper()\n-\n-\t// Delete the bucket if it exists.\n-\tif err := DeleteBucketIfExists(ctx, client, bucket); err != nil {\n-\t\treturn fmt.Errorf(\"error deleting bucket: %w\", err)\n-\t}\n-\tb := client.Bucket(bucket)\n-\n-\t// Now create the bucket.\n-\t// Retry because the bucket can take time to fully delete.\n-\tRetry(t, 10, 30*time.Second, func(r *R) {\n-\t\tif err := b.Create(ctx, projectID, nil); err != nil {\n-\t\t\tif err, ok := err.(*googleapi.Error); ok {\n-\t\t\t\t// Just in case...\n-\t\t\t\tif err.Code == 409 {\n-\t\t\t\t\tDeleteBucketIfExists(ctx, client, bucket) // Ignore error.\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tr.Errorf(\"Bucket.Create(%q): %v\", bucket, err)\n-\t\t}\n-\t})\n-\n-\tWaitForBucketToExist(ctx, t, b)\n-\n-\treturn nil\n-}\n-\n // DeleteBucketIfExists deletes a bucket and all its objects.\n func DeleteBucketIfExists(ctx context.Context, client *storage.Client, bucket string) error {\n \tb := client.Bucket(bucket)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -61,7 +61,7 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName := tc.ProjectID + \"-golang-samples-transcoder-test\"\n+\tbucketName := testutil.TestBucket(ctx, t, tc.ProjectID, \"golang-samples-transcoder\")\n \tinputURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testVideoFileName\n \tinputConcatURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testConcatFileName\n \tinputOverlayImageURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testOverlayImageFileName",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -95,7 +95,7 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \n \ttestJobTemplates(t, projectNumber)\n \tt.Logf(\"\\ntestJobTemplates() completed\\n\")\n-\twriteTestGCSFiles(t, tc.ProjectID, bucketName)\n+\twriteTestGCSFiles(t, bucketName)\n \tt.Logf(\"\\nwriteTestGCSFiles() completed\\n\")\n \ttestJobFromPreset(t, projectNumber, inputURI, outputURIForPreset)\n \tt.Logf(\"\\ntestJobFromPreset() completed\\n\")",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/acl/acl_test.go",
        "code_diff": "@@ -17,9 +17,8 @@\npackage acl\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n+\t\"io\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/acl/acl_test.go",
        "code_diff": "@@ -36,13 +35,11 @@\nfunc TestACL(t *testing.T) {\n \tdefer client.Close()\n \n \tvar (\n-\t\tbucket                = tc.ProjectID + \"-samples-acl-bucket-1\"\n+\t\tbucket                = testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, \"samples-acl-bucket-1\")\n \t\tobject                = \"foo.txt\"\n \t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers\n \t)\n \n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n-\n \tb := client.Bucket(bucket)\n \n \t// Upload a test object with storage.Writer.",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/acl/acl_test.go",
        "code_diff": "@@ -61,10 +58,10 @@\nfunc TestACL(t *testing.T) {\n \tif err := addBucketDefaultOwner(bucket, allAuthenticatedUsers); err != nil {\n \t\tt.Errorf(\"addBucketDefaultOwner: %v\", err)\n \t}\n-\tif err := printBucketACL(ioutil.Discard, bucket); err != nil {\n+\tif err := printBucketACL(io.Discard, bucket); err != nil {\n \t\tt.Errorf(\"printBucketACL: %v\", err)\n \t}\n-\tif err := printBucketACLForUser(ioutil.Discard, bucket, allAuthenticatedUsers); err != nil {\n+\tif err := printBucketACLForUser(io.Discard, bucket, allAuthenticatedUsers); err != nil {\n \t\tt.Errorf(\"printBucketACLForUser: %v\", err)\n \t}\n \tif err := removeBucketDefaultOwner(bucket, allAuthenticatedUsers); err != nil {",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -119,11 +119,7 @@\nfunc TestStorageClass(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tif err := changeDefaultStorageClass(ioutil.Discard, bucketName); err != nil {\n \t\tt.Errorf(\"changeDefaultStorageClass: %v\", err)",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -142,11 +138,7 @@\nfunc TestListBuckets(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tbuckets, err := listBuckets(ioutil.Discard, tc.ProjectID)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -171,11 +163,7 @@\nfunc TestGetBucketMetadata(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tbuf := new(bytes.Buffer)\n \tif _, err := getBucketMetadata(buf, bucketName); err != nil {",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -192,11 +180,7 @@\nfunc TestIAM(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tif _, err := getBucketPolicy(ioutil.Discard, bucketName); err != nil {\n \t\tt.Errorf(\"getBucketPolicy: %#v\", err)",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -230,11 +214,7 @@\nfunc TestCORSConfiguration(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \twant := []storage.CORS{\n \t\t{",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -270,11 +250,7 @@\nfunc TestRequesterPays(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \t// Tests which update the bucket metadata must be retried in order to avoid\n \t// flakes from rate limits.",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -297,11 +273,7 @@\nfunc TestKMS(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")\n \tcryptoKeyID := os.Getenv(\"GOLANG_SAMPLES_KMS_CRYPTOKEY\")",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -341,11 +313,7 @@\nfunc TestBucketLock(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tretentionPeriod := 5 * time.Second\n \ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -432,11 +400,7 @@\nfunc TestUniformBucketLevelAccess(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n \t\tif err := enableUniformBucketLevelAccess(ioutil.Discard, bucketName); err != nil {",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -471,11 +435,7 @@\nfunc TestPublicAccessPrevention(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tif err := setPublicAccessPreventionEnforced(ioutil.Discard, bucketName); err != nil {\n \t\tt.Errorf(\"setPublicAccessPreventionEnforced: %v\", err)",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -518,11 +478,7 @@\nfunc TestLifecycleManagement(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tif err := enableBucketLifecycleManagement(ioutil.Discard, bucketName); err != nil {\n \t\tt.Fatalf(\"enableBucketLifecycleManagement: %v\", err)",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -568,11 +524,7 @@\nfunc TestBucketLabel(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tlabelName := \"label-name\"\n \tlabelValue := \"label-value\"",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -610,11 +562,7 @@\nfunc TestBucketWebsiteInfo(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tindex := \"index.html\"\n \tnotFoundPage := \"404.html\"",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -639,11 +587,7 @@\nfunc TestSetBucketPublicIAM(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tif err != nil {\n-\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n-\t}\n-\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tif err := setBucketPublicIAM(ioutil.Discard, bucketName); err != nil {\n \t\tt.Fatalf(\"setBucketPublicIAM: %v\", err)",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/control_quickstart/main_test.go",
        "code_diff": "@@ -50,13 +50,7 @@\nfunc TestControlQuickstart(t *testing.T) {\n \t\t}\n \t})\n \n-\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n-\tt.Cleanup(func() {\n-\t\ttestutil.DeleteBucketIfExists(ctx, client, bucketName)\n-\t})\n-\tif err != nil {\n-\t\tt.Fatalf(\"creating bucket: %v\", err)\n-\t}\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \n \tstdOut, stdErr, err := m.Run(nil, time.Minute, \"--bucket\", bucketName)",
        "comments": [],
        "commit_messages": [
            "update calls to createtestbucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -19,7 +19,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n+\t\"log\"\n \t\"mime/multipart\"\n \t\"net/http\"\n \t\"net/http/httputil\"",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -33,48 +33,70 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-// TestObjects runs all samples tests of the package.\n+const (\n+\ttestPrefix      = \"storage-objects-test\"\n+\tbucketExpiryAge = time.Hour * 24\n+)\n+\n+func TestMain(m *testing.M) {\n+\t// Run tests\n+\texit := m.Run()\n+\n+\t// Delete old buckets whose name begins with our test prefix\n+\ttc, _ := testutil.ContextMain(m)\n+\n+\tctx := context.Background()\n+\tc, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tdefer c.Close()\n+\n+\tif err := testutil.DeleteExpiredBuckets(c, tc.ProjectID, testPrefix, bucketExpiryAge); err != nil {\n+\t\t// Don't fail the test if cleanup fails\n+\t\tlog.Printf(\"Post-test cleanup failed: %v\", err)\n+\t}\n+\tos.Exit(exit)\n+}\n+\n+// TestObjects runs most of the samples tests of the package.\n func TestObjects(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tt.Cleanup(func() { client.Close() })\n \n-\tdir, err := ioutil.TempDir(\"\", \"objectsTestTempDir\")\n+\tdir, err := os.MkdirTemp(\"\", \"objectsTestTempDir\")\n \tif err != nil {\n-\t\tt.Fatalf(\"ioutil.TempDir: %v\", err)\n+\t\tt.Fatalf(\"os.MkdirTemp: %v\", err)\n \t}\n \tdefer os.RemoveAll(dir) // clean up\n \n \tvar (\n-\t\tbucket           = tc.ProjectID + \"-samples-object-bucket-1\"\n-\t\tdstBucket        = tc.ProjectID + \"-samples-object-bucket-2\"\n-\t\tbucketVersioning = tc.ProjectID + \"-bucket-versioning-enabled\"\n+\t\tbucket           = testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\t\tdstBucket        = testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\t\tbucketVersioning = testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \t\tobject1          = \"foo.txt\"\n \t\tobject2          = \"foo/a.txt\"\n \t\tobject3          = \"bar.txt\"\n \t\tdstObj           = \"foobar.txt\"\n \t)\n \n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, dstBucket)\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketVersioning)\n-\n-\tif err := enableVersioning(ioutil.Discard, bucketVersioning); err != nil {\n+\tif err := enableVersioning(io.Discard, bucketVersioning); err != nil {\n \t\tt.Fatalf(\"enableVersioning: %v\", err)\n \t}\n \n-\tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {\n+\tif err := uploadFile(io.Discard, bucket, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n \t}\n-\tif err := uploadFile(ioutil.Discard, bucket, object2); err != nil {\n+\tif err := uploadFile(io.Discard, bucket, object2); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object2, err)\n \t}\n \n-\tif err := streamFileUpload(ioutil.Discard, bucketVersioning, object1); err != nil {\n+\tif err := streamFileUpload(io.Discard, bucketVersioning, object1); err != nil {\n \t\tt.Fatalf(\"streamFileUpload(%q): %v\", object1, err)\n \t}\n \t// Check enableVersioning correctly work.",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -91,7 +113,7 @@\nfunc TestObjects(t *testing.T) {\n \t// Keep the original generation of object1 before re-uploading\n \t// to use in the versioning samples.\n \tgen := attrs.Generation\n-\tif err := streamFileUpload(ioutil.Discard, bucketVersioning, object1); err != nil {\n+\tif err := streamFileUpload(io.Discard, bucketVersioning, object1); err != nil {\n \t\tt.Fatalf(\"streamFileUpload(%q): %v\", object1, err)\n \t}",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -144,14 +166,14 @@\nfunc TestObjects(t *testing.T) {\n \t}\n \n \t{\n-\t\tif err := downloadUsingRequesterPays(ioutil.Discard, bucket, object1, tc.ProjectID); err != nil {\n+\t\tif err := downloadUsingRequesterPays(io.Discard, bucket, object1, tc.ProjectID); err != nil {\n \t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)\n \t\t}\n \t}\n \tt.Run(\"changeObjectStorageClass\", func(t *testing.T) {\n \t\tbkt := client.Bucket(bucket)\n \t\tobj := bkt.Object(object1)\n-\t\tif err := changeObjectStorageClass(ioutil.Discard, bucket, object1); err != nil {\n+\t\tif err := changeObjectStorageClass(io.Discard, bucket, object1); err != nil {\n \t\t\tt.Errorf(\"changeObjectStorageClass: %v\", err)\n \t\t}\n \t\twantStorageClass := \"COLDLINE\"",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -163,14 +185,14 @@\nfunc TestObjects(t *testing.T) {\n \t\t\tt.Errorf(\"object storage class: got %q, want %q\", oattrs.StorageClass, wantStorageClass)\n \t\t}\n \t})\n-\tif err := copyOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, object3, gen); err != nil {\n+\tif err := copyOldVersionOfObject(io.Discard, bucketVersioning, object1, object3, gen); err != nil {\n \t\tt.Fatalf(\"copyOldVersionOfObject: %v\", err)\n \t}\n \t// Delete the first version of an object1 for a bucketVersioning.\n-\tif err := deleteOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, gen); err != nil {\n+\tif err := deleteOldVersionOfObject(io.Discard, bucketVersioning, object1, gen); err != nil {\n \t\tt.Fatalf(\"deleteOldVersionOfObject: %v\", err)\n \t}\n-\tdata, err := downloadFileIntoMemory(ioutil.Discard, bucket, object1)\n+\tdata, err := downloadFileIntoMemory(io.Discard, bucket, object1)\n \tif err != nil {\n \t\tt.Fatalf(\"downloadFileIntoMemory: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -181,7 +203,7 @@\nfunc TestObjects(t *testing.T) {\n \tt.Run(\"setMetadata\", func(t *testing.T) {\n \t\tbkt := client.Bucket(bucket)\n \t\tobj := bkt.Object(object1)\n-\t\terr = setMetadata(ioutil.Discard, bucket, object1)\n+\t\terr = setMetadata(io.Discard, bucket, object1)\n \t\tif err != nil {\n \t\t\tt.Errorf(\"setMetadata: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -193,15 +215,15 @@\nfunc TestObjects(t *testing.T) {\n \t\t\tt.Errorf(\"object content = %q; want %q\", got, want)\n \t\t}\n \t})\n-\t_, err = getMetadata(ioutil.Discard, bucket, object1)\n+\t_, err = getMetadata(io.Discard, bucket, object1)\n \tif err != nil {\n \t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tt.Run(\"publicFile\", func(t *testing.T) {\n-\t\tif err := makePublic(ioutil.Discard, bucket, object1); err != nil {\n+\t\tif err := makePublic(io.Discard, bucket, object1); err != nil {\n \t\t\tt.Errorf(\"makePublic: %v\", err)\n \t\t}\n-\t\tdata, err = downloadPublicFile(ioutil.Discard, bucket, object1)\n+\t\tdata, err = downloadPublicFile(io.Discard, bucket, object1)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"downloadPublicFile: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -212,13 +234,13 @@\nfunc TestObjects(t *testing.T) {\n \n \tt.Run(\"downloadByteRange\", func(t *testing.T) {\n \t\tdestination := filepath.Join(dir, \"fileDownloadByteRangeDestination.txt\")\n-\t\terr = downloadByteRange(ioutil.Discard, bucket, object1, 1, 4, destination)\n+\t\terr = downloadByteRange(io.Discard, bucket, object1, 1, 4, destination)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"downloadFile: %v\", err)\n \t\t}\n-\t\tdata, err := ioutil.ReadFile(destination)\n+\t\tdata, err := os.ReadFile(destination)\n \t\tif err != nil {\n-\t\t\tt.Fatalf(\"ioutil.ReadFile: %v\", err)\n+\t\t\tt.Fatalf(\"os.ReadFile: %v\", err)\n \t\t}\n \t\tif got, want := string(data), \"ell\"; got != want {\n \t\t\tt.Errorf(\"contents = %q; want %q\", got, want)",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -227,31 +249,31 @@\nfunc TestObjects(t *testing.T) {\n \n \tt.Run(\"downloadFile\", func(t *testing.T) {\n \t\tdestination := filepath.Join(dir, \"fileDownloadDestination.txt\")\n-\t\terr = downloadFile(ioutil.Discard, bucket, object1, destination)\n+\t\terr = downloadFile(io.Discard, bucket, object1, destination)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"downloadFile: %v\", err)\n \t\t}\n-\t\tdata, err := ioutil.ReadFile(destination)\n+\t\tdata, err := os.ReadFile(destination)\n \t\tif err != nil {\n-\t\t\tt.Fatalf(\"ioutil.ReadFile: %v\", err)\n+\t\t\tt.Fatalf(\"os.ReadFile: %v\", err)\n \t\t}\n \t\tif got, want := string(data), \"Hello\\nworld\"; got != want {\n \t\t\tt.Errorf(\"contents = %q; want %q\", got, want)\n \t\t}\n \t})\n \n-\terr = moveFile(ioutil.Discard, bucket, object1)\n+\terr = moveFile(io.Discard, bucket, object1)\n \tif err != nil {\n \t\tt.Fatalf(\"moveFile: %v\", err)\n \t}\n \t// object1's new name.\n \tobject1 = object1 + \"-rename\"\n \n-\tif err := copyFile(ioutil.Discard, dstBucket, bucket, object1); err != nil {\n+\tif err := copyFile(io.Discard, dstBucket, bucket, object1); err != nil {\n \t\tt.Errorf(\"copyFile: %v\", err)\n \t}\n \tt.Run(\"composeFile\", func(t *testing.T) {\n-\t\tif err := composeFile(ioutil.Discard, bucket, object1, object2, dstObj); err != nil {\n+\t\tif err := composeFile(io.Discard, bucket, object1, object2, dstObj); err != nil {\n \t\t\tt.Errorf(\"composeFile: %v\", err)\n \t\t}\n \t\tbkt := client.Bucket(bucket)",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -264,40 +286,34 @@\nfunc TestObjects(t *testing.T) {\n \t\t}\n \t})\n \n-\tif err := deleteFile(ioutil.Discard, bucket, object1); err != nil {\n+\tif err := deleteFile(io.Discard, bucket, object1); err != nil {\n \t\tt.Errorf(\"deleteFile: %v\", err)\n \t}\n \n \tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \tnewKey := []byte(\"My-secret-AES-256-encryption-key\")\n \n-\tif err := generateEncryptionKey(ioutil.Discard); err != nil {\n+\tif err := generateEncryptionKey(io.Discard); err != nil {\n \t\tt.Errorf(\"generateEncryptionKey: %v\", err)\n \t}\n-\tif err := uploadEncryptedFile(ioutil.Discard, bucket, object1, key); err != nil {\n+\tif err := uploadEncryptedFile(io.Discard, bucket, object1, key); err != nil {\n \t\tt.Errorf(\"uploadEncryptedFile: %v\", err)\n \t}\n-\tdata, err = downloadEncryptedFile(ioutil.Discard, bucket, object1, key)\n+\tdata, err = downloadEncryptedFile(io.Discard, bucket, object1, key)\n \tif err != nil {\n \t\tt.Errorf(\"downloadEncryptedFile: %v\", err)\n \t}\n \tif got, want := string(data), \"top secret\"; got != want {\n \t\tt.Errorf(\"object content = %q; want %q\", got, want)\n \t}\n-\tif err := rotateEncryptionKey(ioutil.Discard, bucket, object1, key, newKey); err != nil {\n+\tif err := rotateEncryptionKey(io.Discard, bucket, object1, key, newKey); err != nil {\n \t\tt.Errorf(\"rotateEncryptionKey: %v\", err)\n \t}\n-\tif err := deleteFile(ioutil.Discard, bucket, object1); err != nil {\n-\t\tt.Errorf(\"deleteFile: %v\", err)\n-\t}\n-\tif err := deleteFile(ioutil.Discard, bucket, object2); err != nil {\n-\t\tt.Errorf(\"deleteFile: %v\", err)\n-\t}\n \to := client.Bucket(bucket).Object(dstObj)\n \tif err := o.Delete(ctx); err != nil {\n \t\tt.Errorf(\"Object(%q).Delete: %v\", dstObj, err)\n \t}\n-\tif err := disableVersioning(ioutil.Discard, bucketVersioning); err != nil {\n+\tif err := disableVersioning(io.Discard, bucketVersioning); err != nil {\n \t\tt.Fatalf(\"disableVersioning: %v\", err)\n \t}\n \tbAttrs, err = bkt.Attrs(ctx)",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -307,33 +323,6 @@\nfunc TestObjects(t *testing.T) {\n \tif bAttrs.VersioningEnabled {\n \t\tt.Fatalf(\"object versioning is not disabled\")\n \t}\n-\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\t// Cleanup, this part won't be executed if Fatal happens.\n-\t\t// TODO(jbd): Implement garbage cleaning.\n-\t\tif err := client.Bucket(bucket).Delete(ctx); err != nil {\n-\t\t\tr.Errorf(\"Bucket(%q).Delete: %v\", bucket, err)\n-\t\t}\n-\t})\n-\n-\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := deleteFile(ioutil.Discard, dstBucket, object1+\"-copy\"); err != nil {\n-\t\t\tr.Errorf(\"deleteFile: %v\", err)\n-\t\t}\n-\t})\n-\n-\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := client.Bucket(dstBucket).Delete(ctx); err != nil {\n-\t\t\tr.Errorf(\"Bucket(%q).Delete: %v\", dstBucket, err)\n-\t\t}\n-\t})\n-\n-\t// CleanBucket to delete versioned objects in bucket\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketVersioning)\n-\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := client.Bucket(bucketVersioning).Delete(ctx); err != nil {\n-\t\t\tr.Errorf(\"Bucket(%q).Delete: %v\", bucketVersioning, err)\n-\t\t}\n-\t})\n }\n \n func TestKMSObjects(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -343,19 +332,17 @@\nfunc TestKMSObjects(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tt.Cleanup(func() { client.Close() })\n \n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")\n \tcryptoKeyID := os.Getenv(\"GOLANG_SAMPLES_KMS_CRYPTOKEY\")\n \tif keyRingID == \"\" || cryptoKeyID == \"\" {\n \t\tt.Skip(\"GOLANG_SAMPLES_KMS_KEYRING and GOLANG_SAMPLES_KMS_CRYPTOKEY must be set\")\n \t}\n \n-\tbucket := tc.ProjectID + \"-samples-object-bucket-kms\"\n+\tbucket := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tobject := \"foo.txt\"\n \n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n-\n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \tt.Run(\"\u0441hangeObjectCSEKtoKMS\", func(t *testing.T) {\n \t\tobject1 := \"foo1.txt\"",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -371,7 +358,7 @@\nfunc TestKMSObjects(t *testing.T) {\n \t\t\t\tr.Errorf(\"Writer.Close: %v\", err)\n \t\t\t}\n \t\t})\n-\t\tif err := \u0441hangeObjectCSEKToKMS(ioutil.Discard, bucket, object1, key, kmsKeyName); err != nil {\n+\t\tif err := \u0441hangeObjectCSEKToKMS(io.Discard, bucket, object1, key, kmsKeyName); err != nil {\n \t\t\tt.Errorf(\"\u0441hangeObjectCSEKtoKMS: %v\", err)\n \t\t}\n \t\tattrs, err := obj.Attrs(ctx)",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -383,20 +370,23 @@\nfunc TestKMSObjects(t *testing.T) {\n \t\t}\n \t})\n \n-\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object, kmsKeyName); err != nil {\n+\tif err := uploadWithKMSKey(io.Discard, bucket, object, kmsKeyName); err != nil {\n \t\tt.Errorf(\"uploadWithKMSKey: %v\", err)\n \t}\n }\n \n func TestV4SignedURL(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tt.Cleanup(func() { client.Close() })\n \n-\tbucketName := tc.ProjectID + \"-signed-url-bucket-name\"\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tobjectName := \"foo.txt\"\n \n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n-\n \t// Generate PUT URL.\n \tputBuf := new(bytes.Buffer)\n \tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName)",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -455,13 +445,15 @@\nfunc TestV4SignedURL(t *testing.T) {\n func TestPostPolicyV4(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tt.Cleanup(func() { client.Close() })\n \n-\tbucketName := tc.ProjectID + \"-post-policy-bucket-name\"\n+\tbucketName := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tobjectName := \"foo.txt\"\n \n-\tif err := testutil.CleanBucket(ctx, t, tc.ProjectID, bucketName); err != nil {\n-\t\tt.Fatalf(\"CleanBucket: %v\", err)\n-\t}\n \tputBuf := new(bytes.Buffer)\n \tpolicy, err := generateSignedPostPolicyV4(putBuf, bucketName, objectName)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -534,18 +526,12 @@\nfunc TestPostPolicyV4(t *testing.T) {\n \t\t\t\tg, w, string(requestDump), responseDump)\n \t\t}\n \n-\t\tio.Copy(ioutil.Discard, res.Body)\n+\t\tio.Copy(io.Discard, res.Body)\n \t\tif err := res.Body.Close(); err != nil {\n \t\t\tr.Errorf(\"Body.Close: %v\", err)\n \t\t}\n \t})\n \n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n-\t}\n-\tdefer client.Close()\n-\n \t// Verify that the file was uploaded by reading back its attributes.\n \tbkt := client.Bucket(bucketName)\n \tobj := bkt.Object(objectName)",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -566,22 +552,21 @@\nfunc TestObjectBucketLock(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tt.Cleanup(func() { client.Close() })\n \n \tvar (\n-\t\tbucketName      = tc.ProjectID + \"-retent-samples-object-bucket\"\n+\t\tbucketName      = testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \t\tobjectName      = \"foo.txt\"\n \t\tretentionPeriod = 5 * time.Second\n \t)\n \n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tbucket := client.Bucket(bucketName)\n \tbucketAttrs, err := bucket.Attrs(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"Bucket(%q).Update: %v\", bucketName, err)\n \t}\n \n-\tif err := uploadFile(ioutil.Discard, bucketName, objectName); err != nil {\n+\tif err := uploadFile(io.Discard, bucketName, objectName); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", objectName, err)\n \t}\n \t// Updating a bucket is conditionally idempotent, so we set metageneration match and let the library handle the retry",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -593,20 +578,20 @@\nfunc TestObjectBucketLock(t *testing.T) {\n \t\t}); err != nil {\n \t\tt.Errorf(\"Bucket(%q).Update: %v\", bucketName, err)\n \t}\n-\tif err := setEventBasedHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\tif err := setEventBasedHold(io.Discard, bucketName, objectName); err != nil {\n \t\tt.Errorf(\"setEventBasedHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err := getMetadata(ioutil.Discard, bucketName, objectName)\n+\toAttrs, err := getMetadata(io.Discard, bucketName, objectName)\n \tif err != nil {\n \t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif !oAttrs.EventBasedHold {\n \t\tt.Errorf(\"event-based hold is not enabled\")\n \t}\n-\tif err := releaseEventBasedHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\tif err := releaseEventBasedHold(io.Discard, bucketName, objectName); err != nil {\n \t\tt.Errorf(\"releaseEventBasedHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err = getMetadata(ioutil.Discard, bucketName, objectName)\n+\toAttrs, err = getMetadata(io.Discard, bucketName, objectName)\n \tif err != nil {\n \t\tt.Errorf(\"getMetadata: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "remove all references to CleanBucket"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(all): remove all references to CleanBucket",
        "pr_number": 4000,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -17,7 +17,6 @@\npackage main\n import (\n \t\"bytes\"\n \t\"context\"\n-\t\"fmt\"\n \t\"io\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "bug fixes"
        ],
        "last_commit_sha": "4898d2e970783de137eb798a2f2ce8ba4e9dde9a"
    },
    {
        "pr_title": "test(storagetransfer): add retries to all storagetransfer tests",
        "pr_number": 3972,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -150,84 +150,90 @@\nfunc TestMain(m *testing.M) {\n func TestQuickstart(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n-\tresp, err := quickstart(buf, tc.ProjectID, gcsSourceBucket, gcsSinkBucket)\n-\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n \n-\tif err != nil {\n-\t\tt.Errorf(\"quickstart: %#v\", err)\n-\t}\n+\t\tresp, err := quickstart(buf, tc.ProjectID, gcsSourceBucket, gcsSinkBucket)\n+\t\tdefer cleanupSTSJob(resp, tc.ProjectID)\n \n-\tgot := buf.String()\n-\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"quickstart: got %q, want %q\", got, want)\n-\t}\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"quickstart: %#v\", err)\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"quickstart: got %q, want %q\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestTransferFromAws(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n+\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n \n-\tresp, err := transferFromAws(buf, tc.ProjectID, s3Bucket, gcsSinkBucket)\n-\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\t\tresp, err := transferFromAws(buf, tc.ProjectID, s3Bucket, gcsSinkBucket)\n+\t\tdefer cleanupSTSJob(resp, tc.ProjectID)\n \n-\tif err != nil {\n-\t\tt.Errorf(\"transfer_from_aws: %#v\", err)\n-\t}\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"transfer_from_aws: %#v\", err)\n+\t\t}\n \n-\tgot := buf.String()\n-\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"transfer_from_aws: got %q, want %q\", got, want)\n-\t}\n+\t\tgot := buf.String()\n+\t\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"transfer_from_aws: got %q, want %q\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestTransferToNearline(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n+\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n \n-\tresp, err := transferToNearline(buf, tc.ProjectID, gcsSourceBucket, gcsSinkBucket)\n-\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\t\tresp, err := transferToNearline(buf, tc.ProjectID, gcsSourceBucket, gcsSinkBucket)\n+\t\tdefer cleanupSTSJob(resp, tc.ProjectID)\n \n-\tif err != nil {\n-\t\tt.Errorf(\"transfer_from_aws: %#v\", err)\n-\t}\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"transfer_from_aws: %#v\", err)\n+\t\t}\n \n-\tgot := buf.String()\n-\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"transfer_to_nearline: got %q, want %q\", got, want)\n-\t}\n+\t\tgot := buf.String()\n+\t\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"transfer_to_nearline: got %q, want %q\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestGetLatestTransferOperation(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n-\n-\tjob, err := transferToNearline(buf, tc.ProjectID, gcsSourceBucket, gcsSinkBucket)\n-\tdefer cleanupSTSJob(job, tc.ProjectID)\n+\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n \n-\top, err := checkLatestTransferOperation(buf, tc.ProjectID, job.Name)\n+\t\tjob, err := transferToNearline(buf, tc.ProjectID, gcsSourceBucket, gcsSinkBucket)\n+\t\tdefer cleanupSTSJob(job, tc.ProjectID)\n \n-\tif err != nil {\n-\t\tt.Errorf(\"check_latest_transfer_operation: %#v\", err)\n-\t}\n-\tif !strings.Contains(op.Name, \"transferOperations/\") {\n-\t\tt.Errorf(\"check_latest_transfer_operation: Operation returned didn't have a valid operation name: %q\", op.Name)\n-\t}\n+\t\top, err := checkLatestTransferOperation(buf, tc.ProjectID, job.Name)\n \n-\tgot := buf.String()\n-\tif want := op.Name; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"check_latest_transfer_operation: got %q, want %q\", got, want)\n-\t}\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"check_latest_transfer_operation: %#v\", err)\n+\t\t}\n+\t\tif !strings.Contains(op.Name, \"transferOperations/\") {\n+\t\t\tr.Errorf(\"check_latest_transfer_operation: Operation returned didn't have a valid operation name: %q\", op.Name)\n+\t\t}\n+\t\tgot := buf.String()\n+\t\tif want := op.Name; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"check_latest_transfer_operation: got %q, want %q\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestDownloadToPosix(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n-\n \trootDirectory, err := ioutil.TempDir(\"\", \"download-to-posix-test\")\n \tif err != nil {\n \t\tt.Fatalf(\"download_to_posix: %#v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "dfd69ed611c69003d870e123eb1b41b56c19ef10"
    },
    {
        "pr_title": "test(storagetransfer): add retries to all storagetransfer tests",
        "pr_number": 3972,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -237,24 +243,26 @@\nfunc TestDownloadToPosix(t *testing.T) {\n \tsinkAgentPoolName := \"\" //use default agent pool\n \tgcsSourcePath := rootDirectory + \"/\"\n \n-\tresp, err := downloadToPosix(buf, tc.ProjectID, sinkAgentPoolName, gcsSinkBucket, gcsSourcePath, rootDirectory)\n-\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n \n-\tif err != nil {\n-\t\tt.Errorf(\"download_to_posix: %#v\", err)\n-\t}\n+\t\tresp, err := downloadToPosix(buf, tc.ProjectID, sinkAgentPoolName, gcsSinkBucket, gcsSourcePath, rootDirectory)\n+\t\tdefer cleanupSTSJob(resp, tc.ProjectID)\n \n-\tgot := buf.String()\n-\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"download_to_posix: got %q, want %q\", got, want)\n-\t}\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"download_to_posix: %#v\", err)\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"download_to_posix: got %q, want %q\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestTransferFromPosix(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n-\n \trootDirectory, err := ioutil.TempDir(\"\", \"transfer-from-posix-test\")\n \tif err != nil {\n \t\tt.Fatalf(\"transfer_from_posix: %#v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "dfd69ed611c69003d870e123eb1b41b56c19ef10"
    },
    {
        "pr_title": "test(storagetransfer): add retries to all storagetransfer tests",
        "pr_number": 3972,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -263,24 +271,26 @@\nfunc TestTransferFromPosix(t *testing.T) {\n \n \tsourceAgentPoolName := \"\" //use default agent pool\n \n-\tresp, err := transferFromPosix(buf, tc.ProjectID, sourceAgentPoolName, rootDirectory, gcsSinkBucket)\n-\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n \n-\tif err != nil {\n-\t\tt.Errorf(\"transfer_from_posix: %#v\", err)\n-\t}\n+\t\tresp, err := transferFromPosix(buf, tc.ProjectID, sourceAgentPoolName, rootDirectory, gcsSinkBucket)\n+\t\tdefer cleanupSTSJob(resp, tc.ProjectID)\n \n-\tgot := buf.String()\n-\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"transfer_from_posix: got %q, want %q\", got, want)\n-\t}\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"transfer_from_posix: %#v\", err)\n+\t\t}\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"transfer_from_posix: got %q, want %q\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestTransferBetweenPosix(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n-\n \trootDirectory, err := ioutil.TempDir(\"\", \"transfer-between-posix-test-source\")\n \tif err != nil {\n \t\tt.Fatalf(\"transfer_between_posix: %#v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "dfd69ed611c69003d870e123eb1b41b56c19ef10"
    },
    {
        "pr_title": "test(storagetransfer): add retries to all storagetransfer tests",
        "pr_number": 3972,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -296,23 +306,25 @@\nfunc TestTransferBetweenPosix(t *testing.T) {\n \tsourceAgentPoolName := \"\" //use default agent pool\n \tsinkAgentPoolName := \"\"   //use default agent pool\n \n-\tresp, err := transferBetweenPosix(buf, tc.ProjectID, sourceAgentPoolName, sinkAgentPoolName, rootDirectory, destinationDirectory, gcsSinkBucket)\n-\tif err != nil {\n-\t\tt.Errorf(\"transfer_between_posix: %#v\", err)\n-\t}\n-\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n \n-\tgot := buf.String()\n-\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"transfer_between_posix: got %q, want %q\", got, want)\n-\t}\n+\t\tresp, err := transferBetweenPosix(buf, tc.ProjectID, sourceAgentPoolName, sinkAgentPoolName, rootDirectory, destinationDirectory, gcsSinkBucket)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"transfer_between_posix: %#v\", err)\n+\t\t}\n+\t\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"transfer_between_posix: got %q, want %q\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestTransferUsingManifest(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n-\n \trootDirectory, err := ioutil.TempDir(\"\", \"transfer-using-manifest-test\")\n \tif err != nil {\n \t\tt.Fatalf(\"transfer_using_manifest: %#v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "dfd69ed611c69003d870e123eb1b41b56c19ef10"
    },
    {
        "pr_title": "test(storagetransfer): add retries to all storagetransfer tests",
        "pr_number": 3972,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -324,62 +336,68 @@\nfunc TestTransferUsingManifest(t *testing.T) {\n \tdefer object.Delete(context.Background())\n \n \ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n+\n \t\tresp, err := transferUsingManifest(buf, tc.ProjectID, sourceAgentPoolName, rootDirectory, gcsSinkBucket, gcsSourceBucket, \"manifest.csv\")\n \t\tdefer cleanupSTSJob(resp, tc.ProjectID)\n \n \t\tif err != nil {\n \t\t\tr.Errorf(\"transfer_using_manifest: %#v\", err)\n \t\t}\n-\t})\n \n-\tgot := buf.String()\n-\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"transfer_using_manifest: got %q, want %q\", got, want)\n-\t}\n+\t\tgot := buf.String()\n+\t\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"transfer_using_manifest: got %q, want %q\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestTransferFromS3CompatibleSource(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tbuf := new(bytes.Buffer)\n-\n \tsourceAgentPoolName := \"\" //use default agent pool\n \tsourcePath := \"\"          //use root directory\n \tgcsPath := \"\"             //use root directory\n \n-\tresp, err := transferFromS3CompatibleSource(buf, tc.ProjectID, sourceAgentPoolName, s3Bucket, sourcePath, gcsSinkBucket, gcsPath)\n+\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n \n-\tif err != nil {\n-\t\tt.Errorf(\"transfer_from_s3_compatible_source: %#v\", err)\n-\t}\n-\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\t\tresp, err := transferFromS3CompatibleSource(buf, tc.ProjectID, sourceAgentPoolName, s3Bucket, sourcePath, gcsSinkBucket, gcsPath)\n \n-\tgot := buf.String()\n-\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"transfer_from_s3_compatible_source: got %q, want %q\", got, want)\n-\t}\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"transfer_from_s3_compatible_source: %#v\", err)\n+\t\t}\n+\t\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"transfer_from_s3_compatible_source: got %q, want %q\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestTransferFromAzure(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n \n \taccountName := os.Getenv(\"AZURE_STORAGE_ACCOUNT\")\n-\tresp, err := transferFromAzure(buf, tc.ProjectID, accountName, azureContainer, gcsSinkBucket)\n-\tif err != nil {\n-\t\tt.Errorf(\"transfer_from_azure: %#v\", err)\n-\t}\n-\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n \n-\tgot := buf.String()\n-\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"transfer_from_azure: got %q, want %q\", got, want)\n-\t}\n+\t\tresp, err := transferFromAzure(buf, tc.ProjectID, accountName, azureContainer, gcsSinkBucket)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"transfer_from_azure: %#v\", err)\n+\t\t}\n+\t\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"transfer_from_azure: got %q, want %q\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestCreateEventDrivenGCSTransfer(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n \tctx := context.Background()\n \n \tpubSubTopicId := testutil.UniqueBucketName(\"pubsubtopic\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "dfd69ed611c69003d870e123eb1b41b56c19ef10"
    },
    {
        "pr_title": "test(storagetransfer): add retries to all storagetransfer tests",
        "pr_number": 3972,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -417,21 +435,24 @@\nfunc TestCreateEventDrivenGCSTransfer(t *testing.T) {\n \n \tpubSubSubscriptionID := sub.String()\n \n-\tresp, err := createEventDrivenGCSTransfer(buf, tc.ProjectID, gcsSourceBucket, gcsSinkBucket, pubSubSubscriptionID)\n-\tif err != nil {\n-\t\tt.Errorf(\"create_event_driven_gcs_transfer: %#v\", err)\n-\t}\n-\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\ttestutil.Retry(t, 5, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n \n-\tgot := buf.String()\n-\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"create_event_driven_gcs_transfer: got %q, want %q\", got, want)\n-\t}\n+\t\tresp, err := createEventDrivenGCSTransfer(buf, tc.ProjectID, gcsSourceBucket, gcsSinkBucket, pubSubSubscriptionID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"create_event_driven_gcs_transfer: %#v\", err)\n+\t\t}\n+\t\tdefer cleanupSTSJob(resp, tc.ProjectID)\n+\n+\t\tgot := buf.String()\n+\t\tif want := \"transferJobs/\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"create_event_driven_gcs_transfer: got %q, want %q\", got, want)\n+\t\t}\n+\t})\n }\n \n func TestCreateEventDrivenAWSTransfer(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n \n \tqueue := testutil.UniqueBucketName(\"stssqsqueue\")\n \tsqsClient := sqs.New(sess)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "dfd69ed611c69003d870e123eb1b41b56c19ef10"
    },
    {
        "pr_title": "feat(pubsub): add create kinesis topic and update samples",
        "pr_number": 3800,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n+\t\"cloud.google.com/go/pubsub/pstest\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"google.golang.org/api/iterator\"\n )",
        "comments": [],
        "commit_messages": [
            "feat(pubsub): add create kinesis topic and update samples"
        ],
        "last_commit_sha": "e0a339ad6c2ab7c336e3d94c3593c3282511624b"
    },
    {
        "pr_title": "feat(vertexai): Multimodal sample with video",
        "pr_number": 3774,
        "file_name": "vertexai/multimodal/multimodal.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2023 Google LLC\n+// Copyright 2024 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "test(vertexai): add test for multimodal, multimodal-video"
        ],
        "last_commit_sha": "bed3c6e4d84eb461ab8f18ad47e023055b957340"
    },
    {
        "pr_title": "feat(vertexai): Multimodal sample with video",
        "pr_number": 3774,
        "file_name": "vertexai/multimodal/multimodal.go",
        "code_diff": "@@ -13,41 +13,27 @@\n// limitations under the License.\n \n // multimodal shows an example of understanding multimodal input\n-package main\n+package multimodal\n \n import (\n \t\"context\"\n+\t\"errors\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"mime\"\n-\t\"os\"\n \t\"path/filepath\"\n \n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-func main() {\n-\tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n-\tlocation := \"us-central1\"\n-\tmodelName := \"gemini-1.0-pro-vision\"\n-\n-\tprompt := \"describe what is in this picture\"\n-\timage := \"gs://generativeai-downloads/images/scones.jpg\"\n-\n-\tif projectID == \"\" {\n-\t\tlog.Fatal(\"require environment variable GOOGLE_CLOUD_PROJECT\")\n-\t}\n-\n-\terr := generateMultimodalContent(os.Stdout, prompt, image, projectID, location, modelName)\n-\tif err != nil {\n-\t\tlog.Fatalf(\"unable to generate: %v\", err)\n-\t}\n-}\n-\n // generateMultimodalContent generates a response into w, based upon the prompt\n // and image provided.\n+// image is a Google Cloud Storage path starting with \"gs://\"\n func generateMultimodalContent(w io.Writer, prompt, image, projectID, location, modelName string) error {\n+\t// prompt := \"describe what is in this picture\"\n+\t// image := \"gs://generativeai-downloads/images/scones.jpg\"\n+\t// location := \"us-central1\"\n+\t// modelName := \"gemini-1.0-pro-vision\"\n \tctx := context.Background()\n \n \tclient, err := genai.NewClient(ctx, projectID, location)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bed3c6e4d84eb461ab8f18ad47e023055b957340"
    },
    {
        "pr_title": "chore(opentelemetry): update opentelemetry dependency, and handle non-fatal resource errors",
        "pr_number": 3771,
        "file_name": "opentelemetry/instrumentation/app/main_test.go",
        "code_diff": "@@ -68,7 +68,7 @@\nfunc TestWriteTelemetry(t *testing.T) {\n \t\tt:               t,\n \t\texpectationsMet: make(chan struct{}),\n \t\texpectations: []*metricExpectation{\n-\t\t\t{name: \"http.rquest.duration\"},\n+\t\t\t{name: \"http.server.duration\"},\n \t\t},\n \t}\n \thttp.HandleFunc(\"/v1/metrics\", ms.handleMetrics)",
        "comments": [],
        "commit_messages": [
            "fix opentelemetry unit test"
        ],
        "last_commit_sha": "eb119e07eaa3db8e953bf940be17c80da9e4789c"
    },
    {
        "pr_title": "chore(opentelemetry): update opentelemetry dependency, and handle non-fatal resource errors",
        "pr_number": 3771,
        "file_name": "opentelemetry/instrumentation/app/main_test.go",
        "code_diff": "@@ -123,7 +123,7 @@\nfunc TestWriteTelemetry(t *testing.T) {\n \t\tselect {\n \t\tcase <-time.After(timeoutSeconds * time.Second):\n \t\t\tt.Error(\"Timeout waiting for metrics\")\n-\t\tcase <-ts.expectationsMet:\n+\t\tcase <-ms.expectationsMet:\n \t\t}\n \t\twg.Done()\n \t}()",
        "comments": [],
        "commit_messages": [
            "fix opentelemetry unit test"
        ],
        "last_commit_sha": "eb119e07eaa3db8e953bf940be17c80da9e4789c"
    },
    {
        "pr_title": "chore(opentelemetry): update opentelemetry dependency, and handle non-fatal resource errors",
        "pr_number": 3771,
        "file_name": "opentelemetry/trace/main.go",
        "code_diff": "@@ -19,6 +19,7 @@\npackage main\n // [START opentelemetry_trace_import]\n import (\n \t\"context\"\n+\t\"errors\"\n \t\"log\"\n \t\"os\"",
        "comments": [],
        "commit_messages": [
            "chore: update opentelemetry dependency, and handle non-fatal resource errors"
        ],
        "last_commit_sha": "eb119e07eaa3db8e953bf940be17c80da9e4789c"
    },
    {
        "pr_title": "test(storage): add retry to HMAC key deletion",
        "pr_number": 3759,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\nimport (\n \t\"context\"\n \t\"errors\"\n \t\"fmt\"\n+\t\"io\"\n \t\"io/ioutil\"\n \t\"os\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "test(storage): add retry to HMAC key deletion"
        ],
        "last_commit_sha": "705ca7c6c578bc328873239a29e3b233a77d5ad4"
    },
    {
        "pr_title": "test(storage): add retry to flaky SignedURL test",
        "pr_number": 3758,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -391,16 +391,13 @@\nfunc TestKMSObjects(t *testing.T) {\n func TestV4SignedURL(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n-\t}\n-\tdefer client.Close()\n \n \tbucketName := tc.ProjectID + \"-signed-url-bucket-name\"\n \tobjectName := \"foo.txt\"\n \n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n+\n+\t// Generate PUT URL.\n \tputBuf := new(bytes.Buffer)\n \tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "test(storage): add retry to flaky SignedURL test"
        ],
        "last_commit_sha": "6444b60bbce119978b77a99522892df39f416728"
    },
    {
        "pr_title": "test(storage): add retry to flaky SignedURL test",
        "pr_number": 3758,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -411,17 +408,7 @@\nfunc TestV4SignedURL(t *testing.T) {\n \t\tt.Errorf(\"got %q, want %q\", got, want)\n \t}\n \n-\thttpClient := &http.Client{}\n-\trequest, err := http.NewRequest(\"PUT\", putURL, strings.NewReader(\"hello world\"))\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to compose HTTP request: %v\", err)\n-\t}\n-\trequest.ContentLength = 11\n-\trequest.Header.Set(\"Content-Type\", \"application/octet-stream\")\n-\t_, err = httpClient.Do(request)\n-\tif err != nil {\n-\t\tt.Errorf(\"httpClient.Do: %v\", err)\n-\t}\n+\t// Generate GET URL.\n \tgetBuf := new(bytes.Buffer)\n \tgetURL, err := generateV4GetObjectSignedURL(getBuf, bucketName, objectName)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "test(storage): add retry to flaky SignedURL test"
        ],
        "last_commit_sha": "6444b60bbce119978b77a99522892df39f416728"
    },
    {
        "pr_title": "feat: add VOD session methods and tests",
        "pr_number": 3728,
        "file_name": "media/videostitcher/create_vod_session.go",
        "code_diff": "@@ -21,7 +21,7 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // createVodSession creates a video on demand (VOD) session in which to insert ads.",
        "comments": [],
        "commit_messages": [
            "feat: add VOD session methods and tests"
        ],
        "last_commit_sha": "86b86de0c54b645ff9dcf23ace2d301edb9b61e8"
    },
    {
        "pr_title": "feat: add VOD session methods and tests",
        "pr_number": 3728,
        "file_name": "media/videostitcher/get_vod_ad_tag_detail.go",
        "code_diff": "@@ -22,7 +22,7 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // getVodAdTagDetail gets the specified ad tag detail for a video on demand (VOD) session.",
        "comments": [],
        "commit_messages": [
            "feat: add VOD session methods and tests"
        ],
        "last_commit_sha": "86b86de0c54b645ff9dcf23ace2d301edb9b61e8"
    },
    {
        "pr_title": "feat: add VOD session methods and tests",
        "pr_number": 3728,
        "file_name": "media/videostitcher/get_vod_session.go",
        "code_diff": "@@ -22,7 +22,7 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // getVodSession gets a VOD session by ID.",
        "comments": [],
        "commit_messages": [
            "feat: add VOD session methods and tests"
        ],
        "last_commit_sha": "86b86de0c54b645ff9dcf23ace2d301edb9b61e8"
    },
    {
        "pr_title": "feat: add VOD session methods and tests",
        "pr_number": 3728,
        "file_name": "media/videostitcher/get_vod_stitch_detail.go",
        "code_diff": "@@ -22,7 +22,7 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // getVodStitchDetail gets the specified stitch detail for a video on demand (VOD) session.",
        "comments": [],
        "commit_messages": [
            "feat: add VOD session methods and tests"
        ],
        "last_commit_sha": "86b86de0c54b645ff9dcf23ace2d301edb9b61e8"
    },
    {
        "pr_title": "feat: add VOD session methods and tests",
        "pr_number": 3728,
        "file_name": "media/videostitcher/list_vod_ad_tag_details.go",
        "code_diff": "@@ -21,7 +21,7 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n \t\"google.golang.org/api/iterator\"\n )",
        "comments": [],
        "commit_messages": [
            "feat: add VOD session methods and tests"
        ],
        "last_commit_sha": "86b86de0c54b645ff9dcf23ace2d301edb9b61e8"
    },
    {
        "pr_title": "feat: add VOD session methods and tests",
        "pr_number": 3728,
        "file_name": "media/videostitcher/list_vod_stitch_details.go",
        "code_diff": "@@ -21,7 +21,7 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n \t\"google.golang.org/api/iterator\"\n )",
        "comments": [],
        "commit_messages": [
            "feat: add VOD session methods and tests"
        ],
        "last_commit_sha": "86b86de0c54b645ff9dcf23ace2d301edb9b61e8"
    },
    {
        "pr_title": "feat: add VOD session methods and tests",
        "pr_number": 3728,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -49,7 +49,8 @@\nconst (\n \tupdatedHostname      = \"updated.cdn.example.com\"\n \tkeyName              = \"my-key\"\n \n-\tvodURI = \"https://storage.googleapis.com/cloud-samples-data/media/hls-vod/manifest.m3u8\"\n+\tvodURI      = \"https://storage.googleapis.com/cloud-samples-data/media/hls-vod/manifest.m3u8\"\n+\tvodAdTagURI = \"https://pubads.g.doubleclick.net/gampad/ads?iu=/21775744923/external/vmap_ad_samples&sz=640x480&cust_params=sample_ar%3Dpreonly&ciu_szs=300x250%2C728x90&gdfp_req=1&ad_rule=1&output=vmap&unviewed_position_start=1&env=vp&impl=s&correlator=\"\n \n \tliveConfigIDPrefix       = \"go-test-live-config\"\n \tdeleteLiveConfigResponse = \"Deleted live config\"",
        "comments": [],
        "commit_messages": [
            "feat: add VOD session methods and tests"
        ],
        "last_commit_sha": "86b86de0c54b645ff9dcf23ace2d301edb9b61e8"
    },
    {
        "pr_title": "feat: add VOD session methods and tests",
        "pr_number": 3728,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -446,7 +447,8 @@\nfunc createTestLiveSession(liveConfigID string, t *testing.T) (string, string) {\n \t\t\tLiveConfig: fmt.Sprintf(\"projects/%s/locations/%s/liveConfigs/%s\", tc.ProjectID, location, liveConfigID),\n \t\t},\n \t}\n-\t// Creates the live session.\n+\t// Creates the live session. Live sessions are\n+\t// ephemeral resources that expire after a few minutes.\n \tresponse, err := client.CreateLiveSession(ctx, req)\n \tif err != nil {\n \t\tt.Fatal(err)",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "86b86de0c54b645ff9dcf23ace2d301edb9b61e8"
    },
    {
        "pr_title": "test(profiler): add tests for ListProfiles sample",
        "pr_number": 3707,
        "file_name": "profiler/export/main.go",
        "code_diff": "@@ -19,11 +19,13 @@\npackage main\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"encoding/csv\"\n \t\"encoding/json\"\n \t\"flag\"\n \t\"fmt\"\n+\t\"io\"\n \t\"log\"\n \t\"os\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "test(profiler): add tests for ListProfiles sample"
        ],
        "last_commit_sha": "952811f05f80b56c096e78a44847eb8ff3f55e8a"
    },
    {
        "pr_title": "test(profiler): add tests for ListProfiles sample",
        "pr_number": 3707,
        "file_name": "profiler/export/main.go",
        "code_diff": "@@ -38,22 +40,24 @@\nvar pageSize = flag.Int(\"page_size\", 100, \"Number of profiles fetched per page.\n var pageToken = flag.String(\"page_token\", \"\", \"PageToken from a previous ListProfiles call. If empty, the listing will start from the begnning. Invalid page tokens result in error.\")\n var maxProfiles = flag.Int(\"max_profiles\", 1000, \"Maximum number of profiles to fetch across all pages. If this is <= 0, will fetch all available profiles\")\n \n+const ProfilesDownloadedSuccessfully = \"Read max allowed profiles\"\n+\n // This function reads profiles for a given project and stores them into locally created files.\n // The profile metadata gets stored into a 'metdata.csv' file, while the individual pprof files\n // are created per profile.\n-func run(ctx context.Context) error {\n+func downloadProfiles(ctx context.Context, w io.Writer, project, pageToken string, pageSize, maxProfiles int) error {\n \tclient, err := cloudprofiler.NewExportClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \tdefer client.Close()\n-\tlog.Printf(\"Attempting to fetch %v profiles with a pageSize of %v for %v\\n\", *maxProfiles, *pageSize, *project)\n+\tlog.Printf(\"Attempting to fetch %v profiles with a pageSize of %v for %v\\n\", maxProfiles, pageSize, project)\n \n \t// Initial request for the ListProfiles API\n \trequest := &pb.ListProfilesRequest{\n-\t\tParent:    fmt.Sprintf(\"projects/%s\", *project),\n-\t\tPageSize:  int32(*pageSize),\n-\t\tPageToken: *pageToken,\n+\t\tParent:    fmt.Sprintf(\"projects/%s\", project),\n+\t\tPageSize:  int32(pageSize),\n+\t\tPageToken: pageToken,\n \t}\n \n \t// create a folder for storing profiles & metadata",
        "comments": [],
        "commit_messages": [
            "test(profiler): add tests for ListProfiles sample"
        ],
        "last_commit_sha": "952811f05f80b56c096e78a44847eb8ff3f55e8a"
    },
    {
        "pr_title": "test(profiler): add tests for ListProfiles sample",
        "pr_number": 3707,
        "file_name": "profiler/export/main.go",
        "code_diff": "@@ -95,6 +99,7 @@\nfunc run(ctx context.Context) error {\n \t\tif err != nil {\n \t\t\treturn fmt.Errorf(\"unable to write file %s: %v\", filename, err)\n \t\t}\n+\t\tfmt.Fprintf(w, \"deployment target: %v\\n\", profile.Deployment.Labels)\n \n \t\tlabelBytes, err := json.Marshal(profile.Labels)\n \t\tif err != nil {",
        "comments": [],
        "commit_messages": [
            "test(profiler): add tests for ListProfiles sample"
        ],
        "last_commit_sha": "952811f05f80b56c096e78a44847eb8ff3f55e8a"
    },
    {
        "pr_title": "test(profiler): add tests for ListProfiles sample",
        "pr_number": 3707,
        "file_name": "profiler/export/main.go",
        "code_diff": "@@ -106,8 +111,8 @@\nfunc run(ctx context.Context) error {\n \t\t\treturn err\n \t\t}\n \n-\t\tif *maxProfiles > 0 && profileCount >= *maxProfiles {\n-\t\t\tlog.Println(\"Read max allowed profiles\")\n+\t\tif maxProfiles > 0 && profileCount >= maxProfiles {\n+\t\t\tfmt.Fprintf(w, \"result: %v\", ProfilesDownloadedSuccessfully)\n \t\t\tbreak\n \t\t}",
        "comments": [],
        "commit_messages": [
            "test(profiler): add tests for ListProfiles sample"
        ],
        "last_commit_sha": "952811f05f80b56c096e78a44847eb8ff3f55e8a"
    },
    {
        "pr_title": "feat: add live session methods and tests",
        "pr_number": 3618,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -16,9 +16,12 @@\npackage videostitcher\n \n import (\n \t\"context\"\n+\t\"errors\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"log\"\n-\n+\t\"net/http\"\n+\t\"regexp\"\n \t\"strconv\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "feat: add live session methods and tests"
        ],
        "last_commit_sha": "183a038ac6ae4ef9edb98c153dd18394b49d8200"
    },
    {
        "pr_title": "feat: add live session methods and tests",
        "pr_number": 3618,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -229,6 +232,38 @@\nfunc getUUID64() (string, error) {\n \treturn strings.ReplaceAll(uuid, \"-\", \"\"), nil\n }\n \n+// Get the playURI first. The last line of the response will contain a\n+// renditions location. Return the renditions.\n+func getPlayURI(playURI string) ([]string, error) {\n+\tresp, err := http.Get(playURI)\n+\tif err != nil {\n+\t\treturn nil, errors.New(\"\\nError getting the play URI\\n\")\n+\t}\n+\tdefer resp.Body.Close()\n+\tbody, err := ioutil.ReadAll(resp.Body)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"ioutil.ReadAll: %v\", err)\n+\t}\n+\n+\tre := regexp.MustCompile(`renditions/.*`)\n+\trenditions := re.FindStringSubmatch(string(body))\n+\tif len(renditions) == 0 {\n+\t\treturn nil, fmt.Errorf(\"\\nRenditions not found in body: %s\\n\", string(body))\n+\t}\n+\treturn renditions, nil\n+}\n+\n+// Curl a rendition.\n+func curlRendition(playURI, renditions string) error {\n+\tre := regexp.MustCompile(`manifest.m3u8.*`)\n+\trenditionURI := re.ReplaceAllString(playURI, renditions)\n+\t_, err := http.Get(renditionURI)\n+\tif err != nil {\n+\t\treturn errors.New(\"\\nError getting the rendition URI\\n\")\n+\t}\n+\treturn nil\n+}\n+\n func createTestSlate(slateID string, t *testing.T) {\n \tt.Helper()\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "183a038ac6ae4ef9edb98c153dd18394b49d8200"
    },
    {
        "pr_title": "chore(vertexai): clean up chat example",
        "pr_number": 3616,
        "file_name": "vertexai/chat/chat.go",
        "code_diff": "@@ -24,11 +24,8 @@\nimport (\n \t\"cloud.google.com/go/vertexai/genai\"\n )\n \n-func makeChatRequests(w io.Writer, projectID string, location string, modelName string) error {\n-\t// location := \"us-central1\"\n-\t// modelName := \"gemini-1.0-pro-002\"\n-\tctx := context.Background()\n-\tclient, err := genai.NewClient(ctx, projectID, location)\n+func makeChatRequests(ctx context.Context, w io.Writer, projectID, region, modelName string) error {\n+\tclient, err := genai.NewClient(ctx, projectID, region)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"error creating client: %w\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "28adb657d0a35efb7fd8e1047fb0f9f8eaf1051e"
    },
    {
        "pr_title": "fix(vertexai): use gs:// in safety-settings-multimodal",
        "pr_number": 3615,
        "file_name": "vertexai/safety-settings-multimodal/safety-settings-multimodal.go",
        "code_diff": "@@ -20,10 +20,9 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"log\"\n-\t\"net/http\"\n-\t\"net/url\"\n+\t\"mime\"\n \t\"os\"\n-\t\"strings\"\n+\t\"path/filepath\"\n \n \t\"cloud.google.com/go/vertexai/genai\"\n )",
        "comments": [],
        "commit_messages": [
            "fix(vertexai): use gs:// in safety-settings-multimodal"
        ],
        "last_commit_sha": "36c1e74dd64607e40575603748bfb3ea925c0ddd"
    },
    {
        "pr_title": "fix(vertexai): use gs:// in safety-settings-multimodal",
        "pr_number": 3615,
        "file_name": "vertexai/safety-settings-multimodal/safety-settings-multimodal.go",
        "code_diff": "@@ -32,39 +31,33 @@\nfunc main() {\n \tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tlocation := \"us-central1\"\n \tmodelName := \"gemini-pro-vision\"\n-\ttemperature := 0.4\n+\n+\tprompt := \"describe what is in this picture\"\n+\timage := \"gs://generativeai-downloads/images/scones.jpg\"\n \n \tif projectID == \"\" {\n \t\tlog.Fatal(\"require environment variable GOOGLE_CLOUD_PROJECT\")\n \t}\n \n-\tcat, _ := partFromImageURL(\"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\")\n-\n-\t// create a multipart (multimodal) prompt\n-\tprompt := []genai.Part{\n-\t\tgenai.Text(\"say something nice about this \"),\n-\t\tcat,\n-\t}\n-\n-\terr := generateContent(os.Stdout, prompt, projectID, location, modelName, float32(temperature))\n+\terr := generateMultimodalContent(os.Stdout, prompt, image, projectID, location, modelName)\n \tif err != nil {\n-\t\tfmt.Printf(\"unable to generate: %v\\n\", err)\n+\t\tlog.Fatalf(\"unable to generate: %v\", err)\n \t}\n }\n \n-// generateContent generates text from prompt and configurations provided.\n-func generateContent(w io.Writer, prompt []genai.Part, projectID, location, modelName string, temperature float32) error {\n+// generateMultimodalContent generates a response into w, based upon the prompt\n+// and image provided.\n+func generateMultimodalContent(w io.Writer, prompt, image, projectID, location, modelName string) error {\n \tctx := context.Background()\n \n \tclient, err := genai.NewClient(ctx, projectID, location)\n \tif err != nil {\n-\t\treturn err\n+\t\treturn fmt.Errorf(\"unable to create client: %v\", err)\n \t}\n \tdefer client.Close()\n \n \tmodel := client.GenerativeModel(modelName)\n-\tmodel.Temperature = temperature\n-\n+\tmodel.Temperature = 0.4\n \t// configure the safety settings thresholds\n \tmodel.SafetySettings = []*genai.SafetySetting{\n \t\t{",
        "comments": [],
        "commit_messages": [
            "fix(vertexai): use gs:// in safety-settings-multimodal"
        ],
        "last_commit_sha": "36c1e74dd64607e40575603748bfb3ea925c0ddd"
    },
    {
        "pr_title": "feat(otel): use Cloud Logging structured log conventions",
        "pr_number": 3590,
        "file_name": "opentelemetry/instrumentation/app/logger.go",
        "code_diff": "@@ -16,11 +16,15 @@\npackage main\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"log/slog\"\n+\t\"os\"\n \n \t\"go.opentelemetry.io/otel/trace\"\n )\n \n+var projectId = os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n+\n // handerWithSpanContext adds attributes from the span context\n // [START opentelemetry_instrumentation_spancontext_logger]\n func handerWithSpanContext(handler slog.Handler) *spanContextLogHandler {",
        "comments": [],
        "commit_messages": [
            "feat(otel): use Cloud Logging structured log conventions"
        ],
        "last_commit_sha": "4d2ab3693db87978a792803cf0b2c4922b78fc74"
    },
    {
        "pr_title": "feat(otel): use Cloud Logging structured log conventions",
        "pr_number": 3590,
        "file_name": "opentelemetry/instrumentation/app/main_test.go",
        "code_diff": "@@ -132,13 +132,13 @@\nfunc TestWriteTelemetry(t *testing.T) {\n }\n \n type expectedLogFormat struct {\n-\tTime        string `json:\"time\"`\n-\tLevel       string `json:\"level\"`\n-\tMsg         string `json:\"msg\"`\n-\tSubRequests int    `json:\"subRequests\"`\n-\tTraceID     string `json:\"trace_id\"`\n-\tSpanID      string `json:\"span_id\"`\n-\tTraceFlags  string `json:\"trace_flags\"`\n+\tTimestamp    string `json:\"timestamp\"`\n+\tSeverity     string `json:\"severity\"`\n+\tMessage      string `json:\"message\"`\n+\tSubRequests  int    `json:\"subRequests\"`\n+\tTraceID      string `json:\"logging.googleapis.com/trace\"`\n+\tSpanID       string `json:\"logging.googleapis.com/spanId\"`\n+\tTraceSampled bool   `json:\"logging.googleapis.com/trace_sampled\"`\n }\n \n const expectedLogMessage = \"handle /multi request\"",
        "comments": [],
        "commit_messages": [
            "feat(otel): use Cloud Logging structured log conventions"
        ],
        "last_commit_sha": "4d2ab3693db87978a792803cf0b2c4922b78fc74"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/create_cdn_key_akamai_test.go",
        "code_diff": "@@ -40,7 +40,7 @@\nfunc TestCreateAkamaiCDNKey(t *testing.T) {\n \t\tt.Fatalf(\"getUUID64 err: %v\", err)\n \t}\n \n-\takamaiCDNKeyID := fmt.Sprintf(\"%s-%s\", akamaiCDNKeyID, uuid)\n+\takamaiCDNKeyID := fmt.Sprintf(\"%s-%s\", akamaiCDNKeyIDPrefix, uuid)\n \takamaiCDNKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, akamaiCDNKeyID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tif err := createCDNKeyAkamai(&buf, tc.ProjectID, akamaiCDNKeyID, akamaiTokenKey); err != nil {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/create_cdn_key_test.go",
        "code_diff": "@@ -16,16 +16,12 @@\npackage videostitcher\n \n import (\n \t\"bytes\"\n-\t\"context\"\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\n-\tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n func TestCreateMediaCDNKey(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/create_cdn_key_test.go",
        "code_diff": "@@ -44,7 +40,7 @@\nfunc TestCreateMediaCDNKey(t *testing.T) {\n \t\tt.Fatalf(\"getUUID64 err: %v\", err)\n \t}\n \n-\tmediaCDNKeyID := fmt.Sprintf(\"%s-%s\", mediaCDNKeyID, uuid)\n+\tmediaCDNKeyID := fmt.Sprintf(\"%s-%s\", mediaCDNKeyIDPrefix, uuid)\n \tmediaCDNKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, mediaCDNKeyID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tif err := createCDNKey(&buf, tc.ProjectID, mediaCDNKeyID, mediaCDNPrivateKey, true); err != nil {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/create_cdn_key_test.go",
        "code_diff": "@@ -54,8 +50,9 @@\nfunc TestCreateMediaCDNKey(t *testing.T) {\n \t\t\tr.Errorf(\"createCDNKey got: %v Want to contain: %v\", got, mediaCDNKeyName)\n \t\t}\n \t})\n+\n \tt.Cleanup(func() {\n-\t\tteardownTestCreateCDNKey(mediaCDNKeyName, t)\n+\t\tdeleteTestCDNKey(mediaCDNKeyName, t)\n \t})\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/create_cdn_key_test.go",
        "code_diff": "@@ -75,7 +72,7 @@\nfunc TestCreateCloudCDNKey(t *testing.T) {\n \t\tt.Fatalf(\"getUUID64 err: %v\", err)\n \t}\n \n-\tcloudCDNKeyID := fmt.Sprintf(\"%s-%s\", cloudCDNKeyID, uuid)\n+\tcloudCDNKeyID := fmt.Sprintf(\"%s-%s\", cloudCDNKeyIDPrefix, uuid)\n \tcloudCDNKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, cloudCDNKeyID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tif err := createCDNKey(&buf, tc.ProjectID, cloudCDNKeyID, cloudCDNPrivateKey, false); err != nil {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/create_slate_test.go",
        "code_diff": "@@ -16,16 +16,12 @@\npackage videostitcher\n \n import (\n \t\"bytes\"\n-\t\"context\"\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\n-\tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n func TestCreateSlate(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/create_slate_test.go",
        "code_diff": "@@ -36,7 +32,7 @@\nfunc TestCreateSlate(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"getUUID err: %v\", err)\n \t}\n-\tslateID := fmt.Sprintf(\"%s-%s\", slateID, uuid)\n+\tslateID := fmt.Sprintf(\"%s-%s\", slateIDPrefix, uuid)\n \tslateName := fmt.Sprintf(\"projects/%s/locations/%s/slates/%s\", tc.ProjectID, location, slateID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tif err := createSlate(&buf, tc.ProjectID, slateID, slateURI); err != nil {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/get_cdn_key_test.go",
        "code_diff": "@@ -16,83 +16,23 @@\npackage videostitcher\n \n import (\n \t\"bytes\"\n-\t\"context\"\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\n-\tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n-func setupTestGetCDNKey(keyID string, t *testing.T) func() {\n-\tt.Helper()\n-\tctx := context.Background()\n-\n-\tclient, err := stitcher.NewVideoStitcherClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"stitcher.NewVideoStitcherClient: %v\", err)\n-\t}\n-\t// client.Close() is called in the returned function\n-\n-\t// Create a random private key for the CDN key. It is not validated.\n-\tmediaCDNPrivateKey, err := getUUID64()\n-\tif err != nil {\n-\t\tt.Fatalf(\"getUUID64 err: %v\", err)\n-\t}\n-\n-\ttc := testutil.SystemTest(t)\n-\treq := &stitcherstreampb.CreateCdnKeyRequest{\n-\t\tParent:   fmt.Sprintf(\"projects/%s/locations/%s\", tc.ProjectID, location),\n-\t\tCdnKeyId: keyID,\n-\t\tCdnKey: &stitcherstreampb.CdnKey{\n-\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_MediaCdnKey{\n-\t\t\t\tMediaCdnKey: &stitcherstreampb.MediaCdnKey{\n-\t\t\t\t\tKeyName:    keyName,\n-\t\t\t\t\tPrivateKey: []byte(mediaCDNPrivateKey),\n-\t\t\t\t},\n-\t\t\t},\n-\t\t\tHostname: hostname,\n-\t\t},\n-\t}\n-\top, err := client.CreateCdnKey(ctx, req)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\t_, err = op.Wait(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\treturn func() {\n-\t\treq := &stitcherstreampb.DeleteCdnKeyRequest{\n-\t\t\tName: fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, keyID),\n-\t\t}\n-\t\t_, err := client.DeleteCdnKey(ctx, req)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\t_, err = op.Wait(ctx)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\tclient.Close()\n-\t}\n-}\n-\n func TestGetCDNKey(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n \tuuid, err := getUUID()\n \tif err != nil {\n \t\tt.Fatalf(\"getUUID err: %v\", err)\n \t}\n-\tmediaCDNKeyID := fmt.Sprintf(\"%s-%s\", mediaCDNKeyID, uuid)\n-\tteardown := setupTestGetCDNKey(mediaCDNKeyID, t)\n-\tt.Cleanup(teardown)\n+\tmediaCDNKeyID := fmt.Sprintf(\"%s-%s\", mediaCDNKeyIDPrefix, uuid)\n+\tcreateTestMediaCDNKey(mediaCDNKeyID, t)\n \n \tmediaCDNKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, mediaCDNKeyID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/get_slate_test.go",
        "code_diff": "@@ -16,71 +16,23 @@\npackage videostitcher\n \n import (\n \t\"bytes\"\n-\t\"context\"\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\n-\tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n-func setupTestGetSlate(slateID string, t *testing.T) func() {\n-\tt.Helper()\n-\tctx := context.Background()\n-\n-\tclient, err := stitcher.NewVideoStitcherClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"stitcher.NewVideoStitcherClient: %v\", err)\n-\t}\n-\t// client.Close() is called in the returned function\n-\n-\ttc := testutil.SystemTest(t)\n-\treq := &stitcherstreampb.CreateSlateRequest{\n-\t\tParent:  fmt.Sprintf(\"projects/%s/locations/%s\", tc.ProjectID, location),\n-\t\tSlateId: slateID,\n-\t\tSlate: &stitcherstreampb.Slate{\n-\t\t\tUri: slateURI,\n-\t\t},\n-\t}\n-\top, err := client.CreateSlate(ctx, req)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\t_, err = op.Wait(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\treturn func() {\n-\t\treq := &stitcherstreampb.DeleteSlateRequest{\n-\t\t\tName: fmt.Sprintf(\"projects/%s/locations/%s/slates/%s\", tc.ProjectID, location, slateID),\n-\t\t}\n-\t\t_, err := client.DeleteSlate(ctx, req)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\t_, err = op.Wait(ctx)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\tclient.Close()\n-\t}\n-}\n-\n func TestGetSlate(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n \tuuid, err := getUUID()\n \tif err != nil {\n \t\tt.Fatalf(\"getUUID err: %v\", err)\n \t}\n-\tslateID := fmt.Sprintf(\"%s-%s\", slateID, uuid)\n-\tteardown := setupTestGetSlate(slateID, t)\n-\tt.Cleanup(teardown)\n+\tslateID := fmt.Sprintf(\"%s-%s\", slateIDPrefix, uuid)\n+\tcreateTestSlate(slateID, t)\n \n \tslateName := fmt.Sprintf(\"projects/%s/locations/%s/slates/%s\", tc.ProjectID, location, slateID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/list_cdn_keys_test.go",
        "code_diff": "@@ -16,83 +16,23 @@\npackage videostitcher\n \n import (\n \t\"bytes\"\n-\t\"context\"\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\n-\tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n-func setupTestListCDNKeys(keyID string, t *testing.T) func() {\n-\tt.Helper()\n-\tctx := context.Background()\n-\n-\tclient, err := stitcher.NewVideoStitcherClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"stitcher.NewVideoStitcherClient: %v\", err)\n-\t}\n-\t// client.Close() is called in the returned function\n-\n-\t// Create a random private key for the CDN key. It is not validated.\n-\tmediaCDNPrivateKey, err := getUUID64()\n-\tif err != nil {\n-\t\tt.Fatalf(\"getUUID64 err: %v\", err)\n-\t}\n-\n-\ttc := testutil.SystemTest(t)\n-\treq := &stitcherstreampb.CreateCdnKeyRequest{\n-\t\tParent:   fmt.Sprintf(\"projects/%s/locations/%s\", tc.ProjectID, location),\n-\t\tCdnKeyId: keyID,\n-\t\tCdnKey: &stitcherstreampb.CdnKey{\n-\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_MediaCdnKey{\n-\t\t\t\tMediaCdnKey: &stitcherstreampb.MediaCdnKey{\n-\t\t\t\t\tKeyName:    keyName,\n-\t\t\t\t\tPrivateKey: []byte(mediaCDNPrivateKey),\n-\t\t\t\t},\n-\t\t\t},\n-\t\t\tHostname: hostname,\n-\t\t},\n-\t}\n-\top, err := client.CreateCdnKey(ctx, req)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\t_, err = op.Wait(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\treturn func() {\n-\t\treq := &stitcherstreampb.DeleteCdnKeyRequest{\n-\t\t\tName: fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, keyID),\n-\t\t}\n-\t\t_, err := client.DeleteCdnKey(ctx, req)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\t_, err = op.Wait(ctx)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\tclient.Close()\n-\t}\n-}\n-\n func TestListCDNKeys(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n \tuuid, err := getUUID()\n \tif err != nil {\n \t\tt.Fatalf(\"getUUID err: %v\", err)\n \t}\n-\tmediaCDNKeyID := fmt.Sprintf(\"%s-%s\", mediaCDNKeyID, uuid)\n-\tteardown := setupTestListCDNKeys(mediaCDNKeyID, t)\n-\tt.Cleanup(teardown)\n+\tmediaCDNKeyID := fmt.Sprintf(\"%s-%s\", mediaCDNKeyIDPrefix, uuid)\n+\tcreateTestMediaCDNKey(mediaCDNKeyID, t)\n \n \tmediaCDNKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, mediaCDNKeyID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/list_slates_test.go",
        "code_diff": "@@ -16,71 +16,23 @@\npackage videostitcher\n \n import (\n \t\"bytes\"\n-\t\"context\"\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\n-\tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n-func setupTestListSlates(slateID string, t *testing.T) func() {\n-\tt.Helper()\n-\tctx := context.Background()\n-\n-\tclient, err := stitcher.NewVideoStitcherClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"stitcher.NewVideoStitcherClient: %v\", err)\n-\t}\n-\t// client.Close() is called in the returned function\n-\n-\ttc := testutil.SystemTest(t)\n-\treq := &stitcherstreampb.CreateSlateRequest{\n-\t\tParent:  fmt.Sprintf(\"projects/%s/locations/%s\", tc.ProjectID, location),\n-\t\tSlateId: slateID,\n-\t\tSlate: &stitcherstreampb.Slate{\n-\t\t\tUri: slateURI,\n-\t\t},\n-\t}\n-\top, err := client.CreateSlate(ctx, req)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\t_, err = op.Wait(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\treturn func() {\n-\t\treq := &stitcherstreampb.DeleteSlateRequest{\n-\t\t\tName: fmt.Sprintf(\"projects/%s/locations/%s/slates/%s\", tc.ProjectID, location, slateID),\n-\t\t}\n-\t\t_, err := client.DeleteSlate(ctx, req)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\t_, err = op.Wait(ctx)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\tclient.Close()\n-\t}\n-}\n-\n func TestListSlates(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n \tuuid, err := getUUID()\n \tif err != nil {\n \t\tt.Fatalf(\"getUUID err: %v\", err)\n \t}\n-\tslateID := fmt.Sprintf(\"%s-%s\", slateID, uuid)\n-\tteardown := setupTestListSlates(slateID, t)\n-\tt.Cleanup(teardown)\n+\tslateID := fmt.Sprintf(\"%s-%s\", slateIDPrefix, uuid)\n+\tcreateTestSlate(slateID, t)\n \n \tslateName := fmt.Sprintf(\"projects/%s/locations/%s/slates/%s\", tc.ProjectID, location, slateID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -24,34 +24,34 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n \t\"google.golang.org/api/iterator\"\n-\n-\tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n const (\n \tlocation            = \"us-central1\" // All samples use this location\n-\tslateID             = \"go-test-slate\"\n+\tslateIDPrefix       = \"go-test-slate\"\n \tslateURI            = \"https://storage.googleapis.com/cloud-samples-data/media/ForBiggerEscapes.mp4\"\n \tupdatedSlateURI     = \"https://storage.googleapis.com/cloud-samples-data/media/ForBiggerJoyrides.mp4\"\n \tdeleteSlateResponse = \"Deleted slate\"\n \n \tdeleteCDNKeyResponse = \"Deleted CDN key\"\n-\tmediaCDNKeyID        = \"go-test-media-cdn\"\n-\tcloudCDNKeyID        = \"go-test-cloud-cdn\"\n-\takamaiCDNKeyID       = \"go-test-akamai-cdn\"\n+\tmediaCDNKeyIDPrefix  = \"go-test-media-cdn\"\n+\tcloudCDNKeyIDPrefix  = \"go-test-cloud-cdn\"\n+\takamaiCDNKeyIDPrefix = \"go-test-akamai-cdn\"\n \thostname             = \"cdn.example.com\"\n \tupdatedHostname      = \"updated.cdn.example.com\"\n \tkeyName              = \"my-key\"\n \n \tvodURI = \"https://storage.googleapis.com/cloud-samples-data/media/hls-vod/manifest.m3u8\"\n \n-\tliveConfigID             = \"my-go-test-live-config\"\n+\tliveConfigIDPrefix       = \"go-test-live-config\"\n \tdeleteLiveConfigResponse = \"Deleted live config\"\n \tliveURI                  = \"https://storage.googleapis.com/cloud-samples-data/media/hls-live/manifest.m3u8\"\n+\tliveAdTagURI             = \"https://pubads.g.doubleclick.net/gampad/ads?iu=/21775744923/external/single_ad_samples&sz=640x480&cust_params=sample_ct%3Dlinear&ciu_szs=300x250%2C728x90&gdfp_req=1&output=vast&unviewed_position_start=1&env=vp&impl=s&correlator=\"\n )\n \n // To run the tests, do the following:",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -80,23 +80,60 @@\nfunc cleanStaleResources(projectID string) {\n \t}\n \tdefer client.Close()\n \n-\t// Slates\n-\treq := &stitcherstreampb.ListSlatesRequest{\n+\t// Live configs\n+\treq := &stitcherstreampb.ListLiveConfigsRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n \t}\n \n-\tit := client.ListSlates(ctx, req)\n+\tit := client.ListLiveConfigs(ctx, req)\n \n \tfor {\n \t\tresponse, err := it.Next()\n \t\tif err == iterator.Done {\n \t\t\tbreak\n \t\t}\n+\t\tif err != nil {\n+\t\t\tlog.Printf(\"Can't find next live config: %s\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\tif strings.Contains(response.GetName(), liveConfigIDPrefix) {\n+\n+\t\t\tarr := strings.Split(response.GetName(), \"-\")\n+\t\t\tt := arr[len(arr)-1]\n+\t\t\tif isResourceStale(t) == true {\n+\t\t\t\treq := &stitcherstreampb.DeleteLiveConfigRequest{\n+\t\t\t\t\tName: response.GetName(),\n+\t\t\t\t}\n+\t\t\t\t// Deletes the live config.\n+\t\t\t\top, err := client.DeleteLiveConfig(ctx, req)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tlog.Printf(\"cleanStaleResources DeleteLiveConfig: %s\", err)\n+\t\t\t\t}\n+\t\t\t\terr = op.Wait(ctx)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tlog.Printf(\"cleanStaleResources Wait: %s\", err)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// Slates\n+\treq2 := &stitcherstreampb.ListSlatesRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n+\t}\n+\n+\tit2 := client.ListSlates(ctx, req2)\n+\n+\tfor {\n+\t\tresponse, err := it2.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n \t\tif err != nil {\n \t\t\tlog.Printf(\"Can't find next slate: %s\", err)\n \t\t\tcontinue\n \t\t}\n-\t\tif strings.Contains(response.GetName(), slateID) {\n+\t\tif strings.Contains(response.GetName(), slateIDPrefix) {\n \n \t\t\tarr := strings.Split(response.GetName(), \"-\")\n \t\t\tt := arr[len(arr)-1]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -118,24 +155,24 @@\nfunc cleanStaleResources(projectID string) {\n \t}\n \n \t// CDN keys\n-\treq2 := &stitcherstreampb.ListCdnKeysRequest{\n+\treq3 := &stitcherstreampb.ListCdnKeysRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n \t}\n \n-\tit2 := client.ListCdnKeys(ctx, req2)\n+\tit3 := client.ListCdnKeys(ctx, req3)\n \n \tfor {\n-\t\tresponse, err := it2.Next()\n+\t\tresponse, err := it3.Next()\n \t\tif err == iterator.Done {\n \t\t\tbreak\n \t\t}\n \t\tif err != nil {\n \t\t\tlog.Printf(\"Can't find next CDN key: %s\", err)\n \t\t\tcontinue\n \t\t}\n-\t\tif strings.Contains(response.GetName(), mediaCDNKeyID) ||\n-\t\t\tstrings.Contains(response.GetName(), cloudCDNKeyID) ||\n-\t\t\tstrings.Contains(response.GetName(), akamaiCDNKeyID) {\n+\t\tif strings.Contains(response.GetName(), mediaCDNKeyIDPrefix) ||\n+\t\t\tstrings.Contains(response.GetName(), cloudCDNKeyIDPrefix) ||\n+\t\t\tstrings.Contains(response.GetName(), akamaiCDNKeyIDPrefix) {\n \n \t\t\tarr := strings.Split(response.GetName(), \"-\")\n \t\t\tt := arr[len(arr)-1]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/update_cdn_key_akamai_test.go",
        "code_diff": "@@ -22,21 +22,20 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n \tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func setupTestUpdateCDNKeyAkamai(keyID string, t *testing.T) func() {\n+func setupTestUpdateCDNKeyAkamai(keyID string, t *testing.T) {\n \tt.Helper()\n \tctx := context.Background()\n \n \tclient, err := stitcher.NewVideoStitcherClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"stitcher.NewVideoStitcherClient: %v\", err)\n \t}\n-\t// client.Close() is called in the returned function\n+\tdefer client.Close()\n \n \t// Create a random token key for the CDN key. It is not validated.\n \takamaiTokenKey, err := getUUID64()",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/update_cdn_key_akamai_test.go",
        "code_diff": "@@ -65,21 +64,6 @@\nfunc setupTestUpdateCDNKeyAkamai(keyID string, t *testing.T) func() {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n-\n-\treturn func() {\n-\t\treq := &stitcherstreampb.DeleteCdnKeyRequest{\n-\t\t\tName: fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, keyID),\n-\t\t}\n-\t\t_, err := client.DeleteCdnKey(ctx, req)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\t_, err = op.Wait(ctx)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\tclient.Close()\n-\t}\n }\n \n func TestUpdateCDNKeyAkamai(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/update_cdn_key_akamai_test.go",
        "code_diff": "@@ -94,9 +78,8 @@\nfunc TestUpdateCDNKeyAkamai(t *testing.T) {\n \t\tt.Fatalf(\"getUUID64 err: %v\", err)\n \t}\n \n-\takamaiCDNKeyID := fmt.Sprintf(\"%s-%s\", akamaiCDNKeyID, uuid)\n-\tteardown := setupTestUpdateCDNKeyAkamai(akamaiCDNKeyID, t)\n-\tt.Cleanup(teardown)\n+\takamaiCDNKeyID := fmt.Sprintf(\"%s-%s\", akamaiCDNKeyIDPrefix, uuid)\n+\tsetupTestUpdateCDNKeyAkamai(akamaiCDNKeyID, t)\n \n \takamaiCDNKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, akamaiCDNKeyID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/update_cdn_key_test.go",
        "code_diff": "@@ -22,21 +22,20 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n \tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func setupTestUpdateCloudCDNKey(keyID string, t *testing.T) func() {\n+func setupTestUpdateCloudCDNKey(keyID string, t *testing.T) {\n \tt.Helper()\n \tctx := context.Background()\n \n \tclient, err := stitcher.NewVideoStitcherClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"stitcher.NewVideoStitcherClient: %v\", err)\n \t}\n-\t// client.Close() is called in the returned function\n+\tdefer client.Close()\n \n \t// Create a random private key for the CDN key. It is not validated.\n \tcloudCDNPrivateKey, err := getUUID64()",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/update_cdn_key_test.go",
        "code_diff": "@@ -66,76 +65,6 @@\nfunc setupTestUpdateCloudCDNKey(keyID string, t *testing.T) func() {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n-\n-\treturn func() {\n-\t\treq := &stitcherstreampb.DeleteCdnKeyRequest{\n-\t\t\tName: fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, keyID),\n-\t\t}\n-\t\t_, err := client.DeleteCdnKey(ctx, req)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\t_, err = op.Wait(ctx)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\tclient.Close()\n-\t}\n-}\n-\n-func setupTestUpdateMediaCDNKey(keyID string, t *testing.T) func() {\n-\tt.Helper()\n-\tctx := context.Background()\n-\n-\tclient, err := stitcher.NewVideoStitcherClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"stitcher.NewVideoStitcherClient: %v\", err)\n-\t}\n-\t// client.Close() is called in the returned function\n-\n-\t// Create a random private key for the CDN key. It is not validated.\n-\tmediaCDNPrivateKey, err := getUUID64()\n-\tif err != nil {\n-\t\tt.Fatalf(\"getUUID64 err: %v\", err)\n-\t}\n-\n-\ttc := testutil.SystemTest(t)\n-\treq := &stitcherstreampb.CreateCdnKeyRequest{\n-\t\tParent:   fmt.Sprintf(\"projects/%s/locations/%s\", tc.ProjectID, location),\n-\t\tCdnKeyId: keyID,\n-\t\tCdnKey: &stitcherstreampb.CdnKey{\n-\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_MediaCdnKey{\n-\t\t\t\tMediaCdnKey: &stitcherstreampb.MediaCdnKey{\n-\t\t\t\t\tKeyName:    keyName,\n-\t\t\t\t\tPrivateKey: []byte(mediaCDNPrivateKey),\n-\t\t\t\t},\n-\t\t\t},\n-\t\t\tHostname: hostname,\n-\t\t},\n-\t}\n-\top, err := client.CreateCdnKey(ctx, req)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\t_, err = op.Wait(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\treturn func() {\n-\t\treq := &stitcherstreampb.DeleteCdnKeyRequest{\n-\t\t\tName: fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, keyID),\n-\t\t}\n-\t\t_, err := client.DeleteCdnKey(ctx, req)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\t_, err = op.Wait(ctx)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\tclient.Close()\n-\t}\n }\n \n func TestUpdateCloudCDNKey(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/update_cdn_key_test.go",
        "code_diff": "@@ -150,9 +79,8 @@\nfunc TestUpdateCloudCDNKey(t *testing.T) {\n \t\tt.Fatalf(\"getUUID64 err: %v\", err)\n \t}\n \n-\tcloudCDNKeyID := fmt.Sprintf(\"%s-%s\", cloudCDNKeyID, uuid)\n-\tteardown := setupTestUpdateCloudCDNKey(cloudCDNKeyID, t)\n-\tt.Cleanup(teardown)\n+\tcloudCDNKeyID := fmt.Sprintf(\"%s-%s\", cloudCDNKeyIDPrefix, uuid)\n+\tsetupTestUpdateCloudCDNKey(cloudCDNKeyID, t)\n \n \tcloudCDNKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, cloudCDNKeyID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/update_cdn_key_test.go",
        "code_diff": "@@ -166,6 +94,10 @@\nfunc TestUpdateCloudCDNKey(t *testing.T) {\n \t\t\tr.Errorf(\"updateCDNKey got: %v Want to contain: %v\", got, updatedHostname)\n \t\t}\n \t})\n+\n+\tt.Cleanup(func() {\n+\t\tdeleteTestCDNKey(cloudCDNKeyName, t)\n+\t})\n }\n \n func TestUpdateMediaCDNKey(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/update_cdn_key_test.go",
        "code_diff": "@@ -180,9 +112,8 @@\nfunc TestUpdateMediaCDNKey(t *testing.T) {\n \t\tt.Fatalf(\"getUUID64 err: %v\", err)\n \t}\n \n-\tmediaCDNKeyID := fmt.Sprintf(\"%s-%s\", mediaCDNKeyID, uuid)\n-\tteardown := setupTestUpdateMediaCDNKey(mediaCDNKeyID, t)\n-\tt.Cleanup(teardown)\n+\tmediaCDNKeyID := fmt.Sprintf(\"%s-%s\", mediaCDNKeyIDPrefix, uuid)\n+\tcreateTestMediaCDNKey(mediaCDNKeyID, t)\n \n \tmediaCDNKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, mediaCDNKeyID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add live config methods and tests",
        "pr_number": 3584,
        "file_name": "media/videostitcher/update_slate_test.go",
        "code_diff": "@@ -16,71 +16,23 @@\npackage videostitcher\n \n import (\n \t\"bytes\"\n-\t\"context\"\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\n-\tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n-func setupTestUpdateSlate(slateID string, t *testing.T) func() {\n-\tt.Helper()\n-\tctx := context.Background()\n-\n-\tclient, err := stitcher.NewVideoStitcherClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"stitcher.NewVideoStitcherClient: %v\", err)\n-\t}\n-\t// client.Close() is called in the returned function\n-\n-\ttc := testutil.SystemTest(t)\n-\treq := &stitcherstreampb.CreateSlateRequest{\n-\t\tParent:  fmt.Sprintf(\"projects/%s/locations/%s\", tc.ProjectID, location),\n-\t\tSlateId: slateID,\n-\t\tSlate: &stitcherstreampb.Slate{\n-\t\t\tUri: slateURI,\n-\t\t},\n-\t}\n-\top, err := client.CreateSlate(ctx, req)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\t_, err = op.Wait(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\n-\treturn func() {\n-\t\treq := &stitcherstreampb.DeleteSlateRequest{\n-\t\t\tName: fmt.Sprintf(\"projects/%s/locations/%s/slates/%s\", tc.ProjectID, location, slateID),\n-\t\t}\n-\t\t_, err := client.DeleteSlate(ctx, req)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\t_, err = op.Wait(ctx)\n-\t\tif err != nil {\n-\t\t\tt.Error(err)\n-\t\t}\n-\t\tclient.Close()\n-\t}\n-}\n-\n func TestUpdateSlate(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n \tuuid, err := getUUID()\n \tif err != nil {\n \t\tt.Fatalf(\"getUUID err: %v\", err)\n \t}\n-\tslateID := fmt.Sprintf(\"%s-%s\", slateID, uuid)\n-\tteardown := setupTestUpdateSlate(slateID, t)\n-\tt.Cleanup(teardown)\n+\tslateID := fmt.Sprintf(\"%s-%s\", slateIDPrefix, uuid)\n+\tcreateTestSlate(slateID, t)\n \n \tslateName := fmt.Sprintf(\"projects/%s/locations/%s/slates/%s\", tc.ProjectID, location, slateID)\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "move common test functions to common file; rearrange imports alphabetically by package"
        ],
        "last_commit_sha": "5f14755c7f3a5cebb7c05b9a2e9c6f5cecc1f32b"
    },
    {
        "pr_title": "feat: add sample and test for getting an access token from an imperso\u2026",
        "pr_number": 3450,
        "file_name": "auth/auth_test.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage snippets\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "add missing import"
        ],
        "last_commit_sha": "133e131986f263fae31d327a9f22b08e6c2b3467"
    },
    {
        "pr_title": "feat(storage): support autoclass v2.1 samples",
        "pr_number": 3446,
        "file_name": "storage/buckets/set_autoclass.go",
        "code_diff": "@@ -29,9 +29,12 @@\nimport (\n \n // Note: Only update requests that disable Autoclass are currently supported.\n // To enable Autoclass, you must set it at bucket creation time.\n-func setAutoclass(w io.Writer, bucketName string, value bool) error {\n+func setAutoclass(w io.Writer, bucketName string) error {\n \t// bucketName := \"bucket-name\"\n-\t// value := false\n+\t// Enable Autoclass for a bucket. Set enabled to false to disable Autoclass.\n+\t// Set Autoclass.TerminalStorageClass, valid values are NEARLINE and ARCHIVE.\n+\tenabled := true\n+\tterminalStorageClass := \"ARCHIVE\"\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "05197a11cbcb7eca992749a45cb1a24222de4565"
    },
    {
        "pr_title": "feat: convert CDN keys to LROs and add separate tests for each CDN ke\u2026",
        "pr_number": 3349,
        "file_name": "media/videostitcher/get_cdn_key.go",
        "code_diff": "@@ -22,7 +22,7 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // getCDNKey gets a CDN key by ID.",
        "comments": [],
        "commit_messages": [
            "feat: convert CDN keys to LROs and add separate tests for each CDN key sample"
        ],
        "last_commit_sha": "54e9416c4d121d106f05cc86368a01ddd15cd3d7"
    },
    {
        "pr_title": "feat: convert CDN keys to LROs and add separate tests for each CDN ke\u2026",
        "pr_number": 3349,
        "file_name": "media/videostitcher/list_cdn_keys.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n // listCDNKeys gets all of the CDN keys for a given location.",
        "comments": [],
        "commit_messages": [
            "feat: convert CDN keys to LROs and add separate tests for each CDN key sample"
        ],
        "last_commit_sha": "54e9416c4d121d106f05cc86368a01ddd15cd3d7"
    },
    {
        "pr_title": "feat: convert CDN keys to LROs and add separate tests for each CDN ke\u2026",
        "pr_number": 3349,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -40,11 +40,11 @@\nconst (\n \tdeleteSlateResponse = \"Deleted slate\"\n \n \tdeleteCDNKeyResponse = \"Deleted CDN key\"\n-\tmediaCDNKeyID        = \"my-go-test-media-cdn\"\n-\tcloudCDNKeyID        = \"my-go-test-cloud-cdn\"\n-\takamaiCDNKeyID       = \"my-go-test-akamai-cdn\"\n+\tmediaCDNKeyID        = \"go-test-media-cdn\"\n+\tcloudCDNKeyID        = \"go-test-cloud-cdn\"\n+\takamaiCDNKeyID       = \"go-test-akamai-cdn\"\n \thostname             = \"cdn.example.com\"\n-\tupdatedHostname      = \"updated.example.com\"\n+\tupdatedHostname      = \"updated.cdn.example.com\"\n \tkeyName              = \"my-key\"\n \n \tvodURI = \"https://storage.googleapis.com/cloud-samples-data/media/hls-vod/manifest.m3u8\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "54e9416c4d121d106f05cc86368a01ddd15cd3d7"
    },
    {
        "pr_title": "feat: convert CDN keys to LROs and add separate tests for each CDN ke\u2026",
        "pr_number": 3349,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -80,6 +80,7 @@\nfunc cleanStaleResources(projectID string) {\n \t}\n \tdefer client.Close()\n \n+\t// Slates\n \treq := &stitcherstreampb.ListSlatesRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n \t}",
        "comments": [],
        "commit_messages": [
            "feat: convert CDN keys to LROs and add separate tests for each CDN key sample"
        ],
        "last_commit_sha": "54e9416c4d121d106f05cc86368a01ddd15cd3d7"
    },
    {
        "pr_title": "feat: convert CDN keys to LROs and add separate tests for each CDN ke\u2026",
        "pr_number": 3349,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -115,6 +116,45 @@\nfunc cleanStaleResources(projectID string) {\n \t\t\t}\n \t\t}\n \t}\n+\n+\t// CDN keys\n+\treq2 := &stitcherstreampb.ListCdnKeysRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n+\t}\n+\n+\tit2 := client.ListCdnKeys(ctx, req2)\n+\n+\tfor {\n+\t\tresponse, err := it2.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tlog.Printf(\"Can't find next CDN key: %s\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\tif strings.Contains(response.GetName(), mediaCDNKeyID) ||\n+\t\t\tstrings.Contains(response.GetName(), cloudCDNKeyID) ||\n+\t\t\tstrings.Contains(response.GetName(), akamaiCDNKeyID) {\n+\n+\t\t\tarr := strings.Split(response.GetName(), \"-\")\n+\t\t\tt := arr[len(arr)-1]\n+\t\t\tif isResourceStale(t) == true {\n+\t\t\t\treq := &stitcherstreampb.DeleteCdnKeyRequest{\n+\t\t\t\t\tName: response.GetName(),\n+\t\t\t\t}\n+\t\t\t\t// Deletes the CDN key.\n+\t\t\t\top, err := client.DeleteCdnKey(ctx, req)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tlog.Printf(\"cleanStaleResources DeleteCdnKey: %s\", err)\n+\t\t\t\t}\n+\t\t\t\terr = op.Wait(ctx)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tlog.Printf(\"cleanStaleResources Wait: %s\", err)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n }\n \n func isResourceStale(timestamp string) bool {",
        "comments": [],
        "commit_messages": [
            "feat: convert CDN keys to LROs and add separate tests for each CDN key sample"
        ],
        "last_commit_sha": "54e9416c4d121d106f05cc86368a01ddd15cd3d7"
    },
    {
        "pr_title": "feat: convert CDN keys to LROs and add separate tests for each CDN ke\u2026",
        "pr_number": 3349,
        "file_name": "media/videostitcher/update_cdn_key.go",
        "code_diff": "@@ -21,35 +21,35 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n \t\"google.golang.org/protobuf/types/known/fieldmaskpb\"\n )\n \n // updateCDNKey updates a CDN key. A CDN key is used to retrieve protected media.\n // If isMediaCDN is true, update a Media CDN key. If false, update a Cloud\n // CDN key. To create an updated privateKey value for Media CDN, see\n // https://cloud.google.com/video-stitcher/docs/how-to/managing-cdn-keys#create-private-key-media-cdn.\n-func updateCDNKey(w io.Writer, projectID, keyID, hostname, keyName, privateKey string, isMediaCDN bool) error {\n+func updateCDNKey(w io.Writer, projectID, keyID, privateKey string, isMediaCDN bool) error {\n \t// projectID := \"my-project-id\"\n \t// keyID := \"my-cdn-key\"\n-\t// hostname := \"updated.cdn.example.com\"\n-\t// keyName := \"cdn-key\"\n \t// privateKey := \"my-updated-private-key\"\n \t// isMediaCDN := true\n \tlocation := \"us-central1\"\n+\thostname := \"updated.cdn.example.com\"\n+\tkeyName := \"cdn-key\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"stitcher.NewVideoStitcherClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n-\tvar req *stitcherpb.UpdateCdnKeyRequest\n+\tvar req *stitcherstreampb.UpdateCdnKeyRequest\n \tif isMediaCDN {\n-\t\treq = &stitcherpb.UpdateCdnKeyRequest{\n-\t\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_MediaCdnKey{\n-\t\t\t\t\tMediaCdnKey: &stitcherpb.MediaCdnKey{\n+\t\treq = &stitcherstreampb.UpdateCdnKeyRequest{\n+\t\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_MediaCdnKey{\n+\t\t\t\t\tMediaCdnKey: &stitcherstreampb.MediaCdnKey{\n \t\t\t\t\t\tKeyName:    keyName,\n \t\t\t\t\t\tPrivateKey: []byte(privateKey),\n \t\t\t\t\t},",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "54e9416c4d121d106f05cc86368a01ddd15cd3d7"
    },
    {
        "pr_title": "feat: convert CDN keys to LROs and add separate tests for each CDN ke\u2026",
        "pr_number": 3349,
        "file_name": "media/videostitcher/update_cdn_key.go",
        "code_diff": "@@ -64,10 +64,10 @@\nfunc updateCDNKey(w io.Writer, projectID, keyID, hostname, keyName, privateKey s\n \t\t\t},\n \t\t}\n \t} else {\n-\t\treq = &stitcherpb.UpdateCdnKeyRequest{\n-\t\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_GoogleCdnKey{\n-\t\t\t\t\tGoogleCdnKey: &stitcherpb.GoogleCdnKey{\n+\t\treq = &stitcherstreampb.UpdateCdnKeyRequest{\n+\t\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_GoogleCdnKey{\n+\t\t\t\t\tGoogleCdnKey: &stitcherstreampb.GoogleCdnKey{\n \t\t\t\t\t\tKeyName:    keyName,\n \t\t\t\t\t\tPrivateKey: []byte(privateKey),\n \t\t\t\t\t},",
        "comments": [],
        "commit_messages": [
            "feat: convert CDN keys to LROs and add separate tests for each CDN key sample"
        ],
        "last_commit_sha": "54e9416c4d121d106f05cc86368a01ddd15cd3d7"
    },
    {
        "pr_title": "feat: convert CDN keys to LROs and add separate tests for each CDN ke\u2026",
        "pr_number": 3349,
        "file_name": "media/videostitcher/update_cdn_key_akamai.go",
        "code_diff": "@@ -21,29 +21,29 @@\nimport (\n \t\"io\"\n \n \tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n-\t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n \t\"google.golang.org/protobuf/types/known/fieldmaskpb\"\n )\n \n // updateCDNKeyAkamai updates an Akamai CDN key. A CDN key is used to retrieve\n // protected media.\n-func updateCDNKeyAkamai(w io.Writer, projectID, keyID, hostname, akamaiTokenKey string) error {\n+func updateCDNKeyAkamai(w io.Writer, projectID, keyID, akamaiTokenKey string) error {\n \t// projectID := \"my-project-id\"\n \t// keyID := \"my-cdn-key\"\n-\t// hostname := \"updated.cdn.example.com\"\n \t// akamaiTokenKey := \"my-updated-token-key\"\n \tlocation := \"us-central1\"\n+\thostname := \"updated.cdn.example.com\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"stitcher.NewVideoStitcherClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n-\treq := &stitcherpb.UpdateCdnKeyRequest{\n-\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_AkamaiCdnKey{\n-\t\t\t\tAkamaiCdnKey: &stitcherpb.AkamaiCdnKey{\n+\treq := &stitcherstreampb.UpdateCdnKeyRequest{\n+\t\tCdnKey: &stitcherstreampb.CdnKey{\n+\t\t\tCdnKeyConfig: &stitcherstreampb.CdnKey_AkamaiCdnKey{\n+\t\t\t\tAkamaiCdnKey: &stitcherstreampb.AkamaiCdnKey{\n \t\t\t\t\tTokenKey: []byte(akamaiTokenKey),\n \t\t\t\t},\n \t\t\t},",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "54e9416c4d121d106f05cc86368a01ddd15cd3d7"
    },
    {
        "pr_title": "fix(dlp): Separated a tests files of samples for `deid` package (PR-1 for deid)",
        "pr_number": 3340,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -48,125 +48,6 @@\nconst (\n \tredactImageTemplate            = \"redact-image-template-go\"\n )\n \n-func TestDeidentifyDateShift(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\ttests := []struct {\n-\t\tinput      string\n-\t\twant       string\n-\t\tlowerBound int32\n-\t\tupperBound int32\n-\t}{\n-\t\t{\n-\t\t\tinput:      \"2016-01-10\",\n-\t\t\tlowerBound: 1,\n-\t\t\tupperBound: 1,\n-\t\t\twant:       \"2016-01-11\",\n-\t\t},\n-\t\t{\n-\t\t\tinput:      \"2016-01-10\",\n-\t\t\tlowerBound: -1,\n-\t\t\tupperBound: -1,\n-\t\t\twant:       \"2016-01-09\",\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\ttest := test\n-\t\tt.Run(test.input, func(t *testing.T) {\n-\t\t\ttest := test\n-\t\t\tt.Parallel()\n-\t\t\tbuf := new(bytes.Buffer)\n-\t\t\terr := deidentifyDateShift(buf, tc.ProjectID, test.lowerBound, test.upperBound, test.input)\n-\t\t\tif err != nil {\n-\t\t\t\tt.Errorf(\"deidentifyDateShift(%v, %v, %q) = error '%q', want %q\", test.lowerBound, test.upperBound, err, test.input, test.want)\n-\t\t\t}\n-\t\t\tif got := buf.String(); got != test.want {\n-\t\t\t\tt.Errorf(\"deidentifyDateShift(%v, %v, %q) = %q, want %q\", test.lowerBound, test.upperBound, got, test.input, test.want)\n-\t\t\t}\n-\t\t})\n-\t}\n-}\n-\n-func TestDeIdentifyWithReplacement(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tinput := \"My name is Alicia Abernathy, and my email address is aabernathy@example.com.\"\n-\tinfoType := []string{\"EMAIL_ADDRESS\"}\n-\treplaceVal := \"[email-address]\"\n-\twant := \"output : My name is Alicia Abernathy, and my email address is [email-address].\"\n-\n-\tvar buf bytes.Buffer\n-\terr := deidentifyWithReplacement(&buf, tc.ProjectID, input, infoType, replaceVal)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyWithReplacement(%q) = %q, want %q\", input, got, want)\n-\t}\n-}\n-\n-func TestDeIdentifyWithWordList(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tvar buf bytes.Buffer\n-\tinput := \"Patient was seen in RM-YELLOW then transferred to rm green.\"\n-\tinfoType := \"CUSTOM_ROOM_ID\"\n-\twordList := []string{\"RM-GREEN\", \"RM-YELLOW\", \"RM-ORANGE\"}\n-\twant := \"output : Patient was seen in [CUSTOM_ROOM_ID] then transferred to [CUSTOM_ROOM_ID].\"\n-\n-\tif err := deidentifyWithWordList(&buf, tc.ProjectID, input, infoType, wordList); err != nil {\n-\t\tt.Errorf(\"deidentifyWithWordList(%q) = error '%q', want %q\", input, err, want)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyWithWordList(%q) = %q, want %q\", input, got, want)\n-\t}\n-}\n-\n-func TestDeIdentifyWithInfotype(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tinput := \"My email is test@example.com\"\n-\tinfoType := []string{\"EMAIL_ADDRESS\"}\n-\twant := \"output : My email is [EMAIL_ADDRESS]\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deidentifyWithInfotype(&buf, tc.ProjectID, input, infoType); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tif got := buf.String(); got != want {\n-\t\tt.Errorf(\"deidentifyFreeTextWithFPEUsingSurrogate(%q) = %q, want %q\", input, got, want)\n-\t}\n-\n-}\n-\n-func TestDeIdentifyDeterministic(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\n-\tinput := \"Jack's phone number is 5555551212\"\n-\tinfoTypeNames := []string{\"PHONE_NUMBER\"}\n-\tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tkeyFileName, cryptoKeyName, keyVersion, err := createKey(t, tc.ProjectID, keyRingName)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tdefer destroyKey(t, tc.ProjectID, keyVersion)\n-\n-\tsurrogateInfoType := \"PHONE_TOKEN\"\n-\twant := \"output : Jack's phone number is PHONE_TOKEN(36):\"\n-\n-\tvar buf bytes.Buffer\n-\n-\tif err := deIdentifyDeterministicEncryption(&buf, tc.ProjectID, input, infoTypeNames, keyFileName, cryptoKeyName, surrogateInfoType); err != nil {\n-\t\tt.Errorf(\"deIdentifyDeterministicEncryption(%q) = error '%q', want %q\", err, input, want)\n-\t}\n-\n-\tif got := buf.String(); !strings.Contains(got, want) {\n-\t\tt.Errorf(\"deIdentifyDeterministicEncryption(%q) = %q, want %q\", input, got, want)\n-\t}\n-\n-}\n-\n func TestDeIdentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cb443fce77f82ec35a2abdb5928700999f5b2930"
    },
    {
        "pr_title": "feat(cloudrunci): Service.Do() method, to support automatic retries in more tests",
        "pr_number": 3307,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -123,7 +123,7 @@\nfunc Accept2xx(r *http.Response) bool {\n \n // AcceptNonServerError returns true for any non-500 http response\n func AcceptNonServerError(r *http.Response) bool {\n-\treturn r.StatusCode > 500\n+\treturn r.StatusCode < 500\n }\n \n func WithAttempts(n int) func(*RetryOptions) {",
        "comments": [],
        "commit_messages": [
            "feat: move retry logic to Do(), have Request() call that.\n\nalso fixes a bug in the AcceptNonServerError helper method."
        ],
        "last_commit_sha": "e08a3350cba9be2e81b6f21396cf8618cb2775e9"
    },
    {
        "pr_title": "feat(cloudrunci): Service.Do() method, to support automatic retries in more tests",
        "pr_number": 3307,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -142,8 +142,8 @@\nfunc WithAcceptFunc(f func(*http.Response) bool) func(*RetryOptions) {\n \t}\n }\n \n-// Request issues an HTTP request to the deployed service.\n-func (s *Service) Request(method string, path string, opts ...func(*RetryOptions)) (*http.Response, error) {\n+// Do executes the provided http.Request using the default http client\n+func (s *Service) Do(req *http.Request, opts ...func(*RetryOptions)) (*http.Response, error) {\n \tif !s.deployed {\n \t\treturn nil, errors.New(\"Request called before Deploy\")\n \t}",
        "comments": [],
        "commit_messages": [
            "feat: move retry logic to Do(), have Request() call that.\n\nalso fixes a bug in the AcceptNonServerError helper method."
        ],
        "last_commit_sha": "e08a3350cba9be2e81b6f21396cf8618cb2775e9"
    },
    {
        "pr_title": "feat(cloudrunci): Service.Do() method, to support automatic retries in more tests",
        "pr_number": 3307,
        "file_name": "run/testing/logging_manual.e2e_test.go",
        "code_diff": "@@ -15,10 +15,8 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [
            "feat: move run tests to use the service.Do method"
        ],
        "last_commit_sha": "e08a3350cba9be2e81b6f21396cf8618cb2775e9"
    },
    {
        "pr_title": "feat(cloudrunci): Service.Do() method, to support automatic retries in more tests",
        "pr_number": 3307,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -17,7 +17,7 @@\npackage cloudruntests\n import (\n \t\"bytes\"\n \t\"encoding/json\"\n-\t\"io\"\n+\t\"io/ioutil\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "fix(merge): fix inconsistent merge."
        ],
        "last_commit_sha": "e08a3350cba9be2e81b6f21396cf8618cb2775e9"
    },
    {
        "pr_title": "feat(cloudrunci): Service.Do() method, to support automatic retries in more tests",
        "pr_number": 3307,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -67,19 +67,17 @@\nfunc caseEditorServiceUI(t *testing.T) {\n \t\tt.Fatalf(\"service.NewRequest: %q\", err)\n \t}\n \n-\ttestutil.Retry(t, 10, 20*time.Second, func(r *testutil.R) {\n-\t\tresp, err := client.Do(req)\n-\t\tif err != nil {\n-\t\t\tr.Errorf(\"client.Do: %v\", err)\n-\t\t}\n-\t\tdefer resp.Body.Close()\n-\t\tr.Logf(\"client.Do: %s %s\\n\", req.Method, req.URL)\n-\n-\t\twantStatus := http.StatusOK\n-\t\tif got := resp.StatusCode; got != wantStatus {\n-\t\t\tr.Errorf(\"response status: got %d, want %d\", got, wantStatus)\n-\t\t}\n-\t})\n+\tresp, err := editorService.Do(req)\n+\tif err != nil {\n+\t\tt.Fatalf(\"client.Do: %v\", err)\n+\t}\n+\tdefer resp.Body.Close()\n+\tt.Logf(\"client.Do: %s %s\\n\", req.Method, req.URL)\n+\n+\twantStatus := http.StatusOK\n+\tif got := resp.StatusCode; got != wantStatus {\n+\t\tt.Errorf(\"response status: got %d, want %d\", got, wantStatus)\n+\t}\n }\n \n func caseEditorServiceRender(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "e08a3350cba9be2e81b6f21396cf8618cb2775e9"
    },
    {
        "pr_title": "feat(cloudrunci): Service.Do() method, to support automatic retries in more tests",
        "pr_number": 3307,
        "file_name": "run/testing/markdown_preview_renderer.e2e_test.go",
        "code_diff": "@@ -15,11 +15,10 @@\npackage cloudruntests\n \n import (\n-\t\"io\"\n+\t\"io/ioutil\"\n \t\"net/http\"\n \t\"strings\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "e08a3350cba9be2e81b6f21396cf8618cb2775e9"
    },
    {
        "pr_title": "feat: convert slates to LROs and add separate tests for each slate sa\u2026",
        "pr_number": 3305,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -15,25 +15,28 @@\npackage videostitcher\n \n import (\n-\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n-\t\"net/http\"\n-\t\"regexp\"\n+\t\"log\"\n+\n \t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n-\tcloudresourcemanager \"google.golang.org/api/cloudresourcemanager/v1\"\n+\t\"google.golang.org/api/iterator\"\n+\n+\tstitcher \"cloud.google.com/go/video/stitcher/apiv1\"\n+\tstitcherstreampb \"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n const (\n \tlocation            = \"us-central1\" // All samples use this location\n-\tslateID             = \"my-go-test-slate\"\n+\tslateID             = \"go-test-slate\"\n+\tslateURI            = \"https://storage.googleapis.com/cloud-samples-data/media/ForBiggerEscapes.mp4\"\n+\tupdatedSlateURI     = \"https://storage.googleapis.com/cloud-samples-data/media/ForBiggerJoyrides.mp4\"\n \tdeleteSlateResponse = \"Deleted slate\"\n \n \tdeleteCDNKeyResponse = \"Deleted CDN key\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b25354f9a6ab846e0acb056535206bbeb4a34be1"
    },
    {
        "pr_title": "fix(dlp): remove the function call of setupPubSub and added a inline code in samples",
        "pr_number": 3288,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -40,8 +40,7 @@\nimport (\n )\n \n const (\n-\tfilePathToGCSUploadForDeidTest = \"./testdata/dlp_sample.csv\"\n-\tfilePathToGCSForDeidTest       = \"/testdata/dlp_sample.csv\"\n+\tfilePathToGCSForDeidTest       = \"./testdata/dlp_sample.csv\"\n \ttableID                        = \"dlp_test_deid_table\"\n \tdataSetID                      = \"dlp_test_deid_dataset\"\n \tdeidentifyTemplateID           = \"deidentified-templat-test-go\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "945e501557b594e898a21c8b19614554535b984e"
    },
    {
        "pr_title": "fix(dlp): remove the function call of setupPubSub and added a inline code in samples",
        "pr_number": 3288,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -735,9 +734,6 @@\nvar (\n func TestMain(m *testing.M) {\n \ttc := testutil.Context{}\n \ttc.ProjectID = os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")\n-\tif tc.ProjectID == \"\" {\n-\t\ttc.ProjectID = os.Getenv(\"\")\n-\t}\n \tcreateRedactImageTemplate(tc.ProjectID, redactImageTemplate)\n \tcreateDeidentifiedTemplate(tc.ProjectID, deidentifyTemplateID)\n \tcreateStructuredDeidentifiedTemplate(tc.ProjectID, deidentifyStructuredTemplateID)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "945e501557b594e898a21c8b19614554535b984e"
    },
    {
        "pr_title": "feat(cloudrunci): Add retry by default to Service.Request",
        "pr_number": 3283,
        "file_name": "run/testing/hello_broken.e2e_test.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "update hello_broken tests to use Request helper."
        ],
        "last_commit_sha": "72ca024961997989542980f40e1c8b60977187ff"
    },
    {
        "pr_title": "feat(cloudrunci): Add retry by default to Service.Request",
        "pr_number": 3283,
        "file_name": "run/testing/helloworld.e2e_test.go",
        "code_diff": "@@ -15,11 +15,9 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"io/ioutil\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [
            {
                "comment": "nit: replace use of `ioutil` with `io`.",
                "position": 21
            },
            {
                "comment": "is this safe to do while we still (nominally) support versions < 1.18, or should we wait?",
                "position": 21
            },
            {
                "comment": "We discussed this OOB, and decided to wait on updating the package here until 1.18 is our minimum supported version.",
                "position": 21
            }
        ],
        "commit_messages": [
            "rename ShouldRetry to avoid negation."
        ],
        "last_commit_sha": "72ca024961997989542980f40e1c8b60977187ff"
    },
    {
        "pr_title": "feat(cloudrunci): Add retry by default to Service.Request",
        "pr_number": 3283,
        "file_name": "run/testing/image_processing.e2e_test.go",
        "code_diff": "@@ -15,10 +15,8 @@\npackage cloudruntests\n \n import (\n-\t\"fmt\"\n \t\"net/http\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [
            "rename ShouldRetry to avoid negation."
        ],
        "last_commit_sha": "72ca024961997989542980f40e1c8b60977187ff"
    },
    {
        "pr_title": "feat(aiplatform): Adds import dataset sample",
        "pr_number": 3280,
        "file_name": "aiplatform/snippets/create_dataset_test.go",
        "code_diff": "@@ -30,27 +30,6 @@\nimport (\n \t\"google.golang.org/api/option\"\n )\n \n-var (\n-\toutput    string\n-\tprojectID string\n-\tregion    string = \"us-central1\"\n-)\n-\n-func TestMain(m *testing.M) {\n-\ttc, ok := testutil.ContextMain(m)\n-\n-\tprojectID = tc.ProjectID\n-\n-\tif !ok {\n-\t\tlog.Fatal(\"couldn't initialize test\")\n-\t\treturn\n-\t}\n-\n-\tm.Run()\n-\n-\tdeleteDataset()\n-}\n-\n func TestCreateDataset(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_messages": [
            "clean up for import image classification sample"
        ],
        "last_commit_sha": "8d4705444485fb9ec45d020710ca6d2089c74dd3"
    },
    {
        "pr_title": "fix(dlp): fixes DLP Risk snippet tests #2897",
        "pr_number": 3272,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -52,7 +52,7 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n-\ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)\n+\ts, err := setupPubSub(ctx, pubsubClient, projectID, pubSubTopic, pubSubSub)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"setupPubSub: %w\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "40d83b29ec5859d96999fa3f642416492e81a224"
    },
    {
        "pr_title": "fix(dlp): fixes DLP Risk snippet tests #2897",
        "pr_number": 3272,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -112,14 +112,14 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \t\treturn fmt.Errorf(\"CreateDlpJob: %w\", err)\n \t}\n \tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())\n-\n \t// Wait for the risk job to finish by waiting for a PubSub message.\n \t// This only waits for 10 minutes. For long jobs, consider using a truly\n \t// asynchronous execution model such as Cloud Functions.\n \tctx, cancel := context.WithTimeout(ctx, 10*time.Minute)\n \tdefer cancel()\n \terr = s.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n \t\t// If this is the wrong job, do not process the result.\n+\n \t\tif msg.Attributes[\"DlpJobName\"] != j.GetName() {\n \t\t\tmsg.Nack()\n \t\t\treturn",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "40d83b29ec5859d96999fa3f642416492e81a224"
    },
    {
        "pr_title": "fix(dlp): fixes DLP Risk snippet tests #2897",
        "pr_number": 3272,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -42,6 +42,7 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \tif err != nil {\n \t\treturn fmt.Errorf(\"dlp.NewClient: %w\", err)\n \t}\n+\tdefer client.Close()\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "40d83b29ec5859d96999fa3f642416492e81a224"
    },
    {
        "pr_title": "fix(dlp): fixes DLP Risk snippet tests #2897",
        "pr_number": 3272,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -51,7 +52,7 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n-\ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)\n+\ts, err := setupPubSub(ctx, pubsubClient, projectID, pubSubTopic, pubSubSub)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"setupPubSub: %w\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "40d83b29ec5859d96999fa3f642416492e81a224"
    },
    {
        "pr_title": "feat(aiplatform): adds delete dataset sample",
        "pr_number": 3269,
        "file_name": "aiplatform/snippets/import_data_image_classification_test.go",
        "code_diff": "@@ -37,7 +37,7 @@\nvar (\n \tgcsURI      string\n )\n \n-func setup(t *testing.T) func() {\n+func setupImportDatasetImageClassification(t *testing.T) func() {\n \tt.Helper()\n \tif testing.Short() {\n \t\tt.Skip(\"skipping integration test\")",
        "comments": [],
        "commit_messages": [
            "disambiguating setups and teardowns"
        ],
        "last_commit_sha": "4623f2295f14e44341fb4fb0f287291cc47bd54d"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -27,6 +27,7 @@\nimport (\n \t\"context\"\n \t\"errors\"\n \t\"fmt\"\n+\t\"log\"\n \t\"net/http\"\n \t\"net/url\"\n \t\"os/exec\"",
        "comments": [],
        "commit_messages": [
            "switch cloudrunci to use 'log' instead of 'fmt.Print*'"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -300,7 +301,7 @@\nfunc (s *Service) Build() error {\n \t}\n \n \tif out, err := gcloud(s.operationLabel(labelOperationBuild), s.buildCmd()); err != nil {\n-\t\tfmt.Printf(string(out))\n+\t\tlog.Printf(string(out))\n \t\treturn fmt.Errorf(\"gcloud: %s: %q\", s.Image, err)\n \t}\n \ts.built = true",
        "comments": [],
        "commit_messages": [
            "switch cloudrunci to use 'log' instead of 'fmt.Print*'"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -461,13 +462,13 @@\nfunc (s *Service) LogEntries(filter string, find string, maxAttempts int) (bool,\n \tdefer client.Close()\n \n \tpreparedFilter := fmt.Sprintf(`resource.type=\"cloud_run_revision\" resource.labels.service_name=\"%s\" %s`, s.version(), filter)\n-\tfmt.Printf(\"Using log filter: %s\\n\", preparedFilter)\n+\tlog.Printf(\"Using log filter: %s\\n\", preparedFilter)\n \n-\tfmt.Println(\"Waiting for logs...\")\n+\tlog.Println(\"Waiting for logs...\")\n \ttime.Sleep(3 * time.Minute)\n \n \tfor i := 1; i < maxAttempts; i++ {\n-\t\tfmt.Printf(\"Attempt #%d\\n\", i)\n+\t\tlog.Printf(\"Attempt #%d\\n\", i)\n \t\tit := client.Entries(ctx, logadmin.Filter(preparedFilter))\n \t\tfor {\n \t\t\tentry, err := it.Next()",
        "comments": [],
        "commit_messages": [
            "switch cloudrunci to use 'log' instead of 'fmt.Print*'"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "internal/cloudrunci/cloudrunjobs.go",
        "code_diff": "@@ -27,6 +27,7 @@\nimport (\n \t\"context\"\n \t\"errors\"\n \t\"fmt\"\n+\t\"log\"\n \t\"os/exec\"\n \t\"strings\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "switch cloudrunci to use 'log' instead of 'fmt.Print*'"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "internal/cloudrunci/cloudrunjobs.go",
        "code_diff": "@@ -304,10 +305,10 @@\nfunc (j *Job) LogEntries(filter string, find string, maxAttempts int) (bool, err\n \tdefer client.Close()\n \n \tpreparedFilter := fmt.Sprintf(`resource.type=\"cloud_run_job\" resource.labels.job_name=\"%s\" %s`, j.version(), filter)\n-\tfmt.Printf(\"Using log filter: %s\\n\", preparedFilter)\n+\tlog.Printf(\"Using log filter: %s\\n\", preparedFilter)\n \n \tfor i := 1; i < maxAttempts; i++ {\n-\t\tfmt.Printf(\"Attempt #%d\\n\", i)\n+\t\tlog.Printf(\"Attempt #%d\\n\", i)\n \t\tit := client.Entries(ctx, logadmin.Filter(preparedFilter))\n \t\tfor {\n \t\t\tentry, err := it.Next()",
        "comments": [],
        "commit_messages": [
            "switch cloudrunci to use 'log' instead of 'fmt.Print*'"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/grpc_ping.e2e_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\nimport (\n \t\"context\"\n \t\"crypto/tls\"\n \t\"fmt\"\n+\t\"log\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "feat(run/testing): include filename in log prefix\n\nthis helps disambiguiate the interleaved logs when testing the whole\npackage"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/grpc_server_streaming.e2e_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"crypto/tls\"\n \t\"crypto/x509\"\n \t\"io\"\n+\t\"log\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "feat(run/testing): include filename in log prefix\n\nthis helps disambiguiate the interleaved logs when testing the whole\npackage"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/h2c.e2e_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage cloudruntests\n \n import (\n \t\"io/ioutil\"\n+\t\"log\"\n \t\"net/http\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "feat(run/testing): include filename in log prefix\n\nthis helps disambiguiate the interleaved logs when testing the whole\npackage"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/hello_broken.e2e_test.go",
        "code_diff": "@@ -15,6 +15,8 @@\npackage cloudruntests\n \n import (\n+\t\"fmt\"\n+\t\"log\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/logging_manual.e2e_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage cloudruntests\n \n import (\n \t\"fmt\"\n+\t\"log\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "feat(run/testing): include filename in log prefix\n\nthis helps disambiguiate the interleaved logs when testing the whole\npackage"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\nimport (\n \t\"bytes\"\n \t\"encoding/json\"\n \t\"io/ioutil\"\n+\t\"log\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "feat(run/testing): include filename in log prefix\n\nthis helps disambiguiate the interleaved logs when testing the whole\npackage"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/markdown_preview_renderer.e2e_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage cloudruntests\n \n import (\n \t\"io/ioutil\"\n+\t\"log\"\n \t\"net/http\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "feat(run/testing): include filename in log prefix\n\nthis helps disambiguiate the interleaved logs when testing the whole\npackage"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/markdown_preview_renderer.e2e_test.go",
        "code_diff": "@@ -25,6 +26,11 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n+func init() {\n+\t// tests should include the filename in any logs, because the log files are per-package.\n+\tlog.SetFlags(log.LstdFlags | log.Lshortfile)\n+}\n+\n func TestRendererService(t *testing.T) {\n \ttc := testutil.EndToEndTest(t)\n \tservice := cloudrunci.NewService(\"render\", tc.ProjectID)",
        "comments": [],
        "commit_messages": [
            "feat(run/testing): include filename in log prefix\n\nthis helps disambiguiate the interleaved logs when testing the whole\npackage"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/pubsub.e2e_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage cloudruntests\n \n import (\n \t\"fmt\"\n+\t\"log\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "feat(run/testing): include filename in log prefix\n\nthis helps disambiguiate the interleaved logs when testing the whole\npackage"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/sigterm_handler.e2e_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage cloudruntests\n \n import (\n \t\"fmt\"\n+\t\"log\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "feat(run/testing): include filename in log prefix\n\nthis helps disambiguiate the interleaved logs when testing the whole\npackage"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(run): add filename to run/testing log output",
        "pr_number": 3251,
        "file_name": "run/testing/system_package.e2e_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage cloudruntests\n \n import (\n \t\"fmt\"\n+\t\"log\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "feat(run/testing): include filename in log prefix\n\nthis helps disambiguiate the interleaved logs when testing the whole\npackage"
        ],
        "last_commit_sha": "ccea8fe5de34ae67a01984dc2d1b30d3c4ab2374"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect send data to hybrid job trigger",
        "pr_number": 3247,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -42,7 +42,8 @@\nimport (\n const (\n \tbucketForDeidCloudStorageForInput  = \"dlp-test-deid-input\"\n \tbucketForDeidCloudStorageForOutput = \"dlp-test-deid-go-lang-output\"\n-\tfilePathToGCSForDeidTest           = \"./testdata/dlp_sample.csv\"\n+\tfilePathToGCSUploadForDeidTest     = \"./testdata/dlp_sample.csv\"\n+\tfilePathToGCSForDeidTest           = \"/testdata/dlp_sample.csv\"\n \ttableID                            = \"dlp_test_deid_table\"\n \tdataSetID                          = \"dlp_test_deid_dataset\"",
        "comments": [],
        "commit_messages": [
            "updated the deid_test as Ci is failing"
        ],
        "last_commit_sha": "0633ecb31278e1ebbc49f27b3b5ccf53725e9979"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect send data to hybrid job trigger",
        "pr_number": 3247,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -26,9 +26,12 @@\nimport (\n \n \t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/datastore\"\n+\tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n const (",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0633ecb31278e1ebbc49f27b3b5ccf53725e9979"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect send data to hybrid job trigger",
        "pr_number": 3247,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -38,6 +41,9 @@\nconst (\n \tssnFileName = \"fake_ssn.txt\"\n \tbucketName  = \"golang-samples-dlp-test2\"\n \n+\tjobTriggerIdPrefix                      = \"dlp-job-trigger-unit-test-case-12345678\"\n+\tdataSetIDForHybridJob                   = \"dlp_test_dataset\"\n+\ttableIDForHybridJob                     = \"dlp_inspect_test_table_table_id\"\n \tinspectsGCSTestFileName                 = \"test.txt\"\n \tfilePathToUpload                        = \"./testdata/test.txt\"\n \tdirPathForInspectGCSSendToScc           = \"dlp-go-lang-test-for-inspect-gcs-send-to-scc/\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0633ecb31278e1ebbc49f27b3b5ccf53725e9979"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect send data to hybrid job trigger",
        "pr_number": 3247,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -649,7 +655,7 @@\nfunc TestInspectDataStoreSendToScc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n \tu := uuid.New().String()[:8]\n-\tdatastoreNamespace := \"golang-samples\" + u\n+\tdatastoreNamespace := fmt.Sprint(\"golang-samples\" + u)\n \tdatastoreKind := \"task\"\n \n \tif err := inspectDataStoreSendToScc(&buf, tc.ProjectID, datastoreNamespace, datastoreKind); err != nil {",
        "comments": [],
        "commit_messages": [
            "minor change"
        ],
        "last_commit_sha": "0633ecb31278e1ebbc49f27b3b5ccf53725e9979"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect send data to hybrid job trigger",
        "pr_number": 3247,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage risk\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"log\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "fixing the branch",
            "updated the inspect test file"
        ],
        "last_commit_sha": "0633ecb31278e1ebbc49f27b3b5ccf53725e9979"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp k anonymity with entity id ",
        "pr_number": 3245,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -40,13 +40,10 @@\nimport (\n )\n \n const (\n-\tbucketForDeidCloudStorageForInput  = \"dlp-test-deid-input\"\n-\tbucketForDeidCloudStorageForOutput = \"dlp-test-deid-go-lang-output\"\n-\tfilePathToGCSUploadForDeidTest     = \"./testdata/dlp_sample.csv\"\n-\tfilePathToGCSForDeidTest           = \"/testdata/dlp_sample.csv\"\n-\ttableID                            = \"dlp_test_deid_table\"\n-\tdataSetID                          = \"dlp_test_deid_dataset\"\n-\n+\tfilePathToGCSUploadForDeidTest = \"./testdata/dlp_sample.csv\"\n+\tfilePathToGCSForDeidTest       = \"/testdata/dlp_sample.csv\"\n+\ttableID                        = \"dlp_test_deid_table\"\n+\tdataSetID                      = \"dlp_test_deid_dataset\"\n \tdeidentifyTemplateID           = \"deidentified-templat-test-go\"\n \tdeidentifyStructuredTemplateID = \"deidentified-structured-template-go\"\n \tredactImageTemplate            = \"redact-image-template-go\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8556f616fd1a213dce702e3a050b652767c0e1bf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp k anonymity with entity id ",
        "pr_number": 3245,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -711,7 +708,7 @@\nfunc TestDeidentifyDataReplaceWithDictionary(t *testing.T) {\n func TestDeidentifyCloudStorage(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n-\t// \"gs://dlp-crest-test/dlp_sample.csv\"\n+\n \tgcsURI := fmt.Sprint(\"gs://\" + bucketForDeidCloudStorageForInput + \"/\" + filePathToGCSForDeidTest)\n \toutputBucket := fmt.Sprint(\"gs://\" + bucketForDeidCloudStorageForOutput)",
        "comments": [],
        "commit_messages": [
            "updated the bucket creation as it's failing in CI"
        ],
        "last_commit_sha": "8556f616fd1a213dce702e3a050b652767c0e1bf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp k anonymity with entity id ",
        "pr_number": 3245,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -18,14 +18,16 @@\npackage risk\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n \t\"log\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"github.com/gofrs/uuid\"\n+\t\"github.com/google/uuid\"\n )\n \n const (",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8556f616fd1a213dce702e3a050b652767c0e1bf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp k anonymity with entity id ",
        "pr_number": 3245,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -47,7 +49,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Numerical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskNumerical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_messages": [
            "sync the branch"
        ],
        "last_commit_sha": "8556f616fd1a213dce702e3a050b652767c0e1bf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp k anonymity with entity id ",
        "pr_number": 3245,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -64,7 +66,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"Categorical\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskCategorical(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_messages": [
            "sync the branch"
        ],
        "last_commit_sha": "8556f616fd1a213dce702e3a050b652767c0e1bf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp k anonymity with entity id ",
        "pr_number": 3245,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -80,7 +82,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Anonymity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskKAnonymity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\", \"county\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_messages": [
            "sync the branch"
        ],
        "last_commit_sha": "8556f616fd1a213dce702e3a050b652767c0e1bf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp k anonymity with entity id ",
        "pr_number": 3245,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -96,7 +98,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"L Diversity\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\terr := riskLDiversity(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"nhtsa_traffic_fatalities\", \"accident_2015\", \"city\", \"state_number\", \"county\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif err != nil {",
        "comments": [],
        "commit_messages": [
            "sync the branch"
        ],
        "last_commit_sha": "8556f616fd1a213dce702e3a050b652767c0e1bf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp k anonymity with entity id ",
        "pr_number": 3245,
        "file_name": "dlp/snippets/risk/risk_test.go",
        "code_diff": "@@ -112,7 +114,7 @@\nfunc TestRisk(t *testing.T) {\n \t\t\tname: \"K Map\",\n \t\t\tfn: func(r *testutil.R) {\n \t\t\t\tbuf := new(bytes.Buffer)\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\triskKMap(buf, tc.ProjectID, \"bigquery-public-data\", riskTopicName+u, riskSubscriptionName+u, \"san_francisco\", \"bikeshare_trips\", \"US\", \"zip_code\")\n \t\t\t\tdefer cleanupPubsub(t, client, riskTopicName+u, riskSubscriptionName+u)\n \t\t\t\tif got, want := buf.String(), \"Created job\"; !strings.Contains(got, want) {",
        "comments": [],
        "commit_messages": [
            "addressed a review comments"
        ],
        "last_commit_sha": "8556f616fd1a213dce702e3a050b652767c0e1bf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect with stored infotype",
        "pr_number": 3242,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -623,7 +623,7 @@\nfunc TestInspectAugmentInfoTypes(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \tgot := buf.String()\n-\tif want := \"Qoute: Quasimodo\"; !strings.Contains(got, want) {\n+\tif want := \"Quote: Quasimodo\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"TestInspectAugmentInfoTypes got %q, want %q\", got, want)\n \t}\n \tif want := \"Info type: PERSON_NAME\"; !strings.Contains(got, want) {",
        "comments": [],
        "commit_messages": [
            "addressed review comments"
        ],
        "last_commit_sha": "bbeab494c2adc27a32b04e7ece0e7609908dec83"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect with stored infotype",
        "pr_number": 3242,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -668,6 +668,68 @@\nfunc TestInspectDataStoreSendToScc(t *testing.T) {\n \t}\n }\n \n+var (\n+\tprojectID                  string\n+\tjobTriggerForInspectSample string\n+\tbucketExpiryAge            = time.Minute * 2\n+\ttestPrefix                 = \"dlp-test-inspect-prefix\"\n+)\n+\n+func createStoredInfoTypeForTesting(t *testing.T, projectID, outputPath string) (string, error) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\tdefer client.Close()\n+\tu := uuid.New().String()[:8]\n+\tdisplayName := \"stored-info-type-for-inspect-test\" + u\n+\tdescription := \"Dictionary of GitHub usernames used in commits\"\n+\n+\tcloudStoragePath := &dlppb.CloudStoragePath{\n+\t\tPath: outputPath,\n+\t}\n+\n+\tbigQueryField := &dlppb.BigQueryField{\n+\t\tTable: &dlppb.BigQueryTable{\n+\t\t\tProjectId: \"bigquery-public-data\",\n+\t\t\tDatasetId: \"samples\",\n+\t\t\tTableId:   \"github_nested\",\n+\t\t},\n+\t\tField: &dlppb.FieldId{\n+\t\t\tName: \"actor\",\n+\t\t},\n+\t}\n+\n+\tlargeCustomDictionaryConfig := &dlppb.LargeCustomDictionaryConfig{\n+\t\tOutputPath: cloudStoragePath,\n+\t\tSource: &dlppb.LargeCustomDictionaryConfig_BigQueryField{\n+\t\t\tBigQueryField: bigQueryField,\n+\t\t},\n+\t}\n+\n+\tstoredInfoTypeConfig := &dlppb.StoredInfoTypeConfig{\n+\t\tDisplayName: displayName,\n+\t\tDescription: description,\n+\t\tType: &dlppb.StoredInfoTypeConfig_LargeCustomDictionary{\n+\t\t\tLargeCustomDictionary: largeCustomDictionaryConfig,\n+\t\t},\n+\t}\n+\n+\treq := &dlppb.CreateStoredInfoTypeRequest{\n+\t\tParent:           fmt.Sprintf(\"projects/%s/locations/global\", projectID),\n+\t\tConfig:           storedInfoTypeConfig,\n+\t\tStoredInfoTypeId: \"go-sample-test-stored-infoType\" + u,\n+\t}\n+\tresp, err := client.CreateStoredInfoType(ctx, req)\n+\tif err != nil {\n+\t\treturn \"nil\", err\n+\t}\n+\n+\treturn resp.Name, nil\n+}\n+\n func TestInspectGCSFileSendToScc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bbeab494c2adc27a32b04e7ece0e7609908dec83"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect with stored infotype",
        "pr_number": 3242,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -798,7 +860,24 @@\nfunc filePathtoGCS(t *testing.T, projectID, bucketNameForInspectGCSSendToScc, di\n \treturn nil\n }\n \n-var projectID, jobTriggerForInspectSample string\n+func deleteStoredInfoTypeAfterTest(t *testing.T, name string) error {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\treq := &dlppb.DeleteStoredInfoTypeRequest{\n+\t\tName: name,\n+\t}\n+\terr = client.DeleteStoredInfoType(ctx, req)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\treturn nil\n+}\n \n func TestMain(m *testing.M) {\n \ttc, ok := testutil.ContextMain(m)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bbeab494c2adc27a32b04e7ece0e7609908dec83"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect bigquery send to scc",
        "pr_number": 3241,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -651,6 +651,157 @@\nfunc TestInspectTableWithCustomHotword(t *testing.T) {\n \t}\n }\n \n+func createBigQueryDataSetId(projectID string) error {\n+\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tmeta := &bigquery.DatasetMetadata{\n+\t\tLocation: \"US\", // See https://cloud.google.com/bigquery/docs/locations\n+\t}\n+\n+\tif err := client.Dataset(dataSetID).Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n+func createTableInsideDataset(projectID, dataSetID string) error {\n+\tctx := context.Background()\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"user_id\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType},\n+\t\t{Name: \"title\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"score\", Type: bigquery.StringFieldType},\n+\t}\n+\n+\tmetaData := &bigquery.TableMetadata{\n+\t\tSchema:         sampleSchema,\n+\t\tExpirationTime: time.Now().AddDate(1, 0, 0), // Table will be automatically deleted in 1 year.\n+\t}\n+\n+\ttableRef := client.Dataset(dataSetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, metaData); err != nil {\n+\t\tlog.Printf(\"[INFO] createBigQueryDataSetId Error while table creation: %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tduration := time.Duration(90) * time.Second\n+\ttime.Sleep(duration)\n+\n+\tinserter := client.Dataset(dataSetID).Table(tableID).Inserter()\n+\titems := []*BigQueryTableItem{\n+\t\t// Item implements the ValueSaver interface.\n+\t\t{UserId: \"602-61-8588\", Age: 32, Title: \"Biostatistician III\", Score: \"A\"},\n+\t\t{UserId: \"618-96-2322\", Age: 69, Title: \"Programmer I\", Score: \"C\"},\n+\t\t{UserId: \"618-96-2322\", Age: 69, Title: \"Executive Secretary\", Score: \"C\"},\n+\t}\n+\tif err := inserter.Put(ctx, items); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n+type BigQueryTableItem struct {\n+\tUserId string\n+\tAge    int\n+\tTitle  string\n+\tScore  string\n+}\n+\n+func (i *BigQueryTableItem) Save() (map[string]bigquery.Value, string, error) {\n+\treturn map[string]bigquery.Value{\n+\t\t\"user_id\": i.UserId,\n+\t\t\"age\":     i.Age,\n+\t\t\"title\":   i.Title,\n+\t\t\"score\":   i.Score,\n+\t}, bigquery.NoDedupeID, nil\n+}\n+\n+func deleteBigQueryAssets(projectID string) error {\n+\n+\tlog.Printf(\"[START] deleteBigQueryAssets: projectID %v and \", projectID)\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tlog.Printf(\"[INFO] deleteBigQueryAssets: delete dataset err %v\", err)\n+\n+\tif err := client.Dataset(\"dlp_test_dataset\").DeleteWithContents(ctx); err != nil {\n+\t\tlog.Printf(\"[INFO] deleteBigQueryAssets: delete dataset err %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tduration := time.Duration(30) * time.Second\n+\ttime.Sleep(duration)\n+\n+\tlog.Printf(\"[END] deleteBigQueryAssets:\")\n+\treturn nil\n+}\n+\n+func deleteJob(projectID, jobName string) error {\n+\tctx := context.Background()\n+\n+\tlog.Printf(\"[START] deleteJob: projectID %v\", projectID)\n+\t// delete job\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\treturn err\n+\t}\n+\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\n+\treq := &dlppb.DeleteDlpJobRequest{\n+\t\tName: jobName,\n+\t}\n+\tfor {\n+\t\tct, cancel := context.WithTimeout(ctx, 300000)\n+\t\tdefer cancel()\n+\t\tabc, err := client.GetDlpJob(ct, &dlppb.GetDlpJobRequest{\n+\t\t\tName: jobName,\n+\t\t})\n+\t\tif err != nil {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\t\treturn err\n+\t\t}\n+\t\tif abc.State == dlppb.DlpJob_DONE {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job done\")\n+\t\t\tbreak\n+\t\t} else if abc.State == dlppb.DlpJob_FAILED {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job failed\")\n+\t\t\treturn err\n+\t\t} else {\n+\t\t\tlog.Printf(\"[INFO] deleteJob:: job continue\")\n+\t\t\tcontinue\n+\t\t}\n+\t}\n+\terr = client.DeleteDlpJob(ctx, req)\n+\tif err != nil {\n+\t\tlog.Printf(\"[INFO] deleteJob:: error %v\", err)\n+\t\treturn err\n+\t}\n+\n+\tlog.Printf(\"[END] deleteJob\")\n+\treturn nil\n+}\n+\n func TestInspectDataStoreSendToScc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "911fe3db1f69f0c6a56f7601ae9585de6eb26b31"
    },
    {
        "pr_title": "docs(samples): Add assets and pools samples and tests",
        "pr_number": 3240,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -16,56 +16,111 @@\npackage livestream\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"fmt\"\n+\t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\tlivestream \"cloud.google.com/go/video/livestream/apiv1\"\n+\t\"cloud.google.com/go/video/livestream/apiv1/livestreampb\"\n+\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n const (\n \tdeleteChannelEventResponse = \"Deleted channel event\"\n \tdeleteChannelResponse      = \"Deleted channel\"\n \tdeleteInputResponse        = \"Deleted input\"\n+\tdeleteAssetResponse        = \"Deleted asset\"\n \tstartChannelResponse       = \"Started channel\"\n \tstopChannelResponse        = \"Stopped channel\"\n \tlocation                   = \"us-central1\"\n \tinputID                    = \"my-go-test-input\"\n \tbackupInputID              = \"my-go-test-backup-input\"\n \tchannelID                  = \"my-go-test-channel\"\n \teventID                    = \"my-go-test-channel-event\"\n+\tassetID                    = \"my-go-test-asset\"\n+\tpoolID                     = \"default\" // only 1 pool supported per location\n )\n \n+var bucketName string\n+var outputURI string\n+var assetURI string\n+\n // To run the tests, do the following:\n // Export the following env vars:\n // *   GOOGLE_APPLICATION_CREDENTIALS\n // *   GOLANG_SAMPLES_PROJECT_ID\n // Enable the following API on the test project:\n // *   Live Stream API\n \n-// TestLiveStream tests major operations on inputs, channels, and channel\n-// events.\n-func TestLiveStream(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+// TestMain tests major operations on inputs, channels, channel\n+// events, assets, and pools.\n+func TestMain(m *testing.M) {\n+\ttc, _ := testutil.ContextMain(m)\n+\tbucketName = tc.ProjectID + \"-golang-samples-livestream-test\"\n+\toutputURI = \"gs://\" + bucketName + \"/test-output-channel/\"\n+\tassetURI = \"gs://cloud-samples-data/media/ForBiggerEscapes.mp4\"\n+\tm.Run()\n+\tcleanStaleAssets(tc)\n+}\n \n-\tbucketName := tc.ProjectID + \"-golang-samples-livestream-test\"\n-\toutputURI := \"gs://\" + bucketName + \"/test-output-channel/\"\n+func cleanStaleAssets(tc testutil.Context) {\n+\tctx := context.Background()\n+\tvar threeHoursInSec int64 = 60 * 60 * 3\n+\ttimeNowSec := time.Now().Unix()\n \n-\ttestInputs(t)\n-\tt.Logf(\"\\ntestInputs() completed\\n\")\n+\tclient, err := livestream.NewClient(ctx)\n+\tif err != nil {\n+\t\tfmt.Printf(\"NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n \n-\ttestChannels(t, outputURI)\n-\tt.Logf(\"\\ntestChannels() completed\\n\")\n+\treq := &livestreampb.ListAssetsRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", tc.ProjectID, location),\n+\t}\n \n-\ttestChannelEvents(t, outputURI)\n-\tt.Logf(\"\\ntestChannelEvents() completed\\n\")\n+\tit := client.ListAssets(ctx, req)\n+\tfor {\n+\t\tresponse, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tfmt.Printf(\"ListAssets: %v\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\treq := &livestreampb.GetAssetRequest{\n+\t\t\tName: response.Name,\n+\t\t}\n+\t\tasset, err := client.GetAsset(ctx, req)\n+\t\tif err != nil {\n+\t\t\tfmt.Printf(\"GetAsset: %v\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\tif asset.GetCreateTime().GetSeconds() < timeNowSec-threeHoursInSec {\n+\t\t\tfmt.Printf(\"%v - delete asset\", asset.GetCreateTime().GetSeconds())\n+\t\t\treq := &livestreampb.DeleteAssetRequest{\n+\t\t\t\tName: asset.GetName(),\n+\t\t\t}\n+\t\t\t// No need to wait for delete ops to finish, as this is a background\n+\t\t\t// cleanup.\n+\t\t\t_, err := client.DeleteAsset(ctx, req)\n+\t\t\tif err != nil {\n+\t\t\t\tfmt.Printf(\"DeleteAsset: %v\", err)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t}\n+\t}\n }\n \n-// testInputs tests major operations on inputs. Create, list, update,\n+// TestInputs tests major operations on inputs. Create, list, update,\n // and get operations check if the input resource name is returned. The\n // delete operation checks for a hard-coded string response.\n-func testInputs(t *testing.T) {\n+func TestInputs(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := &bytes.Buffer{}",
        "comments": [
            {
                "comment": "please consider using unique identifiers, to avoid resource contention between multiple concurrent test runs. This could be:\r\n\r\n```\r\nvar assetID = fmt.Sprintf(\"my-go-test-asset-%s\", uuid.New().String())\r\n```\r\n\r\nthere's no need to change the existing patterns, but it will produce better outcomes, and it means there's no need to delete the existing objects *before* testing.\r\n\r\n(except for pool, which you have documented only allows one per location. Thanks for that!)",
                "position": 30
            },
            {
                "comment": "Done",
                "position": 30
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "5f09f43ac7be35eb13845ed9ad858e690f09980f"
    },
    {
        "pr_title": "docs(samples): Add assets and pools samples and tests",
        "pr_number": 3240,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -169,12 +224,13 @@\nfunc testInputs(t *testing.T) {\n \t\t\tr.Errorf(\"deleteInput got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteInputResponse)\n \t\t}\n \t})\n+\tt.Logf(\"\\nTestInputs() completed\\n\")\n }\n \n-// testChannels tests major operations on channels. Create, list, update,\n+// TestChannels tests major operations on channels. Create, list, update,\n // and get operations check if the channel resource name is returned. The\n // delete operation checks for a hard-coded string response.\n-func testChannels(t *testing.T, outputURI string) {\n+func TestChannels(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "5f09f43ac7be35eb13845ed9ad858e690f09980f"
    },
    {
        "pr_title": "docs(samples): Add assets and pools samples and tests",
        "pr_number": 3240,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -343,12 +399,13 @@\nfunc testChannels(t *testing.T, outputURI string) {\n \t\t\tr.Errorf(\"deleteInput got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteInputResponse)\n \t\t}\n \t})\n+\tt.Logf(\"\\nTestChannels() completed\\n\")\n }\n \n-// testChannelEvents tests event operations on channels. Create, list, and get\n+// TestChannelEvents tests event operations on channels. Create, list, and get\n // operations check if the channel event resource name is returned. The delete\n // operation checks for a hard-coded string response.\n-func testChannelEvents(t *testing.T, outputURI string) {\n+func TestChannelEvents(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "5f09f43ac7be35eb13845ed9ad858e690f09980f"
    },
    {
        "pr_title": "docs(samples): Add batch mode sample and test",
        "pr_number": 3227,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -43,7 +43,6 @@\nconst (\n \ttestCaptionsFileName     = \"captions.srt\"\n \ttestSubtitlesFileName1   = \"subtitles-en.srt\"\n \ttestSubtitlesFileName2   = \"subtitles-es.srt\"\n-\tpreset                   = \"preset/web-hd\"\n \tsmallSpriteSheetFileName = \"small-sprite-sheet0000000000.jpeg\"\n \tlargeSpriteSheetFileName = \"large-sprite-sheet0000000000.jpeg\"\n )",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "0db6b6813fa6c1e8bd741aaad84f8ad9eb453a6f"
    },
    {
        "pr_title": "docs(samples): Add batch mode sample and test",
        "pr_number": 3227,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -70,6 +69,7 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tinputSubtitles1URI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testSubtitlesFileName1\n \tinputSubtitles2URI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testSubtitlesFileName2\n \toutputURIForPreset := \"gs://\" + bucketName + \"/test-output-preset/\"\n+\toutputURIForPresetBatchMode := \"gs://\" + bucketName + \"/test-output-preset-batch-mode/\"\n \toutputURIForTemplate := \"gs://\" + bucketName + \"/test-output-template/\"\n \toutputURIForAdHoc := \"gs://\" + bucketName + \"/test-output-adhoc/\"\n \toutputURIForStaticOverlay := \"gs://\" + bucketName + \"/test-output-static-overlay/\"",
        "comments": [
            {
                "comment": "Are these timings confirmed with the API team that the job is expected to complete within these bounds?",
                "position": 73
            },
            {
                "comment": "These test jobs were intentionally made to complete quickly and have been running for about 2 years now.",
                "position": 73
            },
            {
                "comment": "Sounds good, just wanted to check.",
                "position": 73
            }
        ],
        "commit_messages": [
            "feat(Video Stitcher): Add batch mode sample and test"
        ],
        "last_commit_sha": "0db6b6813fa6c1e8bd741aaad84f8ad9eb453a6f"
    },
    {
        "pr_title": "docs(samples): Add batch mode sample and test",
        "pr_number": 3227,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -99,6 +99,8 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tt.Logf(\"\\nwriteTestGCSFiles() completed\\n\")\n \ttestJobFromPreset(t, projectNumber, inputURI, outputURIForPreset)\n \tt.Logf(\"\\ntestJobFromPreset() completed\\n\")\n+\ttestJobFromPresetBatchMode(t, projectNumber, inputURI, outputURIForPresetBatchMode)\n+\tt.Logf(\"\\ntestJobFromPresetBatchMode() completed\\n\")\n \ttestJobFromTemplate(t, projectNumber, inputURI, outputURIForTemplate)\n \tt.Logf(\"\\ntestJobFromTemplate() completed\\n\")\n \ttestJobFromAdHoc(t, projectNumber, inputURI, outputURIForAdHoc)",
        "comments": [],
        "commit_messages": [
            "feat(Video Stitcher): Add batch mode sample and test"
        ],
        "last_commit_sha": "0db6b6813fa6c1e8bd741aaad84f8ad9eb453a6f"
    },
    {
        "pr_title": "docs(samples): Add batch mode sample and test",
        "pr_number": 3227,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -260,7 +262,7 @@\nfunc testJobFromPreset(t *testing.T, projectNumber string, inputURI string, outp\n \n \t// Create the job.\n \tjobName := fmt.Sprintf(\"projects/%s/locations/%s/jobs/\", projectNumber, location)\n-\tif err := createJobFromPreset(buf, tc.ProjectID, location, inputURI, outputURIForPreset, preset); err != nil {\n+\tif err := createJobFromPreset(buf, tc.ProjectID, location, inputURI, outputURIForPreset); err != nil {\n \t\tt.Errorf(\"createJobFromPreset got err: %v\", err)\n \t}\n \tgot := buf.String()",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "0db6b6813fa6c1e8bd741aaad84f8ad9eb453a6f"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect gcs send to scc",
        "pr_number": 3222,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"log\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "added a sample dlp_inspect_gcs_send_to_scc with test"
        ],
        "last_commit_sha": "0523de1e03969a4f45b000f603e52a44ddef7846"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect gcs send to scc",
        "pr_number": 3222,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -27,7 +28,7 @@\nimport (\n \t\"cloud.google.com/go/datastore\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"github.com/gofrs/uuid\"\n+\t\"github.com/google/uuid\"\n )\n \n const (",
        "comments": [],
        "commit_messages": [
            "added a sample dlp_inspect_gcs_send_to_scc with test"
        ],
        "last_commit_sha": "0523de1e03969a4f45b000f603e52a44ddef7846"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect gcs send to scc",
        "pr_number": 3222,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -36,6 +37,11 @@\nconst (\n \n \tssnFileName = \"fake_ssn.txt\"\n \tbucketName  = \"golang-samples-dlp-test2\"\n+\n+\tinspectsGCSTestFileName                 = \"test.txt\"\n+\tfilePathToUpload                        = \"./testdata/test.txt\"\n+\tdirPathForInspectGCSSendToScc           = \"dlp-go-lang-test-for-inspect-gcs-send-to-scc/\"\n+\tbucketnameForInspectGCSFileWithSampling = \"dlp-job-go-lang-test-inspect-gcs-file-with-sampling\"\n )\n \n func TestInspectDatastore(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0523de1e03969a4f45b000f603e52a44ddef7846"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect gcs send to scc",
        "pr_number": 3222,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -55,7 +61,7 @@\nfunc TestInspectDatastore(t *testing.T) {\n \t\tt.Run(test.kind, func(t *testing.T) {\n \t\t\tt.Parallel()\n \t\t\ttestutil.Retry(t, 5, 15*time.Second, func(r *testutil.R) {\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\tbuf := new(bytes.Buffer)\n \t\t\t\tif err := inspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, \"\", test.kind); err != nil {\n \t\t\t\t\tr.Errorf(\"inspectDatastore(%s) got err: %v\", test.kind, err)",
        "comments": [],
        "commit_messages": [
            "added a sample dlp_inspect_gcs_send_to_scc with test"
        ],
        "last_commit_sha": "0523de1e03969a4f45b000f603e52a44ddef7846"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect gcs send to scc",
        "pr_number": 3222,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -108,7 +114,7 @@\nfunc TestInspectGCS(t *testing.T) {\n \t\tt.Run(test.fileName, func(t *testing.T) {\n \t\t\tt.Parallel()\n \t\t\ttestutil.Retry(t, 5, 15*time.Second, func(r *testutil.R) {\n-\t\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\t\tu := uuid.New().String()[:8]\n \t\t\t\tbuf := new(bytes.Buffer)\n \t\t\t\tif err := inspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, bucketName, test.fileName); err != nil {\n \t\t\t\t\tr.Errorf(\"inspectGCSFile(%s) got err: %v\", test.fileName, err)",
        "comments": [],
        "commit_messages": [
            "added a sample dlp_inspect_gcs_send_to_scc with test"
        ],
        "last_commit_sha": "0523de1e03969a4f45b000f603e52a44ddef7846"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect gcs send to scc",
        "pr_number": 3222,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -267,7 +273,7 @@\nfunc TestInspectBigquery(t *testing.T) {\n \t\ttest := test\n \t\tt.Run(test.table, func(t *testing.T) {\n \t\t\tt.Parallel()\n-\t\t\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\t\t\tu := uuid.New().String()[:8]\n \t\t\tbuf := new(bytes.Buffer)\n \t\t\tif err := inspectBigquery(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName+u, subscriptionName+u, tc.ProjectID, bqDatasetID, test.table); err != nil {\n \t\t\t\tt.Errorf(\"inspectBigquery(%s) got err: %v\", test.table, err)",
        "comments": [],
        "commit_messages": [
            "added a sample dlp_inspect_gcs_send_to_scc with test"
        ],
        "last_commit_sha": "0523de1e03969a4f45b000f603e52a44ddef7846"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect gcs send to scc",
        "pr_number": 3222,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -552,12 +558,18 @@\nfunc TestInspectGcsFileWithSampling(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \ttopicID := \"go-lang-dlp-test-bigquery-with-sampling-topic\"\n \tsubscriptionID := \"go-lang-dlp-test-bigquery-with-sampling-subscription\"\n-\tbucketName, err := createBucket(t, tc.ProjectID)\n+\tctx := context.Background()\n+\tsc, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tdefer sc.Close()\n+\n+\tbucketnameForInspectGCSFileWithSampling, err := testutil.CreateTestBucket(ctx, t, sc, tc.ProjectID, \"dlp-test-inspect-prefix\")\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n-\tdefer deleteBucket(t, tc.ProjectID, bucketName)\n-\tGCSUri := \"gs://\" + bucketName + \"/\"\n+\tGCSUri := \"gs://\" + bucketnameForInspectGCSFileWithSampling + \"/\"\n \n \tvar buf bytes.Buffer\n \tif err := inspectGcsFileWithSampling(&buf, tc.ProjectID, GCSUri, topicID, subscriptionID); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0523de1e03969a4f45b000f603e52a44ddef7846"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect gcs send to scc",
        "pr_number": 3222,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -567,60 +579,11 @@\nfunc TestInspectGcsFileWithSampling(t *testing.T) {\n \tif want := \"Job Created\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"inspectGcsFileWithSampling got %q, want %q\", got, want)\n \t}\n-\n-}\n-\n-func createBucket(t *testing.T, projectID string) (string, error) {\n-\tt.Helper()\n-\n-\tctx := context.Background()\n-\n-\tclient, err := storage.NewClient(ctx)\n+\terr = testutil.DeleteBucketIfExists(ctx, sc, bucketnameForInspectGCSFileWithSampling)\n \tif err != nil {\n-\t\treturn \"\", err\n-\t}\n-\tdefer client.Close()\n-\tu := uuid.Must(uuid.NewV4()).String()[:8]\n-\tbucketName := \"dlp-job-go-lang-test\" + u\n-\n-\t// Check if the bucket already exists.\n-\tbucketExists := false\n-\t_, err = client.Bucket(bucketName).Attrs(ctx)\n-\tif err == nil {\n-\t\tbucketExists = true\n-\t}\n-\n-\t// If the bucket doesn't exist, create it.\n-\tif !bucketExists {\n-\t\tif err := client.Bucket(bucketName).Create(ctx, projectID, &storage.BucketAttrs{\n-\t\t\tStorageClass: \"STANDARD\",\n-\t\t\tLocation:     \"us-central1\",\n-\t\t}); err != nil {\n-\t\t\tlog.Fatalf(\"---Failed to create bucket: %v\", err)\n-\t\t}\n-\t\tfmt.Printf(\"---Bucket '%s' created successfully.\\n\", bucketName)\n-\t} else {\n-\t\tfmt.Printf(\"---Bucket '%s' already exists.\\n\", bucketName)\n-\t}\n-\n-\treturn bucketName, nil\n-}\n-\n-func deleteBucket(t *testing.T, projectID, bucketName string) error {\n-\tt.Helper()\n-\n-\tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tdefer client.Close()\n-\n-\tbucket := client.Bucket(bucketName)\n-\tif err := bucket.Delete(ctx); err != nil {\n \t\tt.Fatal(err)\n \t}\n-\treturn nil\n+\n }\n \n func TestInspectBigQueryTableWithSampling(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0523de1e03969a4f45b000f603e52a44ddef7846"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp update stored infotype ",
        "pr_number": 3220,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8878d4d53fb3596e893ae6df4ec9edb2def4469b"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp update stored infotype ",
        "pr_number": 3220,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -31,6 +32,12 @@\nimport (\n \t\"github.com/google/uuid\"\n )\n \n+const (\n+\ttermListFileName = \"term_list.txt\"\n+\tfilePathToUpload = \"./testdata/term_list_storedInfotype.txt\"\n+\tbucket_prefix    = \"test\"\n+)\n+\n func TestInfoTypes(t *testing.T) {\n \ttestutil.SystemTest(t)\n \ttests := []struct {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8878d4d53fb3596e893ae6df4ec9edb2def4469b"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp update stored infotype ",
        "pr_number": 3220,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -70,22 +77,19 @@\nfunc TestInfoTypes(t *testing.T) {\n \t}\n }\n \n-func skipKOKORO(t *testing.T) {\n-\tif os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\") != \"\" {\n-\t\tt.Skip(\"Skipping testing in KOKORO environment\")\n-\t}\n-}\n-\n func TestCreateStoredInfoType(t *testing.T) {\n-\tskipKOKORO(t)\n-\n \ttc := testutil.SystemTest(t)\n-\n-\toutputPath, err := bucketForStoredInfoType(t, tc.ProjectID)\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n-\n+\tdefer client.Close()\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\toutputPath := fmt.Sprintf(\"gs://\" + bucketName + \"/\")\n \tvar buf bytes.Buffer\n \n \tif err := createStoredInfoType(&buf, tc.ProjectID, outputPath); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8878d4d53fb3596e893ae6df4ec9edb2def4469b"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp update stored infotype ",
        "pr_number": 3220,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -106,39 +110,87 @@\nfunc TestCreateStoredInfoType(t *testing.T) {\n \tdefer deleteStoredInfoTypeAfterTest(t, name)\n }\n \n-func bucketForStoredInfoType(t *testing.T, projectID string) (string, error) {\n+func deleteStoredInfoTypeAfterTest(t *testing.T, name string) error {\n \tt.Helper()\n \tctx := context.Background()\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\treq := &dlppb.DeleteStoredInfoTypeRequest{\n+\t\tName: name,\n+\t}\n+\terr = client.DeleteStoredInfoType(ctx, req)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\treturn nil\n+}\n+\n+func TestUpdateStoredInfoType(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tvar buf bytes.Buffer\n+\tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\treturn \"\", err\n+\t\tt.Fatal(err)\n \t}\n \tdefer client.Close()\n+\toutputBucket, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\toutputPath := fmt.Sprintf(\"gs://\" + outputBucket + \"/\")\n \n-\tu := uuid.New().String()[:8]\n-\tbucketName := \"dlp-go-lang-test-metadata\" + u\n-\tdirPath := \"my-directory/\"\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, bucket_prefix)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n \n-\t// Check if the bucket already exists.\n-\tbucketExists := false\n-\t_, err = client.Bucket(bucketName).Attrs(ctx)\n-\tif err == nil {\n-\t\tbucketExists = true\n+\tfileSetUrl, gcsUri, err := filesForUpdateStoredInfoType(t, tc.ProjectID, bucketName)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n \t}\n \n-\t// If the bucket doesn't exist, create it.\n-\tif !bucketExists {\n-\t\tif err := client.Bucket(bucketName).Create(ctx, projectID, &storage.BucketAttrs{\n-\t\t\tStorageClass: \"STANDARD\",\n-\t\t\tLocation:     \"us-central1\",\n-\t\t}); err != nil {\n-\t\t\tlog.Fatalf(\"Failed to create bucket: %v\", err)\n-\t\t}\n-\t\tfmt.Printf(\"Bucket '%s' created successfully.\\n\", bucketName)\n-\t} else {\n-\t\tfmt.Printf(\"Bucket '%s' already exists.\\n\", bucketName)\n+\tinfoTypeId, err := createStoredInfoTypeForTesting(t, tc.ProjectID, outputPath)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tinfoTypeId = strings.TrimPrefix(infoTypeId, fmt.Sprint(\"projects/\"+tc.ProjectID+\"/locations/global/storedInfoTypes/\"))\n+\n+\tduration := time.Duration(30) * time.Second\n+\ttime.Sleep(duration)\n+\n+\tif err := updateStoredInfoType(&buf, tc.ProjectID, gcsUri, fileSetUrl, infoTypeId); err != nil {\n+\t\tt.Fatal(err)\n \t}\n \n+\tgot := buf.String()\n+\n+\tif want := \"output: \"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"error from create stored infoType %q\", got)\n+\t}\n+\n+\tname := strings.TrimPrefix(got, \"output: \")\n+\n+\tdefer deleteStoredInfoTypeAfterTest(t, name)\n+}\n+\n+func filesForUpdateStoredInfoType(t *testing.T, projectID, bucketName string) (string, string, error) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn \"\", \"\", err\n+\t}\n+\tdefer client.Close()\n+\n+\tdirPath := \"update-stored-infoType-data/\"\n+\n \t// Check if the directory already exists in the bucket.\n \tdirExists := false\n \tquery := &storage.Query{Prefix: dirPath}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8878d4d53fb3596e893ae6df4ec9edb2def4469b"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp update trigger",
        "pr_number": 3219,
        "file_name": "dlp/snippets/trigger/trigger_test.go",
        "code_diff": "@@ -33,6 +33,7 @@\nfunc TestTriggersSamples(t *testing.T) {\n \tif err := listTriggers(buf, tc.ProjectID); err != nil {\n \t\tt.Errorf(\"listTriggers: %v\", err)\n \t}\n+\n \tif got := buf.String(); strings.Contains(got, fullID) {\n \t\tbuf.Reset()\n \t\tif err := deleteTrigger(buf, fullID); err != nil {",
        "comments": [],
        "commit_messages": [
            "added a sample dlp_update_trigger with test case"
        ],
        "last_commit_sha": "f78646ff45ddc2eb5b4c09cdb350cce97000558d"
    },
    {
        "pr_title": "fix(eventarc): update e2e tests to send proper payload",
        "pr_number": 3207,
        "file_name": "eventarc/testing/audit_storage.e2e_test.go",
        "code_diff": "@@ -15,13 +15,16 @@\npackage cloudruntests\n \n import (\n+\t\"context\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"net/http\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\tcloudevent \"github.com/cloudevents/sdk-go/v2\"\n )\n \n func TestAuditStorageSinkService(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "fix(eventarc): update e2e tests to send proper payload\n\nthe service this tests is now using the CloudEvent SDK, which does more\npayload validation, and caused the failures in #3188"
        ],
        "last_commit_sha": "861e2a1043380540bb5b3960a8b501886fa01ddf"
    },
    {
        "pr_title": "fix(eventarc): update e2e tests to send proper payload",
        "pr_number": 3207,
        "file_name": "eventarc/testing/audit_storage.e2e_test.go",
        "code_diff": "@@ -34,12 +37,26 @@\nfunc TestAuditStorageSinkService(t *testing.T) {\n \t}\n \tdefer service.Clean()\n \n-\trequestPath := \"/\"\n-\treq, err := service.NewRequest(\"POST\", requestPath)\n+\tevent := cloudevent.NewEvent(\"1.0\")\n+\tevent.SetID(\"1\")\n+\tevent.SetSource(\"test\")\n+\tevent.SetSubject(\"storage.googleapis.com/projects/_/buckets/my-bucket\")\n+\tevent.SetType(\"test\")\n+\n+\tservice_url, err := service.URL(\"/\")\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\treq, err := cloudevent.NewHTTPRequestFromEvent(context.Background(),\n+\t\tservice_url, event)\n \tif err != nil {\n-\t\tt.Fatalf(\"service.NewRequest: %v\", err)\n+\t\tt.Fatal(err)\n \t}\n \n+\t// add a valid auth header to the cloudevent request.\n+\tauthreq, _ := service.NewRequest(\"POST\", \"/\")\n+\treq.Header.Set(\"Authorization\", authreq.Header.Get(\"Authorization\"))\n+\n \tclient := http.Client{Timeout: 10 * time.Second}\n \tresp, err := client.Do(req)\n \tif err != nil {",
        "comments": [
            {
                "comment": "suggestion: Rather than just print b, should we add a test case around the response body?",
                "position": 52
            },
            {
                "comment": "I added this to give us a better message than \"want 200 got 400\" in the case of errors.\r\nThere is a test for body content in `../audit_storage/main_test.go`, which i think is sufficient.",
                "position": 52
            }
        ],
        "commit_messages": [
            "fix(eventarc): update e2e tests to send proper payload\n\nthe service this tests is now using the CloudEvent SDK, which does more\npayload validation, and caused the failures in #3188"
        ],
        "last_commit_sha": "861e2a1043380540bb5b3960a8b501886fa01ddf"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -25,6 +25,7 @@\nimport (\n \t\"time\"\n \n \t\"cloud.google.com/go/iam\"\n+\t\"cloud.google.com/go/pubsub\"\n \t\"cloud.google.com/go/storage\"\n \tstoragetransfer \"cloud.google.com/go/storagetransfer/apiv1\"\n \t\"cloud.google.com/go/storagetransfer/apiv1/storagetransferpb\"",
        "comments": [
            {
                "comment": "I notice that running in Kokoro seems to be skipped in L55... can this be re-enabled? The linked issue seems to be closed. FYI @muncus ",
                "position": 25
            }
        ],
        "commit_messages": [
            "feat(storagetransfer): add event driven transfer samples"
        ],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -34,23 +35,21 @@\nimport (\n \t\"github.com/aws/aws-sdk-go/aws/session\"\n \t\"github.com/aws/aws-sdk-go/service/s3\"\n \t\"github.com/aws/aws-sdk-go/service/s3/s3manager\"\n+\t\"github.com/aws/aws-sdk-go/service/sqs\"\n )\n \n var sc *storage.Client\n var sts *storagetransfer.Client\n+var sess *session.Session\n var s3Bucket string\n var azureContainer string\n var gcsSourceBucket string\n var gcsSinkBucket string\n+var stsServiceAccountEmail string\n \n func TestMain(m *testing.M) {\n \t// Initialize global vars\n \ttc, _ := testutil.ContextMain(m)\n-\tif os.Getenv(\"KOKORO_BUILD_ID\") != \"\" {\n-\t\t// temporarily skip initialization in kokoro\n-\t\t// See https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\n-\t\treturn\n-\t}\n \n \tctx := context.Background()\n \tc, err := storage.NewClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -80,11 +79,21 @@\nfunc TestMain(m *testing.M) {\n \t}\n \tdefer sts.Close()\n \n-\tgrantSTSPermissions(gcsSourceBucket, tc.ProjectID, sts, sc)\n-\tgrantSTSPermissions(gcsSinkBucket, tc.ProjectID, sts, sc)\n+\treq := &storagetransferpb.GetGoogleServiceAccountRequest{\n+\t\tProjectId: tc.ProjectID,\n+\t}\n+\n+\tresp, err := sts.GetGoogleServiceAccount(ctx, req)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"error getting service account: %v\", err)\n+\t}\n+\tstsServiceAccountEmail = resp.AccountEmail\n+\n+\tgrantSTSPermissions(gcsSourceBucket, sc)\n+\tgrantSTSPermissions(gcsSinkBucket, sc)\n \n \ts3Bucket = testutil.UniqueBucketName(\"stss3bucket\")\n-\tsess, err := session.NewSession(&aws.Config{\n+\tsess, err = session.NewSession(&aws.Config{\n \t\tRegion: aws.String(\"us-west-2\")},\n \t)\n \ts3c := s3.New(sess)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -139,7 +148,6 @@\nfunc TestMain(m *testing.M) {\n }\n \n func TestQuickstart(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "unskip tests and reconfigure secret manager script"
        ],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -157,7 +165,6 @@\nfunc TestQuickstart(t *testing.T) {\n }\n \n func TestTransferFromAws(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "unskip tests and reconfigure secret manager script"
        ],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -176,7 +183,6 @@\nfunc TestTransferFromAws(t *testing.T) {\n }\n \n func TestTransferToNearline(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "unskip tests and reconfigure secret manager script"
        ],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -195,7 +201,6 @@\nfunc TestTransferToNearline(t *testing.T) {\n }\n \n func TestGetLatestTransferOperation(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "unskip tests and reconfigure secret manager script"
        ],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -219,7 +224,6 @@\nfunc TestGetLatestTransferOperation(t *testing.T) {\n }\n \n func TestDownloadToPosix(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "unskip tests and reconfigure secret manager script"
        ],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -247,7 +251,6 @@\nfunc TestDownloadToPosix(t *testing.T) {\n }\n \n func TestTransferFromPosix(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "unskip tests and reconfigure secret manager script"
        ],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -274,7 +277,6 @@\nfunc TestTransferFromPosix(t *testing.T) {\n }\n \n func TestTransferBetweenPosix(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "unskip tests and reconfigure secret manager script"
        ],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -307,7 +309,6 @@\nfunc TestTransferBetweenPosix(t *testing.T) {\n }\n \n func TestTransferUsingManifest(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "unskip tests and reconfigure secret manager script"
        ],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -338,7 +339,6 @@\nfunc TestTransferUsingManifest(t *testing.T) {\n }\n \n func TestTransferFromS3CompatibleSource(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "unskip tests and reconfigure secret manager script"
        ],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "feat(storagetransfer): add event driven transfer samples",
        "pr_number": 3200,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -361,7 +361,6 @@\nfunc TestTransferFromS3CompatibleSource(t *testing.T) {\n }\n \n func TestTransferFromAzure(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/2811\")\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "unskip tests and reconfigure secret manager script"
        ],
        "last_commit_sha": "3c349c05f2d2e274aa75f47b2122511afd8c7902"
    },
    {
        "pr_title": "fix(kms): waiting for key import to finish",
        "pr_number": 3193,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \t\"cloud.google.com/go/kms/apiv1/kmspb\"",
        "comments": [],
        "commit_messages": [
            "Fix #2833 by waiting for import to finish"
        ],
        "last_commit_sha": "08e23a26c3d8f18b75b1980f2b61a27c9fbbdc79"
    },
    {
        "pr_title": "fix(kms): waiting for key import to finish",
        "pr_number": 3193,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -514,6 +515,7 @@\nfunc TestImportEndToEnd(t *testing.T) {\n \tcryptoKeyName := fmt.Sprintf(\"%s/cryptoKeys/%s\", fixture.KeyRingName, cryptoKeyID)\n \n \t// Create import job.\n+\tb.Reset()\n \timportJobID := fixture.RandomID()\n \tif err := createImportJob(&b, fixture.KeyRingName, importJobID); err != nil {\n \t\tt.Fatal(err)",
        "comments": [],
        "commit_messages": [
            "Fix #2833 by waiting for import to finish"
        ],
        "last_commit_sha": "08e23a26c3d8f18b75b1980f2b61a27c9fbbdc79"
    },
    {
        "pr_title": "fix(kms): waiting for key import to finish",
        "pr_number": 3193,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -524,13 +526,17 @@\nfunc TestImportEndToEnd(t *testing.T) {\n \timportJobName := fmt.Sprintf(\"%s/importJobs/%s\", fixture.KeyRingName, importJobID)\n \n \t// Check import job state (wait for ACTIVE).\n+\tb.Reset()\n \tfor !strings.Contains(b.String(), \"ACTIVE\") {\n \t\tif err := checkStateImportJob(&b, importJobName); err != nil {\n \t\t\tt.Fatal(err)\n \t\t}\n+\n+\t\ttime.Sleep(time.Second * 2)\n \t}\n \n \t// Import the key.\n+\tb.Reset()\n \tif err := importManuallyWrappedKey(&b, importJobName, cryptoKeyName); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_messages": [
            "Fix #2833 by waiting for import to finish"
        ],
        "last_commit_sha": "08e23a26c3d8f18b75b1980f2b61a27c9fbbdc79"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp create stored infotype",
        "pr_number": 3191,
        "file_name": "dlp/snippets/metadata/metadata_test.go",
        "code_diff": "@@ -17,10 +17,18 @@\npackage metadata\n \n import (\n \t\"bytes\"\n+\t\"context\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n \t\"strings\"\n \t\"testing\"\n \n+\tdlp \"cloud.google.com/go/dlp/apiv2\"\n+\t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n )\n \n func TestInfoTypes(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "83d551e3025d63ec776de2a1e55baef54d860a30"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n+\t\"cloud.google.com/go/storage\"\n \t\"google.golang.org/api/iterator\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [
            "feat(pubsub): add sample and test for cloud storage subscription"
        ],
        "last_commit_sha": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(pubsub): add cloud storage subscription sample",
        "pr_number": 3190,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -779,6 +780,36 @@\nfunc TestCreateBigQuerySubscription(t *testing.T) {\n \t}\n }\n \n+func TestCreateCloudStorageSubscription(t *testing.T) {\n+\tt.Parallel()\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tdefer client.Close()\n+\tstorageSubID := subID + \"-cloud-storage\"\n+\n+\ttopic, err := getOrCreateTopic(ctx, client, topicID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"CreateTopic: %v\", err)\n+\t}\n+\tvar buf bytes.Buffer\n+\n+\t// Use the same bucket across test instances. This\n+\t// is safe since we're not writing to the bucket\n+\t// and this makes us not have to do bucket cleanups.\n+\tbucketID := fmt.Sprintf(\"%s-%s\", tc.ProjectID, \"pubsub-storage-sub-sink\")\n+\tif err := createOrGetStorageBucket(tc.ProjectID, bucketID); err != nil {\n+\t\tt.Fatalf(\"failed to get or create storage bucket: %v\", err)\n+\t}\n+\n+\tif err := createCloudStorageSubscription(&buf, tc.ProjectID, storageSubID, topic, bucketID); err != nil {\n+\t\tt.Fatalf(\"failed to create cloud storage subscription: %v\", err)\n+\t}\n+\n+\tsub := client.Subscription(storageSubID)\n+\tsub.Delete(ctx)\n+}\n+\n func TestCreateSubscriptionWithExactlyOnceDelivery(t *testing.T) {\n \tt.Parallel()\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "e64735b7869065009bd68a23a8d2d85b66c1c4e4"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp reidentify fpe",
        "pr_number": 3186,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -17,9 +17,9 @@\npackage deid\n // [START dlp_deidentify_fpe]\n import (\n \t\"context\"\n+\t\"encoding/base64\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"",
        "comments": [],
        "commit_messages": [
            "added a sample of reid_text_fpe"
        ],
        "last_commit_sha": "7d7f199acf6554ba54135142d2cde8a13aeb8df3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp reidentify fpe",
        "pr_number": 3186,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -31,12 +31,12 @@\nimport (\n // optional identifier needed for reidentification. surrogateInfoType can be any\n // value not found in your input.\n // Info types can be found with the infoTypes.list method or on https://cloud.google.com/dlp/docs/infotypes-reference\n-func deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n+func deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string, kmsKeyName, wrappedAESKey, surrogateInfoType string) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 123456789\"\n \t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n-\t// keyFileName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"\n-\t// cryptoKeyName := \"YOUR_ENCRYPTED_AES_256_KEY\"\n+\t// kmsKeyName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"\n+\t// wrappedAESKey := \"YOUR_ENCRYPTED_AES_256_KEY\"\n \t// surrogateInfoType := \"AGE\"\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7d7f199acf6554ba54135142d2cde8a13aeb8df3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp reidentify fpe",
        "pr_number": 3186,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -49,11 +49,13 @@\nfunc deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string,\n \tfor _, it := range infoTypeNames {\n \t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n-\t// Read the key file.\n-\tkeyBytes, err := ioutil.ReadFile(keyFileName)\n+\n+\t// Specify an encrypted AES-256 key and the name of the Cloud KMS key that encrypted it.\n+\tkmsWrappedCryptoKey, err := base64.StdEncoding.DecodeString(wrappedAESKey)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"ReadFile: %w\", err)\n+\t\treturn err\n \t}\n+\n \t// Create a configured request.\n \treq := &dlppb.DeidentifyContentRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/global\", projectID),",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7d7f199acf6554ba54135142d2cde8a13aeb8df3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp reidentify fpe",
        "pr_number": 3186,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -534,9 +534,13 @@\nfunc TestDeIdentifyTimeExtract(t *testing.T) {\n \t}\n }\n \n-func TestReidTableDataWithFPE(t *testing.T) {\n+func TestReidTextDataWithFPE(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n+\n+\tinput := \"My SSN is 123456789\"\n+\tinfoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\tsurrogateInfoType := \"AGE\"\n \n \tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7d7f199acf6554ba54135142d2cde8a13aeb8df3"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp reidentify free text with fpe using surrogate",
        "pr_number": 3182,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -347,6 +347,33 @@\nfunc TestDeIdentifyDeterministic(t *testing.T) {\n \n }\n \n+func TestReidentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tvar buf bytes.Buffer\n+\n+\tinputStr := \"My phone number is 1234567890\"\n+\tinfoType := \"PHONE_NUMBER\"\n+\tsurrogateType := \"PHONE_TOKEN\"\n+\tunwrappedKey := \"hu4O2y0RsY9qrVt1d2xAWEmqVqAc1P8Vk7D6peashag=\"\n+\n+\tif err := deidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputStr, infoType, surrogateType, unwrappedKey); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tinputForReid := \"My phone number is PHONE_TOKEN(10):4169075971\"\n+\n+\tbuf.Reset()\n+\tif err := reidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, inputForReid, surrogateType, unwrappedKey); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"output: My phone number is 1234567890\"; got != want {\n+\t\tt.Errorf(\"reidentifyFreeTextWithFPEUsingSurrogate got %q, want %q\", got, want)\n+\t}\n+\n+}\n+\n func TestDeIdentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6483589359982c3f1082b730d0092240e22b4926"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp deidentify reidentify deterministic",
        "pr_number": 3181,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -347,6 +347,79 @@\nfunc TestDeIdentifyDeterministic(t *testing.T) {\n \n }\n \n+func TestDeIdentifyFreeTextWithFPEUsingSurrogate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tinput := \"My phone number is 5555551212\"\n+\tinfoType := \"PHONE_NUMBER\"\n+\tsurrogateType := \"PHONE_TOKEN\"\n+\tunWrappedKey, err := getUnwrappedKey(t)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\twant := \"output: My phone number is PHONE_TOKEN(10):\"\n+\n+\tvar buf bytes.Buffer\n+\tif err := deidentifyFreeTextWithFPEUsingSurrogate(&buf, tc.ProjectID, input, infoType, surrogateType, unWrappedKey); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyFreeTextWithFPEUsingSurrogate(%q) = %q, want %q\", input, got, want)\n+\t}\n+}\n+\n+func getUnwrappedKey(t *testing.T) (string, error) {\n+\tt.Helper()\n+\tkey := make([]byte, 32) // 32 bytes for AES-256\n+\t_, err := rand.Read(key)\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\n+\t// Encode the key to base64\n+\tencodedKey := base64.StdEncoding.EncodeToString(key)\n+\treturn string(encodedKey), nil\n+\n+}\n+\n+func TestReidentifyWithDeterministic(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tvar buf bytes.Buffer\n+\n+\tinputStr := \"My SSN is 372819127\"\n+\tinfoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\tkeyRingName, err := createKeyRing(t, tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tkeyFileName, cryptoKeyName, keyVersion, err := createKey(t, tc.ProjectID, keyRingName)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tdefer destroyKey(t, tc.ProjectID, keyVersion)\n+\n+\tsurrogateInfoType := \"SSN_TOKEN\"\n+\n+\tif err := deIdentifyDeterministicEncryption(&buf, tc.ProjectID, inputStr, infoTypeNames, keyFileName, cryptoKeyName, surrogateInfoType); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tdeidContent := buf.String()\n+\n+\tinputForReid := strings.TrimPrefix(deidContent, \"output : \")\n+\n+\tbuf.Reset()\n+\tif err := reidentifyWithDeterministic(&buf, tc.ProjectID, inputForReid, surrogateInfoType, keyFileName, cryptoKeyName); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"output: My SSN is 372819127\"; got != want {\n+\t\tt.Errorf(\"reidentifyWithDeterministic got %q, want %q\", got, want)\n+\t}\n+\n+}\n+\n func createKeyRing(t *testing.T, projectID string) (string, error) {\n \tt.Helper()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "65e17dc81b5abe3857d66fd8620d177d7ed37228"
    },
    {
        "pr_title": "fix(logging): adds retries, longer timeout to taillogs test",
        "pr_number": 3178,
        "file_name": "logging/taillogs/taillogs_test.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n \n \t\"cloud.google.com/go/logging\"\n \t\"cloud.google.com/go/logging/logadmin\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n )",
        "comments": [],
        "commit_messages": [
            "fix(logging): adds retries, longer timeout to taillogs test"
        ],
        "last_commit_sha": "2c4bcafea93889d9f4da0cd28c05dd317659a717"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect gcs with sampling",
        "pr_number": 3170,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -17,6 +17,8 @@\npackage inspect\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n+\t\"log\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6c5d098dc510b0d17f7309108e11a9ef5495fdbf"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp deidentify replace infotype ",
        "pr_number": 3166,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -273,6 +273,24 @@\nfunc TestDeIdentifyWithWordList(t *testing.T) {\n \t}\n }\n \n+func TestDeIdentifyWithInfotype(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tinput := \"My email is test@example.com\"\n+\tinfoType := []string{\"EMAIL_ADDRESS\"}\n+\twant := \"output : My email is [EMAIL_ADDRESS]\"\n+\n+\tvar buf bytes.Buffer\n+\n+\tif err := deidentifyWithInfotype(&buf, tc.ProjectID, input, infoType); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got := buf.String(); got != want {\n+\t\tt.Errorf(\"deidentifyFreeTextWithFPEUsingSurrogate(%q) = %q, want %q\", input, got, want)\n+\t}\n+\n+}\n+\n func TestDeidentifyTableFPE(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8122bbd3c413a2623415ec32df13693da2d09420"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\npackage subscriptions\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"errors\"\n \t\"fmt\"\n \t\"strconv\"\n \t\"strings\"",
        "comments": [],
        "commit_messages": [
            "Merge branch 'main' into feat-pubsub-clear-bq-sub"
        ],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -30,6 +31,7 @@\nimport (\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"cloud.google.com/go/storage\"\n+\t\"google.golang.org/api/googleapi\"\n \t\"google.golang.org/api/iterator\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -60,8 +62,9 @@\nfunc setup(t *testing.T) *pubsub.Client {\n \t}\n \n \tonce.Do(func() {\n-\t\ttopicID = fmt.Sprintf(\"%s-%d\", topicPrefix, time.Now().UnixNano())\n-\t\tsubID = fmt.Sprintf(\"%s-%d\", subPrefix, time.Now().UnixNano())\n+\t\tvar now = time.Now().UnixNano()\n+\t\ttopicID = fmt.Sprintf(\"%s-%d\", topicPrefix, now)\n+\t\tsubID = fmt.Sprintf(\"%s-%d\", subPrefix, now)\n \n \t\t// Cleanup resources from the previous tests.\n \t\tit := client.Topics(ctx)",
        "comments": [],
        "commit_messages": [
            "chore: minor cleanup"
        ],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -130,26 +133,26 @@\nfunc TestCreate(t *testing.T) {\n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\ttopic, err = client.CreateTopic(ctx, topicID)\n \t\tif err != nil {\n-\t\t\tt.Fatalf(\"CreateTopic: %v\", err)\n+\t\t\tr.Errorf(\"CreateTopic: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\tbuf := new(bytes.Buffer)\n \t\tif err := create(buf, tc.ProjectID, subID, topic); err != nil {\n-\t\t\tt.Fatalf(\"failed to create a subscription: %v\", err)\n+\t\t\tr.Errorf(\"failed to create a subscription: %v\", err)\n \t\t}\n \t\tgot := buf.String()\n \t\twant := \"Created subscription\"\n \t\tif !strings.Contains(got, want) {\n-\t\t\tt.Fatalf(\"got: %s, want: %v\", got, want)\n+\t\t\tr.Errorf(\"got: %s, want: %v\", got, want)\n \t\t}\n \t\tok, err := client.Subscription(subID).Exists(context.Background())\n \t\tif err != nil {\n-\t\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n+\t\t\tr.Errorf(\"failed to check if sub exists: %v\", err)\n \t\t}\n \t\tif !ok {\n-\t\t\tt.Fatalf(\"got none; want sub = %q\", subID)\n+\t\t\tr.Errorf(\"got none; want sub = %q\", subID)\n \t\t}\n \t})\n }",
        "comments": [],
        "commit_messages": [
            "read buffer for push subscription related tests"
        ],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -251,6 +254,45 @@\nfunc TestDelete(t *testing.T) {\n \t}\n }\n \n+func TestPushSubscription(t *testing.T) {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\n+\tvar topic *pubsub.Topic\n+\tvar err error\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\ttopic, err = client.CreateTopic(ctx, topicID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"CreateTopic: %v\", err)\n+\t\t}\n+\t})\n+\n+\tpushSubID := subID + \"-push\"\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n+\t\tendpoint := \"https://\" + tc.ProjectID + \".appspot.com/_ah/push-handlers/push\"\n+\t\tif err := createWithEndpoint(buf, tc.ProjectID, pushSubID, topic, endpoint); err != nil {\n+\t\t\tr.Errorf(\"failed to create a push subscription: %v\", err)\n+\t\t}\n+\t\tgot := buf.String()\n+\t\twant := \"Created subscription\"\n+\t\tif !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"got: %s, want: %v\", got, want)\n+\t\t}\n+\n+\t\tbuf.Reset()\n+\t\tif err := clearPushSubscription(buf, tc.ProjectID, pushSubID); err != nil {\n+\t\t\tr.Errorf(\"failed to clear push subscription: %v\", err)\n+\t\t}\n+\t\tgot2 := buf.String()\n+\t\twant2 := \"Cleared push subscription, reverting to pull\"\n+\t\tif !strings.Contains(got2, want2) {\n+\t\t\tr.Errorf(\"got: %s, want: %v\", got2, want2)\n+\t\t}\n+\t})\n+}\n+\n func TestPullMsgsAsync(t *testing.T) {\n \tt.Parallel()\n \tclient := setup(t)",
        "comments": [],
        "commit_messages": [
            "read buffer for push subscription related tests"
        ],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -282,7 +324,10 @@\nfunc TestPullMsgsAsync(t *testing.T) {\n \t\t// we're not testing client library functionality,\n \t\t// and makes the sample more readable.\n \t\tconst numMsgs = 1\n-\t\tpublishMsgs(ctx, topic, numMsgs)\n+\t\terr = publishMsgs(ctx, topic, numMsgs)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"failed to publish message: %v\", err)\n+\t\t}\n \n \t\tbuf := new(bytes.Buffer)\n \t\terr = pullMsgs(buf, tc.ProjectID, asyncSubID)",
        "comments": [],
        "commit_messages": [
            "Merge branch 'main' into feat-pubsub-clear-bq-sub"
        ],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -328,7 +373,10 @@\nfunc TestPullMsgsSync(t *testing.T) {\n \t\t// we're not testing client library functionality,\n \t\t// and makes the sample more readable.\n \t\tconst numMsgs = 1\n-\t\tpublishMsgs(ctx, topic, numMsgs)\n+\t\terr = publishMsgs(ctx, topic, numMsgs)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"failed to publish message: %v\", err)\n+\t\t}\n \n \t\tbuf := new(bytes.Buffer)\n \t\terr = pullMsgsSync(buf, tc.ProjectID, subIDSync)",
        "comments": [],
        "commit_messages": [
            "Merge branch 'main' into feat-pubsub-clear-bq-sub"
        ],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -371,7 +419,10 @@\nfunc TestPullMsgsConcurrencyControl(t *testing.T) {\n \n \t\t// Publish 5 message to test with.\n \t\tconst numMsgs = 5\n-\t\tpublishMsgs(ctx, topic, numMsgs)\n+\t\terr = publishMsgs(ctx, topic, numMsgs)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"failed to publish message: %v\", err)\n+\t\t}\n \n \t\tbuf := new(bytes.Buffer)\n \t\tif err := pullMsgsConcurrencyControl(buf, tc.ProjectID, subIDConc); err != nil {",
        "comments": [],
        "commit_messages": [
            "Merge branch 'main' into feat-pubsub-clear-bq-sub"
        ],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -690,8 +741,8 @@\nfunc TestDetachSubscription(t *testing.T) {\n \t}\n \tdefer sub.Delete(ctx)\n \n-\tbuf := new(bytes.Buffer)\n-\tif err = detachSubscription(buf, tc.ProjectID, sub.String()); err != nil {\n+\tvar buf bytes.Buffer\n+\tif err = detachSubscription(&buf, tc.ProjectID, sub.String()); err != nil {\n \t\tt.Fatalf(\"detachSubscription: %v\", err)\n \t}\n \tgot := buf.String()",
        "comments": [],
        "commit_messages": [
            "Merge branch 'main' into feat-pubsub-clear-bq-sub"
        ],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -721,9 +772,9 @@\nfunc TestCreateWithFilter(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"CreateTopic: %v\", err)\n \t}\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \tfilter := \"attributes.author=\\\"unknown\\\"\"\n-\tif err := createWithFilter(buf, tc.ProjectID, filterSubID, filter, topic); err != nil {\n+\tif err := createWithFilter(&buf, tc.ProjectID, filterSubID, filter, topic); err != nil {\n \t\tt.Fatalf(\"failed to create subscription with filter: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "Merge branch 'main' into feat-pubsub-clear-bq-sub"
        ],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -828,29 +879,45 @@\nfunc TestCreateBigQuerySubscription(t *testing.T) {\n \tdefer client.Close()\n \tbqSubID := subID + \"-bigquery\"\n \n-\ttopic, err := getOrCreateTopic(ctx, client, topicID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"CreateTopic: %v\", err)\n-\t}\n-\tbuf := new(bytes.Buffer)\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\ttopic, err := getOrCreateTopic(ctx, client, topicID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"CreateTopic: %v\", err)\n+\t\t}\n+\t\tvar buf bytes.Buffer\n \n-\tdatasetID := fmt.Sprintf(\"go_samples_dataset_%d\", time.Now().UnixNano())\n-\ttableID := fmt.Sprintf(\"go_samples_table_%d\", time.Now().UnixNano())\n-\tif err := createBigQueryTable(tc.ProjectID, datasetID, tableID); err != nil {\n-\t\tt.Fatalf(\"failed to create bigquery table: %v\", err)\n-\t}\n+\t\tdatasetID := \"go_pubsub_samples_dataset\"\n+\t\ttableID := \"go_pubsub_samples_table\"\n+\t\tif err := ensureExistsBQTable(tc.ProjectID, datasetID, tableID); err != nil {\n+\t\t\tr.Errorf(\"failed to ensure bigquery table exists: %v\", err)\n+\t\t}\n \n-\tbqTable := fmt.Sprintf(\"%s.%s.%s\", tc.ProjectID, datasetID, tableID)\n+\t\tbqTable := fmt.Sprintf(\"%s.%s.%s\", tc.ProjectID, datasetID, tableID)\n \n-\tif err := createBigQuerySubscription(buf, tc.ProjectID, bqSubID, topic, bqTable); err != nil {\n-\t\tt.Fatalf(\"failed to create bigquery subscription: %v\", err)\n-\t}\n+\t\tif err := createBigQuerySubscription(&buf, tc.ProjectID, bqSubID, topic, bqTable); err != nil {\n+\t\t\tr.Errorf(\"failed to create bigquery subscription: %v\", err)\n+\t\t}\n+\t\tgot := buf.String()\n+\t\twant := \"Created BigQuery subscription\"\n+\t\tif !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"got: %s, want: %v\", got, want)\n+\t\t}\n+\t})\n+\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif err := clearBigQuerySubscription(buf, tc.ProjectID, bqSubID); err != nil {\n+\t\t\tr.Errorf(\"failed to clear bigquery subscription: %v\", err)\n+\t\t}\n+\t\tgot2 := buf.String()\n+\t\twant2 := \"Cleared BigQuery subscription, reverting to pull\"\n+\t\tif !strings.Contains(got2, want2) {\n+\t\t\tr.Errorf(\"got: %s, want: %v\", got2, want2)\n+\t\t}\n+\t})\n \n \tsub := client.Subscription(bqSubID)\n \tsub.Delete(ctx)\n-\tif err := deleteBigQueryDataset(tc.ProjectID, datasetID); err != nil {\n-\t\tt.Logf(\"failed to delete bigquery dataset: %v\", err)\n-\t}\n }\n \n func TestCreateCloudStorageSubscription(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -936,7 +1003,10 @@\nfunc TestReceiveMessagesWithExactlyOnceDelivery(t *testing.T) {\n \t// we're not testing client library functionality,\n \t// and makes the sample more readable.\n \tconst numMsgs = 1\n-\tpublishMsgs(ctx, topic, numMsgs)\n+\terr = publishMsgs(ctx, topic, numMsgs)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to publish message: %v\", err)\n+\t}\n \n \tbuf := new(bytes.Buffer)\n \terr = receiveMessagesWithExactlyOnceDeliveryEnabled(buf, tc.ProjectID, eodSubID)",
        "comments": [],
        "commit_messages": [
            "Merge branch 'main' into feat-pubsub-clear-bq-sub"
        ],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -966,8 +1036,8 @@\nfunc TestOptimisticSubscribe(t *testing.T) {\n \t\tdefer topic.Delete(ctx)\n \t\tdefer topic.Stop()\n \n-\t\tbuf := new(bytes.Buffer)\n-\t\terr = optimisticSubscribe(buf, tc.ProjectID, optTopicID, optSubID)\n+\t\tvar buf bytes.Buffer\n+\t\terr = optimisticSubscribe(&buf, tc.ProjectID, optTopicID, optSubID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"failed to pull messages: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -998,7 +1068,7 @@\nfunc publishMsgs(ctx context.Context, t *pubsub.Topic, numMsgs int) error {\n \t// Check that all messages were published.\n \tfor _, r := range results {\n \t\tif _, err := r.Get(ctx); err != nil {\n-\t\t\treturn fmt.Errorf(\"Get publish result: %w\", err)\n+\t\t\treturn fmt.Errorf(\"get publish result %w\", err)\n \t\t}\n \t}\n \treturn nil",
        "comments": [],
        "commit_messages": [
            "Merge branch 'main' into feat-pubsub-clear-bq-sub"
        ],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(pubsub): add clear export subscription samples",
        "pr_number": 3159,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -1036,42 +1106,41 @@\nfunc getOrCreateSub(ctx context.Context, client *pubsub.Client, subID string, cf\n \treturn sub, nil\n }\n \n-func createBigQueryTable(projectID, datasetID, tableID string) error {\n+// ensureExistsBQTable ensures that the dataset and table exist.\n+// If either does not exist, we create it. Errors returned from\n+// fetching or creating will be returned still.\n+func ensureExistsBQTable(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \n \tc, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"error instantiating bigquery client: %w\", err)\n \t}\n \tdataset := c.Dataset(datasetID)\n-\tif err = dataset.Create(ctx, &bigquery.DatasetMetadata{Location: \"US\"}); err != nil {\n-\t\treturn fmt.Errorf(\"error creating dataset: %w\", err)\n+\tif _, err = dataset.Metadata(ctx); err != nil {\n+\t\tvar e *googleapi.Error\n+\t\tif errors.As(err, &e) && e.Code == 404 {\n+\t\t\tif err = dataset.Create(ctx, &bigquery.DatasetMetadata{Location: \"US\"}); err != nil {\n+\t\t\t\treturn fmt.Errorf(\"error creating dataset: %w\", err)\n+\t\t\t}\n+\t\t}\n \t}\n \n \ttable := dataset.Table(tableID)\n-\tschema := []*bigquery.FieldSchema{\n-\t\t{Name: \"data\", Type: bigquery.BytesFieldType, Required: true},\n-\t\t{Name: \"message_id\", Type: bigquery.StringFieldType, Required: true},\n-\t\t{Name: \"attributes\", Type: bigquery.StringFieldType, Required: true},\n-\t\t{Name: \"subscription_name\", Type: bigquery.StringFieldType, Required: true},\n-\t\t{Name: \"publish_time\", Type: bigquery.TimestampFieldType, Required: true},\n-\t}\n-\tif err := table.Create(ctx, &bigquery.TableMetadata{Schema: schema}); err != nil {\n-\t\treturn fmt.Errorf(\"error creating table: %w\", err)\n-\t}\n-\treturn nil\n-}\n-\n-func deleteBigQueryDataset(projectID, datasetID string) error {\n-\tctx := context.Background()\n-\n-\tc, err := bigquery.NewClient(ctx, projectID)\n-\tif err != nil {\n-\t\treturn fmt.Errorf(\"error instantiating bigquery client: %w\", err)\n-\t}\n-\tdataset := c.Dataset(datasetID)\n-\tif err = dataset.DeleteWithContents(ctx); err != nil {\n-\t\treturn fmt.Errorf(\"error deleting dataset: %w\", err)\n+\tif _, err := table.Metadata(ctx); err != nil {\n+\t\tvar e *googleapi.Error\n+\t\tif errors.As(err, &e) && e.Code == 404 {\n+\t\t\tschema := []*bigquery.FieldSchema{\n+\t\t\t\t{Name: \"data\", Type: bigquery.BytesFieldType, Required: true},\n+\t\t\t\t{Name: \"message_id\", Type: bigquery.StringFieldType, Required: true},\n+\t\t\t\t{Name: \"attributes\", Type: bigquery.StringFieldType, Required: true},\n+\t\t\t\t{Name: \"subscription_name\", Type: bigquery.StringFieldType, Required: true},\n+\t\t\t\t{Name: \"publish_time\", Type: bigquery.TimestampFieldType, Required: true},\n+\t\t\t}\n+\t\t\tif err := table.Create(ctx, &bigquery.TableMetadata{Schema: schema}); err != nil {\n+\t\t\t\treturn fmt.Errorf(\"error creating table: %w\", err)\n+\t\t\t}\n+\t\t}\n \t}\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "148380f4d5c9cf6e47e1fae8f88ebb9ede08904e"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp redact image all text",
        "pr_number": 3149,
        "file_name": "dlp/snippets/redact/redact_test.go",
        "code_diff": "@@ -16,6 +16,11 @@\npackage redact\n \n import (\n \t\"bytes\"\n+\t\"crypto/md5\"\n+\t\"encoding/hex\"\n+\t\"errors\"\n+\t\"io\"\n+\t\"os\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "updated the test case"
        ],
        "last_commit_sha": "5386ba07620219393708339d6ebfe63c0412757f"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp deidentify deterministic",
        "pr_number": 3148,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -17,11 +17,18 @@\npackage deid\n \n import (\n \t\"bytes\"\n+\t\"context\"\n+\t\"encoding/base64\"\n+\t\"fmt\"\n+\t\"log\"\n \t\"strings\"\n \n \t\"testing\"\n \n+\tkms \"cloud.google.com/go/kms/apiv1\"\n+\t\"cloud.google.com/go/kms/apiv1/kmspb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n )\n \n func TestMask(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "04c2afbd057512ec473f60c385aed6608836b292"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp deidentify deterministic",
        "pr_number": 3148,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -180,6 +187,7 @@\nfunc TestDeidentifyExceptionList(t *testing.T) {\n \tif got := buf.String(); got != want {\n \t\tt.Errorf(\"deidentifyExceptionList(%q) = %q, want %q\", input, got, want)\n \t}\n+\n }\n \n func TestDeIdentifyWithReplacement(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "resolving the linting error"
        ],
        "last_commit_sha": "04c2afbd057512ec473f60c385aed6608836b292"
    },
    {
        "pr_title": "feat(fixit): Listing CAs sample + projectId name fixes",
        "pr_number": 3133,
        "file_name": "privateca/create_ca.go",
        "code_diff": "@@ -29,14 +29,14 @@\nimport (\n // responsible for signing certificates within this pool.\n func createCa(\n \tw io.Writer,\n-\tprojectID string,\n+\tprojectId string,\n \tlocation string,\n \tcaPoolId string,\n \tcaId string,\n \tcaCommonName string,\n \torg string,\n \tcaDuration int64) error {\n-\t// projectID := \"your_project_id\"\n+\t// projectId := \"your_project_id\"\n \t// location := \"us-central1\"\t\t// For a list of locations, see: https://cloud.google.com/certificate-authority-service/docs/locations.\n \t// caPoolId := \"ca-pool-id\"\t\t\t// The CA Pool id under which the CA should be created.\n \t// caId := \"ca-id\"\t\t\t\t\t// A unique id/name for the ca.",
        "comments": [],
        "commit_messages": [
            "feat(fixit): Listing CAs sample + projectId name fixes"
        ],
        "last_commit_sha": "3b0d266eab461c50f4a204fe469002385c343be7"
    },
    {
        "pr_title": "feat(fixit): Listing CAs sample + projectId name fixes",
        "pr_number": 3133,
        "file_name": "privateca/create_ca_pool.go",
        "code_diff": "@@ -26,8 +26,8 @@\nimport (\n \n // Create a Certificate Authority pool. All certificates created under this CA pool will\n // follow the same issuance policy, IAM policies, etc.\n-func createCaPool(w io.Writer, projectID string, location string, caPoolId string) error {\n-\t// projectID := \"your_project_id\"\n+func createCaPool(w io.Writer, projectId string, location string, caPoolId string) error {\n+\t// projectId := \"your_project_id\"\n \t// location := \"us-central1\"\t// For a list of locations, see: https://cloud.google.com/certificate-authority-service/docs/locations.\n \t// caPoolId := \"ca-pool-id\"\t\t// A unique id/name for the ca pool.",
        "comments": [],
        "commit_messages": [
            "feat(fixit): Listing CAs sample + projectId name fixes"
        ],
        "last_commit_sha": "3b0d266eab461c50f4a204fe469002385c343be7"
    },
    {
        "pr_title": "feat(fixit): Listing CAs sample + projectId name fixes",
        "pr_number": 3133,
        "file_name": "privateca/delete_ca.go",
        "code_diff": "@@ -26,8 +26,8 @@\nimport (\n \n // Delete a Certificate Authority from the specified CA pool.\n // Before deletion, the CA must be disabled or staged and must not contain any active certificates.\n-func deleteCa(w io.Writer, projectID string, location string, caPoolId string, caId string) error {\n-\t// projectID := \"your_project_id\"\n+func deleteCa(w io.Writer, projectId string, location string, caPoolId string, caId string) error {\n+\t// projectId := \"your_project_id\"\n \t// location := \"us-central1\"\t// For a list of locations, see: https://cloud.google.com/certificate-authority-service/docs/locations.\n \t// caPoolId := \"ca-pool-id\"\t\t// The id of the CA pool under which the CA is present.\n \t// caId := \"ca-id\"\t\t\t\t// The id of the CA to be deleted.",
        "comments": [],
        "commit_messages": [
            "feat(fixit): Listing CAs sample + projectId name fixes"
        ],
        "last_commit_sha": "3b0d266eab461c50f4a204fe469002385c343be7"
    },
    {
        "pr_title": "feat(fixit): Listing CAs sample + projectId name fixes",
        "pr_number": 3133,
        "file_name": "privateca/delete_ca_pool.go",
        "code_diff": "@@ -26,8 +26,8 @@\nimport (\n \n // Delete the CA pool as mentioned by the ca_pool_name.\n // Before deleting the pool, all CAs in the pool MUST BE deleted.\n-func deleteCaPool(w io.Writer, projectID string, location string, caPoolId string) error {\n-\t// projectID := \"your_project_id\"\n+func deleteCaPool(w io.Writer, projectId string, location string, caPoolId string) error {\n+\t// projectId := \"your_project_id\"\n \t// location := \"us-central1\"\t// For a list of locations, see: https://cloud.google.com/certificate-authority-service/docs/locations.\n \t// caPoolId := \"ca-pool-id\"\t\t// A unique id/name for the ca pool.",
        "comments": [],
        "commit_messages": [
            "feat(fixit): Listing CAs sample + projectId name fixes"
        ],
        "last_commit_sha": "3b0d266eab461c50f4a204fe469002385c343be7"
    },
    {
        "pr_title": "feat(fixit): Listing CAs sample + projectId name fixes",
        "pr_number": 3133,
        "file_name": "privateca/disable_ca.go",
        "code_diff": "@@ -25,8 +25,8 @@\nimport (\n )\n \n // Disable a Certificate Authority from the specified CA pool.\n-func disableCa(w io.Writer, projectID string, location string, caPoolId string, caId string) error {\n-\t// projectID := \"your_project_id\"\n+func disableCa(w io.Writer, projectId string, location string, caPoolId string, caId string) error {\n+\t// projectId := \"your_project_id\"\n \t// location := \"us-central1\"\t// For a list of locations, see: https://cloud.google.com/certificate-authority-service/docs/locations.\n \t// caPoolId := \"ca-pool-id\"\t\t// The id of the CA pool under which the CA is present.\n \t// caId := \"ca-id\"\t\t\t\t// The id of the CA to be disabled.",
        "comments": [],
        "commit_messages": [
            "feat(fixit): Listing CAs sample + projectId name fixes"
        ],
        "last_commit_sha": "3b0d266eab461c50f4a204fe469002385c343be7"
    },
    {
        "pr_title": "feat(fixit): Listing CAs sample + projectId name fixes",
        "pr_number": 3133,
        "file_name": "privateca/enable_ca.go",
        "code_diff": "@@ -26,8 +26,8 @@\nimport (\n \n // Enable the Certificate Authority present in the given ca pool.\n // CA cannot be enabled if it has been already deleted.\n-func enableCa(w io.Writer, projectID string, location string, caPoolId string, caId string) error {\n-\t// projectID := \"your_project_id\"\n+func enableCa(w io.Writer, projectId string, location string, caPoolId string, caId string) error {\n+\t// projectId := \"your_project_id\"\n \t// location := \"us-central1\"\t// For a list of locations, see: https://cloud.google.com/certificate-authority-service/docs/locations.\n \t// caPoolId := \"ca-pool-id\"\t\t// The id of the CA pool under which the CA is present.\n \t// caId := \"ca-id\"\t\t\t\t// The id of the CA to be enabled.",
        "comments": [],
        "commit_messages": [
            "feat(fixit): Listing CAs sample + projectId name fixes"
        ],
        "last_commit_sha": "3b0d266eab461c50f4a204fe469002385c343be7"
    },
    {
        "pr_title": "feat(fixit): Listing CAs sample + projectId name fixes",
        "pr_number": 3133,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -184,7 +184,7 @@\nfunc genPublicKey(t *testing.T) []byte {\n \treturn pem.EncodeToMemory(publicKeyBlock)\n }\n \n-func TestCreateCaPool(t *testing.T) {\n+func TestCaPools(t *testing.T) {\n \tsetupTests(t)\n \n \tt.Run(\"createCaPool\", func(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3b0d266eab461c50f4a204fe469002385c343be7"
    },
    {
        "pr_title": "feat(fixit): Listing CAs sample + projectId name fixes",
        "pr_number": 3133,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -221,7 +221,7 @@\nfunc TestCreateCaPool(t *testing.T) {\n \t})\n }\n \n-func TestCreateCa(t *testing.T) {\n+func TestCas(t *testing.T) {\n \tsetupTests(t)\n \tcaPoolId, teardownCaPool := setupCaPool(t)\n \tdefer teardownCaPool(t)",
        "comments": [],
        "commit_messages": [
            "feat(fixit): Listing CAs sample + projectId name fixes"
        ],
        "last_commit_sha": "3b0d266eab461c50f4a204fe469002385c343be7"
    },
    {
        "pr_title": "feat(fixit): Listing CAs sample + projectId name fixes",
        "pr_number": 3133,
        "file_name": "privateca/undelete_ca.go",
        "code_diff": "@@ -25,8 +25,8 @@\nimport (\n )\n \n // Undelete a Certificate Authority from the specified CA pool.\n-func unDeleteCa(w io.Writer, projectID string, location string, caPoolId string, caId string) error {\n-\t// projectID := \"your_project_id\"\n+func unDeleteCa(w io.Writer, projectId string, location string, caPoolId string, caId string) error {\n+\t// projectId := \"your_project_id\"\n \t// location := \"us-central1\"\t// For a list of locations, see: https://cloud.google.com/certificate-authority-service/docs/locations.\n \t// caPoolId := \"ca-pool-id\"\t\t// The id of the CA pool under which the CA is present.\n \t// caId := \"ca-id\"\t\t\t\t// The id of the CA to be undeleted.",
        "comments": [],
        "commit_messages": [
            "feat(fixit): Listing CAs sample + projectId name fixes"
        ],
        "last_commit_sha": "3b0d266eab461c50f4a204fe469002385c343be7"
    },
    {
        "pr_title": "feat(fixit): Adding CA samples for private CA",
        "pr_number": 3122,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -16,13 +16,16 @@\npackage snippets\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"errors\"\n \t\"fmt\"\n \t\"math/rand\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\tprivateca \"cloud.google.com/go/security/privateca/apiv1\"\n+\t\"cloud.google.com/go/security/privateca/apiv1/privatecapb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"google.golang.org/api/googleapi\"\n )",
        "comments": [],
        "commit_messages": [
            "feat(fixit): Adding ca related samples"
        ],
        "last_commit_sha": "6427c4e31276ff34c81742f325baa27b42678028"
    },
    {
        "pr_title": "feat(fixit): Adding CA samples for private CA",
        "pr_number": 3122,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -64,6 +67,63 @@\nfunc setupCaPool(t *testing.T) (string, func(t *testing.T)) {\n \t}\n }\n \n+// Setup and teardown functions for CaTests\n+func setupCa(t *testing.T, caPoolId string) (string, func(t *testing.T)) {\n+\tcaId := fmt.Sprintf(\"test-ca-%v-%v\", time.Now().Format(\"2006-01-02\"), r.Int())\n+\tcaCommonName := fmt.Sprintf(\"CN - %s\", caId)\n+\torg := \"ORGANIZATION\"\n+\tcaDuration := int64(2592000) // 30 days\n+\n+\tif err := createCa(&buf, projectId, location, caPoolId, caId, caCommonName, org, caDuration); err != nil {\n+\t\tt.Fatal(\"setupCa got err:\", err)\n+\t}\n+\n+\t// Return a function to teardown the test\n+\treturn caId, func(t *testing.T) {\n+\t\tif err := deleteCaPerm(projectId, location, caPoolId, caId); err != nil {\n+\t\t\tvar gerr *googleapi.Error\n+\t\t\tif errors.As(err, &gerr) {\n+\t\t\t\tif gerr.Code == 404 {\n+\t\t\t\t\tt.Log(\"setupCa teardown - skipped CA Pool deletion (not found)\")\n+\t\t\t\t} else {\n+\t\t\t\t\tt.Errorf(\"setupCa teardown got err: %v\", err)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+}\n+\n+// Helper function to permanently remove CAs without 30d grace period\n+func deleteCaPerm(projectID string, location string, caPoolId string, caId string) error {\n+\tctx := context.Background()\n+\tcaClient, err := privateca.NewCertificateAuthorityClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer caClient.Close()\n+\n+\tfullCaName := fmt.Sprintf(\"projects/%s/locations/%s/caPools/%s/certificateAuthorities/%s\",\n+\t\tprojectID, location, caPoolId, caId)\n+\n+\treq := &privatecapb.DeleteCertificateAuthorityRequest{\n+\t\tName:                     fullCaName,\n+\t\tIgnoreActiveCertificates: true,\n+\t\tIgnoreDependentResources: true,\n+\t\tSkipGracePeriod:          true,\n+\t}\n+\n+\top, err := caClient.DeleteCertificateAuthority(ctx, req)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif _, err = op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n func TestCreateCaPool(t *testing.T) {\n \tsetupTests(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6427c4e31276ff34c81742f325baa27b42678028"
    },
    {
        "pr_title": "feat(fixit): Adding CA samples for private CA",
        "pr_number": 3122,
        "file_name": "privateca/privateca_test.go",
        "code_diff": "@@ -81,7 +141,7 @@\nfunc TestCreateCaPool(t *testing.T) {\n \t\t}\n \n \t\tif err := deleteCaPool(&buf, projectId, location, caPoolId); err != nil {\n-\t\t\tt.Fatal(\"createCaPool teardown got err:\", err)\n+\t\t\tt.Fatal(\"createCaPool teardown (deleteCaPool) got err:\", err)\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "feat(fixit): Adding ca related samples"
        ],
        "last_commit_sha": "6427c4e31276ff34c81742f325baa27b42678028"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image listed info types",
        "pr_number": 3119,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -279,7 +279,6 @@\nfunc TestInspectBigquery(t *testing.T) {\n \n func TestInspectTable(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\n \tvar buf bytes.Buffer\n \tif err := inspectTable(&buf, tc.ProjectID); err != nil {\n \t\tt.Fatal(err)",
        "comments": [],
        "commit_messages": [
            "refactor code"
        ],
        "last_commit_sha": "cced9ac0d355be1f322c01d9c06b29f48e94cc38"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image listed info types",
        "pr_number": 3119,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -295,9 +294,7 @@\nfunc TestInspectTable(t *testing.T) {\n \n func TestInspectStringWithExclusionRegex(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\n \tvar buf bytes.Buffer\n-\n \tif err := inspectStringWithExclusionRegex(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, bob@example.org\", \".+@example.com\"); err != nil {\n \t\tt.Errorf(\"inspectStringWithExclusionRegex: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "refactor code"
        ],
        "last_commit_sha": "cced9ac0d355be1f322c01d9c06b29f48e94cc38"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image listed info types",
        "pr_number": 3119,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -338,7 +335,7 @@\nfunc TestInspectStringMultipleRules(t *testing.T) {\n \tvar buf bytes.Buffer\n \n \tif err := inspectStringMultipleRules(&buf, tc.ProjectID, \"patient: Jane Doe\"); err != nil {\n-\t\tt.Errorf(\"inspectStringMultipleRules: %v\", err)\n+\t\tt.Fatal(err)\n \t}\n \tgot := buf.String()\n \tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cced9ac0d355be1f322c01d9c06b29f48e94cc38"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image listed info types",
        "pr_number": 3119,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -484,7 +481,6 @@\nfunc TestInspectWithCustomRegex(t *testing.T) {\n func TestInspectStringWithExclusionDictionary(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n-\n \tif err := inspectStringWithExclusionDictionary(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, example@example.com\", []string{\"example@example.com\"}); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cced9ac0d355be1f322c01d9c06b29f48e94cc38"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp inspect image listed info types",
        "pr_number": 3119,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -496,15 +492,11 @@\nfunc TestInspectStringWithExclusionDictionary(t *testing.T) {\n \n func TestInspectImageFile(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\n \tvar buf bytes.Buffer\n-\n \tpathToImage := \"testdata/test.png\"\n-\n \tif err := inspectImageFile(&buf, tc.ProjectID, pathToImage); err != nil {\n \t\tt.Fatal(err)\n \t}\n-\n \tgot := buf.String()\n \tif want := \"Info type: PHONE_NUMBER\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"TestInspectImageFile got %q, want %q\", got, want)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cced9ac0d355be1f322c01d9c06b29f48e94cc38"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp create job",
        "pr_number": 3096,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -19,14 +19,18 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n+\t\"log\"\n \t\"regexp\"\n \t\"strings\"\n \t\"testing\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/dlp/apiv2/dlppb\"\n \t\"cloud.google.com/go/pubsub\"\n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/gofrs/uuid\"\n )\n \n // setupPubSub creates a subscription to the given topic.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "a6dafeb83b6c4fffc0e998ce12bfe084bc3835ab"
    },
    {
        "pr_title": "feat(dlp): added a sample for dlp create job",
        "pr_number": 3096,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -182,6 +186,132 @@\nfunc TestDeleteJob(t *testing.T) {\n \t}\n }\n \n+func TestCreateJob(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tvar buf bytes.Buffer\n+\t// createBucketForCreatJob will create a bucket and upload a txt file\n+\tbucketName, fileName, err := createBucketForCreatJob(t, tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tgcsPath := \"gs://\" + bucketName + \"/\" + fileName\n+\tinfoTypeNames := []string{\"EMAIL_ADDRESS\", \"PERSON_NAME\", \"LOCATION\", \"PHONE_NUMBER\"}\n+\n+\tif err := createJob(&buf, tc.ProjectID, gcsPath, infoTypeNames); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"Created a Dlp Job \"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"TestInspectWithCustomRegex got %q, want %q\", got, want)\n+\t}\n+\n+\tdefer deleteAssetsOfCreateJobTest(t, tc.ProjectID, bucketName, fileName)\n+}\n+\n+func createBucketForCreatJob(t *testing.T, projectID string) (string, string, error) {\n+\tt.Helper()\n+\n+\tctx := context.Background()\n+\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn \"\", \"\", err\n+\t}\n+\tdefer client.Close()\n+\tu := uuid.Must(uuid.NewV4()).String()[:8]\n+\tbucketName := \"dlp-job-go-lang-test\" + u\n+\n+\t// Check if the bucket already exists.\n+\tbucketExists := false\n+\t_, err = client.Bucket(bucketName).Attrs(ctx)\n+\tif err == nil {\n+\t\tbucketExists = true\n+\t}\n+\n+\t// If the bucket doesn't exist, create it.\n+\tif !bucketExists {\n+\t\tif err := client.Bucket(bucketName).Create(ctx, projectID, &storage.BucketAttrs{\n+\t\t\tStorageClass: \"STANDARD\",\n+\t\t\tLocation:     \"us-central1\",\n+\t\t}); err != nil {\n+\t\t\tlog.Fatalf(\"---Failed to create bucket: %v\", err)\n+\t\t}\n+\t\tfmt.Printf(\"---Bucket '%s' created successfully.\\n\", bucketName)\n+\t} else {\n+\t\tfmt.Printf(\"---Bucket '%s' already exists.\\n\", bucketName)\n+\t}\n+\n+\tfilePathToUpload := \"testdata/test.txt\"\n+\n+\t// Open local file.\n+\tfile, err := ioutil.ReadFile(filePathToUpload)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"Failed to read file: %v\", err)\n+\t}\n+\n+\t// Get a reference to the bucket\n+\tbucket := client.Bucket(bucketName)\n+\n+\t// Upload the file\n+\tu = uuid.Must(uuid.NewV4()).String()[:8]\n+\tfileName := \"test\" + u + \".txt\"\n+\tobject := bucket.Object(fileName)\n+\twriter := object.NewWriter(ctx)\n+\t_, err = writer.Write(file)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"---Failed to write file: %v\", err)\n+\t}\n+\terr = writer.Close()\n+\tif err != nil {\n+\t\tlog.Fatalf(\"---Failed to close writer: %v\", err)\n+\t}\n+\tfmt.Printf(\"---File uploaded successfully: %v\\n\", fileName)\n+\n+\t// Check if the file exists in the bucket\n+\t_, err = bucket.Object(fileName).Attrs(ctx)\n+\tif err != nil {\n+\t\tif err == storage.ErrObjectNotExist {\n+\t\t\tfmt.Printf(\"---File %v does not exist in bucket %v\\n\", fileName, bucketName)\n+\t\t} else {\n+\t\t\tlog.Fatalf(\"---Failed to check file existence: %v\", err)\n+\t\t}\n+\t} else {\n+\t\tfmt.Printf(\"---File %v exists in bucket %v\\n\", fileName, bucketName)\n+\t}\n+\n+\treturn bucketName, fileName, nil\n+}\n+\n+func deleteAssetsOfCreateJobTest(t *testing.T, projectID, bucketName, objectName string) error {\n+\tt.Helper()\n+\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\to := client.Bucket(bucketName).Object(objectName)\n+\tattrs, err := o.Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\to = o.If(storage.Conditions{GenerationMatch: attrs.Generation})\n+\n+\tif err := o.Delete(ctx); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tbucket := client.Bucket(bucketName)\n+\tif err := bucket.Delete(ctx); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\treturn nil\n+}\n+\n func TestJobsGet(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "a6dafeb83b6c4fffc0e998ce12bfe084bc3835ab"
    },
    {
        "pr_title": "feat(spanner): add bit reversed sequence samples",
        "pr_number": 3092,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -387,6 +387,17 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"Updated data to VenueDetails column\\n\")\n \tout = runSample(t, queryWithJsonParameter, dbName, \"failed to query with json parameter\")\n \tassertContains(t, out, \"The venue details for venue id 19\")\n+\n+\tout = runSample(t, createSequence, dbName, \"failed to create table with bit reverse sequence enabled\")\n+\tassertContains(t, out, \"Created Seq sequence and Customers table, where the key column CustomerId uses the sequence as a default value\\n\")\n+\tassertContains(t, out, \"Inserted customer record with CustomerId\")\n+\tassertContains(t, out, \"Number of customer records inserted is: 3\")\n+\tout = runSample(t, alterSequence, dbName, \"failed to alter table with bit reverse sequence enabled\")\n+\tassertContains(t, out, \"Altered Seq sequence to skip an inclusive range between 1000 and 5000000\\n\")\n+\tassertContains(t, out, \"Inserted customer record with CustomerId\")\n+\tassertContains(t, out, \"Number of customer records inserted is: 3\")\n+\tout = runSample(t, dropSequence, dbName, \"failed to drop bit reverse sequence column\")\n+\tassertContains(t, out, \"Altered Customers table to drop DEFAULT from CustomerId column and dropped the Seq sequence\\n\")\n }\n \n func TestBackupSample(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "571229884168206e640700523c3ee03895eea703"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -17,15 +17,17 @@\npackage snippets\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"errors\"\n \t\"fmt\"\n \t\"math/rand\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \tcompute \"cloud.google.com/go/compute/apiv1\"\n+\tcomputepb \"cloud.google.com/go/compute/apiv1/computepb\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\tcomputepb \"google.golang.org/genproto/googleapis/cloud/compute/v1\"\n+\t\"google.golang.org/api/googleapi\"\n \t\"google.golang.org/protobuf/proto\"\n )",
        "comments": [],
        "commit_messages": [
            "fix: issue 2929"
        ],
        "last_commit_sha": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -132,12 +134,35 @@\nfunc deleteDiskSnapshot(ctx context.Context, projectId, snapshotName string) err\n \treturn op.Wait(ctx)\n }\n \n-func deleteInstance(ctx context.Context, projectId, zone, instanceName string) error {\n+func deleteInstance(t *testing.T, ctx context.Context, projectId, zone, instanceName string) {\n+\tt.Helper()\n \tinstancesClient, err := compute.NewInstancesRESTClient(ctx)\n \tif err != nil {\n-\t\treturn err\n+\t\tt.Fatalf(\"NewInstancesRESTClient: %v\", err)\n \t}\n \tdefer instancesClient.Close()\n+\n+\t// Get the instance to set all disks to autodelte with intance\n+\tinstance, err := getInstance(ctx, projectId, zone, instanceName)\n+\tif err != nil {\n+\t\tt.Error(\"getInstance err\", err)\n+\t}\n+\n+\tfor _, disk := range instance.GetDisks() {\n+\t\treq := &computepb.SetDiskAutoDeleteInstanceRequest{\n+\t\t\tProject:    projectId,\n+\t\t\tZone:       zone,\n+\t\t\tInstance:   instanceName,\n+\t\t\tDeviceName: disk.GetDeviceName(),\n+\t\t\tAutoDelete: true,\n+\t\t}\n+\n+\t\t_, err := instancesClient.SetDiskAutoDelete(ctx, req)\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"unable to set disk autodelete field: %v\", err)\n+\t\t}\n+\t}\n+\n \treq := &computepb.DeleteInstanceRequest{\n \t\tProject:  projectId,\n \t\tZone:     zone,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -146,121 +171,125 @@\nfunc deleteInstance(ctx context.Context, projectId, zone, instanceName string) e\n \n \top, err := instancesClient.Delete(ctx, req)\n \tif err != nil {\n-\t\treturn err\n+\t\tt.Errorf(\"instanceClient.Delete: %v\", err)\n \t}\n \n-\treturn op.Wait(ctx)\n+\terr = op.Wait(ctx)\n+\tif err != nil {\n+\t\tt.Errorf(\"instanceClient.Delete: %v\", err)\n+\t}\n+}\n+\n+// Produces a test error only in case it was NOT due to a 404. This avoids\n+// flackyness which may result from the ripper cleaning up resources.\n+func errorIfNot404(t *testing.T, msg string, err error) {\n+\tvar gerr *googleapi.Error\n+\tif errors.As(err, &gerr) {\n+\t\tt.Log(gerr.Message, \" - \", gerr.Code)\n+\t\tif gerr.Code == 404 {\n+\t\t\tt.Skip(msg + \" skipped due to a Not Found error (404)\")\n+\t\t} else {\n+\t\t\tt.Errorf(msg+\" got err: %v\", err)\n+\t\t}\n+\t}\n }\n \n func TestComputeDisksSnippets(t *testing.T) {\n-\tt.Skip(\"skipping for flakes. see googlecloudplatform/golang-samples#2929\")\n \tctx := context.Background()\n \tvar r *rand.Rand = rand.New(\n \t\trand.NewSource(time.Now().UnixNano()))\n \ttc := testutil.SystemTest(t)\n-\tzone := \"europe-central2-b\"\n-\tregion := \"europe-central2\"\n-\treplicaZones := []string{\"europe-central2-a\", \"europe-central2-b\"}\n+\tzone := \"europe-west2-b\"\n+\tregion := \"europe-west2\"\n+\treplicaZones := []string{\"europe-west2-a\", \"europe-west2-b\"}\n \tinstanceName := fmt.Sprintf(\"test-instance-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tdiskName := fmt.Sprintf(\"test-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n-\tdiskName2 := fmt.Sprintf(\"test-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tinstanceDiskName := fmt.Sprintf(\"test-instance-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n-\tinstanceDiskName2 := fmt.Sprintf(\"test-instance-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n-\tinstanceDiskName3 := fmt.Sprintf(\"test-instance-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tsnapshotName := fmt.Sprintf(\"test-snapshot-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tsourceImage := \"projects/debian-cloud/global/images/family/debian-11\"\n-\tsourceDisk := fmt.Sprintf(\"projects/%s/zones/europe-central2-b/disks/%s\", tc.ProjectID, diskName)\n \tdiskType := fmt.Sprintf(\"zones/%s/diskTypes/pd-ssd\", zone)\n \tdiskSnapshotLink := fmt.Sprintf(\"projects/%s/global/snapshots/%s\", tc.ProjectID, snapshotName)\n \n \tinstancesClient, err := compute.NewInstancesRESTClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"NewInstancesRESTClient: %v\", err)\n \t}\n-\n \tdefer instancesClient.Close()\n \n \t// Create a snapshot before we run the actual tests\n-\tbuf := &bytes.Buffer{}\n-\terr = createDiskFromImage(buf, tc.ProjectID, zone, diskName, diskType, sourceImage, 50)\n+\tvar buf bytes.Buffer\n+\terr = createDiskFromImage(&buf, tc.ProjectID, zone, diskName, diskType, sourceImage, 50)\n \tif err != nil {\n \t\tt.Fatalf(\"createDiskFromImage got err: %v\", err)\n \t}\n+\tdefer deleteDisk(&buf, tc.ProjectID, zone, diskName)\n+\n \terr = createDiskSnapshot(ctx, tc.ProjectID, zone, diskName, snapshotName)\n \tif err != nil {\n \t\tt.Fatalf(\"createDiskSnapshot got err: %v\", err)\n \t}\n+\tdefer deleteDiskSnapshot(ctx, tc.ProjectID, snapshotName)\n+\n \t// Create a VM instance to attach disks to\n-\tcreateInstance(ctx, tc.ProjectID, zone, instanceName, sourceImage, instanceDiskName)\n+\terr = createInstance(ctx, tc.ProjectID, zone, instanceName, sourceImage, instanceDiskName)\n \tif err != nil {\n \t\tt.Fatalf(\"unable to create instance: %v\", err)\n \t}\n+\tdefer deleteInstance(t, ctx, tc.ProjectID, zone, instanceName)\n \n-\tt.Run(\"Create zonal disk from a snapshot\", func(t *testing.T) {\n-\t\tbuf := &bytes.Buffer{}\n+\tt.Run(\"Create and delete zonal disk from a snapshot\", func(t *testing.T) {\n+\t\tzonalDiskName := fmt.Sprintf(\"test-zonal-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\t\tvar buf bytes.Buffer\n \t\twant := \"Disk created\"\n \n-\t\tif err := createDiskFromSnapshot(buf, tc.ProjectID, zone, diskName2, diskType, diskSnapshotLink, 50); err != nil {\n+\t\tif err := createDiskFromSnapshot(&buf, tc.ProjectID, zone, zonalDiskName, diskType, diskSnapshotLink, 50); err != nil {\n \t\t\tt.Errorf(\"createDiskFromSnapshot got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createDiskFromSnapshot got %q, want %q\", got, want)\n \t\t}\n-\t})\n \n-\tt.Run(\"Delete a disk\", func(t *testing.T) {\n-\t\tbuf := &bytes.Buffer{}\n-\t\twant := \"Disk deleted\"\n+\t\tbuf.Reset()\n+\t\twant = \"Disk deleted\"\n \n-\t\tif err := deleteDisk(buf, tc.ProjectID, zone, diskName2); err != nil {\n-\t\t\tt.Errorf(\"deleteDisk got err: %v\", err)\n+\t\tif err := deleteDisk(&buf, tc.ProjectID, zone, zonalDiskName); err != nil {\n+\t\t\terrorIfNot404(t, \"deleteDisk\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"deleteDisk got %q, want %q\", got, want)\n \t\t}\n \t})\n \n-\tt.Run(\"Create a regional disk from a snapshot\", func(t *testing.T) {\n-\t\tbuf := &bytes.Buffer{}\n+\tt.Run(\"Create and delete a regional disk from a snapshot\", func(t *testing.T) {\n+\t\tregionalDiskName := fmt.Sprintf(\"test-regional-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\t\tvar buf bytes.Buffer\n \t\twant := \"Disk created\"\n \n-\t\tif err := createRegionalDiskFromSnapshot(buf, tc.ProjectID, region, replicaZones, diskName2, diskType, diskSnapshotLink, 50); err != nil {\n+\t\tif err := createRegionalDiskFromSnapshot(&buf, tc.ProjectID, region, replicaZones, regionalDiskName, diskType, diskSnapshotLink, 50); err != nil {\n \t\t\tt.Errorf(\"createRegionalDiskFromSnapshot got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createRegionalDiskFromSnapshot got %q, want %q\", got, want)\n \t\t}\n-\t})\n-\n-\tt.Run(\"Delete a zonal disk\", func(t *testing.T) {\n-\t\tbuf := &bytes.Buffer{}\n-\t\twant := \"Disk deleted\"\n-\t\tif err := deleteDisk(buf, tc.ProjectID, zone, diskName); err != nil {\n-\t\t\tt.Errorf(\"deleteDisk got err: %v\", err)\n-\t\t}\n-\t\tif got := buf.String(); !strings.Contains(got, want) {\n-\t\t\tt.Errorf(\"deleteRegionalDisk got %q, want %q\", got, want)\n-\t\t}\n-\t})\n \n-\tt.Run(\"Delete a regional disk\", func(t *testing.T) {\n-\t\tbuf := &bytes.Buffer{}\n-\t\twant := \"Disk deleted\"\n+\t\tbuf.Reset()\n+\t\twant = \"Disk deleted\"\n \n-\t\terr = deleteRegionalDisk(buf, tc.ProjectID, region, diskName2)\n+\t\terr = deleteRegionalDisk(&buf, tc.ProjectID, region, regionalDiskName)\n \t\tif err != nil {\n-\t\t\tt.Errorf(\"deleteRegionalDisk got err: %v\", err)\n+\t\t\terrorIfNot404(t, \"deleteRegionalDisk\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"deleteRegionalDisk got %q, want %q\", got, want)\n \t\t}\n \t})\n \n \tt.Run(\"Create and resize a regional disk\", func(t *testing.T) {\n-\t\tbuf := &bytes.Buffer{}\n+\t\tregionalDiskName := fmt.Sprintf(\"test-regional-resize-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\t\tvar buf bytes.Buffer\n \t\twant := \"Disk created\"\n \n-\t\tif err := createRegionalDisk(buf, tc.ProjectID, region, replicaZones, diskName2, diskType, 20); err != nil {\n+\t\tif err := createRegionalDisk(&buf, tc.ProjectID, region, replicaZones, regionalDiskName, diskType, 20); err != nil {\n \t\t\tt.Errorf(\"createRegionalDisk got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -270,7 +299,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\tbuf.Reset()\n \t\twant = \"Disk resized\"\n \n-\t\tresizeRegionalDisk(buf, tc.ProjectID, region, diskName2, 50)\n+\t\tresizeRegionalDisk(&buf, tc.ProjectID, region, regionalDiskName, 50)\n \t\tif err != nil {\n \t\t\tt.Errorf(\"resizeRegionalDisk got err: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -282,72 +311,69 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\twant = \"Disk deleted\"\n \n \t\t// clean up\n-\t\terr = deleteRegionalDisk(buf, tc.ProjectID, region, diskName2)\n+\t\terr = deleteRegionalDisk(&buf, tc.ProjectID, region, regionalDiskName)\n \t\tif err != nil {\n-\t\t\tt.Errorf(\"deleteRegionalDisk got err: %v\", err)\n+\t\t\terrorIfNot404(t, \"deleteRegionalDisk\", err)\n \t\t}\n \t})\n \n \tt.Run(\"createEmptyDisk and clone it into a regional disk\", func(t *testing.T) {\n-\t\tbuf := &bytes.Buffer{}\n+\t\tzonalDiskName := fmt.Sprintf(\"test-zonal-clone-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\t\tsourceDisk := fmt.Sprintf(\"projects/%s/zones/europe-west2-b/disks/%s\", tc.ProjectID, zonalDiskName)\n+\t\tregionalDiskName := fmt.Sprintf(\"test-regional-clone-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\t\tvar buf bytes.Buffer\n \t\twant := \"Disk created\"\n \n-\t\tif err := createEmptyDisk(buf, tc.ProjectID, zone, diskName, diskType, 20); err != nil {\n+\t\tif err := createEmptyDisk(&buf, tc.ProjectID, zone, zonalDiskName, diskType, 20); err != nil {\n \t\t\tt.Fatalf(\"createEmptyDisk got err: %v\", err)\n \t\t}\n+\t\tdefer deleteDisk(&buf, tc.ProjectID, zone, zonalDiskName)\n+\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createEmptyDisk got %q, want %q\", got, want)\n \t\t}\n \n-\t\tif err := createRegionalDiskFromDisk(buf, tc.ProjectID, region, replicaZones, diskName2, diskType, sourceDisk, 30); err != nil {\n-\t\t\tt.Errorf(\"createRegionalDiskFromDisk got err: %v\", err)\n+\t\tif err := createRegionalDiskFromDisk(&buf, tc.ProjectID, region, replicaZones, regionalDiskName, diskType, sourceDisk, 30); err != nil {\n+\t\t\tt.Fatalf(\"createRegionalDiskFromDisk got err: %v\", err)\n \t\t}\n+\t\tdefer deleteRegionalDisk(&buf, tc.ProjectID, region, regionalDiskName)\n+\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createRegionalDiskFromDisk got %q, want %q\", got, want)\n \t\t}\n-\n-\t\t// clean up\n-\t\terr = deleteRegionalDisk(buf, tc.ProjectID, region, diskName2)\n-\t\tif err != nil {\n-\t\t\tt.Errorf(\"deleteRegionalDisk got err: %v\", err)\n-\t\t}\n-\n-\t\terr = deleteDisk(buf, tc.ProjectID, zone, diskName)\n-\t\tif err != nil {\n-\t\t\tt.Errorf(\"deleteDisk got err: %v\", err)\n-\t\t}\n \t})\n \n \tt.Run(\"create, clone and delete an encrypted disk\", func(t *testing.T) {\n-\t\tbuf.Reset()\n+\t\tencDiskName1 := fmt.Sprintf(\"test-enc-disk1-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\t\tsourceDisk := fmt.Sprintf(\"projects/%s/zones/europe-west2-b/disks/%s\", tc.ProjectID, encDiskName1)\n+\t\tencDiskName2 := fmt.Sprintf(\"test-enc-disk2-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\t\tvar buf bytes.Buffer\n \t\twant := \"Disk created\"\n \n-\t\tif err := createEncryptedDisk(buf, tc.ProjectID, zone, diskName, diskType, 20, \"SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=\", \"\", \"\", \"\"); err != nil {\n+\t\tif err := createEncryptedDisk(&buf, tc.ProjectID, zone, encDiskName1, diskType, 20, \"SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=\", \"\", \"\", \"\"); err != nil {\n \t\t\tt.Fatalf(\"createEncryptedDisk got err: %v\", err)\n \t\t}\n+\t\tdefer deleteDisk(&buf, tc.ProjectID, zone, encDiskName1)\n+\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createEncryptedDisk got %q, want %q\", got, want)\n \t\t}\n \n-\t\tif err := createDiskFromCustomerEncryptedDisk(buf, tc.ProjectID, zone, diskName2, diskType, 20, sourceDisk, \"SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=\"); err != nil {\n+\t\tif err := createDiskFromCustomerEncryptedDisk(&buf, tc.ProjectID, zone, encDiskName2, diskType, 20, sourceDisk, \"SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=\"); err != nil {\n \t\t\tt.Fatalf(\"createDiskFromCustomerEncryptedDisk got err: %v\", err)\n \t\t}\n+\t\tdefer deleteDisk(&buf, tc.ProjectID, zone, encDiskName2)\n+\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createDiskFromCustomerEncryptedDisk got %q, want %q\", got, want)\n \t\t}\n-\n-\t\t// cleanup\n-\t\terr = deleteDisk(buf, tc.ProjectID, zone, diskName)\n-\t\tif err != nil {\n-\t\t\tt.Errorf(\"deleteDisk got err: %v\", err)\n-\t\t}\n \t})\n \n \tt.Run(\"setDiskAutoDelete\", func(t *testing.T) {\n \t\tbuf.Reset()\n \t\twant := \"disk autoDelete field updated.\"\n \n-\t\tif err := setDiskAutoDelete(buf, tc.ProjectID, zone, instanceName, instanceDiskName, true); err != nil {\n+\t\tif err := setDiskAutoDelete(&buf, tc.ProjectID, zone, instanceName, instanceDiskName, true); err != nil {\n \t\t\tt.Fatalf(\"setDiskAutodelete got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -365,16 +391,18 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t})\n \n \tt.Run(\"Attach a regional disk to VM\", func(t *testing.T) {\n-\t\tif err := createRegionalDisk(buf, tc.ProjectID, region, replicaZones, instanceDiskName2, \"regions/us-west3/diskTypes/pd-ssd\", 20); err != nil {\n+\t\tinstanceRegionalDiskName := fmt.Sprintf(\"test-attach-rw-instance-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\n+\t\tif err := createRegionalDisk(&buf, tc.ProjectID, region, replicaZones, instanceRegionalDiskName, \"regions/us-west3/diskTypes/pd-ssd\", 20); err != nil {\n \t\t\tt.Fatalf(\"createRegionalDisk got err: %v\", err)\n \t\t}\n \n \t\tbuf.Reset()\n \t\twant := \"Disk attached\"\n \n-\t\tdiskUrl := fmt.Sprintf(\"projects/%s/regions/%s/disks/%s\", tc.ProjectID, region, instanceDiskName2)\n+\t\tdiskUrl := fmt.Sprintf(\"projects/%s/regions/%s/disks/%s\", tc.ProjectID, region, instanceRegionalDiskName)\n \n-\t\tif err := attachRegionalDisk(buf, tc.ProjectID, zone, instanceName, diskUrl); err != nil {\n+\t\tif err := attachRegionalDisk(&buf, tc.ProjectID, zone, instanceName, diskUrl); err != nil {\n \t\t\tt.Fatalf(\"attachRegionalDisk got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "fix(compute/disks): don't fail tests in case of not found disks during deletion",
        "pr_number": 3026,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -388,28 +416,31 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \n \t\tfoundDisk := false\n \t\tfor _, disk := range instance.GetDisks() {\n-\t\t\tif strings.Contains(*disk.Source, instanceDiskName2) {\n+\t\t\tif strings.Contains(*disk.Source, instanceRegionalDiskName) {\n \t\t\t\tfoundDisk = true\n \t\t\t}\n \t\t}\n \t\tif !foundDisk {\n-\t\t\tt.Errorf(\"The disk %s is not attached to the instance!\", instanceDiskName2)\n+\t\t\tt.Errorf(\"The disk %s is not attached to the instance!\", instanceRegionalDiskName)\n \t\t}\n \n-\t\t// cannot clean up the disk just yet because it must be done after the VM is terminated\n+\t\t// Cannot clean up the disk just yet because it must be done after the VM is terminated.\n+\t\t// It will be done by deleteInstance function.\n \t})\n \n \tt.Run(\"Attach a read-only regional disk to VM\", func(t *testing.T) {\n-\t\tif err := createRegionalDisk(buf, tc.ProjectID, region, replicaZones, instanceDiskName3, \"regions/us-west3/diskTypes/pd-ssd\", 20); err != nil {\n+\t\tinstanceRegionalDiskName := fmt.Sprintf(\"test-attach-ro-instance-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\n+\t\tif err := createRegionalDisk(&buf, tc.ProjectID, region, replicaZones, instanceRegionalDiskName, \"regions/us-west3/diskTypes/pd-ssd\", 20); err != nil {\n \t\t\tt.Fatalf(\"createRegionalDisk got err: %v\", err)\n \t\t}\n \n \t\tbuf.Reset()\n \t\twant := \"Disk attached\"\n \n-\t\tdiskUrl := fmt.Sprintf(\"projects/%s/regions/%s/disks/%s\", tc.ProjectID, region, instanceDiskName3)\n+\t\tdiskUrl := fmt.Sprintf(\"projects/%s/regions/%s/disks/%s\", tc.ProjectID, region, instanceRegionalDiskName)\n \n-\t\tif err := attachRegionalDiskReadOnly(buf, tc.ProjectID, zone, instanceName, diskUrl); err != nil {\n+\t\tif err := attachRegionalDiskReadOnly(&buf, tc.ProjectID, zone, instanceName, diskUrl); err != nil {\n \t\t\tt.Fatalf(\"attachRegionalDisk got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d10dcf86006b5c5f9580290abef3f46d4fb71987"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -277,6 +277,27 @@\nfunc TestInspectBigquery(t *testing.T) {\n \t}\n }\n \n+func TestInspectStringCustomExcludingSubstring(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tvar buf bytes.Buffer\n+\n+\tif err := inspectStringCustomExcludingSubstring(&buf, tc.ProjectID, \"Name: Doe, John. Name: Example, Jimmy\", \"[A-Z][a-z]{1,15}, [A-Z][a-z]{1,15}\", []string{\"Jimmy\"}); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\n+\tif want := \"Infotype Name: CUSTOM_NAME_DETECTOR\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringCustomExcludingSubstring got %q, want %q\", got, want)\n+\t}\n+\tif want := \"Quote: Doe, John\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringCustomExcludingSubstring got %q, want %q\", got, want)\n+\t}\n+\tif want := \"Jimmy\"; strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringCustomExcludingSubstring got %q, want %q\", got, want)\n+\t}\n+}\n+\n func TestInspectStringMultipleRules(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom excluding substring",
        "pr_number": 3012,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -294,7 +315,7 @@\nfunc TestInspectWithHotWordRules(t *testing.T) {\n \tvar buf bytes.Buffer\n \n \tif err := inspectWithHotWordRules(&buf, tc.ProjectID, \"Patient's MRN 444-5-22222 and just a number 333-2-33333\"); err != nil {\n-\t\tt.Errorf(\"inspectWithHotWordRules: %v\", err)\n+\t\tt.Fatal(err)\n \t}\n \n \tgot := buf.String()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d8776df0cfc85c2a6f9a0e46c67a1f537a999cec"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with multiple rules",
        "pr_number": 3011,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -277,11 +277,23 @@\nfunc TestInspectBigquery(t *testing.T) {\n \t}\n }\n \n+func TestInspectStringMultipleRules(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tvar buf bytes.Buffer\n+\n+\tif err := inspectStringMultipleRules(&buf, tc.ProjectID, \"patient: Jane Doe\"); err != nil {\n+\t\tt.Errorf(\"inspectStringMultipleRules: %v\", err)\n+\t}\n+\tgot := buf.String()\n+\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringMultipleRules got %q, want %q\", got, want)\n+\t}\n+}\n func TestInspectWithHotWordRules(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \n-\tif err := inspectWithHotWordRules(buf, tc.ProjectID, \"Patient's MRN 444-5-22222 and just a number 333-2-33333\"); err != nil {\n+\tif err := inspectWithHotWordRules(&buf, tc.ProjectID, \"Patient's MRN 444-5-22222 and just a number 333-2-33333\"); err != nil {\n \t\tt.Errorf(\"inspectWithHotWordRules: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "36007b41fb4759c3c1f0f64f1abcca31a057302f"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with multiple rules",
        "pr_number": 3011,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -296,9 +308,9 @@\nfunc TestInspectWithHotWordRules(t *testing.T) {\n \n func TestInspectPhoneNumber(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \n-\tif err := inspectPhoneNumber(buf, tc.ProjectID, \"I'm Gary and my phone number is (415) 555-0890\"); err != nil {\n+\tif err := inspectPhoneNumber(&buf, tc.ProjectID, \"I'm Gary and my phone number is (415) 555-0890\"); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "36007b41fb4759c3c1f0f64f1abcca31a057302f"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with multiple rules",
        "pr_number": 3011,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -310,9 +322,9 @@\nfunc TestInspectPhoneNumber(t *testing.T) {\n \n func TestInspectStringWithoutOverlap(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \n-\tif err := inspectStringWithoutOverlap(buf, tc.ProjectID, \"example.com is a domain, james@example.org is an email.\"); err != nil {\n+\tif err := inspectStringWithoutOverlap(&buf, tc.ProjectID, \"example.com is a domain, james@example.org is an email.\"); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "36007b41fb4759c3c1f0f64f1abcca31a057302f"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with multiple rules",
        "pr_number": 3011,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -330,9 +342,9 @@\nfunc TestInspectStringWithoutOverlap(t *testing.T) {\n \n func TestInspectStringCustomHotWord(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \n-\tif err := inspectStringCustomHotWord(buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n+\tif err := inspectStringCustomHotWord(&buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n \t\tt.Fatal(err)\n \t}\n \tgot := buf.String()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "36007b41fb4759c3c1f0f64f1abcca31a057302f"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with multiple rules",
        "pr_number": 3011,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -343,9 +355,9 @@\nfunc TestInspectStringCustomHotWord(t *testing.T) {\n \n func TestInspectStringWithExclusionDictSubstring(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \n-\tif err := inspectStringWithExclusionDictSubstring(buf, tc.ProjectID, \"Some email addresses: gary@example.com, TEST@example.com\", []string{\"TEST\"}); err != nil {\n+\tif err := inspectStringWithExclusionDictSubstring(&buf, tc.ProjectID, \"Some email addresses: gary@example.com, TEST@example.com\", []string{\"TEST\"}); err != nil {\n \t\tt.Fatal(err)\n \t}\n \tgot := buf.String()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "36007b41fb4759c3c1f0f64f1abcca31a057302f"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with multiple rules",
        "pr_number": 3011,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -363,9 +375,9 @@\nfunc TestInspectStringWithExclusionDictSubstring(t *testing.T) {\n \n func TestInspectStringOmitOverlap(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \n-\tif err := inspectStringOmitOverlap(buf, tc.ProjectID, \"gary@example.com\"); err != nil {\n+\tif err := inspectStringOmitOverlap(&buf, tc.ProjectID, \"gary@example.com\"); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "36007b41fb4759c3c1f0f64f1abcca31a057302f"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table infotypes",
        "pr_number": 3001,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -103,6 +103,36 @@\nfunc TestDeidentifyDateShift(t *testing.T) {\n \t}\n }\n \n+func TestDeidentifyTableInfoTypes(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tvar buf bytes.Buffer\n+\n+\tif err := deidentifyTableInfotypes(&buf, tc.ProjectID); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"Table after de-identification\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n+\t}\n+\n+\tif want := \"[PERSON_NAME]\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n+\t}\n+\n+\tif want := \"Charles Dickens\"; strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n+\t}\n+\tif want := \"Mark Twain\"; strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n+\t}\n+\tif want := \"Jane Austen\"; strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyTableInfotypes got %q, want %q\", got, want)\n+\t}\n+\n+}\n+\n func TestDeIdentifyWithRedact(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "158775728490b004d9b03cbce19fcd8da1b4cc33"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table condition masking",
        "pr_number": 3000,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -111,8 +111,8 @@\nfunc TestDeIdentifyWithRedact(t *testing.T) {\n \twant := \"output: My name is Alicia Abernathy, and my email address is .\"\n \n \tvar buf bytes.Buffer\n-\terr := deidentifyWithRedact(&buf, tc.ProjectID, input, infoTypeNames)\n-\tif err != nil {\n+\n+\tif err := deidentifyWithRedact(&buf, tc.ProjectID, input, infoTypeNames); err != nil {\n \t\tt.Errorf(\"deidentifyWithRedact(%q) = error '%q', want %q\", err, input, want)\n \t}\n \tif got := buf.String(); got != want {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1a365cc34703a2cfcafcb68150b9402889953553"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table condition masking",
        "pr_number": 3000,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -174,9 +174,23 @@\nfunc TestDeidentifyTableBucketing(t *testing.T) {\n \n }\n \n-func TestDeidentifyTableConditionInfoTypes(t *testing.T) {\n+func TestDeidentifyTableMaskingCondition(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n+\tvar buf bytes.Buffer\n+\tif err := deidentifyTableMaskingCondition(&buf, tc.ProjectID); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tgot := buf.String()\n+\tif want := \"Table after de-identification :\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyTableMaskingCondition got (%q) =%q \", got, want)\n+\t}\n+\tif want := \"values:{string_value:\\\"**\\\"}\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyTableMaskingCondition got (%q) =%q \", got, want)\n+\t}\n+}\n \n+func TestDeidentifyTableConditionInfoTypes(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n \tvar buf bytes.Buffer\n \n \tif err := deidentifyTableConditionInfoTypes(&buf, tc.ProjectID, []string{\"PATIENT\", \"FACTOID\"}); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1a365cc34703a2cfcafcb68150b9402889953553"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table conditions ",
        "pr_number": 2998,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -110,8 +110,8 @@\nfunc TestDeIdentifyWithRedact(t *testing.T) {\n \tinfoTypeNames := []string{\"EMAIL_ADDRESS\"}\n \twant := \"output: My name is Alicia Abernathy, and my email address is .\"\n \n-\tbuf := new(bytes.Buffer)\n-\terr := deidentifyWithRedact(buf, tc.ProjectID, input, infoTypeNames)\n+\tvar buf bytes.Buffer\n+\terr := deidentifyWithRedact(&buf, tc.ProjectID, input, infoTypeNames)\n \tif err != nil {\n \t\tt.Errorf(\"deidentifyWithRedact(%q) = error '%q', want %q\", err, input, want)\n \t}",
        "comments": [],
        "commit_messages": [
            "addressed review comments"
        ],
        "last_commit_sha": "6da03e176d154089128c0267585aecf0787b4f40"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table conditions ",
        "pr_number": 2998,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -126,9 +126,9 @@\nfunc TestDeidentifyExceptionList(t *testing.T) {\n \tinput := \"jack@example.org accessed customer record of user5@example.com\"\n \twant := \"output : jack@example.org accessed customer record of [EMAIL_ADDRESS]\"\n \n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \n-\tif err := deidentifyExceptionList(buf, tc.ProjectID, input); err != nil {\n+\tif err := deidentifyExceptionList(&buf, tc.ProjectID, input); err != nil {\n \t\tt.Errorf(\"deidentifyExceptionList(%q) = error '%q', want %q\", input, err, want)\n \t}\n \tif got := buf.String(); got != want {",
        "comments": [],
        "commit_messages": [
            "addressed review comments"
        ],
        "last_commit_sha": "6da03e176d154089128c0267585aecf0787b4f40"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table conditions ",
        "pr_number": 2998,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -138,9 +138,9 @@\nfunc TestDeidentifyExceptionList(t *testing.T) {\n \n func TestDeidentifyTableBucketing(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbuf := new(bytes.Buffer)\n+\tvar buf bytes.Buffer\n \n-\tif err := deIdentifyTableBucketing(buf, tc.ProjectID); err != nil {\n+\tif err := deIdentifyTableBucketing(&buf, tc.ProjectID); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_messages": [
            "addressed review comments"
        ],
        "last_commit_sha": "6da03e176d154089128c0267585aecf0787b4f40"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table conditions ",
        "pr_number": 2998,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -157,6 +157,24 @@\nfunc TestDeidentifyTableBucketing(t *testing.T) {\n \n }\n \n+func TestDeidentifyTableConditionInfoTypes(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tvar buf bytes.Buffer\n+\n+\tif err := deidentifyTableConditionInfoTypes(&buf, tc.ProjectID, []string{\"PATIENT\", \"FACTOID\"}); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"Table after de-identification\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"deidentifyTableConditionInfoTypes got %q, want %q\", got, want)\n+\t}\n+\tif want := \"values:{string_value:\\\"[PERSON_NAME] name was a curse invented by [PERSON_NAME].\\\"}}\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"deIdentifyTableBucketing got %q, want %q\", got, want)\n+\t}\n+}\n+\n func TestDeIdentifyWithWordList(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6da03e176d154089128c0267585aecf0787b4f40"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify table bucketing ",
        "pr_number": 2984,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -17,6 +17,8 @@\npackage deid\n \n import (\n \t\"bytes\"\n+\t\"strings\"\n+\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "00d2879b4f2fd55b1ac0b5dd31a55cbab903ec7c"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with exclusion dictionary ",
        "pr_number": 2957,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -282,7 +282,7 @@\nfunc TestInspectPhoneNumber(t *testing.T) {\n \tbuf := new(bytes.Buffer)\n \n \tif err := inspectPhoneNumber(buf, tc.ProjectID, \"I'm Gary and my phone number is (415) 555-0890\"); err != nil {\n-\t\tt.Errorf(\"TestInspectFile: %v\", err)\n+\t\tt.Fatal(err)\n \t}\n \n \tgot := buf.String()",
        "comments": [],
        "commit_messages": [
            "resolving conflicts"
        ],
        "last_commit_sha": "0a61a9ebd3e296cdbeb4016428834a536edee480"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with exclusion dictionary ",
        "pr_number": 2957,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -291,17 +291,16 @@\nfunc TestInspectPhoneNumber(t *testing.T) {\n \t}\n }\n \n-func TestInspectStringCustomHotWord(t *testing.T) {\n+func TestInspectStringWithExclusionDictionary(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)\n \n-\tif err := inspectStringCustomHotWord(buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n-\t\tt.Errorf(\"inspectStringCustomHotWord: %v\", err)\n+\tif err := inspectStringWithExclusionDictionary(buf, tc.ProjectID, \"Some email addresses: gary@example.com, example@example.com\", []string{\"example@example.com\"}); err != nil {\n+\t\tt.Fatal(err)\n \t}\n-\n \tgot := buf.String()\n-\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringCustomHotWord got %q, want %q\", got, want)\n+\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringWithExclusionDictionary got %q, want %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0a61a9ebd3e296cdbeb4016428834a536edee480"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string with exclusion dictionary ",
        "pr_number": 2957,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -312,11 +311,7 @@\nfunc TestInspectStringWithExclusionDictSubstring(t *testing.T) {\n \tif err := inspectStringWithExclusionDictSubstring(buf, tc.ProjectID, \"Some email addresses: gary@example.com, TEST@example.com\", []string{\"TEST\"}); err != nil {\n \t\tt.Fatal(err)\n \t}\n-\n \tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n-\t}\n \n \tif want := \"Infotype Name: DOMAIN_NAME\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0a61a9ebd3e296cdbeb4016428834a536edee480"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string without overlap",
        "pr_number": 2956,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -308,12 +308,32 @@\nfunc TestInspectPhoneNumber(t *testing.T) {\n \t}\n }\n \n+func TestInspectStringWithoutOverlap(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tbuf := new(bytes.Buffer)\n+\n+\tif err := inspectStringWithoutOverlap(buf, tc.ProjectID, \"example.com is a domain, james@example.org is an email.\"); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tgot := buf.String()\n+\tif want := \"Infotype Name: DOMAIN_NAME\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringWithoutOverlap got %q, want %q\", got, want)\n+\t}\n+\tif want := \"Quote: example.com\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringWithoutOverlap got %q, want %q\", got, want)\n+\t}\n+\tif want := \"Quote: example.org\"; strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringWithoutOverlap got %q, want %q\", got, want)\n+\t}\n+}\n+\n func TestInspectStringCustomHotWord(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)\n \n \tif err := inspectStringCustomHotWord(buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n-\t\tt.Errorf(\"inspectStringCustomHotWord: %v\", err)\n+\t\tt.Fatal(err)\n \t}\n \tgot := buf.String()\n \tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "f6653103c145f3abb5e32020de4827c7d473e000"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect string custom omit overlap",
        "pr_number": 2955,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -291,16 +291,16 @@\nfunc TestInspectPhoneNumber(t *testing.T) {\n \t}\n }\n \n-func TestInspectStringWithExclusionDictionary(t *testing.T) {\n+func TestInspectStringCustomHotWord(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)\n \n-\tif err := inspectStringWithExclusionDictionary(buf, tc.ProjectID, \"Some email addresses: gary@example.com, example@example.com\", []string{\"example@example.com\"}); err != nil {\n-\t\tt.Fatal(err)\n+\tif err := inspectStringCustomHotWord(buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n+\t\tt.Errorf(\"inspectStringCustomHotWord: %v\", err)\n \t}\n \tgot := buf.String()\n-\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"inspectStringWithExclusionDictionary got %q, want %q\", got, want)\n+\tif want := \"Infotype Name: PERSON_NAME\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringCustomHotWord got %q, want %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "597c72926fbf53ee836f43ec25e4fe675a840d8e"
    },
    {
        "pr_title": "feat(dlp): added a sample for deidentify redact",
        "pr_number": 2954,
        "file_name": "dlp/snippets/deid/deid_test.go",
        "code_diff": "@@ -101,6 +101,23 @@\nfunc TestDeidentifyDateShift(t *testing.T) {\n \t}\n }\n \n+func TestDeIdentifyWithRedact(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tinput := \"My name is Alicia Abernathy, and my email address is aabernathy@example.com.\"\n+\tinfoTypeNames := []string{\"EMAIL_ADDRESS\"}\n+\twant := \"output: My name is Alicia Abernathy, and my email address is .\"\n+\n+\tbuf := new(bytes.Buffer)\n+\terr := deidentifyWithRedact(buf, tc.ProjectID, input, infoTypeNames)\n+\tif err != nil {\n+\t\tt.Errorf(\"deidentifyWithRedact(%q) = error '%q', want %q\", err, input, want)\n+\t}\n+\tif got := buf.String(); got != want {\n+\t\tt.Errorf(\"deidentifyWithRedact(%q) = %q, want %q\", got, input, want)\n+\t}\n+}\n+\n func TestDeidentifyExceptionList(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "525660aa894768a40ab37e7e5b56c9843a95411f"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect custom regex ",
        "pr_number": 2952,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -312,14 +312,16 @@\nfunc TestInspectStringWithExclusionDictSubstring(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \tgot := buf.String()\n-\n+\tif want := \"Infotype Name: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n+\t}\n \tif want := \"Infotype Name: DOMAIN_NAME\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n \t}\n-\n \tif want := \"Quote: TEST\"; strings.Contains(got, want) {\n \t\tt.Errorf(\"inspectStringWithExclusionDictSubstring got %q, want %q\", got, want)\n \t}\n+\n }\n \n func TestInspectStringOmitOverlap(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "65822d85d19e707de0fc5095cad30d618e60c7e4"
    },
    {
        "pr_title": "feat(dlp): added a sample for inspect custom regex ",
        "pr_number": 2952,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -344,7 +346,7 @@\nfunc TestInspectStringCustomOmitOverlap(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)\n \n-\tif err := inspectStringCustomOmitOverlap(buf, tc.ProjectID, \"Name: Jane Doe. Name: Larry Page.\", \"VIP_DETECTOR\", \"PERSON_NAME\", \"Larry Page|Sergey Brin\"); err != nil {\n+\tif err := inspectStringCustomHotWord(buf, tc.ProjectID, \"patient name: John Doe\", \"patient\", \"PERSON_NAME\"); err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "65822d85d19e707de0fc5095cad30d618e60c7e4"
    },
    {
        "pr_title": "feat(bigquery): add example of writing to default stream",
        "pr_number": 2944,
        "file_name": "bigquery/snippets/managedwriter/integration_test.go",
        "code_diff": "@@ -24,7 +24,7 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func TestPendingStream(t *testing.T) {\n+func TestAppends(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "feat(bigquery): add example of writing to default stream"
        ],
        "last_commit_sha": "a5e9ac01b3b3d3b5ae0a90501566f479118bdf44"
    },
    {
        "pr_title": "chore(functions/functionsv2): Update all storage samples to use type library",
        "pr_number": 2931,
        "file_name": "functions/functionsv2/hellostorage/hello_storage.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2021 Google LLC\n+// Copyright 2023 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "chore(functions/functionsv2): Update all storage samples to use type library"
        ],
        "last_commit_sha": "004f820271817db817618db2319c11b885ab0414"
    },
    {
        "pr_title": "chore(functions/functionsv2): Update all storage samples to use type library",
        "pr_number": 2931,
        "file_name": "functions/functionsv2/hellostorage/hello_storage_test.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2021 Google LLC\n+// Copyright 2023 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "chore(functions/functionsv2): Update all storage samples to use type library"
        ],
        "last_commit_sha": "004f820271817db817618db2319c11b885ab0414"
    },
    {
        "pr_title": "chore(functions/functionsv2): Update all storage samples to use type library",
        "pr_number": 2931,
        "file_name": "functions/functionsv2/hellostorage/hello_storage_test.go",
        "code_diff": "@@ -26,6 +26,9 @@\nimport (\n \t\"time\"\n \n \t\"github.com/cloudevents/sdk-go/v2/event\"\n+\t\"github.com/googleapis/google-cloudevents-go/cloud/storagedata\"\n+\t\"google.golang.org/protobuf/encoding/protojson\"\n+\t\"google.golang.org/protobuf/types/known/timestamppb\"\n )\n \n func TestHelloStorage(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "chore(functions/functionsv2): Update all storage samples to use type library"
        ],
        "last_commit_sha": "004f820271817db817618db2319c11b885ab0414"
    },
    {
        "pr_title": "chore(functions/functionsv2): Update all storage samples to use type library",
        "pr_number": 2931,
        "file_name": "functions/functionsv2/imagemagick/imagemagick.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2022 Google LLC\n+// Copyright 2023 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "chore(functions/functionsv2): Update all storage samples to use type library"
        ],
        "last_commit_sha": "004f820271817db817618db2319c11b885ab0414"
    },
    {
        "pr_title": "chore(functions/functionsv2): Update all storage samples to use type library",
        "pr_number": 2931,
        "file_name": "functions/functionsv2/imagemagick/imagemagick.go",
        "code_diff": "@@ -31,6 +31,8 @@\nimport (\n \t\"cloud.google.com/go/vision/v2/apiv1/visionpb\"\n \t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \tcloudevents \"github.com/cloudevents/sdk-go/v2\"\n+\t\"github.com/googleapis/google-cloudevents-go/cloud/storagedata\"\n+\t\"google.golang.org/protobuf/encoding/protojson\"\n )\n \n // Global API clients used across function invocations.",
        "comments": [],
        "commit_messages": [
            "chore(functions/functionsv2): Update all storage samples to use type library"
        ],
        "last_commit_sha": "004f820271817db817618db2319c11b885ab0414"
    },
    {
        "pr_title": "chore(functions/functionsv2): Update all storage samples to use type library",
        "pr_number": 2931,
        "file_name": "functions/functionsv2/imagemagick/imagemagick_test.go",
        "code_diff": "@@ -22,6 +22,8 @@\nimport (\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \tcloudevents \"github.com/cloudevents/sdk-go/v2\"\n+\t\"github.com/googleapis/google-cloudevents-go/cloud/storagedata\"\n+\t\"google.golang.org/protobuf/encoding/protojson\"\n )\n \n func TestBlurOffensiveImages(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "chore(functions/functionsv2): Update all storage samples to use type library"
        ],
        "last_commit_sha": "004f820271817db817618db2319c11b885ab0414"
    },
    {
        "pr_title": "chore(functions/functionsv2): Update all storage samples to use type library",
        "pr_number": 2931,
        "file_name": "functions/functionsv2/imagemagick/imagemagick_test.go",
        "code_diff": "@@ -51,7 +53,7 @@\nfunc TestBlurOffensiveImages(t *testing.T) {\n \tos.Setenv(\"BLURRED_BUCKET_NAME\", outputBucket)\n \tdefer os.Setenv(\"BLURRED_BUCKET_NAME\", oldEnvValue)\n \n-\te := GCSEvent{\n+\te := &storagedata.StorageObjectData{\n \t\tBucket: inputBucket,\n \t\tName:   \"zombie.jpg\",\n \t}",
        "comments": [],
        "commit_messages": [
            "chore(functions/functionsv2): Update all storage samples to use type library"
        ],
        "last_commit_sha": "004f820271817db817618db2319c11b885ab0414"
    },
    {
        "pr_title": "chore(functions/functionsv2): Update all storage samples to use type library",
        "pr_number": 2931,
        "file_name": "functions/functionsv2/ocr/app/process.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2022 Google LLC\n+// Copyright 2023 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "chore(functions/functionsv2): Update all storage samples to use type library"
        ],
        "last_commit_sha": "004f820271817db817618db2319c11b885ab0414"
    },
    {
        "pr_title": "chore(functions/functionsv2): Update all storage samples to use type library",
        "pr_number": 2931,
        "file_name": "functions/functionsv2/ocr/app/process.go",
        "code_diff": "@@ -23,6 +23,8 @@\nimport (\n \n \t\"github.com/GoogleCloudPlatform/functions-framework-go/functions\"\n \t\"github.com/cloudevents/sdk-go/v2/event\"\n+\t\"github.com/googleapis/google-cloudevents-go/cloud/storagedata\"\n+\t\"google.golang.org/protobuf/encoding/protojson\"\n )\n \n func init() {",
        "comments": [],
        "commit_messages": [
            "chore(functions/functionsv2): Update all storage samples to use type library"
        ],
        "last_commit_sha": "004f820271817db817618db2319c11b885ab0414"
    },
    {
        "pr_title": "chore(functions/functionsv2): Update all storage samples to use type library",
        "pr_number": 2931,
        "file_name": "functions/functionsv2/ocr/app/setup.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2022 Google LLC\n+// Copyright 2023 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "chore(functions/functionsv2): Update all storage samples to use type library"
        ],
        "last_commit_sha": "004f820271817db817618db2319c11b885ab0414"
    },
    {
        "pr_title": "chore(functions/functionsv2): Update all storage samples to use type library",
        "pr_number": 2931,
        "file_name": "functions/functionsv2/ocr/app/setup.go",
        "code_diff": "@@ -23,7 +23,6 @@\nimport (\n \t\"fmt\"\n \t\"os\"\n \t\"strings\"\n-\t\"time\"\n \n \t\"cloud.google.com/go/pubsub\"\n \t\"cloud.google.com/go/storage\"",
        "comments": [],
        "commit_messages": [
            "chore(functions/functionsv2): Update all storage samples to use type library"
        ],
        "last_commit_sha": "004f820271817db817618db2319c11b885ab0414"
    },
    {
        "pr_title": "feat(Transcoder): update captions code samples for display name and l\u2026",
        "pr_number": 2888,
        "file_name": "media/transcoder/create_job_with_embedded_captions.go",
        "code_diff": "@@ -24,7 +24,7 @@\nimport (\n \t\"cloud.google.com/go/video/transcoder/apiv1/transcoderpb\"\n )\n \n-// createJobWithEmbeddedCaptions creates a job that embeds captions in the\n+// createJobWithEmbeddedCaptions creates a job that embeds closed captions in the\n // output video. See https://cloud.google.com/transcoder/docs/how-to/captions-and-subtitles\n // for more information.\n func createJobWithEmbeddedCaptions(w io.Writer, projectID string, location string, inputVideoURI string, inputCaptionsURI string, outputURI string) error {",
        "comments": [],
        "commit_messages": [
            "feat(Transcoder): update captions code samples for display name and language"
        ],
        "last_commit_sha": "345eee321ed041a9d6731fbd981ad4a63801af4a"
    },
    {
        "pr_title": "feat(Transcoder): update captions code samples for display name and l\u2026",
        "pr_number": 2888,
        "file_name": "media/transcoder/create_job_with_embedded_captions.go",
        "code_diff": "@@ -41,6 +41,52 @@\nfunc createJobWithEmbeddedCaptions(w io.Writer, projectID string, location strin\n \t}\n \tdefer client.Close()\n \n+\t// Set up elementary streams. The InputKey field refers to inputs in\n+\t// the Inputs array defined the job config.\n+\telementaryStreams := []*transcoderpb.ElementaryStream{\n+\t\t{\n+\t\t\tKey: \"video_stream0\",\n+\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n+\t\t\t\tVideoStream: &transcoderpb.VideoStream{\n+\t\t\t\t\tCodecSettings: &transcoderpb.VideoStream_H264{\n+\t\t\t\t\t\tH264: &transcoderpb.VideoStream_H264CodecSettings{\n+\t\t\t\t\t\t\tBitrateBps:   550000,\n+\t\t\t\t\t\t\tFrameRate:    60,\n+\t\t\t\t\t\t\tHeightPixels: 360,\n+\t\t\t\t\t\t\tWidthPixels:  640,\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t\t{\n+\t\t\tKey: \"audio_stream0\",\n+\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n+\t\t\t\tAudioStream: &transcoderpb.AudioStream{\n+\t\t\t\t\tCodec:      \"aac\",\n+\t\t\t\t\tBitrateBps: 64000,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t\t{\n+\t\t\tKey: \"cea_stream0\",\n+\t\t\tElementaryStream: &transcoderpb.ElementaryStream_TextStream{\n+\t\t\t\tTextStream: &transcoderpb.TextStream{\n+\t\t\t\t\tCodec: \"cea608\",\n+\t\t\t\t\tMapping: []*transcoderpb.TextStream_TextMapping{\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tAtomKey:    \"atom0\",\n+\t\t\t\t\t\t\tInputKey:   \"caption_input0\",\n+\t\t\t\t\t\t\tInputTrack: 0,\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t\tLanguageCode: \"en-US\",\n+\t\t\t\t\tDisplayName:  \"English\",\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}\n+\n \treq := &transcoderpb.CreateJobRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n \t\tJob: &transcoderpb.Job{",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "345eee321ed041a9d6731fbd981ad4a63801af4a"
    },
    {
        "pr_title": "feat(Transcoder): update captions code samples for display name and l\u2026",
        "pr_number": 2888,
        "file_name": "media/transcoder/create_job_with_standalone_captions.go",
        "code_diff": "@@ -26,14 +26,15 @@\nimport (\n \t\"cloud.google.com/go/video/transcoder/apiv1/transcoderpb\"\n )\n \n-// createJobWithStandaloneCaptions creates a job that can use captions from a\n+// createJobWithStandaloneCaptions creates a job that can use subtitles from a\n // standalone file. See https://cloud.google.com/transcoder/docs/how-to/captions-and-subtitles\n // for more information.\n-func createJobWithStandaloneCaptions(w io.Writer, projectID string, location string, inputVideoURI string, inputCaptionsURI string, outputURI string) error {\n+func createJobWithStandaloneCaptions(w io.Writer, projectID string, location string, inputVideoURI string, inputSubtitles1URI string, inputSubtitles2URI string, outputURI string) error {\n \t// projectID := \"my-project-id\"\n \t// location := \"us-central1\"\n \t// inputVideoURI := \"gs://my-bucket/my-video-file\"\n-\t// inputCaptionsURI := \"gs://my-bucket/my-captions-file\"\n+\t// inputSubtitles1URI := \"gs://my-bucket/my-subtitles-file1\"\n+\t// inputSubtitles2URI := \"gs://my-bucket/my-subtitles-file2\"\n \t// outputURI := \"gs://my-bucket/my-output-folder/\"\n \n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "feat(Transcoder): update captions code samples for display name and language"
        ],
        "last_commit_sha": "345eee321ed041a9d6731fbd981ad4a63801af4a"
    },
    {
        "pr_title": "feat(Transcoder): update captions code samples for display name and l\u2026",
        "pr_number": 2888,
        "file_name": "media/transcoder/create_job_with_standalone_captions.go",
        "code_diff": "@@ -43,6 +44,67 @@\nfunc createJobWithStandaloneCaptions(w io.Writer, projectID string, location str\n \t}\n \tdefer client.Close()\n \n+\t// Set up elementary streams. The InputKey field refers to inputs in\n+\t// the Inputs array defined the job config.\n+\telementaryStreams := []*transcoderpb.ElementaryStream{\n+\t\t{\n+\t\t\tKey: \"video_stream0\",\n+\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n+\t\t\t\tVideoStream: &transcoderpb.VideoStream{\n+\t\t\t\t\tCodecSettings: &transcoderpb.VideoStream_H264{\n+\t\t\t\t\t\tH264: &transcoderpb.VideoStream_H264CodecSettings{\n+\t\t\t\t\t\t\tBitrateBps:   550000,\n+\t\t\t\t\t\t\tFrameRate:    60,\n+\t\t\t\t\t\t\tHeightPixels: 360,\n+\t\t\t\t\t\t\tWidthPixels:  640,\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t\t{\n+\t\t\tKey: \"audio_stream0\",\n+\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n+\t\t\t\tAudioStream: &transcoderpb.AudioStream{\n+\t\t\t\t\tCodec:      \"aac\",\n+\t\t\t\t\tBitrateBps: 64000,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t\t{\n+\t\t\tKey: \"vtt_stream_en\",\n+\t\t\tElementaryStream: &transcoderpb.ElementaryStream_TextStream{\n+\t\t\t\tTextStream: &transcoderpb.TextStream{\n+\t\t\t\t\tCodec:        \"webvtt\",\n+\t\t\t\t\tLanguageCode: \"en-US\",\n+\t\t\t\t\tDisplayName:  \"English\",\n+\t\t\t\t\tMapping: []*transcoderpb.TextStream_TextMapping{\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tAtomKey:  \"atom0\",\n+\t\t\t\t\t\t\tInputKey: \"subtitle_input_en\",\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t\t{\n+\t\t\tKey: \"vtt_stream_es\",\n+\t\t\tElementaryStream: &transcoderpb.ElementaryStream_TextStream{\n+\t\t\t\tTextStream: &transcoderpb.TextStream{\n+\t\t\t\t\tCodec:        \"webvtt\",\n+\t\t\t\t\tLanguageCode: \"es-ES\",\n+\t\t\t\t\tDisplayName:  \"Spanish\",\n+\t\t\t\t\tMapping: []*transcoderpb.TextStream_TextMapping{\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tAtomKey:  \"atom0\",\n+\t\t\t\t\t\t\tInputKey: \"subtitle_input_es\",\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}\n+\n \treq := &transcoderpb.CreateJobRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n \t\tJob: &transcoderpb.Job{",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "345eee321ed041a9d6731fbd981ad4a63801af4a"
    },
    {
        "pr_title": "feat(Transcoder): update captions code samples for display name and l\u2026",
        "pr_number": 2888,
        "file_name": "media/transcoder/create_job_with_standalone_captions.go",
        "code_diff": "@@ -55,57 +117,21 @@\nfunc createJobWithStandaloneCaptions(w io.Writer, projectID string, location str\n \t\t\t\t\t\t\tUri: inputVideoURI,\n \t\t\t\t\t\t},\n \t\t\t\t\t\t{\n-\t\t\t\t\t\t\tKey: \"caption_input0\",\n-\t\t\t\t\t\t\tUri: inputCaptionsURI,\n+\t\t\t\t\t\t\tKey: \"subtitle_input_en\",\n+\t\t\t\t\t\t\tUri: inputSubtitles1URI,\n \t\t\t\t\t\t},\n-\t\t\t\t\t},\n-\t\t\t\t\tEditList: []*transcoderpb.EditAtom{\n \t\t\t\t\t\t{\n-\t\t\t\t\t\t\tKey:    \"atom0\",\n-\t\t\t\t\t\t\tInputs: []string{\"input0\", \"caption_input0\"},\n+\t\t\t\t\t\t\tKey: \"subtitle_input_es\",\n+\t\t\t\t\t\t\tUri: inputSubtitles2URI,\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n-\t\t\t\t\tElementaryStreams: []*transcoderpb.ElementaryStream{\n-\t\t\t\t\t\t{\n-\t\t\t\t\t\t\tKey: \"video_stream0\",\n-\t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_VideoStream{\n-\t\t\t\t\t\t\t\tVideoStream: &transcoderpb.VideoStream{\n-\t\t\t\t\t\t\t\t\tCodecSettings: &transcoderpb.VideoStream_H264{\n-\t\t\t\t\t\t\t\t\t\tH264: &transcoderpb.VideoStream_H264CodecSettings{\n-\t\t\t\t\t\t\t\t\t\t\tBitrateBps:   550000,\n-\t\t\t\t\t\t\t\t\t\t\tFrameRate:    60,\n-\t\t\t\t\t\t\t\t\t\t\tHeightPixels: 360,\n-\t\t\t\t\t\t\t\t\t\t\tWidthPixels:  640,\n-\t\t\t\t\t\t\t\t\t\t},\n-\t\t\t\t\t\t\t\t\t},\n-\t\t\t\t\t\t\t\t},\n-\t\t\t\t\t\t\t},\n-\t\t\t\t\t\t},\n-\t\t\t\t\t\t{\n-\t\t\t\t\t\t\tKey: \"audio_stream0\",\n-\t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_AudioStream{\n-\t\t\t\t\t\t\t\tAudioStream: &transcoderpb.AudioStream{\n-\t\t\t\t\t\t\t\t\tCodec:      \"aac\",\n-\t\t\t\t\t\t\t\t\tBitrateBps: 64000,\n-\t\t\t\t\t\t\t\t},\n-\t\t\t\t\t\t\t},\n-\t\t\t\t\t\t},\n+\t\t\t\t\tEditList: []*transcoderpb.EditAtom{\n \t\t\t\t\t\t{\n-\t\t\t\t\t\t\tKey: \"vtt-stream0\",\n-\t\t\t\t\t\t\tElementaryStream: &transcoderpb.ElementaryStream_TextStream{\n-\t\t\t\t\t\t\t\tTextStream: &transcoderpb.TextStream{\n-\t\t\t\t\t\t\t\t\tCodec: \"webvtt\",\n-\t\t\t\t\t\t\t\t\tMapping: []*transcoderpb.TextStream_TextMapping{\n-\t\t\t\t\t\t\t\t\t\t{\n-\t\t\t\t\t\t\t\t\t\t\tAtomKey:    \"atom0\",\n-\t\t\t\t\t\t\t\t\t\t\tInputKey:   \"caption_input0\",\n-\t\t\t\t\t\t\t\t\t\t\tInputTrack: 0,\n-\t\t\t\t\t\t\t\t\t\t},\n-\t\t\t\t\t\t\t\t\t},\n-\t\t\t\t\t\t\t\t},\n-\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t\tKey:    \"atom0\",\n+\t\t\t\t\t\t\tInputs: []string{\"input0\", \"subtitle_input_en\", \"subtitle_input_es\"},\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n+\t\t\t\t\tElementaryStreams: elementaryStreams,\n \t\t\t\t\tMuxStreams: []*transcoderpb.MuxStream{\n \t\t\t\t\t\t{\n \t\t\t\t\t\t\tKey:               \"sd-hls-fmp4\",",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "345eee321ed041a9d6731fbd981ad4a63801af4a"
    },
    {
        "pr_title": "feat(Transcoder): update captions code samples for display name and l\u2026",
        "pr_number": 2888,
        "file_name": "media/transcoder/create_job_with_standalone_captions.go",
        "code_diff": "@@ -118,9 +144,20 @@\nfunc createJobWithStandaloneCaptions(w io.Writer, projectID string, location str\n \t\t\t\t\t\t\tElementaryStreams: []string{\"audio_stream0\"},\n \t\t\t\t\t\t},\n \t\t\t\t\t\t{\n-\t\t\t\t\t\t\tKey:               \"text-vtt\",\n+\t\t\t\t\t\t\tKey:               \"text-vtt-en\",\n+\t\t\t\t\t\t\tContainer:         \"vtt\",\n+\t\t\t\t\t\t\tElementaryStreams: []string{\"vtt_stream_en\"},\n+\t\t\t\t\t\t\tSegmentSettings: &transcoderpb.SegmentSettings{\n+\t\t\t\t\t\t\t\tSegmentDuration: &duration.Duration{\n+\t\t\t\t\t\t\t\t\tSeconds: 6,\n+\t\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t\t\tIndividualSegments: true,\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t},\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tKey:               \"text-vtt-es\",\n \t\t\t\t\t\t\tContainer:         \"vtt\",\n-\t\t\t\t\t\t\tElementaryStreams: []string{\"vtt-stream0\"},\n+\t\t\t\t\t\t\tElementaryStreams: []string{\"vtt_stream_es\"},\n \t\t\t\t\t\t\tSegmentSettings: &transcoderpb.SegmentSettings{\n \t\t\t\t\t\t\t\tSegmentDuration: &duration.Duration{\n \t\t\t\t\t\t\t\t\tSeconds: 6,",
        "comments": [],
        "commit_messages": [
            "feat(Transcoder): update captions code samples for display name and language"
        ],
        "last_commit_sha": "345eee321ed041a9d6731fbd981ad4a63801af4a"
    },
    {
        "pr_title": "feat(Transcoder): update captions code samples for display name and l\u2026",
        "pr_number": 2888,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -40,7 +40,9 @@\nconst (\n \ttestVideoFileName        = \"ChromeCast.mp4\"\n \ttestConcatFileName       = \"ForBiggerEscapes.mp4\"\n \ttestOverlayImageFileName = \"overlay.jpg\"\n-\ttestCaptionsFileName     = \"caption.srt\"\n+\ttestCaptionsFileName     = \"captions.srt\"\n+\ttestSubtitlesFileName1   = \"subtitles-en.srt\"\n+\ttestSubtitlesFileName2   = \"subtitles-es.srt\"\n \tpreset                   = \"preset/web-hd\"\n \tsmallSpriteSheetFileName = \"small-sprite-sheet0000000000.jpeg\"\n \tlargeSpriteSheetFileName = \"large-sprite-sheet0000000000.jpeg\"",
        "comments": [],
        "commit_messages": [
            "feat(Transcoder): update captions code samples for display name and language"
        ],
        "last_commit_sha": "345eee321ed041a9d6731fbd981ad4a63801af4a"
    },
    {
        "pr_title": "feat(Transcoder): update captions code samples for display name and l\u2026",
        "pr_number": 2888,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -65,6 +67,8 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tinputConcatURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testConcatFileName\n \tinputOverlayImageURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testOverlayImageFileName\n \tinputCaptionsURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testCaptionsFileName\n+\tinputSubtitles1URI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testSubtitlesFileName1\n+\tinputSubtitles2URI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testSubtitlesFileName2\n \toutputURIForPreset := \"gs://\" + bucketName + \"/test-output-preset/\"\n \toutputURIForTemplate := \"gs://\" + bucketName + \"/test-output-template/\"\n \toutputURIForAdHoc := \"gs://\" + bucketName + \"/test-output-adhoc/\"",
        "comments": [],
        "commit_messages": [
            "feat(Transcoder): update captions code samples for display name and language"
        ],
        "last_commit_sha": "345eee321ed041a9d6731fbd981ad4a63801af4a"
    },
    {
        "pr_title": "feat(Transcoder): update captions code samples for display name and l\u2026",
        "pr_number": 2888,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -121,7 +125,7 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \n \ttestJobWithEmbeddedCaptions(t, projectNumber, inputURI, inputCaptionsURI, outputURIForEmbeddedCaptions)\n \tt.Logf(\"\\ntestJobWithEmbeddedCaptions() completed\\n\")\n-\ttestJobWithStandaloneCaptions(t, projectNumber, inputURI, inputCaptionsURI, outputURIForStandaloneCaptions)\n+\ttestJobWithStandaloneCaptions(t, projectNumber, inputURI, inputSubtitles1URI, inputSubtitles2URI, outputURIForStandaloneCaptions)\n \tt.Logf(\"\\ntestJobWithStandaloneCaptions() completed\\n\")\n }",
        "comments": [],
        "commit_messages": [
            "feat(Transcoder): update captions code samples for display name and language"
        ],
        "last_commit_sha": "345eee321ed041a9d6731fbd981ad4a63801af4a"
    },
    {
        "pr_title": "feat(Transcoder): update captions code samples for display name and l\u2026",
        "pr_number": 2888,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -193,6 +197,8 @@\nfunc writeTestGCSFiles(t *testing.T, projectID string, bucketName string) {\n \twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testOverlayImageFileName)\n \twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testConcatFileName)\n \twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testCaptionsFileName)\n+\twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testSubtitlesFileName1)\n+\twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testSubtitlesFileName2)\n }\n \n // writeTestGCSFile deletes the GCS test bucket and uploads a test video file to it.",
        "comments": [],
        "commit_messages": [
            "feat(Transcoder): update captions code samples for display name and language"
        ],
        "last_commit_sha": "345eee321ed041a9d6731fbd981ad4a63801af4a"
    },
    {
        "pr_title": "docs: add comments to explain environment variables",
        "pr_number": 2862,
        "file_name": "cloudsql/postgres/database-sql/connect_connector_iam_authn.go",
        "code_diff": "@@ -41,7 +41,7 @@\nfunc connectWithConnectorIAMAuthN() (*sql.DB, error) {\n \t// Cloud Secret Manager (https://cloud.google.com/secret-manager) to help\n \t// keep secrets safe.\n \tvar (\n-\t\tdbUser                 = mustGetenv(\"DB_IAM_USER\")              // e.g. 'sa-name@project-id.iam'\n+\t\tdbUser                 = mustGetenv(\"DB_IAM_USER\")              // e.g. 'service-account-name@project-id.iam'\n \t\tdbName                 = mustGetenv(\"DB_NAME\")                  // e.g. 'my-database'\n \t\tinstanceConnectionName = mustGetenv(\"INSTANCE_CONNECTION_NAME\") // e.g. 'project:region:instance'\n \t\tusePrivate             = os.Getenv(\"PRIVATE_IP\")",
        "comments": [],
        "commit_messages": [
            "docs: clarify service account user format"
        ],
        "last_commit_sha": "469eaaee43463eca2008ac59f6981850c9f6d528"
    },
    {
        "pr_title": "feat(spanner): add samples for UpdateDatabase",
        "pr_number": 2851,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -31,12 +31,13 @@\nimport (\n \t\"cloud.google.com/go/kms/apiv1/kmspb\"\n \t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n+\tadminpb \"cloud.google.com/go/spanner/admin/database/apiv1/databasepb\"\n \tinstance \"cloud.google.com/go/spanner/admin/instance/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n \t\"google.golang.org/api/iterator\"\n-\tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n \tinstancepb \"google.golang.org/genproto/googleapis/spanner/admin/instance/v1\"\n+\t\"google.golang.org/genproto/protobuf/field_mask\"\n \t\"google.golang.org/grpc/codes\"\n \t\"google.golang.org/grpc/status\"\n )",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b3436e3b2c42ec975005ebf0783628639915455e"
    },
    {
        "pr_title": "feat(storagetransfer): add azure sample",
        "pr_number": 2802,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -28,17 +28,18 @@\nimport (\n \t\"cloud.google.com/go/storage\"\n \tstoragetransfer \"cloud.google.com/go/storagetransfer/apiv1\"\n \t\"cloud.google.com/go/storagetransfer/apiv1/storagetransferpb\"\n+\tazblob \"github.com/Azure/azure-sdk-for-go/sdk/storage/azblob\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/aws/aws-sdk-go/aws\"\n \t\"github.com/aws/aws-sdk-go/aws/session\"\n-\t\"github.com/aws/aws-sdk-go/service/s3/s3manager\"\n-\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/aws/aws-sdk-go/service/s3\"\n+\t\"github.com/aws/aws-sdk-go/service/s3/s3manager\"\n )\n \n var sc *storage.Client\n var sts *storagetransfer.Client\n var s3Bucket string\n+var azureContainer string\n var gcsSourceBucket string\n var gcsSinkBucket string",
        "comments": [],
        "commit_messages": [
            "feat(storagetransfer):add Azure sample",
            "exclude idea files"
        ],
        "last_commit_sha": "2fc8f1044322aa9e8e85f874b184dc4fae6ad933"
    },
    {
        "pr_title": "feat(storagetransfer): add azure sample",
        "pr_number": 2802,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -89,6 +90,19 @@\nfunc TestMain(m *testing.M) {\n \t\tlog.Fatalf(\"couldn't create S3 bucket: %v\", err)\n \t}\n \n+\tconnectionString := os.Getenv(\"AZURE_CONNECTION_STRING\") +\n+\t\t\";\" + \"AccountName=\" + os.Getenv(\"AZURE_STORAGE_ACCOUNT\")\n+\tazClient, err := azblob.NewClientFromConnectionString(connectionString, nil)\n+\tif err != nil {\n+\t\tlog.Fatal(\"Couldn't create Azure client: \" + err.Error())\n+\t}\n+\tazureContainer = testutil.UniqueBucketName(\"azurebucket\")\n+\n+\tazClient.CreateContainer(ctx, azureContainer, nil)\n+\tif err != nil {\n+\t\tlog.Fatal(err)\n+\t}\n+\n \t// Run tests\n \texit := m.Run()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2fc8f1044322aa9e8e85f874b184dc4fae6ad933"
    },
    {
        "pr_title": "feat(storagetransfer): add azure sample",
        "pr_number": 2802,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -111,6 +125,11 @@\nfunc TestMain(m *testing.M) {\n \t\tlog.Printf(\"couldn't delete S3 bucket: %v\", err)\n \t}\n \n+\t_, err = azClient.DeleteContainer(ctx, azureContainer, nil)\n+\tif err != nil {\n+\t\tlog.Printf(\"couldn't delete Azure bucket: %v\", err)\n+\t}\n+\n \tos.Exit(exit)\n }",
        "comments": [],
        "commit_messages": [
            "feat(storagetransfer):add Azure sample",
            "exclude idea files"
        ],
        "last_commit_sha": "2fc8f1044322aa9e8e85f874b184dc4fae6ad933"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -29,6 +29,49 @@\nimport (\n \t\"google.golang.org/protobuf/proto\"\n )\n \n+func createInstance(\n+\tctx context.Context,\n+\tprojectID, zone, instanceName, sourceImage, diskName string,\n+) error {\n+\tinstancesClient, err := compute.NewInstancesRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer instancesClient.Close()\n+\treq := &computepb.InsertInstanceRequest{\n+\t\tProject: projectID,\n+\t\tZone:    zone,\n+\t\tInstanceResource: &computepb.Instance{\n+\t\t\tName: proto.String(instanceName),\n+\t\t\tDisks: []*computepb.AttachedDisk{\n+\t\t\t\t{\n+\t\t\t\t\tInitializeParams: &computepb.AttachedDiskInitializeParams{\n+\t\t\t\t\t\tDiskSizeGb:  proto.Int64(25),\n+\t\t\t\t\t\tSourceImage: proto.String(sourceImage),\n+\t\t\t\t\t\tDiskName:    proto.String(diskName),\n+\t\t\t\t\t},\n+\t\t\t\t\tAutoDelete: proto.Bool(false),\n+\t\t\t\t\tBoot:       proto.Bool(true),\n+\t\t\t\t\tDeviceName: proto.String(diskName),\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\tMachineType: proto.String(fmt.Sprintf(\"zones/%s/machineTypes/n1-standard-1\", zone)),\n+\t\t\tNetworkInterfaces: []*computepb.NetworkInterface{\n+\t\t\t\t{\n+\t\t\t\t\tName: proto.String(\"global/networks/default\"),\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\top, err := instancesClient.Insert(ctx, req)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn op.Wait(ctx)\n+}\n+\n func getInstance(\n \tctx context.Context,\n \tprojectID, zone, instanceName string,",
        "comments": [
            {
                "comment": "Do these tests need to be in the same function as all the others, or could this be done in a more focused (and maintainable!)  `TestRegionalDiskSamples()` method? ",
                "position": 76
            },
            {
                "comment": "They're in the same function so that the initial setup only has to be done once. Specifically the VM instance creation takes a bit of time, and I wanted it done once instead of for every test.\r\n\r\nI suppose I could make a separate function for tests that require a VM instance, but that doesn't lead to nice logical separation - some regional test samples would be in the regular function and some in the function with a VM instance, plus some of the setup would just had to be copy-pasted.",
                "position": 76
            },
            {
                "comment": "That's fair. I think these tests would benefit from some refactoring, but that's beyond the scope of what you're doing here.",
                "position": 76
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -120,6 +163,9 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \tinstanceName := fmt.Sprintf(\"test-instance-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tdiskName := fmt.Sprintf(\"test-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tdiskName2 := fmt.Sprintf(\"test-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\tinstanceDiskName := fmt.Sprintf(\"test-instance-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\tinstanceDiskName2 := fmt.Sprintf(\"test-instance-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\tinstanceDiskName3 := fmt.Sprintf(\"test-instance-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tsnapshotName := fmt.Sprintf(\"test-snapshot-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tsourceImage := \"projects/debian-cloud/global/images/family/debian-11\"\n \tsourceDisk := fmt.Sprintf(\"projects/%s/zones/europe-central2-b/disks/%s\", tc.ProjectID, diskName)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -143,6 +189,11 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"createDiskSnapshot got err: %v\", err)\n \t}\n+\t// Create a VM instance to attach disks to\n+\tcreateInstance(ctx, tc.ProjectID, zone, instanceName, sourceImage, instanceDiskName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"unable to create instance: %v\", err)\n+\t}\n \n \tt.Run(\"Create zonal disk from a snapshot\", func(t *testing.T) {\n \t\tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_messages": [
            "Tests: move VM instance creation to preparation step, add a test for attaching a regional disk to a VM instance"
        ],
        "last_commit_sha": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(compute): Regional disk samples",
        "pr_number": 2801,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -204,6 +255,38 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\t}\n \t})\n \n+\tt.Run(\"Create and resize a regional disk\", func(t *testing.T) {\n+\t\tbuf := &bytes.Buffer{}\n+\t\twant := \"Disk created\"\n+\n+\t\tif err := createRegionalDisk(buf, tc.ProjectID, region, replicaZones, diskName2, diskType, 20); err != nil {\n+\t\t\tt.Errorf(\"createRegionalDisk got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"createRegionalDisk got %q, want %q\", got, want)\n+\t\t}\n+\n+\t\tbuf.Reset()\n+\t\twant = \"Disk resized\"\n+\n+\t\tresizeRegionalDisk(buf, tc.ProjectID, region, diskName2, 50)\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"resizeRegionalDisk got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"resizeRegionalDisk got %q, want %q\", got, want)\n+\t\t}\n+\n+\t\tbuf.Reset()\n+\t\twant = \"Disk deleted\"\n+\n+\t\t// clean up\n+\t\terr = deleteRegionalDisk(buf, tc.ProjectID, region, diskName2)\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"deleteRegionalDisk got err: %v\", err)\n+\t\t}\n+\t})\n+\n \tt.Run(\"createEmptyDisk and clone it into a regional disk\", func(t *testing.T) {\n \t\tbuf := &bytes.Buffer{}\n \t\twant := \"Disk created\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "f90700987703020f715085056308ecea0972f693"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/create_cdn_key.go",
        "code_diff": "@@ -24,16 +24,17 @@\nimport (\n \t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n-// createCdnKey creates a CDN key. A CDN key is used to retrieve protected media.\n-// If akamaiTokenKey != \"\", then this is an Akamai CDN key, or else this is a\n-// Cloud CDN key.\n-func createCdnKey(w io.Writer, projectID, cdnKeyID, hostname, gcdnKeyname, gcdnPrivateKey, akamaiTokenKey string) error {\n+// createCDNKey creates a CDN key. A CDN key is used to retrieve protected media.\n+// If isMediaCDN is true, create a Media CDN key. If false, create a Cloud\n+// CDN key. To create a privateKey value for Media CDN, see\n+// https://cloud.google.com/video-stitcher/docs/how-to/managing-cdn-keys#create-private-key-media-cdn.\n+func createCDNKey(w io.Writer, projectID, keyID, hostname, keyName, privateKey string, isMediaCDN bool) error {\n \t// projectID := \"my-project-id\"\n-\t// cdnKeyID := \"my-cdn-key\"\n+\t// keyID := \"my-cdn-key\"\n \t// hostname := \"cdn.example.com\"\n-\t// gcdnKeyname := \"gcdn-key\"\n-\t// gcdnPrivateKey := \"VGhpcyBpcyBhIHRlc3Qgc3RyaW5nLg==\"\n-\t// akamaiTokenKey := \"VGhpcyBpcyBhIHRlc3Qgc3RyaW5nLg==\"\n+\t// keyName := \"cdn-key\"\n+\t// privateKey := \"my-private-key\"\n+\t// isMediaCDN := true\n \tlocation := \"us-central1\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/create_cdn_key.go",
        "code_diff": "@@ -43,14 +44,15 @@\nfunc createCdnKey(w io.Writer, projectID, cdnKeyID, hostname, gcdnKeyname, gcdnP\n \tdefer client.Close()\n \n \tvar req *stitcherpb.CreateCdnKeyRequest\n-\tif akamaiTokenKey != \"\" {\n+\tif isMediaCDN {\n \t\treq = &stitcherpb.CreateCdnKeyRequest{\n \t\t\tParent:   fmt.Sprintf(\"projects/%s/locations/%s\", projectID, location),\n-\t\t\tCdnKeyId: cdnKeyID,\n+\t\t\tCdnKeyId: keyID,\n \t\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_AkamaiCdnKey{\n-\t\t\t\t\tAkamaiCdnKey: &stitcherpb.AkamaiCdnKey{\n-\t\t\t\t\t\tTokenKey: []byte(akamaiTokenKey),\n+\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_MediaCdnKey{\n+\t\t\t\t\tMediaCdnKey: &stitcherpb.MediaCdnKey{\n+\t\t\t\t\t\tKeyName:    keyName,\n+\t\t\t\t\t\tPrivateKey: []byte(privateKey),\n \t\t\t\t\t},\n \t\t\t\t},\n \t\t\t\tHostname: hostname,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/delete_cdn_key.go",
        "code_diff": "@@ -24,10 +24,10 @@\nimport (\n \t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n-// deleteCdnKey deletes a CDN key.\n-func deleteCdnKey(w io.Writer, projectID, cdnKeyID string) error {\n+// deleteCDNKey deletes a CDN key.\n+func deleteCDNKey(w io.Writer, projectID, keyID string) error {\n \t// projectID := \"my-project-id\"\n-\t// cdnKeyID := \"my-cdn-key\"\n+\t// keyID := \"my-cdn-key\"\n \tlocation := \"us-central1\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/get_cdn_key.go",
        "code_diff": "@@ -25,10 +25,10 @@\nimport (\n \t\"cloud.google.com/go/video/stitcher/apiv1/stitcherpb\"\n )\n \n-// getCdnKey gets a CDN key by ID.\n-func getCdnKey(w io.Writer, projectID, cdnKeyID string) error {\n+// getCDNKey gets a CDN key by ID.\n+func getCDNKey(w io.Writer, projectID, keyID string) error {\n \t// projectID := \"my-project-id\"\n-\t// cdnKeyID := \"my-cdn-key\"\n+\t// keyID := \"my-cdn-key\"\n \tlocation := \"us-central1\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -27,6 +27,7 @@\nimport (\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n \tcloudresourcemanager \"google.golang.org/api/cloudresourcemanager/v1\"\n )",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -35,14 +36,13 @@\nconst (\n \tslateID             = \"my-go-test-slate\"\n \tdeleteSlateResponse = \"Deleted slate\"\n \n-\tdeleteCdnKeyResponse = \"Deleted CDN key\"\n-\tgcdnCdnKeyID         = \"my-go-test-google-cdn\"\n-\takamaiCdnKeyID       = \"my-go-test-akamai-cdn\"\n+\tdeleteCDNKeyResponse = \"Deleted CDN key\"\n+\tmediaCDNKeyID        = \"my-go-test-media-cdn\"\n+\tcloudCDNKeyID        = \"my-go-test-cloud-cdn\"\n+\takamaiCDNKeyID       = \"my-go-test-akamai-cdn\"\n \thostname             = \"cdn.example.com\"\n \tupdatedHostname      = \"updated.example.com\"\n-\tgcdnKeyname          = \"gcdn-key\"\n-\tprivateKey           = \"VGhpcyBpcyBhIHRlc3Qgc3RyaW5nLg==\"\n-\tupdatedPrivateKey    = \"VGhpcyBpcyBhbiB1cGRhdGVkIHRlc3Qgc3RyaW5nLg==\"\n+\tkeyName              = \"my-key\"\n )\n \n var bucketName string",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -101,10 +101,10 @@\nfunc TestSlates(t *testing.T) {\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tslateName := fmt.Sprintf(\"projects/%s/locations/%s/slates/%s\", projectNumber, location, slateID)\n \t\tif err := createSlate(buf, tc.ProjectID, slateID, slateURI); err != nil {\n-\t\t\tr.Errorf(\"createSlate got err: %v\", err)\n+\t\t\tt.Fatalf(\"createSlate got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, slateName) {\n-\t\t\tr.Errorf(\"createSlate got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, slateName)\n+\t\t\tt.Fatalf(\"createSlate got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, slateName)\n \t\t}\n \t})\n \tbuf.Reset()",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -158,149 +158,246 @@\nfunc TestSlates(t *testing.T) {\n \t})\n }\n \n-// TestCdnKeys tests major operations on CDN keys. Create, list, update,\n+// TestCDNKeys tests major operations on CDN keys. Create, list, update,\n // and get operations check if the CDN key resource name is returned. The\n // delete operation checks for a hard-coded string response.\n-func TestCdnKeys(t *testing.T) {\n+func TestCDNKeys(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := &bytes.Buffer{}\n \n \t// Test setup\n \n-\t// Delete the Google CDN key if it exists.\n-\tif err := getCdnKey(buf, tc.ProjectID, gcdnCdnKeyID); err == nil {\n+\t// Delete the Media CDN key if it exists.\n+\tif err := getCDNKey(buf, tc.ProjectID, mediaCDNKeyID); err == nil {\n \t\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\t\tif err := deleteCdnKey(buf, tc.ProjectID, gcdnCdnKeyID); err != nil {\n-\t\t\t\tr.Errorf(\"deleteCdnKey got err: %v\", err)\n+\t\t\tif err := deleteCDNKey(buf, tc.ProjectID, mediaCDNKeyID); err != nil {\n+\t\t\t\tr.Errorf(\"deleteCDNKey got err: %v\", err)\n+\t\t\t}\n+\t\t})\n+\t}\n+\n+\t// Delete the Cloud CDN key if it exists.\n+\tif err := getCDNKey(buf, tc.ProjectID, cloudCDNKeyID); err == nil {\n+\t\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\t\tif err := deleteCDNKey(buf, tc.ProjectID, cloudCDNKeyID); err != nil {\n+\t\t\t\tr.Errorf(\"deleteCDNKey got err: %v\", err)\n \t\t\t}\n \t\t})\n \t}\n \n \t// Delete the Akamai CDN key if it exists.\n-\tif err := getCdnKey(buf, tc.ProjectID, akamaiCdnKeyID); err == nil {\n+\tif err := getCDNKey(buf, tc.ProjectID, akamaiCDNKeyID); err == nil {\n \t\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\t\tif err := deleteCdnKey(buf, tc.ProjectID, akamaiCdnKeyID); err != nil {\n-\t\t\t\tr.Errorf(\"deleteCdnKey got err: %v\", err)\n+\t\t\tif err := deleteCDNKey(buf, tc.ProjectID, akamaiCDNKeyID); err != nil {\n+\t\t\t\tr.Errorf(\"deleteCDNKey got err: %v\", err)\n \t\t\t}\n \t\t})\n \t}\n \n \t// Tests\n-\t// Google CDN tests\n+\t// Media CDN tests\n+\tmediaCDNPrivateKey, err := getUUID64()\n+\tif err != nil {\n+\t\tt.Fatalf(\"uuid err: %v\", err)\n+\t}\n+\n+\t// Create a new Media CDN key.\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectNumber, location, mediaCDNKeyID)\n+\t\tif err := createCDNKey(buf, tc.ProjectID, mediaCDNKeyID, hostname, keyName, mediaCDNPrivateKey, true); err != nil {\n+\t\t\tt.Fatalf(\"createCDNKey (Media CDN) got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n+\t\t\tt.Fatalf(\"createCDNKey (Media CDN) got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t}\n+\t})\n+\tbuf.Reset()\n+\n+\t// List the CDN keys for a given location.\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, mediaCDNKeyID)\n+\t\tif err := listCDNKeys(buf, tc.ProjectID); err != nil {\n+\t\t\tr.Errorf(\"listCDNKeys got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n+\t\t\tr.Errorf(\"listCDNKeys got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t}\n+\t})\n+\tbuf.Reset()\n+\n+\t// Update an existing CDN key.\n+\tupdatedMediaCDNPrivateKey, err := getUUID64()\n+\tif err != nil {\n+\t\tt.Fatalf(\"uuid err: %v\", err)\n+\t}\n+\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, mediaCDNKeyID)\n+\t\tif err := updateCDNKey(buf, tc.ProjectID, mediaCDNKeyID, updatedHostname, keyName, updatedMediaCDNPrivateKey, true); err != nil {\n+\t\t\tr.Errorf(\"updateCDNKey got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n+\t\t\tr.Errorf(\"updateCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t}\n+\t})\n+\tbuf.Reset()\n \n-\t// Create a new Google CDN key.\n+\t// Get the updated CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectNumber, location, gcdnCdnKeyID)\n-\t\tif err := createCdnKey(buf, tc.ProjectID, gcdnCdnKeyID, hostname, gcdnKeyname, privateKey, \"\"); err != nil {\n-\t\t\tr.Errorf(\"createCdnKey (GCDN) got err: %v\", err)\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, mediaCDNKeyID)\n+\t\tif err := getCDNKey(buf, tc.ProjectID, mediaCDNKeyID); err != nil {\n+\t\t\tr.Errorf(\"getCDNKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"createCdnKey (GCDN) got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"getCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t}\n+\t})\n+\n+\t// Delete the CDN key.\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\tif err := deleteCDNKey(buf, tc.ProjectID, mediaCDNKeyID); err != nil {\n+\t\t\tr.Errorf(\"deleteCDNKey got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, deleteCDNKeyResponse) {\n+\t\t\tr.Errorf(\"deleteCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteCDNKeyResponse)\n+\t\t}\n+\t})\n+\n+\t// Cloud CDN tests\n+\n+\t// Create a new Cloud CDN key.\n+\tcloudCDNPrivateKey, err := getUUID64()\n+\tif err != nil {\n+\t\tt.Fatalf(\"uuid err: %v\", err)\n+\t}\n+\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectNumber, location, cloudCDNKeyID)\n+\t\tif err := createCDNKey(buf, tc.ProjectID, cloudCDNKeyID, hostname, keyName, cloudCDNPrivateKey, false); err != nil {\n+\t\t\tt.Fatalf(\"createCDNKey (Cloud CDN) got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n+\t\t\tt.Fatalf(\"createCDNKey (Cloud CDN) got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// List the CDN keys for a given location.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, gcdnCdnKeyID)\n-\t\tif err := listCdnKeys(buf, tc.ProjectID); err != nil {\n-\t\t\tr.Errorf(\"listCdnKeys got err: %v\", err)\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, cloudCDNKeyID)\n+\t\tif err := listCDNKeys(buf, tc.ProjectID); err != nil {\n+\t\t\tr.Errorf(\"listCDNKeys got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"listCdnKeys got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"listCDNKeys got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// Update an existing CDN key.\n+\tupdatedCloudCDNPrivateKey, err := getUUID64()\n+\tif err != nil {\n+\t\tt.Fatalf(\"uuid err: %v\", err)\n+\t}\n+\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, gcdnCdnKeyID)\n-\t\tif err := updateCdnKey(buf, tc.ProjectID, gcdnCdnKeyID, updatedHostname, gcdnKeyname, updatedPrivateKey, \"\"); err != nil {\n-\t\t\tr.Errorf(\"updateCdnKey got err: %v\", err)\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, cloudCDNKeyID)\n+\t\tif err := updateCDNKey(buf, tc.ProjectID, cloudCDNKeyID, updatedHostname, keyName, updatedCloudCDNPrivateKey, false); err != nil {\n+\t\t\tr.Errorf(\"updateCDNKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"updateCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"updateCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// Get the updated CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, gcdnCdnKeyID)\n-\t\tif err := getCdnKey(buf, tc.ProjectID, gcdnCdnKeyID); err != nil {\n-\t\t\tr.Errorf(\"getCdnKey got err: %v\", err)\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, cloudCDNKeyID)\n+\t\tif err := getCDNKey(buf, tc.ProjectID, cloudCDNKeyID); err != nil {\n+\t\t\tr.Errorf(\"getCDNKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"getCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"getCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \n \t// Delete the CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tif err := deleteCdnKey(buf, tc.ProjectID, gcdnCdnKeyID); err != nil {\n-\t\t\tr.Errorf(\"deleteCdnKey got err: %v\", err)\n+\t\tif err := deleteCDNKey(buf, tc.ProjectID, cloudCDNKeyID); err != nil {\n+\t\t\tr.Errorf(\"deleteCDNKey got err: %v\", err)\n \t\t}\n-\t\tif got := buf.String(); !strings.Contains(got, deleteCdnKeyResponse) {\n-\t\t\tr.Errorf(\"deleteCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteCdnKeyResponse)\n+\t\tif got := buf.String(); !strings.Contains(got, deleteCDNKeyResponse) {\n+\t\t\tr.Errorf(\"deleteCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteCDNKeyResponse)\n \t\t}\n \t})\n \n \t// Akamai tests\n \n \t// Create a new Akamai CDN key.\n+\takamaiTokenKey, err := getUUID64()\n+\tif err != nil {\n+\t\tt.Fatalf(\"uuid err: %v\", err)\n+\t}\n+\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectNumber, location, akamaiCdnKeyID)\n-\t\tif err := createCdnKey(buf, tc.ProjectID, akamaiCdnKeyID, hostname, \"\", \"\", privateKey); err != nil {\n-\t\t\tr.Errorf(\"createCdnKey (Akamai) got err: %v\", err)\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectNumber, location, akamaiCDNKeyID)\n+\t\tif err := createCDNKeyAkamai(buf, tc.ProjectID, akamaiCDNKeyID, hostname, akamaiTokenKey); err != nil {\n+\t\t\tt.Fatalf(\"createCDNKeyAkamai got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"createCdnKey (Akamai) got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tt.Fatalf(\"createCDNKeyAkamai got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// List the CDN keys for a given location.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, akamaiCdnKeyID)\n-\t\tif err := listCdnKeys(buf, tc.ProjectID); err != nil {\n-\t\t\tr.Errorf(\"listCdnKeys got err: %v\", err)\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, akamaiCDNKeyID)\n+\t\tif err := listCDNKeys(buf, tc.ProjectID); err != nil {\n+\t\t\tr.Errorf(\"listCDNKeys got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"listCdnKeys got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"listCDNKeys got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// Update an existing CDN key.\n+\tupdatedAkamaiTokenKey, err := getUUID64()\n+\tif err != nil {\n+\t\tt.Fatalf(\"uuid err: %v\", err)\n+\t}\n+\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, akamaiCdnKeyID)\n-\t\tif err := updateCdnKey(buf, tc.ProjectID, akamaiCdnKeyID, updatedHostname, \"\", \"\", updatedPrivateKey); err != nil {\n-\t\t\tr.Errorf(\"updateCdnKey got err: %v\", err)\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, akamaiCDNKeyID)\n+\t\tif err := updateCDNKeyAkamai(buf, tc.ProjectID, akamaiCDNKeyID, updatedHostname, updatedAkamaiTokenKey); err != nil {\n+\t\t\tr.Errorf(\"updateCDNKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"updateCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"updateCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// Get the updated CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, akamaiCdnKeyID)\n-\t\tif err := getCdnKey(buf, tc.ProjectID, akamaiCdnKeyID); err != nil {\n-\t\t\tr.Errorf(\"getCdnKey got err: %v\", err)\n+\t\tcdnKeyName := fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", tc.ProjectID, location, akamaiCDNKeyID)\n+\t\tif err := getCDNKey(buf, tc.ProjectID, akamaiCDNKeyID); err != nil {\n+\t\t\tr.Errorf(\"getCDNKey got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, cdnKeyName) {\n-\t\t\tr.Errorf(\"getCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n+\t\t\tr.Errorf(\"getCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, cdnKeyName)\n \t\t}\n \t})\n \n \t// Delete the CDN key.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n-\t\tif err := deleteCdnKey(buf, tc.ProjectID, akamaiCdnKeyID); err != nil {\n-\t\t\tr.Errorf(\"deleteCdnKey got err: %v\", err)\n+\t\tif err := deleteCDNKey(buf, tc.ProjectID, akamaiCDNKeyID); err != nil {\n+\t\t\tr.Errorf(\"deleteCDNKey got err: %v\", err)\n \t\t}\n-\t\tif got := buf.String(); !strings.Contains(got, deleteCdnKeyResponse) {\n-\t\t\tr.Errorf(\"deleteCdnKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteCdnKeyResponse)\n+\t\tif got := buf.String(); !strings.Contains(got, deleteCDNKeyResponse) {\n+\t\t\tr.Errorf(\"deleteCDNKey got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteCDNKeyResponse)\n \t\t}\n \t})\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -317,12 +414,12 @@\nfunc TestVodSessions(t *testing.T) {\n \t// Create a new VOD session.\n \tsessionPrefix := fmt.Sprintf(\"projects/%s/locations/%s/vodSessions/\", projectNumber, location)\n \tif err := createVodSession(buf, tc.ProjectID, vodURI); err != nil {\n-\t\tt.Errorf(\"createVodSession got err: %v\", err)\n+\t\tt.Fatalf(\"createVodSession got err: %v\", err)\n \t}\n \tgot := buf.String()\n \n \tif !strings.Contains(got, sessionPrefix) {\n-\t\tt.Errorf(\"createVodSession got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, sessionPrefix)\n+\t\tt.Fatalf(\"createVodSession got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, sessionPrefix)\n \t}\n \tstrSlice := strings.Split(got, \"/\")\n \tsessionID = strSlice[len(strSlice)-1]",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -426,23 +523,23 @@\nfunc TestLiveSessions(t *testing.T) {\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tslateName := fmt.Sprintf(\"projects/%s/locations/%s/slates/%s\", projectNumber, location, slateID)\n \t\tif err := createSlate(buf, tc.ProjectID, slateID, slateURI); err != nil {\n-\t\t\tr.Errorf(\"createSlate got err: %v\", err)\n+\t\t\tt.Fatalf(\"createSlate got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, slateName) {\n-\t\t\tr.Errorf(\"createSlate got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, slateName)\n+\t\t\tt.Fatalf(\"createSlate got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, slateName)\n \t\t}\n \t})\n \tbuf.Reset()\n \n \t// Create a new live session and return the play URI.\n \tsessionPrefix := fmt.Sprintf(\"projects/%s/locations/%s/liveSessions/\", projectNumber, location)\n \tif err := createLiveSession(buf, tc.ProjectID, liveURI, slateID); err != nil {\n-\t\tt.Errorf(\"createLiveSession got err: %v\", err)\n+\t\tt.Fatalf(\"createLiveSession got err: %v\", err)\n \t}\n \tgot := buf.String()\n \n \tif !strings.Contains(got, sessionPrefix) {\n-\t\tt.Errorf(\"createLiveSession got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, sessionPrefix)\n+\t\tt.Fatalf(\"createLiveSession got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, sessionPrefix)\n \t}\n \tbuf.Reset()",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/update_cdn_key.go",
        "code_diff": "@@ -25,14 +25,17 @@\nimport (\n \t\"google.golang.org/protobuf/types/known/fieldmaskpb\"\n )\n \n-// updateCdnKey updates a CDN key.\n-func updateCdnKey(w io.Writer, projectID, cdnKeyID, hostname, gcdnKeyname, gcdnPrivateKey, akamaiTokenKey string) error {\n+// updateCDNKey updates a CDN key. A CDN key is used to retrieve protected media.\n+// If isMediaCDN is true, update a Media CDN key. If false, update a Cloud\n+// CDN key. To create an updated privateKey value for Media CDN, see\n+// https://cloud.google.com/video-stitcher/docs/how-to/managing-cdn-keys#create-private-key-media-cdn.\n+func updateCDNKey(w io.Writer, projectID, keyID, hostname, keyName, privateKey string, isMediaCDN bool) error {\n \t// projectID := \"my-project-id\"\n-\t// cdnKeyID := \"my-cdn-key\"\n-\t// hostname := \"cdn.example.com\"\n-\t// gcdnKeyname := \"gcdn-key\"\n-\t// gcdnPrivateKey := \"VGhpcyBpcyBhIHRlc3Qgc3RyaW5nLg==\"\n-\t// akamaiTokenKey := \"VGhpcyBpcyBhIHRlc3Qgc3RyaW5nLg==\"\n+\t// keyID := \"my-cdn-key\"\n+\t// hostname := \"updated.cdn.example.com\"\n+\t// keyName := \"cdn-key\"\n+\t// privateKey := \"my-updated-private-key\"\n+\t// isMediaCDN := true\n \tlocation := \"us-central1\"\n \tctx := context.Background()\n \tclient, err := stitcher.NewVideoStitcherClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(Video Stitcher): Add Media CDN samples. Move Akamai sample to its own file",
        "pr_number": 2790,
        "file_name": "media/videostitcher/update_cdn_key.go",
        "code_diff": "@@ -42,20 +45,21 @@\nfunc updateCdnKey(w io.Writer, projectID, cdnKeyID, hostname, gcdnKeyname, gcdnP\n \tdefer client.Close()\n \n \tvar req *stitcherpb.UpdateCdnKeyRequest\n-\tif akamaiTokenKey != \"\" {\n+\tif isMediaCDN {\n \t\treq = &stitcherpb.UpdateCdnKeyRequest{\n \t\t\tCdnKey: &stitcherpb.CdnKey{\n-\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_AkamaiCdnKey{\n-\t\t\t\t\tAkamaiCdnKey: &stitcherpb.AkamaiCdnKey{\n-\t\t\t\t\t\tTokenKey: []byte(akamaiTokenKey),\n+\t\t\t\tCdnKeyConfig: &stitcherpb.CdnKey_MediaCdnKey{\n+\t\t\t\t\tMediaCdnKey: &stitcherpb.MediaCdnKey{\n+\t\t\t\t\t\tKeyName:    keyName,\n+\t\t\t\t\t\tPrivateKey: []byte(privateKey),\n \t\t\t\t\t},\n \t\t\t\t},\n-\t\t\t\tName:     fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectID, location, cdnKeyID),\n+\t\t\t\tName:     fmt.Sprintf(\"projects/%s/locations/%s/cdnKeys/%s\", projectID, location, keyID),\n \t\t\t\tHostname: hostname,\n \t\t\t},\n \t\t\tUpdateMask: &fieldmaskpb.FieldMask{\n \t\t\t\tPaths: []string{\n-\t\t\t\t\t\"hostname\", \"akamai_cdn_key\",\n+\t\t\t\t\t\"hostname\", \"media_cdn_key\",\n \t\t\t\t},\n \t\t\t},\n \t\t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d1a073cd1e2d9bee8ec563b1c2411e73a3a5eca5"
    },
    {
        "pr_title": "feat(compute): Regional and encrypted disk samples",
        "pr_number": 2787,
        "file_name": "compute/disks/create_disk_from_snapshot.go",
        "code_diff": "@@ -29,17 +29,19 @@\nimport (\n func createDiskFromSnapshot(\n \tw io.Writer,\n \tprojectID, zone, diskName, diskType, snapshotLink string,\n+\tdiskSizeGb int64,\n ) error {\n \t// projectID := \"your_project_id\"\n-\t// zone := \"europe-central2-b\"\n+\t// zone := \"us-west3-b\" // should match diskType below\n \t// diskName := \"your_disk_name\"\n \t// diskType := \"zones/us-west3-b/diskTypes/pd-ssd\"\n-\t// snapshotLink := \"projects/project_name/global/snapshots/snapshot_name\"\n+\t// snapshotLink := \"projects/your_project_id/global/snapshots/snapshot_name\"\n+\t// diskSizeGb := 120\n \n \tctx := context.Background()\n \tdisksClient, err := compute.NewDisksRESTClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewDisksRESTClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewDisksRESTClient: %w\", err)\n \t}\n \tdefer disksClient.Close()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0df195aca584328b35c0fde39a7e7354f1a7ffc4"
    },
    {
        "pr_title": "feat(compute): Regional and encrypted disk samples",
        "pr_number": 2787,
        "file_name": "compute/disks/create_empty_disk.go",
        "code_diff": "@@ -29,16 +29,18 @@\nimport (\n func createEmptyDisk(\n \tw io.Writer,\n \tprojectID, zone, diskName, diskType string,\n+\tdiskSizeGb int64,\n ) error {\n \t// projectID := \"your_project_id\"\n-\t// zone := \"europe-central2-b\"\n+\t// zone := \"us-west3-b\" // should match diskType below\n \t// diskName := \"your_disk_name\"\n \t// diskType := \"zones/us-west3-b/diskTypes/pd-ssd\"\n+\t// diskSizeGb := 120\n \n \tctx := context.Background()\n \tdisksClient, err := compute.NewDisksRESTClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewDisksRESTClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewDisksRESTClient: %w\", err)\n \t}\n \tdefer disksClient.Close()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0df195aca584328b35c0fde39a7e7354f1a7ffc4"
    },
    {
        "pr_title": "feat(compute): Regional and encrypted disk samples",
        "pr_number": 2787,
        "file_name": "compute/disks/delete_disk.go",
        "code_diff": "@@ -27,13 +27,13 @@\nimport (\n // deleteDisk deletes a disk from a project.\n func deleteDisk(w io.Writer, projectID, zone, diskName string) error {\n \t// projectID := \"your_project_id\"\n-\t// zone := \"europe-central2-b\"\n+\t// zone := \"us-west3-b\"\n \t// diskName := \"your_disk_name\"\n \n \tctx := context.Background()\n \tdisksClient, err := compute.NewDisksRESTClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewDisksRESTClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewDisksRESTClient: %w\", err)\n \t}\n \tdefer disksClient.Close()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0df195aca584328b35c0fde39a7e7354f1a7ffc4"
    },
    {
        "pr_title": "feat(compute): Regional and encrypted disk samples",
        "pr_number": 2787,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -29,29 +29,6 @@\nimport (\n \t\"google.golang.org/protobuf/proto\"\n )\n \n-func createDisk(ctx context.Context, projectId, zone, diskName, sourceImage string) error {\n-\tdisksClient, err := compute.NewDisksRESTClient(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tdefer disksClient.Close()\n-\treq := &computepb.InsertDiskRequest{\n-\t\tProject: projectId,\n-\t\tZone:    zone,\n-\t\tDiskResource: &computepb.Disk{\n-\t\t\tName:        proto.String(diskName),\n-\t\t\tSourceImage: proto.String(sourceImage),\n-\t\t},\n-\t}\n-\n-\top, err := disksClient.Insert(ctx, req)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\treturn op.Wait(ctx)\n-}\n-\n func getInstance(\n \tctx context.Context,\n \tprojectID, zone, instanceName string,",
        "comments": [],
        "commit_messages": [
            "Add tests for regional disks"
        ],
        "last_commit_sha": "0df195aca584328b35c0fde39a7e7354f1a7ffc4"
    },
    {
        "pr_title": "feat(compute): Regional and encrypted disk samples",
        "pr_number": 2787,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -138,14 +115,16 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\trand.NewSource(time.Now().UnixNano()))\n \ttc := testutil.SystemTest(t)\n \tzone := \"europe-central2-b\"\n+\tregion := \"europe-central2\"\n+\treplicaZones := []string{\"europe-central2-a\", \"europe-central2-b\"}\n \tinstanceName := fmt.Sprintf(\"test-instance-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tdiskName := fmt.Sprintf(\"test-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tdiskName2 := fmt.Sprintf(\"test-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tsnapshotName := fmt.Sprintf(\"test-snapshot-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tsourceImage := \"projects/debian-cloud/global/images/family/debian-11\"\n+\tsourceDisk := fmt.Sprintf(\"projects/%s/zones/europe-central2-b/disks/%s\", tc.ProjectID, diskName)\n \tdiskType := fmt.Sprintf(\"zones/%s/diskTypes/pd-ssd\", zone)\n \tdiskSnapshotLink := fmt.Sprintf(\"projects/%s/global/snapshots/%s\", tc.ProjectID, snapshotName)\n-\twant := \"Disk created\"\n \n \tinstancesClient, err := compute.NewInstancesRESTClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0df195aca584328b35c0fde39a7e7354f1a7ffc4"
    },
    {
        "pr_title": "feat(compute): Regional and encrypted disk samples",
        "pr_number": 2787,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -154,39 +133,99 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \n \tdefer instancesClient.Close()\n \n+\t// Create a snapshot before we run the actual tests\n \tbuf := &bytes.Buffer{}\n+\terr = createDiskFromImage(buf, tc.ProjectID, zone, diskName, diskType, sourceImage, 50)\n+\tif err != nil {\n+\t\tt.Fatalf(\"createDiskFromImage got err: %v\", err)\n+\t}\n+\terr = createDiskSnapshot(ctx, tc.ProjectID, zone, diskName, snapshotName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"createDiskSnapshot got err: %v\", err)\n+\t}\n \n-\tt.Run(\"createDiskSnapshot and deleteDisk\", func(t *testing.T) {\n-\t\terr := createDisk(ctx, tc.ProjectID, zone, diskName, sourceImage)\n-\t\tif err != nil {\n-\t\t\tt.Fatalf(\"createDisk got err: %v\", err)\n-\t\t}\n-\n-\t\terr = createDiskSnapshot(ctx, tc.ProjectID, zone, diskName, snapshotName)\n-\t\tif err != nil {\n-\t\t\tt.Fatalf(\"createDiskSnapshot got err: %v\", err)\n-\t\t}\n+\tt.Run(\"Create zonal disk from a snapshot\", func(t *testing.T) {\n+\t\tbuf := &bytes.Buffer{}\n+\t\twant := \"Disk created\"\n \n-\t\tif err := createDiskFromSnapshot(buf, tc.ProjectID, zone, diskName2, diskType, diskSnapshotLink); err != nil {\n+\t\tif err := createDiskFromSnapshot(buf, tc.ProjectID, zone, diskName2, diskType, diskSnapshotLink, 50); err != nil {\n \t\t\tt.Errorf(\"createDiskFromSnapshot got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"createDiskFromSnapshot got %q, want %q\", got, want)\n \t\t}\n+\t})\n \n-\t\tbuf.Reset()\n-\t\twant = \"Disk deleted\"\n+\tt.Run(\"Delete a disk\", func(t *testing.T) {\n+\t\tbuf := &bytes.Buffer{}\n+\t\twant := \"Disk deleted\"\n \n \t\tif err := deleteDisk(buf, tc.ProjectID, zone, diskName2); err != nil {\n \t\t\tt.Errorf(\"deleteDisk got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"deleteDisk got %q, want %q\", got, want)\n \t\t}\n+\t})\n+\n+\tt.Run(\"Create a regional disk from a snapshot\", func(t *testing.T) {\n+\t\tbuf := &bytes.Buffer{}\n+\t\twant := \"Disk created\"\n+\n+\t\tif err := createRegionalDiskFromSnapshot(buf, tc.ProjectID, region, replicaZones, diskName2, diskType, diskSnapshotLink, 50); err != nil {\n+\t\t\tt.Errorf(\"createRegionalDiskFromSnapshot got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"createRegionalDiskFromSnapshot got %q, want %q\", got, want)\n+\t\t}\n+\t})\n+\n+\tt.Run(\"Delete a zonal disk\", func(t *testing.T) {\n+\t\tbuf := &bytes.Buffer{}\n+\t\twant := \"Disk deleted\"\n+\t\tif err := deleteDisk(buf, tc.ProjectID, zone, diskName); err != nil {\n+\t\t\tt.Errorf(\"deleteDisk got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"deleteRegionalDisk got %q, want %q\", got, want)\n+\t\t}\n+\t})\n+\n+\tt.Run(\"Delete a regional disk\", func(t *testing.T) {\n+\t\tbuf := &bytes.Buffer{}\n+\t\twant := \"Disk deleted\"\n+\n+\t\terr = deleteRegionalDisk(buf, tc.ProjectID, region, diskName2)\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"deleteRegionalDisk got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"deleteRegionalDisk got %q, want %q\", got, want)\n+\t\t}\n+\t})\n+\n+\tt.Run(\"createEmptyDisk and clone it into a regional disk\", func(t *testing.T) {\n+\t\tbuf := &bytes.Buffer{}\n+\t\twant := \"Disk created\"\n+\n+\t\tif err := createEmptyDisk(buf, tc.ProjectID, zone, diskName, diskType, 20); err != nil {\n+\t\t\tt.Fatalf(\"createEmptyDisk got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"createEmptyDisk got %q, want %q\", got, want)\n+\t\t}\n \n-\t\terr = deleteDiskSnapshot(ctx, tc.ProjectID, snapshotName)\n+\t\tif err := createRegionalDiskFromDisk(buf, tc.ProjectID, region, replicaZones, diskName2, diskType, sourceDisk, 30); err != nil {\n+\t\t\tt.Errorf(\"createRegionalDiskFromDisk got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"createRegionalDiskFromDisk got %q, want %q\", got, want)\n+\t\t}\n+\n+\t\t// clean up\n+\t\terr = deleteRegionalDisk(buf, tc.ProjectID, region, diskName2)\n \t\tif err != nil {\n-\t\t\tt.Errorf(\"deleteDiskSnapshot got err: %v\", err)\n+\t\t\tt.Errorf(\"deleteRegionalDisk got err: %v\", err)\n \t\t}\n \n \t\terr = deleteDisk(buf, tc.ProjectID, zone, diskName)",
        "comments": [
            {
                "comment": "This set up step can be moved into `TestMain(m *testing.M)`.",
                "position": 175
            },
            {
                "comment": "This is not setup - this is the test body! It is calling a code sample wrapped into a function and ensuring that it works.",
                "position": 175
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "0df195aca584328b35c0fde39a7e7354f1a7ffc4"
    },
    {
        "pr_title": "feat(compute): Regional and encrypted disk samples",
        "pr_number": 2787,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -195,17 +234,25 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \t\t}\n \t})\n \n-\tt.Run(\"createEmptyDisk\", func(t *testing.T) {\n+\tt.Run(\"create, clone and delete an encrypted disk\", func(t *testing.T) {\n \t\tbuf.Reset()\n-\t\twant = \"Disk created\"\n+\t\twant := \"Disk created\"\n \n-\t\tif err := createEmptyDisk(buf, tc.ProjectID, zone, diskName, diskType); err != nil {\n-\t\t\tt.Fatalf(\"createEmptyDisk got err: %v\", err)\n+\t\tif err := createEncryptedDisk(buf, tc.ProjectID, zone, diskName, diskType, 20, \"SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=\", \"\", \"\", \"\"); err != nil {\n+\t\t\tt.Fatalf(\"createEncryptedDisk got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, want) {\n-\t\t\tt.Errorf(\"createEmptyDisk got %q, want %q\", got, want)\n+\t\t\tt.Errorf(\"createEncryptedDisk got %q, want %q\", got, want)\n+\t\t}\n+\n+\t\tif err := createDiskFromCustomerEncryptedDisk(buf, tc.ProjectID, zone, diskName2, diskType, 20, sourceDisk, \"SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=\"); err != nil {\n+\t\t\tt.Fatalf(\"createDiskFromCustomerEncryptedDisk got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tt.Errorf(\"createDiskFromCustomerEncryptedDisk got %q, want %q\", got, want)\n \t\t}\n \n+\t\t// cleanup\n \t\terr = deleteDisk(buf, tc.ProjectID, zone, diskName)\n \t\tif err != nil {\n \t\t\tt.Errorf(\"deleteDisk got err: %v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0df195aca584328b35c0fde39a7e7354f1a7ffc4"
    },
    {
        "pr_title": "feat(compute): Regional and encrypted disk samples",
        "pr_number": 2787,
        "file_name": "compute/disks/disks_test.go",
        "code_diff": "@@ -214,7 +261,7 @@\nfunc TestComputeDisksSnippets(t *testing.T) {\n \n \tt.Run(\"setDiskAutoDelete\", func(t *testing.T) {\n \t\tbuf.Reset()\n-\t\twant = \"disk autoDelete field updated.\"\n+\t\twant := \"disk autoDelete field updated.\"\n \n \t\treq := &computepb.InsertInstanceRequest{\n \t\t\tProject: tc.ProjectID,",
        "comments": [],
        "commit_messages": [
            "Minor cleanup in tests"
        ],
        "last_commit_sha": "0df195aca584328b35c0fde39a7e7354f1a7ffc4"
    },
    {
        "pr_title": "feat(compute): Regional and encrypted disk samples",
        "pr_number": 2787,
        "file_name": "compute/disks/set_disk_autodelete.go",
        "code_diff": "@@ -30,14 +30,14 @@\nfunc setDiskAutoDelete(\n \tprojectID, zone, instanceName, diskName string,\n ) error {\n \t// projectID := \"your_project_id\"\n-\t// zone := \"europe-central2-b\"\n+\t// zone := \"us-west3-b\"\n \t// instanceName := \"your_instance_name\"\n \t// diskName := \"your_disk_name\"\n \n \tctx := context.Background()\n \tinstancesClient, err := compute.NewInstancesRESTClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewInstancesRESTClient: %v\", err)\n+\t\treturn fmt.Errorf(\"NewInstancesRESTClient: %w\", err)\n \t}\n \tdefer instancesClient.Close()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0df195aca584328b35c0fde39a7e7354f1a7ffc4"
    },
    {
        "pr_title": "feat(compute): Regional and encrypted disk samples",
        "pr_number": 2787,
        "file_name": "compute/disks/set_disk_autodelete.go",
        "code_diff": "@@ -49,7 +49,7 @@\nfunc setDiskAutoDelete(\n \n \tinstance, err := instancesClient.Get(ctx, getInstanceReq)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"unable to get instance: %v\", err)\n+\t\treturn fmt.Errorf(\"unable to get instance: %w\", err)\n \t}\n \n \tdiskExists := false",
        "comments": [],
        "commit_messages": [
            "Replace %v with %w as per review comment"
        ],
        "last_commit_sha": "0df195aca584328b35c0fde39a7e7354f1a7ffc4"
    },
    {
        "pr_title": "feat(kms): Add docs samples for KMS key import.",
        "pr_number": 2779,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2020 Google LLC\n+// Copyright 2023 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "Update kms_test.go"
        ],
        "last_commit_sha": "ea36b7fb332218d20a09e4c69d05a5243f50c336"
    },
    {
        "pr_title": "feat(cloudsql): split out IAM AuthN into separate file",
        "pr_number": 2765,
        "file_name": "cloudsql/postgres/database-sql/connect_connector.go",
        "code_diff": "@@ -12,9 +12,9 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START cloud_sql_postgres_databasesql_connect_connector]\n package cloudsql\n \n+// [START cloud_sql_postgres_databasesql_connect_connector]\n import (\n \t\"context\"\n \t\"database/sql\"",
        "comments": [],
        "commit_messages": [
            "feat(cloudsql): split out IAM AuthN into separate file"
        ],
        "last_commit_sha": "751625202a20a412e65c7a9108fd5becfa44b0e9"
    },
    {
        "pr_title": "feat(spanner): add support for CMMR phase 2",
        "pr_number": 2719,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -573,6 +573,43 @@\nfunc TestCreateDatabaseWithDefaultLeaderSample(t *testing.T) {\n \tassertContains(t, out, \"The result of the query to get\")\n }\n \n+func TestCustomInstanceConfigSample(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\tprojectID := getSampleProjectId(t)\n+\tdefer cleanupInstanceConfigs(projectID)\n+\n+\tvar b bytes.Buffer\n+\tuserConfigID := fmt.Sprintf(\"custom-golang-samples-config-%v\", randomID())\n+\tif err := createInstanceConfig(&b, projectID, userConfigID, \"nam11\"); err != nil {\n+\t\tt.Fatalf(\"failed to create instance configuration: %v\", err)\n+\t}\n+\tout := b.String()\n+\tassertContains(t, out, \"Created instance configuration\")\n+\n+\tb.Reset()\n+\tif err := updateInstanceConfig(&b, projectID, userConfigID); err != nil {\n+\t\tt.Errorf(\"failed to update instance configuration: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, \"Updated instance configuration\")\n+\n+\tb.Reset()\n+\tif err := listInstanceConfigOperations(&b, projectID); err != nil {\n+\t\tt.Errorf(\"failed to list instance configuration operations: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, \"List instance config operations\")\n+\n+\tb.Reset()\n+\tif err := deleteInstanceConfig(&b, projectID, userConfigID); err != nil {\n+\t\tt.Errorf(\"failed to delete instance configuration: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, \"Deleted instance configuration\")\n+}\n+\n func TestPgSample(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n \tt.Parallel()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d68199a245d10bc794bee67d67e1b1aaa377bd83"
    },
    {
        "pr_title": "feat: Add snippets for Spanner DML with returning clause",
        "pr_number": 2713,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -251,6 +251,9 @@\nfunc TestSample(t *testing.T) {\n \tout = runSample(t, insertUsingDML, dbName, \"failed to insert using DML\")\n \tassertContains(t, out, \"record(s) inserted\")\n \n+\tout = runSample(t, insertUsingDMLReturning, dbName, \"failed to insert using DML with returning clause\")\n+\tassertContains(t, out, \"record(s) inserted\")\n+\n \tout = runSample(t, insertUsingDMLRequestPriority, dbName, \"failed to insert using DML with RequestPriority\")\n \tassertContains(t, out, \"record(s) inserted\")",
        "comments": [],
        "commit_messages": [
            "feat: Add snippets for Spanner DML with returning clause\n\nSamples are provided for INSERT, DELETE, and UPDATE in both GoogleSQL\nand PostgreSQL dialects. To provide a more compelling example for the\nINSERT case, a generated column has been added in the \"create_database\"\nexample so that the generated value can be returned in the INSERT\nexamples. This changed the number of mutations generated for inserts to\nthe Artists table, and the commitStats test case was updated as a\nresult."
        ],
        "last_commit_sha": "91d495440a75d7d05ceeb48572cba6ee752b6f2d"
    },
    {
        "pr_title": "feat: Add snippets for Spanner DML with returning clause",
        "pr_number": 2713,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -260,9 +263,15 @@\nfunc TestSample(t *testing.T) {\n \tout = runSample(t, updateUsingDML, dbName, \"failed to update using DML\")\n \tassertContains(t, out, \"record(s) updated\")\n \n+\tout = runSample(t, updateUsingDMLReturning, dbName, \"failed to update using DML with returning clause\")\n+\tassertContains(t, out, \"record(s) updated\")\n+\n \tout = runSample(t, deleteUsingDML, dbName, \"failed to delete using DML\")\n \tassertContains(t, out, \"record(s) deleted\")\n \n+\tout = runSample(t, deleteUsingDMLReturning, dbName, \"failed to delete using DML with returning clause\")\n+\tassertContains(t, out, \"record(s) deleted\")\n+\n \tout = runSample(t, updateUsingDMLWithTimestamp, dbName, \"failed to update using DML with timestamp\")\n \tassertContains(t, out, \"record(s) updated\")",
        "comments": [],
        "commit_messages": [
            "feat: Add snippets for Spanner DML with returning clause\n\nSamples are provided for INSERT, DELETE, and UPDATE in both GoogleSQL\nand PostgreSQL dialects. To provide a more compelling example for the\nINSERT case, a generated column has been added in the \"create_database\"\nexample so that the generated value can be returned in the INSERT\nexamples. This changed the number of mutations generated for inserts to\nthe Artists table, and the commitStats test case was updated as a\nresult."
        ],
        "last_commit_sha": "91d495440a75d7d05ceeb48572cba6ee752b6f2d"
    },
    {
        "pr_title": "feat: Add snippets for Spanner DML with returning clause",
        "pr_number": 2713,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -276,7 +285,7 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"record(s) inserted\")\n \n \tout = runSample(t, commitStats, dbName, \"failed to request commit stats\")\n-\tassertContains(t, out, \"3 mutations in transaction\")\n+\tassertContains(t, out, \"4 mutations in transaction\")\n \n \tout = runSample(t, queryWithParameter, dbName, \"failed to query with parameter\")\n \tassertContains(t, out, \"12 Melissa Garcia\")",
        "comments": [],
        "commit_messages": [
            "feat: Add snippets for Spanner DML with returning clause\n\nSamples are provided for INSERT, DELETE, and UPDATE in both GoogleSQL\nand PostgreSQL dialects. To provide a more compelling example for the\nINSERT case, a generated column has been added in the \"create_database\"\nexample so that the generated value can be returned in the INSERT\nexamples. This changed the number of mutations generated for inserts to\nthe Artists table, and the commitStats test case was updated as a\nresult."
        ],
        "last_commit_sha": "91d495440a75d7d05ceeb48572cba6ee752b6f2d"
    },
    {
        "pr_title": "feat: Add snippets for Spanner DML with returning clause",
        "pr_number": 2713,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -654,8 +663,17 @@\nfunc TestPgDmlSample(t *testing.T) {\n \t\t`CREATE TABLE Singers (\n \t\t   SingerId  bigint NOT NULL PRIMARY KEY,\n \t\t   FirstName varchar(1024),\n-\t\t   LastName  varchar(1024)\n-\t\t )`)\n+\t\t   LastName  varchar(1024),\n+\t\t   FullName  varchar(2048)\n+\t\t     GENERATED ALWAYS AS (FirstName || ' ' || LastName) STORED\n+\t\t )`,\n+\t\t`CREATE TABLE Albums (\n+\t\t\tSingerId         bigint NOT NULL,\n+\t\t\tAlbumId          bigint NOT NULL,\n+\t\t\tAlbumTitle       varchar(1024),\n+\t\t\tMarketingBudget  bigint,\n+\t\t\tPRIMARY KEY (SingerId, AlbumId)\n+\t\t) INTERLEAVE IN PARENT Singers ON DELETE CASCADE`)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create test database: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "feat: Add snippets for Spanner DML with returning clause\n\nSamples are provided for INSERT, DELETE, and UPDATE in both GoogleSQL\nand PostgreSQL dialects. To provide a more compelling example for the\nINSERT case, a generated column has been added in the \"create_database\"\nexample so that the generated value can be returned in the INSERT\nexamples. This changed the number of mutations generated for inserts to\nthe Artists table, and the commitStats test case was updated as a\nresult."
        ],
        "last_commit_sha": "91d495440a75d7d05ceeb48572cba6ee752b6f2d"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -19,29 +19,36 @@\n// projection (limiting the output to a subset of a table's columns),\n // column filtering (using simple predicates to filter records on the server\n // side), establishing the snapshot time (reading data from the table at a\n-// specific point in time), and decoding Avro row blocks using the third party\n-// \"github.com/linkedin/goavro\" library.\n+// specific point in time), decoding Avro row blocks using the third party\n+// \"github.com/linkedin/goavro\" library, and decoding Arrow row blocks using\n+// the third party \"github.com/apache/arrow/go\" library.\n package main\n \n import (\n+\t\"bytes\"\n \t\"context\"\n+\t\"encoding/json\"\n \t\"flag\"\n \t\"fmt\"\n \t\"io\"\n \t\"log\"\n \t\"sort\"\n+\t\"strings\"\n \t\"sync\"\n \t\"time\"\n \n \tbqStorage \"cloud.google.com/go/bigquery/storage/apiv1\"\n-\t\"github.com/golang/protobuf/ptypes\"\n+\t\"github.com/apache/arrow/go/v10/arrow\"\n+\t\"github.com/apache/arrow/go/v10/arrow/ipc\"\n+\t\"github.com/apache/arrow/go/v10/arrow/memory\"\n \tgax \"github.com/googleapis/gax-go/v2\"\n \tgoavro \"github.com/linkedin/goavro/v2\"\n \tbqStoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1\"\n \t\"google.golang.org/genproto/googleapis/rpc/errdetails\"\n \t\"google.golang.org/grpc\"\n \t\"google.golang.org/grpc/codes\"\n \t\"google.golang.org/grpc/status\"\n+\t\"google.golang.org/protobuf/types/known/timestamppb\"\n )\n \n // rpcOpts is used to configure the underlying gRPC client to accept large",
        "comments": [],
        "commit_messages": [
            "feat(bigquery): add arrow row format example"
        ],
        "last_commit_sha": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -51,12 +58,19 @@\nvar rpcOpts = gax.WithGRPCOptions(\n \tgrpc.MaxCallRecvMsgSize(1024 * 1024 * 129),\n )\n \n+// Available formats\n+const (\n+\tAVRO_FORMAT  = \"avro\"\n+\tARROW_FORMAT = \"arrow\"\n+)\n+\n // Command-line flags.\n var (\n \tprojectID = flag.String(\"project_id\", \"\",\n \t\t\"Cloud Project ID, used for session creation.\")\n \tsnapshotMillis = flag.Int64(\"snapshot_millis\", 0,\n \t\t\"Snapshot time to use for reads, represented in epoch milliseconds format.  Default behavior reads current data.\")\n+\tformat = flag.String(\"format\", AVRO_FORMAT, \"format to read data from storage API. Default is avro.\")\n )\n \n func main() {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -92,22 +106,24 @@\nfunc main() {\n \t\tRowRestriction: `state = \"WA\"`,\n \t}\n \n+\tdataFormat := bqStoragepb.DataFormat_AVRO\n+\tif *format == ARROW_FORMAT {\n+\t\tdataFormat = bqStoragepb.DataFormat_ARROW\n+\t}\n \tcreateReadSessionRequest := &bqStoragepb.CreateReadSessionRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s\", *projectID),\n \t\tReadSession: &bqStoragepb.ReadSession{\n-\t\t\tTable: readTable,\n-\t\t\t// This API can also deliver data serialized in Apache Arrow format.\n-\t\t\t// This example leverages Apache Avro.\n-\t\t\tDataFormat:  bqStoragepb.DataFormat_AVRO,\n+\t\t\tTable:       readTable,\n+\t\t\tDataFormat:  dataFormat,\n \t\t\tReadOptions: tableReadOptions,\n \t\t},\n \t\tMaxStreamCount: 1,\n \t}\n \n \t// Set a snapshot time if it's been specified.\n \tif *snapshotMillis > 0 {\n-\t\tts, err := ptypes.TimestampProto(time.Unix(0, *snapshotMillis*1000))\n-\t\tif err != nil {\n+\t\tts := timestamppb.New(time.Unix(0, *snapshotMillis*1000))\n+\t\tif !ts.IsValid() {\n \t\t\tlog.Fatalf(\"Invalid snapshot millis (%d): %v\", *snapshotMillis, err)\n \t\t}\n \t\tcreateReadSessionRequest.ReadSession.TableModifiers = &bqStoragepb.ReadSession_TableModifiers{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -132,7 +148,7 @@\nfunc main() {\n \t// increasing the MaxStreamCount.\n \treadStream := session.GetStreams()[0].Name\n \n-\tch := make(chan *bqStoragepb.AvroRows)\n+\tch := make(chan *bqStoragepb.ReadRowsResponse)\n \n \t// Use a waitgroup to coordinate the reading and decoding goroutines.\n \tvar wg sync.WaitGroup",
        "comments": [],
        "commit_messages": [
            "feat(bigquery): add arrow row format example"
        ],
        "last_commit_sha": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -151,9 +167,15 @@\nfunc main() {\n \twg.Add(1)\n \tgo func() {\n \t\tdefer wg.Done()\n-\t\terr := processAvro(ctx, session.GetAvroSchema().GetSchema(), ch)\n+\t\tvar err error\n+\t\tswitch *format {\n+\t\tcase ARROW_FORMAT:\n+\t\t\terr = processArrow(ctx, session.GetArrowSchema().GetSerializedSchema(), ch)\n+\t\tcase AVRO_FORMAT:\n+\t\t\terr = processAvro(ctx, session.GetAvroSchema().GetSchema(), ch)\n+\t\t}\n \t\tif err != nil {\n-\t\t\tlog.Fatalf(\"Error processing avro: %v\", err)\n+\t\t\tlog.Fatalf(\"error processing %s: %v\", *format, err)\n \t\t}\n \t}()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -183,6 +205,39 @@\nfunc printDatum(d interface{}) {\n \tfmt.Println()\n }\n \n+// printRecordBatch prints the arrow record batch\n+func printRecordBatch(record arrow.Record) error {\n+\tout, err := record.MarshalJSON()\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tlist := []map[string]interface{}{}\n+\terr = json.Unmarshal(out, &list)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif len(list) == 0 {\n+\t\treturn nil\n+\t}\n+\tfirst := list[0]\n+\tkeys := make([]string, len(first))\n+\ti := 0\n+\tfor k := range first {\n+\t\tkeys[i] = k\n+\t\ti++\n+\t}\n+\tsort.Strings(keys)\n+\tbuilder := strings.Builder{}\n+\tfor _, m := range list {\n+\t\tfor _, key := range keys {\n+\t\t\tbuilder.WriteString(fmt.Sprintf(\"%s: %-20v \", key, m[key]))\n+\t\t}\n+\t\tbuilder.WriteString(\"\\n\")\n+\t}\n+\tfmt.Print(builder.String())\n+\treturn nil\n+}\n+\n // valueFromTypeMap returns the first value/key in the type map.  This function\n // is only suitable for simple schemas, as complex typing such as arrays and\n // records necessitate a more robust implementation.  See the goavro library",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -199,17 +254,16 @@\nfunc valueFromTypeMap(field interface{}) interface{} {\n \treturn nil\n }\n \n-// processStream reads rows from a single storage Stream, and sends the Avro\n+// processStream reads rows from a single storage Stream, and sends the Storage Response\n // data blocks to a channel. This function will retry on transient stream\n // failures and bookmark progress to avoid re-reading data that's already been\n // successfully transmitted.\n-func processStream(ctx context.Context, client *bqStorage.BigQueryReadClient, st string, ch chan<- *bqStoragepb.AvroRows) error {\n+func processStream(ctx context.Context, client *bqStorage.BigQueryReadClient, st string, ch chan<- *bqStoragepb.ReadRowsResponse) error {\n \tvar offset int64\n \n \t// Streams may be long-running.  Rather than using a global retry for the\n \t// stream, implement a retry that resets once progress is made.\n \tretryLimit := 3\n-\n \tretries := 0\n \tfor {\n \t\t// Send the initiating request to start streaming row blocks.",
        "comments": [],
        "commit_messages": [
            "feat(bigquery): add arrow row format example"
        ],
        "last_commit_sha": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -218,7 +272,7 @@\nfunc processStream(ctx context.Context, client *bqStorage.BigQueryReadClient, st\n \t\t\tOffset:     offset,\n \t\t}, rpcOpts)\n \t\tif err != nil {\n-\t\t\treturn fmt.Errorf(\"Couldn't invoke ReadRows: %v\", err)\n+\t\t\treturn fmt.Errorf(\"couldn't invoke ReadRows: %v\", err)\n \t\t}\n \n \t\t// Process the streamed responses.",
        "comments": [],
        "commit_messages": [
            "feat(bigquery): add arrow row format example"
        ],
        "last_commit_sha": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -266,7 +320,49 @@\nfunc processStream(ctx context.Context, client *bqStorage.BigQueryReadClient, st\n \t\t\t\toffset = offset + rc\n \t\t\t\t// We're making progress, reset retries.\n \t\t\t\tretries = 0\n-\t\t\t\tch <- r.GetAvroRows()\n+\t\t\t\tch <- r\n+\t\t\t}\n+\t\t}\n+\t}\n+}\n+\n+// processArrow receives row blocks from a channel, and uses the provided Arrow\n+// schema to decode the blocks into individual row messages for printing.  Will\n+// continue to run until the channel is closed or the provided context is\n+// cancelled.\n+func processArrow(ctx context.Context, schema []byte, ch <-chan *bqStoragepb.ReadRowsResponse) error {\n+\tmem := memory.NewGoAllocator()\n+\tbuf := bytes.NewBuffer(schema)\n+\tr, err := ipc.NewReader(buf, ipc.WithAllocator(mem))\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\taschema := r.Schema()\n+\tfor {\n+\t\tselect {\n+\t\tcase <-ctx.Done():\n+\t\t\t// Context was cancelled.  Stop.\n+\t\t\treturn ctx.Err()\n+\t\tcase rows, ok := <-ch:\n+\t\t\tif !ok {\n+\t\t\t\t// Channel closed, no further arrow messages.  Stop.\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t\tundecoded := rows.GetArrowRecordBatch().GetSerializedRecordBatch()\n+\t\t\tif len(undecoded) > 0 {\n+\t\t\t\tbuf = bytes.NewBuffer(schema)\n+\t\t\t\tbuf.Write(undecoded)\n+\t\t\t\tr, err = ipc.NewReader(buf, ipc.WithAllocator(mem), ipc.WithSchema(aschema))\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tfor r.Next() {\n+\t\t\t\t\trec := r.Record()\n+\t\t\t\t\terr = printRecordBatch(rec)\n+\t\t\t\t\tif err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t}\n \t\t\t}\n \t\t}\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "feat(bigquery): add arrow row format example",
        "pr_number": 2710,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -276,7 +372,7 @@\nfunc processStream(ctx context.Context, client *bqStorage.BigQueryReadClient, st\n // schema to decode the blocks into individual row messages for printing.  Will\n // continue to run until the channel is closed or the provided context is\n // cancelled.\n-func processAvro(ctx context.Context, schema string, ch <-chan *bqStoragepb.AvroRows) error {\n+func processAvro(ctx context.Context, schema string, ch <-chan *bqStoragepb.ReadRowsResponse) error {\n \t// Establish a decoder that can process blocks of messages using the\n \t// reference schema. All blocks share the same schema, so the decoder\n \t// can be long-lived.",
        "comments": [],
        "commit_messages": [
            "feat(bigquery): add arrow row format example"
        ],
        "last_commit_sha": "1da1b3088e0db924ccfad402108131ca0daabd0b"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/bqtestutil/bqtestutil.go",
        "code_diff": "@@ -26,7 +26,7 @@\nimport (\n func UniqueBQName(prefix string) (string, error) {\n \tu, err := uuid.NewV4()\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"failed to generate bq uuid: %v\", err)\n+\t\treturn \"\", fmt.Errorf(\"failed to generate bq uuid: %w\", err)\n \t}\n \treturn fmt.Sprintf(\"%s_%s\", sanitize(prefix, \"_\"), sanitize(u.String(), \"_\")), nil\n }",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_clustered.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importClusteredTable(projectID, destDatasetID, destTableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_avro.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc importAvro(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_avro_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importAvroTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_csv.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importCSVExplicitSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_csv_autodetect.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importCSVAutodetectSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_csv_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importCSVTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_hivepartitioning.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importWithHivePartitioning(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONExplicitSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json_autodetect.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONAutodetectSchema(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json_cmek.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONWithCMEK(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_json_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importJSONTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_orc.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc importORC(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_orc_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importORCTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_parquet.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc importParquet(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_gcs_parquet_truncate.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc importParquetTruncate(projectID, datasetID, tableID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/loadingdata/bigquery_load_table_partitioned.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc importPartitionedTable(projectID, destDatasetID, destTableID string) error\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -93,7 +93,7 @@\nfunc generateExampleMessages(numMessages int) ([][]byte, error) {\n \n \t\tb, err := proto.Marshal(m)\n \t\tif err != nil {\n-\t\t\treturn nil, fmt.Errorf(\"error generating message %d: %v\", i, err)\n+\t\t\treturn nil, fmt.Errorf(\"error generating message %d: %w\", i, err)\n \t\t}\n \t\tmsgs[i] = b\n \t}",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -111,7 +111,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// Instantiate a managedwriter client to handle interactions with the service.\n \tclient, err := managedwriter.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"managedwriter.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"managedwriter.NewClient: %w\", err)\n \t}\n \t// Close the client when we exit the function.\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -124,7 +124,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t\t},\n \t})\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"CreateWriteStream: %v\", err)\n+\t\treturn fmt.Errorf(\"CreateWriteStream: %w\", err)\n \t}\n \n \t// We need to communicate the descriptor of the protocol buffer message we're using, which",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -134,7 +134,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \tm := &exampleproto.SampleData{}\n \tdescriptorProto, err := adapt.NormalizeDescriptor(m.ProtoReflect().Descriptor())\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NormalizeDescriptor: %v\", err)\n+\t\treturn fmt.Errorf(\"NormalizeDescriptor: %w\", err)\n \t}\n \n \t// Instantiate a ManagedStream, which manages low level details like connection state and provides",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -143,13 +143,13 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \tmanagedStream, err := client.NewManagedStream(ctx, managedwriter.WithStreamName(pendingStream.GetName()),\n \t\tmanagedwriter.WithSchemaDescriptor(descriptorProto))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"NewManagedStream: %v\", err)\n+\t\treturn fmt.Errorf(\"NewManagedStream: %w\", err)\n \t}\n \n \t// First, we'll append a single row.\n \trows, err := generateExampleMessages(1)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"generateExampleMessages: %v\", err)\n+\t\treturn fmt.Errorf(\"generateExampleMessages: %w\", err)\n \t}\n \n \t// We'll keep track of the current offset in the stream with curOffset.",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -159,7 +159,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \n \tresult, err := managedStream.AppendRows(ctx, rows, managedwriter.WithOffset(0))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"AppendRows first call error: %v\", err)\n+\t\treturn fmt.Errorf(\"AppendRows first call error: %w\", err)\n \t}\n \tresults = append(results, result)",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -169,11 +169,11 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// This time, we'll append three more rows in a single request.\n \trows, err = generateExampleMessages(3)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"generateExampleMessages: %v\", err)\n+\t\treturn fmt.Errorf(\"generateExampleMessages: %w\", err)\n \t}\n \tresult, err = managedStream.AppendRows(ctx, rows, managedwriter.WithOffset(curOffset))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"AppendRows second call error: %v\", err)\n+\t\treturn fmt.Errorf(\"AppendRows second call error: %w\", err)\n \t}\n \tresults = append(results, result)",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -183,11 +183,11 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// Finally, we'll append two more rows.\n \trows, err = generateExampleMessages(2)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"generateExampleMessages: %v\", err)\n+\t\treturn fmt.Errorf(\"generateExampleMessages: %w\", err)\n \t}\n \tresult, err = managedStream.AppendRows(ctx, rows, managedwriter.WithOffset(curOffset))\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"AppendRows third call error: %v\", err)\n+\t\treturn fmt.Errorf(\"AppendRows third call error: %w\", err)\n \t}\n \tresults = append(results, result)",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -197,7 +197,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t\t// GetResult blocks until we receive a response from the API.\n \t\trecvOffset, err := v.GetResult(ctx)\n \t\tif err != nil {\n-\t\t\treturn fmt.Errorf(\"append %d returned error: %v\", k, err)\n+\t\t\treturn fmt.Errorf(\"append %d returned error: %w\", k, err)\n \t\t}\n \t\tfmt.Fprintf(w, \"Successfully appended data at offset %d.\\n\", recvOffset)\n \t}",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/managedwriter/bigquerystorage_append_rows_pending.go",
        "code_diff": "@@ -206,7 +206,7 @@\nfunc appendToPendingStream(w io.Writer, projectID, datasetID, tableID string) er\n \t// further appends.\n \trowCount, err := managedStream.Finalize(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"error during Finalize: %v\", err)\n+\t\treturn fmt.Errorf(\"error during Finalize: %w\", err)\n \t}\n \n \tfmt.Fprintf(w, \"Stream %s finalized with %d rows.\\n\", managedStream.StreamName(), rowCount)",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryBasic(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query_clustered_table.go",
        "code_diff": "@@ -32,7 +32,7 @@\nfunc queryClusteredTable(w io.Writer, projectID, datasetID, tableID string) erro\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query_destination_table.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc queryWithDestination(w io.Writer, projectID, destDatasetID, destTableID str\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query_destination_table_cmek.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc queryWithDestinationCMEK(w io.Writer, projectID, dstDatasetID, dstTableID s\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query_legacy.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryLegacy(w io.Writer, projectID, sqlString string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query_legacy_large_results.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc queryLegacyLargeResults(w io.Writer, projectID, datasetID, tableID string)\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query_no_cache.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryDisableCache(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_arrays.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryWithArrayParams(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_named.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryWithNamedParams(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_positional.go",
        "code_diff": "@@ -30,7 +30,7 @@\nfunc queryWithPositionalParams(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_structs.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryWithStructParam(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/querying/bigquery_query_params_timestamps.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc queryWithTimestampParam(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/routine/bigquery_list_routines.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc listRoutines(w io.Writer, projectID, datasetID string) error {\n \n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/routine/bigquery_update_routine.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc updateRoutine(projectID, datasetID, routineID string) error {\n \n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/routine/bigquery_update_routine.go",
        "code_diff": "@@ -40,7 +40,7 @@\nfunc updateRoutine(projectID, datasetID, routineID string) error {\n \t// fetch existing metadata\n \tmeta, err := routineRef.Metadata(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"couldn't retrieve metadata: %v\", err)\n+\t\treturn fmt.Errorf(\"couldn't retrieve metadata: %w\", err)\n \t}\n \n \t// Due to a limitation in the backend, supply all the properties for update.",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/table/bigquery_create_table_external_hivepartitioned.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc createTableExternalHivePartitioned(projectID, datasetID, tableID string) er\n \n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [
            "chore(bigquery): wrap go errors"
        ],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "chore(bigquery): wrap go errors",
        "pr_number": 2701,
        "file_name": "bigquery/snippets/table/bigquery_update_materialized_view.go",
        "code_diff": "@@ -31,15 +31,15 @@\nfunc updateMaterializedView(projectID, datasetID, viewID string) error {\n \tctx := context.Background()\n \tclient, err := bigquery.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"bigquery.NewClient: %v\", err)\n+\t\treturn fmt.Errorf(\"bigquery.NewClient: %w\", err)\n \t}\n \tdefer client.Close()\n \n \t// Retrieve current view metadata.\n \tviewRef := client.Dataset(datasetID).Table(viewID)\n \tmeta, err := viewRef.Metadata(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"Metadata(): %v\", err)\n+\t\treturn fmt.Errorf(\"couldn't retrieve view metadata: %w\", err)\n \t}\n \n \tif meta.MaterializedView == nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "85d73b5240e3d847ac749e19ce56b1b4d6042c8d"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "translate/v3/translate_text.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage v3\n \n // [START translate_v3_translate_text]\n // [START translate_v3_translate_text_0]\n+// Imports the Google Cloud Translation library\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "docs(translate): add granular markets to v3 translate api for code sample extraction"
        ],
        "last_commit_sha": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "docs(translate): add granular markers to v3 translate api for code sample extraction",
        "pr_number": 2698,
        "file_name": "translate/v3/translate_text.go",
        "code_diff": "@@ -28,21 +29,24 @@\nimport (\n \n // [END translate_v3_translate_text_0]\n \n-// [START translate_v3_translate_text_1]\n-// translateText translates input text and returns translated text.\n func translateText(w io.Writer, projectID string, sourceLang string, targetLang string, text string) error {\n \t// projectID := \"my-project-id\"\n \t// sourceLang := \"en-US\"\n \t// targetLang := \"fr\"\n \t// text := \"Text you wish to translate\"\n \n+\t// [START translate_v3_translate_text_1]\n+\t// Instantiates a client\n \tctx := context.Background()\n \tclient, err := translate.NewTranslationClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"NewTranslationClient: %v\", err)\n \t}\n \tdefer client.Close()\n+\t// [END translate_v3_translate_text_1]\n \n+\t// [START translate_v3_translate_text_2]\n+\t// Construct request\n \treq := &translatepb.TranslateTextRequest{\n \t\tParent:             fmt.Sprintf(\"projects/%s/locations/global\", projectID),\n \t\tSourceLanguageCode: sourceLang,",
        "comments": [],
        "commit_messages": [
            "docs(translate): add granular markets to v3 translate api for code sample extraction"
        ],
        "last_commit_sha": "adc464032074c6df54359b2e628e1a4691ff0212"
    },
    {
        "pr_title": "test(storage): add test retry",
        "pr_number": 2684,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -22,6 +22,7 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/storage\"",
        "comments": [],
        "commit_messages": [
            "add test retry"
        ],
        "last_commit_sha": "31e2172f76ff79dc04ff98bfdc34d72014e816fb"
    },
    {
        "pr_title": "chore(cloudsql): add consistent region tags",
        "pr_number": 2679,
        "file_name": "cloudsql/mysql/database-sql/connect_tcp.go",
        "code_diff": "@@ -13,6 +13,7 @@\n// limitations under the License.\n \n // [START cloud_sql_mysql_databasesql_connect_tcp]\n+// [START cloud_sql_mysql_databasesql_connect_tcp_sslcerts]\n // [START cloud_sql_mysql_databasesql_sslcerts]\n package cloudsql",
        "comments": [],
        "commit_messages": [
            "chore(cloudsql): add consistent region tags\n\nThis commit adds region tags that match the other languages. A future\ncommit will remove the old region tags."
        ],
        "last_commit_sha": "3b7348b6230662e209fd18490d860eb7f28c59a6"
    },
    {
        "pr_title": "chore(cloudsql): add consistent region tags",
        "pr_number": 2679,
        "file_name": "cloudsql/postgres/database-sql/connect_tcp.go",
        "code_diff": "@@ -13,6 +13,7 @@\n// limitations under the License.\n \n // [START cloud_sql_postgres_databasesql_connect_tcp]\n+// [START cloud_sql_postgres_databasesql_connect_tcp_sslcerts]\n // [START cloud_sql_postgres_databasesql_sslcerts]\n package cloudsql",
        "comments": [],
        "commit_messages": [
            "chore(cloudsql): add consistent region tags\n\nThis commit adds region tags that match the other languages. A future\ncommit will remove the old region tags."
        ],
        "last_commit_sha": "3b7348b6230662e209fd18490d860eb7f28c59a6"
    },
    {
        "pr_title": "chore(cloudsql): add consistent region tags",
        "pr_number": 2679,
        "file_name": "cloudsql/sqlserver/database-sql/connect_tcp.go",
        "code_diff": "@@ -13,6 +13,7 @@\n// limitations under the License.\n \n // [START cloud_sql_sqlserver_databasesql_connect_tcp]\n+// [START cloud_sql_sqlserver_databasesql_connect_tcp_sslcerts]\n // [START cloud_sql_sqlserver_databasesql_sslcerts]\n package cloudsql",
        "comments": [],
        "commit_messages": [
            "chore(cloudsql): add consistent region tags\n\nThis commit adds region tags that match the other languages. A future\ncommit will remove the old region tags."
        ],
        "last_commit_sha": "3b7348b6230662e209fd18490d860eb7f28c59a6"
    },
    {
        "pr_title": "fix(pubsub): fix flaky admin tests",
        "pr_number": 2674,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -125,21 +125,34 @@\nfunc TestCreate(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \tclient := setup(t)\n-\ttopic, err := client.CreateTopic(ctx, topicID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"CreateTopic: %v\", err)\n-\t}\n-\tbuf := new(bytes.Buffer)\n-\tif err := create(buf, tc.ProjectID, subID, topic); err != nil {\n-\t\tt.Fatalf(\"failed to create a subscription: %v\", err)\n-\t}\n-\tok, err := client.Subscription(subID).Exists(context.Background())\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n-\t}\n-\tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", subID)\n-\t}\n+\n+\tvar topic *pubsub.Topic\n+\tvar err error\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\ttopic, err = client.CreateTopic(ctx, topicID)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"CreateTopic: %v\", err)\n+\t\t}\n+\t})\n+\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif err := create(buf, tc.ProjectID, subID, topic); err != nil {\n+\t\t\tt.Fatalf(\"failed to create a subscription: %v\", err)\n+\t\t}\n+\t\tgot := buf.String()\n+\t\twant := \"Created subscription\"\n+\t\tif !strings.Contains(got, want) {\n+\t\t\tt.Fatalf(\"got: %s, want: %v\", got, want)\n+\t\t}\n+\t\tok, err := client.Subscription(subID).Exists(context.Background())\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n+\t\t}\n+\t\tif !ok {\n+\t\t\tt.Fatalf(\"got none; want sub = %q\", subID)\n+\t\t}\n+\t})\n }\n \n func TestList(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c53f66581d9f78ab729b8f9c4e2fcc1e0ebce605"
    },
    {
        "pr_title": "fix(pubsub): fix flaky admin tests",
        "pr_number": 2674,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -198,6 +211,7 @@\nfunc TestIAM(t *testing.T) {\n \t\tif role, member := iam.Viewer, iam.AllUsers; !policy.HasRole(member, role) {\n \t\t\tr.Errorf(\"want %q as viewer, policy=%v\", member, policy)\n \t\t}\n+\n \t})\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c53f66581d9f78ab729b8f9c4e2fcc1e0ebce605"
    },
    {
        "pr_title": "fix(pubsub): fix flaky admin tests",
        "pr_number": 2674,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -357,7 +371,7 @@\nfunc TestPullMsgsConcurrencyControl(t *testing.T) {\n \t\tpublishMsgs(ctx, topic, numMsgs)\n \n \t\tbuf := new(bytes.Buffer)\n-\t\tif err := pullMsgsConcurrenyControl(buf, tc.ProjectID, subIDConc); err != nil {\n+\t\tif err := pullMsgsConcurrencyControl(buf, tc.ProjectID, subIDConc); err != nil {\n \t\t\tr.Errorf(\"failed to pull messages: %v\", err)\n \t\t}\n \t\tgot := buf.String()",
        "comments": [],
        "commit_messages": [
            "fix(pubsub): retry resource creation tests"
        ],
        "last_commit_sha": "c53f66581d9f78ab729b8f9c4e2fcc1e0ebce605"
    },
    {
        "pr_title": "feat(gcfv2/imagemagick_test): use testutil, and upload input file",
        "pr_number": 2633,
        "file_name": "functions/functionsv2/imagemagick/imagemagick_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage imagemagick\n \n import (\n \t\"context\"\n+\t\"io/ioutil\"\n \t\"os\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "make this work in go1.15, which does not have os.ReadFile()"
        ],
        "last_commit_sha": "a2c40ac235db7b025478a408499a8682a57ae5a2"
    },
    {
        "pr_title": "samples(compute): add compute samples for moving instances doc",
        "pr_number": 2630,
        "file_name": "compute/instances/create-start-instance/create_instance_test.go",
        "code_diff": "@@ -26,15 +26,61 @@\nimport (\n \tcompute \"cloud.google.com/go/compute/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \tcomputepb \"google.golang.org/genproto/googleapis/cloud/compute/v1\"\n+\t\"google.golang.org/protobuf/proto\"\n )\n \n+func createDisk(ctx context.Context, projectId, zone, diskName, sourceImage string) error {\n+\tdisksClient, err := compute.NewDisksRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer disksClient.Close()\n+\treq := &computepb.InsertDiskRequest{\n+\t\tProject: projectId,\n+\t\tZone:    zone,\n+\t\tDiskResource: &computepb.Disk{\n+\t\t\tName:        proto.String(diskName),\n+\t\t\tSourceImage: proto.String(sourceImage),\n+\t\t},\n+\t}\n+\n+\top, err := disksClient.Insert(ctx, req)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn op.Wait(ctx)\n+}\n+\n+func deleteDisk(ctx context.Context, projectId, zone, diskName string) error {\n+\tdisksClient, err := compute.NewDisksRESTClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer disksClient.Close()\n+\treq := &computepb.DeleteDiskRequest{\n+\t\tProject: projectId,\n+\t\tZone:    zone,\n+\t\tDisk:    diskName,\n+\t}\n+\n+\top, err := disksClient.Delete(ctx, req)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn op.Wait(ctx)\n+}\n+\n func TestComputeCreateInstanceSnippets(t *testing.T) {\n \tctx := context.Background()\n-\tvar seededRand *rand.Rand = rand.New(\n+\tvar r *rand.Rand = rand.New(\n \t\trand.NewSource(time.Now().UnixNano()))\n \ttc := testutil.SystemTest(t)\n \tzone := \"europe-central2-b\"\n-\tinstanceName := \"test-\" + fmt.Sprint(seededRand.Int())\n+\tinstanceName := fmt.Sprintf(\"test-instance-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\tbootDiskName := fmt.Sprintf(\"test-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n+\tdiskName2 := fmt.Sprintf(\"test-disk-%v-%v\", time.Now().Format(\"01-02-2006\"), r.Int())\n \tnetworkName := \"global/networks/default\"\n \tsubnetworkName := \"regions/europe-central2/subnetworks/default\"\n \texpectedResult := \"Instance created\"",
        "comments": [],
        "commit_messages": [
            "samples(compute): add compute samples for moving instances doc"
        ],
        "last_commit_sha": "14ad97f2630bd88bf5d1b26b28ce65bac52677ed"
    },
    {
        "pr_title": "feat(storagetransfer): add samples for posix transfers and manifest",
        "pr_number": 2624,
        "file_name": "storagetransfer/storagetransfer_test.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage storagetransfer\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"io/ioutil\"\n \t\"log\"\n \t\"os\"\n \t\"strings\"",
        "comments": [],
        "commit_messages": [
            "feat(storagetransfer): add samples for posix transfers and manifest"
        ],
        "last_commit_sha": "5fa31c130083a89ef0b50cc650695cef960f4ac3"
    },
    {
        "pr_title": "feat(storage): update dual-region sample using CustomPlacementConfig",
        "pr_number": 2620,
        "file_name": "storage/buckets/create_bucket_dual_region.go",
        "code_diff": "@@ -25,12 +25,14 @@\nimport (\n )\n \n // createBucketDualRegion creates a new dual-region bucket in the project in the\n-// provided locations.\n-func createBucketDualRegion(w io.Writer, projectID, bucketName, region1, region2 string) error {\n+// provided location and regions.\n+// See https://cloud.google.com/storage/docs/locations#location-dr for more information.\n+func createBucketDualRegion(w io.Writer, projectID, bucketName string) error {\n \t// projectID := \"my-project-id\"\n \t// bucketName := \"bucket-name\"\n-\t// region1 := \"US-EAST1\"\n-\t// region2 := \"US-WEST1\"\n+\tlocation := \"US\"\n+\tregion1 := \"US-EAST1\"\n+\tregion2 := \"US-WEST1\"\n \n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "977c16827e466a344b62e15f1344bcacd3c59aa0"
    },
    {
        "pr_title": "feat(pubsub): create BigQuerySubscription sample",
        "pr_number": 2611,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -26,6 +26,7 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/bigquery\"\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"google.golang.org/api/iterator\"",
        "comments": [],
        "commit_messages": [
            "feat(pubsub): create BigQuerySubscription sample"
        ],
        "last_commit_sha": "18d07bc312bf67ec1affaac7bf0214e82790cbf3"
    },
    {
        "pr_title": "feat(pubsub): create BigQuerySubscription sample",
        "pr_number": 2611,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -725,6 +726,39 @@\nfunc TestCreateWithFilter(t *testing.T) {\n \t}\n }\n \n+func TestCreateBigQuerySubscription(t *testing.T) {\n+\tt.Parallel()\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tdefer client.Close()\n+\tbqSubID := subID + \"-bigquery\"\n+\n+\ttopic, err := getOrCreateTopic(ctx, client, topicID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"CreateTopic: %v\", err)\n+\t}\n+\tbuf := new(bytes.Buffer)\n+\n+\tdatasetID := fmt.Sprintf(\"go_samples_dataset_%d\", time.Now().UnixNano())\n+\ttableID := fmt.Sprintf(\"go_samples_table_%d\", time.Now().UnixNano())\n+\tif err := createBigQueryTable(tc.ProjectID, datasetID, tableID); err != nil {\n+\t\tt.Fatalf(\"failed to create bigquery table: %v\", err)\n+\t}\n+\n+\tbqTable := fmt.Sprintf(\"%s.%s.%s\", tc.ProjectID, datasetID, tableID)\n+\n+\tif err := createBigQuerySubscription(buf, tc.ProjectID, bqSubID, topic, bqTable); err != nil {\n+\t\tt.Fatalf(\"failed to create bigquery subscription: %v\", err)\n+\t}\n+\n+\tsub := client.Subscription(bqSubID)\n+\tsub.Delete(ctx)\n+\tif err := deleteBigQueryDataset(tc.ProjectID, datasetID); err != nil {\n+\t\tt.Logf(\"failed to delete bigquery dataset: %v\", err)\n+\t}\n+}\n+\n func publishMsgs(ctx context.Context, t *pubsub.Topic, numMsgs int) error {\n \tvar results []*pubsub.PublishResult\n \tfor i := 0; i < numMsgs; i++ {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "18d07bc312bf67ec1affaac7bf0214e82790cbf3"
    },
    {
        "pr_title": "feat: add Video Stitcher live session samples and tests",
        "pr_number": 2585,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -18,6 +18,9 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n+\t\"net/http\"\n+\t\"regexp\"\n \t\"strconv\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "feat: add Video Stitcher live session samples and tests"
        ],
        "last_commit_sha": "74c24526c242fd1bf8eb4227ba9acd5857f0f675"
    },
    {
        "pr_title": "feat: add Video Stitcher live session samples and tests",
        "pr_number": 2585,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -47,7 +50,7 @@\nvar slateURI string\n var updatedSlateURI string\n var projectNumber string\n var vodURI string\n-var vodAdTagURI string\n+var liveURI string\n \n // To run the tests, do the following:\n // Export the following env vars:",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "74c24526c242fd1bf8eb4227ba9acd5857f0f675"
    },
    {
        "pr_title": "feat: add Video Stitcher live session samples and tests",
        "pr_number": 2585,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -65,8 +68,7 @@\nfunc TestMain(t *testing.T) {\n \tslateURI = \"https://storage.googleapis.com/\" + bucketName + \"ForBiggerEscapes.mp4\"\n \tupdatedSlateURI = \"https://storage.googleapis.com/\" + bucketName + \"ForBiggerJoyrides.mp4\"\n \tvodURI = \"https://storage.googleapis.com/\" + bucketName + \"hls-vod/manifest.m3u8\"\n-\t// VMAP Pre-roll (https://developers.google.com/interactive-media-ads/docs/sdks/html5/client-side/tags)\n-\tvodAdTagURI = \"https://pubads.g.doubleclick.net/gampad/ads?iu=/21775744923/external/vmap_ad_samples&sz=640x480&cust_params=sample_ar%3Dpreonly&ciu_szs=300x250%2C728x90&gdfp_req=1&ad_rule=1&output=vmap&unviewed_position_start=1&env=vp&impl=s&correlator=\"\n+\tliveURI = \"https://storage.googleapis.com/\" + bucketName + \"hls-live/manifest.m3u8\"\n \n \t// Get the project number\n \tcloudresourcemanagerClient, err := cloudresourcemanager.NewService(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "74c24526c242fd1bf8eb4227ba9acd5857f0f675"
    },
    {
        "pr_title": "feat: add Video Stitcher live session samples and tests",
        "pr_number": 2585,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -314,7 +316,7 @@\nfunc TestVodSessions(t *testing.T) {\n \n \t// Create a new VOD session.\n \tsessionPrefix := fmt.Sprintf(\"projects/%s/locations/%s/vodSessions/\", projectNumber, location)\n-\tif err := createVodSession(buf, tc.ProjectID, vodURI, vodAdTagURI); err != nil {\n+\tif err := createVodSession(buf, tc.ProjectID, vodURI); err != nil {\n \t\tt.Errorf(\"createVodSession got err: %v\", err)\n \t}\n \tgot := buf.String()",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "74c24526c242fd1bf8eb4227ba9acd5857f0f675"
    },
    {
        "pr_title": "feat: add Video Stitcher live session samples and tests",
        "pr_number": 2585,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -362,7 +364,7 @@\nfunc TestVodSessions(t *testing.T) {\n \tbuf.Reset()\n \n \t// Get the specified ad tag detail for a given VOD session.\n-\ttestutil.Retry(t, 1, 2*time.Second, func(r *testutil.R) {\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tif err := getVodAdTagDetail(buf, tc.ProjectID, sessionID, adTagDetailsID); err != nil {\n \t\t\tr.Errorf(\"getVodAdTagDetail got err: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "74c24526c242fd1bf8eb4227ba9acd5857f0f675"
    },
    {
        "pr_title": "feat: add Video Stitcher live session samples and tests",
        "pr_number": 2585,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -394,7 +396,7 @@\nfunc TestVodSessions(t *testing.T) {\n \tbuf.Reset()\n \n \t// Get the specified VOD stitch detail for a given VOD session.\n-\ttestutil.Retry(t, 1, 2*time.Second, func(r *testutil.R) {\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tif err := getVodStitchDetail(buf, tc.ProjectID, sessionID, stitchDetailsID); err != nil {\n \t\t\tr.Errorf(\"getVodStitchDetail got err: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "address feedback"
        ],
        "last_commit_sha": "74c24526c242fd1bf8eb4227ba9acd5857f0f675"
    },
    {
        "pr_title": "feat: add Video Stitcher VOD session samples and tests",
        "pr_number": 2581,
        "file_name": "media/videostitcher/get_cdn_key.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage videostitcher\n // [START video_stitcher_get_cdn_key]\n import (\n \t\"context\"\n+\t\"encoding/json\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_messages": [
            "address feedback; output indented JSON"
        ],
        "last_commit_sha": "f878f65b1ddca6e36d0690cd540ca2fb1bb223d4"
    },
    {
        "pr_title": "feat: add Video Stitcher VOD session samples and tests",
        "pr_number": 2581,
        "file_name": "media/videostitcher/get_slate.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage videostitcher\n // [START video_stitcher_get_slate]\n import (\n \t\"context\"\n+\t\"encoding/json\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_messages": [
            "address feedback; output indented JSON"
        ],
        "last_commit_sha": "f878f65b1ddca6e36d0690cd540ca2fb1bb223d4"
    },
    {
        "pr_title": "feat: add Video Stitcher VOD session samples and tests",
        "pr_number": 2581,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -46,6 +46,8 @@\nvar bucketName string\n var slateURI string\n var updatedSlateURI string\n var projectNumber string\n+var vodURI string\n+var vodAdTagURI string\n \n // To run the tests, do the following:\n // Export the following env vars:",
        "comments": [],
        "commit_messages": [
            "feat: add Video Stitcher VOD session samples and tests"
        ],
        "last_commit_sha": "f878f65b1ddca6e36d0690cd540ca2fb1bb223d4"
    },
    {
        "pr_title": "feat: add Video Stitcher VOD session samples and tests",
        "pr_number": 2581,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -62,6 +64,9 @@\nfunc TestMain(t *testing.T) {\n \tbucketName = \"cloud-samples-data/media/\"\n \tslateURI = \"https://storage.googleapis.com/\" + bucketName + \"ForBiggerEscapes.mp4\"\n \tupdatedSlateURI = \"https://storage.googleapis.com/\" + bucketName + \"ForBiggerJoyrides.mp4\"\n+\tvodURI = \"https://storage.googleapis.com/\" + bucketName + \"hls-vod/manifest.m3u8\"\n+\t// VMAP Pre-roll (https://developers.google.com/interactive-media-ads/docs/sdks/html5/client-side/tags)\n+\tvodAdTagURI = \"https://pubads.g.doubleclick.net/gampad/ads?iu=/21775744923/external/vmap_ad_samples&sz=640x480&cust_params=sample_ar%3Dpreonly&ciu_szs=300x250%2C728x90&gdfp_req=1&ad_rule=1&output=vmap&unviewed_position_start=1&env=vp&impl=s&correlator=\"\n \n \t// Get the project number\n \tcloudresourcemanagerClient, err := cloudresourcemanager.NewService(ctx)",
        "comments": [],
        "commit_messages": [
            "feat: add Video Stitcher VOD session samples and tests"
        ],
        "last_commit_sha": "f878f65b1ddca6e36d0690cd540ca2fb1bb223d4"
    },
    {
        "pr_title": "feat(spanner): add samples for database roles",
        "pr_number": 2579,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -17,51 +17,58 @@\npackage main\n \n import (\n \t\"context\"\n+\t\"errors\"\n \t\"flag\"\n \t\"fmt\"\n \t\"io\"\n \t\"log\"\n \t\"os\"\n \t\"regexp\"\n \t\"strconv\"\n+\t\"strings\"\n \t\"time\"\n \n \t\"cloud.google.com/go/spanner\"\n \t\"google.golang.org/api/iterator\"\n \n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n+\tiampb \"google.golang.org/genproto/googleapis/iam/v1\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n+\texpr \"google.golang.org/genproto/googleapis/type/expr\"\n )\n \n type command func(ctx context.Context, w io.Writer, client *spanner.Client) error\n type adminCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error\n \n var (\n \tcommands = map[string]command{\n-\t\t\"write\":               write,\n-\t\t\"read\":                read,\n-\t\t\"query\":               query,\n-\t\t\"update\":              update,\n-\t\t\"querynewcolumn\":      queryNewColumn,\n-\t\t\"pgquerynewcolumn\":    pgQueryNewColumn,\n-\t\t\"querywithparameter\":  queryWithParameter,\n-\t\t\"pgqueryparameter\":    pgQueryParameter,\n-\t\t\"dmlwrite\":            writeUsingDML,\n-\t\t\"pgdmlwrite\":          pgWriteUsingDML,\n-\t\t\"dmlwritetxn\":         writeWithTransactionUsingDML,\n-\t\t\"pgdmlwritetxn\":       pgWriteWithTransactionUsingDML,\n-\t\t\"readindex\":           readUsingIndex,\n-\t\t\"readstoringindex\":    readStoringIndex,\n-\t\t\"readonlytransaction\": readOnlyTransaction,\n+\t\t\"write\":                    write,\n+\t\t\"read\":                     read,\n+\t\t\"readdatawithdatabaserole\": read,\n+\t\t\"query\":                    query,\n+\t\t\"update\":                   update,\n+\t\t\"querynewcolumn\":           queryNewColumn,\n+\t\t\"pgquerynewcolumn\":         pgQueryNewColumn,\n+\t\t\"querywithparameter\":       queryWithParameter,\n+\t\t\"pgqueryparameter\":         pgQueryParameter,\n+\t\t\"dmlwrite\":                 writeUsingDML,\n+\t\t\"pgdmlwrite\":               pgWriteUsingDML,\n+\t\t\"dmlwritetxn\":              writeWithTransactionUsingDML,\n+\t\t\"pgdmlwritetxn\":            pgWriteWithTransactionUsingDML,\n+\t\t\"readindex\":                readUsingIndex,\n+\t\t\"readstoringindex\":         readStoringIndex,\n+\t\t\"readonlytransaction\":      readOnlyTransaction,\n \t}\n \n \tadminCommands = map[string]adminCommand{\n-\t\t\"createdatabase\":    createDatabase,\n-\t\t\"addnewcolumn\":      addNewColumn,\n-\t\t\"pgaddnewcolumn\":    pgAddNewColumn,\n-\t\t\"addstoringindex\":   addStoringIndex,\n-\t\t\"pgaddstoringindex\": pgAddStoringIndex,\n-\t\t\"pgcreatedatabase\":  pgCreateDatabase,\n+\t\t\"createdatabase\":         createDatabase,\n+\t\t\"addnewcolumn\":           addNewColumn,\n+\t\t\"pgaddnewcolumn\":         pgAddNewColumn,\n+\t\t\"addstoringindex\":        addStoringIndex,\n+\t\t\"pgaddstoringindex\":      pgAddStoringIndex,\n+\t\t\"pgcreatedatabase\":       pgCreateDatabase,\n+\t\t\"addanddropdatabaserole\": addAndDropDatabaseRole,\n+\t\t\"listdatabaseroles\":      listDatabaseRoles,\n \t}\n )",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b1db4ca8da6f002110884fa93c64860ce97acc59"
    },
    {
        "pr_title": "feat(spanner): add samples for database roles",
        "pr_number": 2579,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -706,21 +713,138 @@\nfunc pgAddStoringIndex(ctx context.Context, w io.Writer, adminClient *database.D\n \treturn nil\n }\n \n-func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n+func addAndDropDatabaseRole(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, db string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: db,\n+\t\tStatements: []string{\n+\t\t\t\"CREATE ROLE parent\",\n+\t\t\t\"GRANT SELECT ON TABLE Albums TO ROLE parent\",\n+\t\t\t\"CREATE ROLE child\",\n+\t\t\t\"GRANT ROLE parent TO ROLE child\",\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Created roles parent and child and granted privileges\\n\")\n+\top, err = adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: db,\n+\t\tStatements: []string{\n+\t\t\t\"REVOKE ROLE parent FROM ROLE child\",\n+\t\t\t\"DROP ROLE child\",\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Revoked privileges and dropped role child\\n\")\n+\treturn nil\n+}\n+\n+func enableFineGrainedAccess(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, db string, iamMember string) error {\n+\tif iamMember == \"\" {\n+\t\treturn errors.New(\"IAM member must be specified\")\n+\t}\n+\tdatabaseRole := \"parent\"\n+\ttitle := \"condition title\"\n+\tpolicy, err := adminClient.GetIamPolicy(ctx, &iampb.GetIamPolicyRequest{\n+\t\tResource: db,\n+\t\tOptions: &iampb.GetPolicyOptions{\n+\t\t\t// IAM conditions need at least version 3\n+\t\t\tRequestedPolicyVersion: 3,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// IAM conditions need at least version 3\n+\tif policy.Version < 3 {\n+\t\tpolicy.Version = 3\n+\t}\n+\tpolicy.Bindings = append(policy.Bindings, []*iampb.Binding{\n+\t\t{\n+\t\t\tRole:    \"roles/spanner.fineGrainedAccessUser\",\n+\t\t\tMembers: []string{iamMember},\n+\t\t},\n+\t\t{\n+\t\t\tRole:    \"roles/spanner.databaseRoleUser\",\n+\t\t\tMembers: []string{iamMember},\n+\t\t\tCondition: &expr.Expr{\n+\t\t\t\tExpression: fmt.Sprintf(`resource.name.endsWith(\"/databaseRoles/%s\")`, databaseRole),\n+\t\t\t\tTitle:      title,\n+\t\t\t},\n+\t\t},\n+\t}...)\n+\t_, err = adminClient.SetIamPolicy(ctx, &iampb.SetIamPolicyRequest{\n+\t\tResource: db,\n+\t\tPolicy:   policy,\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Fprintf(w, \"Enabled fine-grained access in IAM.\\n\")\n+\treturn nil\n+}\n+\n+func listDatabaseRoles(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, db string) error {\n+\titer := adminClient.ListDatabaseRoles(ctx, &adminpb.ListDatabaseRolesRequest{\n+\t\tParent: db,\n+\t})\n+\trolePrefix := db + \"/databaseRoles/\"\n+\tfor {\n+\t\trole, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tif !strings.HasPrefix(role.Name, rolePrefix) {\n+\t\t\treturn fmt.Errorf(\"Role %v does not have prefix %v\", role.Name, rolePrefix)\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%s\\n\", strings.TrimPrefix(role.Name, rolePrefix))\n+\t}\n+\treturn nil\n+}\n+\n+func run(ctx context.Context, w io.Writer, cmd string, db string, arg string) error {\n+\tvar databaseRole string\n+\tif cmd == \"readdatawithdatabaserole\" {\n+\t\tdatabaseRole = \"parent\"\n+\t}\n+\n+\tcfg := spanner.ClientConfig{\n+\t\tDatabaseRole: databaseRole,\n+\t}\n+\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n+\tdefer adminClient.Close()\n \n-\tdataClient, err := spanner.NewClient(ctx, db)\n+\tdataClient, err := spanner.NewClientWithConfig(ctx, db, cfg)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n+\tdefer dataClient.Close()\n \n-\treturn adminClient, dataClient\n-}\n+\tif cmd == \"enablefinegrainedaccess\" {\n+\t\terr := enableFineGrainedAccess(ctx, w, adminClient, db, arg)\n+\t\tif err != nil {\n+\t\t\tfmt.Fprintf(w, \"%s failed with %v\", cmd, err)\n+\t\t}\n+\t\treturn err\n+\t}\n \n-func run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, w io.Writer, cmd string, db string) error {\n \tif adminCmdFn := adminCommands[cmd]; adminCmdFn != nil {\n \t\terr := adminCmdFn(ctx, w, adminClient, db)\n \t\tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b1db4ca8da6f002110884fa93c64860ce97acc59"
    },
    {
        "pr_title": "feat(spanner): add samples for database roles",
        "pr_number": 2579,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -735,7 +859,7 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \t\tflag.Usage()\n \t\tos.Exit(2)\n \t}\n-\terr := cmdFn(ctx, w, dataClient)\n+\terr = cmdFn(ctx, w, dataClient)\n \tif err != nil {\n \t\tfmt.Fprintf(w, \"%s failed with %v\", cmd, err)\n \t}",
        "comments": [],
        "commit_messages": [
            "feat(spanner): add samples for database roles"
        ],
        "last_commit_sha": "b1db4ca8da6f002110884fa93c64860ce97acc59"
    },
    {
        "pr_title": "feat: add Video Stitcher CDN key samples and tests",
        "pr_number": 2577,
        "file_name": "media/videostitcher/stitcher_test.go",
        "code_diff": "@@ -28,10 +28,18 @@\nimport (\n )\n \n const (\n+\tlocation            = \"us-central1\" // All samples use this location\n+\tslateID             = \"my-go-test-slate\"\n+\tdeleteSlateResponse = \"Deleted slate\"\n+\n \tdeleteCdnKeyResponse = \"Deleted CDN key\"\n-\tdeleteSlateResponse  = \"Deleted slate\"\n-\tlocation             = \"us-central1\" // All samples use this location\n-\tslateID              = \"my-go-test-slate\"\n+\tgcdnCdnKeyID         = \"my-go-test-google-cdn\"\n+\takamaiCdnKeyID       = \"my-go-test-akamai-cdn\"\n+\thostname             = \"cdn.example.com\"\n+\tupdatedHostname      = \"updated.example.com\"\n+\tgcdnKeyname          = \"gcdn-key\"\n+\tprivateKey           = \"VGhpcyBpcyBhIHRlc3Qgc3RyaW5nLg==\"\n+\tupdatedPrivateKey    = \"VGhpcyBpcyBhbiB1cGRhdGVkIHRlc3Qgc3RyaW5nLg==\"\n )\n \n var bucketName string",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3331dd50979244524da4aedbb7876d8a11238bfc"
    },
    {
        "pr_title": "fix: Add some resilience to the grpc tests",
        "pr_number": 2573,
        "file_name": "run/testing/grpc_server_streaming.e2e_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"crypto/x509\"\n \t\"io\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [
            {
                "comment": "Nit: move `5` to a predefined constant? (This is a case of [\"magic numbers\"](https://en.wikipedia.org/wiki/Magic_number_(programming)#Unnamed_numerical_constants))",
                "position": 25
            }
        ],
        "commit_messages": [
            "fix(run/testing): Add some resilience to the grpc tests\n\nThese tests occasionally flake, and adding a couple retries here should\n(hopefully) resolve the flakes."
        ],
        "last_commit_sha": "5dd950c5156f3937744d633d9d9956f18e1c7425"
    },
    {
        "pr_title": "fix(healthcare): Wait for dataset operation to complete before continuing with tests",
        "pr_number": 2554,
        "file_name": "healthcare/dataset_create.go",
        "code_diff": "@@ -19,13 +19,16 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n \n \thealthcare \"google.golang.org/api/healthcare/v1\"\n )\n \n // createDataset creates a dataset.\n func createDataset(w io.Writer, projectID, location, datasetID string) error {\n-\tctx := context.Background()\n+\t// Set a deadline for the dataset to become initialized.\n+\tctx, cancel := context.WithTimeout(context.Background(), 2*time.Minute)\n+\tdefer cancel()\n \n \thealthcareService, err := healthcare.NewService(ctx)\n \tif err != nil {",
        "comments": [
            {
                "comment": "The fact that you're waiting for a response might not be totally obvious here. Is it worth adding a comment about what is happening and how long you should expect to wait for a response?",
                "position": 32
            }
        ],
        "commit_messages": [
            "fix(healthcare): Wait for dataset operation to complete before continuing with tests"
        ],
        "last_commit_sha": "39f837f8915849a053632d21aa47a60a817be6d3"
    },
    {
        "pr_title": "feat: sample for creating channel with failover backup input",
        "pr_number": 2550,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -32,6 +32,7 @@\nconst (\n \tstopChannelResponse        = \"Stopped channel\"\n \tlocation                   = \"us-central1\"\n \tinputID                    = \"my-go-test-input\"\n+\tbackupInputID              = \"my-go-test-backup-input\"\n \tchannelID                  = \"my-go-test-channel\"\n \teventID                    = \"my-go-test-channel-event\"\n )",
        "comments": [],
        "commit_messages": [
            "feat:add Live Stream sample for creating a channel with a failover backup input"
        ],
        "last_commit_sha": "4fad2d9d8eaeeb1783bf1c6817abc25351adee9d"
    },
    {
        "pr_title": "feat: sample for creating channel with failover backup input",
        "pr_number": 2550,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -94,6 +95,22 @@\nfunc testInputs(t *testing.T) {\n \t\t})\n \t}\n \n+\t// Delete the default backup input if it exists\n+\tif err := getInput(buf, tc.ProjectID, location, backupInputID); err == nil {\n+\t\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\t\tif err := deleteInput(buf, tc.ProjectID, location, backupInputID); err != nil {\n+\t\t\t\tr.Errorf(\"deleteInput got err: %v\", err)\n+\t\t\t}\n+\t\t})\n+\t}\n+\n+\t// Create a new backup input.\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\tif err := createInput(buf, tc.ProjectID, location, backupInputID); err != nil {\n+\t\t\tr.Errorf(\"createInput got err: %v\", err)\n+\t\t}\n+\t})\n+\n \t// Tests\n \n \t// Create a new input.",
        "comments": [],
        "commit_messages": [
            "feat:add Live Stream sample for creating a channel with a failover backup input"
        ],
        "last_commit_sha": "4fad2d9d8eaeeb1783bf1c6817abc25351adee9d"
    },
    {
        "pr_title": "feat: sample for creating channel with failover backup input",
        "pr_number": 2550,
        "file_name": "media/livestream/livestream_test.go",
        "code_diff": "@@ -283,8 +300,30 @@\nfunc testChannels(t *testing.T, outputURI string) {\n \t})\n \tbuf.Reset()\n \n+\t// Create a new channel with backup input.\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\tchannelName := fmt.Sprintf(\"projects/%s/locations/%s/channels/%s\", tc.ProjectID, location, channelID)\n+\t\tif err := createChannelWithBackupInput(buf, tc.ProjectID, location, channelID, inputID, backupInputID, outputURI); err != nil {\n+\t\t\tr.Errorf(\"createChannel got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, channelName) {\n+\t\t\tr.Errorf(\"createChannel got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, channelName)\n+\t\t}\n+\t})\n+\tbuf.Reset()\n+\n \t// Clean up\n \n+\t// Delete the channel with backup input.\n+\ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n+\t\tif err := deleteChannel(buf, tc.ProjectID, location, channelID); err != nil {\n+\t\t\tr.Errorf(\"deleteChannel got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, deleteChannelResponse) {\n+\t\t\tr.Errorf(\"deleteChannel got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, deleteChannelResponse)\n+\t\t}\n+\t})\n+\n \t// Delete the input.\n \ttestutil.Retry(t, 3, 2*time.Second, func(r *testutil.R) {\n \t\tif err := deleteInput(buf, tc.ProjectID, location, inputID); err != nil {",
        "comments": [],
        "commit_messages": [
            "feat:add Live Stream sample for creating a channel with a failover backup input"
        ],
        "last_commit_sha": "4fad2d9d8eaeeb1783bf1c6817abc25351adee9d"
    },
    {
        "pr_title": "chore: Fix test flakes in TestJobTemplatesAndJobs",
        "pr_number": 2533,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -72,8 +72,9 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \toutputURIForAnimatedOverlay := \"gs://\" + bucketName + \"/test-output-animated-overlay/\"\n \toutputDirForSetNumberSpritesheet := \"test-output-set-number-spritesheet/\"\n \toutputURIForSetNumberSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForSetNumberSpritesheet\n-\toutputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n-\toutputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n+\t// TODO: Uncomment following lines and testJobWithPeriodicImagesSpritesheet after fixing https://github.com/GoogleCloudPlatform/golang-samples/issues/2432 (t.Skip not used due to size of test)\n+\t//outputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n+\t//outputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n \toutputURIForConcat := \"gs://\" + bucketName + \"/test-output-concat/\"\n \toutputURIForEmbeddedCaptions := \"gs://\" + bucketName + \"/test-output-embedded-captions/\"\n \toutputURIForStandaloneCaptions := \"gs://\" + bucketName + \"/test-output-standalone-captions/\"",
        "comments": [],
        "commit_messages": [
            "chore: Fix test flakes in TestJobTemplatesAndJobs\n\nrefs: #2432"
        ],
        "last_commit_sha": "7e19ca958412834bd694862fdfb9e768e10edc84"
    },
    {
        "pr_title": "feat(spanner): add sample for STORING indexes on a Spanner PostgreSQL database",
        "pr_number": 2526,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -56,11 +56,12 @@\nvar (\n \t}\n \n \tadminCommands = map[string]adminCommand{\n-\t\t\"createdatabase\":   createDatabase,\n-\t\t\"addnewcolumn\":     addNewColumn,\n-\t\t\"pgaddnewcolumn\":   pgAddNewColumn,\n-\t\t\"addstoringindex\":  addStoringIndex,\n-\t\t\"pgcreatedatabase\": pgCreateDatabase,\n+\t\t\"createdatabase\":    createDatabase,\n+\t\t\"addnewcolumn\":      addNewColumn,\n+\t\t\"pgaddnewcolumn\":    pgAddNewColumn,\n+\t\t\"addstoringindex\":   addStoringIndex,\n+\t\t\"pgaddstoringindex\": pgAddStoringIndex,\n+\t\t\"pgcreatedatabase\":  pgCreateDatabase,\n \t}\n )",
        "comments": [],
        "commit_messages": [
            "feat(spanner): add sample for STORING indexes on a Spanner PostgreSQL database"
        ],
        "last_commit_sha": "ae958c1caadd85e18b89a434df2a00ae50413c31"
    },
    {
        "pr_title": "feat(spanner): add sample for STORING indexes on a Spanner PostgreSQL database",
        "pr_number": 2526,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -688,6 +689,23 @@\nfunc pgWriteWithTransactionUsingDML(ctx context.Context, w io.Writer, client *sp\n \treturn err\n }\n \n+func pgAddStoringIndex(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t\"CREATE INDEX AlbumsByAlbumTitle2 ON Albums(AlbumTitle) INCLUDE (MarketingBudget)\",\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"failed to execute spanner database DDL request: %v\", err)\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn fmt.Errorf(\"failed to complete spanner database DDL request: %v\", err)\n+\t}\n+\tfmt.Fprintf(w, \"Added storing index\\n\")\n+\treturn nil\n+}\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ae958c1caadd85e18b89a434df2a00ae50413c31"
    },
    {
        "pr_title": "fix: Update env vars and log filter",
        "pr_number": 2517,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -12,6 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START cloudrun_jobs_quickstart]\n package main\n \n import (",
        "comments": [],
        "commit_messages": [
            "fix: Update env vars and log filter"
        ],
        "last_commit_sha": "5aceb538835584ff97035b28a5882f69c30306f1"
    },
    {
        "pr_title": "fix: Update env vars and log filter",
        "pr_number": 2517,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -34,10 +35,14 @@\ntype Config struct {\n }\n \n func configFromEnv() (Config, error) {\n-\ttaskNum := os.Getenv(\"TASK_NUM\")\n-\tattemptNum := os.Getenv(\"ATTEMPT_NUM\")\n+\t// [START cloudrun_jobs_env_vars]\n+\t// Job-defined\n+\ttaskNum := os.Getenv(\"CLOUD_RUN_TASK_INDEX\")\n+\tattemptNum := os.Getenv(\"CLOUD_RUN_TASK_ATTEMPT\")\n+\t// User-defined\n \tsleepMs, err := sleepMsToInt(os.Getenv(\"SLEEP_MS\"))\n \tfailRate, err := failRateToFloat(os.Getenv(\"FAIL_RATE\"))\n+\t// [END cloudrun_jobs_env_vars]\n \n \tif err != nil {\n \t\treturn Config{}, err",
        "comments": [],
        "commit_messages": [
            "fix: Update env vars and log filter"
        ],
        "last_commit_sha": "5aceb538835584ff97035b28a5882f69c30306f1"
    },
    {
        "pr_title": "fix: Update env vars and log filter",
        "pr_number": 2517,
        "file_name": "run/jobs/main.go",
        "code_diff": "@@ -90,7 +95,9 @@\nfunc main() {\n \t// Simulate errors\n \tif config.failRate > 0 {\n \t\tif failure := randomFailure(config); failure != nil {\n+\t\t\t// [START cloudrun_jobs_exit_process]\n \t\t\tlog.Fatalf(\"%v\", failure)\n+\t\t\t// [END cloudrun_jobs_exit_process]\n \t\t}\n \t}",
        "comments": [],
        "commit_messages": [
            "fix: Update env vars and log filter"
        ],
        "last_commit_sha": "5aceb538835584ff97035b28a5882f69c30306f1"
    },
    {
        "pr_title": "fix(bigquery/storage): handle retryable RESOURCE_EXHAUSTED errors in bigquery storage sample",
        "pr_number": 2516,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -38,7 +38,10 @@\nimport (\n \tgax \"github.com/googleapis/gax-go/v2\"\n \tgoavro \"github.com/linkedin/goavro/v2\"\n \tbqStoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1\"\n+\t\"google.golang.org/genproto/googleapis/rpc/errdetails\"\n \t\"google.golang.org/grpc\"\n+\t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n // rpcOpts is used to configure the underlying gRPC client to accept large",
        "comments": [],
        "commit_messages": [
            "fix(bigquery/storage): handle retryable RESOURCE_EXHAUSTED errors in bigquery storage sample\n\n* Adds special handling for retryable RESOURCE_EXHAUSTED errors returned from bigquery storage api, so they aren't treated as regular errors.\n* Fixes retries being reset every time an error is observed, so at most 3 back-to-back errors are retried."
        ],
        "last_commit_sha": "1ba40d4517f1b2edc5fab80956a6a7d7f4f5290b"
    },
    {
        "pr_title": "fix(bigquery/storage): handle retryable RESOURCE_EXHAUSTED errors in bigquery storage sample",
        "pr_number": 2516,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -207,8 +210,8 @@\nfunc processStream(ctx context.Context, client *bqStorage.BigQueryReadClient, st\n \t// stream, implement a retry that resets once progress is made.\n \tretryLimit := 3\n \n+\tretries := 0\n \tfor {\n-\t\tretries := 0\n \t\t// Send the initiating request to start streaming row blocks.\n \t\trowStream, err := client.ReadRows(ctx, &bqStoragepb.ReadRowsRequest{\n \t\t\tReadStream: st,",
        "comments": [],
        "commit_messages": [
            "fix(bigquery/storage): handle retryable RESOURCE_EXHAUSTED errors in bigquery storage sample\n\n* Adds special handling for retryable RESOURCE_EXHAUSTED errors returned from bigquery storage api, so they aren't treated as regular errors.\n* Fixes retries being reset every time an error is observed, so at most 3 back-to-back errors are retried."
        ],
        "last_commit_sha": "1ba40d4517f1b2edc5fab80956a6a7d7f4f5290b"
    },
    {
        "pr_title": "test(iam): Add Retry to TestServiceAccounts",
        "pr_number": 2507,
        "file_name": "iam/snippets/service_accounts_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\nimport (\n \t\"bytes\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/gofrs/uuid\"",
        "comments": [
            {
                "comment": "This should have a return after it to avoid a panic on L52 I believe.",
                "position": 24
            },
            {
                "comment": "Fixed, thank you! Let's see what the real problem is now...",
                "position": 24
            }
        ],
        "commit_messages": [
            "chore(iam): Add Retry to TestServiceAccounts\n\ncloses: #2486"
        ],
        "last_commit_sha": "80ec83d93a0766561c289aef7649e0d1ec5f828f"
    },
    {
        "pr_title": "feat(spanner): add PG samples for getting-started",
        "pr_number": 2493,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -43,18 +43,24 @@\nvar (\n \t\t\"query\":               query,\n \t\t\"update\":              update,\n \t\t\"querynewcolumn\":      queryNewColumn,\n+\t\t\"pgquerynewcolumn\":    pgQueryNewColumn,\n \t\t\"querywithparameter\":  queryWithParameter,\n+\t\t\"pgqueryparameter\":    pgQueryParameter,\n \t\t\"dmlwrite\":            writeUsingDML,\n+\t\t\"pgdmlwrite\":          pgWriteUsingDML,\n \t\t\"dmlwritetxn\":         writeWithTransactionUsingDML,\n+\t\t\"pgdmlwritetxn\":       pgWriteWithTransactionUsingDML,\n \t\t\"readindex\":           readUsingIndex,\n \t\t\"readstoringindex\":    readStoringIndex,\n \t\t\"readonlytransaction\": readOnlyTransaction,\n \t}\n \n \tadminCommands = map[string]adminCommand{\n-\t\t\"createdatabase\":  createDatabase,\n-\t\t\"addnewcolumn\":    addNewColumn,\n-\t\t\"addstoringindex\": addStoringIndex,\n+\t\t\"createdatabase\":   createDatabase,\n+\t\t\"addnewcolumn\":     addNewColumn,\n+\t\t\"pgaddnewcolumn\":   pgAddNewColumn,\n+\t\t\"addstoringindex\":  addStoringIndex,\n+\t\t\"pgcreatedatabase\": pgCreateDatabase,\n \t}\n )",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cdb87fb2536e7d36072a2311f87c639a345a96a9"
    },
    {
        "pr_title": "feat(spanner): add PG samples for getting-started",
        "pr_number": 2493,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -477,6 +483,211 @@\nfunc writeWithTransactionUsingDML(ctx context.Context, w io.Writer, client *span\n \n // [END spanner_dml_getting_started_update]\n \n+func pgCreateDatabase(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, db string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(db)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"invalid database id %v\", db)\n+\t}\n+\t// Databases with PostgreSQL dialect do not support extra DDL statements in the `CreateDatabase` call.\n+\top, err := adminClient.CreateDatabase(ctx, &adminpb.CreateDatabaseRequest{\n+\t\tParent:          matches[1],\n+\t\tDatabaseDialect: adminpb.DatabaseDialect_POSTGRESQL,\n+\t\t// Note that PostgreSQL uses double quotes for quoting identifiers. This also\n+\t\t// includes database names in the CREATE DATABASE statement.\n+\t\tCreateStatement: `CREATE DATABASE \"` + matches[2] + `\"`,\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif _, err := op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tupdateReq := &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: db,\n+\t\tStatements: []string{\n+\t\t\t`CREATE TABLE Singers (\n+\t\t\t\tSingerId   bigint NOT NULL PRIMARY KEY,\n+\t\t\t\tFirstName  varchar(1024),\n+\t\t\t\tLastName   varchar(1024),\n+\t\t\t\tSingerInfo bytea\n+\t\t\t)`,\n+\t\t\t`CREATE TABLE Albums (\n+\t\t\t\tAlbumId      bigint NOT NULL,\n+\t\t\t\tSingerId     bigint NOT NULL REFERENCES Singers (SingerId),\n+\t\t\t\tAlbumTitle   text,\n+\t\t\t\tPRIMARY KEY(SingerId, AlbumId)\n+\t\t\t)`,\n+\t\t},\n+\t}\n+\topUpdate, err := adminClient.UpdateDatabaseDdl(ctx, updateReq)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := opUpdate.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Created database [%v]\\n\", db)\n+\treturn nil\n+}\n+\n+func pgWriteUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\tstmt := spanner.Statement{\n+\t\t\tSQL: `INSERT INTO Singers (SingerId, FirstName, LastName) VALUES\n+\t\t\t\t(12, 'Melissa', 'Garcia'),\n+\t\t\t\t(13, 'Russell', 'Morales'),\n+\t\t\t\t(14, 'Jacqueline', 'Long'),\n+\t\t\t\t(15, 'Dylan', 'Shaw')`,\n+\t\t}\n+\t\trowCount, err := txn.Update(ctx, stmt)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d record(s) inserted.\\n\", rowCount)\n+\t\treturn err\n+\t})\n+\treturn err\n+}\n+\n+func pgQueryParameter(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT SingerId, FirstName, LastName FROM Singers\n+\t\t\tWHERE LastName = $1`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"p1\": \"Garcia\",\n+\t\t},\n+\t}\n+\ttype Singers struct {\n+\t\tSingerID            int64\n+\t\tFirstName, LastName string\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar val Singers\n+\t\tif err := row.ToStruct(&val); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", val.SingerID, val.FirstName, val.LastName)\n+\t}\n+}\n+\n+func pgAddNewColumn(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t\"ALTER TABLE Albums ADD COLUMN MarketingBudget bigint\",\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Added MarketingBudget column\\n\")\n+\treturn nil\n+}\n+\n+func pgQueryNewColumn(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tstmt := spanner.Statement{SQL: `SELECT SingerId, AlbumId, MarketingBudget FROM Albums`}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar singerID, albumID int64\n+\t\tvar marketingBudget spanner.NullInt64\n+\t\tif err := row.ColumnByName(\"singerid\", &singerID); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tif err := row.ColumnByName(\"albumid\", &albumID); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tif err := row.ColumnByName(\"marketingbudget\", &marketingBudget); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tbudget := \"NULL\"\n+\t\tif marketingBudget.Valid {\n+\t\t\tbudget = strconv.FormatInt(marketingBudget.Int64, 10)\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %d %s\\n\", singerID, albumID, budget)\n+\t}\n+}\n+\n+func pgWriteWithTransactionUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\t// getBudget returns the budget for a record with a given albumId and singerId.\n+\t\tgetBudget := func(albumID, singerID int64) (int64, error) {\n+\t\t\tkey := spanner.Key{albumID, singerID}\n+\t\t\trow, err := txn.ReadRow(ctx, \"Albums\", key, []string{\"MarketingBudget\"})\n+\t\t\tif err != nil {\n+\t\t\t\treturn 0, fmt.Errorf(\"error reading marketing budget for album_id=%v,singer_id=%v: %v\",\n+\t\t\t\t\talbumID, singerID, err)\n+\t\t\t}\n+\t\t\tvar budget int64\n+\t\t\tif err := row.Column(0, &budget); err != nil {\n+\t\t\t\treturn 0, fmt.Errorf(\"error decoding marketing budget for album_id=%v,singer_id=%v: %v\",\n+\t\t\t\t\talbumID, singerID, err)\n+\t\t\t}\n+\t\t\treturn budget, nil\n+\t\t}\n+\t\t// updateBudget updates the budget for a record with a given albumId and singerId.\n+\t\tupdateBudget := func(singerID, albumID, albumBudget int64) error {\n+\t\t\tstmt := spanner.Statement{\n+\t\t\t\tSQL: `UPDATE Albums\n+\t\t\t\t\tSET MarketingBudget = $1\n+\t\t\t\t\tWHERE SingerId = $2 and AlbumId = $3`,\n+\t\t\t\tParams: map[string]interface{}{\n+\t\t\t\t\t\"p1\": albumBudget,\n+\t\t\t\t\t\"p2\": singerID,\n+\t\t\t\t\t\"p3\": albumID,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t\t_, err := txn.Update(ctx, stmt)\n+\t\t\treturn err\n+\t\t}\n+\n+\t\t// Transfer the marketing budget from one album to another. By keeping the actions\n+\t\t// in a single transaction, it ensures the movement is atomic.\n+\t\tconst transferAmt = 200000\n+\t\talbum2Budget, err := getBudget(2, 2)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\t// The transaction will only be committed if this condition still holds at the time\n+\t\t// of commit. Otherwise it will be aborted and the callable will be rerun by the\n+\t\t// client library.\n+\t\tif album2Budget >= transferAmt {\n+\t\t\talbum1Budget, err := getBudget(1, 1)\n+\t\t\tif err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tif err = updateBudget(1, 1, album1Budget+transferAmt); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tif err = updateBudget(2, 2, album2Budget-transferAmt); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tfmt.Fprintf(w, \"Moved %d from Album2's MarketingBudget to Album1's.\", transferAmt)\n+\t\t}\n+\t\treturn nil\n+\t})\n+\treturn err\n+}\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cdb87fb2536e7d36072a2311f87c639a345a96a9"
    },
    {
        "pr_title": "feat(spanner): add PG samples for getting-started",
        "pr_number": 2493,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -564,7 +564,7 @@\nfunc TestCreateDatabaseWithDefaultLeaderSample(t *testing.T) {\n \tassertContains(t, out, \"The result of the query to get\")\n }\n \n-func TestPgCreateDatabase(t *testing.T) {\n+func TestPgSample(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n \tt.Parallel()",
        "comments": [],
        "commit_messages": [
            "move PG samples for getting-started to separate samples and add integration tests for new samples"
        ],
        "last_commit_sha": "cdb87fb2536e7d36072a2311f87c639a345a96a9"
    },
    {
        "pr_title": "feat(spanner): add PG samples for getting-started",
        "pr_number": 2493,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -575,6 +575,18 @@\nfunc TestPgCreateDatabase(t *testing.T) {\n \tdefer cancel()\n \tout := runSampleWithContext(ctx, t, pgCreateDatabase, dbName, \"failed to create a Spanner PG database\")\n \tassertContains(t, out, fmt.Sprintf(\"Created Spanner PostgreSQL database [%s]\", dbName))\n+\n+\tout = runSampleWithContext(ctx, t, pgAddNewColumn, dbName, \"failed to add new column in Spanner PG database\")\n+\tassertContains(t, out, \"Added MarketingBudget column\")\n+\n+\trunSample(t, write, dbName, \"failed to insert data in Spanner PG database\")\n+\trunSample(t, update, dbName, \"failed to update data in Spanner PG database\")\n+\tout = runSample(t, pgWriteWithTransactionUsingDML, dbName, \"failed to write with transaction using DML in Spanner PG database\")\n+\tassertContains(t, out, \"Moved 200000 from Album2's MarketingBudget to Album1\")\n+\tout = runSample(t, pgQueryNewColumn, dbName, \"failed to query new column in Spanner PG database\")\n+\tassertContains(t, out, \"1 1 300000\")\n+\tassertContains(t, out, \"2 2 300000\")\n+\n }\n \n func TestPgQueryParameter(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "move PG samples for getting-started to separate samples and add integration tests for new samples"
        ],
        "last_commit_sha": "cdb87fb2536e7d36072a2311f87c639a345a96a9"
    },
    {
        "pr_title": "feat(spanner): add PG samples for getting-started",
        "pr_number": 2493,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -611,17 +623,22 @@\nfunc TestPgQueryParameter(t *testing.T) {\n \t\t\t\"FirstName\": \"Alice\",\n \t\t\t\"LastName\":  \"Bruxelles\",\n \t\t}),\n+\t\tspanner.InsertOrUpdateMap(\"Singers\", map[string]interface{}{\n+\t\t\t\"SingerId\":  12,\n+\t\t\t\"FirstName\": \"Melissa\",\n+\t\t\t\"LastName\":  \"Garcia\",\n+\t\t}),\n \t})\n \tif err != nil {\n \t\tt.Fatalf(\"failed to insert test records: %v\", err)\n \t}\n \n \tout := runSample(t, pgQueryParameter, dbName, \"failed to execute PG query with parameter\")\n-\tassertContains(t, out, \"1 Bruce Allison\")\n+\tassertContains(t, out, \"12 Melissa Garcia\")\n \tassertNotContains(t, out, \"2 Alice Bruxelles\")\n }\n \n-func TestPgDmlWithParameters(t *testing.T) {\n+func TestPgDmlSample(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n \tt.Parallel()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cdb87fb2536e7d36072a2311f87c639a345a96a9"
    },
    {
        "pr_title": "feat(spanner): add PG samples for getting-started",
        "pr_number": 2493,
        "file_name": "spanner/spanner_snippets/spanner/pg_spanner_create_database.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc pgCreateDatabase(ctx context.Context, w io.Writer, db string) error {\n \t// db := \"projects/my-project/instances/my-instance/databases/my-database\"\n \tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(db)\n \tif matches == nil || len(matches) != 3 {\n-\t\treturn fmt.Errorf(\"invalid database id %s\", db)\n+\t\treturn fmt.Errorf(\"invalid database id %v\", db)\n \t}\n \n \tadminClient, err := database.NewDatabaseAdminClient(ctx)",
        "comments": [],
        "commit_messages": [
            "move PG samples for getting-started to separate samples and add integration tests for new samples"
        ],
        "last_commit_sha": "cdb87fb2536e7d36072a2311f87c639a345a96a9"
    },
    {
        "pr_title": "feat(spanner): add PG samples for getting-started",
        "pr_number": 2493,
        "file_name": "spanner/spanner_snippets/spanner/pg_spanner_create_database.go",
        "code_diff": "@@ -40,6 +40,7 @@\nfunc pgCreateDatabase(ctx context.Context, w io.Writer, db string) error {\n \t}\n \tdefer adminClient.Close()\n \n+\t// Databases with PostgreSQL dialect do not support extra DDL statements in the `CreateDatabase` call.\n \treq := &adminpb.CreateDatabaseRequest{\n \t\tParent:          matches[1],\n \t\tDatabaseDialect: adminpb.DatabaseDialect_POSTGRESQL,",
        "comments": [],
        "commit_messages": [
            "move PG samples for getting-started to separate samples and add integration tests for new samples"
        ],
        "last_commit_sha": "cdb87fb2536e7d36072a2311f87c639a345a96a9"
    },
    {
        "pr_title": "feat(spanner): add PG samples for getting-started",
        "pr_number": 2493,
        "file_name": "spanner/spanner_snippets/spanner/pg_spanner_create_database.go",
        "code_diff": "@@ -54,8 +55,6 @@\nfunc pgCreateDatabase(ctx context.Context, w io.Writer, db string) error {\n \tif _, err := opCreate.Wait(ctx); err != nil {\n \t\treturn err\n \t}\n-\t// Databases that are created with PostgreSQL dialect do not support extra DDL statements in the `CreateDatabase` call.\n-\t// We must therefore execute these in a separate UpdateDatabaseDdl call after the database has been created.\n \tupdateReq := &adminpb.UpdateDatabaseDdlRequest{\n \t\tDatabase: db,\n \t\tStatements: []string{",
        "comments": [],
        "commit_messages": [
            "move PG samples for getting-started to separate samples and add integration tests for new samples"
        ],
        "last_commit_sha": "cdb87fb2536e7d36072a2311f87c639a345a96a9"
    },
    {
        "pr_title": "feat(spanner): add PG samples for getting-started",
        "pr_number": 2493,
        "file_name": "spanner/spanner_snippets/spanner/pg_spanner_create_database.go",
        "code_diff": "@@ -66,9 +65,10 @@\nfunc pgCreateDatabase(ctx context.Context, w io.Writer, db string) error {\n \t\t\t\tSingerInfo bytea\n \t\t\t)`,\n \t\t\t`CREATE TABLE Albums (\n-\t\t\t\tAlbumId      bigint NOT NULL PRIMARY KEY,\n+\t\t\t\tAlbumId      bigint NOT NULL,\n \t\t\t\tSingerId     bigint NOT NULL REFERENCES Singers (SingerId),\n-\t\t\t\tAlbumTitle   text\n+\t\t\t\tAlbumTitle   text,\n+                PRIMARY KEY(SingerId, AlbumId)\n \t\t\t)`,\n \t\t},\n \t}",
        "comments": [],
        "commit_messages": [
            "add more CLIs for equivalent PG samples in getting started"
        ],
        "last_commit_sha": "cdb87fb2536e7d36072a2311f87c639a345a96a9"
    },
    {
        "pr_title": "feat(spanner): add PG samples for getting-started",
        "pr_number": 2493,
        "file_name": "spanner/spanner_snippets/spanner/pg_spanner_query_parameter.go",
        "code_diff": "@@ -38,11 +38,12 @@\nfunc pgQueryParameter(w io.Writer, db string) error {\n \tdefer client.Close()\n \n \tstmt := spanner.Statement{\n-\t\tSQL: `SELECT SingerId, FirstName, LastName FROM Singers WHERE LastName LIKE $1`,\n-\t\t// Use 'p1' to bind to the parameter with index 1.\n-\t\tParams: map[string]interface{}{\"p1\": \"A%\"},\n+\t\tSQL: `SELECT SingerId, FirstName, LastName FROM Singers\n+\t\t\tWHERE LastName = $1`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"p1\": \"Garcia\",\n+\t\t},\n \t}\n-\tfmt.Fprint(w, \"Listing all singers with a last name that starts with 'A'\\n\")\n \ttype Singers struct {\n \t\tSingerID            int64\n \t\tFirstName, LastName string",
        "comments": [],
        "commit_messages": [
            "add more CLIs for equivalent PG samples in getting started"
        ],
        "last_commit_sha": "cdb87fb2536e7d36072a2311f87c639a345a96a9"
    },
    {
        "pr_title": "feat(pubsublite): support regional resources in samples",
        "pr_number": 2492,
        "file_name": "pubsublite/admin/create_subscription.go",
        "code_diff": "@@ -23,11 +23,13 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func createSubscription(w io.Writer, projectID, region, zone, topicID, subID string) error {\n+func createSubscription(w io.Writer, projectID, region, location, topicID, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n-\t// NOTE: topic and subscription must be in the same zone (i.e. \"us-central1-a\")\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n+\t// NOTE: topic and subscription must be in the same region/zone (e.g. \"us-central1-a\")\n \t// topicID := \"my-topic\"\n \t// subID := \"my-subscription\"\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): support regional resources in samples"
        ],
        "last_commit_sha": "d37a0d63ae752a35734ec033e60d41138fbeef04"
    },
    {
        "pr_title": "feat(pubsublite): support regional resources in samples",
        "pr_number": 2492,
        "file_name": "pubsublite/admin/create_topic.go",
        "code_diff": "@@ -23,13 +23,14 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func createTopic(w io.Writer, projectID, region, zone, topicID, reservation string, regional bool) error {\n+func createTopic(w io.Writer, projectID, region, location, topicID, reservation string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\" // see https://cloud.google.com/pubsub/lite/docs/locations\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// topicID := \"my-topic\"\n \t// reservation := \"projects/my-project-id/reservations/my-reservation\"\n-\t// regional := \"true\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): support regional resources in samples"
        ],
        "last_commit_sha": "d37a0d63ae752a35734ec033e60d41138fbeef04"
    },
    {
        "pr_title": "feat(pubsublite): support regional resources in samples",
        "pr_number": 2492,
        "file_name": "pubsublite/admin/create_topic.go",
        "code_diff": "@@ -39,12 +40,7 @@\nfunc createTopic(w io.Writer, projectID, region, zone, topicID, reservation stri\n \n \tconst gib = 1 << 30\n \n-\tvar topicPath string\n-\tif regional {\n-\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, region, topicID)\n-\t} else {\n-\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, zone, topicID)\n-\t}\n+\ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, location, topicID)\n \t// For ranges of fields in TopicConfig, see https://pkg.go.dev/cloud.google.com/go/pubsublite/#TopicConfig\n \ttopic, err := client.CreateTopic(ctx, pubsublite.TopicConfig{\n \t\tName:                       topicPath,",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): support regional resources in samples"
        ],
        "last_commit_sha": "d37a0d63ae752a35734ec033e60d41138fbeef04"
    },
    {
        "pr_title": "feat(pubsublite): support regional resources in samples",
        "pr_number": 2492,
        "file_name": "pubsublite/admin/delete_subscription.go",
        "code_diff": "@@ -23,10 +23,12 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func deleteSubscription(w io.Writer, projectID, region, zone, subID string) error {\n+func deleteSubscription(w io.Writer, projectID, region, location, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// subID := \"my-subscription\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): support regional resources in samples"
        ],
        "last_commit_sha": "d37a0d63ae752a35734ec033e60d41138fbeef04"
    },
    {
        "pr_title": "feat(pubsublite): support regional resources in samples",
        "pr_number": 2492,
        "file_name": "pubsublite/admin/get_subscription.go",
        "code_diff": "@@ -23,10 +23,12 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func getSubscription(w io.Writer, projectID, region, zone, subID string) error {\n+func getSubscription(w io.Writer, projectID, region, location, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// subID := \"my-subscription\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): support regional resources in samples"
        ],
        "last_commit_sha": "d37a0d63ae752a35734ec033e60d41138fbeef04"
    },
    {
        "pr_title": "feat(pubsublite): support regional resources in samples",
        "pr_number": 2492,
        "file_name": "pubsublite/admin/get_topic.go",
        "code_diff": "@@ -23,10 +23,12 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func getTopic(w io.Writer, projectID, region, zone, topicID string, regional bool) error {\n+func getTopic(w io.Writer, projectID, region, location, topicID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// topicID := \"my-topic\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): support regional resources in samples"
        ],
        "last_commit_sha": "d37a0d63ae752a35734ec033e60d41138fbeef04"
    },
    {
        "pr_title": "feat(pubsublite): support regional resources in samples",
        "pr_number": 2492,
        "file_name": "pubsublite/admin/list_subscriptions_in_project.go",
        "code_diff": "@@ -24,10 +24,12 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n-func listSubscriptionsInProject(w io.Writer, projectID, region, zone string) error {\n+func listSubscriptionsInProject(w io.Writer, projectID, region, location string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): support regional resources in samples"
        ],
        "last_commit_sha": "d37a0d63ae752a35734ec033e60d41138fbeef04"
    },
    {
        "pr_title": "feat(pubsublite): support regional resources in samples",
        "pr_number": 2492,
        "file_name": "pubsublite/admin/list_subscriptions_in_topic.go",
        "code_diff": "@@ -24,10 +24,12 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n-func listSubscriptionsInTopic(w io.Writer, projectID, region, zone, topicID string) error {\n+func listSubscriptionsInTopic(w io.Writer, projectID, region, location, topicID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central\"\n \t// topicID := \"my-topic\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): support regional resources in samples"
        ],
        "last_commit_sha": "d37a0d63ae752a35734ec033e60d41138fbeef04"
    },
    {
        "pr_title": "feat(pubsublite): support regional resources in samples",
        "pr_number": 2492,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -86,15 +86,22 @@\nfunc TestTopicAdmin(t *testing.T) {\n \ttestZone := randomZone()\n \n \ttopicID := resourcePrefix + uuid.NewString()\n-\ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \tt.Run(\"CreateTopic\", func(t *testing.T) {\n+\t\tctx := context.Background()\n+\t\treservationID = resourcePrefix + uuid.NewString()\n+\t\treservationPath = fmt.Sprintf(\"projects/%s/locations/%s/reservations/%s\", projNumber, testRegion, reservationID)\n+\t\tclient.CreateReservation(ctx, pubsublite.ReservationConfig{\n+\t\t\tName:               reservationPath,\n+\t\t\tThroughputCapacity: 4,\n+\t\t})\n+\n \t\tbuf := new(bytes.Buffer)\n-\t\terr := createTopic(buf, tc.ProjectID, testRegion, testZone, topicID, \"\", false)\n+\t\terr := createTopic(buf, tc.ProjectID, testRegion, testZone, topicID, reservationPath)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"createTopic: %v\", err)\n \t\t}\n \t\tgot := buf.String()\n-\t\twant := \"Created zonal topic\"\n+\t\twant := \"Created topic\"\n \t\tif !strings.Contains(got, want) {\n \t\t\tt.Fatalf(\"createTopic() mismatch: got: %s\\nwant: %s\", got, want)\n \t\t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d37a0d63ae752a35734ec033e60d41138fbeef04"
    },
    {
        "pr_title": "feat(pubsublite): support regional resources in samples",
        "pr_number": 2492,
        "file_name": "pubsublite/admin/update_subscription.go",
        "code_diff": "@@ -23,10 +23,12 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func updateSubscription(w io.Writer, projectID, region, zone, subID string) error {\n+func updateSubscription(w io.Writer, projectID, region, location, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// subID := \"my-subscription\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): support regional resources in samples"
        ],
        "last_commit_sha": "d37a0d63ae752a35734ec033e60d41138fbeef04"
    },
    {
        "pr_title": "feat(pubsublite): support regional resources in samples",
        "pr_number": 2492,
        "file_name": "pubsublite/admin/update_topic.go",
        "code_diff": "@@ -24,26 +24,22 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func updateTopic(w io.Writer, projectID, region, zone, topicID, reservation string, regional bool) error {\n+func updateTopic(w io.Writer, projectID, region, location, topicID, reservation string) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n-\t// zone := \"us-central1-a\"\n+\t// NOTE: location can be either a region (\"us-central1\") or a zone (\"us-central1-a\")\n+\t// For a list of valid locations, see https://cloud.google.com/pubsub/lite/docs/locations.\n+\t// location := \"us-central1\"\n \t// topicID := \"my-topic\"\n \t// reservation := \"projects/my-project-id/reservations/my-reservation\"\n-\t// regional := \"true\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"pubsublite.NewAdminClient: %v\", err)\n \t}\n \tdefer client.Close()\n \n-\tvar topicPath string\n-\tif regional {\n-\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, region, topicID)\n-\t} else {\n-\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, zone, topicID)\n-\t}\n+\ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, location, topicID)\n \t// For ranges of fields in TopicConfigToUpdate, see https://pkg.go.dev/cloud.google.com/go/pubsublite/#TopicConfigToUpdate\n \tconfig := pubsublite.TopicConfigToUpdate{\n \t\tName:                       topicPath,",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): support regional resources in samples"
        ],
        "last_commit_sha": "d37a0d63ae752a35734ec033e60d41138fbeef04"
    },
    {
        "pr_title": "fix(run): deflake sigterm-handler by sigterm'ing explicitly",
        "pr_number": 2481,
        "file_name": "run/sigterm-handler/main.go",
        "code_diff": "@@ -27,6 +27,9 @@\nimport (\n \t\"time\"\n )\n \n+// Create channel to listen for signals.\n+var signalChan chan (os.Signal) = make(chan os.Signal, 1)\n+\n func main() {\n \t// Determine port for HTTP service.\n \tport := os.Getenv(\"PORT\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3c6e41298f20b83b1f826c1d6f0c3b0c668b568f"
    },
    {
        "pr_title": "fix(run): deflake sigterm-handler by sigterm'ing explicitly",
        "pr_number": 2481,
        "file_name": "run/sigterm-handler/main.go",
        "code_diff": "@@ -40,8 +43,6 @@\nfunc main() {\n \t\tHandler: http.HandlerFunc(handler),\n \t}\n \n-\t// Create channel to listen for signals.\n-\tsignalChan := make(chan os.Signal, 1)\n \t// SIGINT handles Ctrl+C locally.\n \t// SIGTERM handles Cloud Run termination signal.\n \tsignal.Notify(signalChan, syscall.SIGINT, syscall.SIGTERM)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3c6e41298f20b83b1f826c1d6f0c3b0c668b568f"
    },
    {
        "pr_title": "fix(run): deflake sigterm-handler by sigterm'ing explicitly",
        "pr_number": 2481,
        "file_name": "run/testing/sigterm_handler.e2e_test.go",
        "code_diff": "@@ -35,13 +35,14 @@\nfunc TestSigtermHandlerService(t *testing.T) {\n \tdefer GetLogEntries(service, t)\n \tdefer service.Clean()\n \n-\trequestPath := \"/\"\n+\t// Explicitly send SIGTERM\n+\trequestPath := \"/?terminate=1\"\n \treq, err := service.NewRequest(\"GET\", requestPath)\n \tif err != nil {\n \t\tt.Fatalf(\"service.NewRequest: %v\", err)\n \t}\n \n-\tclient := http.Client{Timeout: 10 * time.Second}\n+\tclient := http.Client{Timeout: 30 * time.Second}\n \tresp, err := client.Do(req)\n \tif err != nil {\n \t\tt.Fatalf(\"client.Do: %v\", err)",
        "comments": [],
        "commit_messages": [
            "fix(run): deflake by sigterm'ing explicitly\n\nExplicitly terminate, rather that relying on instance timeouts."
        ],
        "last_commit_sha": "3c6e41298f20b83b1f826c1d6f0c3b0c668b568f"
    },
    {
        "pr_title": "fix(serverless): clean up ID token example",
        "pr_number": 2472,
        "file_name": "functions/security/idtoken.go",
        "code_diff": "@@ -17,7 +17,6 @@\npackage security\n \n // [START functions_bearer_token]\n // [START cloudrun_service_to_service_auth]\n-// [START run_service_to_service_auth]\n \n import (\n \t\"context\"",
        "comments": [
            {
                "comment": "This context may be in the accompanying docs, but in all uses I see here, targetURL and audience are identical. I'd suggest including an explanation of when these args might differ, for other readers without context.",
                "position": 17
            },
            {
                "comment": "Fixed.",
                "position": 17
            }
        ],
        "commit_messages": [
            "fix(serverless): clean up ID token example"
        ],
        "last_commit_sha": "46e33366fd2b2f02121f03628fa2a386cfbacdb1"
    },
    {
        "pr_title": "fix(serverless): clean up ID token example",
        "pr_number": 2472,
        "file_name": "functions/security/idtoken.go",
        "code_diff": "@@ -27,14 +26,22 @@\nimport (\n \t\"google.golang.org/api/idtoken\"\n )\n \n-// makeGetRequest makes a request to the provided targetURL with an authenticated client.\n-func makeGetRequest(w io.Writer, targetURL string) error {\n-\t// functionURL := \"https://TARGET_URL\"\n+// `makeGetRequest` makes a request to the provided `targetURL`\n+// with an authenticated client using audience `audience`.\n+func makeGetRequest(w io.Writer, targetURL string, audience string) error {\n+\t// [END functions_bearer_token]\n+\t// Example `audience` value (Cloud Run): https://my-cloud-run-service.run.app/\n+\t// (`targetURL` and `audience` will differ for non-root URLs and GET parameters)\n+\t// [END cloudrun_service_to_service_auth]\n+\t// [START functions_bearer_token]\n+\t// Example `audience` value (Cloud Functions): https://<PROJECT>-<REGION>-<PROJECT_ID>.cloudfunctions.net/myFunction\n+\t// (`targetURL` and `audience` will differ for GET parameters)\n+\t// [START cloudrun_service_to_service_auth]\n \tctx := context.Background()\n \n \t// client is a http.Client that automatically adds an \"Authorization\" header\n \t// to any requests made.\n-\tclient, err := idtoken.NewClient(ctx, targetURL)\n+\tclient, err := idtoken.NewClient(ctx, audience)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"idtoken.NewClient: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "46e33366fd2b2f02121f03628fa2a386cfbacdb1"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -562,6 +562,280 @@\nfunc TestCreateDatabaseWithDefaultLeaderSample(t *testing.T) {\n \tassertContains(t, out, \"The result of the query to get\")\n }\n \n+func TestPgCreateDatabase(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\n+\tctx, cancel := context.WithTimeout(context.Background(), time.Hour)\n+\tdefer cancel()\n+\tout := runSampleWithContext(ctx, t, pgCreateDatabase, dbName, \"failed to create a Spanner PG database\")\n+\tassertContains(t, out, fmt.Sprintf(\"Created Spanner PostgreSQL database [%s]\", dbName))\n+}\n+\n+func TestPgQueryParameter(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tdbCleanup, err := createTestPgDatabase(\n+\t\tdbName,\n+\t\t`CREATE TABLE Singers (\n+\t\t   SingerId  bigint NOT NULL PRIMARY KEY,\n+\t\t   FirstName varchar(1024),\n+\t\t   LastName  varchar(1024)\n+\t\t )`)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tclient, err := spanner.NewClient(context.Background(), dbName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create Spanner client: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\t_, err = client.Apply(context.Background(), []*spanner.Mutation{\n+\t\tspanner.InsertOrUpdateMap(\"Singers\", map[string]interface{}{\n+\t\t\t\"SingerId\":  1,\n+\t\t\t\"FirstName\": \"Bruce\",\n+\t\t\t\"LastName\":  \"Allison\",\n+\t\t}),\n+\t\tspanner.InsertOrUpdateMap(\"Singers\", map[string]interface{}{\n+\t\t\t\"SingerId\":  2,\n+\t\t\t\"FirstName\": \"Alice\",\n+\t\t\t\"LastName\":  \"Bruxelles\",\n+\t\t}),\n+\t})\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to insert test records: %v\", err)\n+\t}\n+\n+\tout := runSample(t, pgQueryParameter, dbName, \"failed to execute PG query with parameter\")\n+\tassertContains(t, out, \"1 Bruce Allison\")\n+\tassertNotContains(t, out, \"2 Alice Bruxelles\")\n+}\n+\n+func TestPgDmlWithParameters(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tdbCleanup, err := createTestPgDatabase(\n+\t\tdbName,\n+\t\t`CREATE TABLE Singers (\n+\t\t   SingerId  bigint NOT NULL PRIMARY KEY,\n+\t\t   FirstName varchar(1024),\n+\t\t   LastName  varchar(1024)\n+\t\t )`)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tout := runSample(t, pgDmlWithParameters, dbName, \"failed to execute PG DML with parameter\")\n+\tassertContains(t, out, \"Inserted 2 singers\")\n+}\n+\n+func TestPgNumericDataType(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tdbCleanup, err := createTestPgDatabase(dbName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tout := runSample(t, pgNumericDataType, dbName, \"failed to execute PG Numeric sample\")\n+\tassertContains(t, out, \"Inserted 1 venue(s)\")\n+\tassertContains(t, out, \"Revenues of Venue 1: 3150.25\")\n+\tassertContains(t, out, \"Revenues of Venue 2: <null>\")\n+\tassertContains(t, out, \"Revenues of Venue 3: NaN\")\n+\tassertContains(t, out, \"Inserted 2 Venues using mutations\")\n+}\n+\n+func TestPgFunctions(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tdbCleanup, err := createTestPgDatabase(dbName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tout := runSample(t, pgFunctions, dbName, \"failed to execute PG functions sample\")\n+\tassertContains(t, out, \"1284352323 seconds after epoch is 2010-09-13 04:32:03 +0000 UTC\")\n+}\n+\n+func TestPgInformationSchema(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tdbCleanup, err := createTestPgDatabase(dbName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tout := runSample(t, pgInformationSchema, dbName, \"failed to execute PG INFORMATION_SCHEMA sample\")\n+\tassertContains(t, out, \"Table: public.venues (User defined type: null)\")\n+}\n+\n+func TestPgCastDataType(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tdbCleanup, err := createTestPgDatabase(dbName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tout := runSample(t, pgCastDataType, dbName, \"failed to execute PG cast data type sample\")\n+\tassertContains(t, out, \"String: 1\")\n+\tassertContains(t, out, \"Int: 2\")\n+\tassertContains(t, out, \"Decimal: 3\")\n+\tassertContains(t, out, \"Bytes: 4\")\n+\tassertContains(t, out, \"Bool: true\")\n+\tassertContains(t, out, \"Timestamp: 2021-11-03 09:35:01 +0000 UTC\")\n+}\n+\n+func TestPgInterleavedTable(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tdbCleanup, err := createTestPgDatabase(dbName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tout := runSample(t, pgInterleavedTable, dbName, \"failed to execute PG interleaved table sample\")\n+\tassertContains(t, out, \"Created interleaved table hierarchy using PostgreSQL dialect\")\n+}\n+\n+func TestPgBatchDml(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tdbCleanup, err := createTestPgDatabase(\n+\t\tdbName,\n+\t\t`CREATE TABLE Singers (\n+\t\t   SingerId  bigint NOT NULL PRIMARY KEY,\n+\t\t   FirstName varchar(1024),\n+\t\t   LastName  varchar(1024)\n+\t\t )`)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tout := runSample(t, pgBatchDml, dbName, \"failed to execute PG Batch DML sample\")\n+\tassertContains(t, out, \"Inserted [1 1] singers\")\n+}\n+\n+func TestPgPartitionedDml(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tdbCleanup, err := createTestPgDatabase(\n+\t\tdbName,\n+\t\t`CREATE TABLE users (\n+\t\t\tuser_id   bigint NOT NULL PRIMARY KEY,\n+\t\t\tuser_name varchar(1024),\n+\t\t\tactive    boolean\n+\t\t)`)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tclient, err := spanner.NewClient(context.Background(), dbName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create Spanner client: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\t_, err = client.Apply(context.Background(), []*spanner.Mutation{\n+\t\tspanner.InsertOrUpdateMap(\"users\", map[string]interface{}{\n+\t\t\t\"user_id\":   1,\n+\t\t\t\"user_name\": \"User 1\",\n+\t\t\t\"active\":    false,\n+\t\t}),\n+\t\tspanner.InsertOrUpdateMap(\"users\", map[string]interface{}{\n+\t\t\t\"user_id\":   2,\n+\t\t\t\"user_name\": \"User 2\",\n+\t\t\t\"active\":    false,\n+\t\t}),\n+\t\tspanner.InsertOrUpdateMap(\"users\", map[string]interface{}{\n+\t\t\t\"user_id\":   3,\n+\t\t\t\"user_name\": \"User 3\",\n+\t\t\t\"active\":    true,\n+\t\t}),\n+\t})\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to insert test records: %v\", err)\n+\t}\n+\n+\tout := runSample(t, pgPartitionedDml, dbName, \"failed to execute PG Partitioned DML sample\")\n+\tassertContains(t, out, \"Deleted at least 2 inactive users\")\n+}\n+\n+func TestPgCaseSensitivity(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tdbCleanup, err := createTestPgDatabase(dbName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tout := runSample(t, pgCaseSensitivity, dbName, \"failed to execute PG case sensitivity sample\")\n+\tassertContains(t, out, \"SingerId: 1, FirstName: Bruce, LastName: Allison\")\n+\tassertContains(t, out, \"SingerId: 1, FullName: Bruce Allison\")\n+}\n+\n+func TestPgOrderNulls(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\t_, dbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tdbCleanup, err := createTestPgDatabase(dbName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create test database: %v\", err)\n+\t}\n+\tdefer dbCleanup()\n+\n+\tout := runSample(t, pgOrderNulls, dbName, \"failed to execute PG order nulls sample\")\n+\tassertContains(t, out, \"Singers ORDER BY Name\\n\\tAlice\\n\\tBruce\\n\\t<null>\")\n+\tassertContains(t, out, \"Singers ORDER BY Name DESC\\n\\t<null>\\n\\tBruce\\n\\tAlice\")\n+\tassertContains(t, out, \"Singers ORDER BY Name NULLS FIRST\\n\\t<null>\\n\\tAlice\\n\\tBruce\")\n+\tassertContains(t, out, \"Singers ORDER BY Name DESC NULLS LAST\\n\\tBruce\\n\\tAlice\\n\\t<null>\")\n+}\n+\n func maybeCreateKey(projectId, locationId, keyRingId, keyId string) error {\n \tclient, err := kms.NewKeyManagementClient(context.Background())\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "spanner/spanner_snippets/spanner/spanner_create_clients.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2020 Google LLC\n+// Copyright 2022 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "incorporate requested changes"
        ],
        "last_commit_sha": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(spanner): add samples for PG",
        "pr_number": 2469,
        "file_name": "spanner/spanner_snippets/spanner/spanner_create_clients.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage spanner\n \n // [START spanner_create_clients]\n+// [START spanner_postgresql_create_clients]\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "incorporate requested changes"
        ],
        "last_commit_sha": "ec4c9d05583ffba38f3eb80e2181bd27a7379ea4"
    },
    {
        "pr_title": "feat(secretmanager): Updated samples with checksum use examples",
        "pr_number": 2459,
        "file_name": "secretmanager/access_secret_version.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage secretmanager\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tsecretmanager \"cloud.google.com/go/secretmanager/apiv1\"",
        "comments": [],
        "commit_messages": [
            "feat(secretmanager): Updated samples with checksum use examples"
        ],
        "last_commit_sha": "1a52f0ad5dad8fad936b795b9392c64f59f8caaa"
    },
    {
        "pr_title": "feat(secretmanager): Updated samples with checksum use examples",
        "pr_number": 2459,
        "file_name": "secretmanager/add_secret_version.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage secretmanager\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tsecretmanager \"cloud.google.com/go/secretmanager/apiv1\"",
        "comments": [],
        "commit_messages": [
            "feat(secretmanager): Updated samples with checksum use examples"
        ],
        "last_commit_sha": "1a52f0ad5dad8fad936b795b9392c64f59f8caaa"
    },
    {
        "pr_title": "feat(secretmanager): Updated samples with checksum use examples",
        "pr_number": 2459,
        "file_name": "secretmanager/add_secret_version.go",
        "code_diff": "@@ -31,6 +32,10 @@\nfunc addSecretVersion(w io.Writer, parent string) error {\n \n \t// Declare the payload to store.\n \tpayload := []byte(\"my super secret data\")\n+\t// Compute checksum, use Castagnoli polynomial. Providing a checksum\n+\t// is optional.\n+\tcrc32c := crc32.MakeTable(crc32.Castagnoli)\n+\tchecksum := int64(crc32.Checksum(payload, crc32c))\n \n \t// Create the client.\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "feat(secretmanager): Updated samples with checksum use examples"
        ],
        "last_commit_sha": "1a52f0ad5dad8fad936b795b9392c64f59f8caaa"
    },
    {
        "pr_title": "feat(storage): add preconditions to object samples",
        "pr_number": 2442,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -91,8 +91,8 @@\nfunc TestObjects(t *testing.T) {\n \t// Keep the original generation of object1 before re-uploading\n \t// to use in the versioning samples.\n \tgen := attrs.Generation\n-\tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n-\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n+\tif err := streamFileUpload(ioutil.Discard, bucketVersioning, object1); err != nil {\n+\t\tt.Fatalf(\"streamFileUpload(%q): %v\", object1, err)\n \t}\n \n \t{",
        "comments": [],
        "commit_messages": [
            "fix test"
        ],
        "last_commit_sha": "5977f19f216b741e773453f9ae974fa804629a5b"
    },
    {
        "pr_title": "feat(storage): add preconditions to object samples",
        "pr_number": 2442,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -264,6 +264,10 @@\nfunc TestObjects(t *testing.T) {\n \t\t}\n \t})\n \n+\tif err := deleteFile(ioutil.Discard, bucket, object1); err != nil {\n+\t\tt.Errorf(\"deleteFile: %v\", err)\n+\t}\n+\n \tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \tnewKey := []byte(\"My-secret-AES-256-encryption-key\")",
        "comments": [],
        "commit_messages": [
            "fix test"
        ],
        "last_commit_sha": "5977f19f216b741e773453f9ae974fa804629a5b"
    },
    {
        "pr_title": "feat(storage): add preconditions to object samples",
        "pr_number": 2442,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -354,7 +358,7 @@\nfunc TestKMSObjects(t *testing.T) {\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \tt.Run(\"\u0441hangeObjectCSEKtoKMS\", func(t *testing.T) {\n-\t\tobject1 := \"foo.txt\"\n+\t\tobject1 := \"foo1.txt\"\n \t\tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \t\tobj := client.Bucket(bucket).Object(object1)",
        "comments": [],
        "commit_messages": [
            "fix kms test"
        ],
        "last_commit_sha": "5977f19f216b741e773453f9ae974fa804629a5b"
    },
    {
        "pr_title": "feat(cloudsql/sqlserver): update to v2 sample",
        "pr_number": 2436,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql.go",
        "code_diff": "@@ -12,11 +12,11 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Sample database-sql demonstrates connection to a Cloud SQL instance from App Engine\n-// standard. The application is a Golang version of the \"Tabs vs Spaces\" web\n-// app presented at Cloud Next '19 as seen in this video:\n+// Sample database-sql demonstrates connecting to a Cloud SQL instance.\n+// The application is a Go version of the \"Tabs vs Spaces\"\n+// web app presented at Google Cloud Next 2019 as seen in this video:\n // https://www.youtube.com/watch?v=qVgzP3PsXFw&t=1833s\n-package main\n+package cloudsql\n \n import (\n \t\"database/sql\"",
        "comments": [],
        "commit_messages": [
            "feat(cloudsql/sqlserver): update to v2 sample"
        ],
        "last_commit_sha": "cc4a6036f70102f27e2b4425bf9f9b532ba032ea"
    },
    {
        "pr_title": "feat(cloudsql/sqlserver): update to v2 sample",
        "pr_number": 2436,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudsql\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_messages": [
            "feat(cloudsql/sqlserver): update to v2 sample"
        ],
        "last_commit_sha": "cc4a6036f70102f27e2b4425bf9f9b532ba032ea"
    },
    {
        "pr_title": "feat(cloudsql/postgres): update to v2 samples",
        "pr_number": 2433,
        "file_name": "cloudsql/postgres/database-sql/cloudsql.go",
        "code_diff": "@@ -12,11 +12,11 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Sample database-sql demonstrates connection to a Cloud SQL instance from App Engine\n-// standard. The application is a Golang version of the \"Tabs vs Spaces\" web\n-// app presented at Cloud Next '19 as seen in this video:\n+// Sample database-sql demonstrates connecting to a Cloud SQL instance.\n+// The application is a Go version of the \"Tabs vs Spaces\"\n+// web app presented at Google Cloud Next 2019 as seen in this video:\n // https://www.youtube.com/watch?v=qVgzP3PsXFw&t=1833s\n-package main\n+package cloudsql\n \n import (\n \t\"database/sql\"",
        "comments": [],
        "commit_messages": [
            "feat(cloudsql/postgres): update to v2 samples"
        ],
        "last_commit_sha": "35199c04e1961a70a8a93858a206f84bef9bde6f"
    },
    {
        "pr_title": "feat(cloudsql/postgres): update to v2 samples",
        "pr_number": 2433,
        "file_name": "cloudsql/postgres/database-sql/cloudsql_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudsql\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_messages": [
            "feat(cloudsql/postgres): update to v2 samples"
        ],
        "last_commit_sha": "35199c04e1961a70a8a93858a206f84bef9bde6f"
    },
    {
        "pr_title": "fix(opencensus): trace exemplar example to show how to use attachments",
        "pr_number": 2402,
        "file_name": "opencensus/trace_exemplar.go",
        "code_diff": "@@ -19,15 +19,33 @@\npackage opencensus\n \n // [START monitoring_opencensus_configure_trace_exemplar]\n import (\n+\t\"fmt\"\n \t\"time\"\n \n \tgooglepb \"github.com/golang/protobuf/ptypes/timestamp\"\n \tdistributionpb \"google.golang.org/genproto/googleapis/api/distribution\"\n \tmonitoringpb \"google.golang.org/genproto/googleapis/monitoring/v3\"\n+\t\"google.golang.org/protobuf/types/known/anypb\"\n )\n \n-func createDataPointWithExemplar() *monitoringpb.Point {\n+// Generates metric TimeSeries points containing Exemplars with attached tracing span.\n+func createDataPointWithExemplar(projectID string) (*monitoringpb.Point, error) {\n+\t// projectID := \"my-cloud-project-id\"\n \tend := time.Now().Unix()\n+\ttraceId := \"0000000000000001\"\n+\tspanId := \"00000001\"\n+\tspanCtx, err := anypb.New(&monitoringpb.SpanContext{\n+\t\tSpanName: fmt.Sprintf(\"projects/%s/traces/%s/spans/%s\", projectID, traceId, spanId),\n+\t})\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tdroppedLabels, err := anypb.New(&monitoringpb.DroppedLabels{\n+\t\tLabel: map[string]string{\"Label\": \"Dropped\"},\n+\t})\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n \tdataPoint := &monitoringpb.Point{\n \t\tInterval: &monitoringpb.TimeInterval{\n \t\t\tStartTime: &googlepb.Timestamp{Seconds: end - 60},",
        "comments": [],
        "commit_messages": [
            "fix: trace exemplar exemplar missing traces.\n\nTrace Exemplar example showed how to make exemplars, but not with attachments. This adds both the `DroppedLabels` attachment and the `SpanContext` attachment to demonstrate how to do trace-metric correlation."
        ],
        "last_commit_sha": "c989e7269bf29ee6fc4ede75df7d9f3fbf137f8c"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -33,12 +33,14 @@\nconst (\n \ttemplateID               = \"my-go-test-template\"\n \tdeleteTemplateReponse    = \"Deleted job template\"\n \tdeleteJobReponse         = \"Deleted job\"\n+\tjobRunningState          = \"RUNNING\"\n \tjobSucceededState        = \"SUCCEEDED\"\n \ttestBucketName           = \"cloud-samples-data\"\n \ttestBucketDirName        = \"media/\"\n \ttestVideoFileName        = \"ChromeCast.mp4\"\n \ttestConcatFileName       = \"ForBiggerEscapes.mp4\"\n \ttestOverlayImageFileName = \"overlay.jpg\"\n+\ttestCaptionsFileName     = \"caption.srt\"\n \tpreset                   = \"preset/web-hd\"\n \tsmallSpriteSheetFileName = \"small-sprite-sheet0000000000.jpeg\"\n \tlargeSpriteSheetFileName = \"large-sprite-sheet0000000000.jpeg\"",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -62,6 +64,7 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tinputURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testVideoFileName\n \tinputConcatURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testConcatFileName\n \tinputOverlayImageURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testOverlayImageFileName\n+\tinputCaptionsURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testCaptionsFileName\n \toutputURIForPreset := \"gs://\" + bucketName + \"/test-output-preset/\"\n \toutputURIForTemplate := \"gs://\" + bucketName + \"/test-output-template/\"\n \toutputURIForAdHoc := \"gs://\" + bucketName + \"/test-output-adhoc/\"",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -72,6 +75,8 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \toutputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n \toutputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n \toutputURIForConcat := \"gs://\" + bucketName + \"/test-output-concat/\"\n+\toutputURIForEmbeddedCaptions := \"gs://\" + bucketName + \"/test-output-embedded-captions/\"\n+\toutputURIForStandaloneCaptions := \"gs://\" + bucketName + \"/test-output-standalone-captions/\"\n \n \t// Get the project number\n \tcloudresourcemanagerClient, err := cloudresourcemanager.NewService(ctx)",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -113,6 +118,11 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \n \ttestJobWithConcatenatedInputs(t, projectNumber, inputURI, 0*time.Second, 8*time.Second+100*time.Millisecond, inputConcatURI, 3*time.Second+500*time.Millisecond, 15*time.Second, outputURIForConcat)\n \tt.Logf(\"\\ntestJobWithConcatenatedInputs() completed\\n\")\n+\n+\ttestJobWithEmbeddedCaptions(t, projectNumber, inputURI, inputCaptionsURI, outputURIForEmbeddedCaptions)\n+\tt.Logf(\"\\ntestJobWithEmbeddedCaptions() completed\\n\")\n+\ttestJobWithStandaloneCaptions(t, projectNumber, inputURI, inputCaptionsURI, outputURIForStandaloneCaptions)\n+\tt.Logf(\"\\ntestJobWithStandaloneCaptions() completed\\n\")\n }\n \n // testJobTemplates tests major operations on job templates. Create, get,",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -182,6 +192,7 @@\nfunc writeTestGCSFiles(t *testing.T, projectID string, bucketName string) {\n \twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testVideoFileName)\n \twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testOverlayImageFileName)\n \twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testConcatFileName)\n+\twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testCaptionsFileName)\n }\n \n // writeTestGCSFile deletes the GCS test bucket and uploads a test video file to it.",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -247,6 +258,7 @@\nfunc testJobFromPreset(t *testing.T, projectNumber string, inputURI string, outp\n \t}\n \tstrSlice := strings.Split(got, \"/\")\n \tjobID = strSlice[len(strSlice)-1]\n+\tbuf.Reset()\n \n \t// Get the job by job ID.\n \ttestutil.Retry(t, 3, 5*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -258,14 +270,23 @@\nfunc testJobFromPreset(t *testing.T, projectNumber string, inputURI string, outp\n \t\t\tr.Errorf(\"getJob got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobName)\n \t\t}\n \t})\n+\tbuf.Reset()\n \n-\t// Get the job state (should be succeeded).\n-\ttestutil.Retry(t, 10, 60*time.Second, func(r *testutil.R) {\n+\t// Get the job state, which should be succeeded. If the job is still running on the last attempt, pass the test.\n+\ttestutil.Retry(t, 3, 30*time.Second, func(r *testutil.R) {\n \t\tif err := getJobState(buf, tc.ProjectID, location, jobID); err != nil {\n \t\t\tr.Errorf(\"getJobState got err: %v\", err)\n \t\t}\n-\t\tif got := buf.String(); !strings.Contains(got, jobSucceededState) {\n-\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\tgot := buf.String()\n+\n+\t\tif r.Attempt == 3 {\n+\t\t\tif !strings.Contains(got, jobSucceededState) && !strings.Contains(got, jobRunningState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v or %v\\n----\\n\", got, jobSucceededState, jobRunningState)\n+\t\t\t}\n+\t\t} else {\n+\t\t\tif !strings.Contains(got, jobSucceededState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\t\t}\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -320,14 +341,23 @@\nfunc testJobFromTemplate(t *testing.T, projectNumber string, inputURI string, ou\n \t}\n \tstrSlice := strings.Split(got, \"/\")\n \tjobID = strSlice[len(strSlice)-1]\n+\tbuf.Reset()\n \n-\t// Get the job state (should be succeeded).\n-\ttestutil.Retry(t, 10, 60*time.Second, func(r *testutil.R) {\n+\t// Get the job state, which should be succeeded. If the job is still running on the last attempt, pass the test.\n+\ttestutil.Retry(t, 3, 30*time.Second, func(r *testutil.R) {\n \t\tif err := getJobState(buf, tc.ProjectID, location, jobID); err != nil {\n \t\t\tr.Errorf(\"getJobState got err: %v\", err)\n \t\t}\n-\t\tif got := buf.String(); !strings.Contains(got, jobSucceededState) {\n-\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\tgot := buf.String()\n+\n+\t\tif r.Attempt == 3 {\n+\t\t\tif !strings.Contains(got, jobSucceededState) && !strings.Contains(got, jobRunningState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v or %v\\n----\\n\", got, jobSucceededState, jobRunningState)\n+\t\t\t}\n+\t\t} else {\n+\t\t\tif !strings.Contains(got, jobSucceededState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\t\t}\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -371,6 +401,7 @@\nfunc testJobFromAdHoc(t *testing.T, projectNumber string, inputURI string, outpu\n \t}\n \tstrSlice := strings.Split(got, \"/\")\n \tjobID = strSlice[len(strSlice)-1]\n+\tbuf.Reset()\n \n \t// Get the job.\n \ttestutil.Retry(t, 3, 5*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -382,14 +413,23 @@\nfunc testJobFromAdHoc(t *testing.T, projectNumber string, inputURI string, outpu\n \t\t\tr.Errorf(\"getJob got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobName)\n \t\t}\n \t})\n+\tbuf.Reset()\n \n-\t// Get the job state (should be succeeded).\n-\ttestutil.Retry(t, 10, 60*time.Second, func(r *testutil.R) {\n+\t// Get the job state, which should be succeeded. If the job is still running on the last attempt, pass the test.\n+\ttestutil.Retry(t, 3, 30*time.Second, func(r *testutil.R) {\n \t\tif err := getJobState(buf, tc.ProjectID, location, jobID); err != nil {\n \t\t\tr.Errorf(\"getJobState got err: %v\", err)\n \t\t}\n-\t\tif got := buf.String(); !strings.Contains(got, jobSucceededState) {\n-\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\tgot := buf.String()\n+\n+\t\tif r.Attempt == 3 {\n+\t\t\tif !strings.Contains(got, jobSucceededState) && !strings.Contains(got, jobRunningState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v or %v\\n----\\n\", got, jobSucceededState, jobRunningState)\n+\t\t\t}\n+\t\t} else {\n+\t\t\tif !strings.Contains(got, jobSucceededState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\t\t}\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -423,6 +463,7 @@\nfunc testJobWithStaticOverlay(t *testing.T, projectNumber string, inputURI strin\n \t}\n \tstrSlice := strings.Split(got, \"/\")\n \tjobID = strSlice[len(strSlice)-1]\n+\tbuf.Reset()\n \n \t// Get the job.\n \ttestutil.Retry(t, 3, 5*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -434,14 +475,23 @@\nfunc testJobWithStaticOverlay(t *testing.T, projectNumber string, inputURI strin\n \t\t\tr.Errorf(\"getJob got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobName)\n \t\t}\n \t})\n+\tbuf.Reset()\n \n-\t// Get the job state (should be succeeded).\n-\ttestutil.Retry(t, 10, 60*time.Second, func(r *testutil.R) {\n+\t// Get the job state, which should be succeeded. If the job is still running on the last attempt, pass the test.\n+\ttestutil.Retry(t, 3, 30*time.Second, func(r *testutil.R) {\n \t\tif err := getJobState(buf, tc.ProjectID, location, jobID); err != nil {\n \t\t\tr.Errorf(\"getJobState got err: %v\", err)\n \t\t}\n-\t\tif got := buf.String(); !strings.Contains(got, jobSucceededState) {\n-\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\tgot := buf.String()\n+\n+\t\tif r.Attempt == 3 {\n+\t\t\tif !strings.Contains(got, jobSucceededState) && !strings.Contains(got, jobRunningState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v or %v\\n----\\n\", got, jobSucceededState, jobRunningState)\n+\t\t\t}\n+\t\t} else {\n+\t\t\tif !strings.Contains(got, jobSucceededState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\t\t}\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -475,6 +525,7 @@\nfunc testJobWithAnimatedOverlay(t *testing.T, projectNumber string, inputURI str\n \t}\n \tstrSlice := strings.Split(got, \"/\")\n \tjobID = strSlice[len(strSlice)-1]\n+\tbuf.Reset()\n \n \t// Get the job.\n \ttestutil.Retry(t, 3, 5*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -486,14 +537,23 @@\nfunc testJobWithAnimatedOverlay(t *testing.T, projectNumber string, inputURI str\n \t\t\tr.Errorf(\"getJob got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobName)\n \t\t}\n \t})\n+\tbuf.Reset()\n \n-\t// Get the job state (should be succeeded).\n-\ttestutil.Retry(t, 10, 60*time.Second, func(r *testutil.R) {\n+\t// Get the job state, which should be succeeded. If the job is still running on the last attempt, pass the test.\n+\ttestutil.Retry(t, 3, 30*time.Second, func(r *testutil.R) {\n \t\tif err := getJobState(buf, tc.ProjectID, location, jobID); err != nil {\n \t\t\tr.Errorf(\"getJobState got err: %v\", err)\n \t\t}\n-\t\tif got := buf.String(); !strings.Contains(got, jobSucceededState) {\n-\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\tgot := buf.String()\n+\n+\t\tif r.Attempt == 3 {\n+\t\t\tif !strings.Contains(got, jobSucceededState) && !strings.Contains(got, jobRunningState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v or %v\\n----\\n\", got, jobSucceededState, jobRunningState)\n+\t\t\t}\n+\t\t} else {\n+\t\t\tif !strings.Contains(got, jobSucceededState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\t\t}\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -527,6 +587,7 @@\nfunc testJobWithSetNumberImagesSpritesheet(t *testing.T, projectNumber string, i\n \t}\n \tstrSlice := strings.Split(got, \"/\")\n \tjobID = strSlice[len(strSlice)-1]\n+\tbuf.Reset()\n \n \t// Get the job.\n \ttestutil.Retry(t, 3, 5*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -538,14 +599,23 @@\nfunc testJobWithSetNumberImagesSpritesheet(t *testing.T, projectNumber string, i\n \t\t\tr.Errorf(\"getJob got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobName)\n \t\t}\n \t})\n+\tbuf.Reset()\n \n-\t// Get the job state (should be succeeded).\n-\ttestutil.Retry(t, 10, 60*time.Second, func(r *testutil.R) {\n+\t// Get the job state, which should be succeeded. If the job is still running on the last attempt, pass the test.\n+\ttestutil.Retry(t, 3, 30*time.Second, func(r *testutil.R) {\n \t\tif err := getJobState(buf, tc.ProjectID, location, jobID); err != nil {\n \t\t\tr.Errorf(\"getJobState got err: %v\", err)\n \t\t}\n-\t\tif got := buf.String(); !strings.Contains(got, jobSucceededState) {\n-\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\tgot := buf.String()\n+\n+\t\tif r.Attempt == 3 {\n+\t\t\tif !strings.Contains(got, jobSucceededState) && !strings.Contains(got, jobRunningState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v or %v\\n----\\n\", got, jobSucceededState, jobRunningState)\n+\t\t\t}\n+\t\t} else {\n+\t\t\tif !strings.Contains(got, jobSucceededState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\t\t}\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -579,6 +649,7 @@\nfunc testJobWithPeriodicImagesSpritesheet(t *testing.T, projectNumber string, in\n \t}\n \tstrSlice := strings.Split(got, \"/\")\n \tjobID = strSlice[len(strSlice)-1]\n+\tbuf.Reset()\n \n \t// Get the job.\n \ttestutil.Retry(t, 3, 5*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -590,14 +661,23 @@\nfunc testJobWithPeriodicImagesSpritesheet(t *testing.T, projectNumber string, in\n \t\t\tr.Errorf(\"getJob got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobName)\n \t\t}\n \t})\n+\tbuf.Reset()\n \n-\t// Get the job state (should be succeeded).\n-\ttestutil.Retry(t, 10, 60*time.Second, func(r *testutil.R) {\n+\t// Get the job state, which should be succeeded. If the job is still running on the last attempt, pass the test.\n+\ttestutil.Retry(t, 3, 30*time.Second, func(r *testutil.R) {\n \t\tif err := getJobState(buf, tc.ProjectID, location, jobID); err != nil {\n \t\t\tr.Errorf(\"getJobState got err: %v\", err)\n \t\t}\n-\t\tif got := buf.String(); !strings.Contains(got, jobSucceededState) {\n-\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\tgot := buf.String()\n+\n+\t\tif r.Attempt == 3 {\n+\t\t\tif !strings.Contains(got, jobSucceededState) && !strings.Contains(got, jobRunningState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v or %v\\n----\\n\", got, jobSucceededState, jobRunningState)\n+\t\t\t}\n+\t\t} else {\n+\t\t\tif !strings.Contains(got, jobSucceededState) {\n+\t\t\t\tr.Errorf(\"getJobState got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, jobSucceededState)\n+\t\t\t}\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat: add code samples and tests for jobs with captions",
        "pr_number": 2388,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -631,6 +711,7 @@\nfunc testJobWithConcatenatedInputs(t *testing.T, projectNumber string, input1URI\n \t}\n \tstrSlice := strings.Split(got, \"/\")\n \tjobID = strSlice[len(strSlice)-1]\n+\tbuf.Reset()\n \n \t// Get the job.\n \ttestutil.Retry(t, 3, 5*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "feat: add code samples and tests for jobs with captions"
        ],
        "last_commit_sha": "cd621caf996420e17bfc5d4f23cd03d7abf45ab4"
    },
    {
        "pr_title": "feat(cloudsql): Add SQL Server to Cloud SQL Cloud Run quickstart.",
        "pr_number": 2381,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql.go",
        "code_diff": "@@ -27,6 +27,7 @@\nimport (\n \t\"net/http\"\n \t\"os\"\n \t\"strconv\"\n+\t\"strings\"\n \t\"time\"\n \n \t_ \"github.com/denisenkom/go-mssqldb\"",
        "comments": [],
        "commit_messages": [
            "Add SQL Server to Cloud SQL Cloud Run quickstart."
        ],
        "last_commit_sha": "4b1bfdc29ed979f26c5ed78f3be573ba05b0d6a8"
    },
    {
        "pr_title": "feat(spanner): add spanner_copy_backup sample and changes to spanner_update_ba\u2026",
        "pr_number": 2366,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -45,6 +45,7 @@\ntype sampleFunc func(w io.Writer, dbName string) error\n type sampleFuncWithContext func(ctx context.Context, w io.Writer, dbName string) error\n type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string) error\n+type backupSampleFuncWithoutContext func(w io.Writer, dbName, backupID string) error\n type createBackupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string, versionTime time.Time) error\n \n var (",
        "comments": [],
        "commit_messages": [
            "feat(spanner): some code refactoring."
        ],
        "last_commit_sha": "84c6eaedd563c5669dd197ae8b603bedd44e760d"
    },
    {
        "pr_title": "feat(spanner): add spanner_copy_backup sample and changes to spanner_update_ba\u2026",
        "pr_number": 2366,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -401,10 +402,11 @@\nfunc TestBackupSample(t *testing.T) {\n \tassertContains(t, out, fmt.Sprintf(\"/backups/%s\", backupID))\n \tassertContains(t, out, \"Backups listed.\")\n \n-\tout = runSampleWithContext(ctx, t, listBackupOperations, dbName, \"failed to list backup operations\")\n+\tout = runBackupSampleWithoutContext(t, listBackupOperations, dbName, backupID, \"failed to list backup operations\")\n \tassertContains(t, out, fmt.Sprintf(\"on database %s\", dbName))\n+\tassertContains(t, out, fmt.Sprintf(\"copied from %s\", backupID))\n \n-\tout = runBackupSample(ctx, t, updateBackup, dbName, backupID, \"failed to update a backup\")\n+\tout = runBackupSampleWithoutContext(t, updateBackup, dbName, backupID, \"failed to update a backup\")\n \tassertContains(t, out, fmt.Sprintf(\"Updated backup %s\", backupID))\n \n \tout = runBackupSampleWithRetry(ctx, t, restoreBackup, restoreDBName, backupID, \"failed to restore a backup\", 10)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "84c6eaedd563c5669dd197ae8b603bedd44e760d"
    },
    {
        "pr_title": "feat(spanner): add spanner_copy_backup sample and changes to spanner_update_ba\u2026",
        "pr_number": 2366,
        "file_name": "spanner/spanner_snippets/spanner/spanner_list_backup_operations.go",
        "code_diff": "@@ -28,7 +28,13 @@\nimport (\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n-func listBackupOperations(ctx context.Context, w io.Writer, db string) error {\n+// listBackupOperations lists the backup operations that are pending or have completed/failed/cancelled within the last 7 days.\n+func listBackupOperations(w io.Writer, db string, backupId string) error {\n+\t// db := \"projects/my-project/instances/my-instance/databases/my-database\"\n+\t// backupID := \"my-backup\"\n+\n+\tctx := context.Background()\n+\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "84c6eaedd563c5669dd197ae8b603bedd44e760d"
    },
    {
        "pr_title": "feat(spanner): add spanner_copy_backup sample and changes to spanner_update_ba\u2026",
        "pr_number": 2366,
        "file_name": "spanner/spanner_snippets/spanner/spanner_update_backup.go",
        "code_diff": "@@ -24,12 +24,20 @@\nimport (\n \t\"time\"\n \n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n-\tpbts \"github.com/golang/protobuf/ptypes\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n \t\"google.golang.org/genproto/protobuf/field_mask\"\n+\t\"google.golang.org/protobuf/types/known/timestamppb\"\n )\n \n-func updateBackup(ctx context.Context, w io.Writer, db, backupID string) error {\n+// updateBackup updates the expiration time of a pending or completed backup.\n+func updateBackup(w io.Writer, db string, backupID string) error {\n+\t// db := \"projects/my-project/instances/my-instance/databases/my-database\"\n+\t// backupID := \"my-backup\"\n+\n+\t// Add timeout to context.\n+\tctx, cancel := context.WithTimeout(context.Background(), time.Hour)\n+\tdefer cancel()\n+\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "84c6eaedd563c5669dd197ae8b603bedd44e760d"
    },
    {
        "pr_title": "samples(storage): download byte range",
        "pr_number": 2335,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -43,6 +43,12 @@\nfunc TestObjects(t *testing.T) {\n \t}\n \tdefer client.Close()\n \n+\tdir, err := ioutil.TempDir(\"\", \"objectsTestTempDir\")\n+\tif err != nil {\n+\t\tt.Fatalf(\"ioutil.TempDir: %v\", err)\n+\t}\n+\tdefer os.RemoveAll(dir) // clean up\n+\n \tvar (\n \t\tbucket           = tc.ProjectID + \"-samples-object-bucket-1\"\n \t\tdstBucket        = tc.ProjectID + \"-samples-object-bucket-2\"",
        "comments": [],
        "commit_messages": [
            "responded to PR comments"
        ],
        "last_commit_sha": "07b1cfa95daf4fa5c1ba7c39f43daf6ae2dfdda4"
    },
    {
        "pr_title": "samples(storage): Upload file download file into memory",
        "pr_number": 2327,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \t\"net/http\"\n \t\"net/http/httputil\"\n \t\"os\"\n+\t\"path/filepath\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "responded to PR comments"
        ],
        "last_commit_sha": "e6c57ebec0a731fded6565ed4060a135b258b1cf"
    },
    {
        "pr_title": "samples(storage): Upload file download file into memory",
        "pr_number": 2327,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -163,9 +164,9 @@\nfunc TestObjects(t *testing.T) {\n \tif err := deleteOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, gen); err != nil {\n \t\tt.Fatalf(\"deleteOldVersionOfObject: %v\", err)\n \t}\n-\tdata, err := downloadFile(ioutil.Discard, bucket, object1)\n+\tdata, err := downloadFileIntoMemory(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Fatalf(\"downloadFile: %v\", err)\n+\t\tt.Fatalf(\"downloadFileIntoMemory: %v\", err)\n \t}\n \tif got, want := string(data), \"Hello\\nworld\"; got != want {\n \t\tt.Errorf(\"contents = %q; want %q\", got, want)",
        "comments": [],
        "commit_messages": [
            "samples: upload and download file into memory"
        ],
        "last_commit_sha": "e6c57ebec0a731fded6565ed4060a135b258b1cf"
    },
    {
        "pr_title": "samples(storage): Upload file download file into memory",
        "pr_number": 2327,
        "file_name": "storage/objects/stream_file_upload.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage objects\n \n // [START storage_stream_file_upload]\n+// [START storage_file_upload_from_memory]\n import (\n \t\"bytes\"\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "samples: upload and download file into memory"
        ],
        "last_commit_sha": "e6c57ebec0a731fded6565ed4060a135b258b1cf"
    },
    {
        "pr_title": "samples(storage): streaming file upload and download",
        "pr_number": 2325,
        "file_name": "storage/objects/download_file.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage objects\n \n // [START storage_download_file]\n+// [START storage_stream_file_download]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "samples(storage): streaming file upload and download"
        ],
        "last_commit_sha": "555ff7303133424e36d5631d479720295d184fcd"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -37,6 +37,7 @@\nconst (\n \ttestBucketName           = \"cloud-samples-data\"\n \ttestBucketDirName        = \"media/\"\n \ttestVideoFileName        = \"ChromeCast.mp4\"\n+\ttestConcatFileName       = \"ForBiggerEscapes.mp4\"\n \ttestOverlayImageFileName = \"overlay.jpg\"\n \tpreset                   = \"preset/web-hd\"\n \tsmallSpriteSheetFileName = \"small-sprite-sheet0000000000.jpeg\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -59,6 +60,7 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \n \tbucketName := tc.ProjectID + \"-golang-samples-transcoder-test\"\n \tinputURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testVideoFileName\n+\tinputConcatURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testConcatFileName\n \tinputOverlayImageURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testOverlayImageFileName\n \toutputURIForPreset := \"gs://\" + bucketName + \"/test-output-preset/\"\n \toutputURIForTemplate := \"gs://\" + bucketName + \"/test-output-template/\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -69,6 +71,7 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \toutputURIForSetNumberSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForSetNumberSpritesheet\n \toutputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n \toutputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n+\toutputURIForConcat := \"gs://\" + bucketName + \"/test-output-concat/\"\n \n \t// Get the project number\n \tcloudresourcemanagerClient, err := cloudresourcemanager.NewService(ctx)",
        "comments": [],
        "commit_messages": [
            "feat: add code sample and test for concatenating two input videos"
        ],
        "last_commit_sha": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -107,6 +110,9 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \t// Check if the spritesheets exist.\n \tcheckGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+smallSpriteSheetFileName)\n \tcheckGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+largeSpriteSheetFileName)\n+\n+\ttestJobWithConcatenatedInputs(t, projectNumber, inputURI, 0*time.Second, 8*time.Second+100*time.Millisecond, inputConcatURI, 3*time.Second+500*time.Millisecond, 15*time.Second, outputURIForConcat)\n+\tt.Logf(\"\\ntestJobWithConcatenatedInputs() completed\\n\")\n }\n \n // testJobTemplates tests major operations on job templates. Create, get,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat: add code sample and test for concatenating two input videos",
        "pr_number": 2319,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -175,6 +181,7 @@\nfunc writeTestGCSFiles(t *testing.T, projectID string, bucketName string) {\n \ttestutil.CleanBucket(ctx, t, projectID, bucketName)\n \twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testVideoFileName)\n \twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testOverlayImageFileName)\n+\twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testConcatFileName)\n }\n \n // writeTestGCSFile deletes the GCS test bucket and uploads a test video file to it.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6663854203a611bd8d1680c7f6dbdbc74df782ae"
    },
    {
        "pr_title": "feat(storage): update SignedURL samples to handle auth for user ",
        "pr_number": 2318,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -360,14 +360,10 @@\nfunc TestV4SignedURL(t *testing.T) {\n \n \tbucketName := tc.ProjectID + \"-signed-url-bucket-name\"\n \tobjectName := \"foo.txt\"\n-\tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n-\tif serviceAccount == \"\" {\n-\t\tt.Skip(\"GOOGLE_APPLICATION_CREDENTIALS must be set\")\n-\t}\n \n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \tputBuf := new(bytes.Buffer)\n-\tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName, serviceAccount)\n+\tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4PutObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d0786704a2c9ed6d2d09fe06ca6b89f0bb4224df"
    },
    {
        "pr_title": "feat(storage): update SignedURL samples to handle auth for user ",
        "pr_number": 2318,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -383,12 +379,12 @@\nfunc TestV4SignedURL(t *testing.T) {\n \t}\n \trequest.ContentLength = 11\n \trequest.Header.Set(\"Content-Type\", \"application/octet-stream\")\n-\tresponse, err := httpClient.Do(request)\n+\t_, err = httpClient.Do(request)\n \tif err != nil {\n \t\tt.Errorf(\"httpClient.Do: %v\", err)\n \t}\n \tgetBuf := new(bytes.Buffer)\n-\tgetURL, err := generateV4GetObjectSignedURL(getBuf, bucketName, objectName, serviceAccount)\n+\tgetURL, err := generateV4GetObjectSignedURL(getBuf, bucketName, objectName)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4GetObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d0786704a2c9ed6d2d09fe06ca6b89f0bb4224df"
    },
    {
        "pr_title": "feat(cloudsql/mysql): update to V2 sample",
        "pr_number": 2312,
        "file_name": "cloudsql/mysql/database-sql/cloudsql_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudsql\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_messages": [
            "feat(cloudsql): update to V2 sample\n\n* Add connector example in addition to TCP and UNIX socket example\n\n* Add support for Cloud Functions\n    - Create a cmd/app directory for the main package\n    - Rename the top-level package \"cloudsql\"\n    - Move template into Go file for simple deployment\n    - use \"/Votes\" as endpoint for casting a vote to match default Cloud\n      Functions naming scheme\n\n* Simplify application code\n\n* Add new region tags while leaving old tags in place\n\nThis commit leaves a few open TODOs:\n- Migrate to the new region tags and delete the old ones\n- Update the READMEs to add connector instructions, deployment steps for\n  each environment, and verify existing instructions\n- Ensure README covers steps to deploy to App Engine Flex (given the\n  lack of support for Go modules)"
        ],
        "last_commit_sha": "4dedb74068d45f57d415209019a8eb327300d4b5"
    },
    {
        "pr_title": "feat(pubsublite): add regional topic samples",
        "pr_number": 2297,
        "file_name": "pubsublite/admin/create_topic.go",
        "code_diff": "@@ -23,11 +23,13 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func createTopic(w io.Writer, projectID, region, zone, topicID string) error {\n+func createTopic(w io.Writer, projectID, region, zone, topicID, reservation string, regional bool) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\" // see https://cloud.google.com/pubsub/lite/docs/locations\n \t// zone := \"us-central1-a\"\n \t// topicID := \"my-topic\"\n+\t// reservation := \"projects/my-project-id/reservations/my-reservation\"\n+\t// regional := \"true\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "21a3034f52891bfebf3c79b147c63cc17392d57a"
    },
    {
        "pr_title": "feat(pubsublite): add regional topic samples",
        "pr_number": 2297,
        "file_name": "pubsublite/admin/get_topic.go",
        "code_diff": "@@ -23,7 +23,7 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func getTopic(w io.Writer, projectID, region, zone, topicID string) error {\n+func getTopic(w io.Writer, projectID, region, zone, topicID string, regional bool) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n \t// zone := \"us-central1-a\"",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): add regional topic samples"
        ],
        "last_commit_sha": "21a3034f52891bfebf3c79b147c63cc17392d57a"
    },
    {
        "pr_title": "feat(pubsublite): add regional topic samples",
        "pr_number": 2297,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -35,14 +35,16 @@\nimport (\n \n const (\n \tresourcePrefix = \"admin-test-\"\n-\ttestRegion     = \"us-central1\"\n+\ttestRegion     = \"us-west1\"\n )\n \n var (\n-\tsupportedZones = []string{\"us-central1-a\", \"us-central1-b\", \"us-central1-c\"}\n+\tsupportedZones = []string{\"us-west1-a\", \"us-west1-c\"}\n \n-\tonce       sync.Once\n-\tprojNumber string\n+\tonce            sync.Once\n+\tprojNumber      string\n+\treservationID   string\n+\treservationPath string\n )\n \n func setupAdmin(t *testing.T) *pubsublite.AdminClient {",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): add regional topic samples"
        ],
        "last_commit_sha": "21a3034f52891bfebf3c79b147c63cc17392d57a"
    },
    {
        "pr_title": "feat(pubsublite): add regional topic samples",
        "pr_number": 2297,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -70,7 +72,7 @@\nfunc setupAdmin(t *testing.T) *pubsublite.AdminClient {\n \n \t\tprojNumber = strconv.FormatInt(project.ProjectNumber, 10)\n \n-\t\tpsltest.Cleanup(t, client, projNumber, resourcePrefix, supportedZones)\n+\t\tpsltest.Cleanup(t, client, projNumber, testRegion, resourcePrefix, supportedZones)\n \t})\n \n \treturn client",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): add regional topic samples"
        ],
        "last_commit_sha": "21a3034f52891bfebf3c79b147c63cc17392d57a"
    },
    {
        "pr_title": "feat(pubsublite): add regional topic samples",
        "pr_number": 2297,
        "file_name": "pubsublite/admin/pubsublite_admin_test.go",
        "code_diff": "@@ -87,21 +89,21 @@\nfunc TestTopicAdmin(t *testing.T) {\n \ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projNumber, testZone, topicID)\n \tt.Run(\"CreateTopic\", func(t *testing.T) {\n \t\tbuf := new(bytes.Buffer)\n-\t\terr := createTopic(buf, tc.ProjectID, testRegion, testZone, topicID)\n+\t\terr := createTopic(buf, tc.ProjectID, testRegion, testZone, topicID, \"\", false)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"createTopic: %v\", err)\n \t\t}\n \t\tgot := buf.String()\n-\t\twant := fmt.Sprintf(\"Created topic: %s\\n\", topicPath)\n-\t\tif diff := cmp.Diff(want, got); diff != \"\" {\n-\t\t\tt.Fatalf(\"createTopic() mismatch: -want, +got:\\n%s\", diff)\n+\t\twant := \"Created zonal topic\"\n+\t\tif !strings.Contains(got, want) {\n+\t\t\tt.Fatalf(\"createTopic() mismatch: got: %s\\nwant: %s\", got, want)\n \t\t}\n \t})\n \n \tt.Run(\"GetTopic\", func(t *testing.T) {\n \t\ttestutil.Retry(t, 3, 5*time.Second, func(r *testutil.R) {\n \t\t\tbuf := new(bytes.Buffer)\n-\t\t\terr := getTopic(buf, tc.ProjectID, testRegion, testZone, topicID)\n+\t\t\terr := getTopic(buf, tc.ProjectID, testRegion, testZone, topicID, false)\n \t\t\tif err != nil {\n \t\t\t\tr.Errorf(\"getTopic: %v\", err)\n \t\t\t}",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): add regional topic samples"
        ],
        "last_commit_sha": "21a3034f52891bfebf3c79b147c63cc17392d57a"
    },
    {
        "pr_title": "feat(pubsublite): add regional topic samples",
        "pr_number": 2297,
        "file_name": "pubsublite/admin/update_topic.go",
        "code_diff": "@@ -24,19 +24,26 @@\nimport (\n \t\"cloud.google.com/go/pubsublite\"\n )\n \n-func updateTopic(w io.Writer, projectID, region, zone, topicID string) error {\n+func updateTopic(w io.Writer, projectID, region, zone, topicID, reservation string, regional bool) error {\n \t// projectID := \"my-project-id\"\n \t// region := \"us-central1\"\n \t// zone := \"us-central1-a\"\n \t// topicID := \"my-topic\"\n+\t// reservation := \"projects/my-project-id/reservations/my-reservation\"\n+\t// regional := \"true\"\n \tctx := context.Background()\n \tclient, err := pubsublite.NewAdminClient(ctx, region)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"pubsublite.NewAdminClient: %v\", err)\n \t}\n \tdefer client.Close()\n \n-\ttopicPath := fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, zone, topicID)\n+\tvar topicPath string\n+\tif regional {\n+\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, region, topicID)\n+\t} else {\n+\t\ttopicPath = fmt.Sprintf(\"projects/%s/locations/%s/topics/%s\", projectID, zone, topicID)\n+\t}\n \t// For ranges of fields in TopicConfigToUpdate, see https://pkg.go.dev/cloud.google.com/go/pubsublite/#TopicConfigToUpdate\n \tconfig := pubsublite.TopicConfigToUpdate{\n \t\tName:                       topicPath,",
        "comments": [
            {
                "comment": "Can we also show ThroughputReservation as one of the field to be updated in this update topic example? Sorry I didn't think of this one in the first pass.",
                "position": 27
            },
            {
                "comment": "Why is the `regional` bool missing from the Python/Java samples for update topic? I also noticed it is missing for get topic as well.",
                "position": 27
            },
            {
                "comment": "Update topic Java/Python samples have been updated to use a bool for regional too. Thanks for pointing that out!",
                "position": 27
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "21a3034f52891bfebf3c79b147c63cc17392d57a"
    },
    {
        "pr_title": "feat(pubsublite): add regional topic samples",
        "pr_number": 2297,
        "file_name": "pubsublite/internal/psltest/util.go",
        "code_diff": "@@ -28,11 +28,12 @@\nimport (\n // Cleanup deletes all previous test topics/subscriptions from previous test\n // runs. This prevents previous test failures from building up resources that\n // count against quota.\n-func Cleanup(t *testing.T, client *pubsublite.AdminClient, proj, namePrefix string, zones []string) {\n+func Cleanup(t *testing.T, client *pubsublite.AdminClient, proj, region, namePrefix string, zones []string) {\n \tctx := context.Background()\n \n \ttopicSubstring := \"/topics/\" + namePrefix\n \tsubscriptionSubstring := \"/subscriptions/\" + namePrefix\n+\treservationSubstring := \"/reservations/\" + namePrefix\n \n \tfor _, zone := range zones {\n \t\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", proj, zone)",
        "comments": [],
        "commit_messages": [
            "feat(pubsublite): add regional topic samples"
        ],
        "last_commit_sha": "21a3034f52891bfebf3c79b147c63cc17392d57a"
    },
    {
        "pr_title": "feat(storage): add turbo replication (RPO) samples",
        "pr_number": 2279,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -73,14 +73,7 @@\nfunc cleanBucketWithClient(ctx context.Context, t *testing.T, client *storage.Cl\n \t\t}\n \t})\n \n-\t// Wait until the bucket exists.\n-\tRetry(t, 10, 30*time.Second, func(r *R) {\n-\t\tif _, err := b.Attrs(ctx); err != nil {\n-\t\t\t// Bucket does not exist.\n-\t\t\tr.Errorf(\"Bucket was not created\")\n-\t\t\treturn\n-\t\t}\n-\t})\n+\tWaitForBucketToExist(ctx, t, b)\n \n \treturn nil\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "234cd0dc93cb33d69e061f4d4cedf6d5471eb3dd"
    },
    {
        "pr_title": "feat(storage): add turbo replication (RPO) samples",
        "pr_number": 2279,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -127,6 +120,8 @@\nfunc DeleteBucketIfExists(ctx context.Context, client *storage.Client, bucket st\n \t\treturn fmt.Errorf(\"Bucket.Delete(%q): %v\", bucket, err)\n \t}\n \n+\t// Waits for a bucket to no longer exist, as it can take time to propagate\n+\t// Errors after 10 successful attempts at retrieving the bucket's attrs\n \tretries := 10\n \tdelay := 10 * time.Second",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "234cd0dc93cb33d69e061f4d4cedf6d5471eb3dd"
    },
    {
        "pr_title": "refactor(firestore): Add tests, move firestore to firestore package, test main",
        "pr_number": 2276,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage main\n // [START firestore_setup_client_create]\n import (\n \t\"context\"\n+\t\"flag\"\n \t\"fmt\"\n \t\"log\"",
        "comments": [],
        "commit_messages": [
            "test(firestore): make project id overridable for test runs"
        ],
        "last_commit_sha": "d7ca384065373d8072cefa6b28d0bb9991b90dd8"
    },
    {
        "pr_title": "refactor(firestore): Add tests, move firestore to firestore package, test main",
        "pr_number": 2276,
        "file_name": "firestore/save_test.go",
        "code_diff": "@@ -12,13 +12,11 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package firestore\n \n import (\n \t\"context\"\n \t\"os\"\n-\t\"reflect\"\n-\t\"runtime\"\n \t\"testing\"\n \n \t\"cloud.google.com/go/firestore\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d7ca384065373d8072cefa6b28d0bb9991b90dd8"
    },
    {
        "pr_title": "refactor(firestore): Add tests, move firestore to firestore package, test main",
        "pr_number": 2276,
        "file_name": "firestore/save_test.go",
        "code_diff": "@@ -41,25 +39,37 @@\nfunc TestSave(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \n-\tmust := func(f func(context.Context, *firestore.Client) error) {\n-\t\terr := f(ctx, client)\n-\t\tif err != nil {\n-\t\t\tfn := runtime.FuncForPC(reflect.ValueOf(f).Pointer()).Name()\n-\t\t\tt.Fatalf(\"%s: %v\", fn, err)\n-\t\t}\n-\t}\n-\n \t// TODO(someone): check values of docs to make sure data is being manipulated properly.\n-\tmust(addDocAsMap)\n-\tmust(addDocDataTypes)\n-\tmust(addDocAsEntity)\n-\tmust(addDocWithID)\n-\tmust(addDocWithoutID)\n-\tmust(addDocAfterAutoGeneratedID)\n-\tmust(updateDoc)\n-\tmust(updateDocCreateIfMissing)\n-\tmust(updateDocMultiple)\n-\tmust(updateDocNested)\n+\tif err = addDocAsMap(ctx, client); err != nil {\n+\t\tt.Fatalf(\"addDocAsMap: %v\", err)\n+\t}\n+\tif err = addDocDataTypes(ctx, client); err != nil {\n+\t\tt.Fatalf(\"addDocDataTypes: %v\", err)\n+\t}\n+\tif err = addDocAsEntity(ctx, client); err != nil {\n+\t\tt.Fatalf(\"addDocAsEntity: %v\", err)\n+\t}\n+\tif err = addDocWithID(ctx, client); err != nil {\n+\t\tt.Fatalf(\"addDocWithID: %v\", err)\n+\t}\n+\tif err = addDocWithoutID(ctx, client); err != nil {\n+\t\tt.Fatalf(\"addDocWithoutID: %v\", err)\n+\t}\n+\tif err = addDocAfterAutoGeneratedID(ctx, client); err != nil {\n+\t\tt.Fatalf(\"addDocAfterAutoGeneratedID: %v\", err)\n+\t}\n+\tif err = updateDoc(ctx, client); err != nil {\n+\t\tt.Fatalf(\"updateDoc: %v\", err)\n+\t}\n+\tif err = updateDocCreateIfMissing(ctx, client); err != nil {\n+\t\tt.Fatalf(\"updateDocCreateIfMissing: %v\", err)\n+\t}\n+\tif err = updateDocMultiple(ctx, client); err != nil {\n+\t\tt.Fatalf(\"updateDocMultiple: %v\", err)\n+\t}\n+\tif err = updateDocNested(ctx, client); err != nil {\n+\t\tt.Fatalf(\"updateDocNested: %v\", err)\n+\t}\n \tif value, _, err := getField(ctx, client, \"users\", \"frank\", \"favorites\"); err != nil {\n \t\tt.Fatal(err)\n \t} else {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d7ca384065373d8072cefa6b28d0bb9991b90dd8"
    },
    {
        "pr_title": "feat(spanner): add samples for tagging",
        "pr_number": 2257,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -163,6 +163,8 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"1 1 Total Junk\")\n \tout = runSample(t, queryRequestPriority, dbName, \"failed to query data with RequestPriority\")\n \tassertContains(t, out, \"1 1 Total Junk\")\n+\tout = runSample(t, queryWithTag, dbName, \"failed to query data with request tag set\")\n+\tassertContains(t, out, \"1 1 Total Junk\")\n \n \trunSampleWithContext(ctx, t, addIndex, dbName, \"failed to add index\")\n \tout = runSample(t, queryUsingIndex, dbName, \"failed to query using index\")",
        "comments": [],
        "commit_messages": [
            "feat(spanner): add samples for tagging"
        ],
        "last_commit_sha": "a734a74e6842af0987bb8209e19a157410a09554"
    },
    {
        "pr_title": "feat(spanner): add samples for tagging",
        "pr_number": 2257,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -317,6 +319,13 @@\nfunc TestSample(t *testing.T) {\n \tout = runSample(t, queryWithString, dbName, \"failed to query with string\")\n \tassertContains(t, out, \"42 Venue 42\")\n \n+\tout = runSample(t, readWriteTransactionWithTag, dbName, \"failed to perform read-write transaction with tag\")\n+\tassertContains(t, out, \"Venue capacities updated.\")\n+\tassertContains(t, out, \"New venue inserted.\")\n+\tout = runSample(t, queryWithInt, dbName, \"failed to query with int\")\n+\tassertContains(t, out, \"19 Venue 19 6300\")\n+\tassertNotContains(t, out, \"42 Venue 42 3000\")\n+\n \t// Wait 5 seconds to avoid a time drift issue for the next query:\n \t// https://github.com/GoogleCloudPlatform/golang-samples/issues/1146.\n \ttime.Sleep(time.Second * 5)",
        "comments": [],
        "commit_messages": [
            "feat(spanner): add samples for tagging"
        ],
        "last_commit_sha": "a734a74e6842af0987bb8209e19a157410a09554"
    },
    {
        "pr_title": "fix(storage): update PAP to inherited instead of unspecified",
        "pr_number": 2251,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -378,7 +378,6 @@\nfunc TestUniformBucketLevelAccess(t *testing.T) {\n }\n \n func TestPublicAccessPrevention(t *testing.T) {\n-\tt.Skip(\"https://github.com/googleapis/google-cloud-go/issues/4890\")\n \ttc := testutil.SystemTest(t)\n \tbucketName := tc.ProjectID + \"-storage-buckets-tests\"",
        "comments": [],
        "commit_messages": [
            "fix(storage): update PAP to inherited instead of unspecified\n* add sample for inherited\n* change test to inherited instead of unspecified"
        ],
        "last_commit_sha": "91d1b9b43bd69ee16e6964c45bde984d52925f15"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -17,14 +17,24 @@\npackage testutil\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"log\"\n+\t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n+\t\"github.com/google/uuid\"\n \t\"google.golang.org/api/googleapi\"\n \t\"google.golang.org/api/iterator\"\n )\n \n+// CreateTestBucket creates a new bucket with the given prefix\n+func CreateTestBucket(ctx context.Context, t *testing.T, client *storage.Client, projectID, prefix string) (string, error) {\n+\tt.Helper()\n+\tbucketName := UniqueBucketName(prefix)\n+\treturn bucketName, cleanBucketWithClient(ctx, t, client, projectID, bucketName)\n+}\n+\n // CleanBucket creates a new bucket. If the bucket already exists, it will be\n // deleted and recreated.\n func CleanBucket(ctx context.Context, t *testing.T, projectID, bucket string) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -34,12 +44,19 @@\nfunc CleanBucket(ctx context.Context, t *testing.T, projectID, bucket string) er\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\treturn cleanBucketWithClient(ctx, t, client, projectID, bucket)\n+}\n+\n+// cleanBucketWithClient creates a new bucket. If the bucket already exists, it will be\n+// deleted and recreated.\n+// Like CleanBucket but you must provide the storage client.\n+func cleanBucketWithClient(ctx context.Context, t *testing.T, client *storage.Client, projectID, bucket string) error {\n+\tt.Helper()\n \n \t// Delete the bucket if it exists.\n-\tif err := deleteBucketIfExists(ctx, client, bucket); err != nil {\n+\tif err := DeleteBucketIfExists(ctx, client, bucket); err != nil {\n \t\treturn fmt.Errorf(\"error deleting bucket: %v\", err)\n \t}\n-\n \tb := client.Bucket(bucket)\n \n \t// Now create the bucket.",
        "comments": [],
        "commit_messages": [
            "test(storage): Add bucket setup/teardown to bucket tests\n\nThis should hopefully resolve the gcs rate limit issue for these tests."
        ],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -49,7 +66,7 @@\nfunc CleanBucket(ctx context.Context, t *testing.T, projectID, bucket string) er\n \t\t\tif err, ok := err.(*googleapi.Error); ok {\n \t\t\t\t// Just in case...\n \t\t\t\tif err.Code == 409 {\n-\t\t\t\t\tdeleteBucketIfExists(ctx, client, bucket) // Ignore error.\n+\t\t\t\t\tDeleteBucketIfExists(ctx, client, bucket) // Ignore error.\n \t\t\t\t}\n \t\t\t}\n \t\t\tr.Errorf(\"Bucket.Create(%q): %v\", bucket, err)",
        "comments": [],
        "commit_messages": [
            "test(storage): Add bucket setup/teardown to bucket tests\n\nThis should hopefully resolve the gcs rate limit issue for these tests."
        ],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -68,7 +85,8 @@\nfunc CleanBucket(ctx context.Context, t *testing.T, projectID, bucket string) er\n \treturn nil\n }\n \n-func deleteBucketIfExists(ctx context.Context, client *storage.Client, bucket string) error {\n+// DeleteBucketIfExists deletes a bucket and all its objects\n+func DeleteBucketIfExists(ctx context.Context, client *storage.Client, bucket string) error {\n \tb := client.Bucket(bucket)\n \n \t// Check if the bucket does not exist, return nil.",
        "comments": [],
        "commit_messages": [
            "test(storage): Add bucket setup/teardown to bucket tests\n\nThis should hopefully resolve the gcs rate limit issue for these tests."
        ],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -89,6 +107,7 @@\nfunc deleteBucketIfExists(ctx context.Context, client *storage.Client, bucket st\n \t\tif err != nil {\n \t\t\treturn fmt.Errorf(\"Bucket.Objects(%q): %v\", bucket, err)\n \t\t}\n+\t\t// Objects with a hold must have the hold released\n \t\tif attrs.EventBasedHold || attrs.TemporaryHold {\n \t\t\tif _, err := b.Object(attrs.Name).Update(ctx, storage.ObjectAttrsToUpdate{\n \t\t\t\tTemporaryHold:  false,",
        "comments": [],
        "commit_messages": [
            "test(storage): Add bucket setup/teardown to bucket tests\n\nThis should hopefully resolve the gcs rate limit issue for these tests."
        ],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -101,7 +120,6 @@\nfunc deleteBucketIfExists(ctx context.Context, client *storage.Client, bucket st\n \t\tif err := obj.Delete(ctx); err != nil {\n \t\t\treturn fmt.Errorf(\"Bucket(%q).Object(%q).Delete: %v\", bucket, attrs.Name, err)\n \t\t}\n-\n \t}\n \n \t// Then delete the bucket itself.",
        "comments": [],
        "commit_messages": [
            "test(storage): Add bucket setup/teardown to bucket tests\n\nThis should hopefully resolve the gcs rate limit issue for these tests."
        ],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n+\t\"log\"\n \t\"os\"\n \t\"reflect\"\n \t\"strings\"",
        "comments": [],
        "commit_messages": [
            "test(storage): Add bucket setup/teardown to bucket tests\n\nThis should hopefully resolve the gcs rate limit issue for these tests."
        ],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -31,41 +32,69 @@\nimport (\n \tiampb \"google.golang.org/genproto/googleapis/iam/v1\"\n )\n \n+const (\n+\ttestPrefix      = \"storage-buckets-test\"\n+\tbucketExpiryAge = time.Hour * 24\n+)\n+\n+var client *storage.Client\n+\n+func TestMain(m *testing.M) {\n+\t// Initialize global vars\n+\ttc, _ := testutil.ContextMain(m)\n+\n+\tctx := context.Background()\n+\tc, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tclient = c\n+\tdefer client.Close()\n+\n+\t// Run tests\n+\texit := m.Run()\n+\n+\t// Delete old buckets whose name begins with our test prefix\n+\tif err := testutil.DeleteExpiredBuckets(client, tc.ProjectID, testPrefix, bucketExpiryAge); err != nil {\n+\t\t// Don't fail the test if cleanup fails\n+\t\tlog.Printf(\"Post-test cleanup failed: %v\", err)\n+\t}\n+\tos.Exit(exit)\n+}\n+\n func TestCreate(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tbucketName := testutil.UniqueBucketName(testPrefix)\n+\tctx := context.Background()\n+\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n-\t// Clean up bucket before running tests.\n-\tdeleteBucket(ioutil.Discard, bucketName)\n \tif err := createBucket(ioutil.Discard, tc.ProjectID, bucketName); err != nil {\n \t\tt.Fatalf(\"createBucket: %v\", err)\n \t}\n }\n \n func TestCreateBucketClassLocation(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tname := tc.ProjectID + \"-storage-buckets-tests-attrs\"\n+\tbucketName := testutil.UniqueBucketName(testPrefix)\n+\tctx := context.Background()\n+\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n-\t// Clean up bucket before running the test.\n-\tdeleteBucket(ioutil.Discard, name)\n-\tif err := createBucketClassLocation(ioutil.Discard, tc.ProjectID, name); err != nil {\n+\tif err := createBucketClassLocation(ioutil.Discard, tc.ProjectID, bucketName); err != nil {\n \t\tt.Fatalf(\"createBucketClassLocation: %v\", err)\n \t}\n-\tif err := deleteBucket(ioutil.Discard, name); err != nil {\n-\t\tt.Fatalf(\"deleteBucket: %v\", err)\n-\t}\n }\n \n func TestStorageClass(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tif err := changeDefaultStorageClass(ioutil.Discard, bucketName); err != nil {\n \t\tt.Errorf(\"changeDefaultStorageClass: %v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -82,7 +111,13 @@\nfunc TestStorageClass(t *testing.T) {\n \n func TestListBuckets(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tbuckets, err := listBuckets(ioutil.Discard, tc.ProjectID)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -105,7 +140,13 @@\nfunc TestListBuckets(t *testing.T) {\n \n func TestGetBucketMetadata(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tbuf := new(bytes.Buffer)\n \tif _, err := getBucketMetadata(buf, bucketName); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -120,7 +161,13 @@\nfunc TestGetBucketMetadata(t *testing.T) {\n \n func TestIAM(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tif _, err := getBucketPolicy(ioutil.Discard, bucketName); err != nil {\n \t\tt.Errorf(\"getBucketPolicy: %#v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -152,14 +199,13 @@\nfunc TestIAM(t *testing.T) {\n }\n func TestCORSConfiguration(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\tclient, err := storage.NewClient(ctx)\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \twant := []storage.CORS{\n \t\t{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -193,7 +239,13 @@\nfunc TestCORSConfiguration(t *testing.T) {\n \n func TestRequesterPays(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \t// Tests which update the bucket metadata must be retried in order to avoid\n \t// flakes from rate limits.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -214,16 +266,13 @@\nfunc TestRequesterPays(t *testing.T) {\n \n func TestKMS(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tclient, err := storage.NewClient(ctx)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")\n \tcryptoKeyID := os.Getenv(\"GOLANG_SAMPLES_KMS_CRYPTOKEY\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -261,7 +310,13 @@\nfunc TestKMS(t *testing.T) {\n \n func TestBucketLock(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tretentionPeriod := 5 * time.Second\n \ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -346,7 +401,13 @@\nfunc TestBucketLock(t *testing.T) {\n \n func TestUniformBucketLevelAccess(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\tctx := context.Background()\n+\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n+\t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n \t\tif err := enableUniformBucketLevelAccess(ioutil.Discard, bucketName); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -379,16 +440,13 @@\nfunc TestUniformBucketLevelAccess(t *testing.T) {\n \n func TestPublicAccessPrevention(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tclient, err := storage.NewClient(ctx)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tif err := setPublicAccessPreventionEnforced(ioutil.Discard, bucketName); err != nil {\n \t\tt.Errorf(\"setPublicAccessPreventionEnforced: %v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -441,22 +499,19 @@\nfunc TestPublicAccessPrevention(t *testing.T) {\n \n func TestLifecycleManagement(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tif err := enableBucketLifecycleManagement(ioutil.Discard, bucketName); err != nil {\n-\t\tt.Fatalf(\"enableBucketLifecycleManagement: %v\", err)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n-\t// verify lifecycle is set\n-\tclient, err := storage.NewClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\tif err := enableBucketLifecycleManagement(ioutil.Discard, bucketName); err != nil {\n+\t\tt.Fatalf(\"enableBucketLifecycleManagement: %v\", err)\n \t}\n-\tdefer client.Close()\n \n+\t// Verify lifecycle is set\n \tattrs, err := client.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -492,16 +547,13 @@\nfunc TestLifecycleManagement(t *testing.T) {\n \n func TestBucketLabel(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tclient, err := storage.NewClient(ctx)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tlabelName := \"label-name\"\n \tlabelValue := \"label-value\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -537,16 +589,13 @@\nfunc TestBucketLabel(t *testing.T) {\n \n func TestBucketWebsiteInfo(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tclient, err := storage.NewClient(ctx)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tindex := \"index.html\"\n \tnotFoundPage := \"404.html\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "test(storage): Add bucket setup/teardown to bucket tests",
        "pr_number": 2234,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -569,16 +618,13 @@\nfunc TestBucketWebsiteInfo(t *testing.T) {\n \n func TestSetBucketPublicIAM(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n-\n \tctx := context.Background()\n-\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n \n-\tclient, err := storage.NewClient(ctx)\n+\tbucketName, err := testutil.CreateTestBucket(ctx, t, client, tc.ProjectID, testPrefix)\n \tif err != nil {\n-\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t\tt.Fatalf(\"Bucket creation failed: %v\", err)\n \t}\n-\tdefer client.Close()\n+\tdefer testutil.DeleteBucketIfExists(ctx, client, bucketName)\n \n \tif err := setBucketPublicIAM(ioutil.Discard, bucketName); err != nil {\n \t\tt.Fatalf(\"setBucketPublicIAM: %v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bad4b3cd4609a6dfd8577e391e392f207bbcfe8c"
    },
    {
        "pr_title": "feat(firestore): add partition queries samples",
        "pr_number": 2222,
        "file_name": "firestore/firestore_snippets/collection_group_query.go",
        "code_diff": "@@ -42,7 +42,7 @@\nfunc collectionGroupQuery(w io.Writer, projectID string) error {\n \t\t\tbreak\n \t\t}\n \t\tif err != nil {\n-\t\t\treturn err\n+\t\t\treturn fmt.Errorf(\"documents iterator: %v\", err)\n \t\t}\n \t\tfmt.Fprintf(w, \"%s: %s\", doc.Ref.ID, doc.Data()[\"name\"])\n \t}",
        "comments": [],
        "commit_messages": [
            "fix(firestore): use error formatter"
        ],
        "last_commit_sha": "1c092c393e86a24db46b660b8cd183b411a28484"
    },
    {
        "pr_title": "fix(pubsub): update concurrency sample",
        "pr_number": 2220,
        "file_name": "pubsub/subscriptions/pull_concurrency.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"runtime\"\n \t\"sync/atomic\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "fix(pubsub): update concurrency sample"
        ],
        "last_commit_sha": "951f50244010759b60668c4fde2deb2a3b963649"
    },
    {
        "pr_title": "feat(cloudsql): add support for SSL certificates",
        "pr_number": 2219,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -19,16 +19,20 @@\npackage main\n \n import (\n+\t\"crypto/tls\"\n+\t\"crypto/x509\"\n \t\"database/sql\"\n+\t\"errors\"\n \t\"fmt\"\n \t\"html/template\"\n+\t\"io/ioutil\"\n \t\"log\"\n \t\"math\"\n \t\"net/http\"\n \t\"os\"\n \t\"strconv\"\n \n-\t_ \"github.com/go-sql-driver/mysql\"\n+\t\"github.com/go-sql-driver/mysql\"\n )\n \n // vote struct contains a single row from the votes table in the database.",
        "comments": [],
        "commit_messages": [
            "feat(cloudsql): add support for SSL certificates\n\nThis commit adds support for configuring SSL certificates for Postgres\nand MySQL."
        ],
        "last_commit_sha": "d36b98b5d0c081f5f8531608e622830268aaffd4"
    },
    {
        "pr_title": "feat(cloudsql): add support for SSL certificates",
        "pr_number": 2219,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -277,6 +281,41 @@\nfunc initTCPConnectionPool() (*sql.DB, error) {\n \tvar dbURI string\n \tdbURI = fmt.Sprintf(\"%s:%s@tcp(%s:%s)/%s?parseTime=true\", dbUser, dbPwd, dbTCPHost, dbPort, dbName)\n \n+\t// [START_EXCLUDE]\n+\t// [START cloud_sql_postgres_databasesql_sslcerts]\n+\t// (OPTIONAL) Configure SSL certificates\n+\t// For deployments that connect directly to a Cloud SQL instance without\n+\t// using the Cloud SQL Proxy, configuring SSL certificates will ensure the\n+\t// connection is encrypted. This step is entirely OPTIONAL.\n+\tdbRootCert := os.Getenv(\"DB_ROOT_CERT\") // e.g., '/path/to/my/server-ca.pem'\n+\tif dbRootCert != \"\" {\n+\t\tvar (\n+\t\t\tdbCert = mustGetenv(\"DB_CERT\") // e.g. '/path/to/my/client-cert.pem'\n+\t\t\tdbKey  = mustGetenv(\"DB_KEY\")  // e.g. '/path/to/my/client-key.pem'\n+\t\t)\n+\t\tpool := x509.NewCertPool()\n+\t\tpem, err := ioutil.ReadFile(dbRootCert)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\tif ok := pool.AppendCertsFromPEM(pem); !ok {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\tcert, err := tls.LoadX509KeyPair(dbCert, dbKey)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\tmysql.RegisterTLSConfig(\"cloudsql\", &tls.Config{\n+\t\t\tRootCAs:               pool,\n+\t\t\tCertificates:          []tls.Certificate{cert},\n+\t\t\tInsecureSkipVerify:    true,\n+\t\t\tVerifyPeerCertificate: verifyPeerCertFunc(pool),\n+\t\t})\n+\t\tdbURI += \"&tls=cloudsql\"\n+\t}\n+\t// [END cloud_sql_postgres_databasesql_sslcerts]\n+\t// [END_EXCLUDE]\n+\n \t// dbPool is the pool of database connections.\n \tdbPool, err := sql.Open(\"mysql\", dbURI)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "feat(cloudsql): add support for SSL certificates\n\nThis commit adds support for configuring SSL certificates for Postgres\nand MySQL."
        ],
        "last_commit_sha": "d36b98b5d0c081f5f8531608e622830268aaffd4"
    },
    {
        "pr_title": "feat(spanner): add samples for request priorities",
        "pr_number": 2193,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -160,6 +160,8 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"1 1 Total Junk\")\n \tout = runSample(t, query, dbName, \"failed to query data\")\n \tassertContains(t, out, \"1 1 Total Junk\")\n+\tout = runSample(t, queryRequestPriority, dbName, \"failed to query data with RequestPriority\")\n+\tassertContains(t, out, \"1 1 Total Junk\")\n \n \trunSampleWithContext(ctx, t, addIndex, dbName, \"failed to add index\")\n \tout = runSample(t, queryUsingIndex, dbName, \"failed to query using index\")",
        "comments": [],
        "commit_messages": [
            "feat(spanner): add samples for request priorities\n\nAdded samples for setting request priority with streaming read, execute streaming query, commit, batch DML, partitioned DML and batch partitioned queries, added integration tests."
        ],
        "last_commit_sha": "fbde5d2edb24b2bbde5c24092ebeca55ee28f520"
    },
    {
        "pr_title": "feat(spanner): add samples for request priorities",
        "pr_number": 2193,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -194,9 +196,17 @@\nfunc TestSample(t *testing.T) {\n \tassertContains(t, out, \"Forever Hold Your Peace\")\n \tassertContains(t, out, \"Green\")\n \n+\tout = runSample(t, readRequestPriority, dbName, \"failed to read with RequestPriority\")\n+\tassertContains(t, out, \"Go, Go, Go\")\n+\tassertContains(t, out, \"Forever Hold Your Peace\")\n+\tassertContains(t, out, \"Green\")\n+\n \tout = runSample(t, readBatchData, dbName, \"failed to read batch data\")\n \tassertContains(t, out, \"1 Marc Richards\")\n \n+\tout = runSample(t, readBatchDataRequestPriority, dbName, \"failed to read batch data with RequestPriority\")\n+\tassertContains(t, out, \"1 Marc Richards\")\n+\n \trunSampleWithContext(ctx, t, addCommitTimestamp, dbName, \"failed to add commit timestamp\")\n \trunSample(t, updateWithTimestamp, dbName, \"failed to update with timestamp\")\n \tout = runSample(t, queryWithTimestamp, dbName, \"failed to query with timestamp\")",
        "comments": [],
        "commit_messages": [
            "feat(spanner): add samples for request priorities\n\nAdded samples for setting request priority with streaming read, execute streaming query, commit, batch DML, partitioned DML and batch partitioned queries, added integration tests."
        ],
        "last_commit_sha": "fbde5d2edb24b2bbde5c24092ebeca55ee28f520"
    },
    {
        "pr_title": "feat(spanner): add samples for request priorities",
        "pr_number": 2193,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -232,6 +242,9 @@\nfunc TestSample(t *testing.T) {\n \tout = runSample(t, insertUsingDML, dbName, \"failed to insert using DML\")\n \tassertContains(t, out, \"record(s) inserted\")\n \n+\tout = runSample(t, insertUsingDMLRequestPriority, dbName, \"failed to insert using DML with RequestPriority\")\n+\tassertContains(t, out, \"record(s) inserted\")\n+\n \tout = runSample(t, setCustomTimeoutAndRetry, dbName, \"failed to insert using DML with custom timeout and retry\")\n \tassertContains(t, out, \"record(s) inserted\")",
        "comments": [],
        "commit_messages": [
            "feat(spanner): add samples for request priorities\n\nAdded samples for setting request priority with streaming read, execute streaming query, commit, batch DML, partitioned DML and batch partitioned queries, added integration tests."
        ],
        "last_commit_sha": "fbde5d2edb24b2bbde5c24092ebeca55ee28f520"
    },
    {
        "pr_title": "feat(kms): add samples for new rng and hmac APIs",
        "pr_number": 2191,
        "file_name": "kms/create_key_asymmetric_decrypt.go",
        "code_diff": "@@ -19,9 +19,11 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/durationpb\"\n )\n \n // createKeyAsymmetricDecrypt creates a new asymmetric RSA encrypt/decrypt key",
        "comments": [],
        "commit_messages": [
            "feat(kms): add samples for new rng and hmac APIs"
        ],
        "last_commit_sha": "8e84768a1477899cb9675351e647482d7fd0cd9f"
    },
    {
        "pr_title": "feat(kms): add samples for new rng and hmac APIs",
        "pr_number": 2191,
        "file_name": "kms/create_key_asymmetric_sign.go",
        "code_diff": "@@ -19,9 +19,11 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/durationpb\"\n )\n \n // createKeyAsymmetricSign creates a new asymmetric RSA sign/verify key pair",
        "comments": [],
        "commit_messages": [
            "feat(kms): add samples for new rng and hmac APIs"
        ],
        "last_commit_sha": "8e84768a1477899cb9675351e647482d7fd0cd9f"
    },
    {
        "pr_title": "feat(kms): add samples for new rng and hmac APIs",
        "pr_number": 2191,
        "file_name": "kms/create_key_hsm.go",
        "code_diff": "@@ -19,9 +19,11 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/durationpb\"\n )\n \n // createKeyHSM creates a new symmetric encrypt/decrypt key on Cloud KMS.",
        "comments": [],
        "commit_messages": [
            "feat(kms): add samples for new rng and hmac APIs"
        ],
        "last_commit_sha": "8e84768a1477899cb9675351e647482d7fd0cd9f"
    },
    {
        "pr_title": "feat(kms): add samples for new rng and hmac APIs",
        "pr_number": 2191,
        "file_name": "kms/kms_helpers_test.go",
        "code_diff": "@@ -42,6 +42,7 @@\ntype kmsFixture struct {\n \tAsymmetricSignRSAKeyName string\n \tHSMKeyName               string\n \tSymmetricKeyName         string\n+\tHMACKeyName              string\n }\n \n func NewKMSFixture(projectID string) (*kmsFixture, error) {",
        "comments": [],
        "commit_messages": [
            "feat(kms): add samples for new rng and hmac APIs"
        ],
        "last_commit_sha": "8e84768a1477899cb9675351e647482d7fd0cd9f"
    },
    {
        "pr_title": "feat(kms): add samples for new rng and hmac APIs",
        "pr_number": 2191,
        "file_name": "kms/kms_helpers_test.go",
        "code_diff": "@@ -87,6 +88,11 @@\nfunc NewKMSFixture(projectID string) (*kmsFixture, error) {\n \t\treturn nil, fmt.Errorf(\"failed to create symmetric key: %v\", err)\n \t}\n \n+\tk.HMACKeyName, err = k.CreateHMACKey(k.KeyRingName)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"failed to create hmac key: %v\", err)\n+\t}\n+\n \treturn &k, nil\n }",
        "comments": [],
        "commit_messages": [
            "feat(kms): add samples for new rng and hmac APIs"
        ],
        "last_commit_sha": "8e84768a1477899cb9675351e647482d7fd0cd9f"
    },
    {
        "pr_title": "feat(kms): add samples for new rng and hmac APIs",
        "pr_number": 2191,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -119,6 +119,21 @@\nfunc TestCreateKeyLabels(t *testing.T) {\n \t}\n }\n \n+func TestCreateKeyMAC(t *testing.T) {\n+\ttestutil.SystemTest(t)\n+\n+\tparent, id := fixture.KeyRingName, fixture.RandomID()\n+\n+\tvar b bytes.Buffer\n+\tif err := createKeyMac(&b, parent, id); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Created key:\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"createKeyMac: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestCreateKeySymmetricEncryptDecrypt(t *testing.T) {\n \ttestutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [
            "feat(kms): add samples for new rng and hmac APIs"
        ],
        "last_commit_sha": "8e84768a1477899cb9675351e647482d7fd0cd9f"
    },
    {
        "pr_title": "feat(kms): add samples for new rng and hmac APIs",
        "pr_number": 2191,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -346,6 +361,21 @@\nfunc TestEncryptSymmetric(t *testing.T) {\n \t}\n }\n \n+func TestGenerateRandomBytes(t *testing.T) {\n+\ttestutil.SystemTest(t)\n+\n+\tname := fixture.LocationName\n+\n+\tvar b bytes.Buffer\n+\tif err := generateRandomBytes(&b, name, 256); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Random bytes:\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"generateRandomBytes: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestGetKeyVersionAttestation(t *testing.T) {\n \ttestutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [
            "feat(kms): add samples for new rng and hmac APIs"
        ],
        "last_commit_sha": "8e84768a1477899cb9675351e647482d7fd0cd9f"
    },
    {
        "pr_title": "feat(kms): add samples for new rng and hmac APIs",
        "pr_number": 2191,
        "file_name": "kms/kms_test.go",
        "code_diff": "@@ -469,6 +499,21 @@\nfunc TestSignAsymmetric(t *testing.T) {\n \t}\n }\n \n+func TestSignMac(t *testing.T) {\n+\ttestutil.SystemTest(t)\n+\n+\tname := fmt.Sprintf(\"%s/cryptoKeyVersions/1\", fixture.HMACKeyName)\n+\n+\tvar b bytes.Buffer\n+\tif err := signMac(&b, name, \"fruitloops\"); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tif got, want := b.String(), \"Signature:\"; !strings.Contains(got, want) {\n+\t\tt.Errorf(\"signMac: expected %q to contain %q\", got, want)\n+\t}\n+}\n+\n func TestUpdateKeyUpdateLabels(t *testing.T) {\n \ttestutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [
            "feat(kms): add samples for new rng and hmac APIs"
        ],
        "last_commit_sha": "8e84768a1477899cb9675351e647482d7fd0cd9f"
    },
    {
        "pr_title": "feat(spanner): add samples for setting default leader",
        "pr_number": 2178,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -52,7 +52,16 @@\nvar (\n \n func initTest(t *testing.T, id string) (instName, dbName string, cleanup func()) {\n \tprojectID := getSampleProjectId(t)\n-\tinstName, cleanup = createTestInstance(t, projectID)\n+\tinstName, cleanup = createTestInstance(t, projectID, \"regional-us-central1\")\n+\tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n+\tdbName = fmt.Sprintf(\"%s/databases/%s\", instName, dbID)\n+\n+\treturn\n+}\n+\n+func initTestWithConfig(t *testing.T, id string, instanceConfigName string) (instName, dbName string, cleanup func()) {\n+\tprojectID := getSampleProjectId(t)\n+\tinstName, cleanup = createTestInstance(t, projectID, instanceConfigName)\n \tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n \tdbName = fmt.Sprintf(\"%s/databases/%s\", instName, dbID)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0e516505144f82a3b76398acd25b456433193abb"
    },
    {
        "pr_title": "feat(spanner): add samples for setting default leader",
        "pr_number": 2178,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -440,6 +449,75 @@\nfunc TestCustomerManagedEncryptionKeys(t *testing.T) {\n \tassertContains(t, out, fmt.Sprintf(\"using encryption key %s\", kmsKeyName))\n }\n \n+func TestCreateDatabaseWithDefaultLeaderSample(t *testing.T) {\n+\t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n+\tinstName, dbName, cleanup := initTestWithConfig(t, randomID(), \"nam3\")\n+\tdefer cleanup()\n+\n+\tprojectID := getSampleProjectId(t)\n+\tvar b bytes.Buffer\n+\n+\t// Try to get Instance Configs\n+\tconfig := fmt.Sprintf(\"projects/%s/instanceConfigs/%s\", projectID, \"nam3\")\n+\tif err := getInstanceConfig(&b, config); err != nil {\n+\t\tt.Errorf(\"failed to create get instance configs: %v\", err)\n+\t}\n+\tout := b.String()\n+\tassertContains(t, out, \"Available leader options for instance config\")\n+\n+\t// Try to list Instance Configs\n+\tb.Reset()\n+\tif err := listInstanceConfigs(&b, \"projects/\"+projectID); err != nil {\n+\t\tt.Errorf(\"failed to list instance configs: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, \"Available leader options for instance config\")\n+\n+\t// Try to get list of Databases\n+\tb.Reset()\n+\tif err := listDatabases(&b, instName); err != nil {\n+\t\tt.Errorf(\"failed to get list of Databases: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, \"Databases for instance\")\n+\n+\t// Try to create Database with Default Leader\n+\tb.Reset()\n+\tdefaultLeader := \"us-east1\"\n+\tif err := createDatabaseWithDefaultLeader(&b, dbName, defaultLeader); err != nil {\n+\t\tt.Errorf(\"failed to create database with default leader: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, fmt.Sprintf(\"Created database [%s] with default leader%q\\n\", dbName, defaultLeader))\n+\n+\t// Try to update Database with Default Leader\n+\tb.Reset()\n+\tdefaultLeader = \"us-east4\"\n+\tif err := updateDatabaseWithDefaultLeader(&b, dbName, defaultLeader); err != nil {\n+\t\tt.Errorf(\"failed to update database with default leader: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, \"Updated the default leader\\n\")\n+\n+\t// Try to get Database DDL\n+\tb.Reset()\n+\tif err := getDatabaseDdl(&b, dbName); err != nil {\n+\t\tt.Errorf(\"failed to get Database DDL: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, \"Database DDL is as follows\")\n+\n+\t// Try to Query Information Schema Database Options\n+\tb.Reset()\n+\tif err := queryInformationSchemaDatabaseOptions(&b, dbName); err != nil {\n+\t\tt.Errorf(\"failed to query information schema database options: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, \"The result of the query to get\")\n+}\n+\n func maybeCreateKey(projectId, locationId, keyRingId, keyId string) error {\n \tclient, err := kms.NewKeyManagementClient(context.Background())\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0e516505144f82a3b76398acd25b456433193abb"
    },
    {
        "pr_title": "feat(spanner): add samples for setting default leader",
        "pr_number": 2178,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -553,7 +631,7 @@\nfunc mustRunSample(t *testing.T, f sampleFuncWithContext, dbName, errMsg string)\n \treturn b.String()\n }\n \n-func createTestInstance(t *testing.T, projectID string) (instanceName string, cleanup func()) {\n+func createTestInstance(t *testing.T, projectID string, instanceConfigName string) (instanceName string, cleanup func()) {\n \tctx := context.Background()\n \tinstanceID := fmt.Sprintf(\"go-sample-%s\", uuid.New().String()[:16])\n \tinstanceName = fmt.Sprintf(\"projects/%s/instances/%s\", projectID, instanceID)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0e516505144f82a3b76398acd25b456433193abb"
    },
    {
        "pr_title": "fix(compute): iterator to match new return values",
        "pr_number": 2174,
        "file_name": "compute/list_instances.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n \t\"io\"\n \n \tcompute \"cloud.google.com/go/compute/apiv1\"\n+\t\"google.golang.org/api/iterator\"\n \tcomputepb \"google.golang.org/genproto/googleapis/cloud/compute/v1\"\n )",
        "comments": [],
        "commit_messages": [
            "fix(compute): iterator to match new return values"
        ],
        "last_commit_sha": "3969750ab38b4e81b3ee01230d44c204c8a464fc"
    },
    {
        "pr_title": "docs(firestore): incorporate a var to sample, improve docstrings",
        "pr_number": 2173,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -507,8 +507,10 @@\nfunc SnippetIterator_Cursor() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tdefer client.Close()\n-\tcursorStr := \"\"\n \t// [START datastore_cursor_paging]\n+\t// cursorStr is a cursor to start querying at.\n+\tcursorStr := \"\"\n+\n \tconst pageSize = 5\n \tquery := datastore.NewQuery(\"Tasks\").Limit(pageSize)\n \tif cursorStr != \"\" {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "20cc2b586ef5f2288f8b66b8dcb84b8f4e1f274d"
    },
    {
        "pr_title": "test(storage): Improve logging for objects test",
        "pr_number": 2168,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -378,6 +378,9 @@\nfunc TestV4SignedURL(t *testing.T) {\n \n \thttpClient := &http.Client{}\n \trequest, err := http.NewRequest(\"PUT\", putURL, strings.NewReader(\"hello world\"))\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to compose HTTP request: %v\", err)\n+\t}\n \trequest.ContentLength = 11\n \trequest.Header.Set(\"Content-Type\", \"application/octet-stream\")\n \tresponse, err := httpClient.Do(request)",
        "comments": [],
        "commit_messages": [
            "Improve logging for objects test"
        ],
        "last_commit_sha": "16ab3f5ff260964240fd2fa7d8129eaf4becd7a0"
    },
    {
        "pr_title": "test(storage): Improve logging for objects test",
        "pr_number": 2168,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -422,6 +425,9 @@\nfunc TestPostPolicyV4(t *testing.T) {\n \tbucketName := tc.ProjectID + \"-post-policy-bucket-name\"\n \tobjectName := \"foo.txt\"\n \tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n+\tif serviceAccount == \"\" {\n+\t\tt.Error(\"GOOGLE_APPLICATION_CREDENTIALS must be set\")\n+\t}\n \n \tif err := testutil.CleanBucket(ctx, t, tc.ProjectID, bucketName); err != nil {\n \t\tt.Fatalf(\"CleanBucket: %v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "16ab3f5ff260964240fd2fa7d8129eaf4becd7a0"
    },
    {
        "pr_title": "fix(run): Add retries to tests",
        "pr_number": 2152,
        "file_name": "run/testing/h2c.e2e_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"net/http\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [
            "fix(run): Add retries to tests"
        ],
        "last_commit_sha": "330bb3f79f2bd0ff8ac75f7b1e45f1f7d19992b8"
    },
    {
        "pr_title": "feat(secretmanager): add examples for using etags",
        "pr_number": 2130,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -207,6 +207,25 @@\nfunc TestDeleteSecret(t *testing.T) {\n \t}\n }\n \n+func TestDeleteSecretWithEtag(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n+\tif err := deleteSecretWithEtag(secret.Name, secret.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testClient(t)\n+\t_, err := client.GetSecret(ctx, &secretmanagerpb.GetSecretRequest{\n+\t\tName: secret.Name,\n+\t})\n+\tif terr, ok := grpcstatus.FromError(err); !ok || terr.Code() != grpccodes.NotFound {\n+\t\tt.Errorf(\"deleteSecret: expected %v to be not found\", err)\n+\t}\n+}\n+\n func TestDestroySecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [
            "feat(secretmanager): add examples for using etags"
        ],
        "last_commit_sha": "2190bb1cdeaabe6a1ab7cf7e9852a67647540a60"
    },
    {
        "pr_title": "feat(secretmanager): add examples for using etags",
        "pr_number": 2130,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -232,6 +251,30 @@\nfunc TestDestroySecretVersion(t *testing.T) {\n \t}\n }\n \n+func TestDestroySecretVersionWithEtag(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tpayload := []byte(\"my-secret\")\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n+\tversion := testSecretVersion(t, secret.Name, payload)\n+\n+\tif err := destroySecretVersionWithEtag(version.Name, version.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testClient(t)\n+\tv, err := client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_DESTROYED; got != want {\n+\t\tt.Errorf(\"testSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+}\n+\n func TestDisableEnableSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [
            "feat(secretmanager): add examples for using etags"
        ],
        "last_commit_sha": "2190bb1cdeaabe6a1ab7cf7e9852a67647540a60"
    },
    {
        "pr_title": "feat(secretmanager): add examples for using etags",
        "pr_number": 2130,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -271,6 +314,45 @@\nfunc TestDisableEnableSecretVersion(t *testing.T) {\n \t}\n }\n \n+func TestDisableEnableSecretVersionWithEtag(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tpayload := []byte(\"my-secret\")\n+\tsecret := testSecret(t, tc.ProjectID)\n+\tdefer testCleanupSecret(t, secret.Name)\n+\n+\tversion := testSecretVersion(t, secret.Name, payload)\n+\n+\tif err := disableSecretVersionWithEtag(version.Name, version.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tclient, ctx := testClient(t)\n+\tv, err := client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_DISABLED; got != want {\n+\t\tt.Errorf(\"testSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+\n+\tif err := enableSecretVersionWithEtag(version.Name, v.Etag); err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tv, err = client.GetSecretVersion(ctx, &secretmanagerpb.GetSecretVersionRequest{\n+\t\tName: version.Name,\n+\t})\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tif got, want := v.State, secretmanagerpb.SecretVersion_ENABLED; got != want {\n+\t\tt.Errorf(\"testSecretVersion: expected %v to be %v\", got, want)\n+\t}\n+}\n+\n func TestGetSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [
            "feat(secretmanager): add examples for using etags"
        ],
        "last_commit_sha": "2190bb1cdeaabe6a1ab7cf7e9852a67647540a60"
    },
    {
        "pr_title": "test(spanner): use a separate instance for each test",
        "pr_number": 2122,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -51,31 +51,11 @@\nvar (\n )\n \n func initTest(t *testing.T, id string) (dbName string, cleanup func()) {\n-\tinstance := getInstance(t)\n+\tprojectID := getSampleProjectId(t)\n+\tinstance, cleanup := createTestInstance(t, projectID)\n \tdbID := validLength(fmt.Sprintf(\"smpl-%s\", id), t)\n \tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, dbID)\n \n-\tctx := context.Background()\n-\tadminClient, err := database.NewDatabaseAdminClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to create DB admin client: %v\", err)\n-\t}\n-\n-\t// Check for database existance prior to test start and delete, as resources\n-\t// may not have been cleaned up from previous invocations.\n-\tif db, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: dbName}); err == nil {\n-\t\tt.Logf(\"database %s exists in state %s. delete result: %v\", db.GetName(), db.GetState().String(),\n-\t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName}))\n-\t}\n-\tcleanup = func() {\n-\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n-\t\t\tif err != nil {\n-\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n-\t\t\t}\n-\t\t})\n-\t\tadminClient.Close()\n-\t}\n \treturn\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7c8a1ae33237722b3dd9a2a376c80f21114bace6"
    },
    {
        "pr_title": "test(spanner): use a separate instance for each test",
        "pr_number": 2122,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -103,65 +83,27 @@\nfunc getVersionTime(t *testing.T, dbName string) (versionTime time.Time) {\n \treturn versionTime\n }\n \n-func initBackupTest(t *testing.T, id, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n-\tinstance := getInstance(t)\n+func initBackupTest(t *testing.T, id string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n+\tprojectID := getSampleProjectId(t)\n+\tinstance, cleanup := createTestInstance(t, projectID)\n \trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", id), t)\n \trestoreDBName = fmt.Sprintf(\"%s/databases/%s\", instance, restoreDatabaseID)\n \tbackupID = validLength(fmt.Sprintf(\"backup-%s\", id), t)\n \tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", id), t)\n \n-\tctx, cancel := context.WithTimeout(context.Background(), time.Hour)\n-\tdefer cancel()\n-\tadminClient, err := database.NewDatabaseAdminClient(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to create admin client: %v\", err)\n-\t}\n-\tif db, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: restoreDBName}); err == nil {\n-\t\tt.Logf(\"database %s exists in state %s. delete result: %v\", db.GetName(), db.GetState().String(),\n-\t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName}))\n-\t}\n-\n-\t// Check for any backups that were created from that database and delete those as well\n-\titer := adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n-\t\tParent: instance,\n-\t\tFilter: \"database:\" + dbName,\n-\t})\n-\tfor {\n-\t\tresp, err := iter.Next()\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\tt.Errorf(\"Failed to list backups for database %s: %v\", dbName, err)\n-\t\t}\n-\t\tt.Logf(\"backup %s exists. delete result: %v\", resp.Name,\n-\t\t\tadminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: resp.Name}))\n-\t}\n-\n-\tcleanup = func() {\n-\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName})\n-\t\t\tif err != nil {\n-\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", restoreDBName, err)\n-\t\t\t}\n-\t\t})\n-\t}\n \treturn\n }\n \n func TestCreateInstances(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n \n \trunCreateInstanceSample(t, createInstance)\n \trunCreateInstanceSample(t, createInstanceWithProcessingUnits)\n }\n \n func runCreateInstanceSample(t *testing.T, f instanceSampleFunc) {\n-\tprojectID, _, err := parseInstanceName(getInstance(t))\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to parse instance name: %v\", err)\n-\t}\n-\n+\tprojectID := getSampleProjectId(t)\n \tinstanceID := fmt.Sprintf(\"go-sample-test-%s\", uuid.New().String()[:8])\n \tout := runInstanceSample(t, f, projectID, instanceID, \"failed to create an instance\")\n \tif err := cleanupInstance(projectID, instanceID); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7c8a1ae33237722b3dd9a2a376c80f21114bace6"
    },
    {
        "pr_title": "test(spanner): use a separate instance for each test",
        "pr_number": 2122,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -172,6 +114,7 @@\nfunc runCreateInstanceSample(t *testing.T, f instanceSampleFunc) {\n \n func TestSample(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n \n \tdbName, cleanup := initTest(t, randomID())\n \tdefer cleanup()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7c8a1ae33237722b3dd9a2a376c80f21114bace6"
    },
    {
        "pr_title": "test(spanner): use a separate instance for each test",
        "pr_number": 2122,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -377,10 +320,12 @@\nfunc TestBackupSample(t *testing.T) {\n \t\tt.Skip(\"GOLANG_SAMPLES_E2E_TEST not set\")\n \t}\n \t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n \tid := randomID()\n \tdbName, cleanup := initTest(t, id)\n \tdefer cleanup()\n-\trestoreDBName, backupID, cancelledBackupID, cleanupBackup := initBackupTest(t, id, dbName)\n+\trestoreDBName, backupID, cancelledBackupID, cleanupBackup := initBackupTest(t, id)\n \n \tvar out string\n \t// Set up the database for testing backup operations.",
        "comments": [],
        "commit_messages": [
            "test: use a separate instance for each test"
        ],
        "last_commit_sha": "7c8a1ae33237722b3dd9a2a376c80f21114bace6"
    },
    {
        "pr_title": "test(spanner): use a separate instance for each test",
        "pr_number": 2122,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -423,6 +368,8 @@\nfunc TestBackupSample(t *testing.T) {\n \n func TestCreateDatabaseWithRetentionPeriodSample(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n+\tt.Parallel()\n+\n \tdbName, cleanup := initTest(t, randomID())\n \tdefer cleanup()",
        "comments": [],
        "commit_messages": [
            "test: use a separate instance for each test"
        ],
        "last_commit_sha": "7c8a1ae33237722b3dd9a2a376c80f21114bace6"
    },
    {
        "pr_title": "test(spanner): use a separate instance for each test",
        "pr_number": 2122,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -438,17 +385,16 @@\nfunc TestCustomerManagedEncryptionKeys(t *testing.T) {\n \t\tt.Skip(\"GOLANG_SAMPLES_E2E_TEST not set\")\n \t}\n \ttc := testutil.SystemTest(t)\n+\tt.Parallel()\n+\n \tdbName, cleanup := initTest(t, randomID())\n \tdefer cleanup()\n \n-\tadminClient, err := database.NewDatabaseAdminClient(context.Background())\n-\tif err != nil {\n-\t\tt.Errorf(\"failed to create admin client: %v\", err)\n-\t}\n-\n \tvar b bytes.Buffer\n \n-\tinstanceName := getInstance(t)\n+\tprojectID := getSampleProjectId(t)\n+\tinstanceName, cleanup := createTestInstance(t, projectID)\n+\tdefer cleanup()\n \tlocationId := \"us-central1\"\n \tkeyRingId := \"spanner-test-keyring\"\n \tkeyId := \"spanner-test-key\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7c8a1ae33237722b3dd9a2a376c80f21114bace6"
    },
    {
        "pr_title": "test(spanner): use a separate instance for each test",
        "pr_number": 2122,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -477,11 +423,6 @@\nfunc TestCustomerManagedEncryptionKeys(t *testing.T) {\n \n \t// Try to create a backup of the encrypted database and delete it after the test.\n \tbackupId := fmt.Sprintf(\"enc-backup-%s\", randomID())\n-\tdefer func() {\n-\t\t_ = adminClient.DeleteBackup(context.Background(), &adminpb.DeleteBackupRequest{\n-\t\t\tName: fmt.Sprintf(\"%s/backups/%s\", instanceName, backupId),\n-\t\t})\n-\t}()\n \tb.Reset()\n \tif err := createBackupWithCustomerManagedEncryptionKey(ctx, &b, dbName, backupId, kmsKeyName); err != nil {\n \t\tt.Errorf(\"failed to create backup with customer managed encryption key: %v\", err)",
        "comments": [],
        "commit_messages": [
            "test: use a separate instance for each test"
        ],
        "last_commit_sha": "7c8a1ae33237722b3dd9a2a376c80f21114bace6"
    },
    {
        "pr_title": "test(spanner): use a separate instance for each test",
        "pr_number": 2122,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -492,11 +433,6 @@\nfunc TestCustomerManagedEncryptionKeys(t *testing.T) {\n \n \t// Try to restore the encrypted database and delete the restored database after the test.\n \trestoredName := fmt.Sprintf(\"%s/databases/rest-enc-%s\", instanceName, randomID())\n-\tdefer func() {\n-\t\t_ = adminClient.DropDatabase(context.Background(), &adminpb.DropDatabaseRequest{\n-\t\t\tDatabase: restoredName,\n-\t\t})\n-\t}()\n \trestoreFunc := func(ctx context.Context, w io.Writer, dbName, backupID string) error {\n \t\treturn restoreBackupWithCustomerManagedEncryptionKey(ctx, w, dbName, backupId, kmsKeyName)\n \t}",
        "comments": [],
        "commit_messages": [
            "test: use a separate instance for each test"
        ],
        "last_commit_sha": "7c8a1ae33237722b3dd9a2a376c80f21114bace6"
    },
    {
        "pr_title": "test(spanner): use a separate instance for each test",
        "pr_number": 2122,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -607,15 +543,115 @@\nfunc mustRunSample(t *testing.T, f sampleFuncWithContext, dbName, errMsg string)\n \treturn b.String()\n }\n \n-func getInstance(t *testing.T) string {\n+func createTestInstance(t *testing.T, projectID string) (instanceName string, cleanup func()) {\n+\tctx := context.Background()\n+\tinstanceID := fmt.Sprintf(\"go-sample-%s\", uuid.New().String()[:16])\n+\tinstanceName = fmt.Sprintf(\"projects/%s/instances/%s\", projectID, instanceID)\n+\tinstanceAdmin, err := instance.NewInstanceAdminClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create InstanceAdminClient: %v\", err)\n+\t}\n+\tdatabaseAdmin, err := database.NewDatabaseAdminClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create DatabaseAdminClient: %v\", err)\n+\t}\n+\n+\t// Cleanup old test instances that might not have been deleted.\n+\titer := instanceAdmin.ListInstances(ctx, &instancepb.ListInstancesRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%v\", projectID),\n+\t\tFilter: \"labels.cloud_spanner_samples_test:true\",\n+\t})\n+\tfor {\n+\t\tinstance, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to list existing instances: %v\", err)\n+\t\t}\n+\t\tif createTimeString, ok := instance.Labels[\"create_time\"]; ok {\n+\t\t\tseconds, err := strconv.ParseInt(createTimeString, 10, 64)\n+\t\t\tif err != nil {\n+\t\t\t\tt.Logf(\"could not parse create time %v: %v\", createTimeString, err)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tcreateTime := time.Unix(seconds, 0)\n+\t\t\tdiff := time.Now().Sub(createTime)\n+\t\t\tif diff > time.Hour*24 {\n+\t\t\t\tt.Logf(\"deleting stale test instance %v\", instance.Name)\n+\t\t\t\tdeleteInstanceAndBackups(t, instance.Name, instanceAdmin, databaseAdmin)\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\top, err := instanceAdmin.CreateInstance(ctx, &instancepb.CreateInstanceRequest{\n+\t\tParent:     fmt.Sprintf(\"projects/%s\", projectID),\n+\t\tInstanceId: instanceID,\n+\t\tInstance: &instancepb.Instance{\n+\t\t\tConfig:      fmt.Sprintf(\"projects/%s/instanceConfigs/%s\", projectID, \"regional-us-central1\"),\n+\t\t\tDisplayName: instanceID,\n+\t\t\tNodeCount:   1,\n+\t\t\tLabels: map[string]string{\n+\t\t\t\t\"cloud_spanner_samples_test\": \"true\",\n+\t\t\t\t\"create_time\":                fmt.Sprintf(\"%v\", time.Now().Unix()),\n+\t\t\t},\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\tt.Fatalf(\"could not create instance %s: %v\", fmt.Sprintf(\"projects/%s/instances/%s\", projectID, instanceID), err)\n+\t}\n+\t_, err = op.Wait(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"waiting for instance creation to finish failed: %v\", err)\n+\t}\n+\treturn instanceName, func() {\n+\t\tdeleteInstanceAndBackups(t, instanceName, instanceAdmin, databaseAdmin)\n+\t\tinstanceAdmin.Close()\n+\t\tdatabaseAdmin.Close()\n+\t}\n+}\n+\n+func deleteInstanceAndBackups(\n+\tt *testing.T,\n+\tinstanceName string,\n+\tinstanceAdmin *instance.InstanceAdminClient,\n+\tdatabaseAdmin *database.DatabaseAdminClient) {\n+\tctx := context.Background()\n+\t// Delete all backups before deleting the instance.\n+\titer := databaseAdmin.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"Failed to list backups for instance %s: %v\", instanceName, err)\n+\t\t}\n+\t\tdatabaseAdmin.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: resp.Name})\n+\t}\n+\tinstanceAdmin.DeleteInstance(ctx, &instancepb.DeleteInstanceRequest{Name: instanceName})\n+}\n+\n+func getSampleProjectId(t *testing.T) string {\n+\t// These tests get the project id from the environment variable\n+\t// GOLANG_SAMPLES_SPANNER that is also used by other integration tests for\n+\t// Spanner samples. The tests in this file create a separate instance for\n+\t// each test, so only the project id is used, and the rest of the instance\n+\t// name is ignored.\n \tinstance := os.Getenv(\"GOLANG_SAMPLES_SPANNER\")\n \tif instance == \"\" {\n \t\tt.Skip(\"Skipping spanner integration test. Set GOLANG_SAMPLES_SPANNER.\")\n \t}\n \tif !strings.HasPrefix(instance, \"projects/\") {\n \t\tt.Fatal(\"Spanner instance ref must be in the form of 'projects/PROJECT_ID/instances/INSTANCE_ID'\")\n \t}\n-\treturn instance\n+\tprojectId, _, err := parseInstanceName(instance)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Could not parse project id from instance name %q: %v\", instance, err)\n+\t}\n+\treturn projectId\n }\n \n func assertContains(t *testing.T, out string, sub string) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7c8a1ae33237722b3dd9a2a376c80f21114bace6"
    },
    {
        "pr_title": "feat(spanner): add samples for low-cost instances",
        "pr_number": 2119,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -42,7 +42,7 @@\nimport (\n \n type sampleFunc func(w io.Writer, dbName string) error\n type sampleFuncWithContext func(ctx context.Context, w io.Writer, dbName string) error\n-type instanceSampleFunc func(ctx context.Context, w io.Writer, projectID, instanceID string) error\n+type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string) error\n type createBackupSampleFunc func(ctx context.Context, w io.Writer, dbName, backupID string, versionTime time.Time) error",
        "comments": [],
        "commit_messages": [
            "Fix comments."
        ],
        "last_commit_sha": "cae30a389be5ccd216b92a1835dbea6803eabbc1"
    },
    {
        "pr_title": "feat(spanner): add samples for low-cost instances",
        "pr_number": 2119,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -149,18 +149,21 @@\nfunc initBackupTest(t *testing.T, id, dbName string) (restoreDBName, backupID, c\n \treturn\n }\n \n-func TestCreateInstance(t *testing.T) {\n+func TestCreateInstances(t *testing.T) {\n \t_ = testutil.SystemTest(t)\n \n+\trunCreateInstanceSample(t, createInstance)\n+\trunCreateInstanceSample(t, createInstanceWithProcessingUnits)\n+}\n+\n+func runCreateInstanceSample(t *testing.T, f instanceSampleFunc) {\n \tprojectID, _, err := parseInstanceName(getInstance(t))\n \tif err != nil {\n \t\tt.Fatalf(\"failed to parse instance name: %v\", err)\n \t}\n \n-\tctx, cancel := context.WithTimeout(context.Background(), time.Hour)\n-\tdefer cancel()\n \tinstanceID := fmt.Sprintf(\"go-sample-test-%s\", uuid.New().String()[:8])\n-\tout := runInstanceSample(ctx, t, createInstance, projectID, instanceID, \"failed to create an instance\")\n+\tout := runInstanceSample(t, f, projectID, instanceID, \"failed to create an instance\")\n \tif err := cleanupInstance(projectID, instanceID); err != nil {\n \t\tt.Logf(\"cleanupInstance error: %s\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cae30a389be5ccd216b92a1835dbea6803eabbc1"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -20,13 +20,15 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n+\t\"strconv\"\n \t\"strings\"\n \t\"sync\"\n \t\"testing\"\n \t\"time\"\n \n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n+\t\"google.golang.org/api/iterator\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/go-cmp/cmp\"",
        "comments": [],
        "commit_messages": [
            "refactor(pubsub): make test resources unique and improve cleanup"
        ],
        "last_commit_sha": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -35,6 +37,12 @@\nimport (\n var topicID string\n var subID string\n \n+const (\n+\ttopicPrefix = \"topic\"\n+\tsubPrefix   = \"sub\"\n+\texpireAge   = 24 * time.Hour\n+)\n+\n // once guards cleanup related operations in setup. No need to set up and tear\n // down every time, so this speeds things up.\n var once sync.Once",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -19,18 +19,27 @@\npackage topics\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n \t\"io/ioutil\"\n+\t\"strconv\"\n+\t\"strings\"\n \t\"sync\"\n \t\"testing\"\n \t\"time\"\n \n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n var topicID string\n \n+const (\n+\ttopicPrefix = \"topic\"\n+\texpireAge   = 24 * time.Hour\n+)\n+\n // once guards cleanup related operations in setup. No need to set up and tear\n // down every time, so this speeds things up.\n var once sync.Once",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -39,23 +48,41 @@\nfunc setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n-\ttopicID = \"test-topic\"\n \tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n \n-\t// Cleanup resources from the previous tests.\n \tonce.Do(func() {\n-\t\ttopic := client.Topic(topicID)\n-\t\tok, err := topic.Exists(ctx)\n-\t\tif err != nil {\n-\t\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n-\t\t}\n-\t\tif ok {\n-\t\t\tif err := topic.Delete(ctx); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicID, err)\n+\t\ttopicID = fmt.Sprintf(\"%s-%d\", topicPrefix, time.Now().UnixNano())\n+\n+\t\t// Cleanup resources from previous tests.\n+\t\tit := client.Topics(ctx)\n+\t\tfor {\n+\t\t\tt, err := it.Next()\n+\t\t\tif err == iterator.Done {\n+\t\t\t\tbreak\n+\t\t\t}\n+\t\t\tif err != nil {\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t\ttID := t.ID()\n+\t\t\tp := strings.Split(tID, \"-\")\n+\n+\t\t\t// Only delete resources created from these tests.\n+\t\t\tif p[0] == topicPrefix {\n+\t\t\t\ttCreated := p[1]\n+\t\t\t\ttimestamp, err := strconv.ParseInt(tCreated, 10, 64)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t\ttimeTCreated := time.Unix(0, timestamp)\n+\t\t\t\tif time.Since(timeTCreated) > expireAge {\n+\t\t\t\t\tif err := t.Delete(ctx); err != nil {\n+\t\t\t\t\t\tfmt.Printf(\"Delete topic err: %v: %v\", t.String(), err)\n+\t\t\t\t\t}\n+\t\t\t\t}\n \t\t\t}\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "refactor(pubsub): make test resources unique and improve cleanup",
        "pr_number": 2084,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -185,36 +212,6 @@\nfunc TestIAM(t *testing.T) {\n \t})\n }\n \n-func TestDelete(t *testing.T) {\n-\tctx := context.Background()\n-\ttc := testutil.SystemTest(t)\n-\tclient := setup(t)\n-\n-\ttopic := client.Topic(topicID)\n-\tok, err := topic.Exists(ctx)\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n-\t}\n-\tif !ok {\n-\t\t_, err := client.CreateTopic(ctx, topicID)\n-\t\tif err != nil {\n-\t\t\tt.Fatalf(\"CreateTopic: %v\", err)\n-\t\t}\n-\t}\n-\n-\tbuf := new(bytes.Buffer)\n-\tif err := delete(buf, tc.ProjectID, topicID); err != nil {\n-\t\tt.Fatalf(\"failed to delete topic (%q): %v\", topicID, err)\n-\t}\n-\tok, err = client.Topic(topicID).Exists(context.Background())\n-\tif err != nil {\n-\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n-\t}\n-\tif ok {\n-\t\tt.Fatalf(\"got topic = %q; want none\", topicID)\n-\t}\n-}\n-\n func TestPublishWithOrderingKey(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1d2006b0cc90bf82f98ab07bdf0b9e53857f1dc9"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "auth/snippets.go",
        "code_diff": "@@ -40,6 +40,7 @@\nfunc implicit() {\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n+\tdefer storageClient.Close()\n \n \tit := storageClient.Buckets(ctx, \"project-id\")\n \tfor {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "auth/snippets.go",
        "code_diff": "@@ -74,6 +75,7 @@\nfunc explicit(jsonPath, projectID string) {\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n+\tdefer client.Close()\n \tfmt.Println(\"Buckets:\")\n \tit := client.Buckets(ctx, projectID)\n \tfor {",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -40,6 +40,7 @@\nfunc listAlertPolicies(w io.Writer, projectID string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \treq := &monitoringpb.ListAlertPoliciesRequest{\n \t\tName: \"projects/\" + projectID,",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -77,6 +78,7 @@\nfunc backupPolicies(w io.Writer, projectID string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer alertClient.Close()\n \talertReq := &monitoringpb.ListAlertPoliciesRequest{\n \t\tName: \"projects/\" + projectID,\n \t\t// Filter:  \"\", // See https://cloud.google.com/monitoring/api/v3/sorting-and-filtering.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -99,6 +101,7 @@\nfunc backupPolicies(w io.Writer, projectID string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer channelClient.Close()\n \tchannelReq := &monitoringpb.ListNotificationChannelsRequest{\n \t\tName: \"projects/\" + projectID,\n \t\t// Filter:  \"\", // See https://cloud.google.com/monitoring/api/v3/sorting-and-filtering.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -193,10 +196,12 @@\nfunc restorePolicies(w io.Writer, projectID string, r io.Reader) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer alertClient.Close()\n \tchannelClient, err := monitoring.NewNotificationChannelClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer channelClient.Close()\n \n \t// When a channel is recreated, rather than updated, it will get\n \t// a new name.  We have to update the AlertPolicy with the new",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -279,6 +284,7 @@\nfunc replaceChannels(w io.Writer, projectID, alertPolicyID string, channelIDs []\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \tpolicy := &monitoringpb.AlertPolicy{\n \t\tName: \"projects/\" + projectID + \"/alertPolicies/\" + alertPolicyID,",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -41,6 +41,7 @@\nfunc writeTimeSeriesValue(projectID, metricType string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer c.Close()\n \tnow := &timestamp.Timestamp{\n \t\tSeconds: time.Now().Unix(),\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "speech/caption/caption.go",
        "code_diff": "@@ -69,6 +69,7 @@\nfunc recognizeGCS(w io.Writer, gcsURI string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \t// Send the request with the URI (gs://...)\n \t// and sample rate information to be transcripted.",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "texttospeech/synthesize_file/synthesize_file.go",
        "code_diff": "@@ -39,6 +39,7 @@\nfunc SynthesizeTextFile(w io.Writer, textFile, outputFile string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \ttext, err := ioutil.ReadFile(textFile)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "texttospeech/synthesize_text/synthesize_text.go",
        "code_diff": "@@ -38,6 +38,7 @@\nfunc SynthesizeText(w io.Writer, text, outputFile string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \treq := texttospeechpb.SynthesizeSpeechRequest{\n \t\tInput: &texttospeechpb.SynthesisInput{",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -33,6 +33,7 @@\nfunc label(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn fmt.Errorf(\"video.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tfileBytes, err := ioutil.ReadFile(file)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -89,6 +90,7 @@\nfunc shotChange(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \tfileBytes, err := ioutil.ReadFile(file)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -128,6 +130,7 @@\nfunc explicitContent(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \tfileBytes, err := ioutil.ReadFile(file)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -32,6 +32,7 @@\nfunc labelURI(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn fmt.Errorf(\"video.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \top, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{\n \t\tFeatures: []videopb.Feature{",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -85,6 +86,7 @@\nfunc shotChangeURI(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \top, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{\n \t\tFeatures: []videopb.Feature{",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "fix(all): always call client.Close when creating a client",
        "pr_number": 2080,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -123,6 +125,7 @@\nfunc explicitContentURI(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n+\tdefer client.Close()\n \n \top, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{\n \t\tFeatures: []videopb.Feature{",
        "comments": [],
        "commit_messages": [
            "fix(all): always call client.Close when creating a client"
        ],
        "last_commit_sha": "ff329566059e5219d733975d3a7968d835fac1cb"
    },
    {
        "pr_title": "test(storage): fix HMAC key creation",
        "pr_number": 2071,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage hmac\n \n import (\n \t\"context\"\n+\t\"errors\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"os\"",
        "comments": [],
        "commit_messages": [
            "test(storage): fix HMAC key creation\n\nThis test failed again with a nil pointer dereference. I believe\nit's because test execution was not pausing after key creation\nfailed. This forces a fatal error at that point.\n\nFixes #2037"
        ],
        "last_commit_sha": "14d8387e555c752eb23d97b0f1123d0d0e17b575"
    },
    {
        "pr_title": "test(storage): fix HMAC key creation",
        "pr_number": 2071,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -82,7 +83,7 @@\nfunc TestActivateKey(t *testing.T) {\n \tkey, err := createTestKey(tc.ProjectID, t)\n \tdefer deleteTestKey(key)\n \tif err != nil {\n-\t\tt.Errorf(\"Error in key creation: %s\", err)\n+\t\tt.Fatalf(\"Error in key creation: %s\", err)\n \t}\n \n \t// Key must first be deactivated in order to update to active state.",
        "comments": [],
        "commit_messages": [
            "update other tests"
        ],
        "last_commit_sha": "14d8387e555c752eb23d97b0f1123d0d0e17b575"
    },
    {
        "pr_title": "test(storage): fix HMAC key creation",
        "pr_number": 2071,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -105,7 +106,7 @@\nfunc TestDeactivateKey(t *testing.T) {\n \tkey, err := createTestKey(tc.ProjectID, t)\n \tdefer deleteTestKey(key)\n \tif err != nil {\n-\t\tt.Errorf(\"Error in key creation: %s\", err)\n+\t\tt.Fatalf(\"Error in key creation: %s\", err)\n \t}\n \n \tkey, err = deactivateHMACKey(ioutil.Discard, key.AccessID, key.ProjectID)",
        "comments": [],
        "commit_messages": [
            "update other tests"
        ],
        "last_commit_sha": "14d8387e555c752eb23d97b0f1123d0d0e17b575"
    },
    {
        "pr_title": "test(storage): fix HMAC key creation",
        "pr_number": 2071,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -122,7 +123,7 @@\nfunc TestGetKey(t *testing.T) {\n \tkey, err := createTestKey(tc.ProjectID, t)\n \tdefer deleteTestKey(key)\n \tif err != nil {\n-\t\tt.Errorf(\"Error in key creation: %s\", err)\n+\t\tt.Fatalf(\"Error in key creation: %s\", err)\n \t}\n \n \ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [
            "test(storage): fix HMAC key creation\n\nThis test failed again with a nil pointer dereference. I believe\nit's because test execution was not pausing after key creation\nfailed. This forces a fatal error at that point.\n\nFixes #2037"
        ],
        "last_commit_sha": "14d8387e555c752eb23d97b0f1123d0d0e17b575"
    },
    {
        "pr_title": "test(storage): fix HMAC key creation",
        "pr_number": 2071,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -142,7 +143,7 @@\nfunc TestDeleteKey(t *testing.T) {\n \tkey, err := createTestKey(tc.ProjectID, t)\n \tdefer deleteTestKey(key)\n \tif err != nil {\n-\t\tt.Errorf(\"Error in key creation: %s\", err)\n+\t\tt.Fatalf(\"Error in key creation: %s\", err)\n \t}\n \n \t// Keys must be in INACTIVE state before deletion.",
        "comments": [],
        "commit_messages": [
            "update other tests"
        ],
        "last_commit_sha": "14d8387e555c752eb23d97b0f1123d0d0e17b575"
    },
    {
        "pr_title": "test(storage): fix HMAC key creation",
        "pr_number": 2071,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -177,7 +178,8 @@\nfunc createTestKey(projectID string, t *testing.T) (*storage.HMACKey, error) {\n \t\t// Nil key check should not happen but is added to handle flaky\n \t\t// \"nil pointer dereference\" error.\n \t\tif key == nil {\n-\t\t\tr.Errorf(\"Returned nil key.\")\n+\t\t\tr.Errorf(\"CreateHMACKey returned nil key.\")\n+\t\t\terr = errors.New(\"CreateHMACKey returned nil key\")\n \t\t\treturn\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "test(storage): fix HMAC key creation\n\nThis test failed again with a nil pointer dereference. I believe\nit's because test execution was not pausing after key creation\nfailed. This forces a fatal error at that point.\n\nFixes #2037"
        ],
        "last_commit_sha": "14d8387e555c752eb23d97b0f1123d0d0e17b575"
    },
    {
        "pr_title": "docs(appengine): add comment about authenticated push JWT token validation",
        "pr_number": 2059,
        "file_name": "appengine/go11x/pubsub/authenicated_push/main_test.go",
        "code_diff": "@@ -41,32 +41,43 @@\nfunc TestReceiveMessagesHandler(t *testing.T) {\n \n \ttests := []struct {\n \t\tname    string\n+\t\temail   string\n \t\taud     string\n \t\ttoken   string\n \t\twantErr bool\n \t}{\n \t\t{\n \t\t\tname:    \"works\",\n+\t\t\temail:   \"test-service-account-email@example.com\",\n \t\t\taud:     \"http://example.com\",\n \t\t\ttoken:   testToken,\n \t\t\twantErr: false,\n \t\t},\n+\t\t{\n+\t\t\tname:    \"bad email\",\n+\t\t\temail:   \"bad-email@example.com\",\n+\t\t\taud:     \"http://example.com\",\n+\t\t\ttoken:   testToken,\n+\t\t\twantErr: true,\n+\t\t},\n \t\t{\n \t\t\tname:    \"bad token sent\",\n+\t\t\temail:   \"test-service-account-email@example.com\",\n \t\t\taud:     \"http://example.com\",\n \t\t\ttoken:   \"bad token\",\n \t\t\twantErr: true,\n \t\t},\n \t\t{\n \t\t\tname:    \"mismatched aud claim in auth token\",\n+\t\t\temail:   \"test-service-account-email@example.com\",\n \t\t\taud:     \"http://mismatched.com\",\n \t\t\ttoken:   testToken,\n \t\t\twantErr: true,\n \t\t},\n \t}\n \tfor _, tt := range tests {\n \t\tt.Run(tt.name, func(t *testing.T) {\n-\t\t\tauthToken, pk := createRS256JWT(t, tt.aud)\n+\t\t\tauthToken, pk := createRS256JWT(t, tt.email, tt.aud)\n \t\t\tapp := &app{pubsubVerificationToken: testToken}\n \t\t\tapp.defaultHTTPClient = createClient(t, pk)\n \t\t\tpr := &pushRequest{",
        "comments": [],
        "commit_messages": [
            "Updated claim verification with a working example."
        ],
        "last_commit_sha": "eb8fe22b538e92bfcdd3306e83f34e1c6cf5570f"
    },
    {
        "pr_title": "docs(appengine): add comment about authenticated push JWT token validation",
        "pr_number": 2059,
        "file_name": "appengine/go11x/pubsub/authenicated_push/main_test.go",
        "code_diff": "@@ -148,9 +159,9 @@\ntype jwk struct {\n \tN   string `json:\"n\"`\n }\n \n-func createRS256JWT(t *testing.T, aud string) (string, rsa.PublicKey) {\n+func createRS256JWT(t *testing.T, email string, aud string) (string, rsa.PublicKey) {\n \tt.Helper()\n-\ttoken := createAuthToken(t, aud)\n+\ttoken := createAuthToken(t, email, aud)\n \tprivateKey, err := rsa.GenerateKey(rand.Reader, 2048)\n \tif err != nil {\n \t\tt.Fatalf(\"unable to generate key: %v\", err)",
        "comments": [],
        "commit_messages": [
            "Updated claim verification with a working example."
        ],
        "last_commit_sha": "eb8fe22b538e92bfcdd3306e83f34e1c6cf5570f"
    },
    {
        "pr_title": "fix(spanner): fix conflicting restore db operations",
        "pr_number": 2050,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -361,8 +361,10 @@\nfunc TestSample(t *testing.T) {\n }\n \n func TestBackupSample(t *testing.T) {\n-\t_ = testutil.EndToEndTest(t)\n-\n+\tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n+\t\tt.Skip(\"GOLANG_SAMPLES_E2E_TEST not set\")\n+\t}\n+\t_ = testutil.SystemTest(t)\n \tid := randomID()\n \tdbName, cleanup := initTest(t, id)\n \tdefer cleanup()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "73b9f759c90ff9c48b2099bc3a073b68d1e3ff7a"
    },
    {
        "pr_title": "test(storage): unflake TestGetKey",
        "pr_number": 2041,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -44,7 +44,7 @@\nfunc TestMain(m *testing.M) {\n \n func TestListKeys(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tkey, err := createTestKey(tc.ProjectID)\n+\tkey, err := createTestKey(tc.ProjectID, t)\n \tdefer deleteTestKey(key)\n \tif err != nil {\n \t\tt.Fatalf(\"Error in key creation: %s\", err)",
        "comments": [],
        "commit_messages": [
            "test(storage): unflake testgetkey"
        ],
        "last_commit_sha": "5ecfc74393d7deb3706c4b5149f11047c167fe09"
    },
    {
        "pr_title": "test(storage): unflake TestGetKey",
        "pr_number": 2041,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -79,7 +79,7 @@\nfunc TestCreateKey(t *testing.T) {\n \n func TestActivateKey(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tkey, err := createTestKey(tc.ProjectID)\n+\tkey, err := createTestKey(tc.ProjectID, t)\n \tdefer deleteTestKey(key)\n \tif err != nil {\n \t\tt.Errorf(\"Error in key creation: %s\", err)",
        "comments": [],
        "commit_messages": [
            "test(storage): unflake testgetkey"
        ],
        "last_commit_sha": "5ecfc74393d7deb3706c4b5149f11047c167fe09"
    },
    {
        "pr_title": "test(storage): unflake TestGetKey",
        "pr_number": 2041,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -102,7 +102,7 @@\nfunc TestActivateKey(t *testing.T) {\n \n func TestDeactivateKey(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tkey, err := createTestKey(tc.ProjectID)\n+\tkey, err := createTestKey(tc.ProjectID, t)\n \tdefer deleteTestKey(key)\n \tif err != nil {\n \t\tt.Errorf(\"Error in key creation: %s\", err)",
        "comments": [],
        "commit_messages": [
            "test(storage): unflake testgetkey"
        ],
        "last_commit_sha": "5ecfc74393d7deb3706c4b5149f11047c167fe09"
    },
    {
        "pr_title": "test(storage): unflake TestGetKey",
        "pr_number": 2041,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -119,7 +119,7 @@\nfunc TestDeactivateKey(t *testing.T) {\n \n func TestGetKey(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tkey, err := createTestKey(tc.ProjectID)\n+\tkey, err := createTestKey(tc.ProjectID, t)\n \tdefer deleteTestKey(key)\n \tif err != nil {\n \t\tt.Errorf(\"Error in key creation: %s\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5ecfc74393d7deb3706c4b5149f11047c167fe09"
    },
    {
        "pr_title": "test(storage): unflake TestGetKey",
        "pr_number": 2041,
        "file_name": "storage/service_account/hmac/hmac_test.go",
        "code_diff": "@@ -139,7 +139,7 @@\nfunc TestGetKey(t *testing.T) {\n \n func TestDeleteKey(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tkey, err := createTestKey(tc.ProjectID)\n+\tkey, err := createTestKey(tc.ProjectID, t)\n \tdefer deleteTestKey(key)\n \tif err != nil {\n \t\tt.Errorf(\"Error in key creation: %s\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5ecfc74393d7deb3706c4b5149f11047c167fe09"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "dataproc/dataproc_test.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \n \tdataproc \"cloud.google.com/go/dataproc/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n \t\"google.golang.org/api/option\"\n \tdataprocpb \"google.golang.org/genproto/googleapis/cloud/dataproc/v1\"\n )",
        "comments": [],
        "commit_messages": [
            "Add UUID to resource names and retries to workflow sample"
        ],
        "last_commit_sha": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "dataproc/instantiate_inline_workflow_template_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_messages": [
            "Add UUID to resource names and retries to workflow sample"
        ],
        "last_commit_sha": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(dataproc): increase retry count and delay for workflow templates, add UUID to resource names",
        "pr_number": 2034,
        "file_name": "dataproc/quickstart/quickstart_test.go",
        "code_diff": "@@ -25,6 +25,7 @@\nimport (\n \tdataproc \"cloud.google.com/go/dataproc/apiv1\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n \t\"google.golang.org/api/iterator\"\n \t\"google.golang.org/api/option\"\n \tdataprocpb \"google.golang.org/genproto/googleapis/cloud/dataproc/v1\"",
        "comments": [],
        "commit_messages": [
            "Add UUID to resource names and retries to workflow sample"
        ],
        "last_commit_sha": "1685e4b8f05d8f3937e077e24771b65ee8817313"
    },
    {
        "pr_title": "fix(pubsublite): improved publish error handling",
        "pr_number": 2008,
        "file_name": "pubsublite/quickstart_publisher/main.go",
        "code_diff": "@@ -21,9 +21,11 @@\nimport (\n \t\"flag\"\n \t\"fmt\"\n \t\"log\"\n+\t\"sync\"\n \n \t\"cloud.google.com/go/pubsub\"\n \t\"cloud.google.com/go/pubsublite/pscompat\"\n+\t\"golang.org/x/sync/errgroup\"\n )\n \n func main() {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "19c72eaad6256600e3894d60a794c4c7c2708d3b"
    },
    {
        "pr_title": "feat: add samples for CMEK with Spanner",
        "pr_number": 2001,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -26,15 +26,18 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \tinstance \"cloud.google.com/go/spanner/admin/instance/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n \t\"google.golang.org/api/iterator\"\n+\tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n \tinstancepb \"google.golang.org/genproto/googleapis/spanner/admin/instance/v1\"\n \t\"google.golang.org/grpc/codes\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n type sampleFunc func(w io.Writer, dbName string) error",
        "comments": [],
        "commit_messages": [
            "fix: create key before database"
        ],
        "last_commit_sha": "7d31c309c2d7ec0c41b8373726b65016391a550e"
    },
    {
        "pr_title": "feat: add samples for CMEK with Spanner",
        "pr_number": 2001,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -412,6 +415,108 @@\nfunc TestCreateDatabaseWithRetentionPeriodSample(t *testing.T) {\n \tassertContains(t, out, fmt.Sprintf(\"Created database [%s] with version retention period %q\", dbName, wantRetentionPeriod))\n }\n \n+func TestCustomerManagedEncryptionKeys(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tdbName, cleanup := initTest(t, randomID())\n+\tdefer cleanup()\n+\tadminClient, err := database.NewDatabaseAdminClient(context.Background())\n+\tif err != nil {\n+\t\tt.Errorf(\"failed to create admin client: %v\", err)\n+\t}\n+\n+\tvar b bytes.Buffer\n+\n+\tinstanceName := getInstance(t)\n+\tlocationId := \"us-central1\"\n+\tkeyRingId := \"spanner-test-keyring\"\n+\tkeyId := \"spanner-test-key\"\n+\n+\t// Create an encryption key if it does not already exist.\n+\tif err := maybeCreateKey(tc.ProjectID, locationId, keyRingId, keyId); err != nil {\n+\t\tt.Errorf(\"failed to create encryption key: %v\", err)\n+\t}\n+\tkmsKeyName := fmt.Sprintf(\n+\t\t\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\",\n+\t\ttc.ProjectID,\n+\t\tlocationId,\n+\t\tkeyRingId,\n+\t\tkeyId,\n+\t)\n+\n+\t// Create an encrypted database. The database is automatically deleted by the cleanup function.\n+\tif err := createDatabaseWithCustomerManagedEncryptionKey(&b, dbName, kmsKeyName); err != nil {\n+\t\tt.Errorf(\"failed to create database with customer managed encryption key: %v\", err)\n+\t}\n+\tout := b.String()\n+\tassertContains(t, out, fmt.Sprintf(\"Created database [%s] using encryption key %q\", dbName, kmsKeyName))\n+\n+\t// Try to create a backup of the encrypted database and delete it after the test.\n+\tbackupId := fmt.Sprintf(\"enc-backup-%s\", randomID())\n+\tdefer func() {\n+\t\t_ = adminClient.DeleteBackup(context.Background(), &adminpb.DeleteBackupRequest{\n+\t\t\tName: fmt.Sprintf(\"%s/backups/%s\", instanceName, backupId),\n+\t\t})\n+\t}()\n+\tb.Reset()\n+\tif err := createBackupWithCustomerManagedEncryptionKey(&b, dbName, backupId, kmsKeyName); err != nil {\n+\t\tt.Errorf(\"failed to create backup with customer managed encryption key: %v\", err)\n+\t}\n+\tout = b.String()\n+\tassertContains(t, out, fmt.Sprintf(\"backups/%s\", backupId))\n+\tassertContains(t, out, fmt.Sprintf(\"using encryption key %s\", kmsKeyName))\n+\n+\t// Try to restore the encrypted database and delete the restored database after the test.\n+\trestoredName := fmt.Sprintf(\"%s/databases/rest-enc-%s\", instanceName, randomID())\n+\tdefer func() {\n+\t\t_ = adminClient.DropDatabase(context.Background(), &adminpb.DropDatabaseRequest{\n+\t\t\tDatabase: restoredName,\n+\t\t})\n+\t}()\n+\trestoreFunc := func(w io.Writer, dbName, backupID string) error {\n+\t\treturn restoreBackupWithCustomerManagedEncryptionKey(w, dbName, backupId, kmsKeyName)\n+\t}\n+\tout = runBackupSampleWithRetry(t, restoreFunc, restoredName, backupId, \"failed to restore database with customer managed encryption key\", 10)\n+\tassertContains(t, out, fmt.Sprintf(\"Database %s restored\", dbName))\n+\tassertContains(t, out, fmt.Sprintf(\"using encryption key %s\", kmsKeyName))\n+}\n+\n+func maybeCreateKey(projectId, locationId, keyRingId, keyId string) error {\n+\tclient, err := kms.NewKeyManagementClient(context.Background())\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Try to create a key ring\n+\tcreateKeyRingRequest := kmspb.CreateKeyRingRequest{\n+\t\tParent:    fmt.Sprintf(\"projects/%s/locations/%s\", projectId, locationId),\n+\t\tKeyRingId: keyRingId,\n+\t\tKeyRing:   &kmspb.KeyRing{},\n+\t}\n+\t_, err = client.CreateKeyRing(context.Background(), &createKeyRingRequest)\n+\tif err != nil {\n+\t\tif status, ok := status.FromError(err); !ok || status.Code() != codes.AlreadyExists {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\t// Try to create a key\n+\tcreateKeyRequest := kmspb.CreateCryptoKeyRequest{\n+\t\tParent:      fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s\", projectId, locationId, keyRingId),\n+\t\tCryptoKeyId: keyId,\n+\t\tCryptoKey: &kmspb.CryptoKey{\n+\t\t\tPurpose: kmspb.CryptoKey_ENCRYPT_DECRYPT,\n+\t\t},\n+\t}\n+\t_, err = client.CreateCryptoKey(context.Background(), &createKeyRequest)\n+\tif err != nil {\n+\t\tif status, ok := status.FromError(err); !ok || status.Code() != codes.AlreadyExists {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n func runSample(t *testing.T, f sampleFunc, dbName, errMsg string) string {\n \tvar b bytes.Buffer\n \tif err := f(&b, dbName); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7d31c309c2d7ec0c41b8373726b65016391a550e"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -39,6 +39,8 @@\nconst (\n \ttestVideoFileName        = \"ChromeCast.mp4\"\n \ttestOverlayImageFileName = \"overlay.jpg\"\n \tpreset                   = \"preset/web-hd\"\n+\tsmallSpriteSheetFileName = \"small-sprite-sheet0000000000.jpeg\"\n+\tlargeSpriteSheetFileName = \"large-sprite-sheet0000000000.jpeg\"\n )\n \n // To run the tests, do the following:",
        "comments": [],
        "commit_messages": [
            "feat: add spritesheet samples and tests"
        ],
        "last_commit_sha": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -63,6 +65,10 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \toutputURIForAdHoc := \"gs://\" + bucketName + \"/test-output-adhoc/\"\n \toutputURIForStaticOverlay := \"gs://\" + bucketName + \"/test-output-static-overlay/\"\n \toutputURIForAnimatedOverlay := \"gs://\" + bucketName + \"/test-output-animated-overlay/\"\n+\toutputDirForSetNumberSpritesheet := \"test-output-set-number-spritesheet/\"\n+\toutputURIForSetNumberSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForSetNumberSpritesheet\n+\toutputDirForPeriodicSpritesheet := \"test-output-periodic-spritesheet/\"\n+\toutputURIForPeriodicSpritesheet := \"gs://\" + bucketName + \"/\" + outputDirForPeriodicSpritesheet\n \n \t// Get the project number\n \tcloudresourcemanagerClient, err := cloudresourcemanager.NewService(ctx)",
        "comments": [],
        "commit_messages": [
            "feat: add spritesheet samples and tests"
        ],
        "last_commit_sha": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -89,6 +95,18 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tt.Logf(\"\\ntestJobWithStaticOverlay() completed\\n\")\n \ttestJobWithAnimatedOverlay(t, projectNumber, inputURI, inputOverlayImageURI, outputURIForAnimatedOverlay)\n \tt.Logf(\"\\ntestJobWithAnimatedOverlay() completed\\n\")\n+\n+\ttestJobWithSetNumberImagesSpritesheet(t, projectNumber, inputURI, outputURIForSetNumberSpritesheet)\n+\tt.Logf(\"\\ntestJobWithSetNumberImagesSpritesheet() completed\\n\")\n+\t// Check if the spritesheets exist.\n+\tcheckGCSFileExists(t, bucketName, outputDirForSetNumberSpritesheet+smallSpriteSheetFileName)\n+\tcheckGCSFileExists(t, bucketName, outputDirForSetNumberSpritesheet+largeSpriteSheetFileName)\n+\n+\ttestJobWithPeriodicImagesSpritesheet(t, projectNumber, inputURI, outputURIForPeriodicSpritesheet)\n+\tt.Logf(\"\\ntestJobWithPeriodicImagesSpritesheet() completed\\n\")\n+\t// Check if the spritesheets exist.\n+\tcheckGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+smallSpriteSheetFileName)\n+\tcheckGCSFileExists(t, bucketName, outputDirForPeriodicSpritesheet+largeSpriteSheetFileName)\n }\n \n // testJobTemplates tests major operations on job templates. Create, get,",
        "comments": [],
        "commit_messages": [
            "feat: add spritesheet samples and tests"
        ],
        "last_commit_sha": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat(media): add spritesheet samples and tests",
        "pr_number": 1998,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -180,6 +198,29 @@\nfunc writeTestGCSFile(t *testing.T, dstBucket string, srcBucket string, srcObjec\n \t}\n }\n \n+func checkGCSFileExists(t *testing.T, bucketName string, fileName string) {\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n+\n+\tobjAttrs, err := client.Bucket(bucketName).Object(fileName).Attrs(ctx)\n+\tif err == nil && objAttrs != nil {\n+\t\treturn\n+\t}\n+\tif err == storage.ErrObjectNotExist {\n+\t\tt.Fatalf(\"Spritesheet %q does not exist in bucket %q: %v\", fileName, bucketName, err)\n+\t}\n+\tif err != nil {\n+\t\tt.Fatalf(\"Error getting bucket attrs: %v\", err)\n+\t}\n+}\n+\n // testJobFromPreset tests major operations on a job created from a preset. It\n // will wait until the job successfully completes as part of the test.\n func testJobFromPreset(t *testing.T, projectNumber string, inputURI string, outputURIForPreset string) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1f4415386432677e6d7063c24e3f9719994c6ea0"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -18,8 +18,6 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n-\t\"io\"\n-\t\"os\"\n \t\"strconv\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "Remove local test files"
        ],
        "last_commit_sha": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -31,14 +29,16 @@\nimport (\n )\n \n const (\n-\tlocation              = \"us-central1\"\n-\ttemplateID            = \"my-go-test-template\"\n-\tdeleteTemplateReponse = \"Deleted job template\"\n-\tdeleteJobReponse      = \"Deleted job\"\n-\tjobSucceededState     = \"SUCCEEDED\"\n-\ttestVideoFileName     = \"ChromeCast.mp4\"\n-\ttestVideoFileLocation = \"../testdata/\"\n-\tpreset                = \"preset/web-hd\"\n+\tlocation                 = \"us-central1\"\n+\ttemplateID               = \"my-go-test-template\"\n+\tdeleteTemplateReponse    = \"Deleted job template\"\n+\tdeleteJobReponse         = \"Deleted job\"\n+\tjobSucceededState        = \"SUCCEEDED\"\n+\ttestBucketName           = \"cloud-samples-data\"\n+\ttestBucketDirName        = \"media/\"\n+\ttestVideoFileName        = \"ChromeCast.mp4\"\n+\ttestOverlayImageFileName = \"overlay.jpg\"\n+\tpreset                   = \"preset/web-hd\"\n )\n \n // To run the tests, do the following:",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -56,10 +56,13 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \tctx := context.Background()\n \n \tbucketName := tc.ProjectID + \"-golang-samples-transcoder-test\"\n-\tinputURI := \"gs://\" + bucketName + \"/\" + testVideoFileName\n+\tinputURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testVideoFileName\n+\tinputOverlayImageURI := \"gs://\" + bucketName + \"/\" + testBucketDirName + testOverlayImageFileName\n \toutputURIForPreset := \"gs://\" + bucketName + \"/test-output-preset/\"\n \toutputURIForTemplate := \"gs://\" + bucketName + \"/test-output-template/\"\n \toutputURIForAdHoc := \"gs://\" + bucketName + \"/test-output-adhoc/\"\n+\toutputURIForStaticOverlay := \"gs://\" + bucketName + \"/test-output-static-overlay/\"\n+\toutputURIForAnimatedOverlay := \"gs://\" + bucketName + \"/test-output-animated-overlay/\"\n \n \t// Get the project number\n \tcloudresourcemanagerClient, err := cloudresourcemanager.NewService(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -74,14 +77,18 @@\nfunc TestJobTemplatesAndJobs(t *testing.T) {\n \n \ttestJobTemplates(t, projectNumber)\n \tt.Logf(\"\\ntestJobTemplates() completed\\n\")\n-\twriteTestGCSFile(t, tc.ProjectID, bucketName)\n-\tt.Logf(\"\\nwriteTestGCSFile() completed\\n\")\n+\twriteTestGCSFiles(t, tc.ProjectID, bucketName)\n+\tt.Logf(\"\\nwriteTestGCSFiles() completed\\n\")\n \ttestJobFromPreset(t, projectNumber, inputURI, outputURIForPreset)\n \tt.Logf(\"\\ntestJobFromPreset() completed\\n\")\n \ttestJobFromTemplate(t, projectNumber, inputURI, outputURIForTemplate)\n \tt.Logf(\"\\ntestJobFromTemplate() completed\\n\")\n \ttestJobFromAdHoc(t, projectNumber, inputURI, outputURIForAdHoc)\n \tt.Logf(\"\\ntestJobFromAdHoc() completed\\n\")\n+\ttestJobWithStaticOverlay(t, projectNumber, inputURI, inputOverlayImageURI, outputURIForStaticOverlay)\n+\tt.Logf(\"\\ntestJobWithStaticOverlay() completed\\n\")\n+\ttestJobWithAnimatedOverlay(t, projectNumber, inputURI, inputOverlayImageURI, outputURIForAnimatedOverlay)\n+\tt.Logf(\"\\ntestJobWithAnimatedOverlay() completed\\n\")\n }\n \n // testJobTemplates tests major operations on job templates. Create, get,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "feat: add code samples and tests for overlay creation",
        "pr_number": 1988,
        "file_name": "media/transcoder/transcoder_test.go",
        "code_diff": "@@ -144,35 +151,32 @@\nfunc testJobTemplates(t *testing.T, projectNumber string) {\n \t})\n }\n \n-// writeTestGCSFile deletes the GCS test bucket and uploads a test video file to it.\n-func writeTestGCSFile(t *testing.T, projectID string, bucketName string) {\n+func writeTestGCSFiles(t *testing.T, projectID string, bucketName string) {\n \tt.Helper()\n+\tctx := context.Background()\n+\ttestutil.CleanBucket(ctx, t, projectID, bucketName)\n+\twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testVideoFileName)\n+\twriteTestGCSFile(t, bucketName, testBucketName, testBucketDirName+testOverlayImageFileName)\n+}\n+\n+// writeTestGCSFile deletes the GCS test bucket and uploads a test video file to it.\n+func writeTestGCSFile(t *testing.T, dstBucket string, srcBucket string, srcObject string) {\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n \tdefer client.Close()\n \n-\ttestutil.CleanBucket(ctx, t, projectID, bucketName)\n-\n-\t// Open local test file.\n-\tf, err := os.Open(testVideoFileLocation + testVideoFileName)\n-\tif err != nil {\n-\t\tt.Fatalf(\"os.Open: %v\", err)\n-\t}\n-\tdefer f.Close()\n-\n-\tctx, cancel := context.WithTimeout(ctx, time.Second*120)\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \n-\t// Upload an object with storage.Writer.\n-\twc := client.Bucket(bucketName).Object(testVideoFileName).NewWriter(ctx)\n-\tif _, err = io.Copy(wc, f); err != nil {\n-\t\tt.Fatalf(\"io.Copy: %v\", err)\n-\t}\n-\tif err := wc.Close(); err != nil {\n-\t\tt.Fatalf(\"Writer.Close: %v\", err)\n+\tdstObject := srcObject\n+\tsrc := client.Bucket(srcBucket).Object(srcObject)\n+\tdst := client.Bucket(dstBucket).Object(dstObject)\n+\n+\tif _, err := dst.CopierFrom(src).Run(ctx); err != nil {\n+\t\tt.Fatalf(\"Object(%q).CopierFrom(%q).Run: %v\", dstObject, srcObject, err)\n \t}\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cfb4d529dd24dfa8774a731e10be489ad084315c"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -40,6 +40,7 @@\nimport (\n type sampleFunc func(w io.Writer, dbName string) error\n type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(w io.Writer, dbName, backupID string) error\n+type createBackupSampleFunc func(w io.Writer, dbName, backupID string, versionTime time.Time) error\n \n var (\n \tvalidInstancePattern = regexp.MustCompile(\"^projects/(?P<project>[^/]+)/instances/(?P<instance>[^/]+)$\")",
        "comments": [],
        "commit_messages": [
            "samples: parameterise version time in backup"
        ],
        "last_commit_sha": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -74,6 +75,30 @@\nfunc initTest(t *testing.T, id string) (dbName string, cleanup func()) {\n \treturn\n }\n \n+func getVersionTime(t *testing.T, dbName string) (versionTime time.Time) {\n+\tctx := context.Background()\n+\tclient, err := spanner.NewClient(ctx, dbName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to create client: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT CURRENT_TIMESTAMP()`,\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\trow, err := iter.Next()\n+\tif err != nil {\n+\t\tt.Fatalf(\"failed to get current time: %v\", err)\n+\t}\n+\tif err := row.Columns(&versionTime); err != nil {\n+\t\tt.Fatalf(\"failed to get version time: %v\", err)\n+\t}\n+\n+\treturn versionTime\n+}\n+\n func initBackupTest(t *testing.T, id, dbName string) (restoreDBName, backupID, cancelledBackupID string, cleanup func()) {\n \tinstance := getInstance(t)\n \trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", id), t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -346,7 +371,8 @@\nfunc TestBackupSample(t *testing.T) {\n \trunSample(t, write, dbName, \"failed to insert data\")\n \n \t// Start testing backup operations.\n-\tout = runBackupSample(t, createBackup, dbName, backupID, \"failed to create a backup\")\n+\tversionTime := getVersionTime(t, dbName)\n+\tout = runCreateBackupSample(t, createBackup, dbName, backupID, versionTime, \"failed to create a backup\")\n \tassertContains(t, out, fmt.Sprintf(\"backups/%s\", backupID))\n \n \tout = runBackupSample(t, cancelBackup, dbName, cancelledBackupID, \"failed to cancel a backup\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "spanner/spanner_snippets/spanner/spanner_create_backup.go",
        "code_diff": "@@ -28,7 +28,8 @@\nimport (\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n-func createBackup(w io.Writer, db, backupID string) error {\n+func createBackup(w io.Writer, db, backupID string, versionTime time.Time) error {\n+\t// versionTime := time.Now().AddDate(0, 0, -1) // one day ago\n \tmatches := regexp.MustCompile(\"^(.+)/databases/(.+)$\").FindStringSubmatch(db)\n \tif matches == nil || len(matches) != 3 {\n \t\treturn fmt.Errorf(\"createBackup: invalid database id %q\", db)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "spanner/spanner_snippets/spanner/spanner_create_backup.go",
        "code_diff": "@@ -40,10 +41,6 @@\nfunc createBackup(w io.Writer, db, backupID string) error {\n \t\treturn fmt.Errorf(\"createBackup.NewDatabaseAdminClient: %v\", err)\n \t}\n \tdefer adminClient.Close()\n-\tdbMetadata, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: db})\n-\tif err != nil {\n-\t\treturn fmt.Errorf(\"createBackup.GetDatabase: %v\", err)\n-\t}\n \n \texpireTime := time.Now().AddDate(0, 0, 14)\n \t// Create a backup.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "samples(spanner): PITR samples backup fix",
        "pr_number": 1970,
        "file_name": "spanner/spanner_snippets/spanner/spanner_create_backup.go",
        "code_diff": "@@ -53,7 +50,7 @@\nfunc createBackup(w io.Writer, db, backupID string) error {\n \t\tBackup: &adminpb.Backup{\n \t\t\tDatabase:    db,\n \t\t\tExpireTime:  &pbt.Timestamp{Seconds: expireTime.Unix(), Nanos: int32(expireTime.Nanosecond())},\n-\t\t\tVersionTime: dbMetadata.EarliestVersionTime,\n+\t\t\tVersionTime: &pbt.Timestamp{Seconds: versionTime.Unix(), Nanos: int32(versionTime.Nanosecond())},\n \t\t},\n \t}\n \top, err := adminClient.CreateBackup(ctx, &req)",
        "comments": [],
        "commit_messages": [
            "samples: creates a backup using the current time\n\nInstead of using the earliest version time of the database, uses the\ncurrent time (from spanner). If we used the earliest version time of the\ndatabase instead we would be creating an empty backup, since the\ndatabase we are backing up is not 1 hour old (default version retention\nperiod)."
        ],
        "last_commit_sha": "c3045182a265c4ebd8e7235855e00610031730d2"
    },
    {
        "pr_title": "test: added kokoro integration for cloud sql e2e test",
        "pr_number": 1967,
        "file_name": "cloudsql/mysql/database-sql/cloudsql_test.go",
        "code_diff": "@@ -22,20 +22,50 @@\nimport (\n \t\"testing\"\n )\n \n+type testInfo struct {\n+\tdbName                 string\n+\tdbPass                 string\n+\tdbUser                 string\n+\tdbPort                 string\n+\tinstanceConnectionName string\n+}\n+\n func TestIndex(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"MYSQL_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"MYSQL_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"MYSQL_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"MYSQL_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"MYSQL_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"MYSQL_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5743fc6fd6d2c98c099704c8d27c20b7386513ae"
    },
    {
        "pr_title": "test: added kokoro integration for cloud sql e2e test",
        "pr_number": 1967,
        "file_name": "cloudsql/mysql/database-sql/cloudsql_test.go",
        "code_diff": "@@ -54,22 +84,52 @@\nfunc TestIndex(t *testing.T) {\n \t\t}\n \t\tos.Setenv(\"DB_HOST\", oldDBHost)\n \t}\n+\t// Restore original values\n+\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\tos.Setenv(\"DB_NAME\", oldDBName)\n+\tos.Setenv(\"DB_PASS\", oldDBPass)\n+\tos.Setenv(\"DB_PORT\", oldDBPort)\n+\tos.Setenv(\"DB_USER\", oldDBUser)\n+\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", oldInstance)\n }\n \n func TestCastVote(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"MYSQL_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"MYSQL_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"MYSQL_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"MYSQL_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"MYSQL_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"MYSQL_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5743fc6fd6d2c98c099704c8d27c20b7386513ae"
    },
    {
        "pr_title": "test: added kokoro integration for cloud sql e2e test",
        "pr_number": 1967,
        "file_name": "cloudsql/postgres/database-sql/cloudsql_test.go",
        "code_diff": "@@ -22,20 +22,51 @@\nimport (\n \t\"testing\"\n )\n \n+type testInfo struct {\n+\tdbName                 string\n+\tdbPass                 string\n+\tdbUser                 string\n+\tdbPort                 string\n+\tinstanceConnectionName string\n+}\n+\n func TestIndex(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"POSTGRES_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"POSTGRES_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"POSTGRES_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"POSTGRES_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"POSTGRES_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"POSTGRES_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5743fc6fd6d2c98c099704c8d27c20b7386513ae"
    },
    {
        "pr_title": "test: added kokoro integration for cloud sql e2e test",
        "pr_number": 1967,
        "file_name": "cloudsql/postgres/database-sql/cloudsql_test.go",
        "code_diff": "@@ -52,24 +83,54 @@\nfunc TestIndex(t *testing.T) {\n \t\tif !strings.Contains(body, want) {\n \t\t\tt.Errorf(\"With dbHost='%s', expected to see '%s' in indexHandler response body\", test.dbHost, want)\n \t\t}\n-\t\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\n \t}\n+\t// Restore original values\n+\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\tos.Setenv(\"DB_NAME\", oldDBName)\n+\tos.Setenv(\"DB_PASS\", oldDBPass)\n+\tos.Setenv(\"DB_PORT\", oldDBPort)\n+\tos.Setenv(\"DB_USER\", oldDBUser)\n+\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", oldInstance)\n }\n \n func TestCastVote(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"POSTGRES_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"POSTGRES_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"POSTGRES_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"POSTGRES_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"POSTGRES_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n \t\t{dbHost: \"\"},\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"POSTGRES_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5743fc6fd6d2c98c099704c8d27c20b7386513ae"
    },
    {
        "pr_title": "test: added kokoro integration for cloud sql e2e test",
        "pr_number": 1967,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql_test.go",
        "code_diff": "@@ -22,19 +22,49 @@\nimport (\n \t\"testing\"\n )\n \n+type testInfo struct {\n+\tdbName                 string\n+\tdbPass                 string\n+\tdbUser                 string\n+\tdbPort                 string\n+\tinstanceConnectionName string\n+}\n+\n func TestIndex(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"SQLSERVER_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"SQLSERVER_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"SQLSERVER_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"SQLSERVER_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"SQLSERVER_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"SQLSERVER_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [
            {
                "comment": "In general, mutuating environment variables in tests makes it _really_ difficult to parallelize tests and leads to flakes. What is the value in calling `Setenv` here? What problem are we trying to solve?",
                "position": 43
            },
            {
                "comment": "These are integration tests, so we're trying to run the code in for-real mode to make real connections to the database, and that code reads environment variables.",
                "position": 43
            },
            {
                "comment": "As per our offline conversation, these environment variable mutations will land for now, as e2e tests are run less frequently. We'll rethink the issue if problems surface.",
                "position": 43
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "5743fc6fd6d2c98c099704c8d27c20b7386513ae"
    },
    {
        "pr_title": "test: added kokoro integration for cloud sql e2e test",
        "pr_number": 1967,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql_test.go",
        "code_diff": "@@ -53,21 +83,50 @@\nfunc TestIndex(t *testing.T) {\n \t\t}\n \t\tos.Setenv(\"DB_HOST\", oldDBHost)\n \t}\n+\t// Restore original values\n+\tos.Setenv(\"DB_HOST\", oldDBHost)\n+\tos.Setenv(\"DB_NAME\", oldDBName)\n+\tos.Setenv(\"DB_PASS\", oldDBPass)\n+\tos.Setenv(\"DB_PORT\", oldDBPort)\n+\tos.Setenv(\"DB_USER\", oldDBUser)\n+\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", oldInstance)\n }\n \n func TestCastVote(t *testing.T) {\n \tif os.Getenv(\"GOLANG_SAMPLES_E2E_TEST\") == \"\" {\n \t\tt.Skip()\n \t}\n+\n+\tinfo := testInfo{\n+\t\tdbName:                 os.Getenv(\"SQLSERVER_DATABASE\"),\n+\t\tdbPass:                 os.Getenv(\"SQLSERVER_PASSWORD\"),\n+\t\tdbPort:                 os.Getenv(\"SQLSERVER_PORT\"),\n+\t\tdbUser:                 os.Getenv(\"SQLSERVER_USER\"),\n+\t\tinstanceConnectionName: os.Getenv(\"SQLSERVER_INSTANCE\"),\n+\t}\n+\n \ttests := []struct {\n \t\tdbHost string\n \t}{\n-\t\t{dbHost: os.Getenv(\"DB_HOST\")},\n+\t\t{dbHost: os.Getenv(\"SQLSERVER_HOST\")},\n \t}\n \n+\t// Capture original values\n+\toldDBHost := os.Getenv(\"DB_HOST\")\n+\toldDBName := os.Getenv(\"DB_NAME\")\n+\toldDBPass := os.Getenv(\"DB_PASS\")\n+\toldDBPort := os.Getenv(\"DB_PORT\")\n+\toldDBUser := os.Getenv(\"DB_USER\")\n+\toldInstance := os.Getenv(\"INSTANCE_CONNECTION_NAME\")\n+\n \tfor _, test := range tests {\n-\t\toldDBHost := os.Getenv(\"DB_HOST\")\n+\t\t// Set overwrites\n \t\tos.Setenv(\"DB_HOST\", test.dbHost)\n+\t\tos.Setenv(\"DB_NAME\", info.dbName)\n+\t\tos.Setenv(\"DB_PASS\", info.dbPass)\n+\t\tos.Setenv(\"DB_PORT\", info.dbPort)\n+\t\tos.Setenv(\"DB_USER\", info.dbUser)\n+\t\tos.Setenv(\"INSTANCE_CONNECTION_NAME\", info.instanceConnectionName)\n \n \t\tapp := newApp()\n \t\trr := httptest.NewRecorder()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "5743fc6fd6d2c98c099704c8d27c20b7386513ae"
    },
    {
        "pr_title": "fix: update eventarc storage name",
        "pr_number": 1958,
        "file_name": "eventarc/audit_storage/main.go",
        "code_diff": "@@ -14,7 +14,7 @@\n// [START eventarc_gcs_handler]\n \n-// Sample audit_storage is a Cloud Run service which handles Cloud Audit Log messages with Cloud Storage data.\n+// Sample audit_storage is a Cloud Run service which handles Cloud Audit Log events with Cloud Storage data.\n package main\n \n import (",
        "comments": [],
        "commit_messages": [
            "fix: update eventarc storage name\n\nSigned-off-by: Grant Timmerman <timmerman+devrel@google.com>"
        ],
        "last_commit_sha": "2b6df0c74af110088f3289fef92d2c69502ed504"
    },
    {
        "pr_title": "testing(run): increase retry delay for builds to reduce flakiness",
        "pr_number": 1947,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -33,6 +33,15 @@\nimport (\n \t\"time\"\n )\n \n+// labels are used in operation-related logs.\n+const (\n+\tlabelOperationDeploy        = \"deploy service\"\n+\tlabelOperationBuild         = \"build container image\"\n+\tlabelOperationDeleteService = \"delete service\"\n+\tlabelOperationDeleteImage   = \"delete container image\"\n+\tlabelOperationGetURL        = \"get url\"\n+)\n+\n // Service describes a Cloud Run service\n type Service struct {\n \t// Name is an ID, used for logging and to generate a unique version to this run.",
        "comments": [],
        "commit_messages": [
            "use labels for constants"
        ],
        "last_commit_sha": "6fbfabf219ab5642db787765a29059ad087c9f23"
    },
    {
        "pr_title": "testing(run): increase retry delay for builds to reduce flakiness",
        "pr_number": 1947,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -143,7 +152,7 @@\nfunc (s *Service) ParsedURL() (*url.URL, error) {\n \t\treturn nil, errors.New(\"URL called before Deploy\")\n \t}\n \tif s.url == nil {\n-\t\tout, err := gcloud(s.operationLabel(\"get url\"), s.urlCmd())\n+\t\tout, err := gcloud(s.operationLabel(labelOperationGetURL), s.urlCmd())\n \t\tif err != nil {\n \t\t\treturn nil, fmt.Errorf(\"gcloud: %s: %q\", s.Name, err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "use labels for constants"
        ],
        "last_commit_sha": "6fbfabf219ab5642db787765a29059ad087c9f23"
    },
    {
        "pr_title": "testing(run): increase retry delay for builds to reduce flakiness",
        "pr_number": 1947,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -199,7 +208,7 @@\nfunc (s *Service) Deploy() error {\n \t\t}\n \t}\n \n-\tif _, err := gcloud(s.operationLabel(\"deploy service\"), s.deployCmd()); err != nil {\n+\tif _, err := gcloud(s.operationLabel(labelOperationDeploy), s.deployCmd()); err != nil {\n \t\treturn fmt.Errorf(\"gcloud: %s: %q\", s.version(), err)\n \t}",
        "comments": [],
        "commit_messages": [
            "use labels for constants"
        ],
        "last_commit_sha": "6fbfabf219ab5642db787765a29059ad087c9f23"
    },
    {
        "pr_title": "testing(run): increase retry delay for builds to reduce flakiness",
        "pr_number": 1947,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -223,7 +232,7 @@\nfunc (s *Service) Build() error {\n \t\ts.Image = fmt.Sprintf(\"gcr.io/%s/%s:%s\", s.ProjectID, s.Name, runID)\n \t}\n \n-\tif out, err := gcloud(s.operationLabel(\"build container image\"), s.buildCmd()); err != nil {\n+\tif out, err := gcloud(s.operationLabel(labelOperationBuild), s.buildCmd()); err != nil {\n \t\tfmt.Printf(string(out))\n \t\treturn fmt.Errorf(\"gcloud: %s: %q\", s.Image, err)\n \t}",
        "comments": [],
        "commit_messages": [
            "use labels for constants"
        ],
        "last_commit_sha": "6fbfabf219ab5642db787765a29059ad087c9f23"
    },
    {
        "pr_title": "test(spanner): unflake backup sample tests",
        "pr_number": 1932,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -26,13 +26,15 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \tinstance \"cloud.google.com/go/spanner/admin/instance/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n \t\"google.golang.org/api/iterator\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n \tinstancepb \"google.golang.org/genproto/googleapis/spanner/admin/instance/v1\"\n+\t\"google.golang.org/grpc/codes\"\n )\n \n type sampleFunc func(w io.Writer, dbName string) error",
        "comments": [
            {
                "comment": "Might want to call `b.Reset` at the start of every retry attempt.",
                "position": 33
            },
            {
                "comment": "Good point, done.",
                "position": 33
            }
        ],
        "commit_messages": [
            "fix: use testutil.Retry"
        ],
        "last_commit_sha": "dd8f5b9015442e90ab7491faea5410bc246ce56b"
    },
    {
        "pr_title": "test(spanner): unflake backup sample tests",
        "pr_number": 1932,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -356,7 +358,7 @@\nfunc TestBackupSample(t *testing.T) {\n \tout = runBackupSample(t, updateBackup, dbName, backupID, \"failed to update a backup\")\n \tassertContains(t, out, fmt.Sprintf(\"Updated backup %s\", backupID))\n \n-\tout = runBackupSample(t, restoreBackup, restoreDBName, backupID, \"failed to restore a backup\")\n+\tout = runBackupSampleWithRetry(t, restoreBackup, restoreDBName, backupID, \"failed to restore a backup\", 10)\n \tassertContains(t, out, fmt.Sprintf(\"Source database %s restored from backup\", dbName))\n \n \t// This sample should run after a restore operation.",
        "comments": [],
        "commit_messages": [
            "fix: use testutil.Retry"
        ],
        "last_commit_sha": "dd8f5b9015442e90ab7491faea5410bc246ce56b"
    },
    {
        "pr_title": "test(run): increase gcloud retry attempts from 3 to 5",
        "pr_number": 1911,
        "file_name": "internal/cloudrunci/gcloud.go",
        "code_diff": "@@ -37,12 +37,13 @@\nfunc init() {\n }\n \n // gcloud provides a common mechanism for executing gcloud commands.\n-// It will attempt to retry failed commands 3 times with 2 second wait intervals.\n+// It will attempt to retry failed commands. Use gcloudWithoutRetry() for no retry.\n func gcloud(label string, cmd *exec.Cmd) ([]byte, error) {\n \tvar out []byte\n \tvar err error\n \n-\tsuccess := testutil.RetryWithoutTest(3, 2*time.Second, func(r *testutil.R) {\n+\tmaxAttempts := 5\n+\tsuccess := testutil.RetryWithoutTest(maxAttempts, 2*time.Second, func(r *testutil.R) {\n \t\tout, err = gcloudExec(fmt.Sprintf(\"Attempt #%d: \", r.Attempt), label, cmd)\n \t\tif err != nil {\n \t\t\tlog.Printf(\"gcloudExec: %v\", err)",
        "comments": [],
        "commit_messages": [
            "cloudrunci: increase gcloud retry attempts from 3 to 5"
        ],
        "last_commit_sha": "40a9ab48717583ac28ca35bb303b4b762359cb8d"
    },
    {
        "pr_title": "feat(run): Add sigterm handler sample",
        "pr_number": 1902,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -24,13 +24,18 @@\npackage cloudrunci\n \n import (\n+\t\"context\"\n \t\"errors\"\n \t\"fmt\"\n \t\"net/http\"\n \t\"net/url\"\n \t\"os/exec\"\n \t\"path\"\n+\t\"strings\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/logging/logadmin\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n // labels are used in operation-related logs.",
        "comments": [],
        "commit_messages": [
            "Update testing"
        ],
        "last_commit_sha": "f1c6a3d5267c1fe96415ce980991ad36f7ad1cfa"
    },
    {
        "pr_title": "feat: add h2c sample for Cloud Run",
        "pr_number": 1887,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -57,6 +57,12 @@\ntype Service struct {\n \t// Additional runtime environment variable overrides for the app.\n \tEnv EnvVars\n \n+\t// Build the image without Dockerfile, using Google Cloud buildpacks.\n+\tAsBuildpack bool\n+\n+\t// Strictly HTTP/2 serving\n+\tHTTP2 bool\n+\n \tdeployed bool     // Whether the service has been deployed.\n \tbuilt    bool     // Whether the container image has been built.\n \turl      *url.URL // The url of the deployed service.",
        "comments": [],
        "commit_messages": [
            "add system tests\n\nSigned-off-by: Ahmet Alp Balkan <ahmetb@google.com>"
        ],
        "last_commit_sha": "165ad02c9ec0cfd5947af2b0f6f2499db4d4a02c"
    },
    {
        "pr_title": "feat: add h2c sample for Cloud Run",
        "pr_number": 1887,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -259,6 +265,7 @@\nfunc (s *Service) operationLabel(op string) string {\n func (s *Service) deployCmd() *exec.Cmd {\n \targs := append([]string{\n \t\t\"--quiet\",\n+\t\t\"alpha\", // TODO until --use-http2 goes GA\n \t\t\"run\",\n \t\t\"deploy\",\n \t\ts.version(),",
        "comments": [],
        "commit_messages": [
            "add system tests\n\nSigned-off-by: Ahmet Alp Balkan <ahmetb@google.com>"
        ],
        "last_commit_sha": "165ad02c9ec0cfd5947af2b0f6f2499db4d4a02c"
    },
    {
        "pr_title": "feat: add h2c sample for Cloud Run",
        "pr_number": 1887,
        "file_name": "internal/cloudrunci/cloudrunci.go",
        "code_diff": "@@ -276,6 +283,9 @@\nfunc (s *Service) deployCmd() *exec.Cmd {\n \tif s.AllowUnauthenticated {\n \t\targs = append(args, \"--allow-unauthenticated\")\n \t}\n+\tif s.HTTP2 {\n+\t\targs = append(args, \"--use-http2\")\n+\t}\n \n \t// NOTE: if the \"beta\" component is not available, and this is run in parallel,\n \t// gcloud will attempt to install those components multiple",
        "comments": [],
        "commit_messages": [
            "add system tests\n\nSigned-off-by: Ahmet Alp Balkan <ahmetb@google.com>"
        ],
        "last_commit_sha": "165ad02c9ec0cfd5947af2b0f6f2499db4d4a02c"
    },
    {
        "pr_title": "chore(speech): quickstart now uses a gcs file",
        "pr_number": 1878,
        "file_name": "speech/speech_quickstart/main.go",
        "code_diff": "@@ -21,7 +21,6 @@\npackage main\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"log\"\n \n \tspeech \"cloud.google.com/go/speech/apiv1\"",
        "comments": [],
        "commit_messages": [
            "chore: quickstart now uses a gcs file"
        ],
        "last_commit_sha": "6b5e2f9efe4b0db7e333994d59182cf8cc9dfd1f"
    },
    {
        "pr_title": "chore(speech): quickstart now uses a gcs file",
        "pr_number": 1878,
        "file_name": "speech/speech_quickstart/main.go",
        "code_diff": "@@ -37,14 +36,8 @@\nfunc main() {\n \t\tlog.Fatalf(\"Failed to create client: %v\", err)\n \t}\n \n-\t// Sets the name of the audio file to transcribe.\n-\tfilename := \"/path/to/audio.raw\"\n-\n-\t// Reads the audio file into memory.\n-\tdata, err := ioutil.ReadFile(filename)\n-\tif err != nil {\n-\t\tlog.Fatalf(\"Failed to read file: %v\", err)\n-\t}\n+\t// The path to the remote audio file to transcribe.\n+\tfileURI := \"gs://cloud-samples-data/speech/brooklyn_bridge.raw\"\n \n \t// Detects speech in the audio file.\n \tresp, err := client.Recognize(ctx, &speechpb.RecognizeRequest{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6b5e2f9efe4b0db7e333994d59182cf8cc9dfd1f"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -84,6 +84,21 @@\nfunc (app *app) indexHandler(w http.ResponseWriter, r *http.Request) {\n }\n \n func main() {\n+\tapp := newApp()\n+\n+\thttp.HandleFunc(\"/\", app.indexHandler)\n+\tport := os.Getenv(\"PORT\")\n+\tif port == \"\" {\n+\t\tport = \"8080\"\n+\t}\n+\n+\tlog.Printf(\"Listening on port %s\", port)\n+\tif err := http.ListenAndServe(\":\"+port, nil); err != nil {\n+\t\tlog.Fatal(err)\n+\t}\n+}\n+\n+func newApp() *app {\n \tparsedTemplate, err := template.ParseFiles(\"templates/index.html\")\n \tif err != nil {\n \t\tlog.Fatalf(\"unable to parse template file: %s\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -93,11 +108,11 @@\nfunc main() {\n \t\ttmpl: parsedTemplate,\n \t}\n \n-\t// If the optional DB_TCP_HOST environment variable is set, it contains\n+\t// If the optional DB_HOST environment variable is set, it contains\n \t// the IP address and port number of a TCP connection pool to be created,\n-\t// such as \"127.0.0.1:3306\". If DB_TCP_HOST is not set, a Unix socket\n+\t// such as \"127.0.0.1:3306\". If DB_HOST is not set, a Unix socket\n \t// connection pool will be created instead.\n-\tif os.Getenv(\"DB_TCP_HOST\") != \"\" {\n+\tif os.Getenv(\"DB_HOST\") != \"\" {\n \t\tapp.db, err = initTCPConnectionPool()\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"initTCPConnectionPool: unable to connect: %v\", err)",
        "comments": [],
        "commit_messages": [
            "Added tests for all three Cloud SQL flavors"
        ],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -111,28 +126,17 @@\nfunc main() {\n \n \t// Create the votes table if it does not already exist.\n \tif _, err = app.db.Exec(`CREATE TABLE IF NOT EXISTS votes\n-\t( vote_id SERIAL NOT NULL, time_cast timestamp NOT NULL,\n-\tcandidate CHAR(6) NOT NULL, PRIMARY KEY (vote_id) );`); err != nil {\n+\t( id SERIAL NOT NULL, created_at datetime NOT NULL, updated_at datetime  NOT NULL,\n+\tcandidate VARCHAR(6) NOT NULL, PRIMARY KEY (id) );`); err != nil {\n \t\tlog.Fatalf(\"DB.Exec: unable to create table: %s\", err)\n \t}\n-\n-\thttp.HandleFunc(\"/\", app.indexHandler)\n-\tport := os.Getenv(\"PORT\")\n-\tif port == \"\" {\n-\t\tport = \"8080\"\n-\t}\n-\n-\tlog.Printf(\"Listening on port %s\", port)\n-\tif err := http.ListenAndServe(\":\"+port, nil); err != nil {\n-\t\tlog.Fatal(err)\n-\t}\n-\n+\treturn app\n }\n \n // recentVotes returns a slice of the last 5 votes cast.\n func recentVotes(app *app) ([]vote, error) {\n \tvar votes []vote\n-\trows, err := app.db.Query(`SELECT candidate, time_cast FROM votes ORDER BY time_cast DESC LIMIT 5`)\n+\trows, err := app.db.Query(`SELECT candidate, created_at FROM votes ORDER BY created_at DESC LIMIT 5`)\n \tif err != nil {\n \t\treturn votes, fmt.Errorf(\"DB.Query: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -152,11 +156,11 @@\nfunc recentVotes(app *app) ([]vote, error) {\n func currentTotals(app *app) (*templateData, error) {\n \t// get total votes for each candidate\n \tvar tabVotes, spaceVotes uint\n-\terr := app.db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='TABS'`).Scan(&tabVotes)\n+\terr := app.db.QueryRow(`SELECT count(id) FROM votes WHERE candidate='TABS'`).Scan(&tabVotes)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}\n-\terr = app.db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='SPACES'`).Scan(&spaceVotes)\n+\terr = app.db.QueryRow(`SELECT count(id) FROM votes WHERE candidate='SPACES'`).Scan(&spaceVotes)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "Added tests for all three Cloud SQL flavors"
        ],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -203,14 +207,13 @@\nfunc saveVote(w http.ResponseWriter, r *http.Request, app *app) error {\n \t}\n \n \t// [START cloud_sql_mysql_databasesql_connection]\n-\tsqlInsert := \"INSERT INTO votes(candidate, time_cast) VALUES(?, NOW())\"\n+\tsqlInsert := \"INSERT INTO votes(candidate, created_at, updated_at) VALUES(?, NOW(), NOW())\"\n \tif team == \"TABS\" || team == \"SPACES\" {\n \t\tif _, err := app.db.Exec(sqlInsert, team); err != nil {\n \t\t\tfmt.Fprintf(w, \"unable to save vote: %s\", err)\n \t\t\treturn fmt.Errorf(\"DB.Exec: %v\", err)\n-\t\t} else {\n-\t\t\tfmt.Fprintf(w, \"Vote successfully cast for %s!\\n\", team)\n \t\t}\n+\t\tfmt.Fprintf(w, \"Vote successfully cast for %s!\\n\", team)\n \t}\n \treturn nil\n \t// [END cloud_sql_mysql_databasesql_connection]",
        "comments": [],
        "commit_messages": [
            "Added tests for all three Cloud SQL flavors"
        ],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/postgres/database-sql/cloudsql.go",
        "code_diff": "@@ -88,20 +88,34 @@\nfunc (app *app) indexHandler(w http.ResponseWriter, r *http.Request) {\n }\n \n func main() {\n+\tapp := newApp()\n+\n+\thttp.HandleFunc(\"/\", app.indexHandler)\n+\tport := os.Getenv(\"PORT\")\n+\tif port == \"\" {\n+\t\tport = \"8080\"\n+\t}\n+\n+\tlog.Printf(\"Listening on port %s\", port)\n+\tif err := http.ListenAndServe(\":\"+port, nil); err != nil {\n+\t\tlog.Fatal(err)\n+\t}\n+}\n+\n+func newApp() *app {\n \tparsedTemplate, err := template.ParseFiles(\"templates/index.html\")\n \tif err != nil {\n \t\tlog.Fatalf(\"unable to parse template file: %s\", err)\n \t}\n-\n \tapp := &app{\n \t\ttmpl: parsedTemplate,\n \t}\n \n-\t// If the optional DB_TCP_HOST environment variable is set, it contains\n+\t// If the optional DB_HOST environment variable is set, it contains\n \t// the IP address and port number of a TCP connection pool to be created,\n-\t// such as \"127.0.0.1:5432\". If DB_TCP_HOST is not set, a Unix socket\n+\t// such as \"127.0.0.1:5432\". If DB_HOST is not set, a Unix socket\n \t// connection pool will be created instead.\n-\tif os.Getenv(\"DB_TCP_HOST\") != \"\" {\n+\tif os.Getenv(\"DB_HOST\") != \"\" {\n \t\tapp.db, err = initTCPConnectionPool()\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"initTCPConnectionPool: unable to connect: %s\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/postgres/database-sql/cloudsql.go",
        "code_diff": "@@ -115,28 +129,18 @@\nfunc main() {\n \n \t// Create the votes table if it does not already exist.\n \tif _, err = app.db.Exec(`CREATE TABLE IF NOT EXISTS votes\n-\t( vote_id SERIAL NOT NULL, time_cast timestamp NOT NULL,\n-\tcandidate CHAR(6) NOT NULL, PRIMARY KEY (vote_id) );`); err != nil {\n+\t( id SERIAL NOT NULL, created_at timestamp NOT NULL, updated_at timestamp NOT NULL,\n+\tcandidate VARCHAR(6) NOT NULL, PRIMARY KEY (id) );`); err != nil {\n \t\tlog.Fatalf(\"DB.Exec: unable to create table: %s\", err)\n \t}\n \n-\thttp.HandleFunc(\"/\", app.indexHandler)\n-\tport := os.Getenv(\"PORT\")\n-\tif port == \"\" {\n-\t\tport = \"8080\"\n-\t}\n-\n-\tlog.Printf(\"Listening on port %s\", port)\n-\tif err := http.ListenAndServe(\":\"+port, nil); err != nil {\n-\t\tlog.Fatal(err)\n-\t}\n-\n+\treturn app\n }\n \n // recentVotes returns a slice of the last 5 votes cast.\n func recentVotes(app *app) ([]vote, error) {\n \tvar votes []vote\n-\trows, err := app.db.Query(`SELECT candidate, time_cast FROM votes ORDER BY time_cast DESC LIMIT 5`)\n+\trows, err := app.db.Query(`SELECT candidate, created_at FROM votes ORDER BY created_at DESC LIMIT 5`)\n \tif err != nil {\n \t\treturn votes, fmt.Errorf(\"DB.Query: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/postgres/database-sql/cloudsql.go",
        "code_diff": "@@ -156,11 +160,11 @@\nfunc recentVotes(app *app) ([]vote, error) {\n func currentTotals(app *app) (*templateData, error) {\n \t// get total votes for each candidate\n \tvar tabVotes, spaceVotes uint\n-\terr := app.db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='TABS'`).Scan(&tabVotes)\n+\terr := app.db.QueryRow(`SELECT count(id) FROM votes WHERE candidate='TABS'`).Scan(&tabVotes)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}\n-\terr = app.db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='SPACES'`).Scan(&spaceVotes)\n+\terr = app.db.QueryRow(`SELECT count(id) FROM votes WHERE candidate='SPACES'`).Scan(&spaceVotes)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "Added tests for all three Cloud SQL flavors"
        ],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/postgres/database-sql/cloudsql.go",
        "code_diff": "@@ -207,14 +211,13 @@\nfunc saveVote(w http.ResponseWriter, r *http.Request, app *app) error {\n \t}\n \n \t// [START cloud_sql_postgres_databasesql_connection]\n-\tsqlInsert := \"INSERT INTO votes(candidate, time_cast) VALUES($1, NOW())\"\n+\tsqlInsert := \"INSERT INTO votes(candidate, created_at, updated_at) VALUES($1, NOW(), NOW())\"\n \tif team == \"TABS\" || team == \"SPACES\" {\n \t\tif _, err := app.db.Exec(sqlInsert, team); err != nil {\n \t\t\tfmt.Fprintf(w, \"unable to save vote: %s\", err)\n \t\t\treturn fmt.Errorf(\"DB.Exec: %v\", err)\n-\t\t} else {\n-\t\t\tfmt.Fprintf(w, \"Vote successfully cast for %s!\\n\", team)\n \t\t}\n+\t\tfmt.Fprintf(w, \"Vote successfully cast for %s!\\n\", team)\n \t}\n \treturn nil\n \t// [END cloud_sql_postgres_databasesql_connection]",
        "comments": [],
        "commit_messages": [
            "Added tests for all three Cloud SQL flavors"
        ],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql.go",
        "code_diff": "@@ -84,6 +84,21 @@\nfunc (app *app) indexHandler(w http.ResponseWriter, r *http.Request) {\n }\n \n func main() {\n+\tapp := newApp()\n+\thttp.HandleFunc(\"/\", app.indexHandler)\n+\tport := os.Getenv(\"PORT\")\n+\tif port == \"\" {\n+\t\tport = \"8080\"\n+\t}\n+\n+\tlog.Printf(\"Listening on port %s\", port)\n+\tif err := http.ListenAndServe(\":\"+port, nil); err != nil {\n+\t\tlog.Fatal(err)\n+\t}\n+\n+}\n+\n+func newApp() *app {\n \tparsedTemplate, err := template.ParseFiles(\"templates/index.html\")\n \tif err != nil {\n \t\tlog.Fatalf(\"unable to parse template file: %s\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql.go",
        "code_diff": "@@ -109,18 +124,7 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"DB.Exec: unable to create votes table: %s\", err)\n \t}\n-\n-\thttp.HandleFunc(\"/\", app.indexHandler)\n-\tport := os.Getenv(\"PORT\")\n-\tif port == \"\" {\n-\t\tport = \"8080\"\n-\t}\n-\n-\tlog.Printf(\"Listening on port %s\", port)\n-\tif err := http.ListenAndServe(\":\"+port, nil); err != nil {\n-\t\tlog.Fatal(err)\n-\t}\n-\n+\treturn app\n }\n \n // recentVotes returns a slice of the last 5 votes cast.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "testing(cloudsql): added integration tests for all 3 Cloud SQL flavors",
        "pr_number": 1872,
        "file_name": "cloudsql/sqlserver/database-sql/cloudsql.go",
        "code_diff": "@@ -202,9 +206,8 @@\nfunc saveVote(w http.ResponseWriter, r *http.Request, app *app) error {\n \t\tif _, err := app.db.Exec(sqlInsert, team); err != nil {\n \t\t\tfmt.Fprintf(w, \"unable to save vote: %s\", err)\n \t\t\treturn fmt.Errorf(\"DB.Exec: %v\", err)\n-\t\t} else {\n-\t\t\tfmt.Fprintf(w, \"Vote successfully cast for %s!\\n\", team)\n \t\t}\n+\t\tfmt.Fprintf(w, \"Vote successfully cast for %s!\\n\", team)\n \t}\n \treturn nil\n \t// [END cloud_sql_sqlserver_databasesql_connection]",
        "comments": [],
        "commit_messages": [
            "Added tests for all three Cloud SQL flavors"
        ],
        "last_commit_sha": "15f4af12b662dcadb5ca291c306c0b6893333efd"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/assets/add_delete_security_marks.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage assets\n \n+// [START securitycenter_add_delete_security_marks]\n // [START add_delete_security_marks]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/assets/add_security_marks.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage assets\n \n+// [START securitycenter_add_security_marks]\n // [START add_security_marks]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/assets/delete_security_marks.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage assets\n \n+// [START securitycenter_delete_security_marks]\n // [START delete_security_marks]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/assets/list_all_assets.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage assets\n \n+// [START securitycenter_list_all_assets]\n // [START list_all_assets]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/assets/list_all_project_assets.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage assets\n \n+// [START securitycenter_list_project_assets]\n // [START list_project_assets]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/assets/list_assets_with_security_marks.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage assets\n \n+// [START securitycenter_list_assets_with_security_marks]\n // [START list_assets_with_security_marks]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/assets/list_project_assets_and_state_changes.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage assets\n \n+// [START securitycenter_list_project_assets_and_state_changes]\n // [START list_project_assets_and_state_changes]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/assets/list_project_assets_at_time.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage assets\n \n+// [START securitycenter_list_project_assets_at_time]\n // [START list_project_assets_at_time]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/add_security_marks.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_add_security_marks]\n // [START add_security_marks]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/create_finding.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_create_finding]\n // [START create_finding]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/create_finding_with_source_properties.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_create_finding_with_source_properties]\n // [START create_finding_with_source_properties]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/create_source.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_create_source]\n // [START create_source]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/get_source.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_get_source]\n // [START get_source]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/get_source_iam.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_get_iam_policy_source]\n // [START get_iam_policy_source]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/list_all_findings.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_list_all_findings]\n // [START list_all_findings]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/list_filtered_findings.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_list_filtered_findings]\n // [START list_filtered_findings]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/list_findings_at_time.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_list_findings_at_time]\n // [START list_findings_at_time]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/list_findings_with_security_mark.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_list_findings_with_marks]\n // [START list_findings_with_marks]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/list_sources.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_list_sources]\n // [START list_sources]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/set_finding_state.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_set_finding_state]\n // [START set_finding_state]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/set_source_iam.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_set_iam_policy_source]\n // [START set_iam_policy_source]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/test_iam.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_test_iam]\n // [START test_iam]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/update_finding_source_properties.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_update_finding_source_properties]\n // [START update_finding_source_properties]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/findings/update_source.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage findings\n \n+// [START securitycenter_update_source]\n // [START update_source]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/notifications/create_notification_config.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage notifications\n \n+// [START securitycenter_create_notification_config]\n // [START scc_create_notification_config]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/notifications/delete_notification_config.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage notifications\n \n+// [START securitycenter_delete_notification_config]\n // [START scc_delete_notification_config]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/notifications/get_notification_config.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage notifications\n \n+// [START securitycenter_get_notification_config]\n // [START scc_get_notification_config]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/notifications/list_notification_configs.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage notifications\n \n+// [START securitycenter_list_notification_configs]\n // [START scc_list_notification_configs]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/notifications/receive_notifications.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage notifications\n \n+// [START securitycenter_receive_notifications]\n // [START scc_receive_notifications]\n import (\n \t\"bytes\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/notifications/update_notification_config.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage notifications\n \n+// [START securitycenter_update_notification_config]\n // [START scc_update_notification_config]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/settings/enable_asset_discovery.go",
        "code_diff": "@@ -15,6 +15,7 @@\n// Package settings contains snippets for working with CSCC organization settings.\n package settings\n \n+// [START securitycenter_get_org_settings]\n // [START get_org_settings]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "docs(securitycenter): wrap samples with future prefix",
        "pr_number": 1867,
        "file_name": "securitycenter/settings/get_org_settings.go",
        "code_diff": "@@ -14,6 +14,7 @@\npackage settings\n \n+// [START securitycenter_get_org_settings]\n // [START get_org_settings]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "docs: Wrap samples with future prefix"
        ],
        "last_commit_sha": "45dbb5a260a78496cc2a53e10a9b10da88ddbda9"
    },
    {
        "pr_title": "chore: added retry for flaky ttranslate test",
        "pr_number": 1860,
        "file_name": "translate/v3/batch_translate_text_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [
            "chore: fixed lint"
        ],
        "last_commit_sha": "c61c854192cdf02d49c33a207ffbae0bea7f57f6"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "dataproc/dataproc_test.go",
        "code_diff": "@@ -52,10 +52,10 @@\nfunc deleteCluster(projectID string, clusterName, region string) error {\n \treturn nil\n }\n \n-func TestCreateCluster(t *testing.T) {\n+func TestDataproc(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tclusterName := fmt.Sprintf(\"go-cc-test-%s\", tc.ProjectID)\n+\tclusterName := fmt.Sprintf(\"go-dp-test-%s\", tc.ProjectID)\n \tregion := \"us-central1\"\n \n \tdeleteCluster(tc.ProjectID, clusterName, region) // Delete the cluster if it already exists, ignoring any errors.",
        "comments": [],
        "commit_messages": [
            "combined create_cluster and submit_job tests"
        ],
        "last_commit_sha": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "dataproc/quickstart/quickstart.go",
        "code_diff": "@@ -14,8 +14,8 @@\n// [START dataproc_quickstart]\n \n-// This quickstart shows how you can use the Cloud Dataproc Client library to create a\n-// Cloud Dataproc cluster, submit a PySpark job to the cluster, wait for the job to finish\n+// This quickstart shows how you can use the Dataproc Client library to create a\n+// Dataproc cluster, submit a PySpark job to the cluster, wait for the job to finish\n // and finally delete the cluster.\n //\n // Usage:",
        "comments": [],
        "commit_messages": [
            "Adding submit_job sample, update quickstart, update create_cluster"
        ],
        "last_commit_sha": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "dataproc/quickstart/quickstart.go",
        "code_diff": "@@ -30,7 +30,7 @@\nimport (\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n-\t\"time\"\n+\t\"regexp\"\n \n \tdataproc \"cloud.google.com/go/dataproc/apiv1\"\n \t\"cloud.google.com/go/storage\"",
        "comments": [],
        "commit_messages": [
            "Adding submit_job sample, update quickstart, update create_cluster"
        ],
        "last_commit_sha": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(dataproc): new sample for job_submit + updating quickstart / create_cluster",
        "pr_number": 1850,
        "file_name": "dataproc/quickstart/quickstart.go",
        "code_diff": "@@ -124,83 +124,35 @@\nfunc main() {\n \t\t},\n \t}\n \n-\tsubmitJobResp, err := jobClient.SubmitJob(ctx, submitJobReq)\n+\tsubmitJobOp, err := jobClient.SubmitJobAsOperation(ctx, submitJobReq)\n \tif err != nil {\n-\t\tfmt.Printf(\"error submitting job: %v\\n\", err)\n+\t\tfmt.Printf(\"error with request to submitting job: %v\\n\", err)\n \t\treturn\n \t}\n \n-\tid := submitJobResp.Reference.JobId\n-\n-\tfmt.Printf(\"Submitted job %q\\n\", id)\n-\n-\t// These states all signify that a job has terminated, successfully or not.\n-\tterminalStates := map[dataprocpb.JobStatus_State]bool{\n-\t\tdataprocpb.JobStatus_ERROR:     true,\n-\t\tdataprocpb.JobStatus_CANCELLED: true,\n-\t\tdataprocpb.JobStatus_DONE:      true,\n-\t}\n-\n-\t// We can create a timeout such that the job gets cancelled if not in a terminal state after a certain amount of time.\n-\ttimeout := 5 * time.Minute\n-\tstart := time.Now()\n-\n-\tvar state dataprocpb.JobStatus_State\n-\tfor {\n-\t\tif time.Since(start) > timeout {\n-\t\t\tcancelReq := &dataprocpb.CancelJobRequest{\n-\t\t\t\tProjectId: projectID,\n-\t\t\t\tRegion:    region,\n-\t\t\t\tJobId:     id,\n-\t\t\t}\n-\n-\t\t\tif _, err := jobClient.CancelJob(ctx, cancelReq); err != nil {\n-\t\t\t\tfmt.Printf(\"error cancelling job: %v\\n\", err)\n-\t\t\t}\n-\t\t\tfmt.Printf(\"job %q timed out after %d minutes\\n\", id, int64(timeout.Minutes()))\n-\t\t\treturn\n-\t\t}\n-\n-\t\tgetJobReq := &dataprocpb.GetJobRequest{\n-\t\t\tProjectId: projectID,\n-\t\t\tRegion:    region,\n-\t\t\tJobId:     id,\n-\t\t}\n-\t\tgetJobResp, err := jobClient.GetJob(ctx, getJobReq)\n-\t\tif err != nil {\n-\t\t\tfmt.Printf(\"error getting job %q with error: %v\\n\", id, err)\n-\t\t\treturn\n-\t\t}\n-\t\tstate = getJobResp.Status.State\n-\t\tif terminalStates[state] {\n-\t\t\tbreak\n-\t\t}\n-\n-\t\t// Sleep as to not excessively poll the API.\n-\t\ttime.Sleep(1 * time.Second)\n+\tsubmitJobResp, err := submitJobOp.Wait(ctx)\n+\tif err != nil {\n+\t\tfmt.Printf(\"error submitting job: %v\\n\", err)\n+\t\treturn\n \t}\n \n-\t// Cloud Dataproc job outget gets saved to a GCS bucket allocated to it.\n-\tgetCReq := &dataprocpb.GetClusterRequest{\n-\t\tProjectId:   projectID,\n-\t\tRegion:      region,\n-\t\tClusterName: clusterName,\n-\t}\n+\tre := regexp.MustCompile(\"gs://(.+?)/(.+)\")\n+\tmatches := re.FindStringSubmatch(submitJobResp.DriverOutputResourceUri)\n \n-\tresp, err := clusterClient.GetCluster(ctx, getCReq)\n-\tif err != nil {\n-\t\tfmt.Printf(\"error getting cluster %q: %v\\n\", clusterName, err)\n+\tif len(matches) < 3 {\n+\t\tfmt.Printf(\"regex error: %s\\n\", submitJobResp.DriverOutputResourceUri)\n \t\treturn\n \t}\n \n+\t// Dataproc job outget gets saved to a GCS bucket allocated to it.\n \tstorageClient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tfmt.Printf(\"error creating storage client: %v\\n\", err)\n \t\treturn\n \t}\n \n-\tobj := fmt.Sprintf(\"google-cloud-dataproc-metainfo/%s/jobs/%s/driveroutput.000000000\", resp.ClusterUuid, id)\n-\treader, err := storageClient.Bucket(resp.Config.ConfigBucket).Object(obj).NewReader(ctx)\n+\tobj := fmt.Sprintf(\"%s.000000000\", matches[2])\n+\treader, err := storageClient.Bucket(matches[1]).Object(obj).NewReader(ctx)\n \tif err != nil {\n \t\tfmt.Printf(\"error reading job output: %v\\n\", err)\n \t\treturn",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ae34132c4966c12c0a1e1da2aa5c070b0c229d26"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "kms/decrypt_asymmetric.go",
        "code_diff": "@@ -18,10 +18,12 @@\npackage kms\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // decryptAsymmetric will attempt to decrypt a given ciphertext with an",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "kms/decrypt_symmetric.go",
        "code_diff": "@@ -18,10 +18,12 @@\npackage kms\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // decryptSymmetric will decrypt the input ciphertext bytes using the specified symmetric key.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "kms/encrypt_symmetric.go",
        "code_diff": "@@ -18,10 +18,12 @@\npackage kms\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // encryptSymmetric encrypts the input plaintext with the specified symmetric",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "kms/encrypt_symmetric.go",
        "code_diff": "@@ -41,10 +43,18 @@\nfunc encryptSymmetric(w io.Writer, name string, message string) error {\n \t// ciphertexts are always byte arrays.\n \tplaintext := []byte(message)\n \n+\t// Optional but recommended: Compute plaintext's CRC32C.\n+\tcrc32c := func(data []byte) uint32 {\n+\t\tt := crc32.MakeTable(crc32.Castagnoli)\n+\t\treturn crc32.Checksum(data, t)\n+\t}\n+\tplaintextCRC32C := crc32c(plaintext)\n+\n \t// Build the request.\n \treq := &kmspb.EncryptRequest{\n-\t\tName:      name,\n-\t\tPlaintext: plaintext,\n+\t\tName:            name,\n+\t\tPlaintext:       plaintext,\n+\t\tPlaintextCrc32C: wrapperspb.Int64(int64(plaintextCRC32C)),\n \t}\n \n \t// Call the API.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "kms/get_public_key.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"crypto/x509\"\n \t\"encoding/pem\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"",
        "comments": [],
        "commit_messages": [
            "kms: make crc32c() a nested function to resolve compile issues"
        ],
        "last_commit_sha": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "kms/sign_asymmetric.go",
        "code_diff": "@@ -19,10 +19,12 @@\nimport (\n \t\"context\"\n \t\"crypto/sha256\"\n \t\"fmt\"\n+\t\"hash/crc32\"\n \t\"io\"\n \n \tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n+\t\"google.golang.org/protobuf/types/known/wrapperspb\"\n )\n \n // signAsymmetric will sign a plaintext message using a saved asymmetric private",
        "comments": [],
        "commit_messages": [
            "kms: add integrity verification to sign_asymmetric.go"
        ],
        "last_commit_sha": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "feat(kms): add integrity verification to cryptographic operations",
        "pr_number": 1830,
        "file_name": "kms/sign_asymmetric.go",
        "code_diff": "@@ -48,6 +50,14 @@\nfunc signAsymmetric(w io.Writer, name string, message string) error {\n \t\treturn fmt.Errorf(\"failed to create digest: %v\", err)\n \t}\n \n+\t// Optional but recommended: Compute digest's CRC32C.\n+\tcrc32c := func(data []byte) uint32 {\n+\t\tt := crc32.MakeTable(crc32.Castagnoli)\n+\t\treturn crc32.Checksum(data, t)\n+\n+\t}\n+\tdigestCRC32C := crc32c(digest.Sum(nil))\n+\n \t// Build the signing request.\n \t//\n \t// Note: Key algorithms will require a varying hash function. For example,",
        "comments": [],
        "commit_messages": [
            "kms: add integrity verification to sign_asymmetric.go"
        ],
        "last_commit_sha": "fc5760cb91488c04c4e584d0a6e361fb9e8ef9d3"
    },
    {
        "pr_title": "fix(pubsub): remove channel usage in concurrency sample",
        "pr_number": 1825,
        "file_name": "pubsub/subscriptions/pull_concurrency.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"runtime\"\n+\t\"sync/atomic\"\n \t\"time\"\n \n \t\"cloud.google.com/go/pubsub\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6e2b16be2b421d9f1c9f87b0160ce8c454d9d880"
    },
    {
        "pr_title": "chore(opentelemetry): update trace example to latest released APIs",
        "pr_number": 1821,
        "file_name": "opentelemetry/trace/main.go",
        "code_diff": "@@ -31,11 +31,13 @@\nimport (\n // [START opentelemetry_trace_main_function]\n func main() {\n \t// Create exporter.\n+\tctx := context.Background()\n \tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \texporter, err := texporter.NewExporter(texporter.WithProjectID(projectID))\n \tif err != nil {\n \t\tlog.Fatalf(\"texporter.NewExporter: %v\", err)\n \t}\n+\tdefer exporter.Shutdown(ctx) // flushes any pending spans\n \n \t// Create trace provider with the exporter.\n \t//",
        "comments": [],
        "commit_messages": [
            "chore(opentelemetry): update trace example to latest released APIs\n\nFix example to flush pending spans."
        ],
        "last_commit_sha": "5bea6b818b2d03b5f771f0ec2ef28c1555e2b519"
    },
    {
        "pr_title": "test(pubsub): wrap dead letter sample test in retry",
        "pr_number": 1818,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -359,46 +359,55 @@\nfunc TestCreateWithDeadLetterPolicy(t *testing.T) {\n \tdeadLetterSubID := subID + \"-dead-letter-sub\"\n \tdeadLetterSinkID := topicID + \"-dead-letter-sink\"\n \n-\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSourceTopic.Delete(ctx)\n-\tdefer deadLetterSourceTopic.Stop()\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSourceTopic.Delete(ctx)\n+\t\tdefer deadLetterSourceTopic.Stop()\n \n-\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSinkTopic.Delete(ctx)\n-\tdefer deadLetterSinkTopic.Stop()\n+\t\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSinkTopic.Delete(ctx)\n+\t\tdefer deadLetterSinkTopic.Stop()\n \n-\tbuf := new(bytes.Buffer)\n-\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n-\t\tt.Fatalf(\"createSubWithDeadLetter failed: %v\", err)\n-\t}\n-\tsub := client.Subscription(deadLetterSubID)\n-\tok, err := sub.Exists(context.Background())\n-\tif err != nil {\n-\t\tt.Fatalf(\"sub.Exists failed: %v\", err)\n-\t}\n-\tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", deadLetterSubID)\n-\t}\n-\tdefer sub.Delete(ctx)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n+\t\t\tr.Errorf(\"createSubWithDeadLetter failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tsub := client.Subscription(deadLetterSubID)\n+\t\tok, err := sub.Exists(context.Background())\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"sub.Exists failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif !ok {\n+\t\t\tr.Errorf(\"got none; want sub = %q\", deadLetterSubID)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer sub.Delete(ctx)\n \n-\tcfg, err := sub.Config(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := cfg.DeadLetterPolicy\n-\twant := &pubsub.DeadLetterPolicy{\n-\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n-\t\tMaxDeliveryAttempts: 10,\n-\t}\n-\tif !cmp.Equal(got, want) {\n-\t\tt.Fatalf(\"got cfg: %+v; want cfg: %+v\", got, want)\n-\t}\n+\t\tcfg, err := sub.Config(ctx)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"createSubWithDeadLetter config: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tgot := cfg.DeadLetterPolicy\n+\t\twant := &pubsub.DeadLetterPolicy{\n+\t\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n+\t\t\tMaxDeliveryAttempts: 10,\n+\t\t}\n+\t\tif !cmp.Equal(got, want) {\n+\t\t\tr.Errorf(\"got cfg: %+v; want cfg: %+v\", got, want)\n+\t\t\treturn\n+\t\t}\n+\t})\n }\n \n func TestUpdateDeadLetterPolicy(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "a24c17701f32d8df528378e5f2ecbf3a2c3b878a"
    },
    {
        "pr_title": "test(pubsub): wrap dead letter sample test in retry",
        "pr_number": 1818,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -410,62 +419,75 @@\nfunc TestUpdateDeadLetterPolicy(t *testing.T) {\n \tdeadLetterSubID := subID + \"-update-sub\"\n \tdeadLetterSinkID := topicID + \"-update-sink\"\n \n-\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSourceTopic.Delete(ctx)\n-\tdefer deadLetterSourceTopic.Stop()\n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tdeadLetterSourceTopic, err := getOrCreateTopic(ctx, client, deadLetterSourceID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSourceTopic.Delete(ctx)\n+\t\tdefer deadLetterSourceTopic.Stop()\n \n-\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n-\tif err != nil {\n-\t\tt.Fatalf(\"getOrCreateTopic: %v\", err)\n-\t}\n-\tdefer deadLetterSinkTopic.Delete(ctx)\n-\tdefer deadLetterSinkTopic.Stop()\n+\t\tdeadLetterSinkTopic, err := getOrCreateTopic(ctx, client, deadLetterSinkID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"getOrCreateTopic: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer deadLetterSinkTopic.Delete(ctx)\n+\t\tdefer deadLetterSinkTopic.Stop()\n \n-\tbuf := new(bytes.Buffer)\n-\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n-\t\tt.Fatalf(\"createSubWithDeadLetter failed: %v\", err)\n-\t}\n-\tsub := client.Subscription(deadLetterSubID)\n-\tok, err := sub.Exists(context.Background())\n-\tif err != nil {\n-\t\tt.Fatalf(\"sub.Exists failed: %v\", err)\n-\t}\n-\tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", deadLetterSubID)\n-\t}\n-\tdefer sub.Delete(ctx)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif err := createSubWithDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSourceID, deadLetterSinkTopic.String()); err != nil {\n+\t\t\tr.Errorf(\"createSubWithDeadLetter failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tsub := client.Subscription(deadLetterSubID)\n+\t\tok, err := sub.Exists(context.Background())\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"sub.Exists failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif !ok {\n+\t\t\tr.Errorf(\"got none; want sub = %q\", deadLetterSubID)\n+\t\t\treturn\n+\t\t}\n+\t\tdefer sub.Delete(ctx)\n \n-\tif err := updateDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSinkTopic.String()); err != nil {\n-\t\tt.Fatalf(\"updateDeadLetter failed: %v\", err)\n-\t}\n+\t\tif err := updateDeadLetter(buf, tc.ProjectID, deadLetterSubID, deadLetterSinkTopic.String()); err != nil {\n+\t\t\tr.Errorf(\"updateDeadLetter failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n \n-\tcfg, err := sub.Config(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot := cfg.DeadLetterPolicy\n-\twant := &pubsub.DeadLetterPolicy{\n-\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n-\t\tMaxDeliveryAttempts: 20,\n-\t}\n-\tif !cmp.Equal(got, want) {\n-\t\tt.Fatalf(\"got cfg: %+v; want cfg: %+v\", got, want)\n-\t}\n+\t\tcfg, err := sub.Config(ctx)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"update dead letter policy config: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tgot := cfg.DeadLetterPolicy\n+\t\twant := &pubsub.DeadLetterPolicy{\n+\t\t\tDeadLetterTopic:     deadLetterSinkTopic.String(),\n+\t\t\tMaxDeliveryAttempts: 20,\n+\t\t}\n+\t\tif !cmp.Equal(got, want) {\n+\t\t\tr.Errorf(\"got cfg: %+v; want cfg: %+v\", got, want)\n+\t\t\treturn\n+\t\t}\n \n-\tif err := removeDeadLetterTopic(buf, tc.ProjectID, deadLetterSubID); err != nil {\n-\t\tt.Fatalf(\"removeDeadLetterTopic failed: %v\", err)\n-\t}\n-\tcfg, err = sub.Config(ctx)\n-\tif err != nil {\n-\t\tt.Fatal(err)\n-\t}\n-\tgot = cfg.DeadLetterPolicy\n-\tif got != nil {\n-\t\tt.Fatalf(\"got dead letter policy: %+v, want nil\", got)\n-\t}\n+\t\tif err := removeDeadLetterTopic(buf, tc.ProjectID, deadLetterSubID); err != nil {\n+\t\t\tr.Errorf(\"removeDeadLetterTopic failed: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tcfg, err = sub.Config(ctx)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"update dead letter policy config: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tgot = cfg.DeadLetterPolicy\n+\t\tif got != nil {\n+\t\t\tr.Errorf(\"got dead letter policy: %+v, want nil\", got)\n+\t\t\treturn\n+\t\t}\n+\t})\n }\n \n func TestPullMsgsDeadLetterDeliveryAttempts(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "test(pubsub): wrap dead letter sample test in retry"
        ],
        "last_commit_sha": "a24c17701f32d8df528378e5f2ecbf3a2c3b878a"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage main\n \n // [START fs_initialize]\n+// [START firestore_setup_client_create]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -39,6 +40,7 @@\nfunc createClient(ctx context.Context) *firestore.Client {\n \treturn client\n }\n \n+// [END firestore_setup_client_create]\n // [END fs_initialize]\n \n func main() {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -48,6 +50,7 @@\nfunc main() {\n \tdefer client.Close()\n \n \t// [START fs_add_data_1]\n+\t// [START firestore_setup_dataset_pt1]\n \t_, _, err := client.Collection(\"users\").Add(ctx, map[string]interface{}{\n \t\t\"first\": \"Ada\",\n \t\t\"last\":  \"Lovelace\",",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -56,9 +59,11 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"Failed adding alovelace: %v\", err)\n \t}\n+\t// [END firestore_setup_dataset_pt1]\n \t// [END fs_add_data_1]\n \n \t// [START fs_add_data_2]\n+\t// [START firestore_setup_dataset_pt2]\n \t_, _, err = client.Collection(\"users\").Add(ctx, map[string]interface{}{\n \t\t\"first\":  \"Alan\",\n \t\t\"middle\": \"Mathison\",",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_quickstart/main.go",
        "code_diff": "@@ -68,9 +73,11 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"Failed adding aturing: %v\", err)\n \t}\n+\t// [END firestore_setup_dataset_pt2]\n \t// [END fs_add_data_2]\n \n \t// [START fs_get_all_users]\n+\t// [START firestore_setup_dataset_read]\n \titer := client.Collection(\"users\").Documents(ctx)\n \tfor {\n \t\tdoc, err := iter.Next()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/collection_group_query.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_collection_group_query]\n+// [START firestore_query_collection_group_filter_eq]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/collection_group_setup.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_collection_group_query_data_setup]\n+// [START firestore_query_collection_group_dataset]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/increment.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_update_document_increment]\n+// [START firestore_data_set_numeric_increment]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/listen_changes.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_changes]\n+// [START firestore_listen_query_changes]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "docs: normalize firestore region tags"
        ],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/listen_document.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_document]\n+// [START firestore_listen_document]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "docs: normalize firestore region tags"
        ],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/listen_document.go",
        "code_diff": "@@ -29,11 +29,11 @@\nimport (\n // listenDocument listens to a single document.\n func listenDocument(ctx context.Context, w io.Writer, projectID, collection string) error {\n \t// projectID := \"project-id\"\n-\t// [START fs_detach_listener]\n+\t// [START firestore_listen_detach]\n \t// \u0421ontext with timeout stops listening to changes.\n \tctx, cancel := context.WithTimeout(ctx, 30*time.Second)\n \tdefer cancel()\n-\t// [END fs_detach_listener]\n+\t// [END firestore_listen_detach]\n \n \tclient, err := firestore.NewClient(ctx, projectID)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "docs: normalize firestore region tags"
        ],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/listen_errors.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_errors]\n+// [START firestore_listen_handle_error]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "docs: normalize firestore region tags"
        ],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/listen_multiple.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage main\n \n-// [START fs_listen_multiple]\n+// [START firestore_listen_query_snapshots]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "docs: normalize firestore region tags"
        ],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/main.go",
        "code_diff": "@@ -25,6 +25,7 @@\nimport (\n )\n \n // [START fs_class_definition]\n+// [START firestore_data_custom_type_definition]\n \n // City represents a city.\n type City struct {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -15,17 +15,20 @@\npackage main\n \n // [START fs_dependencies]\n+// [START firestore_setup_dependencies]\n import (\n \t\"context\"\n \t\"fmt\"\n \n \t\"cloud.google.com/go/firestore\"\n )\n \n+// [END firestore_setup_dependencies]\n // [END fs_dependencies]\n \n func prepareQuery(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_create_examples]\n+\t// [START firestore_query_filter_dataset]\n \tcities := []struct {\n \t\tid string\n \t\tc  City",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -66,30 +69,37 @@\nfunc prepareQuery(ctx context.Context, client *firestore.Client) error {\n \t\t\treturn err\n \t\t}\n \t}\n+\t// [END firestore_query_filter_dataset]\n \t// [END fs_query_create_examples]\n \treturn nil\n }\n \n func createQuery(client *firestore.Client) {\n \t// [START fs_create_query]\n+\t// [START firestore_query_filter_eq_boolean]\n \tquery := client.Collection(\"cities\").Where(\"capital\", \"==\", true)\n+\t// [END firestore_query_filter_eq_boolean]\n \t// [END fs_create_query]\n \t_ = query\n }\n \n func createQueryTwo(client *firestore.Client) {\n \t// [START fs_create_query_two]\n+\t// [START firestore_query_filter_eq_string]\n \tquery := client.Collection(\"cities\").Where(\"state\", \"==\", \"CA\")\n+\t// [END firestore_query_filter_eq_string]\n \t// [END fs_create_query_two]\n \t_ = query\n }\n \n func createSimpleQueries(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_simple_queries]\n+\t// [START firestore_query_filter_single_examples]\n \tcountryQuery := cities.Where(\"state\", \"==\", \"CA\")\n \tpopQuery := cities.Where(\"population\", \"<\", 1000000)\n \tcityQuery := cities.Where(\"name\", \">=\", \"San Francisco\")\n+\t// [END firestore_query_filter_single_examples]\n \t// [END fs_simple_queries]\n \n \t_ = countryQuery",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -100,8 +110,10 @@\nfunc createSimpleQueries(client *firestore.Client) {\n func createChainedQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_chained_query]\n+\t// [START firestore_query_filter_compound_multi_eq]\n \tdenverQuery := cities.Where(\"name\", \"==\", \"Denver\").Where(\"state\", \"==\", \"CO\")\n \tcaliQuery := cities.Where(\"state\", \"==\", \"CA\").Where(\"population\", \"<=\", 1000000)\n+\t// [END firestore_query_filter_compound_multi_eq]\n \t// [END fs_chained_query]\n \n \t_ = denverQuery",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -112,7 +124,9 @@\nfunc createInvalidChainedQuery(client *firestore.Client) {\n \t// Note: this is an instance of a currently unsupported chained query\n \tcities := client.Collection(\"cities\")\n \t// [START fs_invalid_chained_query]\n+\t// [START firestore_query_filter_compound_multi_eq]\n \tquery := cities.Where(\"country\", \"==\", \"USA\").Where(\"population\", \">\", 5000000)\n+\t// [END firestore_query_filter_compound_multi_eq]\n \t// [END fs_invalid_chained_query]\n \n \t_ = query",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -121,8 +135,10 @@\nfunc createInvalidChainedQuery(client *firestore.Client) {\n func createRangeQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_range_query]\n+\t// [START firestore_query_filter_range_valid]\n \tstateQuery := cities.Where(\"state\", \">=\", \"CA\").Where(\"state\", \"<\", \"IN\")\n \tpopulationQuery := cities.Where(\"state\", \"==\", \"CA\").Where(\"population\", \">\", 1000000)\n+\t// [END firestore_query_filter_range_valid]\n \t// [END fs_range_query]\n \n \t_ = stateQuery",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -134,7 +150,9 @@\nfunc createInvalidRangeQuery(client *firestore.Client) {\n \t// are limited to a single field.\n \tcities := client.Collection(\"cities\")\n \t// [START fs_invalid_range_query]\n+\t// [START firestore_query_filter_range_invalid]\n \tquery := cities.Where(\"state\", \">=\", \"CA\").Where(\"population\", \">\", 1000000)\n+\t// [END firestore_query_filter_range_invalid]\n \t// [END fs_invalid_range_query]\n \n \t_ = query",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -143,7 +161,9 @@\nfunc createInvalidRangeQuery(client *firestore.Client) {\n func createOrderByNameLimitQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_order_by_name_limit_query]\n+\t// [START firestore_query_order_limit]\n \tquery := cities.OrderBy(\"name\", firestore.Asc).Limit(3)\n+\t// [END firestore_query_order_limit]\n \t// [END fs_order_by_name_limit_query]\n \n \t_ = query",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -152,7 +172,9 @@\nfunc createOrderByNameLimitQuery(client *firestore.Client) {\n func createOrderByNameLimitToLastQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_order_by_name_limit_to_last_query]\n+\t// [START firestore_query_order_limit]\n \tquery := cities.OrderBy(\"name\", firestore.Asc).LimitToLast(3)\n+\t// [END firestore_query_order_limit]\n \t// [END fs_order_by_name_limit_to_last_query]\n \n \t_ = query",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -161,23 +183,29 @@\nfunc createOrderByNameLimitToLastQuery(client *firestore.Client) {\n func createOrderByNameDescLimitQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_order_by_name_desc_limit_query]\n+\t// [START firestore_query_order_desc_limit]\n \tquery := cities.OrderBy(\"name\", firestore.Desc).Limit(3)\n+\t// [END firestore_query_order_desc_limit]\n \t// [END fs_order_by_name_desc_limit_query]\n \n \t_ = query\n }\n \n func createMultipleOrderByQuery(client *firestore.Client) {\n \t// [START fs_order_by_multiple]\n+\t// [START firestore_query_order_multi]\n \tquery := client.Collection(\"cities\").OrderBy(\"state\", firestore.Asc).OrderBy(\"population\", firestore.Desc)\n+\t// [END firestore_query_order_multi]\n \t// [END fs_order_by_multiple]\n \t_ = query\n }\n \n func createRangeWithOrderByAndLimitQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_where_order_by_limit_query]\n+\t// [START firestore_query_order_limit_field_valid]\n \tquery := cities.Where(\"population\", \">\", 2500000).OrderBy(\"population\", firestore.Desc).Limit(2)\n+\t// [END firestore_query_order_limit_field_valid]\n \t// [END fs_where_order_by_limit_query]\n \n \t_ = query",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -186,7 +214,9 @@\nfunc createRangeWithOrderByAndLimitQuery(client *firestore.Client) {\n func createRangeWithOrderByQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_range_order_by_query]\n+\t// [START firestore_query_order_with_filter]\n \tquery := cities.Where(\"population\", \">\", 2500000).OrderBy(\"population\", firestore.Asc)\n+\t// [END firestore_query_order_with_filter]\n \t// [END fs_range_order_by_query]\n \n \t_ = query",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -195,30 +225,37 @@\nfunc createRangeWithOrderByQuery(client *firestore.Client) {\n func createInvalidRangeWithOrderByQuery(client *firestore.Client) {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_invalid_range_order_by_query]\n+\t// [START firestore_query_order_field_invalid]\n \t// Note: This is an invalid query. It violates the constraint that range\n \t// and order by are required to be on the same field.\n \tquery := cities.Where(\"population\", \">\", 2500000).OrderBy(\"country\", firestore.Asc)\n+\t// [END firestore_query_order_field_invalid]\n \t// [END fs_invalid_range_order_by_query]\n \n \t_ = query\n }\n \n func createSimpleStartAtQuery(client *firestore.Client) {\n \t// [START fs_simple_start_at]\n+\t// [START firestore_query_cursor_start_at_field_value_single]\n \tquery := client.Collection(\"cities\").OrderBy(\"population\", firestore.Asc).StartAt(1000000)\n+\t// [END firestore_query_cursor_start_at_field_value_single]\n \t// [END fs_simple_start_at]\n \t_ = query\n }\n \n func createSimpleEndtAtQuery(client *firestore.Client) {\n \t// [START fs_simple_end_at]\n+\t// [START firestore_query_cursor_end_at_field_value_single]\n \tquery := client.Collection(\"cities\").OrderBy(\"population\", firestore.Asc).EndAt(1000000)\n+\t// [END firestore_query_cursor_end_at_field_value_single]\n \t// [END fs_simple_end_at]\n \t_ = query\n }\n \n func paginateCursor(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_paginate_cursor]\n+\t// [START firestore_query_cursor_pagination]\n \tcities := client.Collection(\"cities\")\n \n \t// Get the first 25 cities, ordered by population.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -237,13 +274,15 @@\nfunc paginateCursor(ctx context.Context, client *firestore.Client) error {\n \t\tLimit(25)\n \n \t// ...\n+\t// [END firestore_query_cursor_pagination]\n \t// [END fs_paginate_cursor]\n \t_ = secondPage\n \treturn nil\n }\n \n func createMultipleStartAtQuery(client *firestore.Client) {\n \t// [START fs_start_at_multiple]\n+\t// [START firestore_query_cursor_start_at_field_value_multi]\n \t// Will return all Springfields.\n \tclient.Collection(\"cities\").\n \t\tOrderBy(\"name\", firestore.Asc).",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -255,13 +294,16 @@\nfunc createMultipleStartAtQuery(client *firestore.Client) {\n \t\tOrderBy(\"name\", firestore.Asc).\n \t\tOrderBy(\"state\", firestore.Asc).\n \t\tStartAt(\"Springfield\", \"Wisconsin\")\n+\t// [END firestore_query_cursor_start_at_field_value_multi]\n \t// [END fs_start_at_multiple]\n }\n \n func createInQuery(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_filter_in]\n+\t// [START firestore_query_filter_in]\n \tcities := client.Collection(\"cities\")\n \tquery := cities.Where(\"country\", \"in\", []string{\"USA\", \"Japan\"}).Documents(ctx)\n+\t// [END firestore_query_filter_in]\n \t// [END fs_query_filter_in]\n \n \t_ = query",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -270,8 +312,10 @@\nfunc createInQuery(ctx context.Context, client *firestore.Client) error {\n \n func createInQueryWithArray(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_filter_in_with_array]\n+\t// [START firestore_query_filter_in_with_array]\n \tcities := client.Collection(\"cities\")\n \tquery := cities.Where(\"regions\", \"in\", [][]string{{\"west_coast\"}, {\"east_coast\"}}).Documents(ctx)\n+\t// [END firestore_query_filter_in_with_array]\n \t// [END fs_query_filter_in_with_array]\n \n \t_ = query",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -281,7 +325,9 @@\nfunc createInQueryWithArray(ctx context.Context, client *firestore.Client) error\n func createArrayContainsQuery(ctx context.Context, client *firestore.Client) error {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_array_contains_query]\n+\t// [START firestore_query_filter_array_contains]\n \tquery := cities.Where(\"regions\", \"array-contains\", \"west_coast\").Documents(ctx)\n+\t// [END firestore_query_filter_array_contains]\n \t// [END fs_array_contains_query]\n \n \t_ = query",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -290,8 +336,10 @@\nfunc createArrayContainsQuery(ctx context.Context, client *firestore.Client) err\n \n func createArrayContainsAnyQuery(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_query_filter_array_contains_any]\n+\t// [START firestore_query_filter_array_contains_any]\n \tcities := client.Collection(\"cities\")\n \tquery := cities.Where(\"regions\", \"array-contains-any\", []string{\"west_coast\", \"east_coast\"}).Documents(ctx)\n+\t// [END firestore_query_filter_array_contains_any]\n \t// [END fs_query_filter_array_contains_any]\n \n \t_ = query",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -25,39 +25,48 @@\nimport (\n \n func createDocReference(client *firestore.Client) {\n \t// [START fs_doc_reference]\n+\t// [START firestore_data_reference_document]\n \talovelaceRef := client.Collection(\"users\").Doc(\"alovelace\")\n+\t// [END firestore_data_reference_document]\n \t// [END fs_doc_reference]\n \n \t_ = alovelaceRef\n }\n \n func createCollectionReference(client *firestore.Client) {\n \t// [START fs_coll_reference]\n+\t// [START firestore_data_reference_collection]\n \tusersRef := client.Collection(\"users\")\n+\t// [END firestore_data_reference_collection]\n \t// [END fs_coll_reference]\n \n \t_ = usersRef\n }\n \n func createDocReferenceFromString(client *firestore.Client) {\n \t// [START fs_doc_reference_alternate]\n+\t// [START firestore_data_reference_document_path]\n \talovelaceRef := client.Doc(\"users/alovelace\")\n+\t// [END firestore_data_reference_document_path]\n \t// [END fs_doc_reference_alternate]\n \n \t_ = alovelaceRef\n }\n \n func createSubcollectionReference(client *firestore.Client) {\n \t// [START fs_subcoll_reference]\n+\t// [START firestore_data_reference_subcollection]\n \tmessageRef := client.Collection(\"rooms\").Doc(\"roomA\").\n \t\tCollection(\"messages\").Doc(\"message1\")\n+\t// [END firestore_data_reference_subcollection]\n \t// [END fs_subcoll_reference]\n \n \t_ = messageRef\n }\n \n func prepareRetrieve(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_retrieve_create_examples]\n+\t// [START firestore_data_get_dataset]\n \tcities := []struct {\n \t\tid string\n \t\tc  City",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -74,37 +83,43 @@\nfunc prepareRetrieve(ctx context.Context, client *firestore.Client) error {\n \t\t\treturn err\n \t\t}\n \t}\n+\t// [END firestore_data_get_dataset]\n \t// [END fs_retrieve_create_examples]\n \treturn nil\n }\n \n func docAsMap(ctx context.Context, client *firestore.Client) (map[string]interface{}, error) {\n \t// [START fs_get_doc_as_map]\n+\t// [START firestore_data_get_as_map]\n \tdsnap, err := client.Collection(\"cities\").Doc(\"SF\").Get(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \tm := dsnap.Data()\n \tfmt.Printf(\"Document data: %#v\\n\", m)\n+\t// [END firestore_data_get_as_map]\n \t// [END fs_get_doc_as_map]\n \treturn m, nil\n }\n \n func docAsEntity(ctx context.Context, client *firestore.Client) (*City, error) {\n \t// [START fs_get_doc_as_entity]\n+\t// [START firestore_data_get_as_custom_type]\n \tdsnap, err := client.Collection(\"cities\").Doc(\"BJ\").Get(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \tvar c City\n \tdsnap.DataTo(&c)\n \tfmt.Printf(\"Document data: %#v\\n\", c)\n+\t// [END firestore_data_get_as_custom_type]\n \t// [END fs_get_doc_as_entity]\n \treturn &c, nil\n }\n \n func multipleDocs(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_get_multiple_docs]\n+\t// [START firestore_data_query]\n \tfmt.Println(\"All capital cities:\")\n \titer := client.Collection(\"cities\").Where(\"capital\", \"==\", true).Documents(ctx)\n \tfor {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -117,12 +132,14 @@\nfunc multipleDocs(ctx context.Context, client *firestore.Client) error {\n \t\t}\n \t\tfmt.Println(doc.Data())\n \t}\n+\t// [END firestore_data_query]\n \t// [END fs_get_multiple_docs]\n \treturn nil\n }\n \n func allDocs(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_get_all_docs]\n+\t// [START firestore_data_get_all_documents]\n \tfmt.Println(\"All cities:\")\n \titer := client.Collection(\"cities\").Documents(ctx)\n \tfor {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/retrieve.go",
        "code_diff": "@@ -135,12 +152,14 @@\nfunc allDocs(ctx context.Context, client *firestore.Client) error {\n \t\t}\n \t\tfmt.Println(doc.Data())\n \t}\n+\t// [END firestore_data_get_all_documents]\n \t// [END fs_get_all_docs]\n \treturn nil\n }\n \n func getCollections(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_get_collections]\n+\t// [START firestore_data_get_sub_collections]\n \titer := client.Collection(\"cities\").Doc(\"SF\").Collections(ctx)\n \tfor {\n \t\tcollRef, err := iter.Next()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -27,6 +27,7 @@\nimport (\n \n func addDocAsMap(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_simple_doc_as_map]\n+\t// [START firestore_data_set_from_map]\n \t_, err := client.Collection(\"cities\").Doc(\"LA\").Set(ctx, map[string]interface{}{\n \t\t\"name\":    \"Los Angeles\",\n \t\t\"state\":   \"CA\",",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -36,12 +37,14 @@\nfunc addDocAsMap(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_from_map]\n \t// [END fs_add_simple_doc_as_map]\n \treturn err\n }\n \n func addDocDataTypes(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_doc_data_types]\n+\t// [START firestore_data_set_from_map_nested]\n \tdoc := make(map[string]interface{})\n \tdoc[\"stringExample\"] = \"Hello world!\"\n \tdoc[\"booleanExample\"] = true",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -59,24 +62,28 @@\nfunc addDocDataTypes(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_from_map_nested]\n \t// [END fs_add_doc_data_types]\n \treturn err\n }\n \n func addDocWithID(ctx context.Context, client *firestore.Client) error {\n \tvar data = make(map[string]interface{})\n \t// [START fs_add_doc_with_id]\n+\t// [START firestore_data_set_id_specified]\n \t_, err := client.Collection(\"cities\").Doc(\"new-city-id\").Set(ctx, data)\n \tif err != nil {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_id_specified]\n \t// [END fs_add_doc_with_id]\n \treturn err\n }\n \n func addDocWithoutID(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_doc_auto_id]\n+\t// [START firestore_data_set_id_random_collection]\n \t_, _, err := client.Collection(\"cities\").Add(ctx, map[string]interface{}{\n \t\t\"name\":    \"Tokyo\",\n \t\t\"country\": \"Japan\",",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -85,12 +92,14 @@\nfunc addDocWithoutID(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_id_random_collection]\n \t// [END fs_add_doc_auto_id]\n \treturn err\n }\n \n func addDocAsEntity(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_add_simple_doc_as_entity]\n+\t// [START firestore_data_set_from_custom_type]\n \tcity := City{\n \t\tName:    \"Los Angeles\",\n \t\tCountry: \"USA\",",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -100,6 +109,7 @@\nfunc addDocAsEntity(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_from_custom_type]\n \t// [END fs_add_simple_doc_as_entity]\n \treturn err\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -111,6 +121,7 @@\nfunc addDocAfterAutoGeneratedID(ctx context.Context, client *firestore.Client) e\n \t}\n \n \t// [START fs_add_doc_data_after_auto_id]\n+\t// [START firestore_data_set_id_random_document_ref]\n \tref := client.Collection(\"cities\").NewDoc()\n \n \t// later...",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -119,6 +130,7 @@\nfunc addDocAfterAutoGeneratedID(ctx context.Context, client *firestore.Client) e\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_id_random_document_ref]\n \t// [END fs_add_doc_data_after_auto_id]\n \treturn err\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -132,6 +144,7 @@\nfunc updateDoc(ctx context.Context, client *firestore.Client) error {\n \t\tlog.Printf(\"adding city DC: %s\", err)\n \t}\n \t// [START fs_update_doc]\n+\t// [START firestore_data_set_field]\n \t_, err = client.Collection(\"cities\").Doc(\"DC\").Update(ctx, []firestore.Update{\n \t\t{\n \t\t\tPath:  \"capital\",",
        "comments": [],
        "commit_messages": [
            "fix updateDoc tag"
        ],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -142,12 +155,14 @@\nfunc updateDoc(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_field]\n \t// [END fs_update_doc]\n \treturn err\n }\n \n func updateDocCreateIfMissing(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_update_create_if_missing]\n+\t// [START firestore_data_set_doc_upsert]\n \t_, err := client.Collection(\"cities\").Doc(\"BJ\").Set(ctx, map[string]interface{}{\n \t\t\"capital\": true,\n \t}, firestore.MergeAll)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -156,6 +171,7 @@\nfunc updateDocCreateIfMissing(ctx context.Context, client *firestore.Client) err\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_doc_upsert]\n \t// [END fs_update_create_if_missing]\n \treturn err\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -183,6 +199,7 @@\nfunc updateDocMultiple(ctx context.Context, client *firestore.Client) error {\n \n func updateDocNested(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_update_nested_fields]\n+\t// [START firestore_data_set_nested_fields]\n \tinitialData := map[string]interface{}{\n \t\t\"name\": \"Frank\",\n \t\t\"age\":  12,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -210,6 +227,7 @@\nfunc updateDocNested(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_nested_fields]\n \t// [END fs_update_nested_fields]\n \treturn err\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -223,30 +241,35 @@\nfunc updateDocServerTimestamp(ctx context.Context, client *firestore.Client) err\n \t}\n \n \t// [START fs_update_server_timestamp]\n+\t// [START firestore_data_set_server_timestamp]\n \t_, err := client.Collection(\"objects\").Doc(\"some-id\").Set(ctx, map[string]interface{}{\n \t\t\"timestamp\": firestore.ServerTimestamp,\n \t}, firestore.MergeAll)\n \tif err != nil {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_set_server_timestamp]\n \t// [END fs_update_server_timestamp]\n \treturn err\n }\n \n func deleteDoc(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_delete_doc]\n+\t// [START firestore_data_delete_doc]\n \t_, err := client.Collection(\"cities\").Doc(\"DC\").Delete(ctx)\n \tif err != nil {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_delete_doc]\n \t// [END fs_delete_doc]\n \treturn err\n }\n \n func deleteField(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_delete_field]\n+\t// [START firestore_data_delete_field]\n \t_, err := client.Collection(\"cities\").Doc(\"BJ\").Update(ctx, []firestore.Update{\n \t\t{\n \t\t\tPath:  \"capital\",",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -257,6 +280,7 @@\nfunc deleteField(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_data_delete_field]\n \t// [END fs_delete_field]\n \n \t// Use Set once this feature is implemented:",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -268,6 +292,7 @@\nfunc deleteField(ctx context.Context, client *firestore.Client) error {\n }\n \n // [START fs_delete_collection]\n+// [START firestore_data_delete_collection]\n func deleteCollection(ctx context.Context, client *firestore.Client,\n \tref *firestore.CollectionRef, batchSize int) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -306,6 +331,7 @@\nfunc deleteCollection(ctx context.Context, client *firestore.Client,\n \t}\n }\n \n+// [END firestore_data_delete_collection]\n // [END fs_delete_collection]\n \n func runSimpleTransaction(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -318,6 +344,7 @@\nfunc runSimpleTransaction(ctx context.Context, client *firestore.Client) error {\n \t}\n \n \t// [START fs_run_simple_transaction]\n+\t// [START firestore_transaction_document_update]\n \tref := client.Collection(\"cities\").Doc(\"SF\")\n \terr := client.RunTransaction(ctx, func(ctx context.Context, tx *firestore.Transaction) error {\n \t\tdoc, err := tx.Get(ref) // tx.Get, NOT ref.Get!",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -336,12 +363,14 @@\nfunc runSimpleTransaction(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors appropriately in this section.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_transaction_document_update]\n \t// [END fs_run_simple_transaction]\n \treturn err\n }\n \n func infoTransaction(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_return_info_transaction]\n+\t// [START firestore_transaction_document_update_conditional]\n \tref := client.Collection(\"cities\").Doc(\"SF\")\n \terr := client.RunTransaction(ctx, func(ctx context.Context, tx *firestore.Transaction) error {\n \t\tdoc, err := tx.Get(ref)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -364,12 +393,14 @@\nfunc infoTransaction(ctx context.Context, client *firestore.Client) error {\n \t\t// Handle any errors in an appropriate way, such as returning them.\n \t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n+\t// [END firestore_transaction_document_update_conditional]\n \t// [END fs_return_info_transaction]\n \treturn err\n }\n \n func batchWrite(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_batch_write]\n+\t// [START firestore_data_batch_writes]\n \t// Get a new write batch.\n \tbatch := client.Batch()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -15,6 +15,7 @@\npackage main\n \n // [START fs_counter_classes]\n+// [START firestore_solution_sharded_counter_custom_type]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -37,9 +38,11 @@\ntype Shard struct {\n \tCount int\n }\n \n+// [END firestore_solution_sharded_counter_custom_type]\n // [END fs_counter_classes]\n \n // [START fs_create_counter]\n+// [START firestore_solution_sharded_counter_create]\n \n // initCounter creates a given number of shards as\n // subcollection of specified document.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -57,9 +60,11 @@\nfunc (c *Counter) initCounter(ctx context.Context, docRef *firestore.DocumentRef\n \treturn nil\n }\n \n+// [END firestore_solution_sharded_counter_create]\n // [END fs_create_counter]\n \n // [START fs_increment_counter]\n+// [START firestore_solution_sharded_counter_increment]\n \n // incrementCounter increments a randomly picked shard.\n func (c *Counter) incrementCounter(ctx context.Context, docRef *firestore.DocumentRef) (*firestore.WriteResult, error) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "docs(firestore): normalize region tags",
        "pr_number": 1816,
        "file_name": "firestore/firestore_snippets/solution_counters.go",
        "code_diff": "@@ -71,9 +76,11 @@\nfunc (c *Counter) incrementCounter(ctx context.Context, docRef *firestore.Docume\n \t})\n }\n \n+// [END firestore_solution_sharded_counter_increment]\n // [END fs_increment_counter]\n \n // [START fs_get_count]\n+// [START firestore_solution_sharded_counter_get]\n \n // getCount returns a total count across all shards.\n func (c *Counter) getCount(ctx context.Context, docRef *firestore.DocumentRef) (int64, error) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2a096c01f3ab1cb27848e4144bca79608c17a577"
    },
    {
        "pr_title": "fix(appengine): Improve tasks/create_task test reliability",
        "pr_number": 1814,
        "file_name": "appengine/go11x/tasks/create_task/create_task_test.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage main\n \n import (\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_messages": [
            "fix(appengine): Improve tasks/create_task test reliability"
        ],
        "last_commit_sha": "a7c5a0d17876cc3e00629636ad10102437f585c9"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "eventarc/generic/main.go",
        "code_diff": "@@ -14,7 +14,7 @@\n// [START eventarc_generic_handler]\n \n-// Sample eventarc-generic is a Cloud Run service which logs and echos received requests.\n+// Sample generic is a Cloud Run service which logs and echos received requests.\n package main\n \n import (",
        "comments": [],
        "commit_messages": [
            "refactor: improve eventarc go samples\n\nSigned-off-by: Grant Timmerman <timmerman+devrel@google.com>"
        ],
        "last_commit_sha": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "eventarc/generic/main.go",
        "code_diff": "@@ -24,34 +24,32 @@\nimport (\n \t\"log\"\n \t\"net/http\"\n \t\"os\"\n+\t\"strings\"\n )\n \n-func logAndRespond(w http.ResponseWriter, msg string) {\n-\tlog.Println(msg)\n-\tfmt.Fprintln(w, msg)\n-}\n-\n // GenericHandler receives and echos a HTTP request's headers and body.\n func GenericHandler(w http.ResponseWriter, r *http.Request) {\n-\tlogAndRespond(w, \"Event received!\")\n+\tlog.Println(\"Event received!\")\n \n \t// Log all headers besides authorization header\n-\tlogAndRespond(w, \"HEADERS:\")\n-\tdelete(r.Header, \"Authorization\")\n+\tlog.Println(\"HEADERS:\")\n \theaderMap := make(map[string]string)\n \tfor k, v := range r.Header {\n-\t\theaderMap[k] = string(v[0])\n-\t\tlogAndRespond(w, fmt.Sprintf(\"%q: %q\\n\", k, v[0]))\n+\t\tif k != \"Authorization\" {\n+\t\t\tval := strings.Join(v, \",\")\n+\t\t\theaderMap[k] = val\n+\t\t\tlog.Println(fmt.Sprintf(\"%q: %q\\n\", k, val))\n+\t\t}\n \t}\n \n \t// Log body\n-\tlogAndRespond(w, \"BODY:\")\n+\tlog.Println(\"BODY:\")\n \tbodyBytes, err := ioutil.ReadAll(r.Body)\n \tif err != nil {\n \t\tlog.Printf(\"error parsing body: %v\", err)\n \t}\n \tbody := string(bodyBytes)\n-\tlogAndRespond(w, body)\n+\tlog.Println(body)\n \n \t// Format and print full output\n \ttype result struct {",
        "comments": [
            {
                "comment": "I'm a bit confused -- why write the body and heads above _and_ in JSON here? I might be missing something.",
                "position": 61
            },
            {
                "comment": "Should probably `log` the error.",
                "position": 63
            },
            {
                "comment": "Thanks for catching. You're right, we already respond here so no need to respond above.\r\n\r\nSimplified the sample a bit.",
                "position": 61
            },
            {
                "comment": "Now also logs the error.",
                "position": 63
            },
            {
                "comment": "```suggestion\r\n\t\thttp.Error(w, \"Could not marshal JSON output\", 500)\r\n\t\treturn\r\n```",
                "position": 63
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "refactor: improve eventarc go samples",
        "pr_number": 1788,
        "file_name": "eventarc/generic/main_test.go",
        "code_diff": "@@ -25,7 +25,7 @@\nimport (\n \t\"testing\"\n )\n \n-func TestGenericCloudEvent(t *testing.T) {\n+func TestGenericHandler(t *testing.T) {\n \ttests := []struct {\n \t\twant string\n \t\tomit string",
        "comments": [],
        "commit_messages": [
            "refactor: improve eventarc go samples\n\nSigned-off-by: Grant Timmerman <timmerman+devrel@google.com>"
        ],
        "last_commit_sha": "255bd5196e4386079771891dd17ce1d413a4a470"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -43,14 +43,15 @@\nfunc TestObjects(t *testing.T) {\n \tdefer client.Close()\n \n \tvar (\n-\t\tbucket                = tc.ProjectID + \"-samples-object-bucket-1\"\n-\t\tdstBucket             = tc.ProjectID + \"-samples-object-bucket-2\"\n-\t\tbucketVersioning      = tc.ProjectID + \"-bucket-versioning-enabled\"\n-\t\tobject1               = \"foo.txt\"\n-\t\tobject2               = \"foo/a.txt\"\n-\t\tobject3               = \"bar.txt\"\n-\t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers\n-\t\troleReader            = storage.RoleReader\n+\t\tbucket           = tc.ProjectID + \"-samples-object-bucket-1\"\n+\t\tdstBucket        = tc.ProjectID + \"-samples-object-bucket-2\"\n+\t\tbucketVersioning = tc.ProjectID + \"-bucket-versioning-enabled\"\n+\t\tobject1          = \"foo.txt\"\n+\t\tobject2          = \"foo/a.txt\"\n+\t\tobject3          = \"bar.txt\"\n+\t\tdstObj           = \"foobar.txt\"\n+\t\tallUsers         = storage.AllUsers\n+\t\troleReader       = storage.RoleReader\n \t)\n \n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -142,6 +143,21 @@\nfunc TestObjects(t *testing.T) {\n \t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)\n \t\t}\n \t}\n+\tt.Run(\"changeObjectStorageClass\", func(t *testing.T) {\n+\t\tbkt := client.Bucket(bucket)\n+\t\tobj := bkt.Object(object1)\n+\t\tif err := changeObjectStorageClass(ioutil.Discard, bucket, object1); err != nil {\n+\t\t\tt.Errorf(\"changeObjectStorageClass: %v\", err)\n+\t\t}\n+\t\twantStorageClass := \"COLDLINE\"\n+\t\toattrs, err := obj.Attrs(ctx)\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"obj.Attrs: %v\", err)\n+\t\t}\n+\t\tif oattrs.StorageClass != wantStorageClass {\n+\t\t\tt.Errorf(\"object storage class: got %q, want %q\", oattrs.StorageClass, wantStorageClass)\n+\t\t}\n+\t})\n \tif err := copyOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, object3, gen); err != nil {\n \t\tt.Fatalf(\"copyOldVersionOfObject: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -161,9 +177,18 @@\nfunc TestObjects(t *testing.T) {\n \tif err != nil {\n \t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n-\tif err := makePublic(ioutil.Discard, bucket, object1, allAuthenticatedUsers, roleReader); err != nil {\n-\t\tt.Errorf(\"makePublic: %v\", err)\n-\t}\n+\tt.Run(\"publicFile\", func(t *testing.T) {\n+\t\tif err := makePublic(ioutil.Discard, bucket, object1, allUsers, roleReader); err != nil {\n+\t\t\tt.Errorf(\"makePublic: %v\", err)\n+\t\t}\n+\t\tdata, err = downloadPublicFile(ioutil.Discard, bucket, object1)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"downloadPublicFile: %v\", err)\n+\t\t}\n+\t\tif got, want := string(data), \"Hello\\nworld\"; got != want {\n+\t\t\tt.Errorf(\"contents = %q; want %q\", got, want)\n+\t\t}\n+\t})\n \n \terr = moveFile(ioutil.Discard, bucket, object1)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "test for downloadPublicFile"
        ],
        "last_commit_sha": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -175,6 +200,19 @@\nfunc TestObjects(t *testing.T) {\n \tif err := copyFile(ioutil.Discard, dstBucket, bucket, object1); err != nil {\n \t\tt.Errorf(\"copyFile: %v\", err)\n \t}\n+\tt.Run(\"composeFile\", func(t *testing.T) {\n+\t\tif err := composeFile(ioutil.Discard, bucket, object1, object2, dstObj); err != nil {\n+\t\t\tt.Errorf(\"composeFile: %v\", err)\n+\t\t}\n+\t\tbkt := client.Bucket(bucket)\n+\t\tobj := bkt.Object(dstObj)\n+\t\t_, err = obj.Attrs(ctx)\n+\t\tif err == storage.ErrObjectNotExist {\n+\t\t\tt.Errorf(\"Destination object was not created\")\n+\t\t} else if err != nil {\n+\t\t\tt.Errorf(\"object.Attrs: %v\", err)\n+\t\t}\n+\t})\n \n \tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \tnewKey := []byte(\"My-secret-AES-256-encryption-key\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "feat(storage): add last samples part",
        "pr_number": 1784,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -201,10 +239,13 @@\nfunc TestObjects(t *testing.T) {\n \tif err := deleteFile(ioutil.Discard, bucket, object2); err != nil {\n \t\tt.Errorf(\"deleteFile: %v\", err)\n \t}\n+\to := client.Bucket(bucket).Object(dstObj)\n+\tif err := o.Delete(ctx); err != nil {\n+\t\tt.Errorf(\"Object(%q).Delete: %v\", dstObj, err)\n+\t}\n \tif err := disableVersioning(ioutil.Discard, bucketVersioning); err != nil {\n \t\tt.Fatalf(\"disableVersioning: %v\", err)\n \t}\n-\n \tbAttrs, err = bkt.Attrs(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketVersioning, err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ca13a4ca4054d4a9ae2b6e25081d55c4f04603f8"
    },
    {
        "pr_title": "test(spanner): increase timeout and cleanup test",
        "pr_number": 1771,
        "file_name": "spanner/spanner_leaderboard/leaderboard.go",
        "code_diff": "@@ -36,7 +36,27 @@\nimport (\n )\n \n type command func(ctx context.Context, w io.Writer, client *spanner.Client) error\n-type adminCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error\n+type uniqueRand struct {\n+\tused map[int64]bool\n+\trand *rand.Rand\n+}\n+\n+func newUniqueRand() uniqueRand {\n+\treturn uniqueRand{\n+\t\tused: map[int64]bool{},\n+\t\trand: rand.New(rand.NewSource(time.Now().UnixNano())),\n+\t}\n+}\n+\n+func (r *uniqueRand) rnd(min, max int64) int64 {\n+\tfor {\n+\t\trnd := r.rand.Int63n(max) + min\n+\t\tif !r.used[rnd] {\n+\t\t\tr.used[rnd] = true\n+\t\t\treturn rnd\n+\t\t}\n+\t}\n+}\n \n var (\n \tcommands = map[string]command{",
        "comments": [
            {
                "comment": "Does the player ID need to be an int? Can we use a UUID instead?",
                "position": 45
            },
            {
                "comment": "I don't think we should change that. This sample is used across all supported programming languages and uses the same data model for all of them.",
                "position": 45
            }
        ],
        "commit_messages": [
            "test(spanner): increase timeout and cleanup test\n\nInserting 800 rows as a single Batch DML statement can take a long time, and the\ntransaction can be aborted one or more times. The deadline used for such an operation\ntherefore needs to be (very) long. It is now increased to 10 minutes.\n\nFurthermore, the test case has been cleaned up a little bit:\n* The multiple deferred functions for cleaning up have been combined into one.\n* The database name is no longer fixed, allowing multiple instances of this test case\n  to be executed at the same time.\n* The generated player id's are now guaranteed to be unique. The previous version\n  generated random id values that could overlap (although the probability was extremely\n  low).\n\nFixes #1726"
        ],
        "last_commit_sha": "64d1e868afa8caa3254700151888719411ec082e"
    },
    {
        "pr_title": "test(spanner): increase timeout and cleanup test",
        "pr_number": 1771,
        "file_name": "spanner/spanner_leaderboard/leaderboard_test.go",
        "code_diff": "@@ -19,16 +19,23 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"os\"\n+\t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n+func randomID() string {\n+\tnow := time.Now().UTC()\n+\treturn fmt.Sprintf(\"%s-%s\", strconv.FormatInt(now.Unix(), 10), uuid.New().String()[:8])\n+}\n+\n func TestSample(t *testing.T) {\n-\ttc := testutil.EndToEndTest(t)\n+\ttestutil.EndToEndTest(t)\n \n \tinstance := os.Getenv(\"GOLANG_SAMPLES_SPANNER\")\n \tif instance == \"\" {",
        "comments": [],
        "commit_messages": [
            "test(spanner): increase timeout and cleanup test\n\nInserting 800 rows as a single Batch DML statement can take a long time, and the\ntransaction can be aborted one or more times. The deadline used for such an operation\ntherefore needs to be (very) long. It is now increased to 10 minutes.\n\nFurthermore, the test case has been cleaned up a little bit:\n* The multiple deferred functions for cleaning up have been combined into one.\n* The database name is no longer fixed, allowing multiple instances of this test case\n  to be executed at the same time.\n* The generated player id's are now guaranteed to be unique. The previous version\n  generated random id values that could overlap (although the probability was extremely\n  low).\n\nFixes #1726"
        ],
        "last_commit_sha": "64d1e868afa8caa3254700151888719411ec082e"
    },
    {
        "pr_title": "test(spanner): increase timeout and cleanup test",
        "pr_number": 1771,
        "file_name": "spanner/spanner_leaderboard/leaderboard_test.go",
        "code_diff": "@@ -37,16 +44,22 @@\nfunc TestSample(t *testing.T) {\n \tif !strings.HasPrefix(instance, \"projects/\") {\n \t\tt.Fatal(\"Spanner instance ref must be in the form of 'projects/PROJECT_ID/instances/INSTANCE_ID'\")\n \t}\n-\t// \"test-l-\" is different from the database name in snippet_test.go because\n-\t// this prevents from running against the same database.\n-\tdbName := fmt.Sprintf(\"%s/databases/test-l-%s\", instance, tc.ProjectID)\n+\tdbName := fmt.Sprintf(\"%s/databases/lb-%s\", instance, randomID())\n \n \tctx := context.Background()\n \tadminClient, dataClient := createClients(ctx, dbName)\n-\tdefer adminClient.Close()\n-\tdefer dataClient.Close()\n+\tdefer func() {\n+\t\tdataClient.Close()\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n+\t\t\t}\n+\t\t})\n+\t\tadminClient.Close()\n+\t}()\n \n-\t// Check for database existance prior to test start and delete, as resources may not have\n+\t// Check for database existence prior to test start and delete, as resources may not have\n \t// been cleaned up from previous invocations.\n \tif db, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: dbName}); err == nil {\n \t\tt.Logf(\"database %s exists in state %s. delete result: %v\", db.GetName(), db.GetState().String(),",
        "comments": [
            {
                "comment": "Can we insert fewer rows into the table to speed it up? I _think_ this is only used in a Codelab. So, I'm willing to have a less-robust test for the sake of reliability and speed.",
                "position": 61
            },
            {
                "comment": "I noticed that the test case is executing the `insertPlayers` and `insertScores` twice. AFAICT, there's no good reason for doing so, and reducing that to once for both methods will significantly reduce the total number of rows that are inserted (from 1600 to 400 for scores and from 200 to 100 for players). That should speed it up quite a bit.\r\n\r\nThe 10 minutes should be overkill in most cases. It seems that the deadline is most commonly exceeded if Spanner aborts the transaction a couple of times in a row, causing multiple retries.",
                "position": 61
            }
        ],
        "commit_messages": [
            "test(spanner): increase timeout and cleanup test\n\nInserting 800 rows as a single Batch DML statement can take a long time, and the\ntransaction can be aborted one or more times. The deadline used for such an operation\ntherefore needs to be (very) long. It is now increased to 10 minutes.\n\nFurthermore, the test case has been cleaned up a little bit:\n* The multiple deferred functions for cleaning up have been combined into one.\n* The database name is no longer fixed, allowing multiple instances of this test case\n  to be executed at the same time.\n* The generated player id's are now guaranteed to be unique. The previous version\n  generated random id values that could overlap (although the probability was extremely\n  low).\n\nFixes #1726"
        ],
        "last_commit_sha": "64d1e868afa8caa3254700151888719411ec082e"
    },
    {
        "pr_title": "test(spanner): increase timeout and cleanup test",
        "pr_number": 1771,
        "file_name": "spanner/spanner_leaderboard/leaderboard_test.go",
        "code_diff": "@@ -61,8 +74,8 @@\nfunc TestSample(t *testing.T) {\n \trunCommand := func(t *testing.T, cmd string, dbName string, timespan int) string {\n \t\tt.Helper()\n \t\tvar b bytes.Buffer\n-\t\t// Set timeout to 60s so it should avoid DeadlineExceeded error.\n-\t\tcctx, cancel := context.WithTimeout(ctx, 60000*time.Millisecond)\n+\t\t// Set timeout to 600 seconds so it should avoid DeadlineExceeded error.\n+\t\tcctx, cancel := context.WithTimeout(ctx, 600*time.Second)\n \t\tdefer cancel()\n \t\tif err := run(cctx, adminClient, dataClient, &b, cmd, dbName, timespan); err != nil {\n \t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)",
        "comments": [],
        "commit_messages": [
            "test(spanner): increase timeout and cleanup test\n\nInserting 800 rows as a single Batch DML statement can take a long time, and the\ntransaction can be aborted one or more times. The deadline used for such an operation\ntherefore needs to be (very) long. It is now increased to 10 minutes.\n\nFurthermore, the test case has been cleaned up a little bit:\n* The multiple deferred functions for cleaning up have been combined into one.\n* The database name is no longer fixed, allowing multiple instances of this test case\n  to be executed at the same time.\n* The generated player id's are now guaranteed to be unique. The previous version\n  generated random id values that could overlap (although the probability was extremely\n  low).\n\nFixes #1726"
        ],
        "last_commit_sha": "64d1e868afa8caa3254700151888719411ec082e"
    },
    {
        "pr_title": "fix(dialogflow): remove the cmd options",
        "pr_number": 1770,
        "file_name": "dialogflow/intent_management/intent_management.go",
        "code_diff": "@@ -12,18 +12,13 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package intentmgmt\n \n // [START import_libraries]\n import (\n \t\"context\"\n \t\"errors\"\n-\t\"flag\"\n \t\"fmt\"\n-\t\"log\"\n-\t\"os\"\n-\t\"path/filepath\"\n-\t\"strings\"\n \n \tdialogflow \"cloud.google.com/go/dialogflow/apiv2\"\n \t\"google.golang.org/api/iterator\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "f566e91464dfeae14f23b314e29349b0d43054ca"
    },
    {
        "pr_title": "refactor(logging): debrand stackdriver logging in favor of cloud logging",
        "pr_number": 1766,
        "file_name": "logging/logging_quickstart/main.go",
        "code_diff": "@@ -14,7 +14,7 @@\n// [START logging_quickstart]\n \n-// Sample logging-quickstart writes a log entry to Stackdriver Logging.\n+// Sample logging-quickstart writes a log entry to Cloud Logging.\n package main\n \n import (",
        "comments": [],
        "commit_messages": [
            "refactor(logging): debrand stackdriver logging in favor of cloud logging"
        ],
        "last_commit_sha": "fe44723340ca5073b072d8d3209cbfa71689fc36"
    },
    {
        "pr_title": "refactor(logging): debrand stackdriver logging in favor of cloud logging",
        "pr_number": 1766,
        "file_name": "logging/stdlogging/main.go",
        "code_diff": "@@ -14,7 +14,7 @@\n// [START logging_stdlogging]\n \n-// Sample stdlogging writes log.Logger logs to the Stackdriver Logging.\n+// Sample stdlogging writes log.Logger logs to the Cloud Logging.\n package main\n \n import (",
        "comments": [],
        "commit_messages": [
            "refactor(logging): debrand stackdriver logging in favor of cloud logging"
        ],
        "last_commit_sha": "fe44723340ca5073b072d8d3209cbfa71689fc36"
    },
    {
        "pr_title": "refactor(logging): debrand stackdriver logging in favor of cloud logging",
        "pr_number": 1766,
        "file_name": "run/logging-manual/main.go",
        "code_diff": "@@ -59,11 +59,11 @@\ntype Entry struct {\n \tSeverity string `json:\"severity,omitempty\"`\n \tTrace    string `json:\"logging.googleapis.com/trace,omitempty\"`\n \n-\t// Stackdriver Log Viewer allows filtering and display of this as `jsonPayload.component`.\n+\t// Cloud Log Viewer allows filtering and display of this as `jsonPayload.component`.\n \tComponent string `json:\"component,omitempty\"`\n }\n \n-// String renders an entry structure to the JSON format expected by Stackdriver.\n+// String renders an entry structure to the JSON format expected by Cloud Logging.\n func (e Entry) String() string {\n \tif e.Severity == \"\" {\n \t\te.Severity = \"INFO\"",
        "comments": [],
        "commit_messages": [
            "refactor(logging): debrand stackdriver logging in favor of cloud logging"
        ],
        "last_commit_sha": "fe44723340ca5073b072d8d3209cbfa71689fc36"
    },
    {
        "pr_title": "fix(bigquery):  minor refactor to avoid pushback failures",
        "pr_number": 1764,
        "file_name": "bigquery/snippets/table/integration_test.go",
        "code_diff": "@@ -150,6 +150,12 @@\nfunc TestTables(t *testing.T) {\n \tif err := updateTableAddColumn(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"updateTableAddColumn(%q %q): %v\", testDatasetID, testTableID, err)\n \t}\n+\n+\t// Change tables to avoid hitting metadata update limits in a short period.\n+\ttestTableID, err = bqtestutil.UniqueBQName(\"testtable\")\n+\tif err := createTableExplicitSchema(tc.ProjectID, testDatasetID, testTableID); err != nil {\n+\t\tt.Fatalf(\"createTableExplicitSchema(%q %q): %v\", testDatasetID, testTableID, err)\n+\t}\n \tif err := addTableLabel(tc.ProjectID, testDatasetID, testTableID); err != nil {\n \t\tt.Fatalf(\"addTableLabel(%q %q): %v\", testDatasetID, testTableID, err)\n \t}",
        "comments": [],
        "commit_messages": [
            "fix(bigquery):  minor refactor to avoid pushback failures\n\nCurrently, table snippet tests mutate metadata for a table serially.\nRecently, changes to how mutation pushback work in the backend are\ncausing intermittent failures.  The pushback is significant enough\nthat retries are insufficient to address this with the table snippet\ntests.\n\nThis change addresses the problem by directing some of the mutation\nexamples to modify an additional BigQuery table."
        ],
        "last_commit_sha": "db96e981207e32811c19fe00b47fc5ab5519e667"
    },
    {
        "pr_title": "pubsub: fix error in the concurrency example.",
        "pr_number": 1753,
        "file_name": "pubsub/subscriptions/pull_concurrency.go",
        "code_diff": "@@ -18,14 +18,14 @@\npackage subscriptions\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"io\"\n \t\"runtime\"\n+\t\"sync/atomic\"\n \t\"time\"\n \n \t\"cloud.google.com/go/pubsub\"\n )\n \n-func pullMsgsConcurrenyControl(w io.Writer, projectID, subID string) error {\n+func pullMsgsConcurrenyControl(counter *int32, projectID, subID string) error {\n \t// projectID := \"my-project-id\"\n \t// subID := \"my-sub\"\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "pubsub: fix error in the concurrency example\n\nThe current example is processing all the messages in a single goroutine\nand is NOT concurrent.\n\nTo make tests pass, use a counter that can be incremented concurrently."
        ],
        "last_commit_sha": "5361f14af0d9e3d4ce6369af303b101cd4b7ab05"
    },
    {
        "pr_title": "refactor(functions/tips/contexttip): contexttip sample for pubsub publish",
        "pr_number": 1751,
        "file_name": "functions/tips/contexttip/context_tip.go",
        "code_diff": "@@ -14,6 +14,7 @@\n// [START functions_golang_context]\n // [START functions_tips_gcp_apis]\n+// [START functions_pubsub_setup]\n \n // Package contexttip is an example of how to use Pub/Sub and context.Context in\n // a Cloud Function.",
        "comments": [],
        "commit_messages": [
            "refactor(functions/tips/contexttip): adjust contexttip sample for pubsub publish reuse"
        ],
        "last_commit_sha": "26e0890fc367a849344836065fc4df18252ed0ec"
    },
    {
        "pr_title": "refactor(functions/tips/contexttip): contexttip sample for pubsub publish",
        "pr_number": 1751,
        "file_name": "functions/tips/contexttip/context_tip.go",
        "code_diff": "@@ -23,7 +24,6 @@\nimport (\n \t\"context\"\n \t\"encoding/json\"\n \t\"fmt\"\n-\t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"",
        "comments": [],
        "commit_messages": [
            "refactor(functions/tips/contexttip): adjust contexttip sample for pubsub publish reuse"
        ],
        "last_commit_sha": "26e0890fc367a849344836065fc4df18252ed0ec"
    },
    {
        "pr_title": "refactor(functions/tips/contexttip): contexttip sample for pubsub publish",
        "pr_number": 1751,
        "file_name": "functions/tips/contexttip/context_tip.go",
        "code_diff": "@@ -49,31 +49,36 @@\nfunc init() {\n \t}\n }\n \n+// [END functions_pubsub_setup]\n+\n+// [START functions_pubsub_publish]\n+\n type publishRequest struct {\n-\tTopic string `json:\"topic\"`\n+\tTopic   string `json:\"topic\"`\n+\tMessage string `json:\"message\"`\n }\n \n // PublishMessage publishes a message to Pub/Sub. PublishMessage only works\n // with topics that already exist.\n func PublishMessage(w http.ResponseWriter, r *http.Request) {\n-\t// Read the request body.\n-\tdata, err := ioutil.ReadAll(r.Body)\n-\tif err != nil {\n-\t\tlog.Printf(\"ioutil.ReadAll: %v\", err)\n-\t\thttp.Error(w, \"Error reading request\", http.StatusBadRequest)\n+\t// Parse the request body to get the topic name and message.\n+\tp := publishRequest{}\n+\n+\tif err := json.NewDecoder(r.Body).Decode(&p); err != nil {\n+\t\tlog.Printf(\"json.NewDecoder: %v\", err)\n+\t\thttp.Error(w, \"Error parsing request\", http.StatusBadRequest)\n \t\treturn\n \t}\n \n-\t// Parse the request body to get the topic name.\n-\tp := publishRequest{}\n-\tif err := json.Unmarshal(data, &p); err != nil {\n-\t\tlog.Printf(\"json.Unmarshal: %v\", err)\n-\t\thttp.Error(w, \"Error parsing request\", http.StatusBadRequest)\n+\tif p.Topic == \"\" || p.Message == \"\" {\n+\t\ts := \"missing 'topic' or 'message' parameter\"\n+\t\tlog.Println(s)\n+\t\thttp.Error(w, s, http.StatusBadRequest)\n \t\treturn\n \t}\n \n \tm := &pubsub.Message{\n-\t\tData: []byte(\"Test message\"),\n+\t\tData: []byte(p.Message),\n \t}\n \t// Publish and Get use r.Context() because they are only needed for this\n \t// function invocation. If this were a background function, they would use",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "26e0890fc367a849344836065fc4df18252ed0ec"
    },
    {
        "pr_title": "refactor(functions/tips/contexttip): contexttip sample for pubsub publish",
        "pr_number": 1751,
        "file_name": "functions/tips/contexttip/context_tip_test.go",
        "code_diff": "@@ -26,8 +26,6 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n )\n \n-const topicName = \"functions-test-topic\"\n-\n func TestPublishMessage(t *testing.T) {\n \t// TODO: Use testutil to get the project.\n \tprojectID = os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")",
        "comments": [],
        "commit_messages": [
            "refactor(functions/tips/contexttip): adjust contexttip sample for pubsub publish reuse"
        ],
        "last_commit_sha": "26e0890fc367a849344836065fc4df18252ed0ec"
    },
    {
        "pr_title": "refactor(functions/tips/contexttip): contexttip sample for pubsub publish",
        "pr_number": 1751,
        "file_name": "functions/tips/contexttip/context_tip_test.go",
        "code_diff": "@@ -42,6 +40,11 @@\nfunc TestPublishMessage(t *testing.T) {\n \t\tt.Fatalf(\"pubsub.NewClient: %v\", err)\n \t}\n \n+\ttopicName := os.Getenv(\"FUNCTIONS_TOPIC_NAME\")\n+\tif topicName == \"\" {\n+\t\ttopicName = \"functions-test-topic\"\n+\t}\n+\n \ttopic := client.Topic(topicName)\n \texists, err := topic.Exists(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "refactor(functions/tips/contexttip): adjust contexttip sample for pubsub publish reuse"
        ],
        "last_commit_sha": "26e0890fc367a849344836065fc4df18252ed0ec"
    },
    {
        "pr_title": "feat(pubsub): add attributes sample and cleanup region tags",
        "pr_number": 1744,
        "file_name": "pubsub/topics/publish.go",
        "code_diff": "@@ -14,7 +14,6 @@\npackage topics\n \n-// [START pubsub_publish]\n // [START pubsub_quickstart_publisher]\n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "feat(pubsub): add attributes sample and cleanup region tags"
        ],
        "last_commit_sha": "6c41521f833fb813b07d057d6a74680aa2358491"
    },
    {
        "pr_title": "feat(pubsub): add attributes sample and cleanup region tags",
        "pr_number": 1744,
        "file_name": "pubsub/topics/publish_scale.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage topics\n \n-// [START pubsub_publish_with_error_handling_that_scales]\n+// [START pubsub_publish_with_error_handler]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "feat(pubsub): add attributes sample and cleanup region tags"
        ],
        "last_commit_sha": "6c41521f833fb813b07d057d6a74680aa2358491"
    },
    {
        "pr_title": "testing(run): add retry behavior to cloudrunci gcloud commands",
        "pr_number": 1741,
        "file_name": "internal/cloudrunci/gcloud.go",
        "code_diff": "@@ -21,6 +21,9 @@\nimport (\n \t\"os\"\n \t\"os/exec\"\n \t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n // gcloudBin is the path to the gcloud executable.",
        "comments": [],
        "commit_messages": [
            "testing(cloudrunci): add retry behavior to gcloud commands"
        ],
        "last_commit_sha": "ec2f33a8658029618e882504d4e28578a844bfc3"
    },
    {
        "pr_title": "testing(run): add retry behavior to cloudrunci gcloud commands",
        "pr_number": 1741,
        "file_name": "internal/cloudrunci/gcloud_test.go",
        "code_diff": "@@ -15,6 +15,9 @@\npackage cloudrunci\n \n import (\n+\t\"io/ioutil\"\n+\t\"log\"\n+\t\"os\"\n \t\"os/exec\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ec2f33a8658029618e882504d4e28578a844bfc3"
    },
    {
        "pr_title": "feat(storage): sample gap (1/2 object part)",
        "pr_number": 1722,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -48,6 +48,7 @@\nfunc TestObjects(t *testing.T) {\n \t\tbucketVersioning      = tc.ProjectID + \"-bucket-versioning-enabled\"\n \t\tobject1               = \"foo.txt\"\n \t\tobject2               = \"foo/a.txt\"\n+\t\tobject3               = \"bar.txt\"\n \t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers\n \t\troleReader            = storage.RoleReader\n \t)",
        "comments": [],
        "commit_messages": [
            "new object name generation samples"
        ],
        "last_commit_sha": "808d0e9f9ec93d58a5f35163c6d1db0d17ef71e4"
    },
    {
        "pr_title": "feat(storage): sample gap (1/2 object part)",
        "pr_number": 1722,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -56,13 +57,8 @@\nfunc TestObjects(t *testing.T) {\n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, dstBucket)\n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketVersioning)\n \n-\t{\n-\t\t// Enable versioning\n-\t\tattr := storage.BucketAttrsToUpdate{VersioningEnabled: true}\n-\t\t_, err := client.Bucket(bucketVersioning).Update(ctx, attr)\n-\t\tif err != nil {\n-\t\t\tt.Fatalf(\"storage.BucketAttrsToUpdate{VersioningEnabled: true}: %v\", err)\n-\t\t}\n+\tif err := enableVersioning(ioutil.Discard, bucketVersioning); err != nil {\n+\t\tt.Fatalf(\"enableVersioning: %v\", err)\n \t}\n \n \tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {",
        "comments": [],
        "commit_messages": [
            "docs(sample): enable versioning"
        ],
        "last_commit_sha": "808d0e9f9ec93d58a5f35163c6d1db0d17ef71e4"
    },
    {
        "pr_title": "feat(storage): sample gap (1/2 object part)",
        "pr_number": 1722,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -75,6 +71,20 @@\nfunc TestObjects(t *testing.T) {\n \tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n \t}\n+\t// Check enableVersioning correctly work.\n+\tbkt := client.Bucket(bucketVersioning)\n+\tbAttrs, err := bkt.Attrs(ctx)\n+\tif !bAttrs.VersioningEnabled {\n+\t\tt.Fatalf(\"object versioning is not enabled\")\n+\t}\n+\tobj := bkt.Object(object1)\n+\tattrs, err := obj.Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Object(%q).Attrs: %v\", bucketVersioning, object1, err)\n+\t}\n+\t// Keep the original generation of object1 before re-uploading\n+\t// to use in the versioning samples.\n+\tgen := attrs.Generation\n \tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n \t}",
        "comments": [
            {
                "comment": "Can we check that versioning was disabled?",
                "position": 75
            },
            {
                "comment": "Done",
                "position": 75
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "808d0e9f9ec93d58a5f35163c6d1db0d17ef71e4"
    },
    {
        "pr_title": "feat(storage): sample gap (1/2 object part)",
        "pr_number": 1722,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -132,7 +142,13 @@\nfunc TestObjects(t *testing.T) {\n \t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)\n \t\t}\n \t}\n-\n+\tif err := copyOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, object3, gen); err != nil {\n+\t\tt.Fatalf(\"copyOldVersionOfObject: %v\", err)\n+\t}\n+\t// Delete the first version of an object1 for a bucketVersioning.\n+\tif err := deleteOldVersionOfObject(ioutil.Discard, bucketVersioning, object1, gen); err != nil {\n+\t\tt.Fatalf(\"deleteOldVersionOfObject: %v\", err)\n+\t}\n \tdata, err := downloadFile(ioutil.Discard, bucket, object1)\n \tif err != nil {\n \t\tt.Fatalf(\"downloadFile: %v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "808d0e9f9ec93d58a5f35163c6d1db0d17ef71e4"
    },
    {
        "pr_title": "feat(storage): sample gap (1/2 object part)",
        "pr_number": 1722,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -163,6 +179,9 @@\nfunc TestObjects(t *testing.T) {\n \tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \tnewKey := []byte(\"My-secret-AES-256-encryption-key\")\n \n+\tif err := generateEncryptionKey(ioutil.Discard); err != nil {\n+\t\tt.Errorf(\"generateEncryptionKey: %v\", err)\n+\t}\n \tif err := uploadEncryptedFile(ioutil.Discard, bucket, object1, key); err != nil {\n \t\tt.Errorf(\"uploadEncryptedFile: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "storage_generate_encryption_key"
        ],
        "last_commit_sha": "808d0e9f9ec93d58a5f35163c6d1db0d17ef71e4"
    },
    {
        "pr_title": "feat(storage): sample gap",
        "pr_number": 1706,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -25,8 +25,10 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\tiampb \"google.golang.org/genproto/googleapis/iam/v1\"\n )\n \n func TestCreate(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "385feba29d94923947b6342db98d626b91a20e2b"
    },
    {
        "pr_title": "feat(storage): sample gap",
        "pr_number": 1706,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -124,6 +126,46 @@\nfunc TestIAM(t *testing.T) {\n \t\tt.Errorf(\"removeBucketConditionalIAMBinding: %v\", err)\n \t}\n }\n+func TestCORSConfiguration(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n+\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n+\twant := []storage.CORS{\n+\t\t{\n+\t\t\tMaxAge:          time.Hour,\n+\t\t\tMethods:         []string{\"GET\"},\n+\t\t\tOrigins:         []string{\"some-origin.com\"},\n+\t\t\tResponseHeaders: []string{\"Content-Type\"},\n+\t\t},\n+\t}\n+\tif err := setBucketCORSConfiguration(ioutil.Discard, bucketName, want[0].MaxAge, want[0].Methods, want[0].Origins, want[0].ResponseHeaders); err != nil {\n+\t\tt.Fatalf(\"setBucketCORSConfiguration: %v\", err)\n+\t}\n+\tattrs, err := client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif !reflect.DeepEqual(attrs.CORS, want) {\n+\t\tt.Fatalf(\"Unexpected CORS Configuration: got: %v, want: %v\", attrs.CORS, want)\n+\t}\n+\tif err := removeBucketCORSConfiguration(ioutil.Discard, bucketName); err != nil {\n+\t\tt.Fatalf(\"removeBucketCORSConfiguration: %v\", err)\n+\t}\n+\tattrs, err = client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif attrs.CORS != nil {\n+\t\tt.Fatalf(\"Unexpected CORS Configuration: got: %v, want: %v\", attrs.CORS, []storage.CORS{})\n+\t}\n+}\n \n func TestRequesterPays(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "385feba29d94923947b6342db98d626b91a20e2b"
    },
    {
        "pr_title": "feat(storage): sample gap",
        "pr_number": 1706,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -144,6 +186,15 @@\nfunc TestKMS(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbucketName := tc.ProjectID + \"-storage-buckets-tests\"\n \n+\tctx := context.Background()\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketName)\n+\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")\n \tcryptoKeyID := os.Getenv(\"GOLANG_SAMPLES_KMS_CRYPTOKEY\")",
        "comments": [],
        "commit_messages": [
            "check kms key"
        ],
        "last_commit_sha": "385feba29d94923947b6342db98d626b91a20e2b"
    },
    {
        "pr_title": "feat(storage): sample gap",
        "pr_number": 1706,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -153,7 +204,24 @@\nfunc TestKMS(t *testing.T) {\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \tif err := setBucketDefaultKMSKey(ioutil.Discard, bucketName, kmsKeyName); err != nil {\n-\t\tt.Fatalf(\"setBucketDefaultKmsKey: failed to enable default kms key (%q): %v\", kmsKeyName, err)\n+\t\tt.Fatalf(\"setBucketDefaultKMSKey: failed to enable default KMS key (%q): %v\", kmsKeyName, err)\n+\t}\n+\tattrs, err := client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif attrs.Encryption.DefaultKMSKeyName != kmsKeyName {\n+\t\tt.Fatalf(\"Default KMS key was not set correctly: got %v, want %v\", attrs.Encryption.DefaultKMSKeyName, kmsKeyName)\n+\t}\n+\tif err := removeBucketDefaultKMSKey(ioutil.Discard, bucketName); err != nil {\n+\t\tt.Fatalf(\"removeBucketDefaultKMSKey: failed to remove default KMS key: %v\", err)\n+\t}\n+\tattrs, err = client.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n+\t}\n+\tif attrs.Encryption != nil {\n+\t\tt.Fatalf(\"Default KMS key was not removed from a bucket(%v)\", bucketName)\n \t}\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "385feba29d94923947b6342db98d626b91a20e2b"
    },
    {
        "pr_title": "feat(storage): sample gap",
        "pr_number": 1706,
        "file_name": "storage/buckets/get_bucket_policy.go",
        "code_diff": "@@ -14,7 +14,7 @@\npackage buckets\n \n-// [START storage_get_bucket_policy]\n+// [START storage_view_bucket_iam_members]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "storage_view_bucket_iam_members: tag, use V3"
        ],
        "last_commit_sha": "385feba29d94923947b6342db98d626b91a20e2b"
    },
    {
        "pr_title": "feat(storage): sample gap",
        "pr_number": 1706,
        "file_name": "storage/buckets/get_bucket_policy.go",
        "code_diff": "@@ -26,7 +26,7 @@\nimport (\n )\n \n // getBucketPolicy gets the bucket IAM policy.\n-func getBucketPolicy(w io.Writer, bucketName string) (*iam.Policy, error) {\n+func getBucketPolicy(w io.Writer, bucketName string) (*iam.Policy3, error) {\n \t// bucketName := \"bucket-name\"\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)",
        "comments": [],
        "commit_messages": [
            "storage_view_bucket_iam_members: tag, use V3"
        ],
        "last_commit_sha": "385feba29d94923947b6342db98d626b91a20e2b"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/markdown-preview/renderer/main_test.go",
        "code_diff": "@@ -15,15 +15,9 @@\npackage main\n \n import (\n-\t\"io/ioutil\"\n-\t\"net/http\"\n \t\"net/http/httptest\"\n \t\"strings\"\n \t\"testing\"\n-\t\"time\"\n-\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/cloudrunci\"\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n var tests = []struct {",
        "comments": [],
        "commit_messages": [
            "run: package naming and minor test fixes"
        ],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/events_pubsub.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/events_storage.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/grpc_ping.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main_test\n+package cloudruntests\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/grpc_server_streaming.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main_test\n+package cloudruntests\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/hello_broken.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/helloworld.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main_test\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "refactor(run/helloworld): move e2e tests to run/testing"
        ],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/helloworld.e2e_test.go",
        "code_diff": "@@ -30,6 +30,7 @@\nfunc TestHelloworldService(t *testing.T) {\n \n \tservice := cloudrunci.NewService(\"helloworld\", tc.ProjectID)\n \tservice.Env = cloudrunci.EnvVars{\"NAME\": \"Override\"}\n+\tservice.Dir = \"../helloworld\"\n \tif err := service.Deploy(); err != nil {\n \t\tt.Fatalf(\"service.Deploy %q: %v\", service.Name, err)\n \t}",
        "comments": [],
        "commit_messages": [
            "refactor(run/helloworld): move e2e tests to run/testing"
        ],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/image_processing.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/logging_manual.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/markdown_preview_editor.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/pubsub.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "refactor(run): move e2e tests to separate testing directory",
        "pr_number": 1681,
        "file_name": "run/testing/system_package.e2e_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package cloudruntests\n \n import (\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9a7ebec41692deb8dcf462225a9b6425dcf8e4bc"
    },
    {
        "pr_title": "fix(bigtable): add retry for writing data test",
        "pr_number": 1630,
        "file_name": "bigtable/writes/writes_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/bigtable\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"",
        "comments": [],
        "commit_messages": [
            "lint"
        ],
        "last_commit_sha": "3376870f2cc71961852cc041489033fd7cb68443"
    },
    {
        "pr_title": "feat(run/events): Run Events Quickstarts",
        "pr_number": 1621,
        "file_name": "run/events_pubsub/main.go",
        "code_diff": "@@ -12,38 +12,47 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START run_events_pubsub_server]\n+// [START run_events_pubsub_handler]\n \n-// Sample run-pubsub-events is a Cloud Run service which handles Pub/Sub messages.\n+// Sample run-events-pubsub is a Cloud Run service which handles Pub/Sub messages.\n package main\n \n import (\n-\t\"context\"\n+\t\"encoding/json\"\n \t\"fmt\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"\n-\n-\tcloudevents \"github.com/cloudevents/sdk-go/v2\"\n )\n \n-var (\n-\thandler = http.DefaultServeMux\n-)\n+// PubSubMessage is the payload of a Pub/Sub event.\n+type PubSubMessage struct {\n+\tMessage struct {\n+\t\tData []byte `json:\"data,omitempty\"`\n+\t\tID   string `json:\"id\"`\n+\t} `json:\"message\"`\n+\tSubscription string `json:\"subscription\"`\n+}\n \n-func main() {\n-\tctx := context.Background()\n-\t// Create a new HTTP client for CloudEvents\n-\tp, err := cloudevents.NewHTTP()\n-\tif err != nil {\n-\t\tlog.Fatal(err)\n+// HelloEventsPubSub receives and processes a Pub/Sub push message.\n+func HelloEventsPubSub(w http.ResponseWriter, r *http.Request) {\n+\tvar e PubSubMessage\n+\tif err := json.NewDecoder(r.Body).Decode(&e); err != nil {\n+\t\thttp.Error(w, \"Bad HTTP Request\", http.StatusBadRequest)\n+\t\tlog.Printf(\"Bad HTTP Request: %v\", http.StatusBadRequest)\n+\t\treturn\n \t}\n-\thandleFn, err := cloudevents.NewHTTPReceiveHandler(ctx, p, HelloPubSub)\n-\tif err != nil {\n-\t\tlog.Fatal(err)\n+\tname := string(e.Message.Data)\n+\tif name == \"\" {\n+\t\tname = \"World\"\n \t}\n-\thandler.Handle(\"/\", handleFn)\n+\ts := fmt.Sprintf(\"Hello, %s! ID: %s\", name, string(r.Header.Get(\"Ce-Id\")))\n+\tlog.Printf(s)\n+\tfmt.Fprintln(w, s)\n+}\n \n+func main() {\n+\thttp.HandleFunc(\"/\", HelloEventsPubSub)\n \t// Determine port for HTTP service.\n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "e5635ef10e2009146c14ecd360494c80f9244111"
    },
    {
        "pr_title": "feat(run/markdown-preview): use client library to mint identity tokens",
        "pr_number": 1617,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -17,12 +17,14 @@\npackage main\n // [START run_secure_request]\n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"net/http\"\n \t\"time\"\n \n-\t\"cloud.google.com/go/compute/metadata\"\n+\t\"golang.org/x/oauth2\"\n+\t\"google.golang.org/api/idtoken\"\n )\n \n // RenderService represents our upstream render service.",
        "comments": [],
        "commit_messages": [
            "feat(run/markdown-preview): use client library to mint identity tokens"
        ],
        "last_commit_sha": "68038dd765f434f9907174acdb70d66dde8c7908"
    },
    {
        "pr_title": "feat(run/markdown-preview): use client library to mint identity tokens",
        "pr_number": 1617,
        "file_name": "run/markdown-preview/editor/render.go",
        "code_diff": "@@ -31,10 +33,12 @@\ntype RenderService struct {\n \tURL string\n \t// Authenticated determines whether identity token authentication will be used.\n \tAuthenticated bool\n+\t// tokenSource provides an identity token for requests to the Render Service.\n+\ttokenSource oauth2.TokenSource\n }\n \n-// NewRequest creates a new HTTP request with IAM ID Token credential.\n-// This token is automatically handled by private Cloud Run (fully managed) and Cloud Functions.\n+// NewRequest creates a new HTTP request to the Render service.\n+// If authentication is enabled, an Identity Token is created and added.\n func (s *RenderService) NewRequest(method string) (*http.Request, error) {\n \treq, err := http.NewRequest(method, s.URL, nil)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "68038dd765f434f9907174acdb70d66dde8c7908"
    },
    {
        "pr_title": "pubsub: add subscription detach samples",
        "pr_number": 1604,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -456,6 +456,9 @@\nfunc TestPullMsgsDeadLetterDeliveryAttempts(t *testing.T) {\n \t\t\tMaxDeliveryAttempts: 10,\n \t\t},\n \t})\n+\tif err != nil {\n+\t\tt.Fatalf(\"getOrCreateSub: %v\", err)\n+\t}\n \tdefer sub.Delete(ctx)\n \n \tif err = publishMsgs(ctx, deadLetterSourceTopic, 1); err != nil {",
        "comments": [],
        "commit_messages": [
            "pubsub: add detach subscription samples"
        ],
        "last_commit_sha": "455044b8351f67b11897de911b19247c64695515"
    },
    {
        "pr_title": "storage: listing noncurrent object versions",
        "pr_number": 1585,
        "file_name": "internal/testutil/storage_cleaner.go",
        "code_diff": "@@ -58,8 +58,11 @@\nfunc deleteBucketIfExists(ctx context.Context, t *testing.T, client *storage.Cli\n \t\treturn\n \t}\n \n-\t// Delete all of the elements in the already existent bucket.\n-\tit := b.Objects(ctx, nil)\n+\t// Delete all of the elements in the already existent bucket, including noncurrent objects.\n+\tit := b.Objects(ctx, &storage.Query{\n+\t\t// Versions true to output all generations of objects.\n+\t\tVersions: true,\n+\t})\n \tfor {\n \t\tattrs, err := it.Next()\n \t\tif err == iterator.Done {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "30b14cbef2b9f4a9e6e1468231a2c87da12ff0e4"
    },
    {
        "pr_title": "storage: listing noncurrent object versions",
        "pr_number": 1585,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -45,6 +45,7 @@\nfunc TestObjects(t *testing.T) {\n \tvar (\n \t\tbucket                = tc.ProjectID + \"-samples-object-bucket-1\"\n \t\tdstBucket             = tc.ProjectID + \"-samples-object-bucket-2\"\n+\t\tbucketVersioning      = tc.ProjectID + \"-bucket-versioning-enabled\"\n \t\tobject1               = \"foo.txt\"\n \t\tobject2               = \"foo/a.txt\"\n \t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers",
        "comments": [],
        "commit_messages": [
            "list all versioned files"
        ],
        "last_commit_sha": "30b14cbef2b9f4a9e6e1468231a2c87da12ff0e4"
    },
    {
        "pr_title": "storage: listing noncurrent object versions",
        "pr_number": 1585,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -53,6 +54,16 @@\nfunc TestObjects(t *testing.T) {\n \n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucket)\n \ttestutil.CleanBucket(ctx, t, tc.ProjectID, dstBucket)\n+\ttestutil.CleanBucket(ctx, t, tc.ProjectID, bucketVersioning)\n+\n+\t{\n+\t\t// Enable versioning\n+\t\tattr := storage.BucketAttrsToUpdate{VersioningEnabled: true}\n+\t\t_, err := client.Bucket(bucketVersioning).Update(ctx, attr)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"storage.BucketAttrsToUpdate{VersioningEnabled: true}: %v\", err)\n+\t\t}\n+\t}\n \n \tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "30b14cbef2b9f4a9e6e1468231a2c87da12ff0e4"
    },
    {
        "pr_title": "storage: listing noncurrent object versions",
        "pr_number": 1585,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -61,6 +72,13 @@\nfunc TestObjects(t *testing.T) {\n \t\tt.Fatalf(\"uploadFile(%q): %v\", object2, err)\n \t}\n \n+\tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n+\t}\n+\tif err := uploadFile(ioutil.Discard, bucketVersioning, object1); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n+\t}\n+\n \t{\n \t\t// Should only show \"foo/a.txt\", not \"foo.txt\"\n \t\tvar buf bytes.Buffer",
        "comments": [],
        "commit_messages": [
            "list all versioned files"
        ],
        "last_commit_sha": "30b14cbef2b9f4a9e6e1468231a2c87da12ff0e4"
    },
    {
        "pr_title": "storage: listing noncurrent object versions",
        "pr_number": 1585,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -90,6 +108,25 @@\nfunc TestObjects(t *testing.T) {\n \t\t}\n \t}\n \n+\t{\n+\t\t// Should show 2 versions of foo.txt\n+\t\tvar buf bytes.Buffer\n+\t\tif err := listFilesAllVersion(&buf, bucketVersioning); err != nil {\n+\t\t\tt.Fatalf(\"listFilesAllVersion: %v\", err)\n+\t\t}\n+\n+\t\ti := 0\n+\t\tfor _, line := range strings.Split(strings.TrimSuffix(buf.String(), \"\\n\"), \"\\n\") {\n+\t\t\tif got, want := line, object1; !strings.Contains(got, want) {\n+\t\t\t\tt.Errorf(\"List(Versions: true) got %q; want to contain %q\", got, want)\n+\t\t\t}\n+\t\t\ti++\n+\t\t}\n+\t\tif i != 2 {\n+\t\t\tt.Errorf(\"listFilesAllVersion should show 2 versions of foo.txt; got %d\", i)\n+\t\t}\n+\t}\n+\n \t{\n \t\tif err := downloadUsingRequesterPays(ioutil.Discard, bucket, object1, tc.ProjectID); err != nil {\n \t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "30b14cbef2b9f4a9e6e1468231a2c87da12ff0e4"
    },
    {
        "pr_title": "fix(functions): remove redundant GCS sample",
        "pr_number": 1582,
        "file_name": "functions/helloworld/hello_cloud_storage.go",
        "code_diff": "@@ -19,8 +19,11 @@\npackage helloworld\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"log\"\n \t\"time\"\n+\n+\t\"cloud.google.com/go/functions/metadata\"\n )\n \n // GCSEvent is the payload of a GCS event.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c9412b56316cbce04dcad523f1b48a319de00325"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -28,20 +28,14 @@\nimport (\n \t\"os\"\n \t\"strconv\"\n \n-\t\"github.com/go-sql-driver/mysql\"\n+\t_ \"github.com/go-sql-driver/mysql\"\n )\n \n-// db is the global database connection pool.\n-var db *sql.DB\n-\n-// parsedTemplate is the global parsed HTML template.\n-var parsedTemplate *template.Template\n-\n // vote struct contains a single row from the votes table in the database.\n // Each vote includes a candidate (\"TABS\" or \"SPACES\") and a timestamp.\n type vote struct {\n \tCandidate string\n-\tVoteTime  mysql.NullTime\n+\tVoteTime  sql.NullTime\n }\n \n // voteDiff is used to provide a string representation of the current voting",
        "comments": [],
        "commit_messages": [
            "update mysql sample"
        ],
        "last_commit_sha": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -63,38 +57,66 @@\ntype templateData struct {\n \tRecentVotes []vote\n }\n \n-func main() {\n-\tvar err error\n+// app struct contains global state.\n+type app struct {\n+\t// db is the global database connection pool.\n+\tdb *sql.DB\n+\t// tmpl is the parsed HTML template.\n+\ttmpl *template.Template\n+}\n+\n+// indexHandler handles requests to the / route.\n+func (app *app) indexHandler(w http.ResponseWriter, r *http.Request) {\n+\tswitch r.Method {\n+\tcase \"GET\":\n+\t\tif err := showTotals(w, r, app); err != nil {\n+\t\t\tlog.Printf(\"showTotals: %v\", err)\n+\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n+\t\t}\n+\tcase \"POST\":\n+\t\tif err := saveVote(w, r, app); err != nil {\n+\t\t\tlog.Printf(\"saveVote: %v\", err)\n+\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n+\t\t}\n+\tdefault:\n+\t\thttp.Error(w, fmt.Sprintf(\"HTTP Method %s Not Allowed\", r.Method), http.StatusMethodNotAllowed)\n+\t}\n+}\n \n-\tparsedTemplate, err = template.ParseFiles(\"templates/index.html\")\n+func main() {\n+\tparsedTemplate, err := template.ParseFiles(\"templates/index.html\")\n \tif err != nil {\n \t\tlog.Fatalf(\"unable to parse template file: %s\", err)\n \t}\n \n+\tapp := &app{\n+\t\ttmpl: parsedTemplate,\n+\t}\n+\n \t// If the optional DB_TCP_HOST environment variable is set, it contains\n \t// the IP address and port number of a TCP connection pool to be created,\n \t// such as \"127.0.0.1:3306\". If DB_TCP_HOST is not set, a Unix socket\n \t// connection pool will be created instead.\n \tif os.Getenv(\"DB_TCP_HOST\") != \"\" {\n-\t\tdb, err = initTcpConnectionPool()\n+\t\tapp.db, err = initTCPConnectionPool()\n \t\tif err != nil {\n-\t\t\tlog.Fatalf(\"initTcpConnectionPool: unable to connect: %s\", err)\n+\t\t\tlog.Fatalf(\"initTCPConnectionPool: unable to connect: %v\", err)\n \t\t}\n \t} else {\n-\t\tdb, err = initSocketConnectionPool()\n+\t\tapp.db, err = initSocketConnectionPool()\n \t\tif err != nil {\n-\t\t\tlog.Fatalf(\"initSocketConnectionPool: unable to connect: %s\", err)\n+\t\t\tlog.Fatalf(\"initSocketConnectionPool: unable to connect: %v\", err)\n \t\t}\n \t}\n \n \t// Create the votes table if it does not already exist.\n-\tif _, err = db.Exec(`CREATE TABLE IF NOT EXISTS votes\n+\tif _, err = app.db.Exec(`CREATE TABLE IF NOT EXISTS votes\n \t( vote_id SERIAL NOT NULL, time_cast timestamp NOT NULL,\n \tcandidate CHAR(6) NOT NULL, PRIMARY KEY (vote_id) );`); err != nil {\n \t\tlog.Fatalf(\"DB.Exec: unable to create table: %s\", err)\n \t}\n \n-\thttp.HandleFunc(\"/\", indexHandler)\n+\thttp.HandleFunc(\"/\", app.indexHandler)\n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {\n \t\tport = \"8080\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -107,28 +129,10 @@\nfunc main() {\n \n }\n \n-// indexHandler handles requests to the / route.\n-func indexHandler(w http.ResponseWriter, r *http.Request) {\n-\tswitch r.Method {\n-\tcase \"GET\":\n-\t\tif err := showTotals(w, r); err != nil {\n-\t\t\tlog.Printf(\"showTotals: %v\", err)\n-\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n-\t\t}\n-\tcase \"POST\":\n-\t\tif err := saveVote(w, r); err != nil {\n-\t\t\tlog.Printf(\"saveVote: %v\", err)\n-\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n-\t\t}\n-\tdefault:\n-\t\thttp.Error(w, fmt.Sprintf(\"HTTP Method %s Not Allowed\", r.Method), http.StatusMethodNotAllowed)\n-\t}\n-}\n-\n // recentVotes returns a slice of the last 5 votes cast.\n-func recentVotes() ([]vote, error) {\n+func recentVotes(app *app) ([]vote, error) {\n \tvar votes []vote\n-\trows, err := db.Query(`SELECT candidate, time_cast FROM votes ORDER BY time_cast DESC LIMIT 5`)\n+\trows, err := app.db.Query(`SELECT candidate, time_cast FROM votes ORDER BY time_cast DESC LIMIT 5`)\n \tif err != nil {\n \t\treturn votes, fmt.Errorf(\"DB.Query: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "update mysql sample"
        ],
        "last_commit_sha": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -145,60 +149,63 @@\nfunc recentVotes() ([]vote, error) {\n }\n \n // currentTotals returns a templateData structure for populating the web page.\n-func currentTotals() (templateData, error) {\n-\n+func currentTotals(app *app) (*templateData, error) {\n \t// get total votes for each candidate\n \tvar tabVotes, spaceVotes uint\n-\terr := db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='TABS'`).Scan(&tabVotes)\n+\terr := app.db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='TABS'`).Scan(&tabVotes)\n \tif err != nil {\n-\t\treturn templateData{}, fmt.Errorf(\"DB.QueryRow: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}\n-\terr = db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='SPACES'`).Scan(&spaceVotes)\n+\terr = app.db.QueryRow(`SELECT count(vote_id) FROM votes WHERE candidate='SPACES'`).Scan(&spaceVotes)\n \tif err != nil {\n-\t\treturn templateData{}, fmt.Errorf(\"DB.QueryRow: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"DB.QueryRow: %v\", err)\n \t}\n \n \tvar voteDiffStr string = voteDiff(int(math.Abs(float64(tabVotes) - float64(spaceVotes)))).String()\n \n-\tlatestVotesCast, err := recentVotes()\n+\tlatestVotesCast, err := recentVotes(app)\n \tif err != nil {\n-\t\treturn templateData{}, fmt.Errorf(\"recentVotes: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"recentVotes: %v\", err)\n \t}\n-\treturn templateData{tabVotes, spaceVotes, voteDiffStr, latestVotesCast}, nil\n \n+\tpageData := templateData{\n+\t\tTabsCount:   tabVotes,\n+\t\tSpacesCount: spaceVotes,\n+\t\tVoteMargin:  voteDiffStr,\n+\t\tRecentVotes: latestVotesCast,\n+\t}\n+\n+\treturn &pageData, nil\n }\n \n // showTotals renders an HTML template showing the current vote totals.\n-func showTotals(w http.ResponseWriter, r *http.Request) error {\n-\n-\ttotals, err := currentTotals()\n+func showTotals(w http.ResponseWriter, r *http.Request, app *app) error {\n+\ttotals, err := currentTotals(app)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"currentTotals: %v\", err)\n \t}\n-\terr = parsedTemplate.Execute(w, totals)\n+\terr = app.tmpl.Execute(w, totals)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Template.Execute: %v\", err)\n \t}\n \treturn nil\n }\n \n // saveVote saves a vote passed as http.Request form data.\n-func saveVote(w http.ResponseWriter, r *http.Request) error {\n+func saveVote(w http.ResponseWriter, r *http.Request, app *app) error {\n \tif err := r.ParseForm(); err != nil {\n \t\treturn fmt.Errorf(\"Request.ParseForm: %v\", err)\n \t}\n \n-\tvar team string\n-\tif teamprop, ok := r.Form[\"team\"]; ok {\n-\t\tteam = teamprop[0]\n-\t} else {\n+\tteam := r.FormValue(\"team\")\n+\tif team == \"\" {\n \t\treturn fmt.Errorf(\"team property missing from form submission\")\n \t}\n \n \t// [START cloud_sql_mysql_databasesql_connection]\n-\tsqlInsert := \"INSERT INTO votes (candidate) VALUES (?)\"\n+\tsqlInsert := \"INSERT INTO votes(candidate, time_cast) VALUES(?, NOW())\"\n \tif team == \"TABS\" || team == \"SPACES\" {\n-\t\tif _, err := db.Exec(sqlInsert, team); err != nil {\n+\t\tif _, err := app.db.Exec(sqlInsert, team); err != nil {\n \t\t\tfmt.Fprintf(w, \"unable to save vote: %s\", err)\n \t\t\treturn fmt.Errorf(\"DB.Exec: %v\", err)\n \t\t} else {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -214,13 +221,13 @@\nfunc saveVote(w http.ResponseWriter, r *http.Request) error {\n func mustGetenv(k string) string {\n \tv := os.Getenv(k)\n \tif v == \"\" {\n-\t\tlog.Printf(\"Warning: %s environment variable not set.\\n\", k)\n+\t\tlog.Fatalf(\"Warning: %s environment variable not set.\\n\", k)\n \t}\n \treturn v\n }\n \n // initSocketConnectionPool initializes a Unix socket connection pool for\n-// a Cloud SQL instance of MySQL.\n+// a Cloud SQL instance of SQL Server.\n func initSocketConnectionPool() (*sql.DB, error) {\n \t// [START cloud_sql_mysql_databasesql_create_socket]\n \tvar (",
        "comments": [],
        "commit_messages": [
            "update mysql sample"
        ],
        "last_commit_sha": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "cloudsql: update MySQL sample",
        "pr_number": 1564,
        "file_name": "cloudsql/mysql/database-sql/cloudsql.go",
        "code_diff": "@@ -230,8 +237,13 @@\nfunc initSocketConnectionPool() (*sql.DB, error) {\n \t\tdbName                 = mustGetenv(\"DB_NAME\")\n \t)\n \n+\tsocketDir, isSet := os.LookupEnv(\"DB_SOCKET_DIR\")\n+\tif !isSet {\n+\t\tsocketDir = \"/cloudsql\"\n+\t}\n+\n \tvar dbURI string\n-\tdbURI = fmt.Sprintf(\"%s:%s@unix(/cloudsql/%s)/%s\", dbUser, dbPwd, instanceConnectionName, dbName)\n+\tdbURI = fmt.Sprintf(\"%s:%s@unix(/%s/%s)/%s?parseTime=true\", dbUser, dbPwd, socketDir, instanceConnectionName, dbName)\n \n \t// dbPool is the pool of database connections.\n \tdbPool, err := sql.Open(\"mysql\", dbURI)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "eb29e81f5de1ae473cf93a13c4973d1204252e3f"
    },
    {
        "pr_title": "datastore: admin export/import samples",
        "pr_number": 1553,
        "file_name": "datastore/admin/datastore_admin_entities_export.go",
        "code_diff": "@@ -26,13 +26,13 @@\nimport (\n \n // entitiesExport exports a copy of all or a subset of entities from\n // Datastore to another storage system, such as Cloud Storage.\n-func entitiesExport(w io.Writer, projectID, outputURLPrefix string) error {\n+func entitiesExport(w io.Writer, projectID, outputURLPrefix string) (*adminpb.ExportEntitiesResponse, error) {\n \t// projectID := \"project-id\"\n \t// outputURLPrefix := \"gs://bucket-name\"\n \tctx := context.Background()\n \tclient, err := admin.NewDatastoreAdminClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"admin.NewDatastoreAdminClient: %v\", err)\n+\t\treturn nil, fmt.Errorf(\"admin.NewDatastoreAdminClient: %v\", err)\n \t}\n \tdefer client.Close()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "eb2b3d0efbd4336f257b156e6289e631cfe15efa"
    },
    {
        "pr_title": "datastore: admin export/import samples",
        "pr_number": 1553,
        "file_name": "datastore/admin/datastore_admin_test.go",
        "code_diff": "@@ -15,20 +15,27 @@\npackage samples\n \n import (\n+\t\"context\"\n \t\"io/ioutil\"\n \t\"testing\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func TestCreate(t *testing.T) {\n+func TestAdmin(t *testing.T) {\n+\t// Roles to be set in your Service Account and App Engine default service account\n+\t// to run this test:\n+\t// `Datastore Import Export Admin`, or `Cloud Datastore Owner`, or `Owner`,\n+\t// `Storage Admin`, or `Owner`.\n+\t// See https://cloud.google.com/datastore/docs/export-import-entities#permissions for full details\n+\ttc := testutil.SystemTest(t)\n+\tctx := context.Background()\n \tclient, err := clientCreate(ioutil.Discard)\n \tif err != nil {\n \t\tt.Fatalf(\"clientCreate: %v\", err)\n \t}\n \tdefer client.Close()\n \n-\ttc := testutil.SystemTest(t)\n \tindices, err := indexList(ioutil.Discard, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"indexList: %v\", err)",
        "comments": [
            {
                "comment": "Thanks for adding this. Can we also link to the authority page here as well?\r\n\r\n```suggestion\r\n\t// `Storage Admin`, or `Owner`.\r\n\t// See https://cloud.google.com/datastore/docs/export-import-entities#permissions for full details\r\n```",
                "position": 16
            },
            {
                "comment": "+1 to adding the link",
                "position": 16
            },
            {
                "comment": "Perhaps this should have a timestamp to prevent namespace clashes?",
                "position": 35
            },
            {
                "comment": "Thank you for review! \r\nOh, I used [this bucket creation](https://github.com/GoogleCloudPlatform/golang-samples/blob/56f12b11eec1006b65de0b8270ddaba42d3dfab8/storage/buckets/buckets_test.go#L32) as an example. So we need to update it and other's samples too?",
                "position": 35
            },
            {
                "comment": "Gotcha-- maybe @tbpg can chime in here on the best approach? He would know better.",
                "position": 35
            },
            {
                "comment": "Appears to be a unique suffix and the call to `CleanBucket` should prevent staleness issues. So, this seems OK to me.",
                "position": 35
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "eb2b3d0efbd4336f257b156e6289e631cfe15efa"
    },
    {
        "pr_title": "monitoring: demonstrate creation of a POST uptime check to go along with the GET uptime check",
        "pr_number": 1499,
        "file_name": "monitoring/uptime/uptime.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage uptime\n \n import (\n \t\"context\"\n+\t\"encoding/base64\"\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_messages": [
            "add a URL-encoded body to the POST uptime check example"
        ],
        "last_commit_sha": "3b151248e58ad686c6ef99c1818c9a3b82d4d2ab"
    },
    {
        "pr_title": "monitoring: demonstrate creation of a POST uptime check to go along with the GET uptime check",
        "pr_number": 1499,
        "file_name": "monitoring/uptime/uptime.go",
        "code_diff": "@@ -30,8 +31,8 @@\nimport (\n \n // [START monitoring_uptime_check_create]\n \n-// create creates an example uptime check.\n-func create(w io.Writer, projectID string) (*monitoringpb.UptimeCheckConfig, error) {\n+// createGet creates an example uptime check on a GET request.\n+func createGet(w io.Writer, projectID string) (*monitoringpb.UptimeCheckConfig, error) {\n \tctx := context.Background()\n \tclient, err := monitoring.NewUptimeCheckClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "demonstrate creation of a POST uptime check to go along with the GET uptime check"
        ],
        "last_commit_sha": "3b151248e58ad686c6ef99c1818c9a3b82d4d2ab"
    },
    {
        "pr_title": "monitoring: demonstrate creation of a POST uptime check to go along with the GET uptime check",
        "pr_number": 1499,
        "file_name": "monitoring/uptime/uptime.go",
        "code_diff": "@@ -41,7 +42,7 @@\nfunc create(w io.Writer, projectID string) (*monitoringpb.UptimeCheckConfig, err\n \treq := &monitoringpb.CreateUptimeCheckConfigRequest{\n \t\tParent: \"projects/\" + projectID,\n \t\tUptimeCheckConfig: &monitoringpb.UptimeCheckConfig{\n-\t\t\tDisplayName: \"new uptime check\",\n+\t\t\tDisplayName: \"new GET uptime check\",\n \t\t\tResource: &monitoringpb.UptimeCheckConfig_MonitoredResource{\n \t\t\t\tMonitoredResource: &monitoredres.MonitoredResource{\n \t\t\t\t\tType: \"uptime_url\",",
        "comments": [],
        "commit_messages": [
            "demonstrate creation of a POST uptime check to go along with the GET uptime check"
        ],
        "last_commit_sha": "3b151248e58ad686c6ef99c1818c9a3b82d4d2ab"
    },
    {
        "pr_title": "monitoring: demonstrate creation of a POST uptime check to go along with the GET uptime check",
        "pr_number": 1499,
        "file_name": "monitoring/uptime/uptime.go",
        "code_diff": "@@ -52,8 +53,9 @@\nfunc create(w io.Writer, projectID string) (*monitoringpb.UptimeCheckConfig, err\n \t\t\t},\n \t\t\tCheckRequestType: &monitoringpb.UptimeCheckConfig_HttpCheck_{\n \t\t\t\tHttpCheck: &monitoringpb.UptimeCheckConfig_HttpCheck{\n-\t\t\t\t\tPath: \"/\",\n-\t\t\t\t\tPort: 80,\n+\t\t\t\t\tRequestMethod: monitoringpb.UptimeCheckConfig_HttpCheck_GET,\n+\t\t\t\t\tPath:          \"/\",\n+\t\t\t\t\tPort:          80,\n \t\t\t\t},\n \t\t\t},\n \t\t\tTimeout: &duration.Duration{Seconds: 10},",
        "comments": [],
        "commit_messages": [
            "demonstrate creation of a POST uptime check to go along with the GET uptime check"
        ],
        "last_commit_sha": "3b151248e58ad686c6ef99c1818c9a3b82d4d2ab"
    },
    {
        "pr_title": "monitoring: demonstrate creation of a POST uptime check to go along with the GET uptime check",
        "pr_number": 1499,
        "file_name": "monitoring/uptime/uptime_test.go",
        "code_diff": "@@ -24,11 +24,11 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func TestCreate(t *testing.T) {\n+func TestCreateGet(t *testing.T) {\n \tc := testutil.SystemTest(t)\n \ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n \t\tbuf := new(bytes.Buffer)\n-\t\tconfig, err := create(buf, c.ProjectID)\n+\t\tconfig, err := createGet(buf, c.ProjectID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"create: %v\", err)\n \t\t\treturn",
        "comments": [],
        "commit_messages": [
            "demonstrate creation of a POST uptime check to go along with the GET uptime check"
        ],
        "last_commit_sha": "3b151248e58ad686c6ef99c1818c9a3b82d4d2ab"
    },
    {
        "pr_title": "monitoring: demonstrate creation of a POST uptime check to go along with the GET uptime check",
        "pr_number": 1499,
        "file_name": "monitoring/uptime/uptime_test.go",
        "code_diff": "@@ -41,6 +41,23 @@\nfunc TestCreate(t *testing.T) {\n \t})\n }\n \n+func TestCreatePost(t *testing.T) {\n+\tc := testutil.SystemTest(t)\n+\ttestutil.Retry(t, 5, 5*time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n+\t\tconfig, err := createPost(buf, c.ProjectID)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"create POST: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\twant := \"Successfully\"\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"%q not found in output: %q\", want, got)\n+\t\t}\n+\t\tdelete(ioutil.Discard, config.GetName())\n+\t})\n+}\n+\n func TestList(t *testing.T) {\n \tc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "demonstrate creation of a POST uptime check to go along with the GET uptime check"
        ],
        "last_commit_sha": "3b151248e58ad686c6ef99c1818c9a3b82d4d2ab"
    },
    {
        "pr_title": "monitoring: demonstrate creation of a POST uptime check to go along with the GET uptime check",
        "pr_number": 1499,
        "file_name": "monitoring/uptime/uptime_test.go",
        "code_diff": "@@ -67,7 +84,7 @@\nfunc TestListIPs(t *testing.T) {\n \n func TestGet(t *testing.T) {\n \tc := testutil.SystemTest(t)\n-\tconfig, err := create(ioutil.Discard, c.ProjectID)\n+\tconfig, err := createPost(ioutil.Discard, c.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"create: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "demonstrate creation of a POST uptime check to go along with the GET uptime check"
        ],
        "last_commit_sha": "3b151248e58ad686c6ef99c1818c9a3b82d4d2ab"
    },
    {
        "pr_title": "monitoring: demonstrate creation of a POST uptime check to go along with the GET uptime check",
        "pr_number": 1499,
        "file_name": "monitoring/uptime/uptime_test.go",
        "code_diff": "@@ -84,7 +101,7 @@\nfunc TestGet(t *testing.T) {\n \n func TestUpdate(t *testing.T) {\n \tc := testutil.SystemTest(t)\n-\tconfig, err := create(ioutil.Discard, c.ProjectID)\n+\tconfig, err := createGet(ioutil.Discard, c.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"create: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "demonstrate creation of a POST uptime check to go along with the GET uptime check"
        ],
        "last_commit_sha": "3b151248e58ad686c6ef99c1818c9a3b82d4d2ab"
    },
    {
        "pr_title": "bigtable: update region tags for reads and filters",
        "pr_number": 1496,
        "file_name": "bigtable/filters/filters.go",
        "code_diff": "@@ -16,24 +16,7 @@\n// with various filters.\n package filters\n \n-// [START bigtable_filters_limit_row_sample]\n-// [START bigtable_filters_limit_row_regex]\n-// [START bigtable_filters_limit_cells_per_col]\n-// [START bigtable_filters_limit_cells_per_row]\n-// [START bigtable_filters_limit_cells_per_row_offset]\n-// [START bigtable_filters_limit_col_family_regex]\n-// [START bigtable_filters_limit_col_qualifier_regex]\n-// [START bigtable_filters_limit_col_range]\n-// [START bigtable_filters_limit_value_range]\n-// [START bigtable_filters_limit_value_regex]\n-// [START bigtable_filters_limit_timestamp_range]\n-// [START bigtable_filters_limit_block_all]\n-// [START bigtable_filters_limit_pass_all]\n-// [START bigtable_filters_modify_strip_value]\n-// [START bigtable_filters_modify_apply_label]\n-// [START bigtable_filters_composing_chain]\n-// [START bigtable_filters_composing_interleave]\n-// [START bigtable_filters_composing_condition]\n+// [START bigtable_filters_imports]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [
            {
                "comment": "I'm still a bit concerned by these all being grouped together into a single snippet, rather than each snippet in it's own file. It seems unlikely to me that all of the snippets use the same exact set of imports. If one of the imports is extra or missing, the sample will fail to compile.\r\n\r\nThe helper functions would probably only be defined once and defined with the new tags you gave. So, I don't know how to guarantee the imports needed for the helpers are present in each file...\r\n\r\nIt's up to you what you would prefer to do.",
                "position": 22
            },
            {
                "comment": "Hey Tyler, I definitely agree on the imports, but this is a quick fix to help get new documentation out. In the original version it would've made more sense, but this will have to do for the moment. I will probably go through sometime or work with a contractor to get all these samples split up into individual files.",
                "position": 22
            },
            {
                "comment": "Sounds good.",
                "position": 22
            }
        ],
        "commit_messages": [
            "[bigtable] Update region tags for reads and filters"
        ],
        "last_commit_sha": "11ee272903e93783c0b3798b9a3a58fb87f3f96d"
    },
    {
        "pr_title": "bigtable: update region tags for reads and filters",
        "pr_number": 1496,
        "file_name": "bigtable/filters/filters.go",
        "code_diff": "@@ -45,24 +28,7 @@\nimport (\n \t\"cloud.google.com/go/bigtable\"\n )\n \n-// [END bigtable_filters_limit_row_sample]\n-// [END bigtable_filters_limit_row_regex]\n-// [END bigtable_filters_limit_cells_per_col]\n-// [END bigtable_filters_limit_cells_per_row]\n-// [END bigtable_filters_limit_cells_per_row_offset]\n-// [END bigtable_filters_limit_col_family_regex]\n-// [END bigtable_filters_limit_col_qualifier_regex]\n-// [END bigtable_filters_limit_col_range]\n-// [END bigtable_filters_limit_value_range]\n-// [END bigtable_filters_limit_value_regex]\n-// [END bigtable_filters_limit_timestamp_range]\n-// [END bigtable_filters_limit_block_all]\n-// [END bigtable_filters_limit_pass_all]\n-// [END bigtable_filters_modify_strip_value]\n-// [END bigtable_filters_modify_apply_label]\n-// [END bigtable_filters_composing_chain]\n-// [END bigtable_filters_composing_interleave]\n-// [END bigtable_filters_composing_condition]\n+// [END bigtable_filters_imports]\n \n // [START bigtable_filters_limit_row_sample]\n func filterLimitRowSample(w io.Writer, projectID, instanceID string, tableName string) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "11ee272903e93783c0b3798b9a3a58fb87f3f96d"
    },
    {
        "pr_title": "bigtable: update region tags for reads and filters",
        "pr_number": 1496,
        "file_name": "bigtable/filters/filters.go",
        "code_diff": "@@ -191,24 +157,7 @@\nfunc filterComposingCondition(w io.Writer, projectID, instanceID string, tableNa\n \n // [END bigtable_filters_composing_condition]\n \n-// [START bigtable_filters_limit_row_sample]\n-// [START bigtable_filters_limit_row_regex]\n-// [START bigtable_filters_limit_cells_per_col]\n-// [START bigtable_filters_limit_cells_per_row]\n-// [START bigtable_filters_limit_cells_per_row_offset]\n-// [START bigtable_filters_limit_col_family_regex]\n-// [START bigtable_filters_limit_col_qualifier_regex]\n-// [START bigtable_filters_limit_col_range]\n-// [START bigtable_filters_limit_value_range]\n-// [START bigtable_filters_limit_value_regex]\n-// [START bigtable_filters_limit_timestamp_range]\n-// [START bigtable_filters_limit_block_all]\n-// [START bigtable_filters_limit_pass_all]\n-// [START bigtable_filters_modify_strip_value]\n-// [START bigtable_filters_modify_apply_label]\n-// [START bigtable_filters_composing_chain]\n-// [START bigtable_filters_composing_interleave]\n-// [START bigtable_filters_composing_condition]\n+// [START bigtable_filters_print]\n func readWithFilter(w io.Writer, projectID, instanceID string, tableName string, filter bigtable.Filter) error {\n \t// projectID := \"my-project-id\"\n \t// instanceID := \"my-instance-id\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "11ee272903e93783c0b3798b9a3a58fb87f3f96d"
    },
    {
        "pr_title": "bigtable: update region tags for reads and filters",
        "pr_number": 1496,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -15,13 +15,7 @@\n// Package reads contains snippets related to reading data from Cloud Bigtable.\n package reads\n \n-// [START bigtable_reads_row]\n-// [START bigtable_reads_row_partial]\n-// [START bigtable_reads_rows]\n-// [START bigtable_reads_row_range]\n-// [START bigtable_reads_row_ranges]\n-// [START bigtable_reads_prefix]\n-// [START bigtable_reads_filter]\n+// [START bigtable_reads_imports]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "Update read region tags"
        ],
        "last_commit_sha": "11ee272903e93783c0b3798b9a3a58fb87f3f96d"
    },
    {
        "pr_title": "bigtable: update region tags for reads and filters",
        "pr_number": 1496,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -32,13 +26,7 @@\nimport (\n \t\"cloud.google.com/go/bigtable\"\n )\n \n-// [END bigtable_reads_row]\n-// [END bigtable_reads_row_partial]\n-// [END bigtable_reads_rows]\n-// [END bigtable_reads_row_range]\n-// [END bigtable_reads_row_ranges]\n-// [END bigtable_reads_prefix]\n-// [END bigtable_reads_filter]\n+// [END bigtable_reads_imports]\n \n // [START bigtable_reads_row]\n func readRow(w io.Writer, projectID, instanceID string, tableName string) error {",
        "comments": [],
        "commit_messages": [
            "Update read region tags"
        ],
        "last_commit_sha": "11ee272903e93783c0b3798b9a3a58fb87f3f96d"
    },
    {
        "pr_title": "bigtable: update region tags for reads and filters",
        "pr_number": 1496,
        "file_name": "bigtable/reads/reads.go",
        "code_diff": "@@ -228,13 +216,7 @@\nfunc readFilter(w io.Writer, projectID, instanceID string, tableName string) err\n \n // [END bigtable_reads_filter]\n \n-// [START bigtable_reads_row]\n-// [START bigtable_reads_row_partial]\n-// [START bigtable_reads_rows]\n-// [START bigtable_reads_row_range]\n-// [START bigtable_reads_row_ranges]\n-// [START bigtable_reads_prefix]\n-// [START bigtable_reads_filter]\n+// [START bigtable_reads_print]\n func printRow(w io.Writer, row bigtable.Row) {\n \tfmt.Fprintf(w, \"Reading data for %s:\\n\", row.Key())\n \tfor columnFamily, cols := range row {",
        "comments": [],
        "commit_messages": [
            "Update read region tags"
        ],
        "last_commit_sha": "11ee272903e93783c0b3798b9a3a58fb87f3f96d"
    },
    {
        "pr_title": "spanner: add spanner_create_instance sample.",
        "pr_number": 1490,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -25,12 +25,16 @@\nimport (\n \t\"time\"\n \n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n+\tinstance \"cloud.google.com/go/spanner/admin/instance/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n \t\"google.golang.org/api/iterator\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n+\tinstancepb \"google.golang.org/genproto/googleapis/spanner/admin/instance/v1\"\n )\n \n type sampleFunc func(w io.Writer, dbName string) error\n+type instanceSampleFunc func(w io.Writer, projectID, instanceID string) error\n type backupSampleFunc func(w io.Writer, dbName, backupID string) error\n \n func initTest(t *testing.T, projectID string) (dbName string, cleanup func()) {",
        "comments": [],
        "commit_messages": [
            "spanner: add spanner_create_instance sample."
        ],
        "last_commit_sha": "4f685c393d9f2a2363f40875567470e7b6ab0d7e"
    },
    {
        "pr_title": "spanner: add spanner_create_instance sample.",
        "pr_number": 1490,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -107,6 +111,17 @@\nfunc initBackupTest(t *testing.T, projectID, dbName string) (restoreDBName, back\n \treturn\n }\n \n+func TestCreateInstance(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tinstanceID := fmt.Sprintf(\"go-sample-test-%s\", uuid.New().String()[:8])\n+\tout := runInstanceSample(t, createInstance, tc.ProjectID, instanceID, \"failed to create an instance\")\n+\tif err := cleanupInstance(tc.ProjectID, instanceID); err != nil {\n+\t\tt.Logf(\"cleanupInstance error: %s\", err)\n+\t}\n+\tassertContains(t, out, fmt.Sprintf(\"Created instance [%s]\", instanceID))\n+}\n+\n func TestSample(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4f685c393d9f2a2363f40875567470e7b6ab0d7e"
    },
    {
        "pr_title": "spanner: add spanner_create_instance sample.",
        "pr_number": 1490,
        "file_name": "spanner/spanner_snippets/spanner/integration_test.go",
        "code_diff": "@@ -351,6 +366,14 @@\nfunc runBackupSample(t *testing.T, f backupSampleFunc, dbName, backupID, errMsg\n \treturn b.String()\n }\n \n+func runInstanceSample(t *testing.T, f instanceSampleFunc, projectID, instanceID, errMsg string) string {\n+\tvar b bytes.Buffer\n+\tif err := f(&b, projectID, instanceID); err != nil {\n+\t\tt.Errorf(\"%s: %v\", errMsg, err)\n+\t}\n+\treturn b.String()\n+}\n+\n func mustRunSample(t *testing.T, f sampleFunc, dbName, errMsg string) string {\n \tvar b bytes.Buffer\n \tif err := f(&b, dbName); err != nil {",
        "comments": [],
        "commit_messages": [
            "spanner: add spanner_create_instance sample."
        ],
        "last_commit_sha": "4f685c393d9f2a2363f40875567470e7b6ab0d7e"
    },
    {
        "pr_title": "pubsub: proper handling of concurrent pull",
        "pr_number": 1467,
        "file_name": "pubsub/subscriptions/pull_concurrency.go",
        "code_diff": "@@ -48,16 +48,12 @@\nfunc pullMsgsConcurrenyControl(w io.Writer, projectID, subID string) error {\n \n \t// Create a channel to handle messages to as they come in.\n \tcm := make(chan *pubsub.Message)\n+\tdefer close(cm)\n \t// Handle individual messages in a goroutine.\n \tgo func() {\n-\t\tfor {\n-\t\t\tselect {\n-\t\t\tcase msg := <-cm:\n-\t\t\t\tfmt.Fprintf(w, \"Got message :%q\\n\", string(msg.Data))\n-\t\t\t\tmsg.Ack()\n-\t\t\tcase <-ctx.Done():\n-\t\t\t\treturn\n-\t\t\t}\n+\t\tfor msg := range cm {\n+\t\t\tfmt.Fprintf(w, \"Got message :%q\\n\", string(msg.Data))\n+\t\t\tmsg.Ack()\n \t\t}\n \t}()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c7872eb5927c2492dbd40da1d9aee9d1ea671487"
    },
    {
        "pr_title": "all: remove legacy health check handlers",
        "pr_number": 1442,
        "file_name": "appengine_flexible/helloworld/helloworld.go",
        "code_diff": "@@ -24,7 +24,6 @@\nimport (\n \n func main() {\n \thttp.HandleFunc(\"/\", handle)\n-\thttp.HandleFunc(\"/_ah/health\", healthCheckHandler)\n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {\n \t\tport = \"8080\"",
        "comments": [],
        "commit_messages": [
            "all: remove legacy health check handlers\n\nLegacy health checks migrated to split health checks, which are now the\ndefault. Split health checks are not sent to apps by default, so these\nhandlers are not working as intended.\n\nNone of the app.yaml files have health checks configured, so I chose not\nto add new split handlers & configuration."
        ],
        "last_commit_sha": "4c4973ce09e08a0a9161a3e1ecf3bada8089deb5"
    },
    {
        "pr_title": "all: remove legacy health check handlers",
        "pr_number": 1442,
        "file_name": "appengine_flexible/websockets/main.go",
        "code_diff": "@@ -18,7 +18,6 @@\npackage main\n \n import (\n-\t\"fmt\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"",
        "comments": [
            {
                "comment": "Healthchecks are noted in the [docs for websockets](https://cloud.google.com/appengine/docs/flexible/go/using-websockets-and-session-affinity?hl=en) as part of how the platform relocates sessions to preserve connections using session affinity. Migrating to split healthchecks seems valuable.",
                "position": 24
            },
            {
                "comment": "That doc mentions \"If the target instance fails health checks, App Engine moves the session to a healthy instance.\" That seems very reasonable.\r\n\r\nhttps://cloud.google.com/appengine/docs/flexible/custom-runtimes/configuring-your-app-with-app-yaml#updated_health_checks mentions health checks are on by default and only need to be customized if you want to. So, I'm not sure it's valuable to add health checks here. Maybe we should update the websocket doc to link to the health check docs?",
                "position": 24
            },
            {
                "comment": "Agreed, let's remove this and cross-link the docs. I'll send a CL to the docs now.",
                "position": 24
            }
        ],
        "commit_messages": [
            "all: remove legacy health check handlers\n\nLegacy health checks migrated to split health checks, which are now the\ndefault. Split health checks are not sent to apps by default, so these\nhandlers are not working as intended.\n\nNone of the app.yaml files have health checks configured, so I chose not\nto add new split handlers & configuration."
        ],
        "last_commit_sha": "4c4973ce09e08a0a9161a3e1ecf3bada8089deb5"
    },
    {
        "pr_title": "all: remove legacy health check handlers",
        "pr_number": 1442,
        "file_name": "appengine_flexible/websockets/main.go",
        "code_diff": "@@ -29,7 +28,6 @@\nimport (\n func main() {\n \thttp.Handle(\"/\", http.FileServer(http.Dir(\"static\")))\n \thttp.HandleFunc(\"/ws\", socketHandler)\n-\thttp.HandleFunc(\"/_ah/health\", healthCheckHandler)\n \n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {",
        "comments": [],
        "commit_messages": [
            "all: remove legacy health check handlers\n\nLegacy health checks migrated to split health checks, which are now the\ndefault. Split health checks are not sent to apps by default, so these\nhandlers are not working as intended.\n\nNone of the app.yaml files have health checks configured, so I chose not\nto add new split handlers & configuration."
        ],
        "last_commit_sha": "4c4973ce09e08a0a9161a3e1ecf3bada8089deb5"
    },
    {
        "pr_title": "all: remove legacy health check handlers",
        "pr_number": 1442,
        "file_name": "appengine_flexible/websockets/main_test.go",
        "code_diff": "@@ -18,7 +18,6 @@\nimport (\n \t\"bytes\"\n \t\"net/http\"\n \t\"net/http/httptest\"\n-\t\"strings\"\n \t\"testing\"\n \n \t\"github.com/gorilla/websocket\"",
        "comments": [],
        "commit_messages": [
            "all: remove legacy health check handlers\n\nLegacy health checks migrated to split health checks, which are now the\ndefault. Split health checks are not sent to apps by default, so these\nhandlers are not working as intended.\n\nNone of the app.yaml files have health checks configured, so I chose not\nto add new split handlers & configuration."
        ],
        "last_commit_sha": "4c4973ce09e08a0a9161a3e1ecf3bada8089deb5"
    },
    {
        "pr_title": "all: remove legacy health check handlers",
        "pr_number": 1442,
        "file_name": "getting-started/devflowapp/devflowapp.go",
        "code_diff": "@@ -96,7 +96,6 @@\nfunc main() {\n \thttp.HandleFunc(\"/\", handleDefault)\n \thttp.HandleFunc(\"/messages\", handleCheckMessages)\n \thttp.HandleFunc(\"/send\", handleSend)\n-\thttp.HandleFunc(\"/_ah/health\", healthCheckHandler)\n \n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {",
        "comments": [],
        "commit_messages": [
            "all: remove legacy health check handlers\n\nLegacy health checks migrated to split health checks, which are now the\ndefault. Split health checks are not sent to apps by default, so these\nhandlers are not working as intended.\n\nNone of the app.yaml files have health checks configured, so I chose not\nto add new split handlers & configuration."
        ],
        "last_commit_sha": "4c4973ce09e08a0a9161a3e1ecf3bada8089deb5"
    },
    {
        "pr_title": "all: remove legacy health check handlers",
        "pr_number": 1442,
        "file_name": "getting-started/helloworld/helloworld.go",
        "code_diff": "@@ -24,7 +24,6 @@\nimport (\n \n func main() {\n \thttp.HandleFunc(\"/\", handle)\n-\thttp.HandleFunc(\"/_ah/health\", healthCheckHandler)\n \n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {",
        "comments": [],
        "commit_messages": [
            "all: remove legacy health check handlers\n\nLegacy health checks migrated to split health checks, which are now the\ndefault. Split health checks are not sent to apps by default, so these\nhandlers are not working as intended.\n\nNone of the app.yaml files have health checks configured, so I chose not\nto add new split handlers & configuration."
        ],
        "last_commit_sha": "4c4973ce09e08a0a9161a3e1ecf3bada8089deb5"
    },
    {
        "pr_title": "storage: enable bucket object lifecycle management",
        "pr_number": 1424,
        "file_name": "storage/buckets/buckets_test.go",
        "code_diff": "@@ -16,13 +16,16 @@\npackage buckets\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"os\"\n+\t\"reflect\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [
            {
                "comment": "Do we need to make sure this bucket exists? Can use `testutil.CleanBucket`.",
                "position": 23
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "6f813336bf9c6da89c45447e226f1dbd373bccfe"
    },
    {
        "pr_title": "functions: update ocr sample to use environment variables",
        "pr_number": 1403,
        "file_name": "functions/ocr/app/ocr_test.go",
        "code_diff": "@@ -38,28 +38,23 @@\nconst (\n )\n \n var (\n-\tprojectID       string\n-\tbucketName      string\n \timageBucketName string\n )\n \n-// TestMain sets up the config rather than using the config file\n-// which contains placeholder values.\n func setupTests(t *testing.T) {\n \tctx := context.Background()\n \tprojectID = os.Getenv(\"GOLANG_SAMPLES_PROJECT_ID\")\n \tif projectID == \"\" {\n \t\tt.Skip(\"GOLANG_SAMPLES_PROJECT_ID is unset\")\n \t}\n-\tbucketName = fmt.Sprintf(\"%s-result\", projectID)\n+\tresultBucket = fmt.Sprintf(\"%s-result\", projectID)\n+\tos.Setenv(\"GOOGLE_CLOUD_PROJECT\", projectID)\n+\tos.Setenv(\"RESULT_BUCKET\", resultBucket)\n+\tos.Setenv(\"RESULT_TOPIC\", \"test-result-topic\")\n+\tos.Setenv(\"TO_LANG\", \"en,fr,es,ja,ru\")\n+\tos.Setenv(\"TRANSLATE_TOPIC\", \"test-translate-topic\")\n+\n \timageBucketName = \"cloud-samples-data/functions\"\n-\tconfig = &configuration{\n-\t\tProjectID:      projectID,\n-\t\tResultTopic:    \"test-result-topic\",\n-\t\tResultBucket:   bucketName,\n-\t\tTranslateTopic: \"test-translate-topic\",\n-\t\tToLang:         []string{\"en\", \"fr\", \"es\", \"ja\", \"ru\"},\n-\t}\n \n \tvar err error // Prevent shadowing clients with :=.\n \tvisionClient, err = vision.NewImageAnnotatorClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "01e158b0cffa7e0d0aa95f9dd097ef2924d42ee7"
    },
    {
        "pr_title": "functions: update ocr sample to use environment variables",
        "pr_number": 1403,
        "file_name": "functions/ocr/app/ocr_test.go",
        "code_diff": "@@ -82,8 +77,8 @@\nfunc setupTests(t *testing.T) {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n \n-\tif _, err := storageClient.Bucket(bucketName).Attrs(ctx); err != nil {\n-\t\tt.Skipf(\"Could not get bucket %v: %v\", bucketName, err)\n+\tif _, err := storageClient.Bucket(resultBucket).Attrs(ctx); err != nil {\n+\t\tt.Skipf(\"Could not get bucket %v: %v\", resultBucket, err)\n \t}\n }",
        "comments": [],
        "commit_messages": [
            "fix tests"
        ],
        "last_commit_sha": "01e158b0cffa7e0d0aa95f9dd097ef2924d42ee7"
    },
    {
        "pr_title": "functions: update ocr sample to use environment variables",
        "pr_number": 1403,
        "file_name": "functions/ocr/app/save.go",
        "code_diff": "@@ -23,8 +23,9 @@\nimport (\n \t\"log\"\n )\n \n-// SaveResult is executed when a message is published to the Cloud Pub/Sub topic specified by\n-// RESULT_TOPIC in config.json file, and saves the data packet to a file in GCS.\n+// SaveResult is executed when a message is published to the Cloud Pub/Sub topic\n+// specified by the RESULT_TOPIC environment vairable, and saves the data packet\n+// to a file in GCS.\n func SaveResult(ctx context.Context, event PubSubMessage) error {\n \tif err := setup(ctx); err != nil {\n \t\treturn fmt.Errorf(\"ProcessImage: %v\", err)",
        "comments": [],
        "commit_messages": [
            "functions: update ocr sample to use environment variables"
        ],
        "last_commit_sha": "01e158b0cffa7e0d0aa95f9dd097ef2924d42ee7"
    },
    {
        "pr_title": "functions: update ocr sample to use environment variables",
        "pr_number": 1403,
        "file_name": "functions/ocr/app/setup.go",
        "code_diff": "@@ -20,9 +20,9 @@\npackage ocr\n \n import (\n \t\"context\"\n-\t\"encoding/json\"\n \t\"fmt\"\n \t\"os\"\n+\t\"strings\"\n \t\"time\"\n \n \t\"cloud.google.com/go/pubsub\"",
        "comments": [],
        "commit_messages": [
            "functions: update ocr sample to use environment variables"
        ],
        "last_commit_sha": "01e158b0cffa7e0d0aa95f9dd097ef2924d42ee7"
    },
    {
        "pr_title": "functions: update ocr sample to use environment variables",
        "pr_number": 1403,
        "file_name": "functions/ocr/app/setup.go",
        "code_diff": "@@ -32,14 +32,6 @@\nimport (\n \t\"golang.org/x/text/language\"\n )\n \n-type configuration struct {\n-\tProjectID      string   `json:\"PROJECT_ID\"`\n-\tResultTopic    string   `json:\"RESULT_TOPIC\"`\n-\tResultBucket   string   `json:\"RESULT_BUCKET\"`\n-\tTranslateTopic string   `json:\"TRANSLATE_TOPIC\"`\n-\tToLang         []string `json:\"TO_LANG\"`\n-}\n-\n type ocrMessage struct {\n \tText     string       `json:\"text\"`\n \tFileName string       `json:\"fileName\"`",
        "comments": [],
        "commit_messages": [
            "functions: update ocr sample to use environment variables"
        ],
        "last_commit_sha": "01e158b0cffa7e0d0aa95f9dd097ef2924d42ee7"
    },
    {
        "pr_title": "functions: update ocr sample to use environment variables",
        "pr_number": 1403,
        "file_name": "functions/ocr/app/setup.go",
        "code_diff": "@@ -67,22 +59,20 @@\nvar (\n \ttranslateClient *translate.Client\n \tpubsubClient    *pubsub.Client\n \tstorageClient   *storage.Client\n-\tconfig          *configuration\n+\n+\tprojectID      string\n+\tresultBucket   string\n+\tresultTopic    string\n+\ttoLang         []string\n+\ttranslateTopic string\n )\n \n func setup(ctx context.Context) error {\n-\tif config == nil {\n-\t\tcfgFile, err := os.Open(\"config.json\")\n-\t\tif err != nil {\n-\t\t\treturn fmt.Errorf(\"os.Open: %v\", err)\n-\t\t}\n-\n-\t\td := json.NewDecoder(cfgFile)\n-\t\tconfig = &configuration{}\n-\t\tif err = d.Decode(config); err != nil {\n-\t\t\treturn fmt.Errorf(\"Decode: %v\", err)\n-\t\t}\n-\t}\n+\tprojectID = os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n+\tresultBucket = os.Getenv(\"RESULT_BUCKET\")\n+\tresultTopic = os.Getenv(\"RESULT_TOPIC\")\n+\ttoLang = strings.Split(os.Getenv(\"TO_LANG\"), \",\")\n+\ttranslateTopic = os.Getenv(\"TRANSLATE_TOPIC\")\n \n \tvar err error // Prevent shadowing clients with :=.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "01e158b0cffa7e0d0aa95f9dd097ef2924d42ee7"
    },
    {
        "pr_title": "functions: update ocr sample to use environment variables",
        "pr_number": 1403,
        "file_name": "functions/ocr/app/translate.go",
        "code_diff": "@@ -26,8 +26,9 @@\nimport (\n \t\"cloud.google.com/go/translate\"\n )\n \n-// TranslateText is executed when a message is published to the Cloud Pub/Sub topic specified\n-// by TRANSLATE_TOPIC in config.json, and translates the text using the Google Translate API.\n+// TranslateText is executed when a message is published to the Cloud Pub/Sub\n+// topic specified by the TRANSLATE_TOPIC environment variable, and translates\n+// the text using the Google Translate API.\n func TranslateText(ctx context.Context, event PubSubMessage) error {\n \tif err := setup(ctx); err != nil {\n \t\treturn fmt.Errorf(\"setup: %v\", err)",
        "comments": [],
        "commit_messages": [
            "functions: update ocr sample to use environment variables"
        ],
        "last_commit_sha": "01e158b0cffa7e0d0aa95f9dd097ef2924d42ee7"
    },
    {
        "pr_title": "storage: add PostPolicyV4 sample",
        "pr_number": 1392,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -18,8 +18,11 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n+\t\"io\"\n \t\"io/ioutil\"\n+\t\"mime/multipart\"\n \t\"net/http\"\n+\t\"net/http/httputil\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "storage: add PostPolicyV4 sample\n\nAdd sample for GenerateSignedPostPolicyV4 method, which generates\na signed post policy using V4 signing and creates an upload form\nbased on the policy.\n\nDepends on https://code-review.googlesource.com/c/gocloud/+/55330\nwhich still needs to be merged and released."
        ],
        "last_commit_sha": "a0e336aa7c813e4fccdbc5264a282dc41b32f064"
    },
    {
        "pr_title": "securitycenter: fix broken ListAssets test, stop skipping tests",
        "pr_number": 1379,
        "file_name": "securitycenter/assets/assets_test.go",
        "code_diff": "@@ -200,7 +200,6 @@\nfunc TestListAllProjectAssets(t *testing.T) {\n }\n \n func TestListAllProjectAssetsAtTime(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/1375\")\n \torgID := setup(t)\n \tbuf := new(bytes.Buffer)\n \tvar nothingInstant = time.Date(2019, 1, 1, 0, 0, 0, 0, time.UTC)",
        "comments": [],
        "commit_messages": [
            "remove skip"
        ],
        "last_commit_sha": "a9bd0e4c086b1391acb21ff3c7c74642e880b775"
    },
    {
        "pr_title": "securitycenter: fix broken ListAssets test, stop skipping tests",
        "pr_number": 1379,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -117,7 +117,6 @@\nfunc cleanupNotificationConfig(t *testing.T, notificationConfigID string) error\n }\n \n func TestCreateNotificationConfig(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/1352\")\n \tbuf := new(bytes.Buffer)\n \trand, err := uuid.NewUUID()\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "remove notification test skips"
        ],
        "last_commit_sha": "a9bd0e4c086b1391acb21ff3c7c74642e880b775"
    },
    {
        "pr_title": "securitycenter: fix broken ListAssets test, stop skipping tests",
        "pr_number": 1379,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -137,7 +136,6 @@\nfunc TestCreateNotificationConfig(t *testing.T) {\n }\n \n func TestDeleteNotificationConfig(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/1353\")\n \tbuf := new(bytes.Buffer)\n \trand, err := uuid.NewUUID()\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "remove notification test skips"
        ],
        "last_commit_sha": "a9bd0e4c086b1391acb21ff3c7c74642e880b775"
    },
    {
        "pr_title": "securitycenter: fix broken ListAssets test, stop skipping tests",
        "pr_number": 1379,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -159,7 +157,6 @@\nfunc TestDeleteNotificationConfig(t *testing.T) {\n }\n \n func TestGetNotificationConfig(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/1354\")\n \tbuf := new(bytes.Buffer)\n \trand, err := uuid.NewUUID()\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "remove notification test skips"
        ],
        "last_commit_sha": "a9bd0e4c086b1391acb21ff3c7c74642e880b775"
    },
    {
        "pr_title": "securitycenter: fix broken ListAssets test, stop skipping tests",
        "pr_number": 1379,
        "file_name": "securitycenter/notifications/notifications_test.go",
        "code_diff": "@@ -183,7 +180,6 @@\nfunc TestGetNotificationConfig(t *testing.T) {\n }\n \n func TestListNotificationConfigs(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/1355\")\n \tbuf := new(bytes.Buffer)\n \trand, err := uuid.NewUUID()\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "remove notification test skips"
        ],
        "last_commit_sha": "a9bd0e4c086b1391acb21ff3c7c74642e880b775"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/create_key_asymmetric_decrypt.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [
            {
                "comment": "I guess we update the year since this is a new file?",
                "position": 2
            },
            {
                "comment": "Yup \ud83d\ude04 ",
                "position": 2
            }
        ],
        "commit_messages": [
            "kms: update and add new samples"
        ],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/create_key_labels.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/create_key_ring.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "kms: update and add new samples"
        ],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/decrypt_asymmetric.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "kms: update and add new samples"
        ],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/decrypt_symmetric.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "kms: update and add new samples"
        ],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/destroy_key_version.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "kms: update and add new samples"
        ],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/disable_key_version.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "kms: update and add new samples"
        ],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/disable_key_version.go",
        "code_diff": "@@ -14,25 +14,28 @@\npackage kms\n \n-// [START kms_disable_cryptokey_version]\n+// [START kms_disable_key_version]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \n-\tcloudkms \"cloud.google.com/go/kms/apiv1\"\n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n \tfieldmask \"google.golang.org/genproto/protobuf/field_mask\"\n )\n \n-// disableCryptoKeyVersion disables a specified key version on KMS.\n-func disableCryptoKeyVersion(w io.Writer, name string) error {\n-\t// name := \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n+// disableKeyVersion disables the specified key version on Cloud KMS.\n+func disableKeyVersion(w io.Writer, name string) error {\n+\t// parent := \"projects/my-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key/cryptoKeyVersions/123\"\n+\n+\t// Create the client.\n \tctx := context.Background()\n-\tclient, err := cloudkms.NewKeyManagementClient(ctx)\n+\tclient, err := kms.NewKeyManagementClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"cloudkms.NewKeyManagementClient: %v\", err)\n+\t\treturn fmt.Errorf(\"failed to create kms client: %v\", err)\n \t}\n+\n \t// Build the request.\n \treq := &kmspb.UpdateCryptoKeyVersionRequest{\n \t\tCryptoKeyVersion: &kmspb.CryptoKeyVersion{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/enable_key_version.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "kms: update and add new samples"
        ],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/enable_key_version.go",
        "code_diff": "@@ -14,25 +14,28 @@\npackage kms\n \n-// [START kms_enable_cryptokey_version]\n+// [START kms_enable_key_version]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \n-\tcloudkms \"cloud.google.com/go/kms/apiv1\"\n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n \tfieldmask \"google.golang.org/genproto/protobuf/field_mask\"\n )\n \n-// enableCryptoKeyVersion enables a previously disabled key version on KMS.\n-func enableCryptoKeyVersion(w io.Writer, name string) error {\n-\t// name := \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n+// enableKeyVersion disables the specified key version on Cloud KMS.\n+func enableKeyVersion(w io.Writer, name string) error {\n+\t// parent := \"projects/my-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key/cryptoKeyVersions/123\"\n+\n+\t// Create the client.\n \tctx := context.Background()\n-\tclient, err := cloudkms.NewKeyManagementClient(ctx)\n+\tclient, err := kms.NewKeyManagementClient(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"cloudkms.NewKeyManagementClient: %v\", err)\n+\t\treturn fmt.Errorf(\"failed to create kms client: %v\", err)\n \t}\n+\n \t// Build the request.\n \treq := &kmspb.UpdateCryptoKeyVersionRequest{\n \t\tCryptoKeyVersion: &kmspb.CryptoKeyVersion{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/get_key_labels.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/quickstart/quickstart.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "kms: update and add new samples"
        ],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/quickstart/quickstart.go",
        "code_diff": "@@ -22,34 +22,34 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \n-\tcloudkms \"cloud.google.com/go/kms/apiv1\"\n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \t\"google.golang.org/api/iterator\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n )\n \n func main() {\n+\t// GCP project with which to communicate.\n \tprojectID := \"your-project-id\"\n-\t// Location of the key rings.\n+\n+\t// Location in which to list key rings.\n \tlocationID := \"global\"\n \n-\t// Create the KMS client.\n+\t// Create the client.\n \tctx := context.Background()\n-\tclient, err := cloudkms.NewKeyManagementClient(ctx)\n+\tclient, err := kms.NewKeyManagementClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\tlog.Fatalf(\"failed to setup client: %v\", err)\n \t}\n \n-\t// The resource name of the key rings.\n-\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", projectID, locationID)\n-\n-\t// Build the request.\n-\treq := &kmspb.ListKeyRingsRequest{\n-\t\tParent: parent,\n+\t// Create the request to list KeyRings.\n+\tlistKeyRingsReq := &kmspb.ListKeyRingsRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%s/locations/%s\", projectID, locationID),\n \t}\n-\t// Query the API.\n-\tit := client.ListKeyRings(ctx, req)\n \n-\t// Iterate and print results.\n+\t// List the KeyRings.\n+\tit := client.ListKeyRings(ctx, listKeyRingsReq)\n+\n+\t// Iterate and print the results.\n \tfor {\n \t\tresp, err := it.Next()\n \t\tif err == iterator.Done {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/restore_key_version.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "kms: update and add new samples"
        ],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/sign_asymmetric.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "kms: update and add new samples"
        ],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "kms: add new samples and adopt new format",
        "pr_number": 1341,
        "file_name": "kms/sign_asymmetric.go",
        "code_diff": "@@ -19,25 +19,39 @@\nimport (\n \t\"context\"\n \t\"crypto/sha256\"\n \t\"fmt\"\n+\t\"io\"\n \n-\tcloudkms \"cloud.google.com/go/kms/apiv1\"\n+\tkms \"cloud.google.com/go/kms/apiv1\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n )\n \n-// signAsymmetric will sign a plaintext message using a saved asymmetric private key.\n-func signAsymmetric(name string, message []byte) ([]byte, error) {\n-\t// name: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n-\t// Note: some key algorithms will require a different hash function.\n-\t// For example, EC_SIGN_P384_SHA384 requires SHA-384.\n+// signAsymmetric will sign a plaintext message using a saved asymmetric private\n+// key stored in Cloud KMS.\n+func signAsymmetric(w io.Writer, name string, message string) error {\n+\t// name := \"projects/my-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key/cryptoKeyVersions/123\"\n+\t// message := \"my message\"\n+\n+\t// Create the client.\n \tctx := context.Background()\n-\tclient, err := cloudkms.NewKeyManagementClient(ctx)\n+\tclient, err := kms.NewKeyManagementClient(ctx)\n \tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"cloudkms.NewKeyManagementClient: %v\", err)\n+\t\treturn fmt.Errorf(\"failed to create kms client: %v\", err)\n \t}\n-\t// Find the digest of the message.\n+\n+\t// Convert the message into bytes. Cryptographic plaintexts and\n+\t// ciphertexts are always byte arrays.\n+\tplaintext := []byte(message)\n+\n+\t// Calculate the digest of the message.\n \tdigest := sha256.New()\n-\tdigest.Write(message)\n+\tif _, err := digest.Write(plaintext); err != nil {\n+\t\treturn fmt.Errorf(\"failed to create digest: %v\", err)\n+\t}\n+\n \t// Build the signing request.\n+\t//\n+\t// Note: Key algorithms will require a varying hash function. For example,\n+\t// EC_SIGN_P384_SHA384 requires SHA-384.\n \treq := &kmspb.AsymmetricSignRequest{\n \t\tName: name,\n \t\tDigest: &kmspb.Digest{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b87e310e118b26ee451125dc085207c7a0fb60c5"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\npackage topics\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"io/ioutil\"\n \t\"sync\"\n \t\"testing\"\n \t\"time\"",
        "comments": [
            {
                "comment": "Calling `setup` twice? I see the test below does this, too. I'm not sure why.",
                "position": 23
            }
        ],
        "commit_messages": [
            "remove arguent n and id from Fprintf"
        ],
        "last_commit_sha": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "pubsub: update publish with batch settings sample to queue 10 messages ",
        "pr_number": 1308,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -117,7 +118,6 @@\nfunc TestPublish(t *testing.T) {\n func TestPublishThatScales(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n-\tsetup(t)\n \tclient := setup(t)\n \tclient.CreateTopic(ctx, topicID)\n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "added continue, len(slice) != 0, remove setups"
        ],
        "last_commit_sha": "3dab20b1d42d8993322fae07d772bc366f47c2dd"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -28,18 +28,25 @@\nimport (\n \n \t\"cloud.google.com/go/civil\"\n \t\"cloud.google.com/go/spanner\"\n-\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n+\t\"github.com/golang/protobuf/ptypes\"\n \t\"google.golang.org/api/iterator\"\n \t\"google.golang.org/api/option\"\n+\t\"google.golang.org/genproto/googleapis/longrunning\"\n \t\"google.golang.org/grpc\"\n+\t\"google.golang.org/grpc/codes\"\n \n+\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n+\tpbts \"github.com/golang/protobuf/ptypes\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n \tsppb \"google.golang.org/genproto/googleapis/spanner/v1\"\n+\t\"google.golang.org/genproto/protobuf/field_mask\"\n+\t\"google.golang.org/grpc/status\"\n )\n \n type command func(ctx context.Context, w io.Writer, client *spanner.Client) error\n type newClientCommand func(ctx context.Context, w io.Writer, database string) error\n type adminCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error\n+type backupCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error\n \n var (\n \tcommands = map[string]command{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -109,6 +116,17 @@\nvar (\n \t\t\"createtablewithdatatypes\":        createTableWithDatatypes,\n \t\t\"createtabledocswithtimestamp\":    createTableDocumentsWithTimestamp,\n \t\t\"createtabledocswithhistorytable\": createTableDocumentsWithHistoryTable,\n+\t\t\"listbackupoperations\":            listBackupOperations,\n+\t\t\"listdatabaseoperations\":          listDatabaseOperations,\n+\t}\n+\n+\tbackupCommands = map[string]backupCommand{\n+\t\t\"createbackup\":  createBackup,\n+\t\t\"cancelbackup\":  cancelBackup,\n+\t\t\"listbackups\":   listBackups,\n+\t\t\"updatebackup\":  updateBackup,\n+\t\t\"deletebackup\":  deleteBackup,\n+\t\t\"restorebackup\": restoreBackup,\n \t}\n )",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1894,6 +1912,343 @@\nfunc createClientWithQueryOptions(ctx context.Context, w io.Writer, database str\n \n // [END spanner_create_client_with_query_options]\n \n+// [START spanner_create_backup]\n+\n+func createBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\texpireTime := time.Now().AddDate(0, 0, 14)\n+\t// Create a backup.\n+\top, err := adminClient.StartBackupOperation(ctx, backupID, database, expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Wait for backup operation to complete.\n+\tbackup, err := op.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Get the name, create time and backup size.\n+\tcreateTime := time.Unix(backup.CreateTime.Seconds, int64(backup.CreateTime.Nanos))\n+\tfmt.Fprintf(w, \"Backup %s of size %d bytes was created at %s\\n\", backup.Name, backup.SizeBytes, createTime.Format(time.RFC3339))\n+\treturn nil\n+}\n+\n+// [END spanner_create_backup]\n+\n+// [START spanner_cancel_backup_create]\n+\n+func cancelBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\texpireTime := time.Now().AddDate(0, 0, 14)\n+\t// Create a backup.\n+\top, err := adminClient.StartBackupOperation(ctx, backupID, database, expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Cancel backup creation.\n+\terr = adminClient.LROClient.CancelOperation(ctx, &longrunning.CancelOperationRequest{Name: op.Name()})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Cancel operations are best effort so either it will complete or be\n+\t// cancelled.\n+\tbackup, err := op.Wait(ctx)\n+\tif err != nil {\n+\t\tif waitStatus, ok := status.FromError(err); !ok || waitStatus.Code() != codes.Canceled {\n+\t\t\treturn err\n+\t\t}\n+\t} else {\n+\t\t// Backup was completed before it could be cancelled so delete the\n+\t\t// unwanted backup.\n+\t\terr = adminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: backup.Name})\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\n+\tfmt.Fprintf(w, \"Backup cancelled.\\n\")\n+\treturn nil\n+}\n+\n+// [END spanner_cancel_backup_create]\n+\n+// [START spanner_list_backups]\n+\n+func listBackups(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, db, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(db)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", db)\n+\t}\n+\tinstanceName := matches[1]\n+\n+\tprintBackups := func(iter *database.BackupIterator) error {\n+\t\tfor {\n+\t\t\tresp, err := iter.Next()\n+\t\t\tif err == iterator.Done {\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t\tif err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tfmt.Fprintf(w, \"Backup %s\\n\", resp.Name)\n+\t\t}\n+\t}\n+\n+\tvar iter *database.BackupIterator\n+\tvar filter string\n+\t// List all backups.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups that contain a name.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"name:\" + backupID,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups that expire before a timestamp.\n+\texpireTime := time.Now().AddDate(0, 0, 30)\n+\tfilter = fmt.Sprintf(`expire_time < \"%s\"`, expireTime.Format(time.RFC3339))\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups for a database that contains a name.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"database:\" + db,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List all backups with a size greater than some bytes.\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: \"size_bytes > 100\",\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List backups that were created after a timestamp that are also ready.\n+\tcreateTime := time.Now().AddDate(0, 0, -1)\n+\tfilter = fmt.Sprintf(\n+\t\t`create_time >= \"%s\" AND state:READY`,\n+\t\tcreateTime.Format(time.RFC3339),\n+\t)\n+\titer = adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tif err := printBackups(iter); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// List backups with pagination.\n+\trequest := &adminpb.ListBackupsRequest{\n+\t\tParent:   instanceName,\n+\t\tPageSize: 10,\n+\t}\n+\tfor {\n+\t\titer = adminClient.ListBackups(ctx, request)\n+\t\tif err := printBackups(iter); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tpageToken := iter.PageInfo().Token\n+\t\tif pageToken == \"\" {\n+\t\t\tbreak\n+\t\t} else {\n+\t\t\trequest.PageToken = pageToken\n+\t\t}\n+\t}\n+\n+\tfmt.Fprintf(w, \"Backups listed.\\n\")\n+\treturn nil\n+}\n+\n+// [END spanner_list_backups]\n+\n+// [START spanner_list_backup_operations]\n+\n+func listBackupOperations(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\t// List the CreateBackup operations.\n+\tfilter := fmt.Sprintf(\"(metadata.database:%s) AND (metadata.@type:type.googleapis.com/google.spanner.admin.database.v1.CreateBackupMetadata)\", database)\n+\titer := adminClient.ListBackupOperations(ctx, &adminpb.ListBackupOperationsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tmetadata := &adminpb.CreateBackupMetadata{}\n+\t\tif err := ptypes.UnmarshalAny(resp.Metadata, metadata); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"Backup %s on database %s is %d%% complete.\\n\",\n+\t\t\tmetadata.Name,\n+\t\t\tmetadata.Database,\n+\t\t\tmetadata.Progress.ProgressPercent,\n+\t\t)\n+\t}\n+\treturn nil\n+}\n+\n+// [END spanner_list_backup_operations]\n+\n+// [START spanner_list_database_operations]\n+\n+func listDatabaseOperations(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\t// List the databases that are being optimized after a restore operation.\n+\tfilter := \"(metadata.@type:type.googleapis.com/google.spanner.admin.database.v1.OptimizeRestoredDatabaseMetadata)\"\n+\titer := adminClient.ListDatabaseOperations(ctx, &adminpb.ListDatabaseOperationsRequest{\n+\t\tParent: instanceName,\n+\t\tFilter: filter,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tmetadata := &adminpb.OptimizeRestoredDatabaseMetadata{}\n+\t\tif err := ptypes.UnmarshalAny(resp.Metadata, metadata); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"Database %s restored from backup is %d%% optimized.\\n\",\n+\t\t\tmetadata.Name,\n+\t\t\tmetadata.Progress.ProgressPercent,\n+\t\t)\n+\t}\n+\treturn nil\n+}\n+\n+// [END spanner_list_database_operations]\n+\n+// [START spanner_update_backup]\n+\n+func updateBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tbackupName := matches[1] + \"/backups/\" + backupID\n+\n+\tbackup, err := adminClient.GetBackup(ctx, &adminpb.GetBackupRequest{Name: backupName})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Expire time must be within 366 days of the create time of the backup.\n+\texpireTime := time.Unix(backup.CreateTime.Seconds, int64(backup.CreateTime.Nanos)).AddDate(0, 0, 30)\n+\texpirespb, err := pbts.TimestampProto(expireTime)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t_, err = adminClient.UpdateBackup(ctx, &adminpb.UpdateBackupRequest{\n+\t\tBackup: &adminpb.Backup{\n+\t\t\tName:       backupName,\n+\t\t\tExpireTime: expirespb,\n+\t\t},\n+\t\tUpdateMask: &field_mask.FieldMask{Paths: []string{\"expire_time\"}},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Fprintf(w, \"Updated backup %s\\n\", backupID)\n+\treturn nil\n+}\n+\n+// [END spanner_update_backup]\n+\n+// [START spanner_restore_backup]\n+\n+func restoreBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tinstanceName := matches[1]\n+\tdatabaseID := matches[2]\n+\tbackupName := instanceName + \"/backups/\" + backupID\n+\n+\t// Start restoring backup to a new database.\n+\trestoreOp, err := adminClient.RestoreDatabase(ctx, &adminpb.RestoreDatabaseRequest{\n+\t\tParent:     instanceName,\n+\t\tDatabaseId: databaseID,\n+\t\tSource: &adminpb.RestoreDatabaseRequest_Backup{\n+\t\t\tBackup: backupName,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Wait for restore operation to complete.\n+\tdb, err := restoreOp.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Newly created database has restore information.\n+\tbackupInfo := db.RestoreInfo.GetBackupInfo()\n+\tif backupInfo != nil {\n+\t\tfmt.Fprintf(w, \"Source database %s restored from backup %s\\n\", backupInfo.SourceDatabase, backupInfo.Backup)\n+\t}\n+\n+\treturn nil\n+}\n+\n+// [END spanner_restore_backup]\n+\n+// [START spanner_delete_backup]\n+\n+func deleteBackup(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database, backupID string) error {\n+\tmatches := regexp.MustCompile(\"^(.*)/databases/(.*)$\").FindStringSubmatch(database)\n+\tif matches == nil || len(matches) != 3 {\n+\t\treturn fmt.Errorf(\"Invalid database id %s\", database)\n+\t}\n+\tbackupName := matches[1] + \"/backups/\" + backupID\n+\t// Delete the backup.\n+\terr := adminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: backupName})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Deleted backup %s\\n\", backupID)\n+\treturn nil\n+}\n+\n+// [END spanner_delete_backup]\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \t// [START spanner_create_admin_client_for_emulator]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1924,7 +2279,7 @@\nfunc createClients(ctx context.Context, db string) (*database.DatabaseAdminClien\n \treturn adminClient, dataClient\n }\n \n-func run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, w io.Writer, cmd string, db string) error {\n+func run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, w io.Writer, cmd string, db string, backupID string) error {\n \tif adminCmdFn := adminCommands[cmd]; adminCmdFn != nil {\n \t\terr := adminCmdFn(ctx, w, adminClient, db)\n \t\tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1933,6 +2288,15 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \t\treturn err\n \t}\n \n+\t// Command that needs a backup ID.\n+\tif backupCmdFn := backupCommands[cmd]; backupCmdFn != nil {\n+\t\terr := backupCmdFn(ctx, w, adminClient, db, backupID)\n+\t\tif err != nil {\n+\t\t\tfmt.Fprintf(w, \"%s failed with %v\", cmd, err)\n+\t\t}\n+\t\treturn err\n+\t}\n+\n \t// Command that needs to create a new client.\n \tif newClientCmdFn := newClientCommands[cmd]; newClientCmdFn != nil {\n \t\terr := newClientCmdFn(ctx, w, db)",
        "comments": [],
        "commit_messages": [
            "Refactor to meet the latest test spec."
        ],
        "last_commit_sha": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1957,7 +2321,7 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \n func main() {\n \tflag.Usage = func() {\n-\t\tfmt.Fprintf(os.Stderr, `Usage: spanner_snippets <command> <database_name>\n+\t\tfmt.Fprintf(os.Stderr, `Usage: spanner_snippets <command> <database_name> <backup_id>\n \n \tCommand can be one of: createdatabase, write, query, read, update,\n \t\twritetransaction, addnewcolumn, querynewcolumn, addindex, queryindex, readindex,",
        "comments": [],
        "commit_messages": [
            "Refactor to meet the latest test spec."
        ],
        "last_commit_sha": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -23,36 +23,23 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/spanner\"\n+\tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n-func TestSample(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n+type runCommandFunc func(t *testing.T, cmd, dbName string) string\n+type runBackupCommandFunc func(t *testing.T, cmd, dbName, backupID string) string\n \n-\tinstance := os.Getenv(\"GOLANG_SAMPLES_SPANNER\")\n-\tif instance == \"\" {\n-\t\tt.Skip(\"Skipping spanner integration test. Set GOLANG_SAMPLES_SPANNER.\")\n-\t}\n-\tif !strings.HasPrefix(instance, \"projects/\") {\n-\t\tt.Fatal(\"Spanner instance ref must be in the form of 'projects/PROJECT_ID/instances/INSTANCE_ID'\")\n-\t}\n-\tdbName := fmt.Sprintf(\"%s/databases/test-%s\", instance, tc.ProjectID)\n+func initTest(t *testing.T, projectID string) (dbName string, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client, runCommand runCommandFunc, mustRunCommand runCommandFunc, cleanup func()) {\n+\tinstance := getInstance(t)\n+\tdatabaseID := validLength(fmt.Sprintf(\"test-%s\", projectID), t)\n+\tdbName = fmt.Sprintf(\"%s/databases/%s\", instance, databaseID)\n \n \tctx := context.Background()\n-\tadminClient, dataClient := createClients(ctx, dbName)\n-\tdefer adminClient.Close()\n-\t// The database should be dropped after closing the data client (defer is\n-\t// called in a LIFO order).\n-\tdefer func() {\n-\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n-\t\t\tif err != nil {\n-\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n-\t\t\t}\n-\t\t})\n-\t}()\n-\tdefer dataClient.Close()\n+\tadminClient, dataClient = createClients(ctx, dbName)\n \n \t// Check for database existance prior to test start and delete, as resources may not have\n \t// been cleaned up from previous invocations.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "spanner: code samples for backups",
        "pr_number": 1296,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -61,28 +48,89 @@\nfunc TestSample(t *testing.T) {\n \t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName}))\n \t}\n \n-\tassertContains := func(t *testing.T, out string, sub string) {\n+\trunCommand = func(t *testing.T, cmd, dbName string) string {\n \t\tt.Helper()\n-\t\tif !strings.Contains(out, sub) {\n-\t\t\tt.Errorf(\"got output %q; want it to contain %q\", out, sub)\n+\t\tvar b bytes.Buffer\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, \"\"); err != nil {\n+\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n+\t\treturn b.String()\n \t}\n-\trunCommand := func(t *testing.T, cmd string, dbName string) string {\n+\tmustRunCommand = func(t *testing.T, cmd, dbName string) string {\n \t\tt.Helper()\n \t\tvar b bytes.Buffer\n-\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName); err != nil {\n-\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, \"\"); err != nil {\n+\t\t\tt.Fatalf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n \t\treturn b.String()\n \t}\n-\tmustRunCommand := func(t *testing.T, cmd string, dbName string) string {\n+\tcleanup = func() {\n+\t\tdataClient.Close()\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", dbName, err)\n+\t\t\t}\n+\t\t})\n+\t\tadminClient.Close()\n+\t}\n+\treturn\n+}\n+\n+func initBackupTest(t *testing.T, projectID, dbName string, adminClient *database.DatabaseAdminClient, dataClient *spanner.Client) (restoreDBName, backupID, cancelledBackupID string, runBackupCommand runBackupCommandFunc, cleanup func()) {\n+\tinstance := getInstance(t)\n+\trestoreDatabaseID := validLength(fmt.Sprintf(\"restore-%s\", projectID), t)\n+\trestoreDBName = fmt.Sprintf(\"%s/databases/%s\", instance, restoreDatabaseID)\n+\tbackupID = validLength(fmt.Sprintf(\"backup-%s\", projectID), t)\n+\tcancelledBackupID = validLength(fmt.Sprintf(\"cancel-%s\", projectID), t)\n+\n+\tctx := context.Background()\n+\tif db, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: restoreDBName}); err == nil {\n+\t\tt.Logf(\"database %s exists in state %s. delete result: %v\", db.GetName(), db.GetState().String(),\n+\t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName}))\n+\t}\n+\n+\t// Check for any backups that were created from that database and delete those as well\n+\titer := adminClient.ListBackups(ctx, &adminpb.ListBackupsRequest{\n+\t\tParent: instance,\n+\t\tFilter: \"database:\" + dbName,\n+\t})\n+\tfor {\n+\t\tresp, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"Failed to list backups for database %s: %v\", dbName, err)\n+\t\t}\n+\t\tt.Logf(\"backup %s exists. delete result: %v\", resp.Name,\n+\t\t\tadminClient.DeleteBackup(ctx, &adminpb.DeleteBackupRequest{Name: resp.Name}))\n+\t}\n+\n+\trunBackupCommand = func(t *testing.T, cmd, dbName, backupID string) string {\n \t\tt.Helper()\n \t\tvar b bytes.Buffer\n-\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName); err != nil {\n-\t\t\tt.Fatalf(\"run(%q, %q): %v\", cmd, dbName, err)\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName, backupID); err != nil {\n+\t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n \t\treturn b.String()\n \t}\n+\tcleanup = func() {\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\terr := adminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: restoreDBName})\n+\t\t\tif err != nil {\n+\t\t\t\tr.Errorf(\"DropDatabase(%q): %v\", restoreDBName, err)\n+\t\t\t}\n+\t\t})\n+\t}\n+\treturn\n+}\n+\n+func TestSample(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\n+\tdbName, _, _, runCommand, mustRunCommand, cleanup := initTest(t, tc.ProjectID)\n+\tdefer cleanup()\n \n \t// We execute all the commands of the tutorial code. These commands have to be run in a specific\n \t// order since in many cases earlier commands setup the database for the subsequent commands.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "28a69793ca97b24ef4f01ea9461ebf22a08ebbd1"
    },
    {
        "pr_title": "pubsub: add samples for dead letter topics",
        "pr_number": 1279,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -29,6 +29,7 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/go-cmp/cmp\"\n )\n \n var topicID string",
        "comments": [
            {
                "comment": "`defer` calls are processed in LIFO order. So, might want to delete before stopping?",
                "position": 35
            },
            {
                "comment": "Stop actually has to be called prior to deletion, so this is intended.",
                "position": 35
            }
        ],
        "commit_messages": [
            "pubsub: add samples for dead letter topics"
        ],
        "last_commit_sha": "6bba4173ae59579f6caa818d2028178527ef0d58"
    },
    {
        "pr_title": "pubsub: add samples for dead letter topics",
        "pr_number": 1279,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -251,7 +252,7 @@\nfunc TestPullMsgsConcurrencyControl(t *testing.T) {\n \n \t// Publish 5 message to test with.\n \tconst numMsgs = 5\n-\tpublishMsgs(ctx, topic, 5)\n+\tpublishMsgs(ctx, topic, numMsgs)\n \n \tbuf := new(bytes.Buffer)\n \tif err := pullMsgsConcurrenyControl(buf, tc.ProjectID, subIDConc); err != nil {",
        "comments": [],
        "commit_messages": [
            "pubsub: fix license headers, add test for DeliveryAttempt"
        ],
        "last_commit_sha": "6bba4173ae59579f6caa818d2028178527ef0d58"
    },
    {
        "pr_title": "spanner: create admin client for emulator",
        "pr_number": 1278,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -30,6 +30,8 @@\nimport (\n \t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \t\"google.golang.org/api/iterator\"\n+\t\"google.golang.org/api/option\"\n+\t\"google.golang.org/grpc\"\n \n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )",
        "comments": [],
        "commit_messages": [
            "spanner: create admin client for emulator"
        ],
        "last_commit_sha": "c4cae917cebac2baedf6ba4e08ef440359a089c3"
    },
    {
        "pr_title": "spanner: code samples for query options",
        "pr_number": 1273,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -34,9 +34,11 @@\nimport (\n \t\"google.golang.org/grpc\"\n \n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n+\tsppb \"google.golang.org/genproto/googleapis/spanner/v1\"\n )\n \n type command func(ctx context.Context, w io.Writer, client *spanner.Client) error\n+type newClientCommand func(ctx context.Context, w io.Writer, database string) error\n type adminCommand func(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error\n \n var (",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "26c313864d7fe77b419f87f68c8776e2c5e48fb7"
    },
    {
        "pr_title": "spanner: code samples for query options",
        "pr_number": 1273,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -90,6 +92,11 @@\nvar (\n \t\t\"querywithint\":                queryWithInt,\n \t\t\"querywithstring\":             queryWithString,\n \t\t\"querywithtimestampparameter\": queryWithTimestampParameter,\n+\t\t\"querywithqueryoptions\":       queryWithQueryOptions,\n+\t}\n+\n+\tnewClientCommands = map[string]newClientCommand{\n+\t\t\"createclientwithqueryoptions\": createClientWithQueryOptions,\n \t}\n \n \tadminCommands = map[string]adminCommand{",
        "comments": [],
        "commit_messages": [
            "spanner: code samples for query options\n\nChange-Id: I5c8188de840ce0a46d778aa2c1e6eb272bd927fa"
        ],
        "last_commit_sha": "26c313864d7fe77b419f87f68c8776e2c5e48fb7"
    },
    {
        "pr_title": "spanner: code samples for query options",
        "pr_number": 1273,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1601,6 +1608,35 @@\nfunc queryWithTimestampParameter(ctx context.Context, w io.Writer, client *spann\n \n // [END spanner_query_with_timestamp_parameter]\n \n+// [START spanner_query_with_query_options]\n+\n+func queryWithQueryOptions(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tstmt := spanner.Statement{SQL: `SELECT VenueId, VenueName, LastUpdateTime FROM Venues`}\n+\tqueryOptions := spanner.QueryOptions{\n+\t\tOptions: &sppb.ExecuteSqlRequest_QueryOptions{OptimizerVersion: \"1\"},\n+\t}\n+\titer := client.Single().QueryWithOptions(ctx, stmt, queryOptions)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar lastUpdateTime time.Time\n+\t\tif err := row.Columns(&venueID, &venueName, &lastUpdateTime); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, lastUpdateTime)\n+\t}\n+}\n+\n+// [END spanner_query_with_query_options]\n+\n func queryNewTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n \tstmt := spanner.Statement{\n \t\tSQL: `SELECT SingerId, VenueId, EventDate, Revenue, LastUpdateTime FROM Performances",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "26c313864d7fe77b419f87f68c8776e2c5e48fb7"
    },
    {
        "pr_title": "spanner: code samples for query options",
        "pr_number": 1273,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1821,6 +1857,43 @@\nfunc queryWithHistory(ctx context.Context, w io.Writer, client *spanner.Client)\n \t}\n }\n \n+// [START spanner_create_client_with_query_options]\n+\n+func createClientWithQueryOptions(ctx context.Context, w io.Writer, database string) error {\n+\tqueryOptions := spanner.QueryOptions{\n+\t\tOptions: &sppb.ExecuteSqlRequest_QueryOptions{OptimizerVersion: \"1\"},\n+\t}\n+\tclient, err := spanner.NewClientWithConfig(\n+\t\tctx, database, spanner.ClientConfig{QueryOptions: queryOptions},\n+\t)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer client.Close()\n+\n+\tstmt := spanner.Statement{SQL: `SELECT VenueId, VenueName, LastUpdateTime FROM Venues`}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar lastUpdateTime time.Time\n+\t\tif err := row.Columns(&venueID, &venueName, &lastUpdateTime); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, lastUpdateTime)\n+\t}\n+}\n+\n+// [END spanner_create_client_with_query_options]\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \t// [START spanner_create_admin_client_for_emulator]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "26c313864d7fe77b419f87f68c8776e2c5e48fb7"
    },
    {
        "pr_title": "spanner: code samples for query options",
        "pr_number": 1273,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1860,6 +1933,15 @@\nfunc run(ctx context.Context, adminClient *database.DatabaseAdminClient, dataCli\n \t\treturn err\n \t}\n \n+\t// Command that needs to create a new client.\n+\tif newClientCmdFn := newClientCommands[cmd]; newClientCmdFn != nil {\n+\t\terr := newClientCmdFn(ctx, w, db)\n+\t\tif err != nil {\n+\t\t\tfmt.Fprintf(w, \"%s failed with %v\", cmd, err)\n+\t\t}\n+\t\treturn err\n+\t}\n+\n \t// Normal mode\n \tcmdFn := commands[cmd]\n \tif cmdFn == nil {",
        "comments": [],
        "commit_messages": [
            "spanner: code samples for query options\n\nChange-Id: I5c8188de840ce0a46d778aa2c1e6eb272bd927fa"
        ],
        "last_commit_sha": "26c313864d7fe77b419f87f68c8776e2c5e48fb7"
    },
    {
        "pr_title": "bigquery/bigquery_storage_quickstart: update to show v1 endpoint",
        "pr_number": 1268,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -33,11 +33,11 @@\nimport (\n \t\"sync\"\n \t\"time\"\n \n-\tbqStorage \"cloud.google.com/go/bigquery/storage/apiv1beta1\"\n+\tbqStorage \"cloud.google.com/go/bigquery/storage/apiv1\"\n \t\"github.com/golang/protobuf/ptypes\"\n \tgax \"github.com/googleapis/gax-go/v2\"\n \tgoavro \"github.com/linkedin/goavro/v2\"\n-\tbqStoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1beta1\"\n+\tbqStoragepb \"google.golang.org/genproto/googleapis/cloud/bigquery/storage/v1\"\n \t\"google.golang.org/grpc\"\n )",
        "comments": [
            {
                "comment": "Inline values and don't use `fmt.Sprintf`?",
                "position": 40
            },
            {
                "comment": "I didn't inline here as it's more common to have project/dataset/table in variables rather than pure literals as seen here.  Can drop it, but wanted a sample that's more quickly adapted for a new user.",
                "position": 40
            },
            {
                "comment": "In that case, we should probably stick them in variables right above this. As-is, it looks a little odd. :)",
                "position": 40
            },
            {
                "comment": "done",
                "position": 40
            }
        ],
        "commit_messages": [
            "bigquery/bigquery_storage_quickstart: update to show v1 endpoint"
        ],
        "last_commit_sha": "b5d2c6755ec3a1cdabf7b8d27143dddaa9ff926c"
    },
    {
        "pr_title": "bigquery/bigquery_storage_quickstart: update to show v1 endpoint",
        "pr_number": 1268,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -59,11 +59,11 @@\nvar (\n func main() {\n \tflag.Parse()\n \tctx := context.Background()\n-\tbqStorageClient, err := bqStorage.NewBigQueryStorageClient(ctx)\n+\tbqReadClient, err := bqStorage.NewBigQueryReadClient(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"NewBigQueryStorageClient: %v\", err)\n \t}\n-\tdefer bqStorageClient.Close()\n+\tdefer bqReadClient.Close()\n \n \t// Verify we've been provided a parent project which will contain the read session.  The\n \t// session may exist in a different project than the table being read.",
        "comments": [],
        "commit_messages": [
            "bigquery/bigquery_storage_quickstart: update to show v1 endpoint"
        ],
        "last_commit_sha": "b5d2c6755ec3a1cdabf7b8d27143dddaa9ff926c"
    },
    {
        "pr_title": "bigquery/bigquery_storage_quickstart: update to show v1 endpoint",
        "pr_number": 1268,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -72,31 +72,33 @@\nfunc main() {\n \t}\n \n \t// This example uses baby name data from the public datasets.\n-\treadTable := &bqStoragepb.TableReference{\n-\t\tProjectId: \"bigquery-public-data\",\n-\t\tDatasetId: \"usa_names\",\n-\t\tTableId:   \"usa_1910_current\",\n-\t}\n+\tsrcProjectID := \"bigquery-public-data\"\n+\tsrcDatasetID := \"usa_names\"\n+\tsrcTableID := \"usa_1910_current\"\n+\treadTable := fmt.Sprintf(\"projects/%s/datasets/%s/tables/%s\",\n+\t\tsrcProjectID,\n+\t\tsrcDatasetID,\n+\t\tsrcTableID,\n+\t)\n \n \t// We limit the output columns to a subset of those allowed in the table,\n \t// and set a simple filter to only report names from the state of\n \t// Washington (WA).\n-\ttableReadOptions := &bqStoragepb.TableReadOptions{\n+\ttableReadOptions := &bqStoragepb.ReadSession_TableReadOptions{\n \t\tSelectedFields: []string{\"name\", \"number\", \"state\"},\n \t\tRowRestriction: `state = \"WA\"`,\n \t}\n \n-\treadSessionRequest := &bqStoragepb.CreateReadSessionRequest{\n-\t\tParent:         fmt.Sprintf(\"projects/%s\", *projectID),\n-\t\tTableReference: readTable,\n-\t\tReadOptions:    tableReadOptions,\n-\t\t// This API can also deliver data serialized in Apache Arrow format.\n-\t\t// This example leverages Apache Avro.\n-\t\tFormat: bqStoragepb.DataFormat_AVRO,\n-\t\t// We use a LIQUID strategy in this example because we only\n-\t\t// read from a single stream.  Consider BALANCED if you're consuming\n-\t\t// multiple streams concurrently and want more consistent stream sizes.\n-\t\tShardingStrategy: bqStoragepb.ShardingStrategy_LIQUID,\n+\tcreateReadSessionRequest := &bqStoragepb.CreateReadSessionRequest{\n+\t\tParent: fmt.Sprintf(\"projects/%s\", *projectID),\n+\t\tReadSession: &bqStoragepb.ReadSession{\n+\t\t\tTable: readTable,\n+\t\t\t// This API can also deliver data serialized in Apache Arrow format.\n+\t\t\t// This example leverages Apache Avro.\n+\t\t\tDataFormat:  bqStoragepb.DataFormat_AVRO,\n+\t\t\tReadOptions: tableReadOptions,\n+\t\t},\n+\t\tMaxStreamCount: 1,\n \t}\n \n \t// Set a snapshot time if it's been specified.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b5d2c6755ec3a1cdabf7b8d27143dddaa9ff926c"
    },
    {
        "pr_title": "bigquery/bigquery_storage_quickstart: update to show v1 endpoint",
        "pr_number": 1268,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -105,13 +107,13 @@\nfunc main() {\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"Invalid snapshot millis (%d): %v\", *snapshotMillis, err)\n \t\t}\n-\t\treadSessionRequest.TableModifiers = &bqStoragepb.TableModifiers{\n+\t\tcreateReadSessionRequest.ReadSession.TableModifiers = &bqStoragepb.ReadSession_TableModifiers{\n \t\t\tSnapshotTime: ts,\n \t\t}\n \t}\n \n \t// Create the session from the request.\n-\tsession, err := bqStorageClient.CreateReadSession(ctx, readSessionRequest, rpcOpts)\n+\tsession, err := bqReadClient.CreateReadSession(ctx, createReadSessionRequest, rpcOpts)\n \tif err != nil {\n \t\tlog.Fatalf(\"CreateReadSession: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "bigquery/bigquery_storage_quickstart: update to show v1 endpoint"
        ],
        "last_commit_sha": "b5d2c6755ec3a1cdabf7b8d27143dddaa9ff926c"
    },
    {
        "pr_title": "bigquery/bigquery_storage_quickstart: update to show v1 endpoint",
        "pr_number": 1268,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -123,8 +125,8 @@\nfunc main() {\n \t// We'll use only a single stream for reading data from the table.  Because\n \t// of dynamic sharding, this will yield all the rows in the table. However,\n \t// if you wanted to fan out multiple readers you could do so by having a\n-\t// reader process each individual stream.\n-\treadStream := session.GetStreams()[0]\n+\t// increasing the MaxStreamCount.\n+\treadStream := session.GetStreams()[0].Name\n \n \tch := make(chan *bqStoragepb.AvroRows)",
        "comments": [],
        "commit_messages": [
            "bigquery/bigquery_storage_quickstart: update to show v1 endpoint"
        ],
        "last_commit_sha": "b5d2c6755ec3a1cdabf7b8d27143dddaa9ff926c"
    },
    {
        "pr_title": "bigquery/bigquery_storage_quickstart: update to show v1 endpoint",
        "pr_number": 1268,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -135,7 +137,7 @@\nfunc main() {\n \twg.Add(1)\n \tgo func() {\n \t\tdefer wg.Done()\n-\t\tif err := processStream(ctx, bqStorageClient, readStream, ch); err != nil {\n+\t\tif err := processStream(ctx, bqReadClient, readStream, ch); err != nil {\n \t\t\tlog.Fatalf(\"processStream failure: %v\", err)\n \t\t}\n \t\tclose(ch)",
        "comments": [],
        "commit_messages": [
            "bigquery/bigquery_storage_quickstart: update to show v1 endpoint"
        ],
        "last_commit_sha": "b5d2c6755ec3a1cdabf7b8d27143dddaa9ff926c"
    },
    {
        "pr_title": "bigquery/bigquery_storage_quickstart: update to show v1 endpoint",
        "pr_number": 1268,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -197,7 +199,7 @@\nfunc valueFromTypeMap(field interface{}) interface{} {\n // data blocks to a channel. This function will retry on transient stream\n // failures and bookmark progress to avoid re-reading data that's already been\n // successfully transmitted.\n-func processStream(ctx context.Context, client *bqStorage.BigQueryStorageClient, st *bqStoragepb.Stream, ch chan<- *bqStoragepb.AvroRows) error {\n+func processStream(ctx context.Context, client *bqStorage.BigQueryReadClient, st string, ch chan<- *bqStoragepb.AvroRows) error {\n \tvar offset int64\n \n \t// Streams may be long-running.  Rather than using a global retry for the",
        "comments": [],
        "commit_messages": [
            "bigquery/bigquery_storage_quickstart: update to show v1 endpoint"
        ],
        "last_commit_sha": "b5d2c6755ec3a1cdabf7b8d27143dddaa9ff926c"
    },
    {
        "pr_title": "all: goimports and fix storage test",
        "pr_number": 1265,
        "file_name": "storage/acl/acl_test.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n \n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n // TestACL runs all of the package tests.",
        "comments": [],
        "commit_messages": [
            "storage/acl: clean test bucket"
        ],
        "last_commit_sha": "cbb8567f8c1e1ec08cf861ab44685333ff3d0042"
    },
    {
        "pr_title": "all: goimports and fix storage test",
        "pr_number": 1265,
        "file_name": "storage/acl/acl_test.go",
        "code_diff": "@@ -41,10 +42,9 @@\nfunc TestACL(t *testing.T) {\n \t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers\n \t)\n \n+\tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n+\n \tb := client.Bucket(bucket)\n-\tif err := b.Create(ctx, tc.ProjectID, nil); err != nil {\n-\t\tt.Fatalf(\"Bucket(%q).Create: %v\", bucket, err)\n-\t}\n \n \t// Upload a test object with storage.Writer.\n \twc := b.Object(object).NewWriter(ctx)",
        "comments": [],
        "commit_messages": [
            "storage/acl: clean test bucket"
        ],
        "last_commit_sha": "cbb8567f8c1e1ec08cf861ab44685333ff3d0042"
    },
    {
        "pr_title": "storage: use V3 IAM API",
        "pr_number": 1251,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -28,6 +28,8 @@\nimport (\n \t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/storage\"\n \t\"google.golang.org/api/iterator\"\n+\tiampb \"google.golang.org/genproto/googleapis/iam/v1\"\n+\t\"google.golang.org/genproto/googleapis/type/expr\"\n )\n \n func main() {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8ea735be002a06c356bfd4d966c4c9b8fd2b28e3"
    },
    {
        "pr_title": "storage: use V3 IAM API",
        "pr_number": 1251,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -159,18 +161,18 @@\nfunc deleteBucket(client *storage.Client, bucketName string) error {\n \treturn nil\n }\n \n-func getPolicy(c *storage.Client, bucketName string) (*iam.Policy, error) {\n+func getPolicy(c *storage.Client, bucketName string) (*iam.Policy3, error) {\n \t// [START storage_get_bucket_policy]\n \tctx := context.Background()\n \n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n-\tpolicy, err := c.Bucket(bucketName).IAM().Policy(ctx)\n+\tpolicy, err := c.Bucket(bucketName).IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\tfor _, role := range policy.Roles() {\n-\t\tlog.Printf(\"%q: %q\", role, policy.Members(role))\n+\tfor _, binding := range policy.Bindings {\n+\t\tlog.Printf(\"%q: %q (condition: %v)\", binding.Role, binding.Members, binding.Condition)\n \t}\n \t// [END storage_get_bucket_policy]\n \treturn policy, nil",
        "comments": [],
        "commit_messages": [
            "storage: use V3 IAM API\n\nDO NOT SUBMIT"
        ],
        "last_commit_sha": "8ea735be002a06c356bfd4d966c4c9b8fd2b28e3"
    },
    {
        "pr_title": "storage: use V3 IAM API",
        "pr_number": 1251,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -183,15 +185,18 @@\nfunc addUser(c *storage.Client, bucketName string) error {\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n-\tpolicy, err := bucket.IAM().Policy(ctx)\n+\tpolicy, err := bucket.IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Other valid prefixes are \"serviceAccount:\", \"user:\"\n \t// See the documentation for more values.\n \t// https://cloud.google.com/storage/docs/access-control/iam\n-\tpolicy.Add(\"group:cloud-logs@google.com\", \"roles/storage.objectViewer\")\n-\tif err := bucket.IAM().SetPolicy(ctx, policy); err != nil {\n+\tpolicy.Bindings = append(policy.Bindings, &iampb.Binding{\n+\t\tRole:    \"roles/storage.objectViewer\",\n+\t\tMembers: []string{\"group:cloud-logs@google.com\"},\n+\t})\n+\tif err := bucket.IAM().V3().SetPolicy(ctx, policy); err != nil {\n \t\treturn err\n \t}\n \t// NOTE: It may be necessary to retry this operation if IAM policies are",
        "comments": [],
        "commit_messages": [
            "storage: use V3 IAM API\n\nDO NOT SUBMIT"
        ],
        "last_commit_sha": "8ea735be002a06c356bfd4d966c4c9b8fd2b28e3"
    },
    {
        "pr_title": "storage: use V3 IAM API",
        "pr_number": 1251,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -208,15 +213,32 @@\nfunc removeUser(c *storage.Client, bucketName string) error {\n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n-\tpolicy, err := bucket.IAM().Policy(ctx)\n+\tpolicy, err := bucket.IAM().V3().Policy(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Other valid prefixes are \"serviceAccount:\", \"user:\"\n \t// See the documentation for more values.\n \t// https://cloud.google.com/storage/docs/access-control/iam\n-\tpolicy.Remove(\"group:cloud-logs@google.com\", \"roles/storage.objectViewer\")\n-\tif err := bucket.IAM().SetPolicy(ctx, policy); err != nil {\n+\tfor _, binding := range policy.Bindings {\n+\t\t// Only remove unconditional bindings matching role\n+\t\tif binding.Role == \"roles/storage.objectViewer\" && binding.Condition == nil {\n+\t\t\t// Filter out member.\n+\t\t\ti := -1\n+\t\t\tfor j, member := range binding.Members {\n+\t\t\t\tif member == \"group:cloud-logs@google.com\" {\n+\t\t\t\t\ti = j\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif i == -1 {\n+\t\t\t\treturn errors.New(\"No matching binding group found.\")\n+\t\t\t} else {\n+\t\t\t\tbinding.Members = append(binding.Members[:i], binding.Members[i+1:]...)\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif err := bucket.IAM().V3().SetPolicy(ctx, policy); err != nil {\n \t\treturn err\n \t}\n \t// NOTE: It may be necessary to retry this operation if IAM policies are",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8ea735be002a06c356bfd4d966c4c9b8fd2b28e3"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files (buckets part)",
        "pr_number": 1249,
        "file_name": "storage/buckets/get_bucket_metadata.go",
        "code_diff": "@@ -16,37 +16,34 @@\n// using the Google Storage API. More documentation is available at\n // https://cloud.google.com/storage/docs/json_api/v1/.\n \n-package main\n+package buckets\n \n // [START storage_get_bucket_metadata]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n )\n \n-func getBucketMetadata(w io.Writer, client *storage.Client, bucketName string) (*storage.BucketAttrs, error) {\n+// getBucketMetadata gets the bucket metadata.\n+func getBucketMetadata(w io.Writer, bucketName string) (*storage.BucketAttrs, error) {\n \t// bucketName := \"bucket-name\"\n \tctx := context.Background()\n-\n-\t// Initialize client.\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\treturn nil, fmt.Errorf(\"storage.NewClient: %v\", err)\n \t}\n-\tdefer client.Close() // Closing the client safely cleans up background resources.\n+\tdefer client.Close()\n \n \tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n \tdefer cancel()\n \tattrs, err := client.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn nil, fmt.Errorf(\"Bucket(%q).Attrs: %v\", bucketName, err)\n \t}\n-\n \tfmt.Fprintf(w, \"BucketName: %v\\n\", attrs.Name)\n \tfmt.Fprintf(w, \"Location: %v\\n\", attrs.Location)\n \tfmt.Fprintf(w, \"LocationType: %v\\n\", attrs.LocationType)",
        "comments": [],
        "commit_messages": [
            "Merge branch 'separate_storage_samples'"
        ],
        "last_commit_sha": "6f2852d3810b5ebfba12c872372847cbb655c719"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files (buckets part)",
        "pr_number": 1249,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -15,7 +15,9 @@\n// Sample buckets creates a bucket, lists buckets and deletes a bucket\n // using the Google Storage API. More documentation is available at\n // https://cloud.google.com/storage/docs/json_api/v1/.\n-package main\n+// +build ignore\n+\n+package buckets\n \n import (\n \t\"context\"",
        "comments": [],
        "commit_messages": [
            "Merge branch 'separate_storage_samples'"
        ],
        "last_commit_sha": "6f2852d3810b5ebfba12c872372847cbb655c719"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files (buckets part)",
        "pr_number": 1249,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -248,7 +250,7 @@\nfunc removeUser(c *storage.Client, bucketName string) error {\n \treturn nil\n }\n \n-func addBucketConditionalIamBinding(c *storage.Client, bucketName string, role string, member string, title string, description string, expression string) error {\n+func addBucketConditionalIAMBinding(c *storage.Client, bucketName string, role string, member string, title string, description string, expression string) error {\n \t// [START storage_add_bucket_conditional_iam_binding]\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "replaced Iam with IAM, added newline,  if + err"
        ],
        "last_commit_sha": "6f2852d3810b5ebfba12c872372847cbb655c719"
    },
    {
        "pr_title": "spanner: add a sleep time to fix the flaky test.",
        "pr_number": 1242,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -28,7 +28,6 @@\nimport (\n )\n \n func TestSample(t *testing.T) {\n-\tt.Skip(\"https://github.com/GoogleCloudPlatform/golang-samples/issues/1146\")\n \ttc := testutil.SystemTest(t)\n \n \tinstance := os.Getenv(\"GOLANG_SAMPLES_SPANNER\")",
        "comments": [],
        "commit_messages": [
            "Add a sleep time to fix the flaky test."
        ],
        "last_commit_sha": "4d810d146f1cba64dd2b72b7e06d4e29845949f6"
    },
    {
        "pr_title": "bigquery: add defers to explicitly close all clients",
        "pr_number": 1219,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -31,13 +31,23 @@\nimport (\n // [END bigquery_simple_app_deps]\n \n func main() {\n-\tproj := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n-\tif proj == \"\" {\n+\tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n+\tif projectID == \"\" {\n \t\tfmt.Println(\"GOOGLE_CLOUD_PROJECT environment variable must be set.\")\n \t\tos.Exit(1)\n \t}\n \n-\trows, err := query(proj)\n+\t// [START bigquery_simple_app_client]\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"bigquery.NewClient: %v\", err)\n+\t}\n+\tdefer client.Close()\n+\t// [END bigquery_simple_app_client]\n+\n+\trows, err := query(ctx, client)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}",
        "comments": [
            {
                "comment": "Might want to include the function declaration in the sample? Up to you.",
                "position": 44
            },
            {
                "comment": "I'd defer that until we have a chance to address all languages, since they all use this sparse style: https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries#bigquery_simple_app_client-go",
                "position": 44
            }
        ],
        "commit_messages": [
            "refactor simpleapp to address client lifetime"
        ],
        "last_commit_sha": "80566c8ca96b6de9e636a6155e86cd523dfcd959"
    },
    {
        "pr_title": "bigquery: add defers to explicitly close all clients",
        "pr_number": 1219,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -46,16 +56,8 @@\nfunc main() {\n \t}\n }\n \n-// query returns a slice of the results of a query.\n-func query(proj string) (*bigquery.RowIterator, error) {\n-\t// [START bigquery_simple_app_client]\n-\tctx := context.Background()\n-\n-\tclient, err := bigquery.NewClient(ctx, proj)\n-\tif err != nil {\n-\t\treturn nil, err\n-\t}\n-\t// [END bigquery_simple_app_client]\n+// query returns a row iterator suitable for reading query results.\n+func query(ctx context.Context, client *bigquery.Client) (*bigquery.RowIterator, error) {\n \n \t// [START bigquery_simple_app_query]\n \tquery := client.Query(",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "80566c8ca96b6de9e636a6155e86cd523dfcd959"
    },
    {
        "pr_title": "bigquery: add defers to explicitly close all clients",
        "pr_number": 1219,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -38,6 +38,7 @@\nfunc TestJobs(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\tdefer client.Close()\n \n \t// Control a job lifecycle explicitly: create, report status, cancel.\n \texampleJobID, err := bqtestutil.UniqueBQName(\"golang_example_job\")",
        "comments": [],
        "commit_messages": [
            "bigquery: add defers to explicitly close all clients.\n\nOur samples implicitly leveraged short lifetimes, and thus didn't\ninclude explicit closures.  We've seen examples in the wild of\npeople missing this for longer-lived clients, so this makes all samples\nmore explicit about client lifecycle."
        ],
        "last_commit_sha": "80566c8ca96b6de9e636a6155e86cd523dfcd959"
    },
    {
        "pr_title": "bigquery: add defers to explicitly close all clients",
        "pr_number": 1219,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -67,6 +68,7 @@\nfunc TestCopiesAndExtracts(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\tdefer client.Close()\n \n \tmeta := &bigquery.DatasetMetadata{\n \t\tLocation: \"US\", // See https://cloud.google.com/bigquery/docs/locations",
        "comments": [],
        "commit_messages": [
            "bigquery: add defers to explicitly close all clients.\n\nOur samples implicitly leveraged short lifetimes, and thus didn't\ninclude explicit closures.  We've seen examples in the wild of\npeople missing this for longer-lived clients, so this makes all samples\nmore explicit about client lifecycle."
        ],
        "last_commit_sha": "80566c8ca96b6de9e636a6155e86cd523dfcd959"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -18,6 +18,7 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n+\t\"os\"\n \t\"reflect\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "Use a service account instead"
        ],
        "last_commit_sha": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "secretmanager: add IAM samples",
        "pr_number": 1177,
        "file_name": "secretmanager/secretmanager_test.go",
        "code_diff": "@@ -106,6 +107,17 @@\nfunc testCleanupSecret(tb testing.TB, name string) {\n \t}\n }\n \n+func testIamUser(tb testing.TB) string {\n+\ttb.Helper()\n+\n+\tv := os.Getenv(\"GOLANG_SAMPLES_SERVICE_ACCOUNT_EMAIL\")\n+\tif v == \"\" {\n+\t\ttb.Skip(\"testIamUser: missing GOLANG_SAMPLES_SERVICE_ACCOUNT_EMAIL\")\n+\t}\n+\n+\treturn fmt.Sprintf(\"serviceAccount:%s\", v)\n+}\n+\n func TestAccessSecretVersion(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c38b663db7944368ee79a52165d3ea520b98f0bf"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/get_bucket_metadata.go",
        "code_diff": "@@ -24,6 +24,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"log\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n )",
        "comments": [],
        "commit_messages": [
            "storage: add timeouts to samples\n\nThe storage client doesn't automatically include timeouts by default,\nand users are expected to set their own. This should be included\nin sample code."
        ],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -95,8 +95,11 @@\nfunc main() {\n }\n \n func create(client *storage.Client, projectID, bucketName string) error {\n-\tctx := context.Background()\n \t// [START create_bucket]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif err := client.Bucket(bucketName).Create(ctx, projectID, nil); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -105,9 +108,12 @@\nfunc create(client *storage.Client, projectID, bucketName string) error {\n }\n \n func createWithAttrs(client *storage.Client, projectID, bucketName string) error {\n-\tctx := context.Background()\n \t// [START create_bucket_with_storageclass_and_location]\n+\tctx := context.Background()\n \tbucket := client.Bucket(bucketName)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif err := bucket.Create(ctx, projectID, &storage.BucketAttrs{\n \t\tStorageClass: \"COLDLINE\",\n \t\tLocation:     \"asia\",",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -119,9 +125,12 @@\nfunc createWithAttrs(client *storage.Client, projectID, bucketName string) error\n }\n \n func list(client *storage.Client, projectID string) ([]string, error) {\n-\tctx := context.Background()\n \t// [START list_buckets]\n+\tctx := context.Background()\n+\n \tvar buckets []string\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tit := client.Buckets(ctx, projectID)\n \tfor {\n \t\tbattrs, err := it.Next()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -138,8 +147,11 @@\nfunc list(client *storage.Client, projectID string) ([]string, error) {\n }\n \n func deleteBucket(client *storage.Client, bucketName string) error {\n-\tctx := context.Background()\n \t// [START delete_bucket]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif err := client.Bucket(bucketName).Delete(ctx); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -148,9 +160,11 @@\nfunc deleteBucket(client *storage.Client, bucketName string) error {\n }\n \n func getPolicy(c *storage.Client, bucketName string) (*iam.Policy, error) {\n+\t// [START storage_get_bucket_policy]\n \tctx := context.Background()\n \n-\t// [START storage_get_bucket_policy]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tpolicy, err := c.Bucket(bucketName).IAM().Policy(ctx)\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -163,9 +177,11 @@\nfunc getPolicy(c *storage.Client, bucketName string) (*iam.Policy, error) {\n }\n \n func addUser(c *storage.Client, bucketName string) error {\n+\t// [START add_bucket_iam_member]\n \tctx := context.Background()\n \n-\t// [START add_bucket_iam_member]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n \tpolicy, err := bucket.IAM().Policy(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -186,9 +202,11 @@\nfunc addUser(c *storage.Client, bucketName string) error {\n }\n \n func removeUser(c *storage.Client, bucketName string) error {\n+\t// [START remove_bucket_iam_member]\n \tctx := context.Background()\n \n-\t// [START remove_bucket_iam_member]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tbucket := c.Bucket(bucketName)\n \tpolicy, err := bucket.IAM().Policy(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -209,15 +227,17 @@\nfunc removeUser(c *storage.Client, bucketName string) error {\n }\n \n func setRetentionPolicy(c *storage.Client, bucketName string, retentionPeriod time.Duration) error {\n+\t// [START storage_set_retention_policy]\n \tctx := context.Background()\n \n-\t// [START storage_set_retention_policy]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tRetentionPolicy: &storage.RetentionPolicy{\n \t\t\tRetentionPeriod: retentionPeriod,\n \t\t},\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -226,9 +246,8 @@\nfunc setRetentionPolicy(c *storage.Client, bucketName string, retentionPeriod ti\n }\n \n func removeRetentionPolicy(c *storage.Client, bucketName string) error {\n-\tctx := context.Background()\n-\n \t// [START storage_remove_retention_policy]\n+\tctx := context.Background()\n \tbucket := c.Bucket(bucketName)\n \n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)",
        "comments": [],
        "commit_messages": [
            "storage: add timeouts to samples\n\nThe storage client doesn't automatically include timeouts by default,\nand users are expected to set their own. This should be included\nin sample code."
        ],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -242,6 +261,8 @@\nfunc removeRetentionPolicy(c *storage.Client, bucketName string) error {\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tRetentionPolicy: &storage.RetentionPolicy{},\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -250,10 +271,12 @@\nfunc removeRetentionPolicy(c *storage.Client, bucketName string) error {\n }\n \n func lockRetentionPolicy(c *storage.Client, bucketName string) error {\n-\tctx := context.Background()\n-\n \t// [START storage_lock_retention_policy]\n+\tctx := context.Background()\n \tbucket := c.Bucket(bucketName)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -278,9 +301,11 @@\nfunc lockRetentionPolicy(c *storage.Client, bucketName string) error {\n }\n \n func getRetentionPolicy(c *storage.Client, bucketName string) (*storage.BucketAttrs, error) {\n+\t// [START storage_get_retention_policy]\n \tctx := context.Background()\n \n-\t// [START storage_get_retention_policy]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -296,13 +321,15 @@\nfunc getRetentionPolicy(c *storage.Client, bucketName string) (*storage.BucketAt\n }\n \n func enableDefaultEventBasedHold(c *storage.Client, bucketName string) error {\n+\t// [START storage_enable_default_event_based_hold]\n \tctx := context.Background()\n \n-\t// [START storage_enable_default_event_based_hold]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tDefaultEventBasedHold: true,\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -311,13 +338,15 @@\nfunc enableDefaultEventBasedHold(c *storage.Client, bucketName string) error {\n }\n \n func disableDefaultEventBasedHold(c *storage.Client, bucketName string) error {\n+\t// [START storage_disable_default_event_based_hold]\n \tctx := context.Background()\n \n-\t// [START storage_disable_default_event_based_hold]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tDefaultEventBasedHold: false,\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -326,9 +355,11 @@\nfunc disableDefaultEventBasedHold(c *storage.Client, bucketName string) error {\n }\n \n func getDefaultEventBasedHold(c *storage.Client, bucketName string) (*storage.BucketAttrs, error) {\n+\t// [START storage_get_default_event_based_hold]\n \tctx := context.Background()\n \n-\t// [START storage_get_default_event_based_hold]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -340,13 +371,15 @@\nfunc getDefaultEventBasedHold(c *storage.Client, bucketName string) (*storage.Bu\n }\n \n func enableRequesterPays(c *storage.Client, bucketName string) error {\n+\t// [START enable_requester_pays]\n \tctx := context.Background()\n \n-\t// [START enable_requester_pays]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tRequesterPays: true,\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -355,13 +388,15 @@\nfunc enableRequesterPays(c *storage.Client, bucketName string) error {\n }\n \n func disableRequesterPays(c *storage.Client, bucketName string) error {\n+\t// [START disable_requester_pays]\n \tctx := context.Background()\n \n-\t// [START disable_requester_pays]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tRequesterPays: false,\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -370,9 +405,11 @@\nfunc disableRequesterPays(c *storage.Client, bucketName string) error {\n }\n \n func checkRequesterPays(c *storage.Client, bucketName string) error {\n+\t// [START get_requester_pays_status]\n \tctx := context.Background()\n \n-\t// [START get_requester_pays_status]\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -383,13 +420,15 @@\nfunc checkRequesterPays(c *storage.Client, bucketName string) error {\n }\n \n func setDefaultKMSkey(c *storage.Client, bucketName string, keyName string) error {\n+\t// [START storage_set_bucket_default_kms_key]\n \tctx := context.Background()\n \n-\t// [START storage_set_bucket_default_kms_key]\n \tbucket := c.Bucket(bucketName)\n \tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tEncryption: &storage.BucketEncryption{DefaultKMSKeyName: keyName},\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -398,15 +437,17 @@\nfunc setDefaultKMSkey(c *storage.Client, bucketName string, keyName string) erro\n }\n \n func enableUniformBucketLevelAccess(c *storage.Client, bucketName string) error {\n+\t// [START storage_enable_uniform_bucket_level_access]\n \tctx := context.Background()\n \n-\t// [START storage_enable_uniform_bucket_level_access]\n \tbucket := c.Bucket(bucketName)\n \tenableUniformBucketLevelAccess := storage.BucketAttrsToUpdate{\n \t\tUniformBucketLevelAccess: &storage.UniformBucketLevelAccess{\n \t\t\tEnabled: true,\n \t\t},\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, enableUniformBucketLevelAccess); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -415,15 +456,17 @@\nfunc enableUniformBucketLevelAccess(c *storage.Client, bucketName string) error\n }\n \n func disableUniformBucketLevelAccess(c *storage.Client, bucketName string) error {\n+\t// [START storage_disable_uniform_bucket_level_access]\n \tctx := context.Background()\n \n-\t// [START storage_disable_uniform_bucket_level_access]\n \tbucket := c.Bucket(bucketName)\n \tdisableUniformBucketLevelAccess := storage.BucketAttrsToUpdate{\n \t\tUniformBucketLevelAccess: &storage.UniformBucketLevelAccess{\n \t\t\tEnabled: false,\n \t\t},\n \t}\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tif _, err := bucket.Update(ctx, disableUniformBucketLevelAccess); err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -90,14 +90,16 @@\nfunc main() {\n }\n \n func write(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START upload_file]\n+\tctx := context.Background()\n \tf, err := os.Open(\"notes.txt\")\n \tif err != nil {\n \t\treturn err\n \t}\n \tdefer f.Close()\n \n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n \twc := client.Bucket(bucket).Object(object).NewWriter(ctx)\n \tif _, err = io.Copy(wc, f); err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -110,8 +112,11 @@\nfunc write(client *storage.Client, bucket, object string) error {\n }\n \n func list(w io.Writer, client *storage.Client, bucket string) error {\n-\tctx := context.Background()\n \t// [START storage_list_files]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tit := client.Bucket(bucket).Objects(ctx, nil)\n \tfor {\n \t\tattrs, err := it.Next()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -128,7 +133,6 @@\nfunc list(w io.Writer, client *storage.Client, bucket string) error {\n }\n \n func listByPrefix(w io.Writer, client *storage.Client, bucket, prefix, delim string) error {\n-\tctx := context.Background()\n \t// [START storage_list_files_with_prefix]\n \t// Prefixes and delimiters can be used to emulate directory listings.\n \t// Prefixes can be used filter objects starting with prefix.",
        "comments": [],
        "commit_messages": [
            "storage: add timeouts to samples\n\nThe storage client doesn't automatically include timeouts by default,\nand users are expected to set their own. This should be included\nin sample code."
        ],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -146,6 +150,10 @@\nfunc listByPrefix(w io.Writer, client *storage.Client, bucket, prefix, delim str\n \t//\n \t// However, if you specify prefix=\"a/\" and delim=\"/\", you'll get back:\n \t//   /a/1.txt\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tit := client.Bucket(bucket).Objects(ctx, &storage.Query{\n \t\tPrefix:    prefix,\n \t\tDelimiter: delim,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -165,8 +173,11 @@\nfunc listByPrefix(w io.Writer, client *storage.Client, bucket, prefix, delim str\n }\n \n func read(client *storage.Client, bucket, object string) ([]byte, error) {\n-\tctx := context.Background()\n \t// [START download_file]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n \trc, err := client.Bucket(bucket).Object(object).NewReader(ctx)\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -182,8 +193,11 @@\nfunc read(client *storage.Client, bucket, object string) ([]byte, error) {\n }\n \n func attrs(client *storage.Client, bucket, object string) (*storage.ObjectAttrs, error) {\n-\tctx := context.Background()\n \t// [START get_metadata]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tattrs, err := o.Attrs(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -219,8 +233,11 @@\nfunc attrs(client *storage.Client, bucket, object string) (*storage.ObjectAttrs,\n }\n \n func setEventBasedHold(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START storage_set_event_based_hold]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tobjectAttrsToUpdate := storage.ObjectAttrsToUpdate{\n \t\tEventBasedHold: true,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -233,8 +250,11 @@\nfunc setEventBasedHold(client *storage.Client, bucket, object string) error {\n }\n \n func releaseEventBasedHold(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START storage_release_event_based_hold]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tobjectAttrsToUpdate := storage.ObjectAttrsToUpdate{\n \t\tEventBasedHold: false,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -247,8 +267,11 @@\nfunc releaseEventBasedHold(client *storage.Client, bucket, object string) error\n }\n \n func setTemporaryHold(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START storage_set_temporary_hold]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tobjectAttrsToUpdate := storage.ObjectAttrsToUpdate{\n \t\tTemporaryHold: true,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -261,8 +284,11 @@\nfunc setTemporaryHold(client *storage.Client, bucket, object string) error {\n }\n \n func releaseTemporaryHold(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START storage_release_temporary_hold]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tobjectAttrsToUpdate := storage.ObjectAttrsToUpdate{\n \t\tTemporaryHold: false,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -275,8 +301,11 @@\nfunc releaseTemporaryHold(client *storage.Client, bucket, object string) error {\n }\n \n func makePublic(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START public]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tacl := client.Bucket(bucket).Object(object).ACL()\n \tif err := acl.Set(ctx, storage.AllUsers, storage.RoleReader); err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -286,8 +315,11 @@\nfunc makePublic(client *storage.Client, bucket, object string) error {\n }\n \n func move(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START move_file]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tdstName := object + \"-rename\"\n \n \tsrc := client.Bucket(bucket).Object(object)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -304,8 +336,11 @@\nfunc move(client *storage.Client, bucket, object string) error {\n }\n \n func copyToBucket(client *storage.Client, dstBucket, srcBucket, srcObject string) error {\n-\tctx := context.Background()\n \t// [START copy_file]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \tdstObject := srcObject + \"-copy\"\n \tsrc := client.Bucket(srcBucket).Object(srcObject)\n \tdst := client.Bucket(dstBucket).Object(dstObject)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -318,8 +353,11 @@\nfunc copyToBucket(client *storage.Client, dstBucket, srcBucket, srcObject string\n }\n \n func delete(client *storage.Client, bucket, object string) error {\n-\tctx := context.Background()\n \t// [START delete_file]\n+\tctx := context.Background()\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \to := client.Bucket(bucket).Object(object)\n \tif err := o.Delete(ctx); err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -330,10 +368,13 @@\nfunc delete(client *storage.Client, bucket, object string) error {\n \n // writeEncryptedObject writes an object encrypted with user-provided AES key to a bucket.\n func writeEncryptedObject(client *storage.Client, bucket, object string, secretKey []byte) error {\n-\tctx := context.Background()\n-\n \t// [START storage_upload_encrypted_file]\n+\tctx := context.Background()\n \tobj := client.Bucket(bucket).Object(object)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n+\n \t// Encrypt the object's contents.\n \twc := obj.Key(secretKey).NewWriter(ctx)\n \tif _, err := wc.Write([]byte(\"top secret\")); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -348,10 +389,13 @@\nfunc writeEncryptedObject(client *storage.Client, bucket, object string, secretK\n \n // writeWithKMSKey writes an object encrypted with KMS-provided key to a bucket.\n func writeWithKMSKey(client *storage.Client, bucket, object string, keyName string) error {\n-\tctx := context.Background()\n-\n \t// [START storage_upload_with_kms_key]\n+\tctx := context.Background()\n \tobj := client.Bucket(bucket).Object(object)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n+\n \t// Encrypt the object's contents\n \twc := obj.NewWriter(ctx)\n \twc.KMSKeyName = keyName",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -366,10 +410,12 @@\nfunc writeWithKMSKey(client *storage.Client, bucket, object string, keyName stri\n }\n \n func readEncryptedObject(client *storage.Client, bucket, object string, secretKey []byte) ([]byte, error) {\n-\tctx := context.Background()\n-\n \t// [START storage_download_encrypted_file]\n+\tctx := context.Background()\n \tobj := client.Bucket(bucket).Object(object)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*50)\n+\tdefer cancel()\n \trc, err := obj.Key(secretKey).NewReader(ctx)\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -385,13 +431,17 @@\nfunc readEncryptedObject(client *storage.Client, bucket, object string, secretKe\n }\n \n func rotateEncryptionKey(client *storage.Client, bucket, object string, key, newKey []byte) error {\n-\tctx := context.Background()\n \t// [START storage_rotate_encryption_key]\n+\tctx := context.Background()\n+\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \tobj := client.Bucket(bucket).Object(object)\n+\n+\tctx, cancel := context.WithTimeout(ctx, time.Second*10)\n+\tdefer cancel()\n \t// obj is encrypted with key, we are encrypting it with the newKey.\n \t_, err = obj.Key(newKey).CopierFrom(obj.Key(key)).Run(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/s3_sdk/list_gcs_buckets.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n \n \t\"github.com/aws/aws-sdk-go/aws\"\n \t\"github.com/aws/aws-sdk-go/aws/credentials\"",
        "comments": [],
        "commit_messages": [
            "storage: add timeouts to samples\n\nThe storage client doesn't automatically include timeouts by default,\nand users are expected to set their own. This should be included\nin sample code."
        ],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/service_account/hmac/activate.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n )\n \n // activateHMACKey activates the HMAC key with the given access ID.",
        "comments": [],
        "commit_messages": [
            "storage: add timeouts to samples\n\nThe storage client doesn't automatically include timeouts by default,\nand users are expected to set their own. This should be included\nin sample code."
        ],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/service_account/hmac/create.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n )\n \n // createHMACKey creates a new HMAC key using the given project and service account.",
        "comments": [],
        "commit_messages": [
            "storage: add timeouts to samples\n\nThe storage client doesn't automatically include timeouts by default,\nand users are expected to set their own. This should be included\nin sample code."
        ],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/service_account/hmac/deactivate.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n )\n \n // deactivateHMACKey deactivates the HMAC key with the given access ID.",
        "comments": [],
        "commit_messages": [
            "storage: add timeouts to samples\n\nThe storage client doesn't automatically include timeouts by default,\nand users are expected to set their own. This should be included\nin sample code."
        ],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/service_account/hmac/delete.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n )\n \n // deleteHMACKey deletes the HMAC key with the given access ID. Key must have state",
        "comments": [],
        "commit_messages": [
            "storage: add timeouts to samples\n\nThe storage client doesn't automatically include timeouts by default,\nand users are expected to set their own. This should be included\nin sample code."
        ],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/service_account/hmac/get.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n+\t\"time\"\n )\n \n // getHMACKey retrieves the HMACKeyMetadata with the given access id.",
        "comments": [],
        "commit_messages": [
            "storage: add timeouts to samples\n\nThe storage client doesn't automatically include timeouts by default,\nand users are expected to set their own. This should be included\nin sample code."
        ],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/service_account/hmac/list.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n \t\"fmt\"\n \t\"google.golang.org/api/iterator\"\n \t\"io\"\n+\t\"time\"\n )\n \n // listHMACKeys lists all HMAC keys associated with the project.",
        "comments": [],
        "commit_messages": [
            "storage: add timeouts to samples\n\nThe storage client doesn't automatically include timeouts by default,\nand users are expected to set their own. This should be included\nin sample code."
        ],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "storage: add timeouts to samples",
        "pr_number": 1173,
        "file_name": "storage/storage_quickstart/main.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"log\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n )",
        "comments": [],
        "commit_messages": [
            "storage: add timeouts to samples\n\nThe storage client doesn't automatically include timeouts by default,\nand users are expected to set their own. This should be included\nin sample code."
        ],
        "last_commit_sha": "4c4e4c7b72a72ee4db36a0fef19bdf41da995a19"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2019 Google LLC\n+// Copyright 2020 Google LLC\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");\n // you may not use this file except in compliance with the License.",
        "comments": [],
        "commit_messages": [
            "add doc.go files into packages, set license year to 2020, some minor changes"
        ],
        "last_commit_sha": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -12,65 +12,58 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package objects\n \n import (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n-\t\"log\"\n \t\"net/http\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n-\t\"google.golang.org/api/iterator\"\n-\n \t\"cloud.google.com/go/storage\"\n-\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n-func TestMain(m *testing.M) {\n-\t// These functions are noisy.\n-\tlog.SetOutput(ioutil.Discard)\n-\ts := m.Run()\n-\tlog.SetOutput(os.Stderr)\n-\tos.Exit(s)\n-}\n+// TestObjects runs all samples tests of the package.\n func TestObjects(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tvar (\n-\t\tbucket    = tc.ProjectID + \"-samples-object-bucket-1\"\n-\t\tdstBucket = tc.ProjectID + \"-samples-object-bucket-2\"\n-\n-\t\tobject1 = \"foo.txt\"\n-\t\tobject2 = \"foo/a.txt\"\n+\t\tbucket                = tc.ProjectID + \"-samples-object-bucket-1\"\n+\t\tdstBucket             = tc.ProjectID + \"-samples-object-bucket-2\"\n+\t\tobject1               = \"foo.txt\"\n+\t\tobject2               = \"foo/a.txt\"\n+\t\tallAuthenticatedUsers = storage.AllAuthenticatedUsers\n+\t\troleReader            = storage.RoleReader\n \t)\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n \tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n \n-\tif err := write(client, bucket, object1); err != nil {\n-\t\tt.Fatalf(\"write(%q): %v\", object1, err)\n+\tif err := uploadFile(ioutil.Discard, bucket, object1); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object1, err)\n \t}\n-\tif err := write(client, bucket, object2); err != nil {\n-\t\tt.Fatalf(\"write(%q): %v\", object2, err)\n+\tif err := uploadFile(ioutil.Discard, bucket, object2); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", object2, err)\n \t}\n \n \t{\n \t\t// Should only show \"foo/a.txt\", not \"foo.txt\"\n \t\tvar buf bytes.Buffer\n-\t\tif err := list(&buf, client, bucket); err != nil {\n-\t\t\tt.Fatalf(\"cannot list objects: %v\", err)\n+\t\tif err := listFiles(&buf, bucket); err != nil {\n+\t\t\tt.Fatalf(\"listFiles: %v\", err)\n \t\t}\n \t\tif got, want := buf.String(), object1; !strings.Contains(got, want) {\n \t\t\tt.Errorf(\"List() got %q; want to contain %q\", got, want)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -84,8 +77,8 @@\nfunc TestObjects(t *testing.T) {\n \t\t// Should only show \"foo/a.txt\", not \"foo.txt\"\n \t\tconst prefix = \"foo/\"\n \t\tvar buf bytes.Buffer\n-\t\tif err := listByPrefix(&buf, client, bucket, prefix, \"\"); err != nil {\n-\t\t\tt.Fatalf(\"cannot list objects by prefix: %v\", err)\n+\t\tif err := listFilesWithPrefix(&buf, bucket, prefix, \"\"); err != nil {\n+\t\t\tt.Fatalf(\"listFilesWithPrefix: %v\", err)\n \t\t}\n \t\tif got, want := buf.String(), object1; strings.Contains(got, want) {\n \t\t\tt.Errorf(\"List(%q) got %q; want NOT to contain %q\", prefix, got, want)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -95,101 +88,79 @@\nfunc TestObjects(t *testing.T) {\n \t\t}\n \t}\n \n-\tdata, err := read(client, bucket, object1)\n+\t{\n+\t\tif err := downloadUsingRequesterPays(ioutil.Discard, bucket, object1, tc.ProjectID); err != nil {\n+\t\t\tt.Errorf(\"downloadUsingRequesterPays: %v\", err)\n+\t\t}\n+\t}\n+\n+\tdata, err := downloadFile(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Fatalf(\"cannot read object: %v\", err)\n+\t\tt.Fatalf(\"downloadFile: %v\", err)\n \t}\n-\tif got, want := string(data), \"Hello\\nworld\"; got != want {\n+\tif got, want := string(data), \"Hello\\r\\nworld\"; got != want {\n \t\tt.Errorf(\"contents = %q; want %q\", got, want)\n \t}\n-\t_, err = attrs(client, bucket, object1)\n+\n+\t_, err = getMetadata(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n-\tif err := makePublic(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot to make object public: %v\", err)\n+\tif err := makePublic(ioutil.Discard, bucket, object1, allAuthenticatedUsers, roleReader); err != nil {\n+\t\tt.Errorf(\"makePublic: %v\", err)\n \t}\n-\terr = move(client, bucket, object1)\n+\n+\terr = moveFile(ioutil.Discard, bucket, object1)\n \tif err != nil {\n-\t\tt.Fatalf(\"cannot move object: %v\", err)\n+\t\tt.Fatalf(\"moveFile: %v\", err)\n \t}\n \t// object1's new name.\n \tobject1 = object1 + \"-rename\"\n \n-\tif err := copyToBucket(client, dstBucket, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot copy object to bucket: %v\", err)\n-\t}\n-\tif err := addBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot add bucket acl: %v\", err)\n-\t}\n-\tif err := addDefaultBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot add bucket default acl: %v\", err)\n-\t}\n-\tif err := bucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot get bucket acl: %v\", err)\n-\t}\n-\tif err := bucketACLFiltered(client, bucket, storage.AllAuthenticatedUsers); err != nil {\n-\t\tt.Errorf(\"cannot filter bucket acl: %v\", err)\n-\t}\n-\tif err := deleteDefaultBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot delete bucket default acl: %v\", err)\n-\t}\n-\tif err := deleteBucketACL(client, bucket); err != nil {\n-\t\tt.Errorf(\"cannot delete bucket acl: %v\", err)\n-\t}\n-\tif err := addObjectACL(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot add object acl: %v\", err)\n-\t}\n-\tif err := objectACL(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot get object acl: %v\", err)\n-\t}\n-\tif err := objectACLFiltered(client, bucket, object1, storage.AllAuthenticatedUsers); err != nil {\n-\t\tt.Errorf(\"cannot filter object acl: %v\", err)\n-\t}\n-\tif err := deleteObjectACL(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot delete object acl: %v\", err)\n+\tif err := copyFile(ioutil.Discard, dstBucket, bucket, object1); err != nil {\n+\t\tt.Errorf(\"copyFile: %v\", err)\n \t}\n \n \tkey := []byte(\"my-secret-AES-256-encryption-key\")\n \tnewKey := []byte(\"My-secret-AES-256-encryption-key\")\n \n-\tif err := writeEncryptedObject(client, bucket, object1, key); err != nil {\n-\t\tt.Errorf(\"cannot write an encrypted object: %v\", err)\n+\tif err := uploadEncyptedFile(ioutil.Discard, bucket, object1, key); err != nil {\n+\t\tt.Errorf(\"uploadEncyptedFile: %v\", err)\n \t}\n-\tdata, err = readEncryptedObject(client, bucket, object1, key)\n+\tdata, err = downloadEncryptedFile(ioutil.Discard, bucket, object1, key)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot read the encrypted object: %v\", err)\n+\t\tt.Errorf(\"downloadEncryptedFile: %v\", err)\n \t}\n \tif got, want := string(data), \"top secret\"; got != want {\n \t\tt.Errorf(\"object content = %q; want %q\", got, want)\n \t}\n-\tif err := rotateEncryptionKey(client, bucket, object1, key, newKey); err != nil {\n-\t\tt.Errorf(\"cannot encrypt the object with the new key: %v\", err)\n+\tif err := rotateEncryptionKey(ioutil.Discard, bucket, object1, key, newKey); err != nil {\n+\t\tt.Errorf(\"rotateEncryptionKey: %v\", err)\n \t}\n-\tif err := delete(client, bucket, object1); err != nil {\n-\t\tt.Errorf(\"cannot to delete object: %v\", err)\n+\tif err := deleteFile(ioutil.Discard, bucket, object1); err != nil {\n+\t\tt.Errorf(\"deleteFile: %v\", err)\n \t}\n-\tif err := delete(client, bucket, object2); err != nil {\n-\t\tt.Errorf(\"cannot to delete object: %v\", err)\n+\tif err := deleteFile(ioutil.Discard, bucket, object2); err != nil {\n+\t\tt.Errorf(\"deleteFile: %v\", err)\n \t}\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\t// Cleanup, this part won't be executed if Fatal happens.\n \t\t// TODO(jbd): Implement garbage cleaning.\n \t\tif err := client.Bucket(bucket).Delete(ctx); err != nil {\n-\t\t\tr.Errorf(\"cleanup of bucket failed: %v\", err)\n+\t\t\tr.Errorf(\"Bucket(%q).Delete: %v\", bucket, err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := delete(client, dstBucket, object1+\"-copy\"); err != nil {\n-\t\t\tr.Errorf(\"cannot to delete copy object: %v\", err)\n+\t\tif err := deleteFile(ioutil.Discard, dstBucket, object1+\"-copy\"); err != nil {\n+\t\t\tr.Errorf(\"deleteFile: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\tif err := client.Bucket(dstBucket).Delete(ctx); err != nil {\n-\t\t\tr.Errorf(\"cleanup of bucket failed: %v\", err)\n+\t\t\tr.Errorf(\"Bucket(%q).Delete: %v\", dstBucket, err)\n \t\t}\n \t})\n }",
        "comments": [
            {
                "comment": "Moved into `acl_test.go`",
                "position": 175
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -201,6 +172,7 @@\nfunc TestKMSObjects(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")\n \tcryptoKeyID := os.Getenv(\"GOLANG_SAMPLES_KMS_CRYPTOKEY\")",
        "comments": [
            {
                "comment": "Moved into `acl_test.go`",
                "position": 175
            }
        ],
        "commit_messages": [
            "add client closing"
        ],
        "last_commit_sha": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -211,17 +183,16 @@\nfunc TestKMSObjects(t *testing.T) {\n \tvar (\n \t\tbucket    = tc.ProjectID + \"-samples-object-bucket-1\"\n \t\tdstBucket = tc.ProjectID + \"-samples-object-bucket-2\"\n-\n-\t\tobject1 = \"foo.txt\"\n+\t\tobject1   = \"foo.txt\"\n \t)\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucket)\n \tcleanBucket(t, ctx, client, tc.ProjectID, dstBucket)\n \n \tkmsKeyName := fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\", tc.ProjectID, \"global\", keyRingID, cryptoKeyID)\n \n-\tif err := writeWithKMSKey(client, bucket, object1, kmsKeyName); err != nil {\n-\t\tt.Errorf(\"cannot write a KMS encrypted object: %v\", err)\n+\tif err := uploadWithKMSKey(ioutil.Discard, bucket, object1, kmsKeyName); err != nil {\n+\t\tt.Errorf(\"uploadWithKMSKey: %v\", err)\n \t}\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -232,14 +203,15 @@\nfunc TestV4SignedURL(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tbucketName := tc.ProjectID + \"-signed-url-bucket-name\"\n \tobjectName := \"foo.txt\"\n \tserviceAccount := os.Getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n \tputBuf := new(bytes.Buffer)\n-\tputURL, err := generateV4PutObjectSignedURL(putBuf, client, bucketName, objectName, serviceAccount)\n+\tputURL, err := generateV4PutObjectSignedURL(putBuf, bucketName, objectName, serviceAccount)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4PutObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -257,7 +229,7 @@\nfunc TestV4SignedURL(t *testing.T) {\n \t\tt.Errorf(\"httpClient.Do: %v\", err)\n \t}\n \tgetBuf := new(bytes.Buffer)\n-\tgetURL, err := generateV4GetObjectSignedURL(getBuf, client, bucketName, objectName, serviceAccount)\n+\tgetURL, err := generateV4GetObjectSignedURL(getBuf, bucketName, objectName, serviceAccount)\n \tif err != nil {\n \t\tt.Errorf(\"generateV4GetObjectSignedURL: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -280,7 +252,6 @@\nfunc TestV4SignedURL(t *testing.T) {\n \tif got, want := string(body), \"hello world\"; got != want {\n \t\tt.Errorf(\"object content = %q; want %q\", got, want)\n \t}\n-\n }\n \n func TestObjectBucketLock(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "add client closing"
        ],
        "last_commit_sha": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -290,69 +261,68 @@\nfunc TestObjectBucketLock(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n+\tdefer client.Close()\n \n \tvar (\n-\t\tbucketName = tc.ProjectID + \"-retent-samples-object-bucket\"\n-\n-\t\tobjectName = \"foo.txt\"\n-\n+\t\tbucketName      = tc.ProjectID + \"-retent-samples-object-bucket\"\n+\t\tobjectName      = \"foo.txt\"\n \t\tretentionPeriod = 5 * time.Second\n \t)\n \n \tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n \tbucket := client.Bucket(bucketName)\n \n-\tif err := write(client, bucketName, objectName); err != nil {\n-\t\tt.Fatalf(\"write(%q): %v\", objectName, err)\n+\tif err := uploadFile(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Fatalf(\"uploadFile(%q): %v\", objectName, err)\n \t}\n \tif _, err := bucket.Update(ctx, storage.BucketAttrsToUpdate{\n \t\tRetentionPolicy: &storage.RetentionPolicy{\n \t\t\tRetentionPeriod: retentionPeriod,\n \t\t},\n \t}); err != nil {\n-\t\tt.Errorf(\"unable to set retention policy (%q): %v\", bucketName, err)\n+\t\tt.Errorf(\"Bucket(%q).Update: %v\", bucketName, err)\n \t}\n-\tif err := setEventBasedHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to set event-based hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := setEventBasedHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"setEventBasedHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err := attrs(client, bucketName, objectName)\n+\toAttrs, err := getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif !oAttrs.EventBasedHold {\n \t\tt.Errorf(\"event-based hold is not enabled\")\n \t}\n-\tif err := releaseEventBasedHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to set event-based hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := releaseEventBasedHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"releaseEventBasedHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err = attrs(client, bucketName, objectName)\n+\toAttrs, err = getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif oAttrs.EventBasedHold {\n \t\tt.Errorf(\"event-based hold is not disabled\")\n \t}\n \tif _, err := bucket.Update(ctx, storage.BucketAttrsToUpdate{\n \t\tRetentionPolicy: &storage.RetentionPolicy{},\n \t}); err != nil {\n-\t\tt.Errorf(\"unable to remove retention policy (%q): %v\", bucketName, err)\n+\t\tt.Errorf(\"Bucket(%q).Update: %v\", bucketName, err)\n \t}\n-\tif err := setTemporaryHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to set temporary hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := setTemporaryHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"setTemporaryHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err = attrs(client, bucketName, objectName)\n+\toAttrs, err = getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif !oAttrs.TemporaryHold {\n \t\tt.Errorf(\"temporary hold is not disabled\")\n \t}\n-\tif err := releaseTemporaryHold(client, bucketName, objectName); err != nil {\n-\t\tt.Errorf(\"unable to release temporary hold (%q/%q): %v\", bucketName, objectName, err)\n+\tif err := releaseTemporaryHold(ioutil.Discard, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"releaseTemporaryHold(%q, %q): %v\", bucketName, objectName, err)\n \t}\n-\toAttrs, err = attrs(client, bucketName, objectName)\n+\toAttrs, err = getMetadata(ioutil.Discard, bucketName, objectName)\n \tif err != nil {\n-\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t\tt.Errorf(\"getMetadata: %v\", err)\n \t}\n \tif oAttrs.TemporaryHold {\n \t\tt.Errorf(\"temporary hold is not disabled\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "refactor(storage): separate samples into standalone files",
        "pr_number": 1170,
        "file_name": "storage/objects/objects_test.go",
        "code_diff": "@@ -371,7 +341,7 @@\nfunc cleanBucket(t *testing.T, ctx context.Context, client *storage.Client, proj\n \t\t\t\tbreak\n \t\t\t}\n \t\t\tif err != nil {\n-\t\t\t\tt.Fatalf(\"Bucket.Objects(%q): %v\", bucket, err)\n+\t\t\t\tt.Fatalf(\"Bucket(%q).Objects: %v\", bucket, err)\n \t\t\t}\n \t\t\tif attrs.EventBasedHold || attrs.TemporaryHold {\n \t\t\t\tif _, err := b.Object(attrs.Name).Update(ctx, storage.ObjectAttrsToUpdate{",
        "comments": [],
        "commit_messages": [
            "improve error messages",
            "Merge branch 'separate_storage_samples-pt2' of https://github.com/q-logic/golang-samples into separate_storage_samples-pt2"
        ],
        "last_commit_sha": "21e67e6ccc5ee7569ae077e376c53506bcfecf4f"
    },
    {
        "pr_title": "dataproc: clean clusters before running tests",
        "pr_number": 1163,
        "file_name": "dataproc/create_cluster_test.go",
        "code_diff": "@@ -27,23 +27,28 @@\nimport (\n \tdataprocpb \"google.golang.org/genproto/googleapis/cloud/dataproc/v1\"\n )\n \n-func teardown(t *testing.T, tc testutil.Context, clusterName, region string) {\n-\tt.Helper()\n+func deleteCluster(projectID string, clusterName, region string) error {\n \tctx := context.Background()\n \n \tclusterClient, err := dataproc.NewClusterControllerClient(ctx, option.WithEndpoint(fmt.Sprintf(\"%s-dataproc.googleapis.com:443\", region)))\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"dataproc.NewClusterControllerClient: %v\", err)\n+\t}\n \n \treq := &dataprocpb.DeleteClusterRequest{\n-\t\tProjectId:   tc.ProjectID,\n+\t\tProjectId:   projectID,\n \t\tRegion:      region,\n \t\tClusterName: clusterName,\n \t}\n \top, err := clusterClient.DeleteCluster(ctx, req)\n-\n-\top.Wait(ctx)\n \tif err != nil {\n-\t\tt.Errorf(\"Error deleting cluster %q: %v\", clusterName, err)\n+\t\treturn fmt.Errorf(\"DeleteCluster: %v\", err)\n+\t}\n+\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn fmt.Errorf(\"DeleteCluster.Wait: %v\", err)\n \t}\n+\treturn nil\n }\n \n func TestCreateCluster(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "dataproc: clean clusters before running tests"
        ],
        "last_commit_sha": "026853582d6047ad9fbd814eca667c3d3d66772c"
    },
    {
        "pr_title": "dataproc: clean clusters before running tests",
        "pr_number": 1163,
        "file_name": "dataproc/quickstart/quickstart_test.go",
        "code_diff": "@@ -42,7 +42,7 @@\nsum = rdd.reduce(lambda x, y: x + y)`\n \tregion = \"us-central1\"\n )\n \n-func cleanBucket(t *testing.T, ctx context.Context, client *storage.Client, projectID, bucket string) {\n+func cleanBucket(ctx context.Context, t *testing.T, client *storage.Client, projectID, bucket string) {\n \tb := client.Bucket(bucket)\n \t_, err := b.Attrs(ctx)\n \tif err == nil {",
        "comments": [],
        "commit_messages": [
            "dataproc: clean clusters before running tests"
        ],
        "last_commit_sha": "026853582d6047ad9fbd814eca667c3d3d66772c"
    },
    {
        "pr_title": "dataproc: clean clusters before running tests",
        "pr_number": 1163,
        "file_name": "dataproc/quickstart/quickstart_test.go",
        "code_diff": "@@ -76,20 +76,20 @@\nfunc cleanBucket(t *testing.T, ctx context.Context, client *storage.Client, proj\n \t}\n }\n \n-func setup(t *testing.T, tc testutil.Context) {\n+func setup(t *testing.T, projectID string) {\n \tctx := context.Background()\n \tflag.Parse()\n \n-\tclusterName = \"go-qs-test-\" + tc.ProjectID\n-\tbktName = \"go-dataproc-qs-test-\" + tc.ProjectID\n+\tclusterName = \"go-qs-test-\" + projectID\n+\tbktName = \"go-dataproc-qs-test-\" + projectID\n \tjobFilePath = fmt.Sprintf(\"gs://%s/%s\", bktName, jobFName)\n \n \tsc, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\tt.Errorf(\"Error creating storage client with error: %v\", err)\n+\t\tt.Errorf(\"storage.NewClient: %v\", err)\n \t}\n \n-\tcleanBucket(t, ctx, sc, tc.ProjectID, bktName)\n+\tcleanBucket(ctx, t, sc, projectID, bktName)\n \tbkt := sc.Bucket(bktName)\n \n \tobj := bkt.Object(jobFName)",
        "comments": [],
        "commit_messages": [
            "dataproc: clean clusters before running tests"
        ],
        "last_commit_sha": "026853582d6047ad9fbd814eca667c3d3d66772c"
    },
    {
        "pr_title": "dataproc: clean clusters before running tests",
        "pr_number": 1163,
        "file_name": "dataproc/quickstart/quickstart_test.go",
        "code_diff": "@@ -106,14 +106,16 @@\nfunc setup(t *testing.T, tc testutil.Context) {\n \tif err := w.Close(); err != nil {\n \t\tt.Errorf(\"Error closing file: %v\", err)\n \t}\n+\n+\tdeleteClusters(ctx, projectID) // Ignore any errors.\n }\n \n-func teardown(t *testing.T, tc testutil.Context) {\n+func teardown(t *testing.T, projectID string) {\n \tctx := context.Background()\n \n \tsc, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\tt.Errorf(\"Error creating storage client with error: %v\", err)\n+\t\tt.Errorf(\"storage.NewClient: %v\", err)\n \t}\n \n \tif err := sc.Bucket(bktName).Object(jobFName).Delete(ctx); err != nil {",
        "comments": [],
        "commit_messages": [
            "dataproc: clean clusters before running tests"
        ],
        "last_commit_sha": "026853582d6047ad9fbd814eca667c3d3d66772c"
    },
    {
        "pr_title": "dataproc: clean clusters before running tests",
        "pr_number": 1163,
        "file_name": "dataproc/quickstart/quickstart_test.go",
        "code_diff": "@@ -124,13 +126,19 @@\nfunc teardown(t *testing.T, tc testutil.Context) {\n \t\tt.Errorf(\"Error deleting bucket: %v\", err)\n \t}\n \n+\tif err := deleteClusters(ctx, projectID); err != nil {\n+\t\tt.Errorf(\"deleteClusters: %v\", err)\n+\t}\n+}\n+\n+func deleteClusters(ctx context.Context, projectID string) error {\n \tendpoint := fmt.Sprintf(\"%s-dataproc.googleapis.com:443\", region)\n \tclient, err := dataproc.NewClusterControllerClient(ctx, option.WithEndpoint(endpoint))\n \tif err != nil {\n-\t\tt.Errorf(\"Error creating the cluster client: %s\", err)\n+\t\treturn fmt.Errorf(\"dataproc.NewClusterControllerClient: %v\", err)\n \t}\n \n-\tlReq := &dataprocpb.ListClustersRequest{ProjectId: tc.ProjectID, Region: region}\n+\tlReq := &dataprocpb.ListClustersRequest{ProjectId: projectID, Region: region}\n \tit := client.ListClusters(ctx, lReq)\n \n \tfor {",
        "comments": [],
        "commit_messages": [
            "dataproc: clean clusters before running tests"
        ],
        "last_commit_sha": "026853582d6047ad9fbd814eca667c3d3d66772c"
    },
    {
        "pr_title": "bigquery: run CMEK tests conditionally.",
        "pr_number": 1144,
        "file_name": "bigquery/snippets/bqtestutil/bqtestutil.go",
        "code_diff": "@@ -16,6 +16,7 @@\npackage bqtestutil\n \n import (\n \t\"fmt\"\n+\t\"os\"\n \t\"regexp\"\n \n \t\"github.com/gofrs/uuid\"",
        "comments": [],
        "commit_messages": [
            "bigquery: run CMEK tests conditionally.\n\nCMEK snippet testing necessitates that principals have access to the\nunderlying keychain we use in the samples, which is not allowed to\nhave a public ACL.  Therefore, to simplify testing for external users\nwe only run CMEK tests conditionally if we detect that the environment\nappears to be our CI environment or if the RUN_CMEK_TESTS variable is\nset in the environment."
        ],
        "last_commit_sha": "2e49dea532f5ccd4384d13f640f9004cc3ec5094"
    },
    {
        "pr_title": "bigquery: run CMEK tests conditionally.",
        "pr_number": 1144,
        "file_name": "bigquery/snippets/job/integration_test.go",
        "code_diff": "@@ -89,17 +89,32 @@\nfunc TestCopiesAndExtracts(t *testing.T) {\n \t\tt.Fatalf(\"failed to generate example table2: %v\", err)\n \t}\n \n-\tif err := copyTable(tc.ProjectID, testDatasetID, \"table1\", \"copy1\"); err != nil {\n-\t\tt.Errorf(\"copyTable(%s): %v\", testDatasetID, err)\n-\t}\n-\n-\tif err := copyTableWithCMEK(tc.ProjectID, testDatasetID, \"copycmek\"); err != nil {\n-\t\tt.Errorf(\"copyTableWithCMEK(%s): %v\", testDatasetID, err)\n-\t}\n-\n-\tif err := copyMultiTable(tc.ProjectID, testDatasetID, []string{\"table1\", \"table2\"}, testDatasetID, \"copymulti\"); err != nil {\n-\t\tt.Errorf(\"copyMultiTable(%s): %v\", testDatasetID, err)\n-\t}\n+\t// Run copy job tests in parallel.\n+\tt.Run(\"copy\", func(t *testing.T) {\n+\t\tt.Run(\"copyTable\", func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tif err := copyTable(tc.ProjectID, testDatasetID, \"table1\", \"copy1\"); err != nil {\n+\t\t\t\tt.Errorf(\"copyTable(%s): %v\", testDatasetID, err)\n+\t\t\t}\n+\t\t})\n+\n+\t\tt.Run(\"copyTableWithCMEK\", func(t *testing.T) {\n+\t\t\tif !bqtestutil.RunCMEKTests() {\n+\t\t\t\tt.Skip(\"Skipping CMEK tests\")\n+\t\t\t}\n+\t\t\tt.Parallel()\n+\t\t\tif err := copyTableWithCMEK(tc.ProjectID, testDatasetID, \"copycmek\"); err != nil {\n+\t\t\t\tt.Errorf(\"copyTableWithCMEK(%s): %v\", testDatasetID, err)\n+\t\t\t}\n+\t\t})\n+\n+\t\tt.Run(\"copyMultiTable\", func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tif err := copyMultiTable(tc.ProjectID, testDatasetID, []string{\"table1\", \"table2\"}, testDatasetID, \"copymulti\"); err != nil {\n+\t\t\t\tt.Errorf(\"copyMultiTable(%s): %v\", testDatasetID, err)\n+\t\t\t}\n+\t\t})\n+\t})\n \n \t// Extract tests - setup bucket\n \tstorageClient, err := storage.NewClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2e49dea532f5ccd4384d13f640f9004cc3ec5094"
    },
    {
        "pr_title": "videointelligence: make analyze test E2E and add sleep",
        "pr_number": 1129,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"io\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_messages": [
            "videointelligence: make analyze test E2E and add sleep"
        ],
        "last_commit_sha": "b5df3dbb925f4f9c4b55486075b309d899713766"
    },
    {
        "pr_title": "videointelligence: make analyze test E2E and add sleep",
        "pr_number": 1129,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -27,7 +28,7 @@\nconst catVideo = \"gs://cloud-samples-data/video/cat.mp4\"\n const googleworkVideo = \"gs://python-docs-samples-tests/video/googlework_short.mp4\"\n \n func TestAnalyze(t *testing.T) {\n-\ttestutil.SystemTest(t)\n+\ttestutil.EndToEndTest(t)\n \n \ttests := []struct {\n \t\tname        string",
        "comments": [],
        "commit_messages": [
            "videointelligence: make analyze test E2E and add sleep"
        ],
        "last_commit_sha": "b5df3dbb925f4f9c4b55486075b309d899713766"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "bigquery/snippets/dataset/bigquery_get_dataset.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage dataset\n \n // [START bigquery_get_dataset]\n-\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "address reviewer comments, pass 1"
        ],
        "last_commit_sha": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "bigquery/snippets/dataset/bigquery_get_dataset_labels.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage dataset\n \n // [START bigquery_get_dataset_labels]\n-\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "address reviewer comments, pass 1"
        ],
        "last_commit_sha": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "bigquery/snippets/dataset/bigquery_list_datasets.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage dataset\n \n // [START bigquery_list_datasets]\n-\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "address reviewer comments, pass 1"
        ],
        "last_commit_sha": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "bigquery/snippets/dataset/bigquery_list_datasets_by_label.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage dataset\n \n // [START bigquery_list_datasets_by_label]\n-\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "address reviewer comments, pass 1"
        ],
        "last_commit_sha": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "bigquery/snippets/dataset/bigquery_update_dataset_default_expiration.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage dataset\n \n // [START bigquery_update_dataset_expiration]\n-\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "address reviewer comments, pass 1"
        ],
        "last_commit_sha": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "bigquery/snippets/models/bigquery_get_model.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage models\n \n // [START bigquery_get_model]\n-\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "address reviewer comments, pass 1"
        ],
        "last_commit_sha": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "bigquery: refactor snippets",
        "pr_number": 1126,
        "file_name": "bigquery/snippets/models/bigquery_list_models.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage models\n \n // [START bigquery_list_models]\n-\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "address reviewer comments, pass 1"
        ],
        "last_commit_sha": "e1d234d2824f0b75d754a1699e6d8a7a2cb51fa2"
    },
    {
        "pr_title": "automl: remove old files and update region tags for samples",
        "pr_number": 1119,
        "file_name": "automl/dataset_get.go",
        "code_diff": "@@ -15,7 +15,12 @@\n// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n-// [START automl_get_dataset]\n+// [START automl_language_entity_extraction_get_dataset]\n+// [START automl_language_sentiment_analysis_get_dataset]\n+// [START automl_language_text_classification_get_dataset]\n+// [START automl_translate_get_dataset]\n+// [START automl_vision_classification_get_dataset]\n+// [START automl_vision_object_detection_get_dataset]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7122f6961996c51a00d46b50b2f038e7f9d52f62"
    },
    {
        "pr_title": "automl: remove old files and update region tags for samples",
        "pr_number": 1119,
        "file_name": "automl/dataset_list.go",
        "code_diff": "@@ -15,7 +15,12 @@\n// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n-// [START automl_list_datasets]\n+// [START automl_language_entity_extraction_list_datasets]\n+// [START automl_language_sentiment_analysis_list_datasets]\n+// [START automl_language_text_classification_list_datasets]\n+// [START automl_translate_list_datasets]\n+// [START automl_vision_classification_list_datasets]\n+// [START automl_vision_object_detection_list_datasets]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7122f6961996c51a00d46b50b2f038e7f9d52f62"
    },
    {
        "pr_title": "automl: remove old files and update region tags for samples",
        "pr_number": 1119,
        "file_name": "automl/model_evaluation_get.go",
        "code_diff": "@@ -15,7 +15,12 @@\n// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n-// [START automl_get_model_evaluation]\n+// [START automl_language_entity_extraction_get_model_evaluation]\n+// [START automl_language_sentiment_analysis_get_model_evaluation]\n+// [START automl_language_text_classification_get_model_evaluation]\n+// [START automl_translate_get_model_evaluation]\n+// [START automl_vision_classification_get_model_evaluation]\n+// [START automl_vision_object_detection_get_model_evaluation]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7122f6961996c51a00d46b50b2f038e7f9d52f62"
    },
    {
        "pr_title": "automl: remove old files and update region tags for samples",
        "pr_number": 1119,
        "file_name": "automl/model_evaluation_list.go",
        "code_diff": "@@ -15,7 +15,12 @@\n// Package automl contains samples for Google Cloud AutoML API v1.\n package automl\n \n-// [START automl_list_model_evaluations]\n+// [START automl_language_entity_extraction_list_model_evaluations]\n+// [START automl_language_sentiment_analysis_list_model_evaluations]\n+// [START automl_language_text_classification_list_model_evaluations]\n+// [START automl_translate_list_model_evaluations]\n+// [START automl_vision_classification_list_model_evaluations]\n+// [START automl_vision_object_detection_list_model_evaluations]\n import (\n \t\"context\"\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7122f6961996c51a00d46b50b2f038e7f9d52f62"
    },
    {
        "pr_title": "functions: use request signing",
        "pr_number": 1108,
        "file_name": "functions/slack/search.go",
        "code_diff": "@@ -19,11 +19,32 @@\npackage slack\n \n import (\n+\t\"bytes\"\n+\t\"crypto/hmac\"\n+\t\"crypto/sha256\"\n+\t\"encoding/hex\"\n \t\"encoding/json\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n-\t\"net/url\"\n+\t\"strconv\"\n+\t\"strings\"\n+\t\"time\"\n+)\n+\n+type oldTimeStampError struct {\n+\ts string\n+}\n+\n+func (e *oldTimeStampError) Error() string {\n+\treturn e.s\n+}\n+\n+const (\n+\tversion                     = \"v0\"\n+\tslackRequestTimestampHeader = \"X-Slack-Request-Timestamp\"\n+\tslackSignatureHeader        = \"X-Slack-Signature\"\n )\n \n type attachment struct {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "52a0d66491315bcf78df6264eb9bea8bd391eca0"
    },
    {
        "pr_title": "functions: use request signing",
        "pr_number": 1108,
        "file_name": "functions/slack/search.go",
        "code_diff": "@@ -46,16 +67,31 @@\ntype Message struct {\n // by a Slack command.\n func KGSearch(w http.ResponseWriter, r *http.Request) {\n \tsetup(r.Context())\n+\n+\tbodyBytes, err := ioutil.ReadAll(r.Body)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"Couldn't read request body: %v\", err)\n+\t}\n+\tr.Body = ioutil.NopCloser(bytes.NewBuffer(bodyBytes))\n+\n \tif r.Method != \"POST\" {\n \t\thttp.Error(w, \"Only POST requests are accepted\", 405)\n \t}\n \tif err := r.ParseForm(); err != nil {\n \t\thttp.Error(w, \"Couldn't parse form\", 400)\n \t\tlog.Fatalf(\"ParseForm: %v\", err)\n \t}\n-\tif err := verifyWebHook(r.Form); err != nil {\n+\n+\t// Reset r.Body as ParseForm depletes it by reading the io.ReadCloser.\n+\tr.Body = ioutil.NopCloser(bytes.NewBuffer(bodyBytes))\n+\tresult, err := verifyWebHook(r, config.Secret)\n+\tif err != nil {\n \t\tlog.Fatalf(\"verifyWebhook: %v\", err)\n \t}\n+\tif !result {\n+\t\tlog.Fatalf(\"signatures did not match.\")\n+\t}\n+\n \tif len(r.Form[\"text\"]) == 0 {\n \t\tlog.Fatalf(\"emtpy text in form\")\n \t}",
        "comments": [
            {
                "comment": "```\r\n// verifyWebhook verifies the Slack request signature.\r\n// See https://api.slack.com/docs/verifying-requests-from-slack.\r\n```\r\n\r\nNo need to say \"now.\" :)",
                "position": 96
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "52a0d66491315bcf78df6264eb9bea8bd391eca0"
    },
    {
        "pr_title": "functions: use request signing",
        "pr_number": 1108,
        "file_name": "functions/slack/search.go",
        "code_diff": "@@ -71,20 +107,6 @@\nfunc KGSearch(w http.ResponseWriter, r *http.Request) {\n \n // [END functions_slack_search]\n \n-// [START functions_verify_webhook]\n-func verifyWebHook(form url.Values) error {\n-\tt := form.Get(\"token\")\n-\tif len(t) == 0 {\n-\t\treturn fmt.Errorf(\"empty form token\")\n-\t}\n-\tif t != config.Token {\n-\t\treturn fmt.Errorf(\"invalid request/credentials: %q\", t[0])\n-\t}\n-\treturn nil\n-}\n-\n-// [END functions_verify_webhook]\n-\n // [START functions_slack_request]\n func makeSearchRequest(query string) (*Message, error) {\n \tres, err := entitiesService.Search().Query(query).Limit(1).Do()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "52a0d66491315bcf78df6264eb9bea8bd391eca0"
    },
    {
        "pr_title": "functions: use request signing",
        "pr_number": 1108,
        "file_name": "functions/slack/slack_test.go",
        "code_diff": "@@ -16,12 +16,16 @@\npackage slack\n \n import (\n \t\"context\"\n+\t\"encoding/hex\"\n+\t\"fmt\"\n \t\"log\"\n \t\"net/http/httptest\"\n \t\"net/url\"\n \t\"os\"\n+\t\"strconv\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n \n \t\"google.golang.org/api/kgsearch/v1\"\n \t\"google.golang.org/api/option\"",
        "comments": [],
        "commit_messages": [
            "tbpg reviews 1"
        ],
        "last_commit_sha": "52a0d66491315bcf78df6264eb9bea8bd391eca0"
    },
    {
        "pr_title": "functions: use request signing",
        "pr_number": 1108,
        "file_name": "functions/slack/slack_test.go",
        "code_diff": "@@ -46,11 +50,11 @@\nfunc TestMain(m *testing.M) {\n \t}\n \tconfig = &configuration{\n \t\tProjectID: projectID,\n-\t\tToken:     os.Getenv(\"GOLANG_SAMPLES_SLACK_TOKEN\"),\n+\t\tSecret:    os.Getenv(\"GOLANG_SAMPLES_SLACK_SECRET\"),\n \t\tKey:       os.Getenv(\"GOLANG_SAMPLES_KG_KEY\"),\n \t}\n-\tif config.Token == \"\" {\n-\t\tlog.Print(\"GOLANG_SAMPLES_SLACK_TOKEN is unset. Skipping.\")\n+\tif config.Secret == \"\" {\n+\t\tlog.Print(\"GOLANG_SAMPLES_SLACK_SECRET is unset. Skipping.\")\n \t\treturn\n \t}\n \tif config.Key == \"\" {",
        "comments": [],
        "commit_messages": [
            "tbpg reviews 1"
        ],
        "last_commit_sha": "52a0d66491315bcf78df6264eb9bea8bd391eca0"
    },
    {
        "pr_title": "functions: use request signing",
        "pr_number": 1108,
        "file_name": "functions/slack/slack_test.go",
        "code_diff": "@@ -66,37 +70,6 @@\nfunc TestMain(m *testing.M) {\n \tos.Exit(m.Run())\n }\n \n-func TestVerifyWebHook(t *testing.T) {\n-\ttests := []struct {\n-\t\ttoken   string\n-\t\twantErr bool\n-\t}{\n-\t\t{\n-\t\t\ttoken:   config.Token,\n-\t\t\twantErr: false,\n-\t\t},\n-\t\t{\n-\t\t\ttoken:   \"this is not the token\",\n-\t\t\twantErr: true,\n-\t\t},\n-\t\t{\n-\t\t\ttoken:   \"\",\n-\t\t\twantErr: true,\n-\t\t},\n-\t}\n-\tfor _, test := range tests {\n-\t\tv := make(url.Values)\n-\t\tv.Set(\"token\", test.token)\n-\t\terr := verifyWebHook(v)\n-\t\tif test.wantErr && err == nil {\n-\t\t\tt.Errorf(\"verifyWebHook(%v) got no error, expected error\", test.token)\n-\t\t}\n-\t\tif !test.wantErr && err != nil {\n-\t\t\tt.Errorf(\"verifyWebHook(%v) got %v, want no error\", test.token, err)\n-\t\t}\n-\t}\n-}\n-\n func TestFormatSlackMessage(t *testing.T) {\n \ttests := []struct {\n \t\tquery string",
        "comments": [
            {
                "comment": "`version`",
                "position": 83
            }
        ],
        "commit_messages": [
            "tbpg reviews 1"
        ],
        "last_commit_sha": "52a0d66491315bcf78df6264eb9bea8bd391eca0"
    },
    {
        "pr_title": "run/system_package: add e2e test coverage and update dockerfile",
        "pr_number": 1097,
        "file_name": "internal/cloudrunci/gcloud_test.go",
        "code_diff": "@@ -23,7 +23,6 @@\nimport (\n )\n \n func TestCreateIDToken(t *testing.T) {\n-\tt.Skip()\n \ttestutil.EndToEndTest(t)\n \t// TODO assign to token\n \t_, err := CreateIDToken(\"http://example.com\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "63dd975c7a2f67ba47fc158f199dc49d720bc0e1"
    },
    {
        "pr_title": "firestore: add samples for in and array-contains-any",
        "pr_number": 1081,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -249,6 +249,26 @@\nfunc createMultipleStartAtQuery(client *firestore.Client) {\n \t// [END fs_start_at_multiple]\n }\n \n+func createInQuery(ctx context.Context, client *firestore.Client) error {\n+\t// [START fs_query_filter_in]\n+\tcities := client.Collection(\"cities\")\n+\tquery := cities.Where(\"country\", \"in\", []string{\"USA\", \"Japan\"}).Documents(ctx)\n+\t// [END fs_query_filter_in]\n+\n+\t_ = query\n+\treturn nil\n+}\n+\n+func createInQueryWithArray(ctx context.Context, client *firestore.Client) error {\n+\t// [START fs_query_filter_in_with_array]\n+\tcities := client.Collection(\"cities\")\n+\tquery := cities.Where(\"regions\", \"in\", [][]string{{\"west_coast\"}, {\"east_coast\"}}).Documents(ctx)\n+\t// [END fs_query_filter_in_with_array]\n+\n+\t_ = query\n+\treturn nil\n+}\n+\n func createArrayContainsQuery(ctx context.Context, client *firestore.Client) error {\n \tcities := client.Collection(\"cities\")\n \t// [START fs_array_contains_query]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "138e6d20cefec34218a6417d927c79ecd58a78c1"
    },
    {
        "pr_title": "storage: add list gcs objects with s3 library",
        "pr_number": 1079,
        "file_name": "storage/s3_sdk/list_gcs_buckets.go",
        "code_diff": "@@ -28,7 +28,10 @@\nimport (\n \t\"github.com/aws/aws-sdk-go/service/s3\"\n )\n \n-func listGCSBuckets(w io.Writer, googleAccessKeyID string, googleAccessKeySecret string) ([]*s3.Bucket, error) {\n+func listGCSBuckets(w io.Writer, googleAccessKeyID string, googleAccessKeySecret string) error {\n+\t// googleAccessKeyID := \"Your Google Access Key ID\"\n+\t// googleAccessKeySecret := \"Your Google Access Key Secret\"\n+\n \t// Create a new client and do the following:\n \t// 1. Change the endpoint URL to use the Google Cloud Storage XML API endpoint.\n \t// 2. Use Cloud Storage HMAC Credentials.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "46c0c1c4bd3d8657fec40b9fbe9c2a9e23c87005"
    },
    {
        "pr_title": "storage: add list gcs objects with s3 library",
        "pr_number": 1079,
        "file_name": "storage/s3_sdk/s3_gcs_test.go",
        "code_diff": "@@ -28,7 +28,7 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-func TestList(t *testing.T) {\n+func TestListGCSBuckets(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [
            "storage: create HMAC test key on the fly"
        ],
        "last_commit_sha": "46c0c1c4bd3d8657fec40b9fbe9c2a9e23c87005"
    },
    {
        "pr_title": "storage: add list gcs objects with s3 library",
        "pr_number": 1079,
        "file_name": "storage/s3_sdk/s3_gcs_test.go",
        "code_diff": "@@ -50,7 +50,7 @@\nfunc TestList(t *testing.T) {\n \t// to that amount of time.\n \ttestutil.Retry(t, 75, time.Millisecond*200, func(r *testutil.R) {\n \t\tbuf.Reset()\n-\t\tif _, err := listGCSBuckets(buf, key.AccessID, key.Secret); err != nil {\n+\t\tif err := listGCSBuckets(buf, key.AccessID, key.Secret); err != nil {\n \t\t\tr.Errorf(\"listGCSBuckets: %v\", err)\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "storage: create HMAC test key on the fly"
        ],
        "last_commit_sha": "46c0c1c4bd3d8657fec40b9fbe9c2a9e23c87005"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "tasks/create_http_task.go",
        "code_diff": "@@ -21,15 +21,15 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2beta3\"\n-\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2beta3\"\n+\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2\"\n+\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2\"\n )\n \n // createHTTPTask creates a new task in your with a HTTP target.\n func createHTTPTask(projectID, locationID, queueID, url, message string) (*taskspb.Task, error) {\n \n \t// Create a new Cloud Tasks client instance.\n-\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2beta3\n+\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2\n \tctx := context.Background()\n \tclient, err := cloudtasks.NewClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "Update to new library"
        ],
        "last_commit_sha": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "tasks: Update Cloud Tasks samples to new library version",
        "pr_number": 1077,
        "file_name": "tasks/token/create_http_task_with_token.go",
        "code_diff": "@@ -20,15 +20,15 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2beta3\"\n-\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2beta3\"\n+\tcloudtasks \"cloud.google.com/go/cloudtasks/apiv2\"\n+\ttaskspb \"google.golang.org/genproto/googleapis/cloud/tasks/v2\"\n )\n \n // createHTTPTaskWithToken constructs a task with a authorization token\n // and HTTP target then adds it to a Queue.\n func createHTTPTaskWithToken(projectID, locationID, queueID, url, email, message string) (*taskspb.Task, error) {\n \t// Create a new Cloud Tasks client instance.\n-\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2beta3\n+\t// See https://godoc.org/cloud.google.com/go/cloudtasks/apiv2\n \tctx := context.Background()\n \tclient, err := cloudtasks.NewClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "Update to new library"
        ],
        "last_commit_sha": "f23fa06fa30839121359dd0f018f8d276f68d986"
    },
    {
        "pr_title": "run: add facility for e2e testing",
        "pr_number": 1070,
        "file_name": "internal/testutil/testutil.go",
        "code_diff": "@@ -18,11 +18,12 @@\npackage testutil\n import (\n \t\"errors\"\n \t\"fmt\"\n-\t\"go/build\"\n \t\"log\"\n \t\"os\"\n \t\"path/filepath\"\n \t\"testing\"\n+\n+\t\"golang.org/x/tools/go/packages\"\n )\n \n var noProjectID = errors.New(\"GOLANG_SAMPLES_PROJECT_ID not set\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ae91414c008e505f77fa50d8afa59a4e0eb58d63"
    },
    {
        "pr_title": "all: check PORT env var, explicit ListenAndServe err check, fix testing change check",
        "pr_number": 1060,
        "file_name": "appengine/go11x/static/main.go",
        "code_diff": "@@ -15,7 +15,6 @@\npackage main\n \n import (\n-\t\"fmt\"\n \t\"html/template\"\n \t\"log\"\n \t\"net/http\"",
        "comments": [],
        "commit_messages": [
            "all: check PORT env var, explicit ListenAndServe err check"
        ],
        "last_commit_sha": "b6e23f79b8ba9f45b1889f7e76366320d231c58b"
    },
    {
        "pr_title": "all: check PORT env var, explicit ListenAndServe err check, fix testing change check",
        "pr_number": 1060,
        "file_name": "appengine_flexible/websockets/main.go",
        "code_diff": "@@ -21,6 +21,7 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \t\"net/http\"\n+\t\"os\"\n \n \t\"github.com/gorilla/websocket\"\n )",
        "comments": [],
        "commit_messages": [
            "all: check PORT env var, explicit ListenAndServe err check"
        ],
        "last_commit_sha": "b6e23f79b8ba9f45b1889f7e76366320d231c58b"
    },
    {
        "pr_title": "all: check PORT env var, explicit ListenAndServe err check, fix testing change check",
        "pr_number": 1060,
        "file_name": "docs/error-reporting/fluent/main.go",
        "code_diff": "@@ -20,6 +20,7 @@\npackage main\n import (\n \t\"log\"\n \t\"net/http\"\n+\t\"os\"\n \t\"runtime\"\n \n \t\"github.com/fluent/fluent-logger-golang/fluent\"",
        "comments": [],
        "commit_messages": [
            "all: check PORT env var, explicit ListenAndServe err check"
        ],
        "last_commit_sha": "b6e23f79b8ba9f45b1889f7e76366320d231c58b"
    },
    {
        "pr_title": "all: check PORT env var, explicit ListenAndServe err check, fix testing change check",
        "pr_number": 1060,
        "file_name": "endpoints/getting-started/app.go",
        "code_diff": "@@ -22,7 +22,6 @@\nimport (\n \t\"log\"\n \t\"net/http\"\n \t\"os\"\n-\t\"strconv\"\n \n \t\"github.com/gorilla/mux\"\n )",
        "comments": [],
        "commit_messages": [
            "endpoints: no more Atoi"
        ],
        "last_commit_sha": "b6e23f79b8ba9f45b1889f7e76366320d231c58b"
    },
    {
        "pr_title": "all: check PORT env var, explicit ListenAndServe err check, fix testing change check",
        "pr_number": 1060,
        "file_name": "getting-started/devflowapp/devflowapp.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \t\"net/http\"\n+\t\"os\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/getting-started/devflowapp/services\"\n )",
        "comments": [],
        "commit_messages": [
            "all: check PORT env var, explicit ListenAndServe err check"
        ],
        "last_commit_sha": "b6e23f79b8ba9f45b1889f7e76366320d231c58b"
    },
    {
        "pr_title": "all: check PORT env var, explicit ListenAndServe err check, fix testing change check",
        "pr_number": 1060,
        "file_name": "run/image-processing/main.go",
        "code_diff": "@@ -19,7 +19,6 @@\npackage main\n \n import (\n \t\"encoding/json\"\n-\t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"",
        "comments": [],
        "commit_messages": [
            "all: check PORT env var, explicit ListenAndServe err check"
        ],
        "last_commit_sha": "b6e23f79b8ba9f45b1889f7e76366320d231c58b"
    },
    {
        "pr_title": "healthcare: conditional samples",
        "pr_number": 1041,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -23,6 +23,7 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\tdicomwebsearchinstances \"github.com/GoogleCloudPlatform/golang-samples/healthcare/internal/dicomweb-instance-search\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_messages": [
            "healthcare: conditional samples\n\nConditional patch is not working right now, but the sample looks correct\nto me. So, I left out the region tag and test for it."
        ],
        "last_commit_sha": "0803f27a4718e7381d969bfd17db9af9bb38c992"
    },
    {
        "pr_title": "healthcare: conditional samples",
        "pr_number": 1041,
        "file_name": "healthcare/fhir_test.go",
        "code_diff": "@@ -25,6 +25,9 @@\nimport (\n \t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n+\tconditionaldelete \"github.com/GoogleCloudPlatform/golang-samples/healthcare/internal/fhir-resource-conditional-delete\"\n+\tconditionalpatch \"github.com/GoogleCloudPlatform/golang-samples/healthcare/internal/fhir-resource-conditional-patch\"\n+\tconditionalupdate \"github.com/GoogleCloudPlatform/golang-samples/healthcare/internal/fhir-resource-conditional-update\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"google.golang.org/api/iterator\"\n )",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0803f27a4718e7381d969bfd17db9af9bb38c992"
    },
    {
        "pr_title": "healthcare: conditional samples",
        "pr_number": 1041,
        "file_name": "healthcare/fhir_test.go",
        "code_diff": "@@ -167,6 +170,44 @@\nfunc TestFHIRStore(t *testing.T) {\n \t\t}\n \t})\n \n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tbuf.Reset()\n+\t\tpatchedRes := resource{}\n+\t\tif err := conditionalpatch.ConditionalPatchFHIRResource(buf, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, false); err != nil {\n+\t\t\tr.Errorf(\"ConditionalPatchFHIRResource got err: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif err := json.Unmarshal(buf.Bytes(), &patchedRes); err != nil {\n+\t\t\tr.Errorf(\"json.Unmarshal ConditionalPatchFHIRResource output: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif patchedRes.ID != res.ID {\n+\t\t\tr.Errorf(\"ConditionalPatchFHIRResource got ID=%v, want %v\", patchedRes.ID, res.ID)\n+\t\t\treturn\n+\t\t}\n+\t\tif patchedRes.Active {\n+\t\t\tr.Errorf(\"ConditionalPatchFHIRResource got active=true, expected active=false\")\n+\t\t}\n+\n+\t\tbuf.Reset()\n+\t\tpatchedRes = resource{}\n+\t\tif err := conditionalupdate.ConditionalUpdateFHIRResource(buf, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, true); err != nil {\n+\t\t\tr.Errorf(\"ConditionalUpdateFHIRResource got err: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif err := json.Unmarshal(buf.Bytes(), &patchedRes); err != nil {\n+\t\t\tr.Errorf(\"json.Unmarshal ConditionalUpdateFHIRResource output: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif patchedRes.ID != res.ID {\n+\t\t\tr.Errorf(\"ConditionalUpdateFHIRResource got ID=%v, want %v; wrong condition led to creating a new resource?\", patchedRes.ID, res.ID)\n+\t\t\treturn\n+\t\t}\n+\t\tif !patchedRes.Active {\n+\t\t\tr.Errorf(\"ConditionalUpdateFHIRResource got active=false, expected active=true\")\n+\t\t}\n+\t})\n+\n \ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n \t\tbuf.Reset()\n \t\tif err := fhirGetPatientEverything(buf, tc.ProjectID, location, datasetID, fhirStoreID, res.ID); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0803f27a4718e7381d969bfd17db9af9bb38c992"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/subscriptions/async_pull.go",
        "code_diff": "@@ -25,9 +25,9 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n )\n \n-func pullMsgs(w io.Writer, projectID, subName string, topic *pubsub.Topic) error {\n+func pullMsgs(w io.Writer, projectID, subID string, topic *pubsub.Topic) error {\n \t// projectID := \"my-project-id\"\n-\t// subName := projectID + \"-example-sub\"\n+\t// subID := \"my-sub\"\n \t// topic of type https://godoc.org/cloud.google.com/go/pubsub#Topic\n \tctx := context.Background()\n \tclient, err := pubsub.NewClient(ctx, projectID)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/subscriptions/create_endpoint.go",
        "code_diff": "@@ -24,9 +24,9 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n )\n \n-func createWithEndpoint(w io.Writer, projectID, subName string, topic *pubsub.Topic, endpoint string) error {\n+func createWithEndpoint(w io.Writer, projectID, subID string, topic *pubsub.Topic, endpoint string) error {\n \t// projectID := \"my-project-id\"\n-\t// subName := projectID + \"-example-sub\"\n+\t// subID := \"my-sub\"\n \t// topic of type https://godoc.org/cloud.google.com/go/pubsub#Topic\n \t// endpoint := \"https://my-test-project.appspot.com/push\"\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/subscriptions/pull_error.go",
        "code_diff": "@@ -23,9 +23,9 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n )\n \n-func pullMsgsError(w io.Writer, projectID, subName string) error {\n+func pullMsgsError(w io.Writer, projectID, subID string) error {\n \t// projectID := \"my-project-id\"\n-\t// subName := projectID + \"-example-sub\"\n+\t// subID := \"my-sub\"\n \tctx := context.Background()\n \tclient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -29,8 +29,8 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-var topicName string\n-var subName string\n+var topicID string\n+var subID string\n \n // once guards cleanup related operations in setup. No need to set up and tear\n // down every time, so this speeds things up.",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -40,8 +40,8 @@\nfunc setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n-\ttopicName = tc.ProjectID + \"-test-sub-topic\"\n-\tsubName = tc.ProjectID + \"-test-sub\"\n+\ttopicID = \"test-sub-topic\"\n+\tsubID = \"test-sub\"\n \tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -50,24 +50,24 @@\nfunc setup(t *testing.T) *pubsub.Client {\n \n \t// Cleanup resources from the previous tests.\n \tonce.Do(func() {\n-\t\ttopic := client.Topic(topicName)\n+\t\ttopic := client.Topic(topicID)\n \t\tok, err := topic.Exists(ctx)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t\t}\n \t\tif ok {\n \t\t\tif err := topic.Delete(ctx); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicName, err)\n+\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicID, err)\n \t\t\t}\n \t\t}\n-\t\tsub := client.Subscription(subName)\n+\t\tsub := client.Subscription(subID)\n \t\tok, err = sub.Exists(ctx)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"failed to check if subscription exists: %v\", err)\n \t\t}\n \t\tif ok {\n \t\t\tif err := sub.Delete(ctx); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to cleanup the subscription (%q): %v\", subName, err)\n+\t\t\t\tt.Fatalf(\"failed to cleanup the subscription (%q): %v\", subID, err)\n \t\t\t}\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -79,20 +79,20 @@\nfunc TestCreate(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \tclient := setup(t)\n-\ttopic, err := client.CreateTopic(ctx, topicName)\n+\ttopic, err := client.CreateTopic(ctx, topicID)\n \tif err != nil {\n \t\tt.Fatalf(\"CreateTopic: %v\", err)\n \t}\n \tbuf := new(bytes.Buffer)\n-\tif err := create(buf, tc.ProjectID, subName, topic); err != nil {\n+\tif err := create(buf, tc.ProjectID, subID, topic); err != nil {\n \t\tt.Fatalf(\"failed to create a subscription: %v\", err)\n \t}\n-\tok, err := client.Subscription(subName).Exists(context.Background())\n+\tok, err := client.Subscription(subID).Exists(context.Background())\n \tif err != nil {\n \t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n \t}\n \tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", subName)\n+\t\tt.Fatalf(\"got none; want sub = %q\", subID)\n \t}\n }",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -107,16 +107,16 @@\nfunc TestList(t *testing.T) {\n \t\t}\n \n \t\tfor _, sub := range subs {\n-\t\t\tif sub.ID() == subName {\n+\t\t\tif sub.ID() == subID {\n \t\t\t\treturn // PASS\n \t\t\t}\n \t\t}\n \n-\t\tsubNames := make([]string, len(subs))\n+\t\tsubIDs := make([]string, len(subs))\n \t\tfor i, sub := range subs {\n-\t\t\tsubNames[i] = sub.ID()\n+\t\t\tsubIDs[i] = sub.ID()\n \t\t}\n-\t\tr.Errorf(\"got %+v; want a list with subscription %q\", subNames, subName)\n+\t\tr.Errorf(\"got %+v; want a list with subscription %q\", subIDs, subID)\n \t})\n }",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -125,7 +125,7 @@\nfunc TestIAM(t *testing.T) {\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\tbuf := new(bytes.Buffer)\n-\t\tperms, err := testPermissions(buf, tc.ProjectID, subName)\n+\t\tperms, err := testPermissions(buf, tc.ProjectID, subID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"testPermissions: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -135,14 +135,14 @@\nfunc TestIAM(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := addUsers(tc.ProjectID, subName); err != nil {\n+\t\tif err := addUsers(tc.ProjectID, subID); err != nil {\n \t\t\tr.Errorf(\"addUsers: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\tbuf := new(bytes.Buffer)\n-\t\tpolicy, err := policy(buf, tc.ProjectID, subName)\n+\t\tpolicy, err := policy(buf, tc.ProjectID, subID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"policy: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -160,17 +160,17 @@\nfunc TestDelete(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tclient := setup(t)\n \n-\ttopic := client.Topic(topicName)\n+\ttopic := client.Topic(topicID)\n \tok, err := topic.Exists(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t}\n \tif !ok {\n-\t\ttopic, err := client.CreateTopic(ctx, topicName)\n+\t\ttopic, err := client.CreateTopic(ctx, topicID)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"CreateTopic: %v\", err)\n \t\t}\n-\t\t_, err = client.CreateSubscription(ctx, subName, pubsub.SubscriptionConfig{\n+\t\t_, err = client.CreateSubscription(ctx, subID, pubsub.SubscriptionConfig{\n \t\t\tTopic:       topic,\n \t\t\tAckDeadline: 20 * time.Second,\n \t\t})",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -28,7 +28,7 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-var topicName string\n+var topicID string\n \n // once guards cleanup related operations in setup. No need to set up and tear\n // down every time, so this speeds things up.",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -38,7 +38,7 @@\nfunc setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n-\ttopicName = tc.ProjectID + \"-test-topic\"\n+\ttopicID = \"test-topic\"\n \tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -47,14 +47,14 @@\nfunc setup(t *testing.T) *pubsub.Client {\n \n \t// Cleanup resources from the previous tests.\n \tonce.Do(func() {\n-\t\ttopic := client.Topic(topicName)\n+\t\ttopic := client.Topic(topicID)\n \t\tok, err := topic.Exists(ctx)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t\t}\n \t\tif ok {\n \t\t\tif err := topic.Delete(ctx); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicName, err)\n+\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicID, err)\n \t\t\t}\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -66,15 +66,15 @@\nfunc TestCreate(t *testing.T) {\n \tclient := setup(t)\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)\n-\tif err := create(buf, tc.ProjectID, topicName); err != nil {\n+\tif err := create(buf, tc.ProjectID, topicID); err != nil {\n \t\tt.Fatalf(\"failed to create a topic: %v\", err)\n \t}\n-\tok, err := client.Topic(topicName).Exists(context.Background())\n+\tok, err := client.Topic(topicID).Exists(context.Background())\n \tif err != nil {\n \t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t}\n \tif !ok {\n-\t\tt.Fatalf(\"got none; want topic = %q\", topicName)\n+\t\tt.Fatalf(\"got none; want topic = %q\", topicID)\n \t}\n }",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -88,16 +88,16 @@\nfunc TestList(t *testing.T) {\n \t\t}\n \n \t\tfor _, t := range topics {\n-\t\t\tif t.ID() == topicName {\n+\t\t\tif t.ID() == topicID {\n \t\t\t\treturn // PASS\n \t\t\t}\n \t\t}\n \n-\t\ttopicNames := make([]string, len(topics))\n+\t\ttopicIDs := make([]string, len(topics))\n \t\tfor i, t := range topics {\n-\t\t\ttopicNames[i] = t.ID()\n+\t\t\ttopicIDs[i] = t.ID()\n \t\t}\n-\t\tr.Errorf(\"got %+v; want a list with topic = %q\", topicNames, topicName)\n+\t\tr.Errorf(\"got %+v; want a list with topic = %q\", topicIDs, topicID)\n \t})\n }",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -107,9 +107,9 @@\nfunc TestPublish(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \tclient := setup(t)\n-\tclient.CreateTopic(ctx, topicName)\n+\tclient.CreateTopic(ctx, topicID)\n \tbuf := new(bytes.Buffer)\n-\tif err := publish(buf, tc.ProjectID, topicName, \"hello world\"); err != nil {\n+\tif err := publish(buf, tc.ProjectID, topicID, \"hello world\"); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -119,9 +119,9 @@\nfunc TestPublishThatScales(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tsetup(t)\n \tclient := setup(t)\n-\tclient.CreateTopic(ctx, topicName)\n+\tclient.CreateTopic(ctx, topicID)\n \tbuf := new(bytes.Buffer)\n-\tif err := publishThatScales(buf, tc.ProjectID, topicName, 10); err != nil {\n+\tif err := publishThatScales(buf, tc.ProjectID, topicID, 10); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -131,9 +131,9 @@\nfunc TestPublishCustomAttributes(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tsetup(t)\n \tclient := setup(t)\n-\tclient.CreateTopic(ctx, topicName)\n+\tclient.CreateTopic(ctx, topicID)\n \tbuf := new(bytes.Buffer)\n-\tif err := publishCustomAttributes(buf, tc.ProjectID, topicName); err != nil {\n+\tif err := publishCustomAttributes(buf, tc.ProjectID, topicID); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -142,11 +142,11 @@\nfunc TestIAM(t *testing.T) {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \tclient := setup(t)\n-\tclient.CreateTopic(ctx, topicName)\n+\tclient.CreateTopic(ctx, topicID)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\tbuf := new(bytes.Buffer)\n-\t\tperms, err := testPermissions(buf, tc.ProjectID, topicName)\n+\t\tperms, err := testPermissions(buf, tc.ProjectID, topicID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"testPermissions: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "Pubsub: Correct subscription reference",
        "pr_number": 1017,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -156,14 +156,14 @@\nfunc TestIAM(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := addUsers(tc.ProjectID, topicName); err != nil {\n+\t\tif err := addUsers(tc.ProjectID, topicID); err != nil {\n \t\t\tr.Errorf(\"addUsers: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\tbuf := new(bytes.Buffer)\n-\t\tpolicy, err := policy(buf, tc.ProjectID, topicName)\n+\t\tpolicy, err := policy(buf, tc.ProjectID, topicID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"policy: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "Postfix Pubsub topic and subscription string variables with ID instead of name\n\nSigned-off-by: Abdullah Algarni <AlgarniAbdullah@outlook.com>"
        ],
        "last_commit_sha": "ba5f86e1bce0684faa6ce728daf763090239ab3a"
    },
    {
        "pr_title": "healthcare: add search study by tags",
        "pr_number": 1015,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -30,6 +30,7 @@\nimport (\n // the metadata of the DICOM file and make up the DicomWebPath\n // in the requests to retrieve studies/instances/frames/rendered.\n const (\n+\tstudyPath          = \"studies\"\n \tstudyUID           = \"studies/1.3.6.1.4.1.11129.5.5.111396399361969898205364400549799252857604/\"\n \tseriesUID          = \"series/1.3.6.1.4.1.11129.5.5.195628213694300498946760767481291263511724/\"\n \tinstanceUID        = \"instances/1.3.6.1.4.1.11129.5.5.153751009835107614666834563294684339746480/\"",
        "comments": [],
        "commit_messages": [
            "healthcare: add search study by tags"
        ],
        "last_commit_sha": "f824d4cacbc7412a1d200074d404de4f929088b3"
    },
    {
        "pr_title": "healthcare: add search study by tags",
        "pr_number": 1015,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -82,7 +83,7 @@\nfunc TestDICOMStore(t *testing.T) {\n \t\t\tr.Errorf(\"getDICOMStore got err: %v\", err)\n \t\t}\n \t\tif got := buf.String(); !strings.Contains(got, dicomStoreName) {\n-\t\t\tr.Errorf(\"listDICOMStores got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, dicomStoreName)\n+\t\t\tr.Errorf(\"getDICOMStores got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, dicomStoreName)\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "healthcare: add search study by tags"
        ],
        "last_commit_sha": "f824d4cacbc7412a1d200074d404de4f929088b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/bookshelf.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"io\"\n \t\"os\"\n \n+\t\"cloud.google.com/go/errorreporting\"\n \t\"cloud.google.com/go/storage\"\n )",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/bookshelf.go",
        "code_diff": "@@ -49,9 +50,6 @@\ntype BookDatabase interface {\n \n \t// UpdateBook updates the entry for a given book.\n \tUpdateBook(ctx context.Context, b *Book) error\n-\n-\t// Close closes the database, freeing up any available resources.\n-\tClose(ctx context.Context) error\n }\n \n // Bookshelf holds a BookDatabase and storage info.",
        "comments": [],
        "commit_messages": [
            "getting-started/bookshelf: update config.go refs, remove Close()"
        ],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/bookshelf.go",
        "code_diff": "@@ -62,7 +60,13 @@\ntype Bookshelf struct {\n \tStorageBucketName string\n \n \t// logWriter is used for request logging and can be overridden for tests.\n+\t//\n+\t// See https://cloud.google.com/logging/docs/setup/go for how to use the\n+\t// Stackdriver logging client. Output to stdout and stderr is automaticaly\n+\t// sent to Stackdriver when running on App Engine.\n \tlogWriter io.Writer\n+\n+\terrorClient *errorreporting.Client\n }\n \n // NewBookshelf creates a new Bookshelf.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -32,8 +32,10 @@\ntype firestoreDB struct {\n // Ensure firestoreDB conforms to the BookDatabase interface.\n var _ BookDatabase = &firestoreDB{}\n \n+// [START getting_started_bookshelf_firestore]\n+\n // newFirestoreDB creates a new BookDatabase backed by Cloud Firestore.\n-// See the firestore and google packages for details on creating a suitable\n+// See the firestore package for details on creating a suitable\n // firestore.Client: https://godoc.org/cloud.google.com/go/firestore.\n func newFirestoreDB(client *firestore.Client) (*firestoreDB, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "getting-started/bookshelf: add /errors and /logs and more region tags"
        ],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/db_firestore.go",
        "code_diff": "@@ -55,7 +57,7 @@\nfunc (db *firestoreDB) Close(context.Context) error {\n \treturn db.client.Close()\n }\n \n-// GetBook retrieves a book by its ID.\n+// Book retrieves a book by its ID.\n func (db *firestoreDB) GetBook(ctx context.Context, id string) (*Book, error) {\n \tds, err := db.client.Collection(\"books\").Doc(id).Get(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -27,7 +27,9 @@\nimport (\n \t\"net/http\"\n \t\"os\"\n \t\"path\"\n+\t\"runtime/debug\"\n \n+\t\"cloud.google.com/go/errorreporting\"\n \t\"cloud.google.com/go/firestore\"\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/gofrs/uuid\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -62,13 +64,12 @@\nfunc main() {\n \tif err != nil {\n \t\tlog.Fatalf(\"newFirestoreDB: %v\", err)\n \t}\n-\n-\tshelf, err := NewBookshelf(projectID, db)\n+\tb, err := NewBookshelf(projectID, db)\n \tif err != nil {\n \t\tlog.Fatalf(\"NewBookshelf: %v\", err)\n \t}\n \n-\tshelf.registerHandlers()\n+\tb.registerHandlers()\n \n \tlog.Printf(\"Listening on localhost:%s\", port)\n \tlog.Fatal(http.ListenAndServe(fmt.Sprintf(\":%s\", port), nil))",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -85,16 +86,16 @@\nfunc (b *Bookshelf) registerHandlers() {\n \t\tHandler(appHandler(b.listHandler))\n \tr.Methods(\"GET\").Path(\"/books/add\").\n \t\tHandler(appHandler(b.addFormHandler))\n-\tr.Methods(\"GET\").Path(\"/books/{id:[0-9a-zA-Z]+}\").\n+\tr.Methods(\"GET\").Path(\"/books/{id:[0-9a-zA-Z_\\\\-]+}\").\n \t\tHandler(appHandler(b.detailHandler))\n-\tr.Methods(\"GET\").Path(\"/books/{id:[0-9a-zA-Z]+}/edit\").\n+\tr.Methods(\"GET\").Path(\"/books/{id:[0-9a-zA-Z_\\\\-]+}/edit\").\n \t\tHandler(appHandler(b.editFormHandler))\n \n \tr.Methods(\"POST\").Path(\"/books\").\n \t\tHandler(appHandler(b.createHandler))\n-\tr.Methods(\"POST\", \"PUT\").Path(\"/books/{id:[0-9a-zA-Z]+}\").\n+\tr.Methods(\"POST\", \"PUT\").Path(\"/books/{id:[0-9a-zA-Z_\\\\-]+}\").\n \t\tHandler(appHandler(b.updateHandler))\n-\tr.Methods(\"POST\").Path(\"/books/{id:[0-9a-zA-Z]+}:delete\").\n+\tr.Methods(\"POST\").Path(\"/books/{id:[0-9a-zA-Z_\\\\-]+}:delete\").\n \t\tHandler(appHandler(b.deleteHandler)).Name(\"delete\")\n \n \t// Respond to App Engine and Compute Engine health checks.",
        "comments": [],
        "commit_messages": [
            "getting-started/bookshelf: add /errors and /logs and more region tags"
        ],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -104,22 +105,23 @@\nfunc (b *Bookshelf) registerHandlers() {\n \t\t\tw.Write([]byte(\"ok\"))\n \t\t})\n \n-\t// [START request_logging]\n+\tr.Methods(\"GET\").Path(\"/logs\").Handler(appHandler(b.sendLog))\n+\tr.Methods(\"GET\").Path(\"/errors\").Handler(appHandler(b.sendError))\n+\n \t// Delegate all of the HTTP routing and serving to the gorilla/mux router.\n \t// Log all requests using the standard Apache format.\n \thttp.Handle(\"/\", handlers.CombinedLoggingHandler(b.logWriter, r))\n-\t// [END request_logging]\n }\n \n // listHandler displays a list with summaries of books in the database.\n func (b *Bookshelf) listHandler(w http.ResponseWriter, r *http.Request) *appError {\n \tctx := r.Context()\n \tbooks, err := b.DB.ListBooks(ctx)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"could not list books: %v\", err)\n+\t\treturn b.appErrorf(r, err, \"could not list books: %v\", err)\n \t}\n \n-\treturn listTmpl.Execute(w, r, books)\n+\treturn listTmpl.Execute(b, w, r, books)\n }\n \n // bookFromRequest retrieves a book from the database given a book ID in the",
        "comments": [
            {
                "comment": "Does not appear that named return values are in use. Seems like it could lead to surprises if a later logical error is introduced.",
                "position": 115
            },
            {
                "comment": "I think it's more for documentation - it's not clear from the name `uploadFileFromForm` that a URL would be returned.",
                "position": 115
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -141,27 +143,27 @@\nfunc (b *Bookshelf) bookFromRequest(r *http.Request) (*Book, error) {\n func (b *Bookshelf) detailHandler(w http.ResponseWriter, r *http.Request) *appError {\n \tbook, err := b.bookFromRequest(r)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"%v\", err)\n+\t\treturn b.appErrorf(r, err, \"%v\", err)\n \t}\n \n-\treturn detailTmpl.Execute(w, r, book)\n+\treturn detailTmpl.Execute(b, w, r, book)\n }\n \n // addFormHandler displays a form that captures details of a new book to add to\n // the database.\n func (b *Bookshelf) addFormHandler(w http.ResponseWriter, r *http.Request) *appError {\n-\treturn editTmpl.Execute(w, r, nil)\n+\treturn editTmpl.Execute(b, w, r, nil)\n }\n \n // editFormHandler displays a form that allows the user to edit the details of\n // a given book.\n func (b *Bookshelf) editFormHandler(w http.ResponseWriter, r *http.Request) *appError {\n \tbook, err := b.bookFromRequest(r)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"%v\", err)\n+\t\treturn b.appErrorf(r, err, \"%v\", err)\n \t}\n \n-\treturn editTmpl.Execute(w, r, book)\n+\treturn editTmpl.Execute(b, w, r, book)\n }\n \n // bookFromForm populates the fields of a Book from form values",
        "comments": [],
        "commit_messages": [
            "getting-started/bookshelf: add /errors and /logs and more region tags"
        ],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -187,6 +189,8 @@\nfunc (b *Bookshelf) bookFromForm(r *http.Request) (*Book, error) {\n \treturn book, nil\n }\n \n+// [START getting_started_bookshelf_storage]\n+\n // uploadFileFromForm uploads a file if it's present in the \"image\" form field.\n func (b *Bookshelf) uploadFileFromForm(ctx context.Context, r *http.Request) (url string, err error) {\n \tf, fh, err := r.FormFile(\"image\")",
        "comments": [],
        "commit_messages": [
            "getting-started/bookshelf: add /errors and /logs and more region tags"
        ],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -198,11 +202,11 @@\nfunc (b *Bookshelf) uploadFileFromForm(ctx context.Context, r *http.Request) (ur\n \t}\n \n \tif b.StorageBucket == nil {\n-\t\treturn \"\", errors.New(\"storage bucket is missing: check config.go\")\n+\t\treturn \"\", errors.New(\"storage bucket is missing: check bookshelf.go\")\n \t}\n \tif _, err := b.StorageBucket.Attrs(ctx); err != nil {\n \t\tif err == storage.ErrBucketNotExist {\n-\t\t\treturn \"\", fmt.Errorf(\"bucket %q does not exist: check config.go\", b.StorageBucketName)\n+\t\t\treturn \"\", fmt.Errorf(\"bucket %q does not exist: check bookshelf.go\", b.StorageBucketName)\n \t\t}\n \t\treturn \"\", fmt.Errorf(\"could not get bucket: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "getting-started/bookshelf: update config.go refs, remove Close()"
        ],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -230,16 +234,18 @@\nfunc (b *Bookshelf) uploadFileFromForm(ctx context.Context, r *http.Request) (ur\n \treturn fmt.Sprintf(publicURL, b.StorageBucketName, name), nil\n }\n \n+// [END getting_started_bookshelf_storage]\n+\n // createHandler adds a book to the database.\n func (b *Bookshelf) createHandler(w http.ResponseWriter, r *http.Request) *appError {\n \tctx := r.Context()\n \tbook, err := b.bookFromForm(r)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"could not parse book from form: %v\", err)\n+\t\treturn b.appErrorf(r, err, \"could not parse book from form: %v\", err)\n \t}\n \tid, err := b.DB.AddBook(ctx, book)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"could not save book: %v\", err)\n+\t\treturn b.appErrorf(r, err, \"could not save book: %v\", err)\n \t}\n \thttp.Redirect(w, r, fmt.Sprintf(\"/books/%s\", id), http.StatusFound)\n \treturn nil",
        "comments": [
            {
                "comment": "Passing around the bookshelf object seems reasonable and useful, but it looks to me like maybe it should be embedded inside a context object? That seems to be the kind of role you have in mind for it.",
                "position": 236
            },
            {
                "comment": "I need access to `errorClient` and `errLogger` in `ServeHTTP`. Neither of those is request-scoped, so I don't think it's a good fit to embed in the context - could be wrong. The `errLogger` is kind of request scoped in that we want to pass it the request info, but I'm not sure if that works here.",
                "position": 236
            }
        ],
        "commit_messages": [
            "getting-started/bookshelf: add /errors and /logs and more region tags"
        ],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -250,16 +256,16 @@\nfunc (b *Bookshelf) updateHandler(w http.ResponseWriter, r *http.Request) *appEr\n \tctx := r.Context()\n \tid := mux.Vars(r)[\"id\"]\n \tif id == \"\" {\n-\t\treturn appErrorf(errors.New(\"no book with empty ID\"), \"no book with empty ID\")\n+\t\treturn b.appErrorf(r, errors.New(\"no book with empty ID\"), \"no book with empty ID\")\n \t}\n \tbook, err := b.bookFromForm(r)\n \tif err != nil {\n-\t\treturn appErrorf(err, \"could not parse book from form: %v\", err)\n+\t\treturn b.appErrorf(r, err, \"could not parse book from form: %v\", err)\n \t}\n \tbook.ID = id\n \n \tif err := b.DB.UpdateBook(ctx, book); err != nil {\n-\t\treturn appErrorf(err, \"UpdateBook: %v\", err)\n+\t\treturn b.appErrorf(r, err, \"UpdateBook: %v\", err)\n \t}\n \thttp.Redirect(w, r, fmt.Sprintf(\"/books/%s\", book.ID), http.StatusFound)\n \treturn nil",
        "comments": [],
        "commit_messages": [
            "getting-started/bookshelf: add /errors and /logs and more region tags"
        ],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "getting-started/bookshelf: add /errors and /logs and more region tags",
        "pr_number": 1010,
        "file_name": "getting-started/bookshelf/main_test.go",
        "code_diff": "@@ -56,6 +56,17 @@\nfunc TestMain(m *testing.M) {\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"firestore.NewClient: %v\", err)\n \t\t}\n+\n+\t\t// Delete all docs first to start with a clean slate.\n+\t\tdocs, err := client.Collection(\"books\").DocumentRefs(ctx).GetAll()\n+\t\tif err == nil {\n+\t\t\tfor _, d := range docs {\n+\t\t\t\tif _, err := d.Delete(ctx); err != nil {\n+\t\t\t\t\tlog.Fatalf(\"Delete: %v\", err)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n \t\tdb, err := newFirestoreDB(client)\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"newFirestoreDB: %v\", err)",
        "comments": [],
        "commit_messages": [
            "getting-started/bookshelf: add /errors and /logs and more region tags"
        ],
        "last_commit_sha": "c095f083ca2eb42c732187d4276cd17d080126b3"
    },
    {
        "pr_title": "bigtable: GC snippet + reenable tests",
        "pr_number": 998,
        "file_name": "bigtable/garbagecollection/garbagecollection_test.go",
        "code_diff": "@@ -17,16 +17,17 @@\npackage garbagecollection\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"\n \n \t\"cloud.google.com/go/bigtable\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"github.com/google/uuid\"\n )\n \n func TestGarbageCollection(t *testing.T) {\n-\tt.Skip(\"Flaky: https://github.com/GoogleCloudPlatform/golang-samples/issues/914\")\n \ttc := testutil.SystemTest(t)\n \n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "Adding Snippet for updating Bigtable garbage collection rule and reenabling tests"
        ],
        "last_commit_sha": "f821e1e6191767a36b9a89b485994696b34f46d2"
    },
    {
        "pr_title": "bigtable: GC snippet + reenable tests",
        "pr_number": 998,
        "file_name": "bigtable/garbagecollection/garbagecollection_test.go",
        "code_diff": "@@ -36,8 +37,8 @@\nfunc TestGarbageCollection(t *testing.T) {\n \t\tt.Skip(\"Skipping bigtable integration test. Set GOLANG_SAMPLES_BIGTABLE_PROJECT and GOLANG_SAMPLES_BIGTABLE_INSTANCE.\")\n \t}\n \tadminClient, err := bigtable.NewAdminClient(ctx, project, instance)\n-\n-\ttableName := \"gc-table-\" + tc.ProjectID\n+\tuuid, err := uuid.NewRandom()\n+\ttableName := fmt.Sprintf(\"gc-table-%s-%s\", tc.ProjectID, uuid.String()[:8])\n \tadminClient.DeleteTable(ctx, tableName)\n \n \tif err := adminClient.CreateTable(ctx, tableName); err != nil {",
        "comments": [
            {
                "comment": "This looks like the full string? We usually like to check a smaller amount to avoid breaking the test on small changes.",
                "position": 40
            },
            {
                "comment": "I don't really have an issue with that. If people change the code, they should change the test too.",
                "position": 40
            }
        ],
        "commit_messages": [
            "Adding Snippet for updating Bigtable garbage collection rule and reenabling tests"
        ],
        "last_commit_sha": "f821e1e6191767a36b9a89b485994696b34f46d2"
    },
    {
        "pr_title": "getting-started/sessions: switch to greetings & add regions",
        "pr_number": 991,
        "file_name": "getting-started/sessions/main.go",
        "code_diff": "@@ -12,6 +12,8 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START getting_started_sessions_setup]\n+\n // Command sessions starts an HTTP server that uses session state.\n package main",
        "comments": [],
        "commit_messages": [
            "getting-started/sessions: switch to greetings & add regions"
        ],
        "last_commit_sha": "4951edf95401aa8cb58c32829127323b1f555c9f"
    },
    {
        "pr_title": "getting-started/sessions: switch to greetings & add regions",
        "pr_number": 991,
        "file_name": "getting-started/sessions/main.go",
        "code_diff": "@@ -35,8 +37,18 @@\ntype app struct {\n \ttmpl  *template.Template\n }\n \n-// colors are the random background colors that will be assigned to sessions.\n-var colors = []string{\"red\", \"blue\", \"green\", \"yellow\", \"pink\"}\n+// greetings are the random greetings that will be assigned to sessions.\n+var greetings = []string{\n+\t\"Hello World\",\n+\t\"Hallo Welt\",\n+\t\"Ciao Mondo\",\n+\t\"Salut le Monde\",\n+\t\"Hola Mundo\",\n+}\n+\n+// [END getting_started_sessions_setup]\n+\n+// [START getting_started_sessions_main]\n \n func main() {\n \tport := os.Getenv(\"PORT\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4951edf95401aa8cb58c32829127323b1f555c9f"
    },
    {
        "pr_title": "getting-started/sessions: switch to greetings & add regions",
        "pr_number": 991,
        "file_name": "getting-started/sessions/main.go",
        "code_diff": "@@ -71,7 +83,7 @@\nfunc newApp(projectID string) (*app, error) {\n \t\tlog.Fatalf(\"firestoregorilla.New: %v\", err)\n \t}\n \n-\ttmpl, err := template.New(\"Index\").Parse(\"<body bgcolor={{.color}}>Views {{.views}}</body>\")\n+\ttmpl, err := template.New(\"Index\").Parse(`<body>{{.views}} {{if eq .views 1.0}}view{{else}}views{{end}} for \"{{.greeting}}\"</body>`)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"template.New: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "getting-started/sessions: switch to greetings & add regions"
        ],
        "last_commit_sha": "4951edf95401aa8cb58c32829127323b1f555c9f"
    },
    {
        "pr_title": "getting-started/sessions: switch to greetings & add regions",
        "pr_number": 991,
        "file_name": "getting-started/sessions/main.go",
        "code_diff": "@@ -82,7 +94,12 @@\nfunc newApp(projectID string) (*app, error) {\n \t}, nil\n }\n \n-// index uses sessions to assign users a random color and keep track of views.\n+// [END getting_started_sessions_main]\n+\n+// [START getting_started_sessions_handler]\n+\n+// index uses sessions to assign users a random greeting and keep track of\n+// views.\n func (a *app) index(w http.ResponseWriter, r *http.Request) {\n \tif r.RequestURI != \"/\" {\n \t\treturn",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4951edf95401aa8cb58c32829127323b1f555c9f"
    },
    {
        "pr_title": "getting-started/sessions: switch to greetings & add regions",
        "pr_number": 991,
        "file_name": "getting-started/sessions/main.go",
        "code_diff": "@@ -91,7 +108,7 @@\nfunc (a *app) index(w http.ResponseWriter, r *http.Request) {\n \t// name is a non-empty identifier for this app's sessions. Set it to\n \t// something descriptive for your app. It is used as the Firestore\n \t// collection name that stores the sessions.\n-\tname := \"color-views\"\n+\tname := \"hello-views\"\n \tsession, err := a.store.Get(r, name)\n \tif err != nil {\n \t\t// Could not get the session. Log an error and continue, saving a new",
        "comments": [],
        "commit_messages": [
            "getting-started/sessions: switch to greetings & add regions"
        ],
        "last_commit_sha": "4951edf95401aa8cb58c32829127323b1f555c9f"
    },
    {
        "pr_title": "getting-started/sessions: switch to greetings & add regions",
        "pr_number": 991,
        "file_name": "getting-started/sessions/main_test.go",
        "code_diff": "@@ -37,7 +37,7 @@\nfunc TestIndex(t *testing.T) {\n \n \ta.index(rr, r)\n \n-\tif got, want := rr.Body.String(), \"Views 1\"; !strings.Contains(got, want) {\n+\tif got, want := rr.Body.String(), \"1 view\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"index first visit got:\\n----\\n%v\\n----\\nWant to contain %q\", got, want)\n \t}",
        "comments": [],
        "commit_messages": [
            "getting-started/sessions: fix tests"
        ],
        "last_commit_sha": "4951edf95401aa8cb58c32829127323b1f555c9f"
    },
    {
        "pr_title": "getting-started/sessions: switch to greetings & add regions",
        "pr_number": 991,
        "file_name": "getting-started/sessions/main_test.go",
        "code_diff": "@@ -49,7 +49,7 @@\nfunc TestIndex(t *testing.T) {\n \n \ta.index(rr, r)\n \n-\tif got, want := rr.Body.String(), \"Views 2\"; !strings.Contains(got, want) {\n+\tif got, want := rr.Body.String(), \"2 views\"; !strings.Contains(got, want) {\n \t\tt.Errorf(\"index second visit got:\\n----\\n%v\\n----\\nWant to contain %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_messages": [
            "getting-started/sessions: fix tests"
        ],
        "last_commit_sha": "4951edf95401aa8cb58c32829127323b1f555c9f"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "spanner/spanner_leaderboard/leaderboard_test.go",
        "code_diff": "@@ -25,8 +25,6 @@\nimport (\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n-\t\"google.golang.org/grpc/codes\"\n-\t\"google.golang.org/grpc/status\"\n )\n \n func TestSample(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "spanner: mark test helper, try to deflake timestamp test"
        ],
        "last_commit_sha": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "spanner/spanner_leaderboard/leaderboard_test.go",
        "code_diff": "@@ -46,7 +44,14 @@\nfunc TestSample(t *testing.T) {\n \tdefer adminClient.Close()\n \tdefer dataClient.Close()\n \n-\tassertContains := func(out string, sub string) {\n+\t// Check for database existance prior to test start and delete, as resources may not have\n+\t// been cleaned up from previous invocations.\n+\tif db, err := adminClient.GetDatabase(ctx, &adminpb.GetDatabaseRequest{Name: dbName}); err == nil {\n+\t\tt.Logf(\"database %s exists in state %s. delete result: %v\", db.GetName(), db.GetState().String(),\n+\t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName}))\n+\t}\n+\n+\tassertContains := func(t *testing.T, out string, sub string) {\n \t\tif !strings.Contains(out, sub) {\n \t\t\tt.Errorf(\"got output %q; want it to contain %q\", out, sub)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "spanner: mark test helper, try to deflake timestamp test"
        ],
        "last_commit_sha": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -23,9 +23,8 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n-\tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n-\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\tadminpb \"google.golang.org/genproto/googleapis/spanner/admin/database/v1\"\n )\n \n func TestSample(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "spanner: mark test helper, try to deflake timestamp test"
        ],
        "last_commit_sha": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -52,7 +51,8 @@\nfunc TestSample(t *testing.T) {\n \t\t\tadminClient.DropDatabase(ctx, &adminpb.DropDatabaseRequest{Database: dbName}))\n \t}\n \n-\tassertContains := func(out string, sub string) {\n+\tassertContains := func(t *testing.T, out string, sub string) {\n+\t\tt.Helper()\n \t\tif !strings.Contains(out, sub) {\n \t\t\tt.Errorf(\"got output %q; want it to contain %q\", out, sub)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "spanner: mark test helper, try to deflake timestamp test"
        ],
        "last_commit_sha": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "spanner: mark test helper, try to deflake timestamp test",
        "pr_number": 990,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -93,46 +93,46 @@\nfunc TestSample(t *testing.T) {\n \trunCommand(t, \"write\", dbName)\n \trunCommand(t, \"update\", dbName)\n \tout := runCommand(t, \"dmlwritetxn\", dbName)\n-\tassertContains(out, \"Moved 200000 from Album2's MarketingBudget to Album1\")\n+\tassertContains(t, out, \"Moved 200000 from Album2's MarketingBudget to Album1\")\n \tout = runCommand(t, \"querynewcolumn\", dbName)\n-\tassertContains(out, \"1 1 300000\")\n-\tassertContains(out, \"2 2 300000\")\n+\tassertContains(t, out, \"1 1 300000\")\n+\tassertContains(t, out, \"2 2 300000\")\n \n \trunCommand(t, \"delete\", dbName)\n \trunCommand(t, \"write\", dbName)\n \trunCommand(t, \"update\", dbName)\n \tout = runCommand(t, \"writetransaction\", dbName)\n-\tassertContains(out, \"Moved 200000 from Album2's MarketingBudget to Album1\")\n+\tassertContains(t, out, \"Moved 200000 from Album2's MarketingBudget to Album1\")\n \tout = runCommand(t, \"querynewcolumn\", dbName)\n-\tassertContains(out, \"1 1 300000\")\n-\tassertContains(out, \"2 2 300000\")\n+\tassertContains(t, out, \"1 1 300000\")\n+\tassertContains(t, out, \"2 2 300000\")\n \n \trunCommand(t, \"delete\", dbName)\n \trunCommand(t, \"write\", dbName)\n \twriteTime := time.Now()\n \n-\tassertContains(runCommand(t, \"read\", dbName), \"1 1 Total Junk\")\n+\tassertContains(t, runCommand(t, \"read\", dbName), \"1 1 Total Junk\")\n \n-\tassertContains(runCommand(t, \"query\", dbName), \"1 1 Total Junk\")\n+\tassertContains(t, runCommand(t, \"query\", dbName), \"1 1 Total Junk\")\n \n \trunCommand(t, \"addindex\", dbName)\n \tout = runCommand(t, \"queryindex\", dbName)\n-\tassertContains(out, \"Go, Go, Go\")\n-\tassertContains(out, \"Forever Hold Your Peace\")\n+\tassertContains(t, out, \"Go, Go, Go\")\n+\tassertContains(t, out, \"Forever Hold Your Peace\")\n \tif strings.Contains(out, \"Green\") {\n \t\tt.Errorf(\"got output %q; should not contain Green\", out)\n \t}\n \n \tout = runCommand(t, \"readindex\", dbName)\n-\tassertContains(out, \"Go, Go, Go\")\n-\tassertContains(out, \"Forever Hold Your Peace\")\n-\tassertContains(out, \"Green\")\n+\tassertContains(t, out, \"Go, Go, Go\")\n+\tassertContains(t, out, \"Forever Hold Your Peace\")\n+\tassertContains(t, out, \"Green\")\n \n \trunCommand(t, \"delete\", dbName)\n \trunCommand(t, \"write\", dbName)\n \trunCommand(t, \"update\", dbName)\n \trunCommand(t, \"addstoringindex\", dbName)\n-\tassertContains(runCommand(t, \"readstoringindex\", dbName), \"500000\")\n+\tassertContains(t, runCommand(t, \"readstoringindex\", dbName), \"500000\")\n \tout = runCommand(t, \"readonlytransaction\", dbName)\n \tif strings.Count(out, \"Total Junk\") != 2 {\n \t\tt.Errorf(\"got output %q; wanted it to contain 2 occurrences of Total Junk\", out)",
        "comments": [],
        "commit_messages": [
            "spanner: mark test helper, try to deflake timestamp test"
        ],
        "last_commit_sha": "682a36c9973399f182f4ce7307db1d80fa653463"
    },
    {
        "pr_title": "testing: include region tags in XML test output",
        "pr_number": 985,
        "file_name": "regiontag_test.go",
        "code_diff": "@@ -18,11 +18,13 @@\nimport (\n \t\"bufio\"\n \t\"log\"\n \t\"os/exec\"\n-\t\"strings\"\n+\t\"regexp\"\n \t\"sync\"\n \t\"testing\"\n )\n \n+var startRe = regexp.MustCompile(\"\\\\[START ([[:word:]]+)\\\\]\")\n+\n func listPackages() <-chan string {\n \tc := make(chan string)\n \tgo func() {",
        "comments": [],
        "commit_messages": [
            "regiontag_test: use START regex"
        ],
        "last_commit_sha": "e851fce82b7f0d9ca65a622f33da0c0def471ce3"
    },
    {
        "pr_title": "profiler: remove the docdemo sample, merge it with hotapp",
        "pr_number": 983,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -37,6 +37,8 @@\nvar (\n \tversion = flag.String(\"version\", \"1.0.0\", \"service version\")\n \t// Skew of foo1 function over foo2, in the CPU busyloop, to simulate diff.\n \tskew = flag.Int(\"skew\", 100, \"skew of foo2 over foo1: foo2 will consume skew/100 CPU time compared to foo1 (default is no skew)\")\n+\t// Whether to run some local CPU work to increase the self metric.\n+\tlocalWork = flag.Bool(\"local_work\", false, \"whether to run some local CPU work\")\n \t// There are several goroutines continuously fighting for this mutex.\n \tmu sync.Mutex\n \t// Some allocated memory. Held in a global variable to protect it from GC.",
        "comments": [],
        "commit_messages": [
            "Remove the docdemo sample, merge it with hotapp.\n\nAdd a flag to hotapp sample to run some local work to make the flame\ngraph more interesting, thus allowing to use it as a doc sample.\n\nTested with command:\n\ngo run main.go -project_id oval-time-515 -service aalexand-test -version 1.0.0 -local_work"
        ],
        "last_commit_sha": "d6798df2bf4c40b6aa735741c53d92cb23031d50"
    },
    {
        "pr_title": "profiler: remove the docdemo sample, merge it with hotapp",
        "pr_number": 983,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -98,6 +100,10 @@\nfunc allocMany() {\n // Simulates a CPU-intensive computation.\n func busyloop() {\n \tfor {\n+\t\tif *localWork {\n+\t\t\tfor i := 0; i < 100*(1<<16); i++ {\n+\t\t\t}\n+\t\t}\n \t\tfoo1(100)\n \t\tfoo2(*skew)\n \t\t// Yield so that some preemption happens.",
        "comments": [],
        "commit_messages": [
            "Remove the docdemo sample, merge it with hotapp.\n\nAdd a flag to hotapp sample to run some local work to make the flame\ngraph more interesting, thus allowing to use it as a doc sample.\n\nTested with command:\n\ngo run main.go -project_id oval-time-515 -service aalexand-test -version 1.0.0 -local_work"
        ],
        "last_commit_sha": "d6798df2bf4c40b6aa735741c53d92cb23031d50"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/quickstart/quickstart.go",
        "code_diff": "@@ -12,7 +12,9 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// dlp_quickstart is a basic example of using the Data Loss Prevention API.\n+// [START dlp_quickstart]\n+\n+// The quickstart program is an example of using the Data Loss Prevention API.\n package main\n \n import (",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -20,7 +20,6 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/deid/deid_fpe.go",
        "code_diff": "@@ -32,10 +31,10 @@\nimport (\n // optional identifier needed for reidentification. surrogateInfoType can be any\n // value not found in your input.\n // Info types can be found with the infoTypes.list method or on https://cloud.google.com/dlp/docs/infotypes-reference\n-func deidentifyFPE(w io.Writer, projectID, input string, infoTypes []string, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n+func deidentifyFPE(w io.Writer, projectID, input string, infoTypeNames []string, keyFileName, cryptoKeyName, surrogateInfoType string) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 123456789\"\n-\t// infoTypes := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n \t// keyFileName := \"projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME\"\n \t// cryptoKeyName := \"YOUR_ENCRYPTED_AES_256_KEY\"\n \t// surrogateInfoType := \"AGE\"",
        "comments": [],
        "commit_messages": [
            "dlp: infoTypes instead of i"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/deid/mask.go",
        "code_diff": "@@ -26,10 +26,10 @@\nimport (\n \n // mask deidentifies the input by masking all provided info types with maskingCharacter\n // and prints the result to w.\n-func mask(w io.Writer, projectID, input string, infoTypes []string, maskingCharacter string, numberToMask int32) error {\n+func mask(w io.Writer, projectID, input string, infoTypeNames []string, maskingCharacter string, numberToMask int32) error {\n \t// projectID := \"my-project-id\"\n \t// input := \"My SSN is 111222333\"\n-\t// infoTypes := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n \t// maskingCharacter := \"+\"\n \t// numberToMask := 6\n \t// Will print \"My SSN is ++++++333\"",
        "comments": [],
        "commit_messages": [
            "dlp: infoTypes instead of i"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/deid/reid_fpe.go",
        "code_diff": "@@ -20,7 +20,6 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -16,12 +16,162 @@\npackage inspect\n \n import (\n \t\"bytes\"\n+\t\"context\"\n \t\"strings\"\n \t\"testing\"\n \n+\t\"cloud.google.com/go/bigquery\"\n+\t\"cloud.google.com/go/datastore\"\n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n+const (\n+\ttopicName        = \"dlp-inspect-test-topic\"\n+\tsubscriptionName = \"dlp-inspect-test-sub\"\n+\n+\tssnFileName             = \"fake_ssn.txt\"\n+\tnothingEventfulFileName = \"nothing_eventful.txt\"\n+\tbucketName              = \"golang-samples-dlp-test\"\n+)\n+\n+func TestInspectDatastore(t *testing.T) {\n+\ttc := testutil.EndToEndTest(t)\n+\twriteTestDatastoreFiles(t, tc.ProjectID)\n+\ttests := []struct {\n+\t\tkind string\n+\t\twant string\n+\t}{\n+\t\t{\n+\t\t\tkind: \"SSNTask\",\n+\t\t\twant: \"US_SOCIAL_SECURITY_NUMBER\",\n+\t\t},\n+\t\t{\n+\t\t\tkind: \"BoringTask\",\n+\t\t\twant: \"No results\",\n+\t\t},\n+\t}\n+\tfor _, test := range tests {\n+\t\tt.Run(test.kind, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectDatastore(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, tc.ProjectID, \"\", test.kind)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+type SSNTask struct {\n+\tDescription string\n+}\n+\n+type BoringTask struct {\n+\tDescription string\n+}\n+\n+func writeTestDatastoreFiles(t *testing.T, projectID string) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := datastore.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"datastore.NewClient: %v\", err)\n+\t}\n+\tkind := \"SSNTask\"\n+\tname := \"ssntask1\"\n+\tssnKey := datastore.NameKey(kind, name, nil)\n+\ttask := SSNTask{\n+\t\tDescription: \"My SSN is 111222333\",\n+\t}\n+\tif _, err := client.Put(ctx, ssnKey, &task); err != nil {\n+\t\tt.Fatalf(\"Failed to save task: %v\", err)\n+\t}\n+\n+\tkind = \"BoringTask\"\n+\tname = \"boringtask1\"\n+\tboringKey := datastore.NameKey(kind, name, nil)\n+\tboringTask := BoringTask{\n+\t\tDescription: \"Nothing meaningful\",\n+\t}\n+\tif _, err := client.Put(ctx, boringKey, &boringTask); err != nil {\n+\t\tt.Fatalf(\"Failed to save task: %v\", err)\n+\t}\n+}\n+\n+func TestInspectGCS(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\twriteTestGCSFiles(t, tc.ProjectID)\n+\ttests := []struct {\n+\t\tfileName string\n+\t\twant     string\n+\t}{\n+\t\t{\n+\t\t\tfileName: ssnFileName,\n+\t\t\twant:     \"US_SOCIAL_SECURITY_NUMBER\",\n+\t\t},\n+\t\t{\n+\t\t\tfileName: nothingEventfulFileName,\n+\t\t\twant:     \"No results\",\n+\t\t},\n+\t}\n+\tfor _, test := range tests {\n+\t\tt.Run(test.fileName, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tbuf := new(bytes.Buffer)\n+\t\t\tinspectGCSFile(buf, tc.ProjectID, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, topicName, subscriptionName, bucketName, test.fileName)\n+\t\t\tif got := buf.String(); !strings.Contains(got, test.want) {\n+\t\t\t\tt.Errorf(\"inspectGCSFile(%s) = %q, want %q substring\", test.fileName, got, test.want)\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+func writeTestGCSFiles(t *testing.T, projectID string) {\n+\tt.Helper()\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n+\t}\n+\tbucket := client.Bucket(bucketName)\n+\t_, err = bucket.Attrs(ctx)\n+\tif err != nil {\n+\t\tswitch err {\n+\t\tcase storage.ErrObjectNotExist:\n+\t\t\tif err := bucket.Create(ctx, projectID, nil); err != nil {\n+\t\t\t\tt.Fatalf(\"bucket.Create: %v\", err)\n+\t\t\t}\n+\t\tdefault:\n+\t\t\tt.Fatalf(\"error getting bucket attrs: %v\", err)\n+\t\t}\n+\t}\n+\tif err := writeObject(ctx, bucket, ssnFileName, \"My SSN is 111222333\"); err != nil {\n+\t\tt.Fatalf(\"writeObject: %v\", err)\n+\t}\n+\tif err := writeObject(ctx, bucket, nothingEventfulFileName, \"Nothing eventful\"); err != nil {\n+\t\tt.Fatalf(\"writeObject: %v\", err)\n+\t}\n+}\n+\n+func writeObject(ctx context.Context, bucket *storage.BucketHandle, fileName, content string) error {\n+\tobj := bucket.Object(fileName)\n+\t_, err := obj.Attrs(ctx)\n+\tif err != nil {\n+\t\tswitch err {\n+\t\tcase storage.ErrObjectNotExist:\n+\t\t\tw := obj.NewWriter(ctx)\n+\t\t\tw.Write([]byte(content))\n+\t\t\tif err := w.Close(); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\tdefault:\n+\t\t\treturn err\n+\t\t}\n+\t}\n+\treturn nil\n+}\n+\n func TestInspectString(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/inspect/inspect_test.go",
        "code_diff": "@@ -32,7 +182,7 @@\nfunc TestInspectString(t *testing.T) {\n \n \tgot := buf.String()\n \tif want := \"Info type: EMAIL_ADDRESS\"; !strings.Contains(got, want) {\n-\t\tt.Errorf(\"got %q, want %q\", got, want)\n+\t\tt.Errorf(\"inspectString got %q, want %q\", got, want)\n \t}\n }",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -19,13 +19,9 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n-\t\"io\"\n-\t\"io/ioutil\"\n-\t\"log\"\n \t\"regexp\"\n \t\"strings\"\n \t\"testing\"\n-\t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \t\"cloud.google.com/go/pubsub\"",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -64,25 +60,18 @@\nfunc setupPubSub(projectID, topic, sub string) (*pubsub.Subscription, error) {\n }\n \n // riskNumerical computes the numerical risk of the given column.\n-func riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datasetID, tableID, columnName string) error {\n-\t// projectID := \"my-project-id\"\n-\t// dataProject := \"bigquery-public-data\"\n-\t// pubSubTopic := \"dlp-risk-sample-topic\"\n-\t// pubSubSub := \"dlp-risk-sample-sub\"\n-\t// datasetID := \"nhtsa_traffic_fatalities\"\n-\t// tableID := \"accident_2015\"\n-\t// columnName := \"state_number\"\n+func riskNumerical(projectID, dataProject, pubSubTopic, pubSubSub, datasetID, tableID, columnName string) error {\n \tctx := context.Background()\n \tclient, err := dlp.NewClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -128,11 +117,10 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}\n-\tfmt.Fprintf(w, \"Created job: %v\\n\", j.GetName())\n \n \t// Wait for the risk job to finish by waiting for a PubSub message.\n \tctx, cancel := context.WithCancel(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -143,22 +131,6 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t\treturn\n \t\t}\n \t\tmsg.Ack()\n-\t\ttime.Sleep(500 * time.Millisecond)\n-\t\tresp, err := client.GetDlpJob(ctx, &dlppb.GetDlpJobRequest{\n-\t\t\tName: j.GetName(),\n-\t\t})\n-\t\tif err != nil {\n-\t\t\tlog.Fatalf(\"GetDlpJob: %v\", err)\n-\t\t}\n-\t\tn := resp.GetRiskDetails().GetNumericalStatsResult()\n-\t\tfmt.Fprintf(w, \"Value range: [%v, %v]\\n\", n.GetMinValue(), n.GetMaxValue())\n-\t\tvar tmp string\n-\t\tfor p, v := range n.GetQuantileValues() {\n-\t\t\tif v.String() != tmp {\n-\t\t\t\tfmt.Fprintf(w, \"Value at %v quantile: %v\\n\", p, v)\n-\t\t\t\ttmp = v.String()\n-\t\t\t}\n-\t\t}\n \t\t// Stop listening for more messages.\n \t\tcancel()\n \t})",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/jobs/jobs_test.go",
        "code_diff": "@@ -175,7 +147,7 @@\nfunc TestListJobs(t *testing.T) {\n \ts := buf.String()\n \tif len(s) == 0 {\n \t\t// Create job.\n-\t\triskNumerical(ioutil.Discard, tc.ProjectID, \"bigquery-public-data\", \"risk-topic\", \"risk-sub\", \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n+\t\triskNumerical(tc.ProjectID, \"bigquery-public-data\", \"risk-topic\", \"risk-sub\", \"nhtsa_traffic_fatalities\", \"accident_2015\", \"state_number\")\n \t\tbuf.Reset()\n \t\terr := listJobs(buf, tc.ProjectID, \"\", \"RISK_ANALYSIS_JOB\")\n \t\tif err != nil {",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/redact/redact.go",
        "code_diff": "@@ -12,34 +12,45 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package redact\n \n+// [START dlp_redact_image]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n \t\"io/ioutil\"\n-\t\"log\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )\n \n-// [START dlp_redact_image]\n-\n // redactImage blacks out the identified portions of the input image (with type bytesType)\n // and stores the result in outputPath.\n-func redactImage(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, infoTypes []string, bytesType dlppb.ByteContentItem_BytesType, inputPath, outputPath string) {\n+func redactImage(w io.Writer, projectID string, infoTypeNames []string, bytesType dlppb.ByteContentItem_BytesType, inputPath, outputPath string) error {\n+\t// projectID := \"my-project-id\"\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\t// bytesType := dlppb.ByteContentItem_IMAGE_PNG\n+\t// inputPath := /tmp/input\n+\t// outputPath := /tmp/output\n+\n+\tctx := context.Background()\n+\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t}\n+\n \t// Convert the info type strings to a list of InfoTypes.\n-\tvar i []*dlppb.InfoType\n-\tfor _, it := range infoTypes {\n-\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\tvar infoTypes []*dlppb.InfoType\n+\tfor _, it := range infoTypeNames {\n+\t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n \n \t// Convert the info type strings to a list of types to redact in the image.\n-\tvar ir []*dlppb.RedactImageRequest_ImageRedactionConfig\n-\tfor _, it := range infoTypes {\n-\t\tir = append(ir, &dlppb.RedactImageRequest_ImageRedactionConfig{\n+\tvar redactInfoTypes []*dlppb.RedactImageRequest_ImageRedactionConfig\n+\tfor _, it := range infoTypeNames {\n+\t\tredactInfoTypes = append(redactInfoTypes, &dlppb.RedactImageRequest_ImageRedactionConfig{\n \t\t\tTarget: &dlppb.RedactImageRequest_ImageRedactionConfig_InfoType{\n \t\t\t\tInfoType: &dlppb.InfoType{Name: it},\n \t\t\t},",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/redact/redact_test.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package redact\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/redact/redact_test.go",
        "code_diff": "@@ -24,7 +24,7 @@\nimport (\n )\n \n func TestRedactImage(t *testing.T) {\n-\ttestutil.SystemTest(t)\n+\ttc := testutil.SystemTest(t)\n \ttests := []struct {\n \t\tname      string\n \t\tinputPath string",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -42,11 +41,11 @@\nfunc riskCategorical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub\n \t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_messages": [
            "dlp: reuse ctx and s/pClient/pubsubClient/g"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/categorical.go",
        "code_diff": "@@ -92,7 +91,7 @@\nfunc riskCategorical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "dlp: reuse ctx and s/pClient/pubsubClient/g"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/k_anonymity.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"strings\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/k_anonymity.go",
        "code_diff": "@@ -44,11 +43,11 @@\nfunc riskKAnonymity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_messages": [
            "dlp: reuse ctx and s/pClient/pubsubClient/g"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/k_anonymity.go",
        "code_diff": "@@ -98,7 +97,7 @@\nfunc riskKAnonymity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "dlp: reuse ctx and s/pClient/pubsubClient/g"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"strings\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -46,11 +45,11 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_messages": [
            "dlp: reuse ctx and s/pClient/pubsubClient/g"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/k_map.go",
        "code_diff": "@@ -108,7 +107,7 @@\nfunc riskKMap(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub, datas\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "dlp: reuse ctx and s/pClient/pubsubClient/g"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"strings\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -45,11 +44,11 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t}\n \n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_messages": [
            "dlp: reuse ctx and s/pClient/pubsubClient/g"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/l_diversity.go",
        "code_diff": "@@ -102,7 +101,7 @@\nfunc riskLDiversity(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "dlp: reuse ctx and s/pClient/pubsubClient/g"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/numerical.go",
        "code_diff": "@@ -19,7 +19,6 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \t\"time\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/numerical.go",
        "code_diff": "@@ -42,11 +41,11 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n \t}\n \t// Create a PubSub Client used to listen for when the inspect job finishes.\n-\tpClient, err := pubsub.NewClient(ctx, projectID)\n+\tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"Error creating PubSub client: %v\", err)\n \t}\n-\tdefer pClient.Close()\n+\tdefer pubsubClient.Close()\n \n \t// Create a PubSub subscription we can use to listen for messages.\n \ts, err := setupPubSub(projectID, pubSubTopic, pubSubSub)",
        "comments": [],
        "commit_messages": [
            "dlp: reuse ctx and s/pClient/pubsubClient/g"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/risk/numerical.go",
        "code_diff": "@@ -92,7 +91,7 @@\nfunc riskNumerical(w io.Writer, projectID, dataProject, pubSubTopic, pubSubSub,\n \t\t},\n \t}\n \t// Create the risk job.\n-\tj, err := client.CreateDlpJob(context.Background(), req)\n+\tj, err := client.CreateDlpJob(ctx, req)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"CreateDlpJob: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "dlp: reuse ctx and s/pClient/pubsubClient/g"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -12,35 +12,44 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+package trigger\n \n+// [START dlp_create_trigger]\n import (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n-\t\"time\"\n-\n-\t\"github.com/golang/protobuf/ptypes/duration\"\n \n \tdlp \"cloud.google.com/go/dlp/apiv2\"\n-\t\"google.golang.org/api/iterator\"\n+\t\"github.com/golang/protobuf/ptypes/duration\"\n \tdlppb \"google.golang.org/genproto/googleapis/privacy/dlp/v2\"\n )\n \n-// [START dlp_create_trigger]\n-\n // createTrigger creates a trigger with the given configuration.\n-func createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, triggerID, displayName, description, bucketName string, autoPopulateTimespan bool, scanPeriodDays int64, infoTypes []string) {\n+func createTrigger(w io.Writer, projectID string, triggerID, displayName, description, bucketName string, infoTypeNames []string) error {\n+\t// projectID := \"my-project-id\"\n+\t// triggerID := \"my-trigger\"\n+\t// displayName := \"My Trigger\"\n+\t// description := \"My trigger description\"\n+\t// bucketName := \"my-bucket\"\n+\t// infoTypeNames := []string{\"US_SOCIAL_SECURITY_NUMBER\"}\n+\n+\tctx := context.Background()\n+\n+\tclient, err := dlp.NewClient(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"dlp.NewClient: %v\", err)\n+\t}\n+\n \t// Convert the info type strings to a list of InfoTypes.\n-\tvar i []*dlppb.InfoType\n-\tfor _, it := range infoTypes {\n-\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\tvar infoTypes []*dlppb.InfoType\n+\tfor _, it := range infoTypeNames {\n+\t\tinfoTypes = append(infoTypes, &dlppb.InfoType{Name: it})\n \t}\n \n \t// Create a configured request.\n \treq := &dlppb.CreateJobTriggerRequest{\n-\t\tParent:    \"projects/\" + project,\n+\t\tParent:    \"projects/\" + projectID,\n \t\tTriggerId: triggerID,\n \t\tJobTrigger: &dlppb.JobTrigger{\n \t\t\tDisplayName: displayName,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -53,7 +62,7 @@\nfunc createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihoo\n \t\t\t\t\t\tSchedule: &dlppb.Schedule{\n \t\t\t\t\t\t\tOption: &dlppb.Schedule_RecurrencePeriodDuration{\n \t\t\t\t\t\t\t\tRecurrencePeriodDuration: &duration.Duration{\n-\t\t\t\t\t\t\t\t\tSeconds: scanPeriodDays * 60 * 60 * 24, // Days to seconds.\n+\t\t\t\t\t\t\t\t\tSeconds: 10 * 60 * 60 * 24, // 10 days in seconds.\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},",
        "comments": [],
        "commit_messages": [
            "dlp: delete old samples & finish new ones"
        ],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "dlp: delete old samples & finish new ones",
        "pr_number": 972,
        "file_name": "dlp/snippets/trigger/create.go",
        "code_diff": "@@ -64,10 +73,10 @@\nfunc createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihoo\n \t\t\tJob: &dlppb.JobTrigger_InspectJob{\n \t\t\t\tInspectJob: &dlppb.InspectJobConfig{\n \t\t\t\t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\t\t\t\tInfoTypes:     i,\n-\t\t\t\t\t\tMinLikelihood: minLikelihood,\n+\t\t\t\t\t\tInfoTypes:     infoTypes,\n+\t\t\t\t\t\tMinLikelihood: dlppb.Likelihood_POSSIBLE,\n \t\t\t\t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n-\t\t\t\t\t\t\tMaxFindingsPerRequest: maxFindings,\n+\t\t\t\t\t\t\tMaxFindingsPerRequest: 10,\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tStorageConfig: &dlppb.StorageConfig{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "4b9df835dc2858910a2aa97332867238258e802c"
    },
    {
        "pr_title": "run/image-processing: add Image Processing sample",
        "pr_number": 957,
        "file_name": "functions/imagemagick/imagemagick.go",
        "code_diff": "@@ -14,8 +14,8 @@\n// [START functions_imagemagick_setup]\n \n-// Package imagemagick contains an example of using ImageMagick from a Cloud\n-// Function.\n+// Package imagemagick contains an example of using ImageMagick to process a\n+// file uploaded to Cloud Storage.\n package imagemagick\n \n import (",
        "comments": [],
        "commit_messages": [
            "run/image-processing: add Image Processing sample"
        ],
        "last_commit_sha": "de7a012f8fe80bee65442ce4ee9bd8d68d7d133b"
    },
    {
        "pr_title": "run/image-processing: add Image Processing sample",
        "pr_number": 957,
        "file_name": "run/pubsub/main.go",
        "code_diff": "@@ -20,6 +20,7 @@\npackage main\n import (\n \t\"encoding/json\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"",
        "comments": [],
        "commit_messages": [
            "run/pubsub+imageproc: json unmarshalling"
        ],
        "last_commit_sha": "de7a012f8fe80bee65442ce4ee9bd8d68d7d133b"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/db_memory.go",
        "code_diff": "@@ -12,58 +12,61 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package bookshelf\n+package main\n \n import (\n+\t\"context\"\n \t\"errors\"\n \t\"fmt\"\n \t\"sort\"\n+\t\"strconv\"\n \t\"sync\"\n )\n \n-// Ensure memoryDB conforms to the BookDatabase interface.\n var _ BookDatabase = &memoryDB{}\n \n // memoryDB is a simple in-memory persistence layer for books.\n type memoryDB struct {\n \tmu     sync.Mutex\n-\tnextID int64           // next ID to assign to a book.\n-\tbooks  map[int64]*Book // maps from Book ID to Book.\n+\tnextID int64            // next ID to assign to a book.\n+\tbooks  map[string]*Book // maps from Book ID to Book.\n }\n \n func newMemoryDB() *memoryDB {\n \treturn &memoryDB{\n-\t\tbooks:  make(map[int64]*Book),\n+\t\tbooks:  make(map[string]*Book),\n \t\tnextID: 1,\n \t}\n }\n \n // Close closes the database.\n-func (db *memoryDB) Close() {\n+func (db *memoryDB) Close(context.Context) error {\n \tdb.mu.Lock()\n \tdefer db.mu.Unlock()\n \n \tdb.books = nil\n+\n+\treturn nil\n }\n \n // GetBook retrieves a book by its ID.\n-func (db *memoryDB) GetBook(id int64) (*Book, error) {\n+func (db *memoryDB) GetBook(_ context.Context, id string) (*Book, error) {\n \tdb.mu.Lock()\n \tdefer db.mu.Unlock()\n \n \tbook, ok := db.books[id]\n \tif !ok {\n-\t\treturn nil, fmt.Errorf(\"memorydb: book not found with ID %d\", id)\n+\t\treturn nil, fmt.Errorf(\"memorydb: book not found with ID %q\", id)\n \t}\n \treturn book, nil\n }\n \n // AddBook saves a given book, assigning it a new ID.\n-func (db *memoryDB) AddBook(b *Book) (id int64, err error) {\n+func (db *memoryDB) AddBook(_ context.Context, b *Book) (id string, err error) {\n \tdb.mu.Lock()\n \tdefer db.mu.Unlock()\n \n-\tb.ID = db.nextID\n+\tb.ID = strconv.FormatInt(db.nextID, 10)\n \tdb.books[b.ID] = b\n \n \tdb.nextID++",
        "comments": [
            {
                "comment": "memoryDB is not used anymore either",
                "position": 28
            },
            {
                "comment": "but maybe it should be (for tests? see comment below)",
                "position": 28
            },
            {
                "comment": "Added to tests - see other comment.",
                "position": 28
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/db_memory.go",
        "code_diff": "@@ -72,25 +75,25 @@\nfunc (db *memoryDB) AddBook(b *Book) (id int64, err error) {\n }\n \n // DeleteBook removes a given book by its ID.\n-func (db *memoryDB) DeleteBook(id int64) error {\n-\tif id == 0 {\n-\t\treturn errors.New(\"memorydb: book with unassigned ID passed into deleteBook\")\n+func (db *memoryDB) DeleteBook(_ context.Context, id string) error {\n+\tif id == \"\" {\n+\t\treturn errors.New(\"memorydb: book with unassigned ID passed into DeleteBook\")\n \t}\n \n \tdb.mu.Lock()\n \tdefer db.mu.Unlock()\n \n \tif _, ok := db.books[id]; !ok {\n-\t\treturn fmt.Errorf(\"memorydb: could not delete book with ID %d, does not exist\", id)\n+\t\treturn fmt.Errorf(\"memorydb: could not delete book with ID %q, does not exist\", id)\n \t}\n \tdelete(db.books, id)\n \treturn nil\n }\n \n // UpdateBook updates the entry for a given book.\n-func (db *memoryDB) UpdateBook(b *Book) error {\n-\tif b.ID == 0 {\n-\t\treturn errors.New(\"memorydb: book with unassigned ID passed into updateBook\")\n+func (db *memoryDB) UpdateBook(_ context.Context, b *Book) error {\n+\tif b.ID == \"\" {\n+\t\treturn errors.New(\"memorydb: book with unassigned ID passed into UpdateBook\")\n \t}\n \n \tdb.mu.Lock()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/db_memory.go",
        "code_diff": "@@ -100,16 +103,8 @@\nfunc (db *memoryDB) UpdateBook(b *Book) error {\n \treturn nil\n }\n \n-// booksByTitle implements sort.Interface, ordering books by Title.\n-// https://golang.org/pkg/sort/#example__sortWrapper\n-type booksByTitle []*Book\n-\n-func (s booksByTitle) Less(i, j int) bool { return s[i].Title < s[j].Title }\n-func (s booksByTitle) Len() int           { return len(s) }\n-func (s booksByTitle) Swap(i, j int)      { s[i], s[j] = s[j], s[i] }\n-\n // ListBooks returns a list of books, ordered by title.\n-func (db *memoryDB) ListBooks() ([]*Book, error) {\n+func (db *memoryDB) ListBooks(_ context.Context) ([]*Book, error) {\n \tdb.mu.Lock()\n \tdefer db.mu.Unlock()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/db_test.go",
        "code_diff": "@@ -12,54 +12,55 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package bookshelf\n+package main\n \n import (\n \t\"context\"\n \t\"fmt\"\n \t\"os\"\n-\t\"strconv\"\n \t\"testing\"\n \t\"time\"\n \n-\t\"cloud.google.com/go/datastore\"\n-\n-\t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"cloud.google.com/go/firestore\"\n )\n \n func testDB(t *testing.T, db BookDatabase) {\n-\tdefer db.Close()\n+\tt.Helper()\n+\n+\tctx := context.Background()\n+\n+\tdefer db.Close(ctx)\n \n \tb := &Book{\n \t\tAuthor:      \"testy mc testface\",\n \t\tTitle:       fmt.Sprintf(\"t-%d\", time.Now().Unix()),\n \t\tDescription: \"desc\",\n \t}\n \n-\tid, err := db.AddBook(b)\n+\tid, err := db.AddBook(ctx, b)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n \n \tb.ID = id\n \tb.Description = \"newdesc\"\n-\tif err := db.UpdateBook(b); err != nil {\n+\tif err := db.UpdateBook(ctx, b); err != nil {\n \t\tt.Error(err)\n \t}\n \n-\tgotBook, err := db.GetBook(id)\n+\tgotBook, err := db.GetBook(ctx, id)\n \tif err != nil {\n \t\tt.Error(err)\n \t}\n \tif got, want := gotBook.Description, b.Description; got != want {\n \t\tt.Errorf(\"Update description: got %q, want %q\", got, want)\n \t}\n \n-\tif err := db.DeleteBook(id); err != nil {\n+\tif err := db.DeleteBook(ctx, id); err != nil {\n \t\tt.Error(err)\n \t}\n \n-\tif _, err := db.GetBook(id); err == nil {\n+\tif _, err := db.GetBook(ctx, id); err == nil {\n \t\tt.Error(\"want non-nil err\")\n \t}\n }",
        "comments": [],
        "commit_messages": [
            "getting-started/bookshelf: initial rewrite\n\n* Switch to GAE Standard (go112).\n* Close() returns an error.\n* Booskshelf methods take a context.\n* Remove Datastore and replace it with Firestore.\n* Remove auth/login.\n* Remove databases other than Firestore and Memory.\n* Remove GCE and GKE deployments.\n* Add a go.mod and go.sum.\n* Move webtest into this directory to avoid depending on golang-samples.\n* Move all Go code into a root directory package main.\n* Make handlers methods on Bookshelf, rather than standalone functions.\n* Always initialize storage (see config.go) and give runtime error on\n  image upload.\n* Firestore doc IDs stored as part of the Book in Firestore, rather than\n  assigned during editing and listing."
        ],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -12,34 +12,31 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// Sample bookshelf is a fully-featured app demonstrating several Google Cloud APIs, including Datastore, Cloud SQL, Cloud Storage.\n-// See https://cloud.google.com/go/getting-started/tutorial-app\n+// The bookshelf command starts the bookshelf server, a sample app\n+// demonstrating several Google Cloud APIs, including App Engine, Firestore, and\n+// Cloud Storage.\n+// See https://cloud.google.com/go/getting-started/tutorial-app.\n package main\n \n import (\n \t\"context\"\n-\t\"encoding/json\"\n \t\"errors\"\n \t\"fmt\"\n \t\"io\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"\n \t\"path\"\n-\t\"strconv\"\n \n-\t\"cloud.google.com/go/pubsub\"\n+\t\"cloud.google.com/go/firestore\"\n \t\"cloud.google.com/go/storage\"\n-\n-\tuuid \"github.com/gofrs/uuid\"\n+\t\"github.com/gofrs/uuid\"\n \t\"github.com/gorilla/handlers\"\n \t\"github.com/gorilla/mux\"\n-\n-\t\"github.com/GoogleCloudPlatform/golang-samples/getting-started/bookshelf\"\n )\n \n var (\n-\t// See template.go\n+\t// See template.go.\n \tlistTmpl   = parseTemplate(\"list.html\")\n \teditTmpl   = parseTemplate(\"edit.html\")\n \tdetailTmpl = parseTemplate(\"detail.html\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -50,43 +47,55 @@\nfunc main() {\n \tif port == \"\" {\n \t\tport = \"8080\"\n \t}\n-\tregisterHandlers()\n+\tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n+\tif projectID == \"\" {\n+\t\tlog.Fatal(\"GOOGLE_CLOUD_PROJECT must be set\")\n+\t}\n+\n+\tctx := context.Background()\n+\n+\tclient, err := firestore.NewClient(ctx, projectID)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"firestore.NewClient: %v\", err)\n+\t}\n+\tdb, err := newFirestoreDB(client)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"newFirestoreDB: %v\", err)\n+\t}\n+\n+\tshelf, err := NewBookshelf(projectID, db)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"NewBookshelf: %v\", err)\n+\t}\n+\n+\tshelf.registerHandlers()\n+\n+\tlog.Printf(\"Listening on localhost:%s\", port)\n \tlog.Fatal(http.ListenAndServe(fmt.Sprintf(\":%s\", port), nil))\n }\n \n-func registerHandlers() {\n+func (b *Bookshelf) registerHandlers() {\n \t// Use gorilla/mux for rich routing.\n-\t// See http://www.gorillatoolkit.org/pkg/mux\n+\t// See https://www.gorillatoolkit.org/pkg/mux.\n \tr := mux.NewRouter()\n \n \tr.Handle(\"/\", http.RedirectHandler(\"/books\", http.StatusFound))\n \n \tr.Methods(\"GET\").Path(\"/books\").\n-\t\tHandler(appHandler(listHandler))\n-\tr.Methods(\"GET\").Path(\"/books/mine\").\n-\t\tHandler(appHandler(listMineHandler))\n-\tr.Methods(\"GET\").Path(\"/books/{id:[0-9]+}\").\n-\t\tHandler(appHandler(detailHandler))\n+\t\tHandler(appHandler(b.listHandler))\n \tr.Methods(\"GET\").Path(\"/books/add\").\n-\t\tHandler(appHandler(addFormHandler))\n-\tr.Methods(\"GET\").Path(\"/books/{id:[0-9]+}/edit\").\n-\t\tHandler(appHandler(editFormHandler))\n+\t\tHandler(appHandler(b.addFormHandler))\n+\tr.Methods(\"GET\").Path(\"/books/{id:[0-9a-zA-Z]+}\").\n+\t\tHandler(appHandler(b.detailHandler))\n+\tr.Methods(\"GET\").Path(\"/books/{id:[0-9a-zA-Z]+}/edit\").\n+\t\tHandler(appHandler(b.editFormHandler))\n \n \tr.Methods(\"POST\").Path(\"/books\").\n-\t\tHandler(appHandler(createHandler))\n-\tr.Methods(\"POST\", \"PUT\").Path(\"/books/{id:[0-9]+}\").\n-\t\tHandler(appHandler(updateHandler))\n-\tr.Methods(\"POST\").Path(\"/books/{id:[0-9]+}:delete\").\n-\t\tHandler(appHandler(deleteHandler)).Name(\"delete\")\n-\n-\t// The following handlers are defined in auth.go and used in the\n-\t// \"Authenticating Users\" part of the Getting Started guide.\n-\tr.Methods(\"GET\").Path(\"/login\").\n-\t\tHandler(appHandler(loginHandler))\n-\tr.Methods(\"POST\").Path(\"/logout\").\n-\t\tHandler(appHandler(logoutHandler))\n-\tr.Methods(\"GET\").Path(\"/oauth2callback\").\n-\t\tHandler(appHandler(oauthCallbackHandler))\n+\t\tHandler(appHandler(b.createHandler))\n+\tr.Methods(\"POST\", \"PUT\").Path(\"/books/{id:[0-9a-zA-Z]+}\").\n+\t\tHandler(appHandler(b.updateHandler))\n+\tr.Methods(\"POST\").Path(\"/books/{id:[0-9a-zA-Z]+}:delete\").\n+\t\tHandler(appHandler(b.deleteHandler)).Name(\"delete\")\n \n \t// Respond to App Engine and Compute Engine health checks.\n \t// Indicate the server is healthy.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -98,30 +107,14 @@\nfunc registerHandlers() {\n \t// [START request_logging]\n \t// Delegate all of the HTTP routing and serving to the gorilla/mux router.\n \t// Log all requests using the standard Apache format.\n-\thttp.Handle(\"/\", handlers.CombinedLoggingHandler(os.Stderr, r))\n+\thttp.Handle(\"/\", handlers.CombinedLoggingHandler(b.logWriter, r))\n \t// [END request_logging]\n }\n \n // listHandler displays a list with summaries of books in the database.\n-func listHandler(w http.ResponseWriter, r *http.Request) *appError {\n-\tbooks, err := bookshelf.DB.ListBooks()\n-\tif err != nil {\n-\t\treturn appErrorf(err, \"could not list books: %v\", err)\n-\t}\n-\n-\treturn listTmpl.Execute(w, r, books)\n-}\n-\n-// listMineHandler displays a list of books created by the currently\n-// authenticated user.\n-func listMineHandler(w http.ResponseWriter, r *http.Request) *appError {\n-\tuser := profileFromSession(r)\n-\tif user == nil {\n-\t\thttp.Redirect(w, r, \"/login?redirect=/books/mine\", http.StatusFound)\n-\t\treturn nil\n-\t}\n-\n-\tbooks, err := bookshelf.DB.ListBooksCreatedBy(user.ID)\n+func (b *Bookshelf) listHandler(w http.ResponseWriter, r *http.Request) *appError {\n+\tctx := r.Context()\n+\tbooks, err := b.DB.ListBooks(ctx)\n \tif err != nil {\n \t\treturn appErrorf(err, \"could not list books: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -131,21 +124,22 @@\nfunc listMineHandler(w http.ResponseWriter, r *http.Request) *appError {\n \n // bookFromRequest retrieves a book from the database given a book ID in the\n // URL's path.\n-func bookFromRequest(r *http.Request) (*bookshelf.Book, error) {\n-\tid, err := strconv.ParseInt(mux.Vars(r)[\"id\"], 10, 64)\n-\tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"bad book id: %v\", err)\n+func (b *Bookshelf) bookFromRequest(r *http.Request) (*Book, error) {\n+\tctx := r.Context()\n+\tid := mux.Vars(r)[\"id\"]\n+\tif id == \"\" {\n+\t\treturn nil, errors.New(\"no book with empty ID\")\n \t}\n-\tbook, err := bookshelf.DB.GetBook(id)\n+\tbook, err := b.DB.GetBook(ctx, id)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"could not find book: %v\", err)\n \t}\n \treturn book, nil\n }\n \n // detailHandler displays the details of a given book.\n-func detailHandler(w http.ResponseWriter, r *http.Request) *appError {\n-\tbook, err := bookFromRequest(r)\n+func (b *Bookshelf) detailHandler(w http.ResponseWriter, r *http.Request) *appError {\n+\tbook, err := b.bookFromRequest(r)\n \tif err != nil {\n \t\treturn appErrorf(err, \"%v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -155,14 +149,14 @@\nfunc detailHandler(w http.ResponseWriter, r *http.Request) *appError {\n \n // addFormHandler displays a form that captures details of a new book to add to\n // the database.\n-func addFormHandler(w http.ResponseWriter, r *http.Request) *appError {\n+func (b *Bookshelf) addFormHandler(w http.ResponseWriter, r *http.Request) *appError {\n \treturn editTmpl.Execute(w, r, nil)\n }\n \n // editFormHandler displays a form that allows the user to edit the details of\n // a given book.\n-func editFormHandler(w http.ResponseWriter, r *http.Request) *appError {\n-\tbook, err := bookFromRequest(r)\n+func (b *Bookshelf) editFormHandler(w http.ResponseWriter, r *http.Request) *appError {\n+\tbook, err := b.bookFromRequest(r)\n \tif err != nil {\n \t\treturn appErrorf(err, \"%v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "getting-started/bookshelf: initial rewrite\n\n* Switch to GAE Standard (go112).\n* Close() returns an error.\n* Booskshelf methods take a context.\n* Remove Datastore and replace it with Firestore.\n* Remove auth/login.\n* Remove databases other than Firestore and Memory.\n* Remove GCE and GKE deployments.\n* Add a go.mod and go.sum.\n* Move webtest into this directory to avoid depending on golang-samples.\n* Move all Go code into a root directory package main.\n* Make handlers methods on Bookshelf, rather than standalone functions.\n* Always initialize storage (see config.go) and give runtime error on\n  image upload.\n* Firestore doc IDs stored as part of the Book in Firestore, rather than\n  assigned during editing and listing."
        ],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -172,44 +166,29 @@\nfunc editFormHandler(w http.ResponseWriter, r *http.Request) *appError {\n \n // bookFromForm populates the fields of a Book from form values\n // (see templates/edit.html).\n-func bookFromForm(r *http.Request) (*bookshelf.Book, error) {\n-\timageURL, err := uploadFileFromForm(r)\n+func (b *Bookshelf) bookFromForm(r *http.Request) (*Book, error) {\n+\tctx := r.Context()\n+\timageURL, err := b.uploadFileFromForm(ctx, r)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"could not upload file: %v\", err)\n \t}\n \tif imageURL == \"\" {\n \t\timageURL = r.FormValue(\"imageURL\")\n \t}\n \n-\tbook := &bookshelf.Book{\n+\tbook := &Book{\n \t\tTitle:         r.FormValue(\"title\"),\n \t\tAuthor:        r.FormValue(\"author\"),\n \t\tPublishedDate: r.FormValue(\"publishedDate\"),\n \t\tImageURL:      imageURL,\n \t\tDescription:   r.FormValue(\"description\"),\n-\t\tCreatedBy:     r.FormValue(\"createdBy\"),\n-\t\tCreatedByID:   r.FormValue(\"createdByID\"),\n-\t}\n-\n-\t// If the form didn't carry the user information for the creator, populate it\n-\t// from the currently logged in user (or mark as anonymous).\n-\tif book.CreatedByID == \"\" {\n-\t\tuser := profileFromSession(r)\n-\t\tif user != nil {\n-\t\t\t// Logged in.\n-\t\t\tbook.CreatedBy = user.DisplayName\n-\t\t\tbook.CreatedByID = user.ID\n-\t\t} else {\n-\t\t\t// Not logged in.\n-\t\t\tbook.SetCreatorAnonymous()\n-\t\t}\n \t}\n \n \treturn book, nil\n }\n \n // uploadFileFromForm uploads a file if it's present in the \"image\" form field.\n-func uploadFileFromForm(r *http.Request) (url string, err error) {\n+func (b *Bookshelf) uploadFileFromForm(ctx context.Context, r *http.Request) (url string, err error) {\n \tf, fh, err := r.FormFile(\"image\")\n \tif err == http.ErrMissingFile {\n \t\treturn \"\", nil",
        "comments": [
            {
                "comment": "valid if empty string?",
                "position": 168
            },
            {
                "comment": "No. Good catch. Checked.",
                "position": 168
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -218,15 +197,20 @@\nfunc uploadFileFromForm(r *http.Request) (url string, err error) {\n \t\treturn \"\", err\n \t}\n \n-\tif bookshelf.StorageBucket == nil {\n-\t\treturn \"\", errors.New(\"storage bucket is missing - check config.go\")\n+\tif b.StorageBucket == nil {\n+\t\treturn \"\", errors.New(\"storage bucket is missing: check config.go\")\n+\t}\n+\tif _, err := b.StorageBucket.Attrs(ctx); err != nil {\n+\t\tif err == storage.ErrBucketNotExist {\n+\t\t\treturn \"\", fmt.Errorf(\"bucket %q does not exist: check config.go\", b.StorageBucketName)\n+\t\t}\n+\t\treturn \"\", fmt.Errorf(\"could not get bucket: %v\", err)\n \t}\n \n \t// random filename, retaining existing extension.\n \tname := uuid.Must(uuid.NewV4()).String() + path.Ext(fh.Filename)\n \n-\tctx := context.Background()\n-\tw := bookshelf.StorageBucket.Object(name).NewWriter(ctx)\n+\tw := b.StorageBucket.Object(name).NewWriter(ctx)\n \n \t// Warning: storage.AllUsers gives public read access to anyone.\n \tw.ACL = []storage.ACLRule{{Entity: storage.AllUsers, Role: storage.RoleReader}}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/main.go",
        "code_diff": "@@ -243,79 +227,56 @@\nfunc uploadFileFromForm(r *http.Request) (url string, err error) {\n \t}\n \n \tconst publicURL = \"https://storage.googleapis.com/%s/%s\"\n-\treturn fmt.Sprintf(publicURL, bookshelf.StorageBucketName, name), nil\n+\treturn fmt.Sprintf(publicURL, b.StorageBucketName, name), nil\n }\n \n // createHandler adds a book to the database.\n-func createHandler(w http.ResponseWriter, r *http.Request) *appError {\n-\tbook, err := bookFromForm(r)\n+func (b *Bookshelf) createHandler(w http.ResponseWriter, r *http.Request) *appError {\n+\tctx := r.Context()\n+\tbook, err := b.bookFromForm(r)\n \tif err != nil {\n \t\treturn appErrorf(err, \"could not parse book from form: %v\", err)\n \t}\n-\tid, err := bookshelf.DB.AddBook(book)\n+\tid, err := b.DB.AddBook(ctx, book)\n \tif err != nil {\n \t\treturn appErrorf(err, \"could not save book: %v\", err)\n \t}\n-\tgo publishUpdate(id)\n-\thttp.Redirect(w, r, fmt.Sprintf(\"/books/%d\", id), http.StatusFound)\n+\thttp.Redirect(w, r, fmt.Sprintf(\"/books/%s\", id), http.StatusFound)\n \treturn nil\n }\n \n // updateHandler updates the details of a given book.\n-func updateHandler(w http.ResponseWriter, r *http.Request) *appError {\n-\tid, err := strconv.ParseInt(mux.Vars(r)[\"id\"], 10, 64)\n-\tif err != nil {\n-\t\treturn appErrorf(err, \"bad book id: %v\", err)\n+func (b *Bookshelf) updateHandler(w http.ResponseWriter, r *http.Request) *appError {\n+\tctx := r.Context()\n+\tid := mux.Vars(r)[\"id\"]\n+\tif id == \"\" {\n+\t\treturn appErrorf(errors.New(\"no book with empty ID\"), \"no book with empty ID\")\n \t}\n-\n-\tbook, err := bookFromForm(r)\n+\tbook, err := b.bookFromForm(r)\n \tif err != nil {\n \t\treturn appErrorf(err, \"could not parse book from form: %v\", err)\n \t}\n \tbook.ID = id\n \n-\terr = bookshelf.DB.UpdateBook(book)\n-\tif err != nil {\n-\t\treturn appErrorf(err, \"could not save book: %v\", err)\n+\tif err := b.DB.UpdateBook(ctx, book); err != nil {\n+\t\treturn appErrorf(err, \"UpdateBook: %v\", err)\n \t}\n-\tgo publishUpdate(book.ID)\n-\thttp.Redirect(w, r, fmt.Sprintf(\"/books/%d\", book.ID), http.StatusFound)\n+\thttp.Redirect(w, r, fmt.Sprintf(\"/books/%s\", book.ID), http.StatusFound)\n \treturn nil\n }\n \n // deleteHandler deletes a given book.\n-func deleteHandler(w http.ResponseWriter, r *http.Request) *appError {\n-\tid, err := strconv.ParseInt(mux.Vars(r)[\"id\"], 10, 64)\n-\tif err != nil {\n-\t\treturn appErrorf(err, \"bad book id: %v\", err)\n-\t}\n-\terr = bookshelf.DB.DeleteBook(id)\n-\tif err != nil {\n-\t\treturn appErrorf(err, \"could not delete book: %v\", err)\n+func (b *Bookshelf) deleteHandler(w http.ResponseWriter, r *http.Request) *appError {\n+\tctx := r.Context()\n+\tid := mux.Vars(r)[\"id\"]\n+\tif err := b.DB.DeleteBook(ctx, id); err != nil {\n+\t\treturn appErrorf(err, \"DeleteBook: %v\", err)\n \t}\n \thttp.Redirect(w, r, \"/books\", http.StatusFound)\n \treturn nil\n }\n \n-// publishUpdate notifies Pub/Sub subscribers that the book identified with\n-// the given ID has been added/modified.\n-func publishUpdate(bookID int64) {\n-\tif bookshelf.PubsubClient == nil {\n-\t\treturn\n-\t}\n-\n-\tctx := context.Background()\n-\n-\tb, err := json.Marshal(bookID)\n-\tif err != nil {\n-\t\treturn\n-\t}\n-\ttopic := bookshelf.PubsubClient.Topic(bookshelf.PubsubTopicID)\n-\t_, err = topic.Publish(ctx, &pubsub.Message{Data: b}).Get(ctx)\n-\tlog.Printf(\"Published update to Pub/Sub for Book ID %d: %v\", bookID, err)\n-}\n-\n-// http://blog.golang.org/error-handling-and-go\n+// https://blog.golang.org/error-handling-and-go\n type appHandler func(http.ResponseWriter, *http.Request) *appError\n \n type appError struct {",
        "comments": [
            {
                "comment": "check empty ID here too",
                "position": 316
            },
            {
                "comment": "Done.",
                "position": 316
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "getting-started/bookshelf: initial rewrite",
        "pr_number": 951,
        "file_name": "getting-started/bookshelf/template.go",
        "code_diff": "@@ -20,8 +20,6 @@\nimport (\n \t\"io/ioutil\"\n \t\"net/http\"\n \t\"path/filepath\"\n-\n-\t\"github.com/GoogleCloudPlatform/golang-samples/getting-started/bookshelf\"\n )\n \n // parseTemplate applies a given file to the body of the base template.",
        "comments": [],
        "commit_messages": [
            "getting-started/bookshelf: initial rewrite\n\n* Switch to GAE Standard (go112).\n* Close() returns an error.\n* Booskshelf methods take a context.\n* Remove Datastore and replace it with Firestore.\n* Remove auth/login.\n* Remove databases other than Firestore and Memory.\n* Remove GCE and GKE deployments.\n* Add a go.mod and go.sum.\n* Move webtest into this directory to avoid depending on golang-samples.\n* Move all Go code into a root directory package main.\n* Make handlers methods on Bookshelf, rather than standalone functions.\n* Always initialize storage (see config.go) and give runtime error on\n  image upload.\n* Firestore doc IDs stored as part of the Book in Firestore, rather than\n  assigned during editing and listing."
        ],
        "last_commit_sha": "cc1059a6bc923dd0745cc4c5e853f140f5f6d011"
    },
    {
        "pr_title": "healthcare: add DICOMweb methods and tests",
        "pr_number": 946,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -18,13 +18,26 @@\nimport (\n \t\"bytes\"\n \t\"fmt\"\n \t\"io/ioutil\"\n+\t\"os\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n+// The studyUID, seriesUID, and instanceUID are hard-coded into\n+// the metadata of the DICOM file and make up the DicomWebPath\n+// in the requests to retrieve studies/instances/frames/rendered.\n+const (\n+\tstudyUID           = \"studies/1.3.6.1.4.1.11129.5.5.111396399361969898205364400549799252857604/\"\n+\tseriesUID          = \"series/1.3.6.1.4.1.11129.5.5.195628213694300498946760767481291263511724/\"\n+\tinstanceUID        = \"instances/1.3.6.1.4.1.11129.5.5.153751009835107614666834563294684339746480/\"\n+\tstudyOutputFile    = \"study.multipart\"\n+\tinstanceOutputFile = \"instance.dcm\"\n+\trenderedOutputFile = \"rendered_image.png\"\n+)\n+\n // TestDICOMStore runs all DICOM store tests to avoid having to\n // create/delete DICOM stores for every sample function that needs to be\n // tested.",
        "comments": [],
        "commit_messages": [
            "healthcare: add DICOMweb methods and tests"
        ],
        "last_commit_sha": "f6abd5dfca6d0bd5df4dacda64f0c6980bece3c8"
    },
    {
        "pr_title": "healthcare: add DICOMweb methods and tests",
        "pr_number": 946,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -74,7 +87,7 @@\nfunc TestDICOMStore(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n-\t\tif err := dicomWebStoreInstance(ioutil.Discard, tc.ProjectID, location, datasetID, dicomStoreID, \"studies/1.3.6.1.4.1.11129.5.5.111396399361969898205364400549799252857604\", \"./testdata/dicom_00000001_000.dcm\"); err != nil {\n+\t\tif err := dicomWebStoreInstance(ioutil.Discard, tc.ProjectID, location, datasetID, dicomStoreID, studyUID, \"./testdata/dicom_00000001_000.dcm\"); err != nil {\n \t\t\tr.Errorf(\"dicomStoreInstance got err: %v\", err)\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [
            "healthcare: add DICOMweb methods and tests"
        ],
        "last_commit_sha": "f6abd5dfca6d0bd5df4dacda64f0c6980bece3c8"
    },
    {
        "pr_title": "healthcare: add DICOMweb methods and tests",
        "pr_number": 946,
        "file_name": "healthcare/dicomweb_study_retrieve.go",
        "code_diff": "@@ -19,14 +19,20 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \t\"io\"\n-\t\"io/ioutil\"\n+\t\"os\"\n \n \thealthcare \"google.golang.org/api/healthcare/v1beta1\"\n )\n \n // dicomWebRetrieveStudy retrieves all instances in the given dicomWebPath\n // study.\n-func dicomWebRetrieveStudy(w io.Writer, projectID, location, datasetID, dicomStoreID, dicomWebPath string) error {\n+func dicomWebRetrieveStudy(w io.Writer, projectID, location, datasetID, dicomStoreID, dicomWebPath string, outputFile string) error {\n+\t// projectID := \"my-project\"\n+\t// location := \"us-central1\"\n+\t// datasetID := \"my-dataset\"\n+\t// dicomStoreID := \"my-dicom-store\"\n+\t// dicomWebPath := \"studies/1.3.6.1.4.1.11129.5.5.111396399857604\"\n+\t// outputFile := \"study.multipart\"\n \tctx := context.Background()\n \n \thealthcareService, err := healthcare.NewService(ctx)",
        "comments": [
            {
                "comment": "Probably good to check the status code?",
                "position": 40
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "f6abd5dfca6d0bd5df4dacda64f0c6980bece3c8"
    },
    {
        "pr_title": "pubsub: add missing samples for concurrency control and sync pull",
        "pr_number": 938,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -19,6 +19,8 @@\npackage subscriptions\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"fmt\"\n+\t\"strings\"\n \t\"sync\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6f0e3036cb0290df2f2f57ba9ddaeb1dca33af68"
    },
    {
        "pr_title": "pubsub: canonize Go samples",
        "pr_number": 937,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -12,9 +12,12 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+// package subscriptions is a tool to manage Google Cloud Pub/Sub subscriptions by using the Pub/Sub API.\n+// See more about Google Cloud Pub/Sub at https://cloud.google.com/pubsub/docs/overview.\n+package subscriptions\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"sync\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "37f1e34688d082d511cdc1b8e876aa68f6ba2b3c"
    },
    {
        "pr_title": "pubsub: canonize Go samples",
        "pr_number": 937,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -26,79 +29,85 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-var topic *pubsub.Topic\n-var subID string\n+var topicName string\n+var subName string\n \n-var once sync.Once // guards cleanup related operations in setup.\n+// once guards cleanup related operations in setup. No need to set up and tear\n+// down every time, so this speeds things up.\n+var once sync.Once\n \n func setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n+\ttopicName = tc.ProjectID + \"-test-sub-topic\"\n+\tsubName = tc.ProjectID + \"-test-sub\"\n+\tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n \n-\tsubID = tc.ProjectID + \"-test-sub\"\n-\ttopicID := tc.ProjectID + \"-test-sub-topic\"\n-\n-\t// Cleanup resources from the previous failed tests.\n+\t// Cleanup resources from the previous tests.\n \tonce.Do(func() {\n-\t\t// Create a topic.\n-\t\ttopic = client.Topic(topicID)\n+\t\ttopic := client.Topic(topicName)\n \t\tok, err := topic.Exists(ctx)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t\t}\n-\t\tif !ok {\n-\t\t\tif topic, err = client.CreateTopic(ctx, topicID); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to create the topic: %v\", err)\n+\t\tif ok {\n+\t\t\tif err := topic.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicName, err)\n \t\t\t}\n \t\t}\n-\n-\t\t// Delete the sub if already exists.\n-\t\tsub := client.Subscription(subID)\n+\t\tsub := client.Subscription(subName)\n \t\tok, err = sub.Exists(ctx)\n \t\tif err != nil {\n-\t\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n+\t\t\tt.Fatalf(\"failed to check if subscription exists: %v\", err)\n \t\t}\n \t\tif ok {\n-\t\t\tif err := client.Subscription(subID).Delete(ctx); err != nil {\n-\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", subID, err)\n+\t\t\tif err := sub.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the subscription (%q): %v\", subName, err)\n \t\t\t}\n \t\t}\n \t})\n+\n \treturn client\n }\n \n func TestCreate(t *testing.T) {\n-\tc := setup(t)\n-\n-\tif err := create(c, subID, topic); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\ttopic, err := client.CreateTopic(ctx, topicName)\n+\tif err != nil {\n+\t\tt.Fatalf(\"CreateTopic: %v\", err)\n+\t}\n+\tbuf := new(bytes.Buffer)\n+\tif err := create(buf, tc.ProjectID, subName, topic); err != nil {\n \t\tt.Fatalf(\"failed to create a subscription: %v\", err)\n \t}\n-\tok, err := c.Subscription(subID).Exists(context.Background())\n+\tok, err := client.Subscription(subName).Exists(context.Background())\n \tif err != nil {\n \t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n \t}\n \tif !ok {\n-\t\tt.Fatalf(\"got none; want sub = %q\", subID)\n+\t\tt.Fatalf(\"got none; want sub = %q\", subName)\n \t}\n }\n \n func TestList(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tsubs, err := list(c)\n+\t\tsubs, err := list(tc.ProjectID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"failed to list subscriptions: %v\", err)\n \t\t\treturn\n \t\t}\n \n \t\tfor _, sub := range subs {\n-\t\t\tif sub.ID() == subID {\n+\t\t\tif sub.ID() == subName {\n \t\t\t\treturn // PASS\n \t\t\t}\n \t\t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "37f1e34688d082d511cdc1b8e876aa68f6ba2b3c"
    },
    {
        "pr_title": "pubsub: canonize Go samples",
        "pr_number": 937,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -107,15 +116,16 @@\nfunc TestList(t *testing.T) {\n \t\tfor i, sub := range subs {\n \t\t\tsubNames[i] = sub.ID()\n \t\t}\n-\t\tr.Errorf(\"got %+v; want a list with subscription %q\", subNames, subID)\n+\t\tr.Errorf(\"got %+v; want a list with subscription %q\", subNames, subName)\n \t})\n }\n \n func TestIAM(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tperms, err := testPermissions(c, subID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tperms, err := testPermissions(buf, tc.ProjectID, subName)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"testPermissions: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "37f1e34688d082d511cdc1b8e876aa68f6ba2b3c"
    },
    {
        "pr_title": "pubsub: canonize Go samples",
        "pr_number": 937,
        "file_name": "pubsub/subscriptions/subscription_test.go",
        "code_diff": "@@ -125,15 +135,16 @@\nfunc TestIAM(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := addUsers(c, subID); err != nil {\n+\t\tif err := addUsers(tc.ProjectID, subName); err != nil {\n \t\t\tr.Errorf(\"addUsers: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tpolicy, err := getPolicy(c, subID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tpolicy, err := policy(buf, tc.ProjectID, subName)\n \t\tif err != nil {\n-\t\t\tr.Errorf(\"getPolicy: %v\", err)\n+\t\t\tr.Errorf(\"policy: %v\", err)\n \t\t}\n \t\tif role, member := iam.Editor, \"group:cloud-logs@google.com\"; !policy.HasRole(member, role) {\n \t\t\tr.Errorf(\"want %q as viewer, policy=%v\", member, policy)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "37f1e34688d082d511cdc1b8e876aa68f6ba2b3c"
    },
    {
        "pr_title": "pubsub: canonize Go samples",
        "pr_number": 937,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -12,9 +12,12 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-package main\n+// Package topics is a tool to manage Google Cloud Pub/Sub topics by using the Pub/Sub API.\n+// See more about Google Cloud Pub/Sub at https://cloud.google.com/pubsub/docs/overview.package topics\n+package topics\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"sync\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "37f1e34688d082d511cdc1b8e876aa68f6ba2b3c"
    },
    {
        "pr_title": "pubsub: canonize Go samples",
        "pr_number": 937,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -25,63 +28,67 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n-var topicID string\n+var topicName string\n \n-var once sync.Once // guards cleanup related operations in setup.\n+// once guards cleanup related operations in setup. No need to set up and tear\n+// down every time, so this speeds things up.\n+var once sync.Once\n \n func setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()\n \ttc := testutil.SystemTest(t)\n \n-\ttopicID = tc.ProjectID + \"-test-topic\"\n-\n+\ttopicName = tc.ProjectID + \"-test-topic\"\n+\tvar err error\n \tclient, err := pubsub.NewClient(ctx, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n \n-\t// Cleanup resources from the previous failed tests.\n+\t// Cleanup resources from the previous tests.\n \tonce.Do(func() {\n-\t\ttopic := client.Topic(topicID)\n+\t\ttopic := client.Topic(topicName)\n \t\tok, err := topic.Exists(ctx)\n \t\tif err != nil {\n \t\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t\t}\n-\t\tif !ok {\n-\t\t\treturn\n-\t\t}\n-\t\tif err := topic.Delete(ctx); err != nil {\n-\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicID, err)\n+\t\tif ok {\n+\t\t\tif err := topic.Delete(ctx); err != nil {\n+\t\t\t\tt.Fatalf(\"failed to cleanup the topic (%q): %v\", topicName, err)\n+\t\t\t}\n \t\t}\n \t})\n+\n \treturn client\n }\n \n func TestCreate(t *testing.T) {\n-\tc := setup(t)\n-\tif err := create(c, topicID); err != nil {\n+\tclient := setup(t)\n+\ttc := testutil.SystemTest(t)\n+\tbuf := new(bytes.Buffer)\n+\tif err := create(buf, tc.ProjectID, topicName); err != nil {\n \t\tt.Fatalf(\"failed to create a topic: %v\", err)\n \t}\n-\tok, err := c.Topic(topicID).Exists(context.Background())\n+\tok, err := client.Topic(topicName).Exists(context.Background())\n \tif err != nil {\n-\t\tt.Fatalf(\"failed to check if sub exists: %v\", err)\n+\t\tt.Fatalf(\"failed to check if topic exists: %v\", err)\n \t}\n \tif !ok {\n-\t\tt.Fatalf(\"got none; want topic = %q\", topicID)\n+\t\tt.Fatalf(\"got none; want topic = %q\", topicName)\n \t}\n }\n \n func TestList(t *testing.T) {\n-\tc := setup(t)\n+\ttc := testutil.SystemTest(t)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\ttopics, err := list(c)\n+\t\ttopics, err := list(tc.ProjectID)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"failed to list topics: %v\", err)\n \t\t}\n \n \t\tfor _, t := range topics {\n-\t\t\tif t.ID() == topicID {\n+\t\t\tif t.ID() == topicName {\n \t\t\t\treturn // PASS\n \t\t\t}\n \t\t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "37f1e34688d082d511cdc1b8e876aa68f6ba2b3c"
    },
    {
        "pr_title": "pubsub: canonize Go samples",
        "pr_number": 937,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -90,38 +97,56 @@\nfunc TestList(t *testing.T) {\n \t\tfor i, t := range topics {\n \t\t\ttopicNames[i] = t.ID()\n \t\t}\n-\t\tr.Errorf(\"got %+v; want a list with topic = %q\", topicNames, topicID)\n+\t\tr.Errorf(\"got %+v; want a list with topic = %q\", topicNames, topicName)\n \t})\n }\n \n func TestPublish(t *testing.T) {\n \t// Nothing much to do here, unless we are consuming.\n \t// TODO(jbd): Merge topics and subscriptions programs maybe?\n-\tc := setup(t)\n-\tif err := publish(c, topicID, \"hello world\"); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publish(buf, tc.ProjectID, topicName, \"hello world\"); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestPublishThatScales(t *testing.T) {\n-\tc := setup(t)\n-\tif err := publishThatScales(c, topicID, 10); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tsetup(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publishThatScales(buf, tc.ProjectID, topicName, 10); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestPublishCustomAttributes(t *testing.T) {\n-\tc := setup(t)\n-\tif err := publishCustomAttributes(c, topicID); err != nil {\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tsetup(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n+\tbuf := new(bytes.Buffer)\n+\tif err := publishCustomAttributes(buf, tc.ProjectID, topicName); err != nil {\n \t\tt.Errorf(\"failed to publish message: %v\", err)\n \t}\n }\n \n func TestIAM(t *testing.T) {\n-\tc := setup(t)\n+\tctx := context.Background()\n+\ttc := testutil.SystemTest(t)\n+\tclient := setup(t)\n+\tclient.CreateTopic(ctx, topicName)\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tperms, err := testPermissions(c, topicID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tperms, err := testPermissions(buf, tc.ProjectID, topicName)\n \t\tif err != nil {\n \t\t\tr.Errorf(\"testPermissions: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "37f1e34688d082d511cdc1b8e876aa68f6ba2b3c"
    },
    {
        "pr_title": "pubsub: canonize Go samples",
        "pr_number": 937,
        "file_name": "pubsub/topics/topics_test.go",
        "code_diff": "@@ -131,15 +156,16 @@\nfunc TestIAM(t *testing.T) {\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tif err := addUsers(c, topicID); err != nil {\n+\t\tif err := addUsers(tc.ProjectID, topicName); err != nil {\n \t\t\tr.Errorf(\"addUsers: %v\", err)\n \t\t}\n \t})\n \n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n-\t\tpolicy, err := getPolicy(c, topicID)\n+\t\tbuf := new(bytes.Buffer)\n+\t\tpolicy, err := policy(buf, tc.ProjectID, topicName)\n \t\tif err != nil {\n-\t\t\tr.Errorf(\"getPolicy: %v\", err)\n+\t\t\tr.Errorf(\"policy: %v\", err)\n \t\t}\n \t\tif role, member := iam.Editor, \"group:cloud-logs@google.com\"; !policy.HasRole(member, role) {\n \t\t\tr.Errorf(\"want %q as viewer, policy=%v\", member, policy)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "37f1e34688d082d511cdc1b8e876aa68f6ba2b3c"
    },
    {
        "pr_title": "kms: canonize Go samples",
        "pr_number": 936,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -12,6 +12,8 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// Package kms contains samples for asymmetric keys feature of Cloud Key Management Service\n+// https://cloud.google.com/kms/\n package kms\n \n import (",
        "comments": [],
        "commit_messages": [
            "Canonize Go KMS samples"
        ],
        "last_commit_sha": "813160f00791aac3405add96cd206a0e3e32cc53"
    },
    {
        "pr_title": "kms: canonize Go samples",
        "pr_number": 936,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -67,7 +69,7 @@\nfunc getTestVariables(projectID string) TestVariables {\n \n \tsym := keyRingPath + \"/cryptoKeys/\" + symID\n \tsymVersion := sym + \"/cryptoKeyVersions/1\"\n-\trsaDecrypt := keyRingPath + \"/cryptoKeys/\" + rsaDecryptID + \"/cryptoKeyVersions/2\"\n+\trsaDecryptPath := keyRingPath + \"/cryptoKeys/\" + rsaDecryptID + \"/cryptoKeyVersions/2\"\n \trsaSign := keyRingPath + \"/cryptoKeys/\" + rsaSignID + \"/cryptoKeyVersions/1\"\n \tecSign := keyRingPath + \"/cryptoKeys/\" + ecSignID + \"/cryptoKeyVersions/1\"",
        "comments": [],
        "commit_messages": [
            "PR fixes: function comments, param examples"
        ],
        "last_commit_sha": "813160f00791aac3405add96cd206a0e3e32cc53"
    },
    {
        "pr_title": "bigquery: alter retry strategy for storage sample, improve output.",
        "pr_number": 935,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -165,8 +165,10 @@\nfunc printDatum(d interface{}) {\n \t// Go's map implementation returns keys in a random ordering, so we sort\n \t// the keys before accessing.\n \tkeys := make([]string, len(m))\n+\ti := 0\n \tfor k := range m {\n-\t\tkeys = append(keys, k)\n+\t\tkeys[i] = k\n+\t\ti++\n \t}\n \tsort.Strings(keys)\n \tfor _, key := range keys {",
        "comments": [],
        "commit_messages": [
            "bigquery: alter retry strategy for storage sample, improve output."
        ],
        "last_commit_sha": "d84d1f499efc51140483689c3910c8bc4246f3d8"
    },
    {
        "pr_title": "bigquery: alter retry strategy for storage sample, improve output.",
        "pr_number": 935,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -197,9 +199,13 @@\nfunc valueFromTypeMap(field interface{}) interface{} {\n // successfully transmitted.\n func processStream(ctx context.Context, client *bqStorage.BigQueryStorageClient, st *bqStoragepb.Stream, ch chan<- *bqStoragepb.AvroRows) error {\n \tvar offset int64\n-\tstreamRetry := 3\n+\n+\t// Streams may be long-running.  Rather than using a global retry for the\n+\t// stream, implement a retry that resets once progress is made.\n+\tretryLimit := 3\n \n \tfor {\n+\t\tretries := 0\n \t\t// Send the initiating request to start streaming row blocks.\n \t\trowStream, err := client.ReadRows(ctx, &bqStoragepb.ReadRowsRequest{\n \t\t\tReadPosition: &bqStoragepb.StreamPosition{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d84d1f499efc51140483689c3910c8bc4246f3d8"
    },
    {
        "pr_title": "bigquery: alter retry strategy for storage sample, improve output.",
        "pr_number": 935,
        "file_name": "bigquery/bigquery_storage_quickstart/main.go",
        "code_diff": "@@ -217,8 +223,8 @@\nfunc processStream(ctx context.Context, client *bqStorage.BigQueryStorageClient,\n \t\t\t\treturn nil\n \t\t\t}\n \t\t\tif err != nil {\n-\t\t\t\tstreamRetry--\n-\t\t\t\tif streamRetry <= 0 {\n+\t\t\t\tretries++\n+\t\t\t\tif retries >= retryLimit {\n \t\t\t\t\treturn fmt.Errorf(\"processStream retries exhausted: %v\", err)\n \t\t\t\t}\n \t\t\t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d84d1f499efc51140483689c3910c8bc4246f3d8"
    },
    {
        "pr_title": "[Storage] Bucket metadata samples",
        "pr_number": 929,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -15,11 +15,13 @@\npackage main\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"os\"\n+\t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c743cc874e76246902f9f02d9c12529cce8dada6"
    },
    {
        "pr_title": "functions: Adds sample functions_helloworld_error_test",
        "pr_number": 928,
        "file_name": "functions/tips/error.go",
        "code_diff": "@@ -12,11 +12,11 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n+// [START functions_helloworld_error]\n+\n package tips\n \n import (\n-\t\"context\"\n-\t\"errors\"\n \t\"fmt\"\n \t\"net/http\"\n \t\"os\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "789f6e733aeefedf0d311bf084ca1821dd56583a"
    },
    {
        "pr_title": "getting-started/gopher-run: final changes",
        "pr_number": 925,
        "file_name": "getting-started/gopher-run/cmd/main.go",
        "code_diff": "@@ -24,7 +24,6 @@\nimport (\n \t\"log\"\n \t\"net/http\"\n \t\"os\"\n-\t\"os/exec\"\n \n \t\"cloud.google.com/go/firestore\"\n \t\"cloud.google.com/go/storage\"",
        "comments": [],
        "commit_messages": [
            "getting-started/gopher-run: final changes before con",
            "getting-started/gopher-run: final changes before con",
            "getting-started/gopher-run: final changes before con"
        ],
        "last_commit_sha": "8fa6f9fcae34d3fd343ba623e0380a353b543372"
    },
    {
        "pr_title": "getting-started/gopher-run: final changes",
        "pr_number": 925,
        "file_name": "getting-started/gopher-run/cmd/main.go",
        "code_diff": "@@ -59,7 +58,6 @@\nfunc main() {\n \thttp.HandleFunc(\"/pldata\", a.addPlayData)\n \thttp.HandleFunc(\"/bggenerator\", a.sendGeneratedBackground)\n \thttp.Handle(\"/\", http.StripPrefix(\"/\", http.FileServer(http.Dir(\"static/gorun/\"))))\n-\t// a.submitTrainingJob(context.Background())\n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {\n \t\tport = \"8080\"",
        "comments": [],
        "commit_messages": [
            "getting-started/gopher-run: final changes before con",
            "getting-started/gopher-run: final changes before con",
            "getting-started/gopher-run: final changes before con"
        ],
        "last_commit_sha": "8fa6f9fcae34d3fd343ba623e0380a353b543372"
    },
    {
        "pr_title": "getting-started/gopher-run: final changes",
        "pr_number": 925,
        "file_name": "getting-started/gopher-run/cmd/main.go",
        "code_diff": "@@ -114,34 +112,12 @@\nunroll,0,0,0,0,0,0,0,0,0,0,0`)\n \t\t\tlog.Printf(\"ioutil.ReadAll: %v\", err)\n \t\t\tcontinue\n \t\t}\n+\t\tdata = append(append(data, []byte(\"\\n\")...))\n \t\tdata = append(data, b...)\n \t}\n \tnewObj := bkt.Object(\"pldata.csv\").NewWriter(ctx)\n \tdefer newObj.Close()\n \tnewObj.Write(data)\n-\n-\t// mlService, err := ml.NewService(ctx)\n-\t// if err != nil {\n-\t// \tlog.Printf(\"ml.NewService: %v\", err)\n-\t// }\n-\t// jobsService := mlService.Projects.Jobs\n-\t// job := &ml.GoogleCloudMlV1__Job{\n-\t// \tJobId: \"gotest4\",\n-\t// \tTrainingInput: &ml.GoogleCloudMlV1__TrainingInput{\n-\t// \t\tJobDir:       \"gs://maralder-start-ml/algorithms_training/pldata/\",\n-\t// \t\tPackageUris:  []string{\"gs://maralder-start-ml/xgboost-master.zip\"},\n-\t// \t\tPythonModule: \"python-package/xgboost/core.py\",\n-\t// \t\tRegion:       \"us-central1\",\n-\t// \t\tScaleTier:    \"STANDARD_1\",\n-\t// \t\tArgs:         []string{\"--objective=multi:softmax\", \"--num_class=4\", \"--training_data_path=gs://maralder-start-ml/pldata.csv\"},\n-\t// \t}}\n-\t// resp, err := jobsService.Create(\"projects/\"+\"maralder-start\", job).Do()\n-\t// if err != nil {\n-\t// \tlog.Printf(\"Create: %v\", err)\n-\t// }\n-\t// \"projects/\" + \"maralder-start\" + \"/models/playerdata_linear_classification\",\n-\t// fmt.Println(resp)\n-\texec.Command(\"/bin/sh\", \"cmd/training.sh\").Run()\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8fa6f9fcae34d3fd343ba623e0380a353b543372"
    },
    {
        "pr_title": "getting-started/gopher-run: final changes",
        "pr_number": 925,
        "file_name": "getting-started/gopher-run/generator/generator.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"math/rand\"\n )\n \n+// RequestData is the form in which requests for background generation come in.\n type RequestData struct {\n \tXmin  float64\n \tXmax  float64",
        "comments": [],
        "commit_messages": [
            "getting-started/gopher-run: final changes before con",
            "getting-started/gopher-run: final changes before con",
            "getting-started/gopher-run: final changes before con"
        ],
        "last_commit_sha": "8fa6f9fcae34d3fd343ba623e0380a353b543372"
    },
    {
        "pr_title": "getting-started/gopher-run: final changes",
        "pr_number": 925,
        "file_name": "getting-started/gopher-run/leaderboard/leaderboard.go",
        "code_diff": "@@ -25,8 +25,7 @@\nimport (\n \n // ScoreData is a player's score.\n type ScoreData struct {\n-\tName string `json:\"name\"`\n-\t// ID       string  `json:\"id\"`\n+\tName     string  `json:\"name\"`\n \tTeam     string  `json:\"team\"`\n \tCoins    int     `json:\"coins\"`\n \tDistance float32 `json:\"distance\"`",
        "comments": [],
        "commit_messages": [
            "getting-started/gopher-run: final changes before con",
            "getting-started/gopher-run: final changes before con",
            "getting-started/gopher-run: final changes before con"
        ],
        "last_commit_sha": "8fa6f9fcae34d3fd343ba623e0380a353b543372"
    },
    {
        "pr_title": "getting-started/gopher-run: final changes",
        "pr_number": 925,
        "file_name": "getting-started/gopher-run/leaderboard/leaderboard.go",
        "code_diff": "@@ -54,20 +53,22 @@\nfunc TopScores(ctx context.Context, client *firestore.Client) ([]ScoreData, erro\n \treturn top, nil\n }\n \n-// AddScore adds a score to the leaderboard if it's in the top 10, or the scores database otherwise.\n-func AddScore(ctx context.Context, client *firestore.Client, d ScoreData) error {\n+// AddScore adds a score to the leaderboard database and returns information about whether it updated an existing score.\n+func AddScore(ctx context.Context, client *firestore.Client, d ScoreData) (string, error) {\n \tvar oldD ScoreData\n \titer := client.Collection(\"leaderboard\").Query.Limit(1).Where(\"name\", \"==\", d.Name).Documents(ctx)\n \tdoc, err := iter.Next()\n \tif err != iterator.Done && err != nil {\n-\t\treturn fmt.Errorf(\"iter.Next: %v\", err)\n+\t\treturn \"\", fmt.Errorf(\"iter.Next: %v\", err)\n \t}\n \tif err != iterator.Done {\n \t\tif err = doc.DataTo(&oldD); err != nil {\n-\t\t\treturn fmt.Errorf(\"doc.DataTo: %v\", err)\n+\t\t\treturn \"\", fmt.Errorf(\"doc.DataTo: %v\", err)\n \t\t}\n \t}\n+\ts := \"\"\n \tif oldD.Coins < d.Coins {\n+\t\ts = \"pb\"\n \t\t_, err := client.Collection(\"leaderboard\").Doc(d.Name).Set(ctx, map[string]interface{}{\n \t\t\t\"name\":     d.Name,\n \t\t\t\"team\":     d.Team,",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8fa6f9fcae34d3fd343ba623e0380a353b543372"
    },
    {
        "pr_title": "getting-started/gopher-run: add AI automation and background generation",
        "pr_number": 910,
        "file_name": "getting-started/gopher-run/cmd/main.go",
        "code_diff": "@@ -19,15 +19,25 @@\nimport (\n \t\"context\"\n \t\"encoding/json\"\n \t\"fmt\"\n+\t\"io\"\n+\t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n \t\"os\"\n+\t\"os/exec\"\n \n \t\"cloud.google.com/go/firestore\"\n \t\"cloud.google.com/go/storage\"\n+\t\"github.com/GoogleCloudPlatform/golang-samples/getting-started/gopher-run/generator\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/getting-started/gopher-run/leaderboard\"\n+\t\"golang.org/x/oauth2/google\"\n )\n \n+type playData struct {\n+\tName  string `json:\"name\"`\n+\tValue string `json:\"value\"`\n+}\n+\n type app struct {\n \tprojectID string\n \tbucket    *storage.BucketHandle",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "e0afffe2cc04e62a9a5e5b971eb5f4b288d18590"
    },
    {
        "pr_title": "getting-started/gopher-run: add AI automation and background generation",
        "pr_number": 910,
        "file_name": "getting-started/gopher-run/cmd/main.go",
        "code_diff": "@@ -45,15 +55,96 @@\nfunc main() {\n \t}\n \thttp.HandleFunc(\"/leaderboard/post\", a.addScore)\n \thttp.HandleFunc(\"/leaderboard/get\", a.topScores)\n-\thttp.Handle(\"/\", http.StripPrefix(\"/\", http.FileServer(http.Dir(\"static\"))))\n+\thttp.HandleFunc(\"/predict\", a.predictionRequest)\n+\thttp.HandleFunc(\"/pldata\", a.addPlayData)\n+\thttp.HandleFunc(\"/bggenerator\", a.sendGeneratedBackground)\n+\thttp.Handle(\"/\", http.StripPrefix(\"/\", http.FileServer(http.Dir(\"static/gorun/\"))))\n+\t// a.submitTrainingJob(context.Background())\n \tport := os.Getenv(\"PORT\")\n \tif port == \"\" {\n \t\tport = \"8080\"\n \t}\n-\tfmt.Printf(\"Starting server: localhost:%v\\n\", port)\n+\tfmt.Printf(\"Starting server on port %v\\n\", port)\n \tlog.Fatal(http.ListenAndServe(fmt.Sprintf(\":%s\", port), nil))\n }\n \n+func (a *app) predictionRequest(w http.ResponseWriter, r *http.Request) {\n+\tclient, err := google.DefaultClient(r.Context(), \"https://www.googleapis.com/auth/cloud-platform\")\n+\tif err != nil {\n+\t\tlog.Printf(\"DefaultClient: %v\", err)\n+\t}\n+\tresp, err := client.Post(\"https://ml.googleapis.com/v1/projects/\"+a.projectID+\"/models/playerdata_linear_classification:predict\", \"application/json\", r.Body)\n+\tif err != nil {\n+\t\tlog.Printf(\"client.Post: %v\", err)\n+\t\thttp.Error(w, \"Prediction server error\", http.StatusInternalServerError)\n+\t\treturn\n+\t}\n+\tio.Copy(w, resp.Body)\n+\tresp.Body.Close()\n+}\n+\n+// Concatenate data from the top runs and start a Cloud ML training job on it\n+func (a *app) submitTrainingJob(ctx context.Context) error {\n+\tbkt := a.bucket\n+\ttopPlayers, err := leaderboard.TopScores(ctx, a.fsClient)\n+\tif err != nil {\n+\t\tlog.Printf(\"leaderboard.TopScores: %v\", err)\n+\t\treturn err\n+\t}\n+\t// Add dummy data at the beginning for consistency in which actions are assigned numbers 0,1,2,3 for prediction output\n+\tdata := []byte(`idle,0,0,0,0,0,0,0,0,0,0,0\n+roll,0,0,0,0,0,0,0,0,0,0,0\n+jump,0,0,0,0,0,0,0,0,0,0,0\n+unroll,0,0,0,0,0,0,0,0,0,0,0`)\n+\tfor _, player := range topPlayers {\n+\t\tpld, err := bkt.Object(\"pldata/\" + player.Name + \"_pldata.csv\").NewReader(ctx)\n+\t\tif err != nil {\n+\t\t\tlog.Printf(\"NewReader: %v\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\tdefer pld.Close()\n+\t\told, err := bkt.Object(\"pldata.csv\").NewReader(ctx)\n+\t\tif err != nil {\n+\t\t\tlog.Printf(\"NewReader: %v\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\tdefer old.Close()\n+\t\tb, err := ioutil.ReadAll(pld)\n+\t\tif err != nil {\n+\t\t\tlog.Printf(\"ioutil.ReadAll: %v\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\tdata = append(data, b...)\n+\t}\n+\tnewObj := bkt.Object(\"pldata.csv\").NewWriter(ctx)\n+\tdefer newObj.Close()\n+\tnewObj.Write(data)\n+\n+\t// mlService, err := ml.NewService(ctx)\n+\t// if err != nil {\n+\t// \tlog.Printf(\"ml.NewService: %v\", err)\n+\t// }\n+\t// jobsService := mlService.Projects.Jobs\n+\t// job := &ml.GoogleCloudMlV1__Job{\n+\t// \tJobId: \"gotest4\",\n+\t// \tTrainingInput: &ml.GoogleCloudMlV1__TrainingInput{\n+\t// \t\tJobDir:       \"gs://maralder-start-ml/algorithms_training/pldata/\",\n+\t// \t\tPackageUris:  []string{\"gs://maralder-start-ml/xgboost-master.zip\"},\n+\t// \t\tPythonModule: \"python-package/xgboost/core.py\",\n+\t// \t\tRegion:       \"us-central1\",\n+\t// \t\tScaleTier:    \"STANDARD_1\",\n+\t// \t\tArgs:         []string{\"--objective=multi:softmax\", \"--num_class=4\", \"--training_data_path=gs://maralder-start-ml/pldata.csv\"},\n+\t// \t}}\n+\t// resp, err := jobsService.Create(\"projects/\"+\"maralder-start\", job).Do()\n+\t// if err != nil {\n+\t// \tlog.Printf(\"Create: %v\", err)\n+\t// }\n+\t// \"projects/\" + \"maralder-start\" + \"/models/playerdata_linear_classification\",\n+\t// fmt.Println(resp)\n+\texec.Command(\"/bin/sh\", \"cmd/training.sh\").Run()\n+\treturn nil\n+}\n+\n func (a *app) addScore(w http.ResponseWriter, r *http.Request) {\n \tvar d leaderboard.ScoreData\n \tdecoder := json.NewDecoder(r.Body)",
        "comments": [
            {
                "comment": "Would prefer to do this in Go directly -- `gcloud` probably isn't installed on Cloud Run or other environments (haven't checked).",
                "position": 118
            },
            {
                "comment": "Need to remove this call, assuming the above does the same thing.",
                "position": 118
            },
            {
                "comment": "Will fix later",
                "position": 118
            },
            {
                "comment": "Add a comment saying why this is being done.",
                "position": 69
            },
            {
                "comment": "Done",
                "position": 69
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "e0afffe2cc04e62a9a5e5b971eb5f4b288d18590"
    },
    {
        "pr_title": "getting-started/background: split Translate into smaller functions",
        "pr_number": 909,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -12,7 +12,7 @@\n// See the License for the specific language governing permissions and\n // limitations under the License.\n \n-// [START getting_started_background_translate]\n+// [START getting_started_background_translate_setup]\n \n // Package background contains a Cloud Function to translate text.\n // The function listens to Pub/Sub, does the translations, and stores the",
        "comments": [],
        "commit_messages": [
            "getting-started/background: split Translate into smaller functions"
        ],
        "last_commit_sha": "22cda6edcc2d6970427b6c3af2e2752636c4804e"
    },
    {
        "pr_title": "getting-started/background: split Translate into smaller functions",
        "pr_number": 909,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -55,8 +55,13 @@\ntype PubSubMessage struct {\n \tData []byte `json:\"data\"`\n }\n \n-// Translate translates the given message and stores the result in Firestore.\n-func Translate(ctx context.Context, m PubSubMessage) error {\n+// [END getting_started_background_translate_setup]\n+\n+// [START getting_started_background_translate_init]\n+\n+// initializeClients creates translateClient and firestoreClient if they haven't\n+// been created yet.\n+func initializeClients() error {\n \tprojectID := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tif projectID == \"\" {\n \t\treturn fmt.Errorf(\"GOOGLE_CLOUD_PROJECT must be set\")",
        "comments": [
            {
                "comment": "Is this a convention to include the function name in the comment? I'd leave it out:\r\n* You never risk that comment and function name diverge\r\n* Comment is one word shorter without losing any information\r\n* You don't start a comment with a lower case word making for awkward grammer, see comment for `translateString`\r\n\r\n(I might just be used to seeing comments like `Translate the given message` and my brain is trained to associate that with the function below)",
                "position": 62
            },
            {
                "comment": "Yes, it's standard for comments to start with the thing being described. https://github.com/golang/go/wiki/CodeReviewComments#comment-sentences",
                "position": 62
            }
        ],
        "commit_messages": [
            "getting-started/background: split Translate into smaller functions"
        ],
        "last_commit_sha": "22cda6edcc2d6970427b6c3af2e2752636c4804e"
    },
    {
        "pr_title": "getting-started/background: split Translate into smaller functions",
        "pr_number": 909,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -80,6 +85,42 @@\nfunc Translate(ctx context.Context, m PubSubMessage) error {\n \t\t\treturn fmt.Errorf(\"firestore.NewClient: %v\", err)\n \t\t}\n \t}\n+\treturn nil\n+}\n+\n+// [END getting_started_background_translate_init]\n+\n+// [START getting_started_background_translate_string]\n+\n+// translateString translates text to lang, returning:\n+// * the translated text,\n+// * the automatically detected source language, and\n+// * an error.\n+func translateString(ctx context.Context, text string, lang string) (translated string, originalLang string, err error) {\n+\tl, err := language.Parse(lang)\n+\tif err != nil {\n+\t\treturn \"\", \"\", fmt.Errorf(\"language.Parse: %v\", err)\n+\t}\n+\n+\touts, err := translateClient.Translate(ctx, []string{text}, l, nil)\n+\tif err != nil {\n+\t\treturn \"\", \"\", fmt.Errorf(\"Translate: %v\", err)\n+\t}\n+\n+\tif len(outs) < 1 {\n+\t\treturn \"\", \"\", fmt.Errorf(\"Translate got %d translations, need at least 1\", len(outs))\n+\t}\n+\n+\treturn outs[0].Text, outs[0].Source.String(), nil\n+}\n+\n+// [END getting_started_background_translate_string]\n+\n+// [START getting_started_background_translate]\n+\n+// Translate translates the given message and stores the result in Firestore.\n+func Translate(ctx context.Context, m PubSubMessage) error {\n+\tinitializeClients()\n \n \tt := Translation{}\n \tif err := json.Unmarshal(m.Data, &t); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "22cda6edcc2d6970427b6c3af2e2752636c4804e"
    },
    {
        "pr_title": "getting-started/background: split Translate into smaller functions",
        "pr_number": 909,
        "file_name": "getting-started/background/translate.go",
        "code_diff": "@@ -96,6 +137,7 @@\nfunc Translate(ctx context.Context, m PubSubMessage) error {\n \tdocName = strings.Replace(docName, \"/\", \"-\", -1)\n \tref := firestoreClient.Collection(\"translations\").Doc(docName)\n \n+\t// Run in a transation to prevent concurrent duplicate translations.\n \terr := firestoreClient.RunTransaction(ctx, func(ctx context.Context, tx *firestore.Transaction) error {\n \t\tdoc, err := tx.Get(ref)\n \t\tif err != nil && status.Code(err) != codes.NotFound {",
        "comments": [],
        "commit_messages": [
            "getting-started/background: split Translate into smaller functions"
        ],
        "last_commit_sha": "22cda6edcc2d6970427b6c3af2e2752636c4804e"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/dataset/bigquery_create_dataset.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/bigquery\"\n )",
        "comments": [],
        "commit_messages": [
            "address review comments"
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/dataset/bigquery_delete_label_dataset.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/bigquery\"\n )",
        "comments": [],
        "commit_messages": [
            "address review comments"
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/dataset/bigquery_label_dataset.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/bigquery\"\n )",
        "comments": [],
        "commit_messages": [
            "address review comments"
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/dataset/bigquery_update_dataset_access.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/bigquery\"\n )",
        "comments": [],
        "commit_messages": [
            "address review comments"
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/dataset/bigquery_update_dataset_default_expiration.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \t\"time\"\n \n \t\"cloud.google.com/go/bigquery\"",
        "comments": [],
        "commit_messages": [
            "address review comments"
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/dataset/bigquery_update_dataset_description.go",
        "code_diff": "@@ -18,6 +18,7 @@\npackage dataset\n \n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/bigquery\"\n )",
        "comments": [],
        "commit_messages": [
            "address review comments"
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -44,20 +44,17 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_create_table_partitioned]\n \t// [START bigquery_create_view]\n \t// [START bigquery_delete_label_table]\n-\t// [START bigquery_delete_model]\n \t// [START bigquery_delete_table]\n \t// [START bigquery_extract_table]\n \t// [START bigquery_extract_table_compressed]\n \t// [START bigquery_extract_table_json]\n \t// [START bigquery_get_job]\n-\t// [START bigquery_get_model]\n \t// [START bigquery_get_table]\n \t// [START bigquery_get_table_labels]\n \t// [START bigquery_get_view]\n \t// [START bigquery_grant_view_access]\n \t// [START bigquery_label_table]\n \t// [START bigquery_list_jobs]\n-\t// [START bigquery_list_models]\n \t// [START bigquery_list_tables]\n \t// [START bigquery_load_from_file]\n \t// [START bigquery_load_table_clustered]",
        "comments": [],
        "commit_messages": [
            "bigquery/snippets: split out ML model snippets."
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -93,7 +90,6 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_table_insert_rows]\n \t// [START bigquery_undelete_table]\n \t// [START bigquery_update_table_cmek]\n-\t// [START bigquery_update_model_description]\n \t// [START bigquery_update_table_description]\n \t// [START bigquery_update_table_expiration]\n \t// [START bigquery_update_view_query]",
        "comments": [],
        "commit_messages": [
            "bigquery/snippets: split out ML model snippets."
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -116,20 +112,17 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_create_table_partitioned]\n \t// [END bigquery_create_view]\n \t// [END bigquery_delete_label_table]\n-\t// [END bigquery_delete_model]\n \t// [END bigquery_delete_table]\n \t// [END bigquery_extract_table]\n \t// [END bigquery_extract_table_compressed]\n \t// [END bigquery_extract_table_json]\n \t// [END bigquery_get_job]\n-\t// [END bigquery_get_model]\n \t// [END bigquery_get_table]\n \t// [END bigquery_get_table_labels]\n \t// [END bigquery_get_view]\n \t// [END bigquery_grant_view_access]\n \t// [END bigquery_label_table]\n \t// [END bigquery_list_jobs]\n-\t// [END bigquery_list_models]\n \t// [END bigquery_list_tables]\n \t// [END bigquery_load_from_file]\n \t// [END bigquery_load_table_clustered]",
        "comments": [],
        "commit_messages": [
            "bigquery/snippets: split out ML model snippets."
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -164,7 +157,6 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_relax_column_query_append]\n \t// [END bigquery_table_insert_rows]\n \t// [END bigquery_undelete_table]\n-\t// [END bigquery_update_model_description]\n \t// [END bigquery_update_table_cmek]\n \t// [END bigquery_update_table_description]\n \t// [END bigquery_update_table_expiration]",
        "comments": [],
        "commit_messages": [
            "bigquery/snippets: split out ML model snippets."
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -597,24 +589,6 @@\nfunc updateTableChangeCMEK(client *bigquery.Client, datasetID, tableID string) e\n \treturn nil\n }\n \n-func updateModelDescription(client *bigquery.Client, datasetID, modelID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_update_model_description]\n-\tmodel := client.Dataset(datasetID).Model(modelID)\n-\toldMeta, err := model.Metadata(ctx)\n-\tif err != nil {\n-\t\treturn fmt.Errorf(\"Metadata: %v\", err)\n-\t}\n-\tupdate := bigquery.ModelMetadataToUpdate{\n-\t\tDescription: \"This model was modified from a Go program\",\n-\t}\n-\tif _, err = model.Update(ctx, update, oldMeta.ETag); err != nil {\n-\t\treturn fmt.Errorf(\"Update: %v\", err)\n-\t}\n-\t// [END bigquery_update_model_description]\n-\treturn nil\n-}\n-\n func updateTableDescription(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_table_description]",
        "comments": [],
        "commit_messages": [
            "bigquery/snippets: split out ML model snippets."
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -785,25 +759,6 @@\nfunc deleteTableLabel(client *bigquery.Client, datasetID, tableID string) error\n \treturn nil\n }\n \n-func listModels(client *bigquery.Client, w io.Writer, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_list_models]\n-\tfmt.Fprintf(w, \"Models contained in dataset '%s'\\n\", datasetID)\n-\tit := client.Dataset(datasetID).Models(ctx)\n-\tfor {\n-\t\tm, err := it.Next()\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Fprintf(w, \"Model: %s\\n\", m.FullyQualifiedName())\n-\t}\n-\t// [END bigquery_list_models]\n-\treturn nil\n-}\n-\n func listTables(client *bigquery.Client, w io.Writer, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_list_tables]",
        "comments": [],
        "commit_messages": [
            "bigquery/snippets: split out ML model snippets."
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "bigquery/snippets: split out ML model samples",
        "pr_number": 903,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1142,18 +1097,6 @@\nfunc printTableInfo(client *bigquery.Client, w io.Writer, datasetID, tableID str\n \treturn nil\n }\n \n-func printModelInfo(client *bigquery.Client, w io.Writer, datasetID, modelID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_get_model]\n-\tmeta, err := client.Dataset(datasetID).Model(modelID).Metadata(ctx)\n-\tif err != nil {\n-\t\treturn fmt.Errorf(\"Metadata: %v\", err)\n-\t}\n-\tfmt.Fprintf(w, \"Got model '%q' with friendly name '%q'\\n\", modelID, meta.Name)\n-\t// [END bigquery_get_model]\n-\treturn nil\n-}\n-\n func browseTable(client *bigquery.Client, w io.Writer, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_browse_table]",
        "comments": [],
        "commit_messages": [
            "bigquery/snippets: split out ML model snippets."
        ],
        "last_commit_sha": "fa66e455a24051344fa4f94fcbb51be4a15a85dc"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -26,6 +26,7 @@\nimport (\n \t\"strconv\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/civil\"\n \t\"cloud.google.com/go/spanner\"\n \tdatabase \"cloud.google.com/go/spanner/admin/database/apiv1\"\n \t\"google.golang.org/api/iterator\"",
        "comments": [],
        "commit_messages": [
            "Add Datatypes examples to Spanner sample."
        ],
        "last_commit_sha": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -38,46 +39,55 @@\ntype adminCommand func(ctx context.Context, w io.Writer, adminClient *database.D\n \n var (\n \tcommands = map[string]command{\n-\t\t\"write\":                      write,\n-\t\t\"delete\":                     delete,\n-\t\t\"query\":                      query,\n-\t\t\"read\":                       read,\n-\t\t\"update\":                     update,\n-\t\t\"writetransaction\":           writeWithTransaction,\n-\t\t\"querynewcolumn\":             queryNewColumn,\n-\t\t\"queryindex\":                 queryUsingIndex,\n-\t\t\"readindex\":                  readUsingIndex,\n-\t\t\"readstoringindex\":           readStoringIndex,\n-\t\t\"readonlytransaction\":        readOnlyTransaction,\n-\t\t\"readstaledata\":              readStaleData,\n-\t\t\"readbatchdata\":              readBatchData,\n-\t\t\"updatewithtimestamp\":        updateWithTimestamp,\n-\t\t\"querywithtimestamp\":         queryWithTimestamp,\n-\t\t\"writewithtimestamp\":         writeWithTimestamp,\n-\t\t\"querynewtable\":              queryNewTable,\n-\t\t\"writetodocstable\":           writeToDocumentsTable,\n-\t\t\"updatedocstable\":            updateDocumentsTable,\n-\t\t\"querydocstable\":             queryDocumentsTable,\n-\t\t\"writewithhistory\":           writeWithHistory,\n-\t\t\"updatewithhistory\":          updateWithHistory,\n-\t\t\"querywithhistory\":           queryWithHistory,\n-\t\t\"writestructdata\":            writeStructData,\n-\t\t\"querywithstruct\":            queryWithStruct,\n-\t\t\"querywitharrayofstruct\":     queryWithArrayOfStruct,\n-\t\t\"querywithstructfield\":       queryWithStructField,\n-\t\t\"querywithnestedstructfield\": queryWithNestedStructField,\n-\t\t\"dmlinsert\":                  insertUsingDML,\n-\t\t\"dmlupdate\":                  updateUsingDML,\n-\t\t\"dmldelete\":                  deleteUsingDML,\n-\t\t\"dmlwithtimestamp\":           updateUsingDMLWithTimestamp,\n-\t\t\"dmlwriteread\":               writeAndReadUsingDML,\n-\t\t\"dmlupdatestruct\":            updateUsingDMLStruct,\n-\t\t\"dmlwrite\":                   writeUsingDML,\n-\t\t\"querywithparameter\":         queryWithParameter,\n-\t\t\"dmlwritetxn\":                writeWithTransactionUsingDML,\n-\t\t\"dmlupdatepart\":              updateUsingPartitionedDML,\n-\t\t\"dmldeletepart\":              deleteUsingPartitionedDML,\n-\t\t\"dmlbatchupdate\":             updateUsingBatchDML,\n+\t\t\"write\":                       write,\n+\t\t\"delete\":                      delete,\n+\t\t\"query\":                       query,\n+\t\t\"read\":                        read,\n+\t\t\"update\":                      update,\n+\t\t\"writetransaction\":            writeWithTransaction,\n+\t\t\"querynewcolumn\":              queryNewColumn,\n+\t\t\"queryindex\":                  queryUsingIndex,\n+\t\t\"readindex\":                   readUsingIndex,\n+\t\t\"readstoringindex\":            readStoringIndex,\n+\t\t\"readonlytransaction\":         readOnlyTransaction,\n+\t\t\"readstaledata\":               readStaleData,\n+\t\t\"readbatchdata\":               readBatchData,\n+\t\t\"updatewithtimestamp\":         updateWithTimestamp,\n+\t\t\"querywithtimestamp\":          queryWithTimestamp,\n+\t\t\"writewithtimestamp\":          writeWithTimestamp,\n+\t\t\"querynewtable\":               queryNewTable,\n+\t\t\"writetodocstable\":            writeToDocumentsTable,\n+\t\t\"updatedocstable\":             updateDocumentsTable,\n+\t\t\"querydocstable\":              queryDocumentsTable,\n+\t\t\"writewithhistory\":            writeWithHistory,\n+\t\t\"updatewithhistory\":           updateWithHistory,\n+\t\t\"querywithhistory\":            queryWithHistory,\n+\t\t\"writestructdata\":             writeStructData,\n+\t\t\"querywithstruct\":             queryWithStruct,\n+\t\t\"querywitharrayofstruct\":      queryWithArrayOfStruct,\n+\t\t\"querywithstructfield\":        queryWithStructField,\n+\t\t\"querywithnestedstructfield\":  queryWithNestedStructField,\n+\t\t\"dmlinsert\":                   insertUsingDML,\n+\t\t\"dmlupdate\":                   updateUsingDML,\n+\t\t\"dmldelete\":                   deleteUsingDML,\n+\t\t\"dmlwithtimestamp\":            updateUsingDMLWithTimestamp,\n+\t\t\"dmlwriteread\":                writeAndReadUsingDML,\n+\t\t\"dmlupdatestruct\":             updateUsingDMLStruct,\n+\t\t\"dmlwrite\":                    writeUsingDML,\n+\t\t\"querywithparameter\":          queryWithParameter,\n+\t\t\"dmlwritetxn\":                 writeWithTransactionUsingDML,\n+\t\t\"dmlupdatepart\":               updateUsingPartitionedDML,\n+\t\t\"dmldeletepart\":               deleteUsingPartitionedDML,\n+\t\t\"dmlbatchupdate\":              updateUsingBatchDML,\n+\t\t\"writedatatypesdata\":          writeDatatypesData,\n+\t\t\"querywitharray\":              queryWithArray,\n+\t\t\"querywithbool\":               queryWithBool,\n+\t\t\"querywithbytes\":              queryWithBytes,\n+\t\t\"querywithdate\":               queryWithDate,\n+\t\t\"querywithfloat\":              queryWithFloat,\n+\t\t\"querywithint\":                queryWithInt,\n+\t\t\"querywithstring\":             queryWithString,\n+\t\t\"querywithtimestampparameter\": queryWithTimestampParameter,\n \t}\n \n \tadminCommands = map[string]adminCommand{",
        "comments": [
            {
                "comment": "Consider adding function comments saying what this does.\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/master/CONTRIBUTING.md#comment-functions-and-packages",
                "position": 120
            },
            {
                "comment": "Please inline the `ctx` declaration (don't have it as an argument).\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/master/CONTRIBUTING.md#declare-a-contextcontext-as-needed",
                "position": 120
            },
            {
                "comment": "Please initialize clients in the body of the sample, not passed as an argument.\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/master/CONTRIBUTING.md#initialize-clients-and-services-in-every-sample",
                "position": 120
            },
            {
                "comment": "Should `Datatypes` be `DataTypes`?",
                "position": 120
            },
            {
                "comment": "Please move all of these samples to their own file and include imports in the region tags.\r\n\r\nhttps://github.com/GoogleCloudPlatform/golang-samples/blob/master/CONTRIBUTING.md#one-file-per-sample",
                "position": 120
            },
            {
                "comment": "Updated.",
                "position": 120
            },
            {
                "comment": "This matches the sample's existing style. This can be revisited in a future update.\r\n",
                "position": 120
            },
            {
                "comment": "This matches the sample's existing style. This can be revisited in a future update.\r\n",
                "position": 120
            },
            {
                "comment": "These new samples utilize the existing sample's create database\r\nand command line functionality as well as its test harness.\r\nI'd prefer to leave this as is for now. \r\nThis can be revisited in a future update.",
                "position": 120
            }
        ],
        "commit_messages": [
            "Add Datatypes examples to Spanner sample."
        ],
        "last_commit_sha": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -87,6 +97,7 @@\nvar (\n \t\t\"addstoringindex\":                 addStoringIndex,\n \t\t\"addcommittimestamp\":              addCommitTimestamp,\n \t\t\"createtablewithtimestamp\":        createTableWithTimestamp,\n+\t\t\"createtablewithdatatypes\":        createTableWithDatatypes,\n \t\t\"createtabledocswithtimestamp\":    createTableDocumentsWithTimestamp,\n \t\t\"createtabledocswithhistorytable\": createTableDocumentsWithHistoryTable,\n \t}",
        "comments": [],
        "commit_messages": [
            "Add Datatypes examples to Spanner sample."
        ],
        "last_commit_sha": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "spanner: add Datatypes examples",
        "pr_number": 897,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1266,10 +1277,332 @@\nfunc updateUsingBatchDML(ctx context.Context, w io.Writer, client *spanner.Clien\n \n // [END spanner_dml_batch_update]\n \n+// [START spanner_create_table_with_datatypes]\n+\n+// Creates a Cloud Spanner table comprised of columns for each supported data type\n+// See https://cloud.google.com/spanner/docs/data-types\n+func createTableWithDatatypes(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t`CREATE TABLE Venues (\n+\t\t\t\tVenueId\tINT64 NOT NULL,\n+\t\t\t\tVenueName STRING(100),\n+\t\t\t\tVenueInfo BYTES(MAX),\n+\t\t\t\tCapacity INT64,\n+\t\t\t\tAvailableDates ARRAY<DATE>,\n+\t\t\t\tLastContactDate DATE,\n+\t\t\t\tOutdoorVenue BOOL,\n+\t\t\t\tPopularityScore FLOAT64,\n+\t\t\t\tLastUpdateTime TIMESTAMP NOT NULL OPTIONS (allow_commit_timestamp=true)\n+\t\t\t) PRIMARY KEY (VenueId)`,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"UpdateDatabaseDdl: %v\", err)\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Created Venues table in database [%s]\\n\", database)\n+\treturn nil\n+}\n+\n+// [END spanner_create_table_with_datatypes]\n+\n+// [START spanner_insert_datatypes_data]\n+\n+func writeDatatypesData(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvenueColumns := []string{\"VenueId\", \"VenueName\", \"VenueInfo\", \"Capacity\", \"AvailableDates\",\n+\t\t\"LastContactDate\", \"OutdoorVenue\", \"PopularityScore\", \"LastUpdateTime\"}\n+\tm := []*spanner.Mutation{\n+\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n+\t\t\t[]interface{}{4, \"Venue 4\", []byte(\"Hello World 1\"), 1800,\n+\t\t\t\t[]string{\"2020-12-01\", \"2020-12-02\", \"2020-12-03\"},\n+\t\t\t\t\"2018-09-02\", false, 0.85543, spanner.CommitTimestamp}),\n+\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n+\t\t\t[]interface{}{19, \"Venue 19\", []byte(\"Hello World 2\"), 6300,\n+\t\t\t\t[]string{\"2020-11-01\", \"2020-11-05\", \"2020-11-15\"},\n+\t\t\t\t\"2019-01-15\", true, 0.98716, spanner.CommitTimestamp}),\n+\t\tspanner.InsertOrUpdate(\"Venues\", venueColumns,\n+\t\t\t[]interface{}{42, \"Venue 42\", []byte(\"Hello World 3\"), 3000,\n+\t\t\t\t[]string{\"2020-10-01\", \"2020-10-07\"}, \"2018-10-01\",\n+\t\t\t\tfalse, 0.72598, spanner.CommitTimestamp}),\n+\t}\n+\t_, err := client.Apply(ctx, m)\n+\treturn err\n+}\n+\n+// [END spanner_insert_datatypes_data]\n+\n+// [START spanner_query_with_array_parameter]\n+\n+func queryWithArray(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar date1 = civil.Date{Year: 2020, Month: time.October, Day: 1}\n+\tvar date2 = civil.Date{Year: 2020, Month: time.November, Day: 1}\n+\tvar exampleArray = []civil.Date{date1, date2}\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, AvailableDate FROM Venues v,\n+            \tUNNEST(v.AvailableDates) as AvailableDate \n+            \tWHERE AvailableDate IN UNNEST(@availableDates)`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"availableDates\": exampleArray,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar availableDate civil.Date\n+\t\tif err := row.Columns(&venueID, &venueName, &availableDate); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, availableDate)\n+\t}\n+}\n+\n+// [END spanner_query_with_array_parameter]\n+\n+// [START spanner_query_with_bool_parameter]\n+\n+func queryWithBool(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleBool = true\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, OutdoorVenue FROM Venues\n+            \tWHERE OutdoorVenue = @outdoorVenue`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"outdoorVenue\": exampleBool,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar outdoorVenue bool\n+\t\tif err := row.Columns(&venueID, &venueName, &outdoorVenue); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %t\\n\", venueID, venueName, outdoorVenue)\n+\t}\n+}\n+\n+// [END spanner_query_with_bool_parameter]\n+\n+// [START spanner_query_with_bytes_parameter]\n+\n+func queryWithBytes(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleBytes = []byte(\"Hello World 1\")\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName FROM Venues\n+            \tWHERE VenueInfo = @venueInfo`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"venueInfo\": exampleBytes,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tif err := row.Columns(&venueID, &venueName); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s\\n\", venueID, venueName)\n+\t}\n+}\n+\n+// [END spanner_query_with_bytes_parameter]\n+\n+// [START spanner_query_with_date_parameter]\n+\n+func queryWithDate(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleDate = civil.Date{Year: 2019, Month: time.January, Day: 1}\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, LastContactDate FROM Venues\n+            \tWHERE LastContactDate < @lastContactDate`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"lastContactDate\": exampleDate,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar lastContactDate civil.Date\n+\t\tif err := row.Columns(&venueID, &venueName, &lastContactDate); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %v\\n\", venueID, venueName, lastContactDate)\n+\t}\n+}\n+\n+// [END spanner_query_with_date_parameter]\n+\n+// [START spanner_query_with_float_parameter]\n+\n+func queryWithFloat(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleFloat = 0.8\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, PopularityScore FROM Venues\n+            \tWHERE PopularityScore > @popularityScore`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"popularityScore\": exampleFloat,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar popularityScore float64\n+\t\tif err := row.Columns(&venueID, &venueName, &popularityScore); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %f\\n\", venueID, venueName, popularityScore)\n+\t}\n+}\n+\n+// [END spanner_query_with_float_parameter]\n+\n+// [START spanner_query_with_int_parameter]\n+\n+func queryWithInt(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleInt = 3000\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, Capacity FROM Venues\n+            \tWHERE Capacity >= @capacity`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"capacity\": exampleInt,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID, capacity int64\n+\t\tvar venueName string\n+\t\tif err := row.Columns(&venueID, &venueName, &capacity); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %d\\n\", venueID, venueName, capacity)\n+\t}\n+}\n+\n+// [END spanner_query_with_int_parameter]\n+\n+// [START spanner_query_with_string_parameter]\n+\n+func queryWithString(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleString = \"Venue 42\"\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName FROM Venues\n+            \tWHERE VenueName = @venueName`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"venueName\": exampleString,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tif err := row.Columns(&venueID, &venueName); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s\\n\", venueID, venueName)\n+\t}\n+}\n+\n+// [END spanner_query_with_string_parameter]\n+\n+// [START spanner_query_with_timestamp_parameter]\n+\n+func queryWithTimestampParameter(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tvar exampleTimestamp = time.Now()\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT VenueId, VenueName, LastUpdateTime FROM Venues\n+            \tWHERE LastUpdateTime < @lastUpdateTime`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"lastUpdateTime\": exampleTimestamp,\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar venueID int64\n+\t\tvar venueName string\n+\t\tvar lastUpdateTime time.Time\n+\t\tif err := row.Columns(&venueID, &venueName, &lastUpdateTime); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", venueID, venueName, lastUpdateTime)\n+\t}\n+}\n+\n+// [END spanner_query_with_timestamp_parameter]\n+\n func queryNewTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n \tstmt := spanner.Statement{\n \t\tSQL: `SELECT SingerId, VenueId, EventDate, Revenue, LastUpdateTime FROM Performances\n-\t\t\tORDER BY LastUpdateTime DESC`}\n+\t\t\t\tORDER BY LastUpdateTime DESC`}\n \titer := client.Single().Query(ctx, stmt)\n \tdefer iter.Stop()\n \tfor {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "06ce772cb662d99c1bce416c4fc29467af8d6435"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -38,32 +38,24 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_copy_table]\n \t// [START bigquery_copy_table_cmek]\n \t// [START bigquery_copy_table_multiple_source]\n-\t// [START bigquery_create_dataset]\n \t// [START bigquery_create_table]\n \t// [START bigquery_create_table_clustered]\n \t// [START bigquery_create_table_cmek]\n \t// [START bigquery_create_table_partitioned]\n \t// [START bigquery_create_view]\n-\t// [START bigquery_delete_dataset]\n-\t// [START bigquery_delete_label_dataset]\n \t// [START bigquery_delete_label_table]\n \t// [START bigquery_delete_model]\n \t// [START bigquery_delete_table]\n \t// [START bigquery_extract_table]\n \t// [START bigquery_extract_table_compressed]\n \t// [START bigquery_extract_table_json]\n-\t// [START bigquery_get_dataset]\n-\t// [START bigquery_get_dataset_labels]\n \t// [START bigquery_get_job]\n \t// [START bigquery_get_model]\n \t// [START bigquery_get_table]\n \t// [START bigquery_get_table_labels]\n \t// [START bigquery_get_view]\n \t// [START bigquery_grant_view_access]\n-\t// [START bigquery_label_dataset]\n \t// [START bigquery_label_table]\n-\t// [START bigquery_list_datasets]\n-\t// [START bigquery_list_datasets_by_label]\n \t// [START bigquery_list_jobs]\n \t// [START bigquery_list_models]\n \t// [START bigquery_list_tables]",
        "comments": [],
        "commit_messages": [
            "bigquery: begin splitting snippets out, starting with datasets.\n\nMake BigQuery snippets more like style guide.\n\nAlso, adds a snippets/testutil for generating resource names.\nLet me know if you'd prefer this to be in internal/testutil\nor somewhere else."
        ],
        "last_commit_sha": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -100,9 +92,6 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_relax_column_query_append]\n \t// [START bigquery_table_insert_rows]\n \t// [START bigquery_undelete_table]\n-\t// [START bigquery_update_dataset_access]\n-\t// [START bigquery_update_dataset_description]\n-\t// [START bigquery_update_dataset_expiration]\n \t// [START bigquery_update_table_cmek]\n \t// [START bigquery_update_model_description]\n \t// [START bigquery_update_table_description]",
        "comments": [],
        "commit_messages": [
            "bigquery: begin splitting snippets out, starting with datasets.\n\nMake BigQuery snippets more like style guide.\n\nAlso, adds a snippets/testutil for generating resource names.\nLet me know if you'd prefer this to be in internal/testutil\nor somewhere else."
        ],
        "last_commit_sha": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -121,32 +110,24 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_copy_table]\n \t// [END bigquery_copy_table_cmek]\n \t// [END bigquery_copy_table_multiple_source]\n-\t// [END bigquery_create_dataset]\n \t// [END bigquery_create_table]\n \t// [END bigquery_create_table_clustered]\n \t// [END bigquery_create_table_cmek]\n \t// [END bigquery_create_table_partitioned]\n \t// [END bigquery_create_view]\n-\t// [END bigquery_delete_dataset]\n-\t// [END bigquery_delete_label_dataset]\n \t// [END bigquery_delete_label_table]\n \t// [END bigquery_delete_model]\n \t// [END bigquery_delete_table]\n \t// [END bigquery_extract_table]\n \t// [END bigquery_extract_table_compressed]\n \t// [END bigquery_extract_table_json]\n-\t// [END bigquery_get_dataset]\n-\t// [END bigquery_get_dataset_labels]\n \t// [END bigquery_get_job]\n \t// [END bigquery_get_model]\n \t// [END bigquery_get_table]\n \t// [END bigquery_get_table_labels]\n \t// [END bigquery_get_view]\n \t// [END bigquery_grant_view_access]\n-\t// [END bigquery_label_dataset]\n \t// [END bigquery_label_table]\n-\t// [END bigquery_list_datasets]\n-\t// [END bigquery_list_datasets_by_label]\n \t// [END bigquery_list_jobs]\n \t// [END bigquery_list_models]\n \t// [END bigquery_list_tables]",
        "comments": [],
        "commit_messages": [
            "bigquery: begin splitting snippets out, starting with datasets.\n\nMake BigQuery snippets more like style guide.\n\nAlso, adds a snippets/testutil for generating resource names.\nLet me know if you'd prefer this to be in internal/testutil\nor somewhere else."
        ],
        "last_commit_sha": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -183,11 +164,8 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_relax_column_query_append]\n \t// [END bigquery_table_insert_rows]\n \t// [END bigquery_undelete_table]\n-\t// [END bigquery_update_dataset_access]\n \t// [END bigquery_update_model_description]\n \t// [END bigquery_update_table_cmek]\n-\t// [END bigquery_update_dataset_description]\n-\t// [END bigquery_update_dataset_expiration]\n \t// [END bigquery_update_table_description]\n \t// [END bigquery_update_table_expiration]\n \t// [END bigquery_update_view_query]",
        "comments": [],
        "commit_messages": [
            "bigquery: begin splitting snippets out, starting with datasets.\n\nMake BigQuery snippets more like style guide.\n\nAlso, adds a snippets/testutil for generating resource names.\nLet me know if you'd prefer this to be in internal/testutil\nor somewhere else."
        ],
        "last_commit_sha": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -204,19 +182,6 @@\nfunc cancelJob(client *bigquery.Client, jobID string) error {\n \t// [END bigquery_cancel_job]\n }\n \n-func createDataset(client *bigquery.Client, datasetID string) error {\n-\tctx := context.Background()\n-\t// [START bigquery_create_dataset]\n-\tmeta := &bigquery.DatasetMetadata{\n-\t\tLocation: \"US\", // Create the dataset in the US.\n-\t}\n-\tif err := client.Dataset(datasetID).Create(ctx, meta); err != nil {\n-\t\treturn err\n-\t}\n-\t// [END bigquery_create_dataset]\n-\treturn nil\n-}\n-\n func createView(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_create_view]",
        "comments": [],
        "commit_messages": [
            "bigquery: begin splitting snippets out, starting with datasets.\n\nMake BigQuery snippets more like style guide.\n\nAlso, adds a snippets/testutil for generating resource names.\nLet me know if you'd prefer this to be in internal/testutil\nor somewhere else."
        ],
        "last_commit_sha": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -65,61 +65,14 @@\nfunc TestAll(t *testing.T) {\n \t}\n \n \tdatasetID := uniqueBQName(\"golang_example_dataset\")\n-\tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n+\tif err := client.Dataset(datasetID).Create(ctx, &bigquery.DatasetMetadata{\n+\t\tLocation: \"US\",\n+\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", datasetID, err)\n \t}\n \t// Cleanup dataset at end of test.\n \tdefer client.Dataset(datasetID).DeleteWithContents(ctx)\n \n-\tif err := updateDatasetAccessControl(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDataSetAccessControl(%q): %v\", datasetID, err)\n-\t}\n-\tif err := addDatasetLabel(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n-\t}\n-\n-\tbuf := &bytes.Buffer{}\n-\tif err := datasetLabels(client, buf, datasetID); err != nil {\n-\t\tt.Errorf(\"getDatasetLabels(%q): %v\", datasetID, err)\n-\t}\n-\twant := \"color:green\"\n-\tif got := buf.String(); !strings.Contains(got, want) {\n-\t\tt.Errorf(\"getDatasetLabel(%q) expected %q to contain %q\", datasetID, got, want)\n-\t}\n-\n-\tif err := addDatasetLabel(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n-\t}\n-\tbuf.Reset()\n-\tif err := listDatasetsByLabel(client, buf); err != nil {\n-\t\tt.Errorf(\"listDatasetsByLabel: %v\", err)\n-\t}\n-\tif got := buf.String(); !strings.Contains(got, datasetID) {\n-\t\tt.Errorf(\"listDatasetsByLabel expected %q to contain %q\", got, want)\n-\t}\n-\tif err := deleteDatasetLabel(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetDeleteLabel: %v\", err)\n-\t}\n-\n-\t// Test empty dataset creation/ttl/delete.\n-\tdeletionDatasetID := uniqueBQName(\"golang_example_quickdelete\")\n-\tif err := createDataset(client, deletionDatasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", deletionDatasetID, err)\n-\t}\n-\tif err = updateDatasetDefaultExpiration(client, deletionDatasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetDefaultExpiration(%q): %v\", deletionDatasetID, err)\n-\t}\n-\tif err := deleteEmptyDataset(client, deletionDatasetID); err != nil {\n-\t\tt.Errorf(\"deleteEmptyDataset(%q): %v\", deletionDatasetID, err)\n-\t}\n-\n-\tif err := updateDatasetDescription(client, datasetID); err != nil {\n-\t\tt.Errorf(\"updateDatasetDescription(%q): %v\", datasetID, err)\n-\t}\n-\tif err := listDatasets(client, ioutil.Discard); err != nil {\n-\t\tt.Errorf(\"listDatasets: %v\", err)\n-\t}\n-\n \tinferred := uniqueBQName(\"golang_example_table_inferred\")\n \texplicit := uniqueBQName(\"golang_example_table_explicit\")",
        "comments": [
            {
                "comment": "For multi-line function calls, I generally like to have them outside the `if` statement. It can be a little hard to find the condition being checked after the declaration when it's inline.",
                "position": 94
            },
            {
                "comment": "This is in the corpus of tests I still need to break up.  Will revisit that in subsequent PRs.",
                "position": 94
            }
        ],
        "commit_messages": [
            "bigquery: begin splitting snippets out, starting with datasets.\n\nMake BigQuery snippets more like style guide.\n\nAlso, adds a snippets/testutil for generating resource names.\nLet me know if you'd prefer this to be in internal/testutil\nor somewhere else."
        ],
        "last_commit_sha": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -171,7 +124,7 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"updateTableAddLabel(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n \n-\tbuf.Reset()\n+\tbuf := &bytes.Buffer{}\n \tif err := listTables(client, buf, datasetID); err != nil {\n \t\tt.Errorf(\"listTables(%q): %v\", datasetID, err)\n \t}",
        "comments": [],
        "commit_messages": [
            "bigquery: begin splitting snippets out, starting with datasets.\n\nMake BigQuery snippets more like style guide.\n\nAlso, adds a snippets/testutil for generating resource names.\nLet me know if you'd prefer this to be in internal/testutil\nor somewhere else."
        ],
        "last_commit_sha": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -183,10 +136,6 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"want table list %q to contain table %q\", got, explicit)\n \t}\n \n-\tif err := printDatasetInfo(client, ioutil.Discard, datasetID); err != nil {\n-\t\tt.Errorf(\"printDatasetInfo: %v\", err)\n-\t}\n-\n \t// Stream data, read, query the inferred schema table.\n \tif err := insertRows(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"insertRows(dataset:%q table:%q): %v\", datasetID, inferred, err)",
        "comments": [],
        "commit_messages": [
            "bigquery: begin splitting snippets out, starting with datasets.\n\nMake BigQuery snippets more like style guide.\n\nAlso, adds a snippets/testutil for generating resource names.\nLet me know if you'd prefer this to be in internal/testutil\nor somewhere else."
        ],
        "last_commit_sha": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -298,14 +247,22 @@\nfunc TestViews(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\n \tsrcDatasetID := uniqueBQName(\"golang_example_view_source\")\n-\tif err := createDataset(client, srcDatasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", srcDatasetID, err)\n+\tif err := client.Dataset(srcDatasetID).Create(ctx,\n+\t\t&bigquery.DatasetMetadata{\n+\t\t\tLocation: \"US\",\n+\t\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", srcDatasetID, err)\n \t}\n \tdefer client.Dataset(srcDatasetID).DeleteWithContents(ctx)\n+\n \tviewDatasetID := uniqueBQName(\"golang_example_view_container\")\n-\tif err := createDataset(client, viewDatasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", viewDatasetID, err)\n+\tif err := client.Dataset(viewDatasetID).Create(ctx,\n+\t\t&bigquery.DatasetMetadata{\n+\t\t\tLocation: \"US\",\n+\t\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", viewDatasetID, err)\n \t}\n \tdefer client.Dataset(viewDatasetID).DeleteWithContents(ctx)",
        "comments": [],
        "commit_messages": [
            "bigquery: begin splitting snippets out, starting with datasets.\n\nMake BigQuery snippets more like style guide.\n\nAlso, adds a snippets/testutil for generating resource names.\nLet me know if you'd prefer this to be in internal/testutil\nor somewhere else."
        ],
        "last_commit_sha": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -344,8 +301,11 @@\nfunc TestImportExport(t *testing.T) {\n \n \tdatasetID := uniqueBQName(\"golang_example_dataset_importexport\")\n \ttableID := uniqueBQName(\"golang_example_dataset_importexport\")\n-\tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n+\tif err := client.Dataset(datasetID).Create(ctx,\n+\t\t&bigquery.DatasetMetadata{\n+\t\t\tLocation: \"US\",\n+\t\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", datasetID, err)\n \t}\n \tdefer client.Dataset(datasetID).DeleteWithContents(ctx)",
        "comments": [],
        "commit_messages": [
            "bigquery: begin splitting snippets out, starting with datasets.\n\nMake BigQuery snippets more like style guide.\n\nAlso, adds a snippets/testutil for generating resource names.\nLet me know if you'd prefer this to be in internal/testutil\nor somewhere else."
        ],
        "last_commit_sha": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "bigquery: begin splitting snippets out, starting with datasets.",
        "pr_number": 887,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -469,8 +429,10 @@\nfunc TestPartitioningAndClustering(t *testing.T) {\n \t}\n \n \tdatasetID := uniqueBQName(\"golang_example_dataset_partition_cluster\")\n-\tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n+\tif err := client.Dataset(datasetID).Create(ctx, &bigquery.DatasetMetadata{\n+\t\tLocation: \"US\",\n+\t}); err != nil {\n+\t\tt.Errorf(\"dataset.Create(%q): %v\", datasetID, err)\n \t}\n \tdefer client.Dataset(datasetID).DeleteWithContents(ctx)",
        "comments": [],
        "commit_messages": [
            "bigquery: begin splitting snippets out, starting with datasets.\n\nMake BigQuery snippets more like style guide.\n\nAlso, adds a snippets/testutil for generating resource names.\nLet me know if you'd prefer this to be in internal/testutil\nor somewhere else."
        ],
        "last_commit_sha": "f6fc0af50ca062ff9c573003db2959175b40cfa8"
    },
    {
        "pr_title": "vision/detect: delete unused sample and add subtests",
        "pr_number": 885,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -515,59 +515,6 @@\nfunc detectLogos(w io.Writer, file string) error {\n \n // [END vision_logo_detection]\n \n-// [START vision_text_detection_pdf]\n-\n-// detectAsyncDocument performs Optical Character Recognition (OCR) on a\n-// PDF file stored in GCS.\n-func detectAsyncDocument(w io.Writer, gcsSourceURI, gcsDestinationURI string) error {\n-\tctx := context.Background()\n-\n-\tclient, err := vision.NewImageAnnotatorClient(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\trequest := &visionpb.AsyncBatchAnnotateFilesRequest{\n-\t\tRequests: []*visionpb.AsyncAnnotateFileRequest{\n-\t\t\t{\n-\t\t\t\tFeatures: []*visionpb.Feature{\n-\t\t\t\t\t{\n-\t\t\t\t\t\tType: visionpb.Feature_DOCUMENT_TEXT_DETECTION,\n-\t\t\t\t\t},\n-\t\t\t\t},\n-\t\t\t\tInputConfig: &visionpb.InputConfig{\n-\t\t\t\t\tGcsSource: &visionpb.GcsSource{Uri: gcsSourceURI},\n-\t\t\t\t\t// Supported MimeTypes are: \"application/pdf\" and \"image/tiff\".\n-\t\t\t\t\tMimeType: \"application/pdf\",\n-\t\t\t\t},\n-\t\t\t\tOutputConfig: &visionpb.OutputConfig{\n-\t\t\t\t\tGcsDestination: &visionpb.GcsDestination{Uri: gcsDestinationURI},\n-\t\t\t\t\t// How many pages should be grouped into each json output file.\n-\t\t\t\t\tBatchSize: 2,\n-\t\t\t\t},\n-\t\t\t},\n-\t\t},\n-\t}\n-\n-\toperation, err := client.AsyncBatchAnnotateFiles(ctx, request)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\tfmt.Fprintf(w, \"Waiting for the operation to finish.\")\n-\n-\tresp, err := operation.Wait(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\tfmt.Fprintf(w, \"%v\", resp)\n-\n-\treturn nil\n-}\n-\n-// [END vision_text_detection_pdf]\n-\n // [START vision_localize_objects]\n \n // localizeObjects gets objects and bounding boxes from the Vision API for an image at the given file path.",
        "comments": [],
        "commit_messages": [
            "vision/detect: delete unused sample and add subtests\n\nUsing parallel subtests for TestDetect saves about ~20 seconds per run\n(~22 seconds -> ~2 seconds)."
        ],
        "last_commit_sha": "d6f0a22a6a2b3ccda6e819149ac4003c5fb32fad"
    },
    {
        "pr_title": "vision/detect: delete unused sample and add subtests",
        "pr_number": 885,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -21,12 +21,10 @@\nimport (\n \t\"io\"\n \t\"strings\"\n \t\"testing\"\n-\t\"time\"\n \n \t\"cloud.google.com/go/storage\"\n-\t\"google.golang.org/api/iterator\"\n-\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n func TestDetect(t *testing.T) {",
        "comments": [],
        "commit_messages": [
            "vision/detect: delete unused sample and add subtests\n\nUsing parallel subtests for TestDetect saves about ~20 seconds per run\n(~22 seconds -> ~2 seconds)."
        ],
        "last_commit_sha": "d6f0a22a6a2b3ccda6e819149ac4003c5fb32fad"
    },
    {
        "pr_title": "vision/detect: delete unused sample and add subtests",
        "pr_number": 885,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -57,30 +55,32 @@\nfunc TestDetect(t *testing.T) {\n \t\tif tt.local == nil {\n \t\t\tcontinue\n \t\t}\n-\n-\t\tvar buf bytes.Buffer\n-\t\terr := tt.local(&buf, \"../testdata/\"+tt.path)\n-\t\tif err != nil {\n-\t\t\tt.Fatalf(\"Local %s(%q): got %v, want nil err\", tt.name, tt.path, err)\n-\t\t}\n-\t\tif got := buf.String(); !strings.Contains(strings.ToLower(got), strings.ToLower(tt.wantContain)) {\n-\t\t\tt.Errorf(\"Local %s(%q): got %q, want to contain %q\", tt.name, tt.path, got, tt.wantContain)\n-\t\t}\n+\t\tt.Run(tt.name+\"/local\", func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tvar buf bytes.Buffer\n+\t\t\tif err := tt.local(&buf, \"../testdata/\"+tt.path); err != nil {\n+\t\t\t\tt.Fatalf(\"Local %s(%q): got %v, want nil err\", tt.name, tt.path, err)\n+\t\t\t}\n+\t\t\tif got, wantContain := strings.ToLower(buf.String()), strings.ToLower(tt.wantContain); !strings.Contains(got, wantContain) {\n+\t\t\t\tt.Errorf(\"Local %s(%q): got %q, want to contain %q\", tt.name, tt.path, got, wantContain)\n+\t\t\t}\n+\t\t})\n \t}\n \n \tfor _, tt := range tests {\n \t\tif tt.gcs == nil {\n \t\t\tcontinue\n \t\t}\n-\n-\t\tvar buf bytes.Buffer\n-\t\terr := tt.gcs(&buf, \"gs://python-docs-samples-tests/vision/\"+tt.path)\n-\t\tif err != nil {\n-\t\t\tt.Fatalf(\"GCS %s(%q): got %v, want nil err\", tt.name, tt.path, err)\n-\t\t}\n-\t\tif got := buf.String(); !strings.Contains(strings.ToLower(got), strings.ToLower(tt.wantContain)) {\n-\t\t\tt.Errorf(\"GCS %s(%q): got %q, want to contain %q\", tt.name, tt.path, got, tt.wantContain)\n-\t\t}\n+\t\tt.Run(tt.name+\"/gcs\", func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tvar buf bytes.Buffer\n+\t\t\tif err := tt.gcs(&buf, \"gs://python-docs-samples-tests/vision/\"+tt.path); err != nil {\n+\t\t\t\tt.Fatalf(\"GCS %s(%q): got %v, want nil err\", tt.name, tt.path, err)\n+\t\t\t}\n+\t\t\tif got, wantContain := strings.ToLower(buf.String()), strings.ToLower(tt.wantContain); !strings.Contains(got, wantContain) {\n+\t\t\t\tt.Errorf(\"GCS %s(%q): got %q, want to contain %q\", tt.name, tt.path, got, wantContain)\n+\t\t\t}\n+\t\t})\n \t}\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d6f0a22a6a2b3ccda6e819149ac4003c5fb32fad"
    },
    {
        "pr_title": "vision/detect: delete unused sample and add subtests",
        "pr_number": 885,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -89,43 +89,19 @@\nfunc TestDetectAsyncDocument(t *testing.T) {\n \n \tctx := context.Background()\n \n-\t// Create a temporary bucket\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n \n-\tbucketName := fmt.Sprintf(\"%s-golang-samples-%d\", tc.ProjectID, time.Now().Unix())\n+\tbucketName := fmt.Sprintf(\"%s-vision\", tc.ProjectID)\n \tbucket := client.Bucket(bucketName)\n-\tif err := bucket.Create(ctx, tc.ProjectID, nil); err != nil {\n-\t\tt.Fatal(err)\n-\t}\n+\tcleanBucket(ctx, t, client, tc.ProjectID, bucketName)\n \n-\t// Clean and delete the bucket at the end of the test\n-\tdefer func() {\n-\t\tit := bucket.Objects(ctx, nil)\n-\t\tfor {\n-\t\t\tattrs, err := it.Next()\n-\t\t\tif err == iterator.Done {\n-\t\t\t\tbreak\n-\t\t\t}\n-\t\t\tif err != nil {\n-\t\t\t\tt.Fatal(err)\n-\t\t\t}\n-\t\t\tif err := bucket.Object(attrs.Name).Delete(ctx); err != nil {\n-\t\t\t\tt.Fatal(err)\n-\t\t\t}\n-\t\t}\n-\t\tif err := bucket.Delete(ctx); err != nil {\n-\t\t\tt.Fatal(err)\n-\t\t}\n-\t}()\n-\n-\t// Run the test\n \tvar buf bytes.Buffer\n \tgcsSourceURI := \"gs://python-docs-samples-tests/HodgeConj.pdf\"\n \tgcsDestinationURI := \"gs://\" + bucketName + \"/vision/\"\n-\terr = detectAsyncDocument(&buf, gcsSourceURI, gcsDestinationURI)\n+\terr = detectAsyncDocumentURI(&buf, gcsSourceURI, gcsDestinationURI)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d6f0a22a6a2b3ccda6e819149ac4003c5fb32fad"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/create_note.go",
        "code_diff": "@@ -20,15 +20,14 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n-\t\"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/vulnerability\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // createNote creates and returns a new vulnerability Note.\n func createNote(noteID, projectID string) (*grafeaspb.Note, error) {\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/create_occurrence.go",
        "code_diff": "@@ -20,17 +20,16 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n-\t\"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/vulnerability\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // createsOccurrence creates and returns a new Occurrence of a previously created vulnerability Note.\n func createOccurrence(resourceURL, noteID, occProjectID, noteProjectID string) (*grafeaspb.Occurrence, error) {\n \t// resourceURL := fmt.Sprintf(\"https://gcr.io/my-project/my-image\")\n \t// noteID := fmt.Sprintf(\"my-note\")\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/delete_note.go",
        "code_diff": "@@ -20,15 +20,15 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // deleteNote removes an existing Note from the server.\n func deleteNote(noteID, projectID string) error {\n \t// noteID := fmt.Sprintf(\"my-note\")\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/delete_occurrence.go",
        "code_diff": "@@ -20,15 +20,15 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // deleteOccurrence removes an existing Occurrence from the server.\n func deleteOccurrence(occurrenceID, projectID string) error {\n \t// occurrenceID := path.Base(occurrence.Name)\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/filter_vulnerability_occurrences.go",
        "code_diff": "@@ -20,17 +20,16 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n \t\"google.golang.org/api/iterator\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n-\tvulnerability \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/vulnerability\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // findHighSeverityVulnerabilitiesForImage retrieves a list of only high vulnerability occurrences associated with a resource.\n func findHighSeverityVulnerabilitiesForImage(resourceURL, projectID string) ([]*grafeaspb.Occurrence, error) {\n \t// resourceURL := fmt.Sprintf(\"https://gcr.io/my-project/my-image\")\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/filter_vulnerability_occurrences.go",
        "code_diff": "@@ -42,7 +41,7 @@\nfunc findHighSeverityVulnerabilitiesForImage(resourceURL, projectID string) ([]*\n \t}\n \n \tvar occurrenceList []*grafeaspb.Occurrence\n-\tit := client.ListOccurrences(ctx, req)\n+\tit := client.GetGrafeasClient().ListOccurrences(ctx, req)\n \tfor {\n \t\tocc, err := it.Next()\n \t\tif err == iterator.Done {",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/get_discovery_info.go",
        "code_diff": "@@ -21,17 +21,17 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n \t\"google.golang.org/api/iterator\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // getDiscoveryInfo retrieves and prints the Discovery Occurrence created for a specified image.\n // The Discovery Occurrence contains information about the initial scan on the image.\n func getDiscoveryInfo(w io.Writer, resourceURL, projectID string) error {\n \t// resourceURL := fmt.Sprintf(\"https://gcr.io/my-project/my-image\")\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/get_note.go",
        "code_diff": "@@ -20,15 +20,15 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // getNote retrieves and prints a specified Note from the server.\n func getNote(noteID, projectID string) (*grafeaspb.Note, error) {\n \t// noteID := fmt.Sprintf(\"my-note\")\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/get_occurrence.go",
        "code_diff": "@@ -20,15 +20,15 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // getOccurrence retrieves and prints a specified Occurrence from the server.\n func getOccurrence(occurrenceID, projectID string) (*grafeaspb.Occurrence, error) {\n \t// occurrenceID := path.Base(occurrence.Name)\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/occurrences_for_image.go",
        "code_diff": "@@ -21,17 +21,17 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n \t\"google.golang.org/api/iterator\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // getOccurrencesForImage retrieves all the Occurrences associated with a specified image.\n // Here, all Occurrences are simply printed and counted.\n func getOccurrencesForImage(w io.Writer, resourceURL, projectID string) (int, error) {\n \t// resourceURL := fmt.Sprintf(\"https://gcr.io/my-project/my-image\")\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn -1, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/occurrences_for_note.go",
        "code_diff": "@@ -21,17 +21,17 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n \t\"google.golang.org/api/iterator\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // getOccurrencesForNote retrieves all the Occurrences associated with a specified Note.\n // Here, all Occurrences are printed and counted.\n func getOccurrencesForNote(w io.Writer, noteID, projectID string) (int, error) {\n \t// noteID := fmt.Sprintf(\"my-note\")\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn -1, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/poll_discovery_finished.go",
        "code_diff": "@@ -21,9 +21,9 @@\nimport (\n \t\"fmt\"\n \t\"time\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n-\tdiscovery \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/discovery\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n+\t\"google.golang.org/api/iterator\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // pollDiscoveryOccurrenceFinished returns the discovery occurrence for a resource once it reaches a finished state.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/poll_discovery_finished.go",
        "code_diff": "@@ -33,7 +33,7 @@\nfunc pollDiscoveryOccurrenceFinished(resourceURL, projectID string, timeout time\n \tctx, cancel := context.WithTimeout(context.Background(), timeout)\n \tdefer cancel()\n \n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/poll_discovery_finished.go",
        "code_diff": "@@ -64,14 +64,17 @@\nfunc pollDiscoveryOccurrenceFinished(resourceURL, projectID string, timeout time\n \t\t\t\tFilter: fmt.Sprintf(`kind=\"DISCOVERY\" AND resourceUrl=%q`, resourceURL),\n \t\t\t}\n \t\t\t// [START containeranalysis_poll_discovery_occurrence_finished]\n-\t\t\tit := client.ListOccurrences(ctx, req)\n+\t\t\tit := client.GetGrafeasClient().ListOccurrences(ctx, req)\n \t\t\t// Only one occurrence should ever be returned by ListOccurrences\n \t\t\t// and the given filter.\n \t\t\tresult, err := it.Next()\n+\t\t\tif err == iterator.Done {\n+\t\t\t\tbreak\n+\t\t\t}\n \t\t\tif err != nil {\n \t\t\t\treturn nil, fmt.Errorf(\"it.Next: %v\", err)\n \t\t\t}\n-\t\t\tif result.GetDiscovered() != nil {\n+\t\t\tif result.GetDiscovery() != nil {\n \t\t\t\tdiscoveryOccurrence = result\n \t\t\t}\n \t\t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -23,18 +23,16 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n \tpubsub \"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"github.com/google/uuid\"\n-\tdiscovery \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/discovery\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n-\tvulnerability \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/vulnerability\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n type TestVariables struct {\n \tctx       context.Context\n-\tclient    *containeranalysis.GrafeasV1Beta1Client\n+\tclient    *containeranalysis.Client\n \tnoteID    string\n \tsubID     string\n \timageURL  string",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -49,7 +47,7 @@\nfunc setup(t *testing.T) TestVariables {\n \ttc := testutil.SystemTest(t)\n \t// Create client and context\n \tctx := context.Background()\n-\tclient, _ := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, _ := containeranalysis.NewClient(ctx)\n \t// Get unique id\n \tuuid, err := uuid.NewRandom()\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -275,32 +273,35 @@\nfunc TestPollDiscoveryOccurrenceFinished(t *testing.T) {\n \t\tNoteId: noteID,\n \t\tNote: &grafeaspb.Note{\n \t\t\tType: &grafeaspb.Note_Discovery{\n-\t\t\t\tDiscovery: &discovery.Discovery{},\n+\t\t\t\tDiscovery: &grafeaspb.DiscoveryNote{\n+\t\t\t\t\tAnalysisKind: grafeaspb.NoteKind_DISCOVERY,\n+\t\t\t\t},\n \t\t\t},\n \t\t},\n \t}\n \toccReq := &grafeaspb.CreateOccurrenceRequest{\n \t\tParent: fmt.Sprintf(\"projects/%s\", v.projectID),\n \t\tOccurrence: &grafeaspb.Occurrence{\n-\t\t\tNoteName: fmt.Sprintf(\"projects/%s/notes/%s\", v.projectID, noteID),\n-\t\t\tResource: &grafeaspb.Resource{Uri: v.imageURL},\n-\t\t\tDetails: &grafeaspb.Occurrence_Discovered{\n-\t\t\t\tDiscovered: &discovery.Details{\n-\t\t\t\t\tDiscovered: &discovery.Discovered{\n-\t\t\t\t\t\tAnalysisStatus: discovery.Discovered_FINISHED_SUCCESS,\n-\t\t\t\t\t},\n+\t\t\tNoteName:    fmt.Sprintf(\"projects/%s/notes/%s\", v.projectID, noteID),\n+\t\t\tResourceUri: v.imageURL,\n+\t\t\tDetails: &grafeaspb.Occurrence_Discovery{\n+\t\t\t\tDiscovery: &grafeaspb.DiscoveryOccurrence{\n+\t\t\t\t\tAnalysisStatus: grafeaspb.DiscoveryOccurrence_FINISHED_SUCCESS,\n \t\t\t\t},\n \t\t\t},\n \t\t},\n \t}\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\tt.Errorf(\"containeranalysis.NewGrafeasV1Beta1Client: %v\", err)\n \t}\n \tdefer client.Close()\n-\t_, err = client.CreateNote(ctx, noteReq)\n-\tcreated, err := client.CreateOccurrence(ctx, occReq)\n+\t_, err = client.GetGrafeasClient().CreateNote(ctx, noteReq)\n+\tif err != nil {\n+\t\tt.Errorf(\"createNote(%s): %v\", v.noteID, err)\n+\t}\n+\tcreated, err := client.GetGrafeasClient().CreateOccurrence(ctx, occReq)\n \tif err != nil {\n \t\tt.Errorf(\"createOccurrence(%s, %s): %v\", v.imageURL, v.noteID, err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/samples_test.go",
        "code_diff": "@@ -314,9 +315,9 @@\nfunc TestPollDiscoveryOccurrenceFinished(t *testing.T) {\n \t\tif discOcc == nil {\n \t\t\tr.Errorf(\"discovery occurrence is nil\")\n \t\t}\n-\t\tanalysisStatus := discOcc.GetDiscovered().GetDiscovered().AnalysisStatus\n-\t\tif analysisStatus != discovery.Discovered_FINISHED_SUCCESS {\n-\t\t\tr.Errorf(\"discovery occurrence reported unexpected state: %s, want: %s\", analysisStatus, discovery.Discovered_FINISHED_SUCCESS)\n+\t\tanalysisStatus := discOcc.GetDiscovery().GetAnalysisStatus()\n+\t\tif analysisStatus != grafeaspb.DiscoveryOccurrence_FINISHED_SUCCESS {\n+\t\t\tr.Errorf(\"discovery occurrence reported unexpected state: %s, want: %s\", analysisStatus, grafeaspb.DiscoveryOccurrence_FINISHED_SUCCESS)\n \t\t}\n \t})",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "container_registry: Container Analysis v1",
        "pr_number": 879,
        "file_name": "container_registry/container_analysis/vulnerability_occurrences_for_image.go",
        "code_diff": "@@ -20,16 +20,16 @@\nimport (\n \t\"context\"\n \t\"fmt\"\n \n-\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1beta1\"\n+\tcontaineranalysis \"cloud.google.com/go/containeranalysis/apiv1\"\n \t\"google.golang.org/api/iterator\"\n-\tgrafeaspb \"google.golang.org/genproto/googleapis/devtools/containeranalysis/v1beta1/grafeas\"\n+\tgrafeaspb \"google.golang.org/genproto/googleapis/grafeas/v1\"\n )\n \n // findVulnerabilityOccurrencesForImage retrieves all vulnerability Occurrences associated with a resource.\n func findVulnerabilityOccurrencesForImage(resourceURL, projectID string) ([]*grafeaspb.Occurrence, error) {\n \t// resourceURL := fmt.Sprintf(\"https://gcr.io/my-project/my-image\")\n \tctx := context.Background()\n-\tclient, err := containeranalysis.NewGrafeasV1Beta1Client(ctx)\n+\tclient, err := containeranalysis.NewClient(ctx)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"NewGrafeasV1Beta1Client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "updated container analysis to v1 libraries"
        ],
        "last_commit_sha": "8852d49b240a78d737357a6a00fd555bee64ee8a"
    },
    {
        "pr_title": "bigquery: add ML model samples",
        "pr_number": 873,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -47,13 +47,15 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_delete_dataset]\n \t// [START bigquery_delete_label_dataset]\n \t// [START bigquery_delete_label_table]\n+\t// [START bigquery_delete_model]\n \t// [START bigquery_delete_table]\n \t// [START bigquery_extract_table]\n \t// [START bigquery_extract_table_compressed]\n \t// [START bigquery_extract_table_json]\n \t// [START bigquery_get_dataset]\n \t// [START bigquery_get_dataset_labels]\n \t// [START bigquery_get_job]\n+\t// [START bigquery_get_model]\n \t// [START bigquery_get_table]\n \t// [START bigquery_get_table_labels]\n \t// [START bigquery_get_view]",
        "comments": [],
        "commit_messages": [
            "bigquery: add ML model samples"
        ],
        "last_commit_sha": "421616cc9e0d76204af6ac8ee230be83b2f83927"
    },
    {
        "pr_title": "bigquery: add ML model samples",
        "pr_number": 873,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -63,6 +65,7 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_list_datasets]\n \t// [START bigquery_list_datasets_by_label]\n \t// [START bigquery_list_jobs]\n+\t// [START bigquery_list_models]\n \t// [START bigquery_list_tables]\n \t// [START bigquery_load_from_file]\n \t// [START bigquery_load_table_clustered]",
        "comments": [],
        "commit_messages": [
            "bigquery: add ML model samples"
        ],
        "last_commit_sha": "421616cc9e0d76204af6ac8ee230be83b2f83927"
    },
    {
        "pr_title": "bigquery: add ML model samples",
        "pr_number": 873,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -101,6 +104,7 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_update_dataset_description]\n \t// [START bigquery_update_dataset_expiration]\n \t// [START bigquery_update_table_cmek]\n+\t// [START bigquery_update_model_description]\n \t// [START bigquery_update_table_description]\n \t// [START bigquery_update_table_expiration]\n \t// [START bigquery_update_view_query]",
        "comments": [],
        "commit_messages": [
            "bigquery: add ML model samples"
        ],
        "last_commit_sha": "421616cc9e0d76204af6ac8ee230be83b2f83927"
    },
    {
        "pr_title": "bigquery: add ML model samples",
        "pr_number": 873,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -126,13 +130,15 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_delete_dataset]\n \t// [END bigquery_delete_label_dataset]\n \t// [END bigquery_delete_label_table]\n+\t// [END bigquery_delete_model]\n \t// [END bigquery_delete_table]\n \t// [END bigquery_extract_table]\n \t// [END bigquery_extract_table_compressed]\n \t// [END bigquery_extract_table_json]\n \t// [END bigquery_get_dataset]\n \t// [END bigquery_get_dataset_labels]\n \t// [END bigquery_get_job]\n+\t// [END bigquery_get_model]\n \t// [END bigquery_get_table]\n \t// [END bigquery_get_table_labels]\n \t// [END bigquery_get_view]",
        "comments": [],
        "commit_messages": [
            "bigquery: add ML model samples"
        ],
        "last_commit_sha": "421616cc9e0d76204af6ac8ee230be83b2f83927"
    },
    {
        "pr_title": "bigquery: add ML model samples",
        "pr_number": 873,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -142,6 +148,7 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_list_datasets]\n \t// [END bigquery_list_datasets_by_label]\n \t// [END bigquery_list_jobs]\n+\t// [END bigquery_list_models]\n \t// [END bigquery_list_tables]\n \t// [END bigquery_load_from_file]\n \t// [END bigquery_load_table_clustered]",
        "comments": [],
        "commit_messages": [
            "bigquery: add ML model samples"
        ],
        "last_commit_sha": "421616cc9e0d76204af6ac8ee230be83b2f83927"
    },
    {
        "pr_title": "bigquery: add ML model samples",
        "pr_number": 873,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -177,6 +184,7 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_table_insert_rows]\n \t// [END bigquery_undelete_table]\n \t// [END bigquery_update_dataset_access]\n+\t// [END bigquery_update_model_description]\n \t// [END bigquery_update_table_cmek]\n \t// [END bigquery_update_dataset_description]\n \t// [END bigquery_update_dataset_expiration]",
        "comments": [],
        "commit_messages": [
            "bigquery: add ML model samples"
        ],
        "last_commit_sha": "421616cc9e0d76204af6ac8ee230be83b2f83927"
    },
    {
        "pr_title": "bigquery: add ML model samples",
        "pr_number": 873,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -817,6 +825,24 @@\nfunc updateTableChangeCMEK(client *bigquery.Client, datasetID, tableID string) e\n \treturn nil\n }\n \n+func updateModelDescription(client *bigquery.Client, datasetID, modelID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_model_description]\n+\tmodel := client.Dataset(datasetID).Model(modelID)\n+\toldMeta, err := model.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"Metadata: %v\", err)\n+\t}\n+\tupdate := bigquery.ModelMetadataToUpdate{\n+\t\tDescription: \"This model was modified from a Go program\",\n+\t}\n+\tif _, err = model.Update(ctx, update, oldMeta.ETag); err != nil {\n+\t\treturn fmt.Errorf(\"Update: %v\", err)\n+\t}\n+\t// [END bigquery_update_model_description]\n+\treturn nil\n+}\n+\n func updateTableDescription(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_table_description]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "421616cc9e0d76204af6ac8ee230be83b2f83927"
    },
    {
        "pr_title": "bigquery: add ML model samples",
        "pr_number": 873,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -987,6 +1013,25 @@\nfunc deleteTableLabel(client *bigquery.Client, datasetID, tableID string) error\n \treturn nil\n }\n \n+func listModels(client *bigquery.Client, w io.Writer, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_list_models]\n+\tfmt.Fprintf(w, \"Models contained in dataset '%s'\\n\", datasetID)\n+\tit := client.Dataset(datasetID).Models(ctx)\n+\tfor {\n+\t\tm, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"Model: %s\\n\", m.FullyQualifiedName())\n+\t}\n+\t// [END bigquery_list_models]\n+\treturn nil\n+}\n+\n func listTables(client *bigquery.Client, w io.Writer, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_list_tables]",
        "comments": [],
        "commit_messages": [
            "bigquery: add ML model samples"
        ],
        "last_commit_sha": "421616cc9e0d76204af6ac8ee230be83b2f83927"
    },
    {
        "pr_title": "bigquery: add ML model samples",
        "pr_number": 873,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1325,6 +1370,18 @@\nfunc printTableInfo(client *bigquery.Client, w io.Writer, datasetID, tableID str\n \treturn nil\n }\n \n+func printModelInfo(client *bigquery.Client, w io.Writer, datasetID, modelID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_model]\n+\tmeta, err := client.Dataset(datasetID).Model(modelID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"Metadata: %v\", err)\n+\t}\n+\tfmt.Fprintf(w, \"Got model '%q' with friendly name '%q'\\n\", modelID, meta.Name)\n+\t// [END bigquery_get_model]\n+\treturn nil\n+}\n+\n func browseTable(client *bigquery.Client, w io.Writer, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_browse_table]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "421616cc9e0d76204af6ac8ee230be83b2f83927"
    },
    {
        "pr_title": "spanner: more updates to samples that transfer money",
        "pr_number": 871,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -548,22 +548,20 @@\nfunc writeWithTransaction(ctx context.Context, w io.Writer, client *spanner.Clie\n \t\tif err != nil {\n \t\t\treturn err\n \t\t}\n-\t\tif album2Budget >= 300000 {\n+\t\tconst transferAmt = 200000\n+\t\tif album2Budget >= transferAmt {\n \t\t\talbum1Budget, err := getBudget(spanner.Key{1, 1})\n \t\t\tif err != nil {\n \t\t\t\treturn err\n \t\t\t}\n-\t\t\tconst transfer = 100000\n-\t\t\tif album1Budget >= transfer {\n-\t\t\t\talbum1Budget -= transfer\n-\t\t\t\talbum2Budget += transfer\n-\t\t\t\tcols := []string{\"SingerId\", \"AlbumId\", \"MarketingBudget\"}\n-\t\t\t\ttxn.BufferWrite([]*spanner.Mutation{\n-\t\t\t\t\tspanner.Update(\"Albums\", cols, []interface{}{1, 1, album1Budget}),\n-\t\t\t\t\tspanner.Update(\"Albums\", cols, []interface{}{2, 2, album2Budget}),\n-\t\t\t\t})\n-\t\t\t\tfmt.Fprintf(w, \"Moved %d from Album1's MarketingBudget to Album2's.\", transfer)\n-\t\t\t}\n+\t\t\talbum1Budget += transferAmt\n+\t\t\talbum2Budget -= transferAmt\n+\t\t\tcols := []string{\"SingerId\", \"AlbumId\", \"MarketingBudget\"}\n+\t\t\ttxn.BufferWrite([]*spanner.Mutation{\n+\t\t\t\tspanner.Update(\"Albums\", cols, []interface{}{1, 1, album1Budget}),\n+\t\t\t\tspanner.Update(\"Albums\", cols, []interface{}{2, 2, album2Budget}),\n+\t\t\t})\n+\t\t\tfmt.Fprintf(w, \"Moved %d from Album2's MarketingBudget to Album1's.\", transferAmt)\n \t\t}\n \t\treturn nil\n \t})",
        "comments": [],
        "commit_messages": [
            "spanner: more updates to samples that transfer money\n\nThese changes iterate on #856 to address some requests from @jsimonweb:\n\n- Move $200,000 from Album2 to Album1, rather than $100,000 from Album1 to Album2.\n- Just check the transfer amount against the Album2 budget, not another arbitrary number.\n\nThese changes reduce the scope of updates to other code samples and docs."
        ],
        "last_commit_sha": "61a7349cc7d6bd4d0fb96e47e67bb21fb94f2a98"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -16,7 +16,8 @@\npackage kms\n \n import (\n \t\"context\"\n-\t\"log\"\n+\t\"fmt\"\n+\t\"io\"\n \n \t\"cloud.google.com/go/iam\"\n \tcloudkms \"cloud.google.com/go/kms/apiv1\"",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -28,7 +29,7 @@\nimport (\n \n // createKeyRing creates a new ring to store keys on KMS.\n // example parentName: \"projects/PROJECT_ID/locations/global/\"\n-func createKeyRing(parentName, keyRingId string) error {\n+func createKeyRing(w io.Writer, parentName, keyRingID string) error {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -37,14 +38,14 @@\nfunc createKeyRing(parentName, keyRingId string) error {\n \t// Build the request.\n \treq := &kmspb.CreateKeyRingRequest{\n \t\tParent:    parentName,\n-\t\tKeyRingId: keyRingId,\n+\t\tKeyRingId: keyRingID,\n \t}\n \t// Call the API.\n \tresult, err := client.CreateKeyRing(ctx, req)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tlog.Printf(\"Created key ring: %s\", result)\n+\tfmt.Fprintf(w, \"Created key ring: %s\", result)\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -54,7 +55,7 @@\nfunc createKeyRing(parentName, keyRingId string) error {\n \n // createCryptoKey creates a new symmetric encrypt/decrypt key on KMS.\n // example keyRingName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID\"\n-func createCryptoKey(keyRingName, keyId string) error {\n+func createCryptoKey(w io.Writer, keyRingName, keyID string) error {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -64,7 +65,7 @@\nfunc createCryptoKey(keyRingName, keyId string) error {\n \t// Build the request.\n \treq := &kmspb.CreateCryptoKeyRequest{\n \t\tParent:      keyRingName,\n-\t\tCryptoKeyId: keyId,\n+\t\tCryptoKeyId: keyID,\n \t\tCryptoKey: &kmspb.CryptoKey{\n \t\t\tPurpose: kmspb.CryptoKey_ENCRYPT_DECRYPT,\n \t\t\tVersionTemplate: &kmspb.CryptoKeyVersionTemplate{",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -77,7 +78,7 @@\nfunc createCryptoKey(keyRingName, keyId string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tlog.Printf(\"Created crypto key. %s\", result)\n+\tfmt.Fprintf(w, \"Created crypto key. %s\", result)\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -87,7 +88,7 @@\nfunc createCryptoKey(keyRingName, keyId string) error {\n \n // disableCryptoKeyVersion disables a specified key version on KMS.\n // example keyVersionName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n-func disableCryptoKeyVersion(keyVersionName string) error {\n+func disableCryptoKeyVersion(w io.Writer, keyVersionName string) error {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -108,7 +109,7 @@\nfunc disableCryptoKeyVersion(keyVersionName string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tlog.Printf(\"Disabled crypto key version: %s\", result)\n+\tfmt.Fprintf(w, \"Disabled crypto key version: %s\", result)\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -118,7 +119,7 @@\nfunc disableCryptoKeyVersion(keyVersionName string) error {\n \n // enableCryptoKeyVersion enables a previously disabled key version on KMS.\n // example keyVersionName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n-func enableCryptoKeyVersion(keyVersionName string) error {\n+func enableCryptoKeyVersion(w io.Writer, keyVersionName string) error {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -139,7 +140,7 @@\nfunc enableCryptoKeyVersion(keyVersionName string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tlog.Printf(\"Enabled crypto key version: %s\", result)\n+\tfmt.Fprintf(w, \"Enabled crypto key version: %s\", result)\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -149,7 +150,7 @@\nfunc enableCryptoKeyVersion(keyVersionName string) error {\n \n // destroyCryptoKeyVersion marks a specified key version for deletion. The key can be restored if requested within 24 hours.\n // example keyVersionName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n-func destroyCryptoKeyVersion(keyVersionName string) error {\n+func destroyCryptoKeyVersion(w io.Writer, keyVersionName string) error {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -164,7 +165,7 @@\nfunc destroyCryptoKeyVersion(keyVersionName string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tlog.Printf(\"Destroyed crypto key version: %s\", result)\n+\tfmt.Fprintf(w, \"Destroyed crypto key version: %s\", result)\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -174,7 +175,7 @@\nfunc destroyCryptoKeyVersion(keyVersionName string) error {\n \n // restoreCryptoKeyVersion attempts to recover a key that has been marked for destruction within the last 24 hours.\n // example keyVersionName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n-func restoreCryptoKeyVersion(keyVersionName string) error {\n+func restoreCryptoKeyVersion(w io.Writer, keyVersionName string) error {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -189,7 +190,7 @@\nfunc restoreCryptoKeyVersion(keyVersionName string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tlog.Printf(\"Restored crypto key version: %s\", result)\n+\tfmt.Fprintf(w, \"Restored crypto key version: %s\", result)\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -199,7 +200,7 @@\nfunc restoreCryptoKeyVersion(keyVersionName string) error {\n \n // getRingPolicy retrieves and prints the IAM policy associated with the key ring\n // example keyRingName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID\"\n-func getRingPolicy(keyRingName string) (*iam.Policy, error) {\n+func getRingPolicy(w io.Writer, keyRingName string) (*iam.Policy, error) {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -218,7 +219,7 @@\nfunc getRingPolicy(keyRingName string) (*iam.Policy, error) {\n \t}\n \tfor _, role := range policy.Roles() {\n \t\tfor _, member := range policy.Members(role) {\n-\t\t\tlog.Printf(\"Role: %s Member: %s\\n\", role, member)\n+\t\t\tfmt.Fprintf(w, \"Role: %s Member: %s\\n\", role, member)\n \t\t}\n \t}\n \treturn policy, nil",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -230,7 +231,7 @@\nfunc getRingPolicy(keyRingName string) (*iam.Policy, error) {\n \n // getCryptoKeyPolicy retrieves and prints the IAM policy associated with the key\n // example keyName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID\"\n-func getCryptoKeyPolicy(keyName string) (*iam.Policy, error) {\n+func getCryptoKeyPolicy(w io.Writer, keyName string) (*iam.Policy, error) {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -249,7 +250,7 @@\nfunc getCryptoKeyPolicy(keyName string) (*iam.Policy, error) {\n \t}\n \tfor _, role := range policy.Roles() {\n \t\tfor _, member := range policy.Members(role) {\n-\t\t\tlog.Printf(\"Role: %s Member: %s\\n\", role, member)\n+\t\t\tfmt.Fprintf(w, \"Role: %s Member: %s\\n\", role, member)\n \t\t}\n \t}\n \treturn policy, nil",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -261,7 +262,7 @@\nfunc getCryptoKeyPolicy(keyName string) (*iam.Policy, error) {\n \n // addMemberRingPolicy adds a new member to a specified IAM role for the key ring\n // example keyRingName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID\"\n-func addMemberRingPolicy(keyRingName, member string, role iam.RoleName) error {\n+func addMemberRingPolicy(w io.Writer, keyRingName, member string, role iam.RoleName) error {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -285,7 +286,7 @@\nfunc addMemberRingPolicy(keyRingName, member string, role iam.RoleName) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tlog.Print(\"Added member to keyring policy.\")\n+\tfmt.Fprint(w, \"Added member to keyring policy.\")\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -295,7 +296,7 @@\nfunc addMemberRingPolicy(keyRingName, member string, role iam.RoleName) error {\n \n // removeMemberRingPolicy removes a specified member from an IAM role for the key ring\n // example keyRingName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID\"\n-func removeMemberRingPolicy(keyRingName, member string, role iam.RoleName) error {\n+func removeMemberRingPolicy(w io.Writer, keyRingName, member string, role iam.RoleName) error {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -320,7 +321,7 @@\nfunc removeMemberRingPolicy(keyRingName, member string, role iam.RoleName) error\n \tif err != nil {\n \t\treturn err\n \t}\n-\tlog.Print(\"Removed member from keyring policy.\")\n+\tfmt.Fprint(w, \"Removed member from keyring policy.\")\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -330,7 +331,7 @@\nfunc removeMemberRingPolicy(keyRingName, member string, role iam.RoleName) error\n \n // addMemberCryptoKeyPolicy adds a new member to a specified IAM role for the key\n // example keyName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID\"\n-func addMemberCryptoKeyPolicy(keyName, member string, role iam.RoleName) error {\n+func addMemberCryptoKeyPolicy(w io.Writer, keyName, member string, role iam.RoleName) error {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -354,7 +355,7 @@\nfunc addMemberCryptoKeyPolicy(keyName, member string, role iam.RoleName) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tlog.Print(\"Added member to cryptokey policy.\")\n+\tfmt.Fprint(w, \"Added member to cryptokey policy.\")\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -364,7 +365,7 @@\nfunc addMemberCryptoKeyPolicy(keyName, member string, role iam.RoleName) error {\n \n // removeMemberCryptoKeyPolicy removes a specified member from an IAM role for the key\n // example keyName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID\"\n-func removeMemberCryptoKeyPolicy(keyName, member string, role iam.RoleName) error {\n+func removeMemberCryptoKeyPolicy(w io.Writer, keyName, member string, role iam.RoleName) error {\n \tctx := context.Background()\n \tclient, err := cloudkms.NewKeyManagementClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -17,6 +17,7 @@\npackage kms\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"io/ioutil\"\n \t\"os\"\n \t\"strconv\"\n \t\"strings\"",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -31,7 +32,7 @@\nimport (\n \n type TestVariables struct {\n \tctx            context.Context\n-\tprojectId      string\n+\tprojectID      string\n \tmessage        string\n \tlocation       string\n \tparent         string",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -44,10 +45,10 @@\ntype TestVariables struct {\n \trsaDecryptPath string\n \trsaSignPath    string\n \tecSignPath     string\n-\tsymId          string\n-\trsaDecryptId   string\n-\trsaSignId      string\n-\tecSignId       string\n+\tsymID          string\n+\trsaDecryptID   string\n+\trsaSignID      string\n+\tecSignID       string\n \ttryLimit       int\n \twaitTime       time.Duration\n }",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -59,16 +60,16 @@\nfunc getTestVariables(projectID string) TestVariables {\n \tkeyRing := \"kms-samples\"\n \tkeyRingPath := parent + \"/keyRings/\" + keyRing\n \n-\tsymId := \"symmetric\"\n-\trsaDecryptId := \"rsa-decrypt\"\n-\trsaSignId := \"rsa-sign\"\n-\tecSignId := \"ec-sign\"\n+\tsymID := \"symmetric\"\n+\trsaDecryptID := \"rsa-decrypt\"\n+\trsaSignID := \"rsa-sign\"\n+\tecSignID := \"ec-sign\"\n \n-\tsym := keyRingPath + \"/cryptoKeys/\" + symId\n+\tsym := keyRingPath + \"/cryptoKeys/\" + symID\n \tsymVersion := sym + \"/cryptoKeyVersions/1\"\n-\trsaDecrypt := keyRingPath + \"/cryptoKeys/\" + rsaDecryptId + \"/cryptoKeyVersions/2\"\n-\trsaSign := keyRingPath + \"/cryptoKeys/\" + rsaSignId + \"/cryptoKeyVersions/1\"\n-\tecSign := keyRingPath + \"/cryptoKeys/\" + ecSignId + \"/cryptoKeyVersions/1\"\n+\trsaDecrypt := keyRingPath + \"/cryptoKeys/\" + rsaDecryptID + \"/cryptoKeyVersions/2\"\n+\trsaSign := keyRingPath + \"/cryptoKeys/\" + rsaSignID + \"/cryptoKeyVersions/1\"\n+\tecSign := keyRingPath + \"/cryptoKeys/\" + ecSignID + \"/cryptoKeyVersions/1\"\n \n \tmessage := \"test message 123\"",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -81,19 +82,19 @@\nfunc getTestVariables(projectID string) TestVariables {\n \twaitTime := 5 * time.Second\n \n \tv = TestVariables{ctx, projectID, message, location, parent, member, role, keyRing, keyRingPath,\n-\t\tsym, symVersion, rsaDecrypt, rsaSign, ecSign, symId, rsaDecryptId, rsaSignId, ecSignId, tryLimit, waitTime}\n+\t\tsym, symVersion, rsaDecrypt, rsaSign, ecSign, symID, rsaDecryptID, rsaSignID, ecSignID, tryLimit, waitTime}\n \treturn v\n }\n \n-func createKeyHelper(v TestVariables, keyId, keyPath, parent string,\n+func createKeyHelper(v TestVariables, keyID, keyPath, parent string,\n \tpurpose kmspb.CryptoKey_CryptoKeyPurpose, algorithm kmspb.CryptoKeyVersion_CryptoKeyVersionAlgorithm) bool {\n \tclient, _ := cloudkms.NewKeyManagementClient(v.ctx)\n \tif _, err := getAsymmetricPublicKey(keyPath); err != nil {\n \t\tversionObj := &kmspb.CryptoKeyVersionTemplate{Algorithm: algorithm}\n \t\tkeyObj := &kmspb.CryptoKey{Purpose: purpose, VersionTemplate: versionObj}\n \n \t\tclient.CreateKeyRing(v.ctx, &kmspb.CreateKeyRingRequest{Parent: parent, KeyRingId: v.keyRing})\n-\t\tclient.CreateCryptoKey(v.ctx, &kmspb.CreateCryptoKeyRequest{Parent: parent + \"/keyRings/\" + v.keyRing, CryptoKeyId: keyId, CryptoKey: keyObj})\n+\t\tclient.CreateCryptoKey(v.ctx, &kmspb.CreateCryptoKeyRequest{Parent: parent + \"/keyRings/\" + v.keyRing, CryptoKeyId: keyID, CryptoKey: keyObj})\n \t\treturn true\n \t}\n \treturn false",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -102,20 +103,20 @@\nfunc createKeyHelper(v TestVariables, keyId, keyPath, parent string,\n func TestMain(m *testing.M) {\n \ttc, _ := testutil.ContextMain(m)\n \tv := getTestVariables(tc.ProjectID)\n-\tparent := \"projects/\" + v.projectId + \"/locations/global\"\n+\tparent := \"projects/\" + v.projectID + \"/locations/global\"\n \t// Create cryptokeys in the test project if needed.\n-\ts1 := createKeyHelper(v, v.rsaDecryptId, v.rsaDecryptPath, parent, kmspb.CryptoKey_ASYMMETRIC_DECRYPT, kmspb.CryptoKeyVersion_RSA_DECRYPT_OAEP_2048_SHA256)\n-\ts2 := createKeyHelper(v, v.rsaSignId, v.rsaSignPath, parent, kmspb.CryptoKey_ASYMMETRIC_SIGN, kmspb.CryptoKeyVersion_RSA_SIGN_PSS_2048_SHA256)\n-\ts3 := createKeyHelper(v, v.ecSignId, v.ecSignPath, parent, kmspb.CryptoKey_ASYMMETRIC_SIGN, kmspb.CryptoKeyVersion_EC_SIGN_P256_SHA256)\n-\ts4 := createKeyHelper(v, v.symId, v.symPath, parent, kmspb.CryptoKey_ENCRYPT_DECRYPT, kmspb.CryptoKeyVersion_GOOGLE_SYMMETRIC_ENCRYPTION)\n+\ts1 := createKeyHelper(v, v.rsaDecryptID, v.rsaDecryptPath, parent, kmspb.CryptoKey_ASYMMETRIC_DECRYPT, kmspb.CryptoKeyVersion_RSA_DECRYPT_OAEP_2048_SHA256)\n+\ts2 := createKeyHelper(v, v.rsaSignID, v.rsaSignPath, parent, kmspb.CryptoKey_ASYMMETRIC_SIGN, kmspb.CryptoKeyVersion_RSA_SIGN_PSS_2048_SHA256)\n+\ts3 := createKeyHelper(v, v.ecSignID, v.ecSignPath, parent, kmspb.CryptoKey_ASYMMETRIC_SIGN, kmspb.CryptoKeyVersion_EC_SIGN_P256_SHA256)\n+\ts4 := createKeyHelper(v, v.symID, v.symPath, parent, kmspb.CryptoKey_ENCRYPT_DECRYPT, kmspb.CryptoKeyVersion_GOOGLE_SYMMETRIC_ENCRYPTION)\n \tif s1 || s2 || s3 || s4 {\n \t\t// Leave time for keys to initialize.\n \t\ttime.Sleep(30 * time.Second)\n \t}\n \t// Restore any disabled keys\n \tfor _, keyPath := range []string{v.symVersionPath, v.rsaDecryptPath, v.ecSignPath} {\n-\t\trestoreCryptoKeyVersion(keyPath)\n-\t\tenableCryptoKeyVersion(keyPath)\n+\t\trestoreCryptoKeyVersion(ioutil.Discard, keyPath)\n+\t\tenableCryptoKeyVersion(ioutil.Discard, keyPath)\n \t}\n \t// Run tests.\n \texitCode := m.Run()",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -127,18 +128,18 @@\nfunc TestCreateKeyRing(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tv := getTestVariables(tc.ProjectID)\n \n-\tringId := v.keyRing + \"testcreate\"\n-\terr := createKeyRing(v.parent, ringId)\n+\tringID := v.keyRing + \"testcreate\"\n+\terr := createKeyRing(ioutil.Discard, v.parent, ringID)\n \tif err != nil {\n-\t\tt.Fatalf(\"createKeyRing(%s, %s): %v\", v.projectId, ringId, err)\n+\t\tt.Fatalf(\"createKeyRing(%s, %s): %v\", v.projectID, ringID, err)\n \t}\n \tclient, _ := cloudkms.NewKeyManagementClient(v.ctx)\n-\tresp, err := client.GetKeyRing(v.ctx, &kmspb.GetKeyRingRequest{Name: ringId})\n+\tresp, err := client.GetKeyRing(v.ctx, &kmspb.GetKeyRingRequest{Name: ringID})\n \tif err != nil {\n-\t\tt.Fatalf(\"GetKeyRing(%s): %v\", ringId, err)\n+\t\tt.Fatalf(\"GetKeyRing(%s): %v\", ringID, err)\n \t}\n-\tif !strings.Contains(resp.Name, ringId) {\n-\t\tt.Fatalf(\"new ring %s does not contain requested id %s: %v\", resp.Name, ringId, err)\n+\tif !strings.Contains(resp.Name, ringID) {\n+\t\tt.Fatalf(\"new ring %s does not contain requested ID %s: %v\", resp.Name, ringID, err)\n \t}\n }",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -147,22 +148,22 @@\nfunc TestCreateCryptoKey(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tv := getTestVariables(tc.ProjectID)\n \n-\tkeyId := \"test-\" + strconv.Itoa(int(time.Now().Unix()))\n-\terr := createCryptoKey(v.keyRingPath, keyId)\n+\tkeyID := \"test-\" + strconv.Itoa(int(time.Now().Unix()))\n+\terr := createCryptoKey(ioutil.Discard, v.keyRingPath, keyID)\n \tif err != nil {\n-\t\tt.Fatalf(\"createKey(%s, %s): %v\", v.keyRingPath, keyId, err)\n+\t\tt.Fatalf(\"createKey(%s, %s): %v\", v.keyRingPath, keyID, err)\n \t}\n \tclient, _ := cloudkms.NewKeyManagementClient(v.ctx)\n-\tkeyPath := v.keyRingPath + \"/cryptoKeys/\" + keyId\n+\tkeyPath := v.keyRingPath + \"/cryptoKeys/\" + keyID\n \tresp, err := client.GetCryptoKey(v.ctx, &kmspb.GetCryptoKeyRequest{Name: keyPath})\n \tif err != nil {\n \t\tt.Fatalf(\"GetCryptoKey(%s): %v\", keyPath, err)\n \t}\n-\tif !strings.Contains(resp.Name, keyId) {\n-\t\tt.Fatalf(\"new key %s does not contain requested id %s: %v\", resp.Name, keyId, err)\n+\tif !strings.Contains(resp.Name, keyID) {\n+\t\tt.Fatalf(\"new key %s does not contain requested ID %s: %v\", resp.Name, keyID, err)\n \t}\n \t// mark for destruction\n-\tdestroyCryptoKeyVersion(keyPath + \"/cryptoKeyVersions/1\")\n+\tdestroyCryptoKeyVersion(ioutil.Discard, keyPath+\"/cryptoKeyVersions/1\")\n }\n \n // tests disable/enable/destroy/restore",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -174,7 +175,7 @@\nfunc TestChangeKeyVersionState(t *testing.T) {\n \tfor _, keyPath := range []string{v.symVersionPath, v.rsaDecryptPath, v.ecSignPath} {\n \t\t// test disable\n \t\ttestutil.Retry(t, v.tryLimit, v.waitTime, func(r *testutil.R) {\n-\t\t\tif err := disableCryptoKeyVersion(keyPath); err != nil {\n+\t\t\tif err := disableCryptoKeyVersion(ioutil.Discard, keyPath); err != nil {\n \t\t\t\tr.Errorf(\"disableCryptoKeyVersion(%s): %v\", keyPath, err)\n \t\t\t}\n \t\t\tresp, err := client.GetCryptoKeyVersion(v.ctx, &kmspb.GetCryptoKeyVersionRequest{Name: keyPath})",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -187,7 +188,7 @@\nfunc TestChangeKeyVersionState(t *testing.T) {\n \t\t})\n \t\t// test destroy\n \t\ttestutil.Retry(t, v.tryLimit, v.waitTime, func(r *testutil.R) {\n-\t\t\tif err := destroyCryptoKeyVersion(keyPath); err != nil {\n+\t\t\tif err := destroyCryptoKeyVersion(ioutil.Discard, keyPath); err != nil {\n \t\t\t\tr.Errorf(\"destroyCryptoKeyVersion(%s): %v\", keyPath, err)\n \t\t\t}\n \t\t\tresp, err := client.GetCryptoKeyVersion(v.ctx, &kmspb.GetCryptoKeyVersionRequest{Name: keyPath})",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -200,7 +201,7 @@\nfunc TestChangeKeyVersionState(t *testing.T) {\n \t\t})\n \t\t// test restore\n \t\ttestutil.Retry(t, v.tryLimit, v.waitTime, func(r *testutil.R) {\n-\t\t\tif err := restoreCryptoKeyVersion(keyPath); err != nil {\n+\t\t\tif err := restoreCryptoKeyVersion(ioutil.Discard, keyPath); err != nil {\n \t\t\t\tr.Errorf(\"restoreCryptoKeyVersion(%s): %v\", keyPath, err)\n \t\t\t}\n \t\t\tresp, err := client.GetCryptoKeyVersion(v.ctx, &kmspb.GetCryptoKeyVersionRequest{Name: keyPath})",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -213,7 +214,7 @@\nfunc TestChangeKeyVersionState(t *testing.T) {\n \t\t})\n \t\t// test re-enable\n \t\ttestutil.Retry(t, v.tryLimit, v.waitTime, func(r *testutil.R) {\n-\t\t\tif err := enableCryptoKeyVersion(keyPath); err != nil {\n+\t\t\tif err := enableCryptoKeyVersion(ioutil.Discard, keyPath); err != nil {\n \t\t\t\tr.Errorf(\"enableCryptoKeyVersion(%s): %v\", keyPath, err)\n \t\t\t}\n \t\t\tresp, err := client.GetCryptoKeyVersion(v.ctx, &kmspb.GetCryptoKeyVersionRequest{Name: keyPath})",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -231,7 +232,7 @@\nfunc TestGetRingPolicy(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tv := getTestVariables(tc.ProjectID)\n \n-\tpolicy, err := getRingPolicy(v.keyRingPath)\n+\tpolicy, err := getRingPolicy(ioutil.Discard, v.keyRingPath)\n \tif err != nil {\n \t\tt.Fatalf(\"GetRingPolicy(%s): %v\", v.keyRingPath, err)\n \t}",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -246,11 +247,11 @@\nfunc TestAddMemberRingPolicy(t *testing.T) {\n \n \t// add member\n \ttestutil.Retry(t, v.tryLimit, v.waitTime, func(r *testutil.R) {\n-\t\tif err := addMemberRingPolicy(v.keyRingPath, v.member, v.role); err != nil {\n+\t\tif err := addMemberRingPolicy(ioutil.Discard, v.keyRingPath, v.member, v.role); err != nil {\n \t\t\tr.Errorf(\"addMemberRingPolicy(%s, %s, %s): %v\", v.keyRingPath, v.member, v.role, err)\n \t\t}\n \t})\n-\tpolicy, _ := getRingPolicy(v.keyRingPath)\n+\tpolicy, _ := getRingPolicy(ioutil.Discard, v.keyRingPath)\n \tfound := false\n \tfor _, m := range policy.Members(v.role) {\n \t\tif m == v.member {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -262,11 +263,11 @@\nfunc TestAddMemberRingPolicy(t *testing.T) {\n \t}\n \t// remove member\n \ttestutil.Retry(t, v.tryLimit, v.waitTime, func(r *testutil.R) {\n-\t\tif err := removeMemberRingPolicy(v.keyRingPath, v.member, v.role); err != nil {\n+\t\tif err := removeMemberRingPolicy(ioutil.Discard, v.keyRingPath, v.member, v.role); err != nil {\n \t\t\tr.Errorf(\"removeMemberCryptoKeyPolicy(%s, %s, %s): %v\", v.symPath, v.member, v.role, err)\n \t\t}\n \t})\n-\tpolicy, _ = getRingPolicy(v.keyRingPath)\n+\tpolicy, _ = getRingPolicy(ioutil.Discard, v.keyRingPath)\n \tfound = false\n \tfor _, m := range policy.Members(v.role) {\n \t\tif m == v.member {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "kms: print to io.Writers",
        "pr_number": 867,
        "file_name": "kms/snippets_test.go",
        "code_diff": "@@ -282,16 +283,16 @@\nfunc TestAddRemoveMemberCryptoKey(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tv := getTestVariables(tc.ProjectID)\n \n-\trsaPath := v.keyRingPath + \"/cryptoKeys/\" + v.rsaDecryptId\n-\tecPath := v.keyRingPath + \"/cryptoKeys/\" + v.ecSignId\n+\trsaPath := v.keyRingPath + \"/cryptoKeys/\" + v.rsaDecryptID\n+\tecPath := v.keyRingPath + \"/cryptoKeys/\" + v.ecSignID\n \tfor _, keyPath := range []string{v.symPath, rsaPath, ecPath} {\n \t\t// add member\n \t\ttestutil.Retry(t, v.tryLimit, v.waitTime, func(r *testutil.R) {\n-\t\t\tif err := addMemberCryptoKeyPolicy(keyPath, v.member, v.role); err != nil {\n+\t\t\tif err := addMemberCryptoKeyPolicy(ioutil.Discard, keyPath, v.member, v.role); err != nil {\n \t\t\t\tr.Errorf(\"addMemberCryptoKeyPolicy(%s, %s, %s): %v\", keyPath, v.member, v.role, err)\n \t\t\t}\n \t\t})\n-\t\tpolicy, _ := getCryptoKeyPolicy(keyPath)\n+\t\tpolicy, _ := getCryptoKeyPolicy(ioutil.Discard, keyPath)\n \t\tfound := false\n \t\tfor _, m := range policy.Members(v.role) {\n \t\t\tif m == v.member {",
        "comments": [],
        "commit_messages": [
            "kms: print to io.Writers"
        ],
        "last_commit_sha": "d560e5c5022cf513b7d461ad48eff89cf0abf99b"
    },
    {
        "pr_title": "spanner: add queryWithParameter sample",
        "pr_number": 853,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -73,6 +73,7 @@\nvar (\n \t\t\"dmlwriteread\":               writeAndReadUsingDML,\n \t\t\"dmlupdatestruct\":            updateUsingDMLStruct,\n \t\t\"dmlwrite\":                   writeUsingDML,\n+\t\t\"querywithparameter\":         queryWithParameter,\n \t\t\"dmlwritetxn\":                writeWithTransactionUsingDML,\n \t\t\"dmlupdatepart\":              updateUsingPartitionedDML,\n \t\t\"dmldeletepart\":              deleteUsingPartitionedDML,",
        "comments": [],
        "commit_messages": [
            "Add queryWithParameter to Cloud Spanner sample."
        ],
        "last_commit_sha": "9e9d6adbe8f45adda636d1d21eaddc0399ecf907"
    },
    {
        "pr_title": "spanner: add queryWithParameter sample",
        "pr_number": 853,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -1120,6 +1121,37 @@\nfunc writeUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) err\n \n // [END spanner_dml_getting_started_insert]\n \n+// [START spanner_query_with_parameter]\n+\n+func queryWithParameter(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT SingerId, FirstName, LastName FROM Singers\n+\t\t\tWHERE LastName = @lastName`,\n+\t\tParams: map[string]interface{}{\n+\t\t\t\"lastName\": \"Garcia\",\n+\t\t},\n+\t}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar singerID int64\n+\t\tvar firstName, lastName string\n+\t\tif err := row.Columns(&singerID, &firstName, &lastName); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %s %s\\n\", singerID, firstName, lastName)\n+\t}\n+}\n+\n+// [END spanner_query_with_parameter]\n+\n // [START spanner_dml_getting_started_update]\n \n func writeWithTransactionUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "9e9d6adbe8f45adda636d1d21eaddc0399ecf907"
    },
    {
        "pr_title": "healthcare: more samples",
        "pr_number": 843,
        "file_name": "healthcare/dicom_store_get.go",
        "code_diff": "@@ -29,7 +29,7 @@\nfunc getDICOMStore(w io.Writer, projectID, location, datasetID, dicomStoreID str\n \n \thealthcareService, err := healthcare.NewService(ctx)\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"healthcare.New: %v\", err)\n+\t\treturn fmt.Errorf(\"healthcare.NewService: %v\", err)\n \t}\n \n \tstoresService := healthcareService.Projects.Locations.Datasets.DicomStores",
        "comments": [],
        "commit_messages": [
            "healthcare: more samples"
        ],
        "last_commit_sha": "c8f3cc8503acaf17a60dddbc272d42c825d1c027"
    },
    {
        "pr_title": "healthcare: more samples",
        "pr_number": 843,
        "file_name": "healthcare/dicom_test.go",
        "code_diff": "@@ -34,6 +34,16 @@\nfunc TestDICOMStore(t *testing.T) {\n \tlocation := \"us-central1\"\n \tdatasetID := \"dicom-dataset\"\n \tdicomStoreID := \"my-dicom-store\"\n+\n+\t// Delete test dataset if it already exists.\n+\tif err := getDataset(buf, tc.ProjectID, location, datasetID); err == nil {\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\tif err := deleteDataset(ioutil.Discard, tc.ProjectID, location, datasetID); err != nil {\n+\t\t\t\tr.Errorf(\"deleteDataset got err: %v\", err)\n+\t\t\t}\n+\t\t})\n+\t}\n+\n \tif err := createDataset(ioutil.Discard, tc.ProjectID, location, datasetID); err != nil {\n \t\tt.Skipf(\"Unable to create test dataset: %v\", err)\n \t\treturn",
        "comments": [],
        "commit_messages": [
            "healthcare: more samples"
        ],
        "last_commit_sha": "c8f3cc8503acaf17a60dddbc272d42c825d1c027"
    },
    {
        "pr_title": "healthcare: more samples",
        "pr_number": 843,
        "file_name": "healthcare/fhir_test.go",
        "code_diff": "@@ -16,13 +16,17 @@\npackage snippets\n \n import (\n \t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n // TestFHIRStore runs all FHIR store tests to avoid having to",
        "comments": [],
        "commit_messages": [
            "healthcare: more samples"
        ],
        "last_commit_sha": "c8f3cc8503acaf17a60dddbc272d42c825d1c027"
    },
    {
        "pr_title": "healthcare: more samples",
        "pr_number": 843,
        "file_name": "healthcare/fhir_test.go",
        "code_diff": "@@ -34,6 +38,17 @@\nfunc TestFHIRStore(t *testing.T) {\n \tlocation := \"us-central1\"\n \tdatasetID := \"fhir-dataset\"\n \tfhirStoreID := \"my-fhir-store\"\n+\tresourceType := \"Patient\"\n+\n+\t// Delete test dataset if it already exists.\n+\tif err := getDataset(buf, tc.ProjectID, location, datasetID); err == nil {\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\tif err := deleteDataset(ioutil.Discard, tc.ProjectID, location, datasetID); err != nil {\n+\t\t\t\tr.Errorf(\"deleteDataset got err: %v\", err)\n+\t\t\t}\n+\t\t})\n+\t}\n+\n \tif err := createDataset(ioutil.Discard, tc.ProjectID, location, datasetID); err != nil {\n \t\tt.Skipf(\"Unable to create test dataset: %v\", err)\n \t\treturn",
        "comments": [],
        "commit_messages": [
            "healthcare: more samples"
        ],
        "last_commit_sha": "c8f3cc8503acaf17a60dddbc272d42c825d1c027"
    },
    {
        "pr_title": "healthcare: more samples",
        "pr_number": 843,
        "file_name": "healthcare/fhir_test.go",
        "code_diff": "@@ -53,6 +68,185 @@\nfunc TestFHIRStore(t *testing.T) {\n \t\t}\n \t})\n \n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tbuf.Reset()\n+\t\tif err := createFHIRResource(buf, tc.ProjectID, location, datasetID, fhirStoreID, resourceType); err != nil {\n+\t\t\tr.Errorf(\"createFHIRResource got err: %v\", err)\n+\t\t}\n+\t})\n+\n+\ttype resource struct {\n+\t\tActive bool\n+\t\tID     string\n+\t\tMeta   struct {\n+\t\t\tVersionID string // Used for getFHIRResourceHistory.\n+\t\t}\n+\t}\n+\tres := resource{}\n+\tif err := json.Unmarshal(buf.Bytes(), &res); err != nil {\n+\t\tt.Errorf(\"json.Unmarshal createFHIRResource output: %v\", err)\n+\t}\n+\n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tbuf.Reset()\n+\t\tif err := getFHIRMetadata(buf, tc.ProjectID, location, datasetID, fhirStoreID); err != nil {\n+\t\t\tr.Errorf(\"getFHIRMetadata got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, fhirStoreID) {\n+\t\t\tr.Errorf(\"getFHIRMetadata got \\n----\\n%s\\n----\\nWant to contain:\\n----\\n%s\\n----\\n\", got, fhirStoreID)\n+\t\t}\n+\t})\n+\n+\tbuf.Reset()\n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tif err := getFHIRResource(buf, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, res.ID); err != nil {\n+\t\t\tr.Errorf(\"getFHIRResource got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, res.ID) {\n+\t\t\tr.Errorf(\"getFHIRResource got\\n----\\n%s\\n----\\nWant to contain:\\n----\\n%s\\n----\\n\", got, res.ID)\n+\t\t}\n+\t})\n+\n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tbuf.Reset()\n+\t\tif err := updateFHIRResource(buf, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, res.ID, false); err != nil {\n+\t\t\tr.Errorf(\"updateFHIRResource got err: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tupdatedRes := resource{}\n+\t\tif err := json.Unmarshal(buf.Bytes(), &updatedRes); err != nil {\n+\t\t\tr.Errorf(\"json.Unmarshal updateFHIRResource output: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif updatedRes.Active {\n+\t\t\tr.Errorf(\"updateFHIRResource got active=true, expected active=false\")\n+\t\t}\n+\n+\t\tbuf.Reset()\n+\t\tupdatedRes = resource{}\n+\t\tif err := updateFHIRResource(buf, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, res.ID, true); err != nil {\n+\t\t\tr.Errorf(\"updateFHIRResource got err: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif err := json.Unmarshal(buf.Bytes(), &updatedRes); err != nil {\n+\t\t\tr.Errorf(\"json.Unmarshal updateFHIRResource output: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif !updatedRes.Active {\n+\t\t\tr.Errorf(\"updateFHIRResource got active=false, expected active=true\")\n+\t\t}\n+\t})\n+\n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tbuf.Reset()\n+\t\tif err := patchFHIRResource(buf, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, res.ID, false); err != nil {\n+\t\t\tr.Errorf(\"patchFHIRResource got err: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tpatchedRes := resource{}\n+\t\tif err := json.Unmarshal(buf.Bytes(), &patchedRes); err != nil {\n+\t\t\tr.Errorf(\"json.Unmarshal patchFHIRResource output: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif patchedRes.Active {\n+\t\t\tr.Errorf(\"patchFHIRResource got active=true, expected active=false\")\n+\t\t}\n+\n+\t\tbuf.Reset()\n+\t\tpatchedRes = resource{}\n+\t\tif err := updateFHIRResource(buf, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, res.ID, true); err != nil {\n+\t\t\tr.Errorf(\"patchFHIRResource got err: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif err := json.Unmarshal(buf.Bytes(), &patchedRes); err != nil {\n+\t\t\tr.Errorf(\"json.Unmarshal patchFHIRResource output: %v\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tif !patchedRes.Active {\n+\t\t\tr.Errorf(\"patchFHIRResource got active=false, expected active=true\")\n+\t\t}\n+\t})\n+\n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tbuf.Reset()\n+\t\tif err := fhirGetPatientEverything(buf, tc.ProjectID, location, datasetID, fhirStoreID, res.ID); err != nil {\n+\t\t\tr.Errorf(\"fhirGetPatientEverything got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, res.ID) {\n+\t\t\tr.Errorf(\"fhirGetPatientEverything got\\n----\\n%s\\n----\\nWant to contain:\\n----\\n%s\\n----\\n\", got, res.ID)\n+\t\t}\n+\t})\n+\n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tbuf.Reset()\n+\t\tif err := listFHIRResourceHistory(buf, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, res.ID); err != nil {\n+\t\t\tr.Errorf(\"listFHIRResourceHistory got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, res.Meta.VersionID) {\n+\t\t\tr.Errorf(\"listFHIRResourceHistory got\\n----\\n%s\\n----\\nWant to contain:\\n----\\n%s\\n----\\n\", got, res.Meta.VersionID)\n+\t\t}\n+\t})\n+\n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tbuf.Reset()\n+\t\tif err := getFHIRResourceHistory(buf, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, res.ID, res.Meta.VersionID); err != nil {\n+\t\t\tr.Errorf(\"getFHIRResourceHistory got err: %v\", err)\n+\t\t}\n+\t\tif got := buf.String(); !strings.Contains(got, res.Meta.VersionID) {\n+\t\t\tr.Errorf(\"getFHIRResourceHistory got\\n----\\n%s\\n----\\nWant to contain:\\n----\\n%s\\n----\\n\", got, res.Meta.VersionID)\n+\t\t}\n+\t})\n+\n+\t/*\n+\t\tTODO: Enable. Some import operations fail.\n+\t\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\t\tbuf.Reset()\n+\t\t\t// Delete the bucket (if it exists) then recreate it, optimistically\n+\t\t\t// ignoring errors.\n+\t\t\t// Note: the Healthcare Agent needs access to the bucket.\n+\t\t\t// golang-samples-tests have been given access, but other projects may\n+\t\t\t// fail until they give the agent access to the bucket.\n+\t\t\tbucketName := tc.ProjectID + \"-healthcare-test\"\n+\t\t\tgsURIPrefix := \"gs://\" + bucketName + \"/fhir-export/\"\n+\t\t\tcleanBucket(tc.ProjectID, bucketName)\n+\n+\t\t\tif err := exportFHIRResource(buf, tc.ProjectID, location, datasetID, fhirStoreID, gsURIPrefix); err != nil {\n+\t\t\t\tr.Errorf(\"exportFHIRResource got err: %v\", err)\n+\t\t\t}\n+\n+\t\t\tif err := importFHIRResource(ioutil.Discard, tc.ProjectID, location, datasetID, fhirStoreID, gsURIPrefix+\"**\"); err != nil {\n+\t\t\t\tr.Errorf(\"importFHIRResource got err: %v\", err)\n+\t\t\t}\n+\t\t})\n+\t*/\n+\n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tif err := deleteFHIRResource(ioutil.Discard, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, res.ID); err != nil {\n+\t\t\tr.Errorf(\"deleteFHIRResource got err: %v\", err)\n+\t\t}\n+\t})\n+\n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tbuf.Reset()\n+\t\tif err := purgeFHIRResource(ioutil.Discard, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, res.ID); err != nil {\n+\t\t\tr.Errorf(\"purgeFHIRResource got err: %v\", err)\n+\t\t}\n+\n+\t\tif err := getFHIRResource(ioutil.Discard, tc.ProjectID, location, datasetID, fhirStoreID, resourceType, res.ID); err == nil {\n+\t\t\tr.Errorf(\"getFHIRResource got %q, want it to be not found after purgeFHIRResource\", res.ID)\n+\t\t}\n+\t})\n+\n+\ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n+\t\tbuf.Reset()\n+\t\tif err := fhirExecuteBundle(buf, tc.ProjectID, location, datasetID, fhirStoreID); err != nil {\n+\t\t\tr.Errorf(\"fhirExecuteBundle got err: %v\", err)\n+\t\t}\n+\t\tif got, want := buf.String(), \"201 Created\"; !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"fhirExecuteBundle got\\n----\\n%s\\n----\\nWant to contain:\\n----\\n%s\\n----\\n\", got, want)\n+\t\t}\n+\t})\n+\n \ttestutil.Retry(t, 10, 2*time.Second, func(r *testutil.R) {\n \t\tif err := deleteFHIRStore(ioutil.Discard, tc.ProjectID, location, datasetID, fhirStoreID); err != nil {\n \t\t\tr.Errorf(\"deleteFHIRStore got err: %v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c8f3cc8503acaf17a60dddbc272d42c825d1c027"
    },
    {
        "pr_title": "healthcare: more samples",
        "pr_number": 843,
        "file_name": "healthcare/hl7v2_test.go",
        "code_diff": "@@ -34,6 +34,16 @@\nfunc TestHL7V2Store(t *testing.T) {\n \tlocation := \"us-central1\"\n \tdatasetID := \"hl7v2-dataset\"\n \thl7V2StoreID := \"my-hl7v2-store\"\n+\n+\t// Delete test dataset if it already exists.\n+\tif err := getDataset(buf, tc.ProjectID, location, datasetID); err == nil {\n+\t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\t\tif err := deleteDataset(ioutil.Discard, tc.ProjectID, location, datasetID); err != nil {\n+\t\t\t\tr.Errorf(\"deleteDataset got err: %v\", err)\n+\t\t\t}\n+\t\t})\n+\t}\n+\n \tif err := createDataset(ioutil.Discard, tc.ProjectID, location, datasetID); err != nil {\n \t\tt.Fatalf(\"Unable to create test dataset: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "healthcare: more samples"
        ],
        "last_commit_sha": "c8f3cc8503acaf17a60dddbc272d42c825d1c027"
    },
    {
        "pr_title": "healthcare: more samples",
        "pr_number": 843,
        "file_name": "healthcare/hl7v2_test.go",
        "code_diff": "@@ -66,6 +76,16 @@\nfunc TestHL7V2Store(t *testing.T) {\n \t\t}\n \t})\n \n+\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n+\t\tbuf.Reset()\n+\t\tif err := ingestHL7V2Message(buf, tc.ProjectID, location, datasetID, hl7V2StoreID, dataFile); err != nil {\n+\t\t\tr.Errorf(\"ingestHL7V2Message got err: %v\", err)\n+\t\t}\n+\t\tif got, wantContain := buf.String(), messageID; !strings.Contains(got, wantContain) {\n+\t\t\tr.Errorf(\"ingestHL7V2Message got\\n----\\n%v\\n----\\nWant to contain:\\n----\\n%v\\n----\\n\", got, wantContain)\n+\t\t}\n+\t})\n+\n \ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {\n \t\tbuf.Reset()\n \t\tif err := getHL7V2Message(buf, tc.ProjectID, location, datasetID, hl7V2StoreID, messageID); err != nil {",
        "comments": [],
        "commit_messages": [
            "healthcare: more samples"
        ],
        "last_commit_sha": "c8f3cc8503acaf17a60dddbc272d42c825d1c027"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -15,7 +15,26 @@\n// Code generated by protoc-gen-go. DO NOT EDIT.\n // source: webrisk.proto\n \n-package webrisk_proto\n+/*\n+Package google_cloud_webrisk_v1beta1 is a generated protocol buffer package.\n+\n+It is generated from these files:\n+\twebrisk.proto\n+\n+It has these top-level messages:\n+\tComputeThreatListDiffRequest\n+\tComputeThreatListDiffResponse\n+\tSearchUrisRequest\n+\tSearchUrisResponse\n+\tSearchHashesRequest\n+\tSearchHashesResponse\n+\tThreatEntryAdditions\n+\tThreatEntryRemovals\n+\tRawIndices\n+\tRawHashes\n+\tRiceDeltaEncoding\n+*/\n+package google_cloud_webrisk_v1beta1\n \n import proto \"github.com/golang/protobuf/proto\"\n import fmt \"fmt\"",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -27,6 +46,12 @@\nvar _ = proto.Marshal\n var _ = fmt.Errorf\n var _ = math.Inf\n \n+// This is a compile-time assertion to ensure that this generated file\n+// is compatible with the proto package it is being compiled against.\n+// A compilation error at this line likely means your copy of the\n+// proto package needs to be updated.\n+const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package\n+\n // The type of threat. This maps dirrectly to the threat list a threat may\n // belong to.\n type ThreatType int32",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -58,7 +83,7 @@\nvar ThreatType_value = map[string]int32{\n func (x ThreatType) String() string {\n \treturn proto.EnumName(ThreatType_name, int32(x))\n }\n-func (ThreatType) EnumDescriptor() ([]byte, []int) { return fileDescriptor1, []int{0} }\n+func (ThreatType) EnumDescriptor() ([]byte, []int) { return fileDescriptor0, []int{0} }\n \n // The ways in which threat entry sets can be compressed.\n type CompressionType int32",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -86,7 +111,7 @@\nvar CompressionType_value = map[string]int32{\n func (x CompressionType) String() string {\n \treturn proto.EnumName(CompressionType_name, int32(x))\n }\n-func (CompressionType) EnumDescriptor() ([]byte, []int) { return fileDescriptor1, []int{1} }\n+func (CompressionType) EnumDescriptor() ([]byte, []int) { return fileDescriptor0, []int{1} }\n \n // The type of response sent to the client.\n type ComputeThreatListDiffResponse_ResponseType int32",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -117,13 +142,13 @@\nfunc (x ComputeThreatListDiffResponse_ResponseType) String() string {\n \treturn proto.EnumName(ComputeThreatListDiffResponse_ResponseType_name, int32(x))\n }\n func (ComputeThreatListDiffResponse_ResponseType) EnumDescriptor() ([]byte, []int) {\n-\treturn fileDescriptor1, []int{1, 0}\n+\treturn fileDescriptor0, []int{1, 0}\n }\n \n // Describes an API diff request.\n type ComputeThreatListDiffRequest struct {\n \t// Required. The ThreatList to update.\n-\tThreatType ThreatType `protobuf:\"varint,1,opt,name=threat_type,json=threatType,enum=webrisk_proto.ThreatType\" json:\"threat_type,omitempty\"`\n+\tThreatType ThreatType `protobuf:\"varint,1,opt,name=threat_type,json=threatType,enum=google.cloud.webrisk.v1beta1.ThreatType\" json:\"threat_type,omitempty\"`\n \t// The current version token of the client for the requested list (the\n \t// client version that was received from the last successful diff).\n \tVersionToken []byte `protobuf:\"bytes,2,opt,name=version_token,json=versionToken,proto3\" json:\"version_token,omitempty\"`",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -134,7 +159,7 @@\ntype ComputeThreatListDiffRequest struct {\n func (m *ComputeThreatListDiffRequest) Reset()                    { *m = ComputeThreatListDiffRequest{} }\n func (m *ComputeThreatListDiffRequest) String() string            { return proto.CompactTextString(m) }\n func (*ComputeThreatListDiffRequest) ProtoMessage()               {}\n-func (*ComputeThreatListDiffRequest) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{0} }\n+func (*ComputeThreatListDiffRequest) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{0} }\n \n func (m *ComputeThreatListDiffRequest) GetThreatType() ThreatType {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -168,7 +193,7 @@\ntype ComputeThreatListDiffRequest_Constraints struct {\n \t// 2**20. If zero, no database size limit is set.\n \tMaxDatabaseEntries int32 `protobuf:\"varint,2,opt,name=max_database_entries,json=maxDatabaseEntries\" json:\"max_database_entries,omitempty\"`\n \t// The compression types supported by the client.\n-\tSupportedCompressions []CompressionType `protobuf:\"varint,3,rep,packed,name=supported_compressions,json=supportedCompressions,enum=webrisk_proto.CompressionType\" json:\"supported_compressions,omitempty\"`\n+\tSupportedCompressions []CompressionType `protobuf:\"varint,3,rep,packed,name=supported_compressions,json=supportedCompressions,enum=google.cloud.webrisk.v1beta1.CompressionType\" json:\"supported_compressions,omitempty\"`\n }\n \n func (m *ComputeThreatListDiffRequest_Constraints) Reset() {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -177,7 +202,7 @@\nfunc (m *ComputeThreatListDiffRequest_Constraints) Reset() {\n func (m *ComputeThreatListDiffRequest_Constraints) String() string { return proto.CompactTextString(m) }\n func (*ComputeThreatListDiffRequest_Constraints) ProtoMessage()    {}\n func (*ComputeThreatListDiffRequest_Constraints) Descriptor() ([]byte, []int) {\n-\treturn fileDescriptor1, []int{0, 0}\n+\treturn fileDescriptor0, []int{0, 0}\n }\n \n func (m *ComputeThreatListDiffRequest_Constraints) GetMaxDiffEntries() int32 {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -204,13 +229,13 @@\nfunc (m *ComputeThreatListDiffRequest_Constraints) GetSupportedCompressions() []\n type ComputeThreatListDiffResponse struct {\n \t// The type of response. This may indicate that an action is required by the\n \t// client when the response is received.\n-\tResponseType ComputeThreatListDiffResponse_ResponseType `protobuf:\"varint,4,opt,name=response_type,json=responseType,enum=webrisk_proto.ComputeThreatListDiffResponse_ResponseType\" json:\"response_type,omitempty\"`\n+\tResponseType ComputeThreatListDiffResponse_ResponseType `protobuf:\"varint,4,opt,name=response_type,json=responseType,enum=google.cloud.webrisk.v1beta1.ComputeThreatListDiffResponse_ResponseType\" json:\"response_type,omitempty\"`\n \t// A set of entries to add to a local threat type's list.\n \tAdditions *ThreatEntryAdditions `protobuf:\"bytes,5,opt,name=additions\" json:\"additions,omitempty\"`\n \t// A set of entries to remove from a local threat type's list.\n \t// This field may be empty.\n \tRemovals *ThreatEntryRemovals `protobuf:\"bytes,6,opt,name=removals\" json:\"removals,omitempty\"`\n-\t// The new opaque client version token. \\\n+\t// The new opaque client version token.\n \tNewVersionToken []byte `protobuf:\"bytes,7,opt,name=new_version_token,json=newVersionToken,proto3\" json:\"new_version_token,omitempty\"`\n \t// The expected SHA256 hash of the client state; that is, of the sorted list\n \t// of all hashes present in the database after applying the provided diff.",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -227,7 +252,7 @@\ntype ComputeThreatListDiffResponse struct {\n func (m *ComputeThreatListDiffResponse) Reset()                    { *m = ComputeThreatListDiffResponse{} }\n func (m *ComputeThreatListDiffResponse) String() string            { return proto.CompactTextString(m) }\n func (*ComputeThreatListDiffResponse) ProtoMessage()               {}\n-func (*ComputeThreatListDiffResponse) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{1} }\n+func (*ComputeThreatListDiffResponse) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{1} }\n \n func (m *ComputeThreatListDiffResponse) GetResponseType() ComputeThreatListDiffResponse_ResponseType {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -284,7 +309,7 @@\nfunc (m *ComputeThreatListDiffResponse_Checksum) Reset() {\n func (m *ComputeThreatListDiffResponse_Checksum) String() string { return proto.CompactTextString(m) }\n func (*ComputeThreatListDiffResponse_Checksum) ProtoMessage()    {}\n func (*ComputeThreatListDiffResponse_Checksum) Descriptor() ([]byte, []int) {\n-\treturn fileDescriptor1, []int{1, 0}\n+\treturn fileDescriptor0, []int{1, 0}\n }\n \n func (m *ComputeThreatListDiffResponse_Checksum) GetSha256() []byte {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -299,13 +324,13 @@\ntype SearchUrisRequest struct {\n \t// The URI to be checked for matches.\n \tUri string `protobuf:\"bytes,1,opt,name=uri\" json:\"uri,omitempty\"`\n \t// Required. The ThreatLists to search in.\n-\tThreatTypes []ThreatType `protobuf:\"varint,2,rep,packed,name=threat_types,json=threatTypes,enum=webrisk_proto.ThreatType\" json:\"threat_types,omitempty\"`\n+\tThreatTypes []ThreatType `protobuf:\"varint,2,rep,packed,name=threat_types,json=threatTypes,enum=google.cloud.webrisk.v1beta1.ThreatType\" json:\"threat_types,omitempty\"`\n }\n \n func (m *SearchUrisRequest) Reset()                    { *m = SearchUrisRequest{} }\n func (m *SearchUrisRequest) String() string            { return proto.CompactTextString(m) }\n func (*SearchUrisRequest) ProtoMessage()               {}\n-func (*SearchUrisRequest) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{2} }\n+func (*SearchUrisRequest) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{2} }\n \n func (m *SearchUrisRequest) GetUri() string {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -329,7 +354,7 @@\ntype SearchUrisResponse struct {\n func (m *SearchUrisResponse) Reset()                    { *m = SearchUrisResponse{} }\n func (m *SearchUrisResponse) String() string            { return proto.CompactTextString(m) }\n func (*SearchUrisResponse) ProtoMessage()               {}\n-func (*SearchUrisResponse) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{3} }\n+func (*SearchUrisResponse) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{3} }\n \n func (m *SearchUrisResponse) GetThreat() *SearchUrisResponse_ThreatUri {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -341,7 +366,7 @@\nfunc (m *SearchUrisResponse) GetThreat() *SearchUrisResponse_ThreatUri {\n // Contains threat information on a matching uri.\n type SearchUrisResponse_ThreatUri struct {\n \t// The ThreatList this threat belongs to.\n-\tThreatTypes []ThreatType `protobuf:\"varint,1,rep,packed,name=threat_types,json=threatTypes,enum=webrisk_proto.ThreatType\" json:\"threat_types,omitempty\"`\n+\tThreatTypes []ThreatType `protobuf:\"varint,1,rep,packed,name=threat_types,json=threatTypes,enum=google.cloud.webrisk.v1beta1.ThreatType\" json:\"threat_types,omitempty\"`\n \t// The cache lifetime for the returned match. Clients must not cache this\n \t// response past this timestamp to avoid false positives.\n \tExpireTime *google_protobuf.Timestamp `protobuf:\"bytes,2,opt,name=expire_time,json=expireTime\" json:\"expire_time,omitempty\"`",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -350,7 +375,7 @@\ntype SearchUrisResponse_ThreatUri struct {\n func (m *SearchUrisResponse_ThreatUri) Reset()                    { *m = SearchUrisResponse_ThreatUri{} }\n func (m *SearchUrisResponse_ThreatUri) String() string            { return proto.CompactTextString(m) }\n func (*SearchUrisResponse_ThreatUri) ProtoMessage()               {}\n-func (*SearchUrisResponse_ThreatUri) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{3, 0} }\n+func (*SearchUrisResponse_ThreatUri) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{3, 0} }\n \n func (m *SearchUrisResponse_ThreatUri) GetThreatTypes() []ThreatType {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -372,13 +397,13 @@\ntype SearchHashesRequest struct {\n \t// hash. For JSON requests, this field is base64-encoded.\n \tHashPrefix []byte `protobuf:\"bytes,1,opt,name=hash_prefix,json=hashPrefix,proto3\" json:\"hash_prefix,omitempty\"`\n \t// Required. The ThreatLists to search in.\n-\tThreatTypes []ThreatType `protobuf:\"varint,2,rep,packed,name=threat_types,json=threatTypes,enum=webrisk_proto.ThreatType\" json:\"threat_types,omitempty\"`\n+\tThreatTypes []ThreatType `protobuf:\"varint,2,rep,packed,name=threat_types,json=threatTypes,enum=google.cloud.webrisk.v1beta1.ThreatType\" json:\"threat_types,omitempty\"`\n }\n \n func (m *SearchHashesRequest) Reset()                    { *m = SearchHashesRequest{} }\n func (m *SearchHashesRequest) String() string            { return proto.CompactTextString(m) }\n func (*SearchHashesRequest) ProtoMessage()               {}\n-func (*SearchHashesRequest) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{4} }\n+func (*SearchHashesRequest) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{4} }\n \n func (m *SearchHashesRequest) GetHashPrefix() []byte {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -406,7 +431,7 @@\ntype SearchHashesResponse struct {\n func (m *SearchHashesResponse) Reset()                    { *m = SearchHashesResponse{} }\n func (m *SearchHashesResponse) String() string            { return proto.CompactTextString(m) }\n func (*SearchHashesResponse) ProtoMessage()               {}\n-func (*SearchHashesResponse) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{5} }\n+func (*SearchHashesResponse) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{5} }\n \n func (m *SearchHashesResponse) GetThreats() []*SearchHashesResponse_ThreatHash {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -426,7 +451,7 @@\nfunc (m *SearchHashesResponse) GetNegativeExpireTime() *google_protobuf.Timestam\n type SearchHashesResponse_ThreatHash struct {\n \t// The ThreatList this threat belongs to.\n \t// This must contain at least one entry.\n-\tThreatTypes []ThreatType `protobuf:\"varint,1,rep,packed,name=threat_types,json=threatTypes,enum=webrisk_proto.ThreatType\" json:\"threat_types,omitempty\"`\n+\tThreatTypes []ThreatType `protobuf:\"varint,1,rep,packed,name=threat_types,json=threatTypes,enum=google.cloud.webrisk.v1beta1.ThreatType\" json:\"threat_types,omitempty\"`\n \t// A 32 byte SHA256 hash. This field is in binary format. For JSON\n \t// requests, hashes are base64-encoded.\n \tHash []byte `protobuf:\"bytes,2,opt,name=hash,proto3\" json:\"hash,omitempty\"`",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -439,7 +464,7 @@\nfunc (m *SearchHashesResponse_ThreatHash) Reset()         { *m = SearchHashesRes\n func (m *SearchHashesResponse_ThreatHash) String() string { return proto.CompactTextString(m) }\n func (*SearchHashesResponse_ThreatHash) ProtoMessage()    {}\n func (*SearchHashesResponse_ThreatHash) Descriptor() ([]byte, []int) {\n-\treturn fileDescriptor1, []int{5, 0}\n+\treturn fileDescriptor0, []int{5, 0}\n }\n \n func (m *SearchHashesResponse_ThreatHash) GetThreatTypes() []ThreatType {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -478,7 +503,7 @@\ntype ThreatEntryAdditions struct {\n func (m *ThreatEntryAdditions) Reset()                    { *m = ThreatEntryAdditions{} }\n func (m *ThreatEntryAdditions) String() string            { return proto.CompactTextString(m) }\n func (*ThreatEntryAdditions) ProtoMessage()               {}\n-func (*ThreatEntryAdditions) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{6} }\n+func (*ThreatEntryAdditions) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{6} }\n \n func (m *ThreatEntryAdditions) GetRawHashes() []*RawHashes {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -508,7 +533,7 @@\ntype ThreatEntryRemovals struct {\n func (m *ThreatEntryRemovals) Reset()                    { *m = ThreatEntryRemovals{} }\n func (m *ThreatEntryRemovals) String() string            { return proto.CompactTextString(m) }\n func (*ThreatEntryRemovals) ProtoMessage()               {}\n-func (*ThreatEntryRemovals) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{7} }\n+func (*ThreatEntryRemovals) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{7} }\n \n func (m *ThreatEntryRemovals) GetRawIndices() *RawIndices {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -533,7 +558,7 @@\ntype RawIndices struct {\n func (m *RawIndices) Reset()                    { *m = RawIndices{} }\n func (m *RawIndices) String() string            { return proto.CompactTextString(m) }\n func (*RawIndices) ProtoMessage()               {}\n-func (*RawIndices) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{8} }\n+func (*RawIndices) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{8} }\n \n func (m *RawIndices) GetIndices() []int32 {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -563,7 +588,7 @@\ntype RawHashes struct {\n func (m *RawHashes) Reset()                    { *m = RawHashes{} }\n func (m *RawHashes) String() string            { return proto.CompactTextString(m) }\n func (*RawHashes) ProtoMessage()               {}\n-func (*RawHashes) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{9} }\n+func (*RawHashes) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{9} }\n \n func (m *RawHashes) GetPrefixSize() int32 {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "webrisk: remove unnecessary fields from proto",
        "pr_number": 840,
        "file_name": "webrisk/internal/webrisk_proto/webrisk.pb.go",
        "code_diff": "@@ -600,7 +625,7 @@\ntype RiceDeltaEncoding struct {\n func (m *RiceDeltaEncoding) Reset()                    { *m = RiceDeltaEncoding{} }\n func (m *RiceDeltaEncoding) String() string            { return proto.CompactTextString(m) }\n func (*RiceDeltaEncoding) ProtoMessage()               {}\n-func (*RiceDeltaEncoding) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{10} }\n+func (*RiceDeltaEncoding) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{10} }\n \n func (m *RiceDeltaEncoding) GetFirstValue() int64 {\n \tif m != nil {",
        "comments": [],
        "commit_messages": [
            "clean webrisk protobuf file"
        ],
        "last_commit_sha": "ddc58895588cf3b867ea7302dc452c07b9525a3a"
    },
    {
        "pr_title": "opencensus: use metric exporter interface",
        "pr_number": 825,
        "file_name": "opencensus/opencensus_spanner_quickstart/main.go",
        "code_diff": "@@ -25,7 +25,6 @@\nimport (\n \n \t\"cloud.google.com/go/spanner\"\n \t\"contrib.go.opencensus.io/exporter/stackdriver\"\n-\t\"go.opencensus.io/stats/view\"\n \t\"go.opencensus.io/trace\"\n )",
        "comments": [],
        "commit_messages": [
            "opencensus: update Spanner quickstart"
        ],
        "last_commit_sha": "a5fc117261e43cc5f328930a7fc40d19b95bf607"
    },
    {
        "pr_title": "opencensus: use metric exporter interface",
        "pr_number": 825,
        "file_name": "opencensus/opencensus_spanner_quickstart/main.go",
        "code_diff": "@@ -37,15 +36,20 @@\nfunc main() {\n \t// Exporters use Application Default Credentials to authenticate.\n \t// See https://developers.google.com/identity/protocols/application-default-credentials\n \t// for more details.\n-\texporter, err := stackdriver.NewExporter(stackdriver.Options{\n-\t\tProjectID: \"your-project-id\",\n-\t})\n+\texporter, err := stackdriver.NewExporter(stackdriver.Options{})\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n-\tview.RegisterExporter(exporter)\n+\t// Flush must be called before main() exits to ensure metrics are recorded.\n+\tdefer exporter.Flush()\n+\n \ttrace.RegisterExporter(exporter)\n \n+\tif err := exporter.StartMetricsExporter(); err != nil {\n+\t\tlog.Fatalf(\"Error starting metric exporter: %v\", err)\n+\t}\n+\tdefer exporter.StopMetricsExporter()\n+\n \t// Use trace.AlwaysSample() to always record traces. The\n \t// default sampler skips some traces to conserve resources,\n \t// but can make it hard to debug test traffic. So, remove",
        "comments": [],
        "commit_messages": [
            "opencensus: update Spanner quickstart"
        ],
        "last_commit_sha": "a5fc117261e43cc5f328930a7fc40d19b95bf607"
    },
    {
        "pr_title": "storage: add v4 signed URL get and put samples",
        "pr_number": 811,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -27,7 +27,9 @@\nimport (\n \t\"log\"\n \t\"os\"\n \t\"strings\"\n+\t\"time\"\n \n+\t\"golang.org/x/oauth2/google\"\n \t\"google.golang.org/api/iterator\"\n \n \t\"cloud.google.com/go/storage\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "fd6845a7ba0cb2e478949c93ab76777a0a228c10"
    },
    {
        "pr_title": "storage: add v4 signed URL get and put samples",
        "pr_number": 811,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -20,6 +20,7 @@\nimport (\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n+\t\"net/http\"\n \t\"os\"\n \t\"strings\"\n \t\"testing\"",
        "comments": [],
        "commit_messages": [
            "address lint issues"
        ],
        "last_commit_sha": "fd6845a7ba0cb2e478949c93ab76777a0a228c10"
    },
    {
        "pr_title": "storage: add v4 signed URL get and put samples",
        "pr_number": 811,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -44,7 +45,7 @@\nfunc TestObjects(t *testing.T) {\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n \n \tvar (",
        "comments": [],
        "commit_messages": [
            "use t.Fatal() instead of log.Fatal()"
        ],
        "last_commit_sha": "fd6845a7ba0cb2e478949c93ab76777a0a228c10"
    },
    {
        "pr_title": "storage: add v4 signed URL get and put samples",
        "pr_number": 811,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -198,7 +199,7 @@\nfunc TestKMSObjects(t *testing.T) {\n \tctx := context.Background()\n \tclient, err := storage.NewClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\tt.Fatalf(\"storage.NewClient: %v\", err)\n \t}\n \n \tkeyRingID := os.Getenv(\"GOLANG_SAMPLES_KMS_KEYRING\")",
        "comments": [],
        "commit_messages": [
            "use t.Fatal() instead of log.Fatal()"
        ],
        "last_commit_sha": "fd6845a7ba0cb2e478949c93ab76777a0a228c10"
    },
    {
        "pr_title": "bigtable: add region tags",
        "pr_number": 762,
        "file_name": "bigtable/helloworld/main.go",
        "code_diff": "@@ -16,6 +16,7 @@\n// library to perform basic CRUD operations\n package main\n \n+// [START bigtable_hw_imports]\n import (\n \t\"context\"\n \t\"flag\"",
        "comments": [
            {
                "comment": "Same here.",
                "position": 21
            }
        ],
        "commit_messages": [
            "Adding region tags for Cloud Bigtable samples"
        ],
        "last_commit_sha": "3c862c15f7f3017c16c4513cbcd76909f6a2cdc3"
    },
    {
        "pr_title": "bigtable: add region tags",
        "pr_number": 762,
        "file_name": "bigtable/helloworld/main.go",
        "code_diff": "@@ -25,6 +26,8 @@\nimport (\n \t\"cloud.google.com/go/bigtable\"\n )\n \n+// [END bigtable_hw_imports]\n+\n // User-provided constants.\n const (\n \ttableName        = \"Hello-Bigtable\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3c862c15f7f3017c16c4513cbcd76909f6a2cdc3"
    },
    {
        "pr_title": "bigtable: add region tags",
        "pr_number": 762,
        "file_name": "bigtable/helloworld/main.go",
        "code_diff": "@@ -59,11 +62,14 @@\nfunc main() {\n \n \t// Set up admin client, tables, and column families.\n \t// NewAdminClient uses Application Default Credentials to authenticate.\n+\t// [START bigtable_hw_connect]\n \tadminClient, err := bigtable.NewAdminClient(ctx, *project, *instance)\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create admin client: %v\", err)\n \t}\n+\t// [END bigtable_hw_connect]\n \n+\t// [START bigtable_hw_create_table]\n \ttables, err := adminClient.Tables(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not fetch table list: %v\", err)",
        "comments": [],
        "commit_messages": [
            "Adding region tags for Cloud Bigtable samples"
        ],
        "last_commit_sha": "3c862c15f7f3017c16c4513cbcd76909f6a2cdc3"
    },
    {
        "pr_title": "bigtable: add region tags",
        "pr_number": 762,
        "file_name": "bigtable/helloworld/main.go",
        "code_diff": "@@ -86,14 +92,18 @@\nfunc main() {\n \t\t\tlog.Fatalf(\"Could not create column family %s: %v\", columnFamilyName, err)\n \t\t}\n \t}\n+\t// [END bigtable_hw_create_table]\n \n \t// Set up Bigtable data operations client.\n \t// NewClient uses Application Default Credentials to authenticate.\n+\t// [START bigtable_hw_connect_data]\n \tclient, err := bigtable.NewClient(ctx, *project, *instance)\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create data operations client: %v\", err)\n \t}\n+\t// [END bigtable_hw_connect_data]\n \n+\t// [START bigtable_hw_write_rows]\n \ttbl := client.Open(tableName)\n \tmuts := make([]*bigtable.Mutation, len(greetings))\n \trowKeys := make([]string, len(greetings))",
        "comments": [],
        "commit_messages": [
            "Adding region tags for Cloud Bigtable samples"
        ],
        "last_commit_sha": "3c862c15f7f3017c16c4513cbcd76909f6a2cdc3"
    },
    {
        "pr_title": "bigtable: add region tags",
        "pr_number": 762,
        "file_name": "bigtable/helloworld/main.go",
        "code_diff": "@@ -127,14 +137,18 @@\nfunc main() {\n \t\t}\n \t\tlog.Fatalf(\"Could not write some rows\")\n \t}\n+\t// [END bigtable_hw_write_rows]\n \n+\t// [START bigtable_hw_get_by_key]\n \tlog.Printf(\"Getting a single greeting by row key:\")\n \trow, err := tbl.ReadRow(ctx, rowKeys[0], bigtable.RowFilter(bigtable.ColumnFilter(columnName)))\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not read row with key %s: %v\", rowKeys[0], err)\n \t}\n \tlog.Printf(\"\\t%s = %s\\n\", rowKeys[0], string(row[columnFamilyName][0].Value))\n+\t// [END bigtable_hw_get_by_key]\n \n+\t// [START bigtable_hw_scan_all]\n \tlog.Printf(\"Reading all greeting rows:\")\n \terr = tbl.ReadRows(ctx, bigtable.PrefixRange(columnName), func(row bigtable.Row) bool {\n \t\titem := row[columnFamilyName][0]",
        "comments": [],
        "commit_messages": [
            "Adding region tags for Cloud Bigtable samples"
        ],
        "last_commit_sha": "3c862c15f7f3017c16c4513cbcd76909f6a2cdc3"
    },
    {
        "pr_title": "bigtable: add region tags",
        "pr_number": 762,
        "file_name": "bigtable/helloworld/main.go",
        "code_diff": "@@ -145,7 +159,9 @@\nfunc main() {\n \tif err = client.Close(); err != nil {\n \t\tlog.Fatalf(\"Could not close data operations client: %v\", err)\n \t}\n+\t// [END bigtable_hw_scan_all]\n \n+\t// [START bigtable_hw_delete_table]\n \tlog.Printf(\"Deleting the table\")\n \tif err = adminClient.DeleteTable(ctx, tableName); err != nil {\n \t\tlog.Fatalf(\"Could not delete table %s: %v\", tableName, err)",
        "comments": [],
        "commit_messages": [
            "Adding region tags for Cloud Bigtable samples"
        ],
        "last_commit_sha": "3c862c15f7f3017c16c4513cbcd76909f6a2cdc3"
    },
    {
        "pr_title": "bigquery: add bigquery storage quickstart",
        "pr_number": 760,
        "file_name": "internal/testutil/runmain.go",
        "code_diff": "@@ -72,8 +72,9 @@\nfunc (r *Runner) Cleanup() {\n }\n \n // Run executes runs the built binary until terminated or timeout has\n-// been reached, and indicates successful execution on return.\n-func (r *Runner) Run(env map[string]string, timeout time.Duration) (stdout, stderr []byte, err error) {\n+// been reached, and indicates successful execution on return.  You can\n+// supply extra arguments for the binary via args.\n+func (r *Runner) Run(env map[string]string, timeout time.Duration, args ...string) (stdout, stderr []byte, err error) {\n \tif !r.Built() {\n \t\treturn nil, nil, fmt.Errorf(\"tried to run when binary not built\")\n \t}",
        "comments": [],
        "commit_messages": [
            "address reviewer feedback, and extend testutil runner to allow flags"
        ],
        "last_commit_sha": "58ad38d369c1a1730f23dbd8e15f442aa13d9f8d"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "endpoints/getting-started/app.go",
        "code_diff": "@@ -82,6 +82,8 @@\nfunc (h corsHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n \th(w, r)\n }\n \n+// [START endpoints_auth_info_backend]\n+\n // authInfoHandler reads authentication info provided by the Endpoints proxy.\n func authInfoHandler(w http.ResponseWriter, r *http.Request) {\n \tencodedInfo := r.Header.Get(\"X-Endpoint-API-UserInfo\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "endpoints: auth between services",
        "pr_number": 756,
        "file_name": "endpoints/getting-started/client/main.go",
        "code_diff": "@@ -16,18 +16,15 @@\npackage main\n \n import (\n-\t\"bytes\"\n \t\"crypto/rsa\"\n \t\"crypto/x509\"\n-\t\"encoding/json\"\n \t\"encoding/pem\"\n \t\"errors\"\n \t\"flag\"\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"net/http\"\n-\t\"net/http/httputil\"\n \t\"os\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bce1562a83b73bd76e45c2de94919a09ba7e816e"
    },
    {
        "pr_title": "appengine: add import region tag",
        "pr_number": 744,
        "file_name": "appengine/go11x/static/main.go",
        "code_diff": "@@ -20,6 +20,7 @@\nvar (\n \t)\n )\n \n+// [START main]\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)",
        "comments": [
            {
                "comment": "Need an extra newline between the closing brace and the end comment.",
                "position": 23
            }
        ],
        "commit_messages": [
            "Region tags for documentation\n\nAdded region tags for partial code imports into documentation"
        ],
        "last_commit_sha": "d6ddea04f43e5bc159722a4e33cde2e79bdfc322"
    },
    {
        "pr_title": "appengine: add import region tag",
        "pr_number": 744,
        "file_name": "appengine/go11x/static/main.go",
        "code_diff": "@@ -40,6 +41,9 @@\nfunc main() {\n \tlog.Fatal(http.ListenAndServe(fmt.Sprintf(\":%s\", port), nil))\n }\n \n+//[END main]\n+\n+// [START handlers]\n // indexHandler uses a template to create an index.html.\n func indexHandler(w http.ResponseWriter, r *http.Request) {\n \tif r.URL.Path != \"/\" {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d6ddea04f43e5bc159722a4e33cde2e79bdfc322"
    },
    {
        "pr_title": "iot: add mqtt gateway snippets + test",
        "pr_number": 740,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -383,6 +383,55 @@\nfunc createUnauth(w io.Writer, projectID string, region string, registryID strin\n \n // [END iot_create_unauth_device]\n \n+// [START iot_create_device]\n+\n+// createDevice creates a device in a registry with one of the following public key formats:\n+// RSA_PEM, RSA_X509_PEM, ES256_PEM, ES256_X509_PEM, UNAUTH.\n+func createDevice(w io.Writer, projectID string, region string, registryID string, deviceID string, publicKeyFormat string, keyPath string) (*cloudiot.Device, error) {\n+\tclient, err := getClient()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tkeyBytes, err := ioutil.ReadFile(keyPath)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tvar device cloudiot.Device\n+\n+\t// If no credentials are passed in, create an unauth device.\n+\tif publicKeyFormat == \"UNAUTH\" {\n+\t\tdevice = cloudiot.Device{\n+\t\t\tId: deviceID,\n+\t\t}\n+\t} else {\n+\t\tdevice = cloudiot.Device{\n+\t\t\tId: deviceID,\n+\t\t\tCredentials: []*cloudiot.DeviceCredential{\n+\t\t\t\t{\n+\t\t\t\t\tPublicKey: &cloudiot.PublicKeyCredential{\n+\t\t\t\t\t\tFormat: publicKeyFormat,\n+\t\t\t\t\t\tKey:    string(keyBytes),\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}\n+\t}\n+\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n+\tresponse, err := client.Projects.Locations.Registries.Devices.Create(parent, &device).Do()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tfmt.Fprintf(w, \"Successfully created a device with %s public key: %s\", publicKeyFormat, deviceID)\n+\n+\treturn response, nil\n+}\n+\n+// [END iot_create_device]\n+\n // [START iot_delete_device]\n \n // deleteDevice deletes a device from a registry.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "2d7f189640cf59333260ecd498b372ff7d979dbf"
    },
    {
        "pr_title": "iot: add mqtt gateway snippets + test",
        "pr_number": 740,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -645,7 +694,7 @@\nfunc patchDeviceRSA(w io.Writer, projectID string, region string, registryID str\n // [START iot_set_device_config]\n \n // setConfig sends a configuration change to a device.\n-func setConfig(w io.Writer, projectID string, region string, registryID string, deviceID string, configData string, format string) (*cloudiot.DeviceConfig, error) {\n+func setConfig(w io.Writer, projectID string, region string, registryID string, deviceID string, configData string) (*cloudiot.DeviceConfig, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "iot: add mqtt gateway snippets + test"
        ],
        "last_commit_sha": "2d7f189640cf59333260ecd498b372ff7d979dbf"
    },
    {
        "pr_title": "iot: add mqtt gateway snippets + test",
        "pr_number": 740,
        "file_name": "iot/manager/manager_test.go",
        "code_diff": "@@ -20,17 +20,18 @@\nimport (\n \t\"github.com/google/uuid\"\n )\n \n-var projectID string\n-var topicID string\n-var topicName string // topicName is the full path to the topic (e.g. project/{project}/topics/{topic})\n-var registryID string\n+var (\n+\tprojectID  string\n+\ttopicID    string\n+\ttopicName  string // topicName is the full path to the topic (e.g. project/{project}/topics/{topic}).\n+\tregistryID string\n+\tclient     *pubsub.Client\n+)\n \n const region = \"us-central1\"\n \n var pubKeyRSA = os.Getenv(\"GOLANG_SAMPLES_IOT_PUB\")\n \n-var client *pubsub.Client\n-\n // returns a v1 UUID for a resource: e.g. topic, registry, gateway, device\n func createIDForTest(resource string) string {\n \tuuid, err := uuid.NewRandom()",
        "comments": [],
        "commit_messages": [
            "iot: add mqtt gateway snippets + test"
        ],
        "last_commit_sha": "2d7f189640cf59333260ecd498b372ff7d979dbf"
    },
    {
        "pr_title": "iot: add mqtt gateway snippets + test",
        "pr_number": 740,
        "file_name": "iot/manager/manager_test.go",
        "code_diff": "@@ -44,9 +45,7 @@\nfunc createIDForTest(resource string) string {\n \n func TestMain(m *testing.M) {\n \tsetup(m)\n-\tlog.SetOutput(ioutil.Discard)\n \ts := m.Run()\n-\tlog.SetOutput(os.Stderr)\n \tshutdown()\n \tos.Exit(s)\n }",
        "comments": [],
        "commit_messages": [
            "iot: add mqtt gateway snippets + test"
        ],
        "last_commit_sha": "2d7f189640cf59333260ecd498b372ff7d979dbf"
    },
    {
        "pr_title": "iot: add mqtt gateway snippets + test",
        "pr_number": 740,
        "file_name": "iot/manager/manager_test.go",
        "code_diff": "@@ -55,17 +54,16 @@\nfunc setup(m *testing.M) {\n \tctx := context.Background()\n \ttc, ok := testutil.ContextMain(m)\n \n-\t// Retrive\n-\tif ok {\n-\t\tprojectID = tc.ProjectID\n-\t} else {\n+\t// Retrieve project ID\n+\tif !ok {\n \t\tfmt.Fprintln(os.Stderr, \"Project is not set up properly for system tests. Make sure GOLANG_SAMPLES_PROJECT_ID is set\")\n-\t\tos.Exit(1)\n+\t\treturn\n \t}\n+\tprojectID = tc.ProjectID\n \n \tpubsubClient, err := pubsub.NewClient(ctx, projectID)\n \tif err != nil {\n-\t\tlog.Fatalf(\"Could not create pubsub Client: %v\", err)\n+\t\tfmt.Printf(\"Could not create pubsub Client:\\n%v\\n\", err)\n \t}\n \tclient = pubsubClient",
        "comments": [],
        "commit_messages": [
            "iot: add mqtt gateway snippets + test"
        ],
        "last_commit_sha": "2d7f189640cf59333260ecd498b372ff7d979dbf"
    },
    {
        "pr_title": "pubsub: add publish with custom attributes sample",
        "pr_number": 728,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -162,7 +162,6 @@\nfunc publishThatScales(client *pubsub.Client, topic string, n int) error {\n \n \tfor i := 0; i < n; i++ {\n \t\tresult := t.Publish(ctx, &pubsub.Message{\n-\t\t\t// data must be a ByteString\n \t\t\tData: []byte(\"Message \" + strconv.Itoa(i)),\n \t\t})",
        "comments": [],
        "commit_messages": [
            "Addressed nit's"
        ],
        "last_commit_sha": "451da3c95d2c4caf101c22c6bfd549009adecd7b"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -15,6 +15,7 @@\nimport (\n )\n \n // [START kms_create_keyring]\n+\n // createKeyRing creates a new ring to store keys on KMS.\n // example parentName: \"projects/PROJECT_ID/locations/global/\"\n func createKeyRing(parentName, keyRingId string) error {",
        "comments": [],
        "commit_messages": [
            "Adds newline after [START] tags.\n\nTo prevent region tags from appearing in documentation."
        ],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -40,6 +41,7 @@\nfunc createKeyRing(parentName, keyRingId string) error {\n // [END kms_create_keyring]\n \n // [START kms_create_cryptokey]\n+\n // createCryptoKey creates a new symmetric encrypt/decrypt key on KMS.\n // example keyRingName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID\"\n func createCryptoKey(keyRingName, keyId string) error {",
        "comments": [],
        "commit_messages": [
            "Adds newline after [START] tags.\n\nTo prevent region tags from appearing in documentation."
        ],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -72,6 +74,7 @@\nfunc createCryptoKey(keyRingName, keyId string) error {\n // [END kms_create_cryptokey]\n \n // [START kms_disable_cryptokey_version]\n+\n // disableCryptoKeyVersion disables a specified key version on KMS.\n // example keyVersionName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n func disableCryptoKeyVersion(keyVersionName string) error {",
        "comments": [],
        "commit_messages": [
            "Adds newline after [START] tags.\n\nTo prevent region tags from appearing in documentation."
        ],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -102,6 +105,7 @@\nfunc disableCryptoKeyVersion(keyVersionName string) error {\n // [END kms_disable_cryptokey_version]\n \n // [START kms_enable_cryptokey_version]\n+\n // enableCryptoKeyVersion enables a previously disabled key version on KMS.\n // example keyVersionName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n func enableCryptoKeyVersion(keyVersionName string) error {",
        "comments": [],
        "commit_messages": [
            "Adds newline after [START] tags.\n\nTo prevent region tags from appearing in documentation."
        ],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -132,6 +136,7 @@\nfunc enableCryptoKeyVersion(keyVersionName string) error {\n // [END kms_enable_cryptokey_version]\n \n // [START kms_destroy_cryptokey_version]\n+\n // destroyCryptoKeyVersion marks a specified key version for deletion. The key can be restored if requested within 24 hours.\n // example keyVersionName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n func destroyCryptoKeyVersion(keyVersionName string) error {",
        "comments": [],
        "commit_messages": [
            "Adds newline after [START] tags.\n\nTo prevent region tags from appearing in documentation."
        ],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -156,6 +161,7 @@\nfunc destroyCryptoKeyVersion(keyVersionName string) error {\n // [END kms_destroy_cryptokey_version]\n \n // [START kms_restore_cryptokey_version]\n+\n // restoreCryptoKeyVersion attempts to recover a key that has been marked for destruction within the last 24 hours.\n // example keyVersionName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID/cryptoKeyVersions/1\"\n func restoreCryptoKeyVersion(keyVersionName string) error {",
        "comments": [],
        "commit_messages": [
            "Adds newline after [START] tags.\n\nTo prevent region tags from appearing in documentation."
        ],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -180,6 +186,7 @@\nfunc restoreCryptoKeyVersion(keyVersionName string) error {\n // [END kms_restore_cryptokey_version]\n \n // [START kms_get_keyring_policy]\n+\n // getRingPolicy retrieves and prints the IAM policy associated with the key ring\n // example keyRingName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID\"\n func getRingPolicy(keyRingName string) (*iam.Policy, error) {",
        "comments": [],
        "commit_messages": [
            "Adds newline after [START] tags.\n\nTo prevent region tags from appearing in documentation."
        ],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -209,6 +216,8 @@\nfunc getRingPolicy(keyRingName string) (*iam.Policy, error) {\n \n // [END kms_get_keyring_policy]\n \n+// [START kms_get_cryptokey_policy]\n+\n // getCryptoKeyPolicy retrieves and prints the IAM policy associated with the key\n // example keyName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID\"\n func getCryptoKeyPolicy(keyName string) (*iam.Policy, error) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -236,7 +245,10 @@\nfunc getCryptoKeyPolicy(keyName string) (*iam.Policy, error) {\n \treturn policy, nil\n }\n \n+// [END kms_get_cryptokey_policy]\n+\n // [START kms_add_member_to_keyring_policy]\n+\n // addMemberRingPolicy adds a new member to a specified IAM role for the key ring\n // example keyRingName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID\"\n func addMemberRingPolicy(keyRingName, member string, role iam.RoleName) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -269,6 +281,8 @@\nfunc addMemberRingPolicy(keyRingName, member string, role iam.RoleName) error {\n \n // [END kms_add_member_to_keyring_policy]\n \n+// [START kms_remove_member_from_keyring_policy]\n+\n // removeMemberRingPolicy removes a specified member from an IAM role for the key ring\n // example keyRingName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID\"\n func removeMemberRingPolicy(keyRingName, member string, role iam.RoleName) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -300,7 +314,10 @@\nfunc removeMemberRingPolicy(keyRingName, member string, role iam.RoleName) error\n \treturn nil\n }\n \n+// [END kms_remove_member_from_keyring_policy]\n+\n // [START kms_add_member_to_cryptokey_policy]\n+\n // addMemberCryptoKeyPolicy adds a new member to a specified IAM role for the key\n // example keyName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID\"\n func addMemberCryptoKeyPolicy(keyName, member string, role iam.RoleName) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -334,6 +351,7 @@\nfunc addMemberCryptoKeyPolicy(keyName, member string, role iam.RoleName) error {\n // [END kms_add_member_to_cryptokey_policy]\n \n // [START kms_remove_member_from_cryptokey_policy]\n+\n // removeMemberCryptoKeyPolicy removes a specified member from an IAM role for the key\n // example keyName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID\"\n func removeMemberCryptoKeyPolicy(keyName, member string, role iam.RoleName) error {",
        "comments": [],
        "commit_messages": [
            "Adds newline after [START] tags.\n\nTo prevent region tags from appearing in documentation."
        ],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "kms: add 2 region tags",
        "pr_number": 727,
        "file_name": "kms/snippets.go",
        "code_diff": "@@ -367,6 +385,7 @@\nfunc removeMemberCryptoKeyPolicy(keyName, member string, role iam.RoleName) erro\n // [END kms_remove_member_from_cryptokey_policy]\n \n // [START kms_encrypt]\n+\n // encrypt will encrypt the input plaintext with the specified symmetric key\n // example keyName: \"projects/PROJECT_ID/locations/global/keyRings/RING_ID/cryptoKeys/KEY_ID\"\n func encryptSymmetric(keyName string, plaintext []byte) ([]byte, error) {",
        "comments": [],
        "commit_messages": [
            "Adds newline after [START] tags.\n\nTo prevent region tags from appearing in documentation."
        ],
        "last_commit_sha": "63a890d3be23c73caca44fc7f2e69fd3c5533101"
    },
    {
        "pr_title": "testutil:  revisit BuildMain's runner",
        "pr_number": 719,
        "file_name": "internal/testutil/runmain.go",
        "code_diff": "@@ -5,11 +5,13 @@\npackage testutil\n \n import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"fmt\"\n \t\"io/ioutil\"\n \t\"os\"\n \t\"os/exec\"\n \t\"path/filepath\"\n-\t\"syscall\"\n \t\"testing\"\n \t\"time\"\n )",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "a53dd26c23fb9c18c1ea8e1ef96c90426076871e"
    },
    {
        "pr_title": "testutil:  revisit BuildMain's runner",
        "pr_number": 719,
        "file_name": "internal/testutil/testutil.go",
        "code_diff": "@@ -31,7 +31,7 @@\nfunc (tc Context) Path(p ...string) string {\n // Useful for initializing global variables before running parallel system tests.\n // ok is false if the project is not set up properly for system tests.\n func ContextMain(m *testing.M) (tc Context, ok bool) {\n-\tc, err := context()\n+\tc, err := testContext()\n \tif err == noProjectID {\n \t\treturn c, false\n \t} else if err != nil {",
        "comments": [],
        "commit_messages": [
            "Replace Run(), updated testutil so context() becomes testContext()"
        ],
        "last_commit_sha": "a53dd26c23fb9c18c1ea8e1ef96c90426076871e"
    },
    {
        "pr_title": "testutil:  revisit BuildMain's runner",
        "pr_number": 719,
        "file_name": "internal/testutil/testutil.go",
        "code_diff": "@@ -43,7 +43,7 @@\nfunc ContextMain(m *testing.M) (tc Context, ok bool) {\n // SystemTest gets the test context.\n // The test is skipped if the GOLANG_SAMPLES_PROJECT_ID environment variable is not set.\n func SystemTest(t *testing.T) Context {\n-\ttc, err := context()\n+\ttc, err := testContext()\n \tif err == noProjectID {\n \t\tt.Skip(err)\n \t} else if err != nil {",
        "comments": [],
        "commit_messages": [
            "Replace Run(), updated testutil so context() becomes testContext()"
        ],
        "last_commit_sha": "a53dd26c23fb9c18c1ea8e1ef96c90426076871e"
    },
    {
        "pr_title": "testutil:  revisit BuildMain's runner",
        "pr_number": 719,
        "file_name": "internal/testutil/testutil.go",
        "code_diff": "@@ -60,7 +60,7 @@\nfunc EndToEndTest(t *testing.T) Context {\n \t\tt.Skip(\"GOLANG_SAMPLES_E2E_TEST not set\")\n \t}\n \n-\ttc, err := context()\n+\ttc, err := testContext()\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_messages": [
            "Replace Run(), updated testutil so context() becomes testContext()"
        ],
        "last_commit_sha": "a53dd26c23fb9c18c1ea8e1ef96c90426076871e"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -24,12 +24,10 @@\nimport (\n \t// [END imports]\n )\n \n-// Registry Management\n-\n-// [START iot_create_registry]\n+// [START iot_get_client]\n \n-// createRegistry creates a device registry.\n-func createRegistry(w io.Writer, projectID string, region string, registryID string, topicName string) (*cloudiot.DeviceRegistry, error) {\n+// getClient returns a client based on the environment variable GOOGLE_APPLICATION_CREDENTIALS\n+func getClient() (*cloudiot.Service, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -42,6 +40,22 @@\nfunc createRegistry(w io.Writer, projectID string, region string, registryID str\n \t\treturn nil, err\n \t}\n \n+\treturn client, nil\n+}\n+\n+// [END iot_get_client]\n+\n+// Registry Management\n+\n+// [START iot_create_registry]\n+\n+// createRegistry creates a IoT Core device registry associated with a PubSub topic\n+func createRegistry(w io.Writer, projectID string, region string, registryID string, topicName string) (*cloudiot.DeviceRegistry, error) {\n+\tclient, err := getClient()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n \tregistry := cloudiot.DeviceRegistry{\n \t\tId: registryID,\n \t\tEventNotificationConfigs: []*cloudiot.EventNotificationConfig{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -63,7 +77,7 @@\nfunc createRegistry(w io.Writer, projectID string, region string, registryID str\n \tfmt.Fprintf(w, \"\\tMQTT: %s\\n\", response.MqttConfig.MqttEnabledState)\n \tfmt.Fprintf(w, \"\\tName: %s\\n\", response.Name)\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_create_registry]",
        "comments": [],
        "commit_messages": [
            "iot: changes to gateway manager from review"
        ],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -90,9 +104,9 @@\nfunc deleteRegistry(w io.Writer, projectID string, region string, registryID str\n \t\treturn nil, err\n \t}\n \n-\tfmt.Fprintln(w, \"Deleted registry\")\n+\tfmt.Fprintf(w, \"Deleted registry: %s\\n\", registryID)\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_delete_registry]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -125,7 +139,7 @@\nfunc getRegistry(w io.Writer, projectID string, region string, registryID string\n \tfmt.Fprintf(w, \"\\tMQTT: %s\\n\", response.MqttConfig.MqttEnabledState)\n \tfmt.Fprintf(w, \"\\tName: %s\\n\", response.Name)\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_get_registry]",
        "comments": [],
        "commit_messages": [
            "iot: changes to gateway manager from review"
        ],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -152,12 +166,17 @@\nfunc listRegistries(w io.Writer, projectID string, region string) ([]*cloudiot.D\n \t\treturn nil, err\n \t}\n \n-\tfmt.Fprintln(w, \"Registries:\")\n+\tif len(response.DeviceRegistries) == 0 {\n+\t\tfmt.Fprintln(w, \"No registries found\")\n+\t\treturn response.DeviceRegistries, nil\n+\t}\n+\n+\tfmt.Fprintf(w, \"%d registries:\\n\", len(response.DeviceRegistries))\n \tfor _, registry := range response.DeviceRegistries {\n \t\tfmt.Fprintf(w, \"\\t%s\\n\", registry.Name)\n \t}\n \n-\treturn response.DeviceRegistries, err\n+\treturn response.DeviceRegistries, nil\n }\n \n // [END iot_list_registries]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -194,7 +213,7 @@\nfunc getRegistryIAM(w io.Writer, projectID string, region string, registryID str\n \t\t}\n \t}\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_get_iam_policy]",
        "comments": [],
        "commit_messages": [
            "iot: changes to gateway manager from review"
        ],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -233,7 +252,7 @@\nfunc setRegistryIAM(w io.Writer, projectID string, region string, registryID str\n \n \tfmt.Fprintf(w, \"Successfully set IAM policy for registry: %s\\n\", registryID)\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_set_iam_policy]",
        "comments": [],
        "commit_messages": [
            "iot: changes to gateway manager from review"
        ],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -242,8 +261,8 @@\nfunc setRegistryIAM(w io.Writer, projectID string, region string, registryID str\n \n // [START iot_create_es_device]\n \n-// createES creates a device in a registry with ES credentials.\n-func createES(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n+// createES creates a device in a registry with ES256 credentials.\n+func createES(w io.Writer, projectID string, region string, registryID string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -273,23 +292,23 @@\nfunc createES(w io.Writer, projectID string, region string, registry string, dev\n \t\t},\n \t}\n \n-\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registry)\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n \tresponse, err := client.Projects.Locations.Registries.Devices.Create(parent, &device).Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n-\tfmt.Fprintln(w, \"Successfully created ESA device\")\n+\tfmt.Fprintf(w, \"Successfully created ES256 device: %s\\n\", deviceID)\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_create_es_device]\n \n // [START iot_create_rsa_device]\n \n-// createRSA creates a device in a registry with RS credentials.\n-func createRSA(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n+// createRSA creates a device in a registry given RSA X.509 credentials.\n+func createRSA(w io.Writer, projectID string, region string, registryID string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -319,23 +338,23 @@\nfunc createRSA(w io.Writer, projectID string, region string, registry string, de\n \t\t},\n \t}\n \n-\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registry)\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n \tresponse, err := client.Projects.Locations.Registries.Devices.Create(parent, &device).Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n-\tfmt.Fprintln(w, \"Successfully created RSA device\")\n+\tfmt.Fprintf(w, \"Successfully created RSA256 X.509 device: %s\", deviceID)\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_create_rsa_device]\n \n // [START iot_create_unauth_device]\n \n // createUnauth creates a device in a registry without credentials.\n-func createUnauth(w io.Writer, projectID string, region string, registry string, deviceID string) (*cloudiot.Device, error) {\n+func createUnauth(w io.Writer, projectID string, region string, registryID string, deviceID string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -351,23 +370,23 @@\nfunc createUnauth(w io.Writer, projectID string, region string, registry string,\n \tdevice := cloudiot.Device{\n \t\tId: deviceID,\n \t}\n-\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registry)\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n \tresponse, err := client.Projects.Locations.Registries.Devices.Create(parent, &device).Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n-\tfmt.Fprintln(w, \"Successfully created device without credentials\")\n+\tfmt.Fprintf(w, \"Successfully created device without credentials: %s\\n\", deviceID)\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_create_unauth_device]\n \n // [START iot_delete_device]\n \n // deleteDevice deletes a device from a registry.\n-func deleteDevice(w io.Writer, projectID string, region string, registry string, deviceID string) (*cloudiot.Empty, error) {\n+func deleteDevice(w io.Writer, projectID string, region string, registryID string, deviceID string) (*cloudiot.Empty, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -380,23 +399,23 @@\nfunc deleteDevice(w io.Writer, projectID string, region string, registry string,\n \t\treturn nil, err\n \t}\n \n-\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, deviceID)\n+\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registryID, deviceID)\n \tresponse, err := client.Projects.Locations.Registries.Devices.Delete(path).Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n \tfmt.Fprintf(w, \"Deleted device: %s\\n\", deviceID)\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_delete_device]\n \n // [START iot_get_device]\n \n // getDevice retrieves a specific device and prints its details.\n-func getDevice(w io.Writer, projectID string, region string, registry string, device string) (*cloudiot.Device, error) {\n+func getDevice(w io.Writer, projectID string, region string, registryID string, device string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -409,7 +428,7 @@\nfunc getDevice(w io.Writer, projectID string, region string, registry string, de\n \t\treturn nil, err\n \t}\n \n-\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, device)\n+\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registryID, device)\n \tresponse, err := client.Projects.Locations.Registries.Devices.Get(path).Do()\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -428,15 +447,15 @@\nfunc getDevice(w io.Writer, projectID string, region string, registry string, de\n \tfmt.Fprintf(w, \"\\tLast State Time: %s\\n\", response.LastStateTime)\n \tfmt.Fprintf(w, \"\\tNumId: %d\\n\", response.NumId)\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_get_device]\n \n // [START iot_get_device_configs]\n \n // getDeviceConfigs retrieves and lists device configurations.\n-func getDeviceConfigs(w io.Writer, projectID string, region string, registry string, device string) ([]*cloudiot.DeviceConfig, error) {\n+func getDeviceConfigs(w io.Writer, projectID string, region string, registryID string, device string) ([]*cloudiot.DeviceConfig, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -449,7 +468,7 @@\nfunc getDeviceConfigs(w io.Writer, projectID string, region string, registry str\n \t\treturn nil, err\n \t}\n \n-\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, device)\n+\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registryID, device)\n \tresponse, err := client.Projects.Locations.Registries.Devices.ConfigVersions.List(path).Do()\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -459,15 +478,15 @@\nfunc getDeviceConfigs(w io.Writer, projectID string, region string, registry str\n \t\tfmt.Fprintf(w, \"%d : %s\\n\", config.Version, config.BinaryData)\n \t}\n \n-\treturn response.DeviceConfigs, err\n+\treturn response.DeviceConfigs, nil\n }\n \n // [END iot_get_device_configs]\n \n // [START iot_get_device_state]\n \n // getDeviceStates retrieves and lists device states.\n-func getDeviceStates(w io.Writer, projectID string, region string, registry string, device string) ([]*cloudiot.DeviceState, error) {\n+func getDeviceStates(w io.Writer, projectID string, region string, registryID string, device string) ([]*cloudiot.DeviceState, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -480,7 +499,7 @@\nfunc getDeviceStates(w io.Writer, projectID string, region string, registry stri\n \t\treturn nil, err\n \t}\n \n-\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, device)\n+\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registryID, device)\n \tresponse, err := client.Projects.Locations.Registries.Devices.States.List(path).Do()\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -492,15 +511,15 @@\nfunc getDeviceStates(w io.Writer, projectID string, region string, registry stri\n \t\tfmt.Fprintf(w, \"%s : %s\\n\", state.UpdateTime, state.BinaryData)\n \t}\n \n-\treturn response.DeviceStates, err\n+\treturn response.DeviceStates, nil\n }\n \n // [END iot_get_device_state]\n \n // [START iot_list_devices]\n \n-// listDevices gets the identifiers of devices given a registry name.\n-func listDevices(w io.Writer, projectID string, region string, registry string) ([]*cloudiot.Device, error) {\n+// listDevices gets the identifiers of devices for a specific registry.\n+func listDevices(w io.Writer, projectID string, region string, registryID string) ([]*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [
            {
                "comment": "Return early? Lines up with https://github.com/golang/go/wiki/CodeReviewComments#indent-error-flow.",
                "position": 523
            },
            {
                "comment": "Done, and noted for the future.",
                "position": 523
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -513,7 +532,7 @@\nfunc listDevices(w io.Writer, projectID string, region string, registry string)\n \t\treturn nil, err\n \t}\n \n-\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registry)\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n \tresponse, err := client.Projects.Locations.Registries.Devices.List(parent).Do()\n \tif err != nil {\n \t\treturn nil, err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -524,15 +543,15 @@\nfunc listDevices(w io.Writer, projectID string, region string, registry string)\n \t\tfmt.Fprintf(w, \"\\t%s\\n\", device.Id)\n \t}\n \n-\treturn response.Devices, err\n+\treturn response.Devices, nil\n }\n \n // [END iot_list_devices]\n \n // [START iot_patch_es]\n \n-// patchDeviceES patches a device to use ES credentials.\n-func patchDeviceES(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n+// patchDeviceES patches a device to use ES256 credentials.\n+func patchDeviceES(w io.Writer, projectID string, region string, registryID string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -562,24 +581,24 @@\nfunc patchDeviceES(w io.Writer, projectID string, region string, registry string\n \t\t},\n \t}\n \n-\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, deviceID)\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registryID, deviceID)\n \tresponse, err := client.Projects.Locations.Registries.Devices.\n \t\tPatch(parent, &device).UpdateMask(\"credentials\").Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n-\tfmt.Fprintln(w, \"Successfully patched device with ES credentials\")\n+\tfmt.Fprintln(w, \"Successfully patched device with ES256 credentials\")\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_patch_es]\n \n // [START iot_patch_rsa]\n \n-// patchDeviceRSA patches a device to use RSA credentials.\n-func patchDeviceRSA(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n+// patchDeviceRSA patches a device to use RSA256 X.509 credentials.\n+func patchDeviceRSA(w io.Writer, projectID string, region string, registryID string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -609,24 +628,24 @@\nfunc patchDeviceRSA(w io.Writer, projectID string, region string, registry strin\n \t\t},\n \t}\n \n-\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, deviceID)\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registryID, deviceID)\n \tresponse, err := client.Projects.Locations.Registries.Devices.\n \t\tPatch(parent, &device).UpdateMask(\"credentials\").Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n-\tfmt.Fprintln(w, \"Successfully patched device\")\n+\tfmt.Fprintln(w, \"Successfully patched device with RSA256 X.509 credentials\")\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_patch_rsa]\n \n // [START iot_set_device_config]\n \n // setConfig sends a configuration change to a device.\n-func setConfig(w io.Writer, projectID string, region string, registry string, deviceID string, configData string, format string) (*cloudiot.DeviceConfig, error) {\n+func setConfig(w io.Writer, projectID string, region string, registryID string, deviceID string, configData string, format string) (*cloudiot.DeviceConfig, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -643,23 +662,23 @@\nfunc setConfig(w io.Writer, projectID string, region string, registry string, de\n \t\tBinaryData: b64.StdEncoding.EncodeToString([]byte(configData)),\n \t}\n \n-\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, deviceID)\n+\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registryID, deviceID)\n \tresponse, err := client.Projects.Locations.Registries.Devices.ModifyCloudToDeviceConfig(path, &req).Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n \tfmt.Fprintf(w, \"Config set!\\nVersion now: %d\\n\", response.Version)\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_set_device_config]\n \n // [START iot_send_command]\n \n // sendCommand sends a command to a device listening for commands.\n-func sendCommand(w io.Writer, projectID string, region string, registry string, deviceID string, sendData string) (*cloudiot.SendCommandToDeviceResponse, error) {\n+func sendCommand(w io.Writer, projectID string, region string, registryID string, deviceID string, sendData string) (*cloudiot.SendCommandToDeviceResponse, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -676,7 +695,7 @@\nfunc sendCommand(w io.Writer, projectID string, region string, registry string,\n \t\tBinaryData: b64.StdEncoding.EncodeToString([]byte(sendData)),\n \t}\n \n-\tname := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, deviceID)\n+\tname := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registryID, deviceID)\n \n \tresponse, err := client.Projects.Locations.Registries.Devices.SendCommandToDevice(name, &req).Do()\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -685,11 +704,220 @@\nfunc sendCommand(w io.Writer, projectID string, region string, registry string,\n \n \tfmt.Fprintln(w, \"Sent command to device\")\n \n-\treturn response, err\n+\treturn response, nil\n }\n \n // [END iot_send_command]\n \n+// START BETA FEATURES\n+\n+// [START iot_create_gateway]\n+\n+// createGateway creates a new IoT Core gateway with a given id, public key, and auth method.\n+// gatewayAuthMethod can be one of: ASSOCIATION_ONLY, DEVICE_AUTH_TOKEN_ONLY, ASSOCIATION_AND_DEVICE_AUTH_TOKEN.\n+// https://cloud.google.com/iot/docs/reference/cloudiot/rest/v1/projects.locations.registries.devices#gatewayauthmethod\n+func createGateway(w io.Writer, projectID string, region string, registryID string, gatewayID string, gatewayAuthMethod string, publicKeyPath string) (*cloudiot.Device, error) {\n+\t// Authorize the client using Application Default Credentials.\n+\t// See https://g.co/dv/identity/protocols/application-default-credentials\n+\tctx := context.Background()\n+\thttpClient, err := google.DefaultClient(ctx, cloudiot.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tclient, err := cloudiot.New(httpClient)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tkeyBytes, err := ioutil.ReadFile(publicKeyPath)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tgateway := &cloudiot.Device{\n+\t\tId: gatewayID,\n+\t\tCredentials: []*cloudiot.DeviceCredential{\n+\t\t\t{\n+\t\t\t\tPublicKey: &cloudiot.PublicKeyCredential{\n+\t\t\t\t\tFormat: \"RSA_X509_PEM\",\n+\t\t\t\t\tKey:    string(keyBytes),\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t\tGatewayConfig: &cloudiot.GatewayConfig{\n+\t\t\tGatewayType:       \"GATEWAY\",\n+\t\t\tGatewayAuthMethod: gatewayAuthMethod,\n+\t\t},\n+\t}\n+\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n+\tresponse, err := client.Projects.Locations.Registries.Devices.Create(parent, gateway).Do()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tfmt.Fprintln(w, \"Successfully created gateway:\", gatewayID)\n+\n+\treturn response, nil\n+}\n+\n+// [END iot_create_gateway]\n+\n+// [START iot_list_gateways]\n+\n+// listGateways lists all the gateways in a specific registry.\n+func listGateways(w io.Writer, projectID string, region string, registryID string) ([]*cloudiot.Device, error) {\n+\t// Authorize the client using Application Default Credentials.\n+\t// See https://g.co/dv/identity/protocols/application-default-credentials\n+\tctx := context.Background()\n+\thttpClient, err := google.DefaultClient(ctx, cloudiot.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tclient, err := cloudiot.New(httpClient)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n+\tresponse, err := client.Projects.Locations.Registries.Devices.List(parent).GatewayListOptionsGatewayType(\"GATEWAY\").Do()\n+\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"ListGateways: %v\", err)\n+\t}\n+\n+\tif len(response.Devices) == 0 {\n+\t\tfmt.Fprintln(w, \"No gateways found\")\n+\t\treturn response.Devices, nil\n+\t}\n+\n+\tfmt.Fprintln(w, len(response.Devices), \"devices:\")\n+\tfor _, gateway := range response.Devices {\n+\t\tfmt.Fprintf(w, \"\\t%s\\n\", gateway.Id)\n+\t}\n+\n+\treturn response.Devices, nil\n+}\n+\n+// [END iot_list_gateways]\n+\n+// [START iot_bind_device_to_gateway]\n+\n+// bindDeviceToGateway creates an association between an existing device and gateway.\n+func bindDeviceToGateway(w io.Writer, projectID string, region string, registryID string, gatewayID string, deviceID string) (*cloudiot.BindDeviceToGatewayResponse, error) {\n+\t// Authorize the client using Application Default Credentials.\n+\t// See https://g.co/dv/identity/protocols/application-default-credentials\n+\tctx := context.Background()\n+\thttpClient, err := google.DefaultClient(ctx, cloudiot.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tclient, err := cloudiot.New(httpClient)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n+\tbindRequest := &cloudiot.BindDeviceToGatewayRequest{\n+\t\tDeviceId:  deviceID,\n+\t\tGatewayId: gatewayID,\n+\t}\n+\n+\tresponse, err := client.Projects.Locations.Registries.BindDeviceToGateway(parent, bindRequest).Do()\n+\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"BindDeviceToGateway: %v\", err)\n+\t}\n+\n+\tif response.HTTPStatusCode/100 != 2 {\n+\t\treturn nil, fmt.Errorf(\"BindDeviceToGateway: HTTP status code not 2xx\\n %v\", response)\n+\t}\n+\n+\tfmt.Fprintf(w, \"Bound %s to %s\", deviceID, gatewayID)\n+\n+\treturn response, nil\n+}\n+\n+// [END iot_bind_device_to_gateway]\n+// [START unbind_device_from_gateway]\n+\n+// unbindDeviceFromGateway unbinds a bound device from a gateway.\n+func unbindDeviceFromGateway(w io.Writer, projectID string, region string, registryID string, gatewayID string, deviceID string) (*cloudiot.UnbindDeviceFromGatewayResponse, error) {\n+\t// Authorize the client using Application Default Credentials.\n+\t// See https://g.co/dv/identity/protocols/application-default-credentials\n+\tctx := context.Background()\n+\thttpClient, err := google.DefaultClient(ctx, cloudiot.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tclient, err := cloudiot.New(httpClient)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n+\tunbindRequest := &cloudiot.UnbindDeviceFromGatewayRequest{\n+\t\tDeviceId:  deviceID,\n+\t\tGatewayId: gatewayID,\n+\t}\n+\n+\tresponse, err := client.Projects.Locations.Registries.UnbindDeviceFromGateway(parent, unbindRequest).Do()\n+\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"UnbindDeviceFromGateway error: %v\", err)\n+\t}\n+\n+\tif response.HTTPStatusCode/100 != 2 {\n+\t\treturn nil, fmt.Errorf(\"UnbindDeviceFromGateway: HTTP status code not 2xx\\n %v\", response)\n+\t}\n+\n+\tfmt.Fprintf(w, \"Unbound %s from %s\", deviceID, gatewayID)\n+\n+\treturn response, nil\n+}\n+\n+// [END unbind_device_from_gateway]\n+\n+// [START list_devices_for_gateway]\n+\n+// listDevicesForGateway lists the devices that are bound to a gateway.\n+func listDevicesForGateway(w io.Writer, projectID string, region string, registryID, gatewayID string) ([]*cloudiot.Device, error) {\n+\t// Authorize the client using Application Default Credentials.\n+\t// See https://g.co/dv/identity/protocols/application-default-credentials\n+\tctx := context.Background()\n+\thttpClient, err := google.DefaultClient(ctx, cloudiot.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tclient, err := cloudiot.New(httpClient)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n+\tresponse, err := client.Projects.Locations.Registries.Devices.List(parent).GatewayListOptionsAssociationsGatewayId(gatewayID).Do()\n+\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"ListDevicesForGateway: %v\", err)\n+\t}\n+\n+\tif len(response.Devices) == 0 {\n+\t\tfmt.Fprintln(w, \"\\tNo devices found\")\n+\t\treturn response.Devices, nil\n+\t}\n+\n+\tfmt.Fprintf(w, \"Devices for %s:\\n\", gatewayID)\n+\tfor _, gateway := range response.Devices {\n+\t\tfmt.Fprintf(w, \"\\t%s\\n\", gateway.Id)\n+\t}\n+\n+\treturn response.Devices, nil\n+}\n+\n+// [END list_devices_for_gateway]\n+\n+// END BETA FEATURES\n+\n type command struct {\n \tname string\n \tfn   interface{}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -734,9 +962,19 @@\nfunc main() {\n \t\t{\"sendCommand\", sendCommand, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"send-data\"}},\n \t}\n \n+\t// Beta Features: Gateway management commands\n+\tgatewayManagementCommands := []command{\n+\t\t{\"createGateway\", createGateway, []string{\"cloud-region\", \"registry-id\", \"gateway-id\", \"auth-method\", \"public-key-path\"}},\n+\t\t{\"listGateways\", listGateways, []string{\"cloud-region\", \"registry-id\"}},\n+\t\t{\"bindDeviceToGateway\", bindDeviceToGateway, []string{\"cloud-region\", \"registry-id\", \"gateway-id\", \"device-id\"}},\n+\t\t{\"unbindDeviceFromGateway\", unbindDeviceFromGateway, []string{\"cloud-region\", \"registry-id\", \"gateway-id\", \"device-id\"}},\n+\t\t{\"listDevicesForGateway\", listDevicesForGateway, []string{\"cloud-region\", \"registry-id\", \"gateway-id\"}},\n+\t}\n+\n \tvar commands []command\n \tcommands = append(commands, registryManagementCommands...)\n \tcommands = append(commands, deviceManagementCommands...)\n+\tcommands = append(commands, gatewayManagementCommands...)\n \n \tflag.Usage = func() {\n \t\tfmt.Fprintf(os.Stderr, \"Usage:\\n\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager_test.go",
        "code_diff": "@@ -22,9 +22,26 @@\nimport (\n \n var projectID string\n var topicID string\n+var topicName string // topicName is the full path to the topic (e.g. project/{project}/topics/{topic})\n+var registryID string\n+\n+const region = \"us-central1\"\n+\n+var pubKeyRSA = os.Getenv(\"GOLANG_SAMPLES_IOT_PUB\")\n \n var client *pubsub.Client\n \n+// returns a v1 UUID for a resource: e.g. topic, registry, gateway, device\n+func createIDForTest(resource string) string {\n+\tuuid, err := uuid.NewRandom()\n+\tif err != nil {\n+\t\tlog.Fatalf(\"Could not generate uuid: %v\", err)\n+\t}\n+\tid := fmt.Sprintf(\"golang-test-%s-%s\", resource, uuid.String())\n+\n+\treturn id\n+}\n+\n func TestMain(m *testing.M) {\n \tsetup(m)\n \tlog.SetOutput(ioutil.Discard)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "iot: add gateway management samples to manager",
        "pr_number": 717,
        "file_name": "iot/manager/manager_test.go",
        "code_diff": "@@ -52,54 +69,140 @@\nfunc setup(m *testing.M) {\n \t}\n \tclient = pubsubClient\n \n-\tpubsubUUID, err := uuid.NewRandom()\n-\tif err != nil {\n-\t\tlog.Fatalf(\"Could not generate uuid: %v\", err)\n-\t}\n-\ttopicID = \"golang-iot-topic-\" + pubsubUUID.String()\n+\ttopicID = createIDForTest(\"topic\")\n \n-\tt, err := client.CreateTopic(ctx, topicID)\n+\ttopic, err := client.CreateTopic(ctx, topicID)\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create topic: %v\", err)\n \t}\n-\tfmt.Printf(\"Topic created: %v\\n\", t)\n+\tfmt.Printf(\"Topic created: %v\\n\", topic)\n+\ttopicName = topic.String()\n+\n+\t// Generate UUID v1 for registry used for tests\n+\tregistryID = createIDForTest(\"registry\")\n+\n+\tif _, err = createRegistry(os.Stdout, projectID, region, registryID, topicName); err != nil {\n+\t\tlog.Fatalf(\"Could not create registry: %v\\n\", err)\n+\t}\n }\n \n func shutdown() {\n \tctx := context.Background()\n \n \tt := client.Topic(topicID)\n \tif err := t.Delete(ctx); err != nil {\n-\t\tlog.Fatalf(\"Could not delete topic: %v\", err)\n+\t\tlog.Fatalf(\"Could not delete topic: %v\\n\", err)\n \t}\n \tfmt.Printf(\"Deleted topic: %v\\n\", t)\n+\n+\tif _, err := deleteRegistry(os.Stdout, projectID, region, registryID); err != nil {\n+\t\tlog.Fatalf(\"Could not delete registry: %v\\n\", err)\n+\t}\n }\n \n-func TestSendCommand(t *testing.T) {\n-\t// Generate UUID v1 for test registry and device\n-\tregistryUUID, _ := uuid.NewRandom()\n-\tdeviceUUID, _ := uuid.NewRandom()\n+func TestCreateRegistry(t *testing.T) {\n+\ttestRegistryID := createIDForTest(\"registry\")\n \n-\tregion := \"us-central1\"\n-\tregistryID := \"golang-test-registry-\" + registryUUID.String()\n-\tdeviceID := \"golang-test-device-\" + deviceUUID.String()\n+\ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n+\t\tregistry, err := createRegistry(buf, projectID, region, testRegistryID, topicName)\n+\t\tif err != nil {\n+\t\t\tr.Errorf(\"Could not create registry: %v\\n\", err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tif registry.Id != testRegistryID {\n+\t\t\tr.Errorf(\"Created registry, but registryID is wrong. Got %q, want %q\", registry.Id, testRegistryID)\n+\t\t}\n \n-\ttopic := client.Topic(topicID)\n+\t\twant := fmt.Sprintf(\"Created registry:\\n\\tID: %s\", testRegistryID)\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"CreateRegistry got %s, want substring %q\", got, want)\n+\t\t}\n \n-\tvar buf bytes.Buffer\n+\t\tdeleteRegistry(ioutil.Discard, projectID, region, testRegistryID)\n \n-\tif _, err := createRegistry(&buf, projectID, region, registryID, topic.String()); err != nil {\n-\t\tt.Fatalf(\"Could not create registry: %v\", err)\n-\t}\n+\t})\n+}\n+\n+func TestGetRegistry(t *testing.T) {\n+\ttestRegistryID := createIDForTest(\"registry\")\n+\n+\ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif _, err := createRegistry(ioutil.Discard, projectID, region, testRegistryID, topicName); err != nil {\n+\t\t\tr.Errorf(\"Could not create registry: %v\\n\", err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tif _, err := getRegistry(buf, projectID, region, testRegistryID); err != nil {\n+\t\t\tr.Errorf(\"Could not get registry: %v\\n\", err)\n+\t\t}\n+\n+\t\twant := \"Got registry:\\n\\tID: \" + testRegistryID\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"GetRegistry got %s, want substring %q\", got, want)\n+\t\t}\n \n-\tif _, err := createUnauth(&buf, projectID, region, registryID, deviceID); err != nil {\n+\t\tdeleteRegistry(ioutil.Discard, projectID, region, testRegistryID)\n+\t})\n+}\n+\n+func TestListRegistries(t *testing.T) {\n+\ttestRegistryID := createIDForTest(\"registry\")\n+\n+\ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif _, err := createRegistry(ioutil.Discard, projectID, region, testRegistryID, topicName); err != nil {\n+\t\t\tr.Errorf(\"Could not create registry 1: %v\\n\", err)\n+\t\t}\n+\n+\t\tif _, err := listRegistries(buf, projectID, region); err != nil {\n+\t\t\tr.Errorf(\"Could not list registries: %v\\n\", err)\n+\t\t}\n+\n+\t\twant := testRegistryID + \"\\n\"\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"listRegistries got:\\n %s, want substring: \\n %q\", got, want)\n+\t\t}\n+\n+\t\tdeleteRegistry(ioutil.Discard, projectID, region, testRegistryID)\n+\t})\n+}\n+\n+func TestDeleteRegistry(t *testing.T) {\n+\ttestRegistryID := createIDForTest(\"registry\")\n+\n+\ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n+\t\tbuf := new(bytes.Buffer)\n+\t\tif _, err := createRegistry(ioutil.Discard, projectID, region, testRegistryID, topicName); err != nil {\n+\t\t\tr.Errorf(\"Could not create registry: %v\\n\", err)\n+\t\t}\n+\n+\t\tif _, err := deleteRegistry(buf, projectID, region, testRegistryID); err != nil {\n+\t\t\tr.Errorf(\"Could not delete registry: %v\\n\", err)\n+\t\t}\n+\n+\t\twant := \"Deleted registry: \" + testRegistryID\n+\t\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\t\tr.Errorf(\"deleteRegistry got %s, want substring %q\", got, want)\n+\t\t}\n+\t})\n+}\n+\n+func TestSendCommand(t *testing.T) {\n+\tdeviceID := createIDForTest(\"device\")\n+\n+\tif _, err := createUnauth(ioutil.Discard, projectID, region, registryID, deviceID); err != nil {\n \t\tt.Fatalf(\"Could not create device: %v\", err)\n+\t\treturn\n \t}\n \n \tcommandToSend := \"test\"\n \n \ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n-\t\t_, err := sendCommand(&buf, projectID, region, registryID, deviceID, commandToSend)\n+\t\tbuf := new(bytes.Buffer)\n+\t\t_, err := sendCommand(buf, projectID, region, registryID, deviceID, commandToSend)\n \n \t\t// Currently, there is no Go client to receive commands so instead test for the \"not subscribed\" message\n \t\tif err == nil {",
        "comments": [
            {
                "comment": "Return early?",
                "position": 113
            },
            {
                "comment": "Done.",
                "position": 113
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "99edecb877e00c9c7a78c4ca011b14625a296ed3"
    },
    {
        "pr_title": "monitoring: remove unused samples and rewrite custommetric samples",
        "pr_number": 708,
        "file_name": "monitoring/alert/alert.go",
        "code_diff": "@@ -2,20 +2,16 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// The alert sample demonstrates interacting with the monitoring\n-// and alerting API.\n-package main\n+// Package alert demonstrates interacting with the monitoring and alerting API.\n+package alert\n \n import (\n \t\"bytes\"\n \t\"context\"\n \t\"encoding/json\"\n-\t\"flag\"\n \t\"fmt\"\n \t\"io\"\n \t\"log\"\n-\t\"os\"\n-\t\"strings\"\n \n \tmonitoring \"cloud.google.com/go/monitoring/apiv3\"\n \t\"github.com/golang/protobuf/jsonpb\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7a0892de3b790d736ad296b247311f685f4b4e02"
    },
    {
        "pr_title": "monitoring: remove unused samples and rewrite custommetric samples",
        "pr_number": 708,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -2,23 +2,17 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// Command custommetric creates a custom metric and writes TimeSeries value\n-// to it. It writes a GAUGE measurement, which is a measure of value at a\n-// specific point in time. This means the startTime and endTime of the interval\n-// are the same. To make it easier to see the output, a random value is written.\n-// When reading the TimeSeries back, a window of the last 5 minutes is used.\n-package main\n+// Package custommetric contains custom metric samples.\n+package custommetric\n \n import (\n \t\"context\"\n-\t\"encoding/json\"\n \t\"fmt\"\n \t\"log\"\n \t\"math/rand\"\n-\t\"os\"\n \t\"time\"\n \n-\t\"cloud.google.com/go/monitoring/apiv3\"\n+\tmonitoring \"cloud.google.com/go/monitoring/apiv3\"\n \ttimestamp \"github.com/golang/protobuf/ptypes/timestamp\"\n \t\"google.golang.org/api/iterator\"\n \t\"google.golang.org/genproto/googleapis/api/label\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7a0892de3b790d736ad296b247311f685f4b4e02"
    },
    {
        "pr_title": "monitoring: remove unused samples and rewrite custommetric samples",
        "pr_number": 708,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -30,10 +24,6 @@\nimport (\n \n const metricType = \"custom.googleapis.com/custom_measurement\"\n \n-func projectResource(projectID string) string {\n-\treturn \"projects/\" + projectID\n-}\n-\n // [START monitoring_create_metric]\n \n // createCustomMetric creates a custom metric specified by the metric type.",
        "comments": [],
        "commit_messages": [
            "monitoring: remove unused samples and rewrite custommetric samples"
        ],
        "last_commit_sha": "7a0892de3b790d736ad296b247311f685f4b4e02"
    },
    {
        "pr_title": "monitoring: remove unused samples and rewrite custommetric samples",
        "pr_number": 708,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -66,35 +56,12 @@\nfunc createCustomMetric(projectID, metricType string) error {\n \t\treturn fmt.Errorf(\"could not create custom metric: %v\", err)\n \t}\n \n-\tlog.Printf(\"createCustomMetric: %s\\n\", formatResource(resp))\n+\tlog.Printf(\"createCustomMetric: %s\\n\", resp.GetName())\n \treturn nil\n }\n \n // [END monitoring_create_metric]\n \n-// [START monitoring_list_descriptors]\n-\n-// getCustomMetric reads the custom metric created.\n-func getCustomMetric(projectID, metricType string) (*metric.MetricDescriptor, error) {\n-\tctx := context.Background()\n-\tc, err := monitoring.NewMetricClient(ctx)\n-\tif err != nil {\n-\t\treturn nil, err\n-\t}\n-\treq := &monitoringpb.GetMetricDescriptorRequest{\n-\t\tName: fmt.Sprintf(\"projects/%s/metricDescriptors/%s\", projectID, metricType),\n-\t}\n-\tresp, err := c.GetMetricDescriptor(ctx, req)\n-\tif err != nil {\n-\t\treturn nil, fmt.Errorf(\"could not get custom metric: %v\", err)\n-\t}\n-\n-\tlog.Printf(\"getCustomMetric: %s\\n\", formatResource(resp))\n-\treturn resp, nil\n-}\n-\n-// [END monitoring_list_descriptors]\n-\n // [START monitoring_delete_metric]\n \n // deleteMetric deletes the given metric.",
        "comments": [],
        "commit_messages": [
            "monitoring: remove unused samples and rewrite custommetric samples"
        ],
        "last_commit_sha": "7a0892de3b790d736ad296b247311f685f4b4e02"
    },
    {
        "pr_title": "monitoring: remove unused samples and rewrite custommetric samples",
        "pr_number": 708,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -131,7 +98,7 @@\nfunc writeTimeSeriesValue(projectID, metricType string) error {\n \t\tSeconds: time.Now().Unix(),\n \t}\n \treq := &monitoringpb.CreateTimeSeriesRequest{\n-\t\tName: projectResource(projectID),\n+\t\tName: \"projects/\" + projectID,\n \t\tTimeSeries: []*monitoringpb.TimeSeries{{\n \t\t\tMetric: &metricpb.Metric{\n \t\t\t\tType: metricType,",
        "comments": [],
        "commit_messages": [
            "monitoring: remove unused samples and rewrite custommetric samples"
        ],
        "last_commit_sha": "7a0892de3b790d736ad296b247311f685f4b4e02"
    },
    {
        "pr_title": "monitoring: remove unused samples and rewrite custommetric samples",
        "pr_number": 708,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -159,7 +126,7 @@\nfunc writeTimeSeriesValue(projectID, metricType string) error {\n \t\t\t}},\n \t\t}},\n \t}\n-\tlog.Printf(\"writeTimeseriesRequest: %s\\n\", formatResource(req))\n+\tlog.Printf(\"writeTimeseriesRequest: %+v\\n\", req)\n \n \terr = c.CreateTimeSeries(ctx, req)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "monitoring: remove unused samples and rewrite custommetric samples"
        ],
        "last_commit_sha": "7a0892de3b790d736ad296b247311f685f4b4e02"
    },
    {
        "pr_title": "monitoring: remove unused samples and rewrite custommetric samples",
        "pr_number": 708,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -183,7 +150,7 @@\nfunc readTimeSeriesValue(projectID, metricType string) error {\n \tendTime := time.Now().UTC().Unix()\n \n \treq := &monitoringpb.ListTimeSeriesRequest{\n-\t\tName:   projectResource(projectID),\n+\t\tName:   \"projects/\" + projectID,\n \t\tFilter: fmt.Sprintf(\"metric.type=\\\"%s\\\"\", metricType),\n \t\tInterval: &monitoringpb.TimeInterval{\n \t\t\tStartTime: &timestamp.Timestamp{Seconds: startTime},",
        "comments": [],
        "commit_messages": [
            "monitoring: remove unused samples and rewrite custommetric samples"
        ],
        "last_commit_sha": "7a0892de3b790d736ad296b247311f685f4b4e02"
    },
    {
        "pr_title": "monitoring: remove unused samples and rewrite custommetric samples",
        "pr_number": 708,
        "file_name": "monitoring/custommetric/custommetric.go",
        "code_diff": "@@ -192,7 +159,6 @@\nfunc readTimeSeriesValue(projectID, metricType string) error {\n \t}\n \titer := c.ListTimeSeries(ctx, req)\n \n-\tvar series []*monitoringpb.TimeSeries\n \tfor {\n \t\tresp, err := iter.Next()\n \t\tif err == iterator.Done {",
        "comments": [],
        "commit_messages": [
            "monitoring: remove unused samples and rewrite custommetric samples"
        ],
        "last_commit_sha": "7a0892de3b790d736ad296b247311f685f4b4e02"
    },
    {
        "pr_title": "monitoring: remove unused samples and rewrite custommetric samples",
        "pr_number": 708,
        "file_name": "monitoring/custommetric/custommetric_test.go",
        "code_diff": "@@ -2,16 +2,21 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-package main\n+package custommetric\n \n import (\n+\t\"context\"\n+\t\"fmt\"\n \t\"io/ioutil\"\n \t\"log\"\n \t\"os\"\n \t\"testing\"\n \t\"time\"\n \n+\tmonitoring \"cloud.google.com/go/monitoring/apiv3\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n+\t\"google.golang.org/genproto/googleapis/api/metric\"\n+\tmonitoringpb \"google.golang.org/genproto/googleapis/monitoring/v3\"\n )\n \n func TestMain(m *testing.M) {",
        "comments": [],
        "commit_messages": [
            "monitoring: remove unused samples and rewrite custommetric samples"
        ],
        "last_commit_sha": "7a0892de3b790d736ad296b247311f685f4b4e02"
    },
    {
        "pr_title": "monitoring: remove unused samples and rewrite custommetric samples",
        "pr_number": 708,
        "file_name": "monitoring/snippets/metric_get_test.go",
        "code_diff": "@@ -6,28 +6,24 @@\npackage snippets\n \n import (\n \t\"bytes\"\n-\t\"context\"\n-\t\"fmt\"\n+\t\"io/ioutil\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"\n \n-\tmonitoring \"cloud.google.com/go/monitoring/apiv3\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"google.golang.org/genproto/googleapis/api/metric\"\n-\tmonitoringpb \"google.golang.org/genproto/googleapis/monitoring/v3\"\n )\n \n const metricType = \"custom.googleapis.com/golang-samples-tests/get\"\n \n func TestGetMetricDescriptor(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \n-\tm, err := createMetric(tc.ProjectID)\n+\tm, err := createCustomMetric(ioutil.Discard, tc.ProjectID, metricType)\n \tif err != nil {\n \t\tt.Fatalf(\"createMetric: %v\", err)\n \t}\n-\tdefer deleteMetric(m.GetName())\n+\tdefer deleteMetric(ioutil.Discard, m.GetName())\n \n \ttestutil.Retry(t, 10, 10*time.Second, func(r *testutil.R) {\n \t\tbuf := &bytes.Buffer{}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "7a0892de3b790d736ad296b247311f685f4b4e02"
    },
    {
        "pr_title": "testing/gimmeproj: add option to output list",
        "pr_number": 698,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -32,6 +32,7 @@\nimport (\n \n var (\n \tmetaProject = flag.String(\"project\", \"\", \"Meta-project that manages the pool.\")\n+\tformat      = flag.String(\"output\", \"\", \"Output format for selected operations. Options include: list\")\n \tdatastore   *ds.Client\n \n \tversion   = \"dev\"",
        "comments": [],
        "commit_messages": [
            "testing/gimmeproj: switch to -output flag on status command"
        ],
        "last_commit_sha": "b63645bbd41d4fe15d6a96f5817efe2574462831"
    },
    {
        "pr_title": "testing/gimmeproj: add option to output list",
        "pr_number": 698,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -102,6 +103,7 @@\nfunc submain() error {\n \tusage := errors.New(`\n Usage:\n \tgimmeproj -project=[meta project ID] command\n+\tgimmeproj -project=[meta project ID] -output=list status\n \n Commands:\n \tlease [duration]    Leases a project for a given duration. Prints the project ID to stdout.",
        "comments": [],
        "commit_messages": [
            "testing/gimmeproj: switch to -output flag on status command"
        ],
        "last_commit_sha": "b63645bbd41d4fe15d6a96f5817efe2574462831"
    },
    {
        "pr_title": "testing/gimmeproj: add option to output list",
        "pr_number": 698,
        "file_name": "testing/gimmeproj/main.go",
        "code_diff": "@@ -111,7 +113,7 @@\nCommands:\n Administrative commands:\n \tpool-add [project ID]       Adds a project to the pool.\n \tpool-rm  [project ID]       Removes a project from the pool.\n-\tstatus                      Displays the current status of the meta project.\n+\tstatus                      Displays the current status of the meta project. Respects -output.\n `)\n \n \tif flag.Arg(0) == \"version\" {",
        "comments": [],
        "commit_messages": [
            "testing/gimmeproj: switch to -output flag on status command"
        ],
        "last_commit_sha": "b63645bbd41d4fe15d6a96f5817efe2574462831"
    },
    {
        "pr_title": "videointelligence: add speech transcription snippet",
        "pr_number": 697,
        "file_name": "videointelligence/video_analyze/video_analyze_test.go",
        "code_diff": "@@ -14,6 +14,7 @@\nimport (\n )\n \n const catVideo = \"gs://demomaker/cat.mp4\"\n+const googleworkVideo = \"gs://python-docs-samples-tests/video/googlework_short.mp4\"\n \n func TestAnalyze(t *testing.T) {\n \ttestutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [
            "Add videointelligence speech transcription snippet"
        ],
        "last_commit_sha": "7569b56b6b1e459bed6e3d851f97c91d3487a216"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2018 Google Inc. All rights reserved.\n+// Copyright 2018 Google LLC. All rights reserved.\n // Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -9,13 +9,15 @@\nimport (\n \t\"bytes\"\n \t\"flag\"\n \t\"fmt\"\n+\t\"io\"\n \t\"io/ioutil\"\n \t\"os\"\n \t\"path/filepath\"\n \t\"reflect\"\n \n \t// [START imports]\n \t\"context\"\n+\tb64 \"encoding/base64\"\n \n \t\"golang.org/x/oauth2/google\"\n \tcloudiot \"google.golang.org/api/cloudiot/v1\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -24,9 +26,10 @@\nimport (\n \n // Registry Management\n \n+// [START iot_create_registry]\n+\n // createRegistry creates a device registry.\n-func createRegistry(projectID string, region string, registryID string, topicName string) (*cloudiot.DeviceRegistry, error) {\n-\t// [START iot_create_registry]\n+func createRegistry(w io.Writer, projectID string, region string, registryID string, topicName string) (*cloudiot.DeviceRegistry, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "update manager functions with io.Writer and add command test"
        ],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -54,19 +57,21 @@\nfunc createRegistry(projectID string, region string, registryID string, topicNam\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Created registry:\")\n-\tfmt.Println(\"\\tID: \", response.Id)\n-\tfmt.Println(\"\\tHTTP: \", response.HttpConfig.HttpEnabledState)\n-\tfmt.Println(\"\\tMQTT: \", response.MqttConfig.MqttEnabledState)\n-\tfmt.Println(\"\\tName: \", response.Name)\n-\t// [END iot_create_registry]\n+\tfmt.Fprintln(w, \"Created registry:\")\n+\tfmt.Fprintf(w, \"\\tID: %s\\n\", response.Id)\n+\tfmt.Fprintf(w, \"\\tHTTP: %s\\n\", response.HttpConfig.HttpEnabledState)\n+\tfmt.Fprintf(w, \"\\tMQTT: %s\\n\", response.MqttConfig.MqttEnabledState)\n+\tfmt.Fprintf(w, \"\\tName: %s\\n\", response.Name)\n \n \treturn response, err\n }\n \n-// deleteRegistry deletes a device registry\n-func deleteRegistry(projectID string, region string, registryID string) (*cloudiot.Empty, error) {\n-\t// [START iot_delete_registry]\n+// [END iot_create_registry]\n+\n+// [START iot_delete_registry]\n+\n+// deleteRegistry deletes a device registry if it is empty.\n+func deleteRegistry(w io.Writer, projectID string, region string, registryID string) (*cloudiot.Empty, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [
            {
                "comment": "Please add a function comment.",
                "position": 84
            },
            {
                "comment": "Done",
                "position": 84
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -85,14 +90,17 @@\nfunc deleteRegistry(projectID string, region string, registryID string) (*cloudi\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Deleted registry\")\n-\t// [END iot_delete_registry]\n+\tfmt.Fprintln(w, \"Deleted registry\")\n \n \treturn response, err\n }\n \n-func getRegistry(projectID string, region string, registryID string) (*cloudiot.DeviceRegistry, error) {\n-\t// [START iot_get_registry]\n+// [END iot_delete_registry]\n+\n+// [START iot_get_registry]\n+\n+// getRegistry gets information about a device registry given a registryID.\n+func getRegistry(w io.Writer, projectID string, region string, registryID string) (*cloudiot.DeviceRegistry, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -110,14 +118,22 @@\nfunc getRegistry(projectID string, region string, registryID string) (*cloudiot.\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\t// [END iot_get_iam]\n+\n+\tfmt.Fprintln(w, \"Got registry:\")\n+\tfmt.Fprintf(w, \"\\tID: %s\\n\", response.Id)\n+\tfmt.Fprintf(w, \"\\tHTTP: %s\\n\", response.HttpConfig.HttpEnabledState)\n+\tfmt.Fprintf(w, \"\\tMQTT: %s\\n\", response.MqttConfig.MqttEnabledState)\n+\tfmt.Fprintf(w, \"\\tName: %s\\n\", response.Name)\n \n \treturn response, err\n }\n \n-// getRegistryIam gets the IAM policy for a device registry.\n-func getRegistryIam(projectID string, region string, registryID string) (*cloudiot.Policy, error) {\n-\t// [START iot_get_iam_policy]\n+// [END iot_get_registry]\n+\n+// [START iot_list_registries]\n+\n+// listRegistries gets the names of device registries given a project / region.\n+func listRegistries(w io.Writer, projectID string, region string) ([]*cloudiot.DeviceRegistry, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -130,29 +146,26 @@\nfunc getRegistryIam(projectID string, region string, registryID string) (*cloudi\n \t\treturn nil, err\n \t}\n \n-\tvar req cloudiot.GetIamPolicyRequest\n-\n-\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n-\tresponse, err := client.Projects.Locations.Registries.GetIamPolicy(path, &req).Do()\n+\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", projectID, region)\n+\tresponse, err := client.Projects.Locations.Registries.List(parent).Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Policy:\")\n-\tfor _, binding := range response.Bindings {\n-\t\tfmt.Fprintf(os.Stdout, \"Role: %s\\n\", binding.Role)\n-\t\tfor _, member := range binding.Members {\n-\t\t\tfmt.Fprintf(os.Stdout, \"\\tMember: %s\\n\", member)\n-\t\t}\n+\tfmt.Fprintln(w, \"Registries:\")\n+\tfor _, registry := range response.DeviceRegistries {\n+\t\tfmt.Fprintf(w, \"\\t%s\\n\", registry.Name)\n \t}\n-\t// [END iot_get_iam_policy]\n \n-\treturn response, err\n+\treturn response.DeviceRegistries, err\n }\n \n-// listRegistries gets the names of device registries given a project / region.\n-func listRegistries(projectID string, region string) ([]*cloudiot.DeviceRegistry, error) {\n-\t// [START iot_list_registries]\n+// [END iot_list_registries]\n+\n+// [START iot_get_iam_policy]\n+\n+// getRegistryIAM gets the IAM policy for a device registry.\n+func getRegistryIAM(w io.Writer, projectID string, region string, registryID string) (*cloudiot.Policy, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -165,24 +178,31 @@\nfunc listRegistries(projectID string, region string) ([]*cloudiot.DeviceRegistry\n \t\treturn nil, err\n \t}\n \n-\tparent := fmt.Sprintf(\"projects/%s/locations/%s\", projectID, region)\n-\tresponse, err := client.Projects.Locations.Registries.List(parent).Do()\n+\tvar req cloudiot.GetIamPolicyRequest\n+\n+\tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s\", projectID, region, registryID)\n+\tresponse, err := client.Projects.Locations.Registries.GetIamPolicy(path, &req).Do()\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Registries:\")\n-\tfor _, registry := range response.DeviceRegistries {\n-\t\tfmt.Println(\"\\t\", registry.Name)\n+\tfmt.Fprintln(w, \"Policy:\")\n+\tfor _, binding := range response.Bindings {\n+\t\tfmt.Fprintf(w, \"Role: %s\\n\", binding.Role)\n+\t\tfor _, member := range binding.Members {\n+\t\t\tfmt.Fprintf(w, \"\\tMember: %s\\n\", member)\n+\t\t}\n \t}\n-\t// [END iot_list_registries]\n \n-\treturn response.DeviceRegistries, err\n+\treturn response, err\n }\n \n-// setRegistryIam sets the IAM policy for a device registry\n-func setRegistryIam(projectID string, region string, registryID string, member string, role string) (*cloudiot.Policy, error) {\n-\t// [START iot_set_iam_policy]\n+// [END iot_get_iam_policy]\n+\n+// [START iot_set_iam_policy]\n+\n+// setRegistryIAM sets the IAM policy for a device registry\n+func setRegistryIAM(w io.Writer, projectID string, region string, registryID string, member string, role string) (*cloudiot.Policy, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -211,17 +231,19 @@\nfunc setRegistryIam(projectID string, region string, registryID string, member s\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Set policy!\")\n-\t// [END iot_set_iam_policy]\n+\tfmt.Fprintf(w, \"Successfully set IAM policy for registry: %s\\n\", registryID)\n \n \treturn response, err\n }\n \n+// [END iot_set_iam_policy]\n+\n // Device Management\n \n-// createEs creates a device in a registry with ES credentials\n-func createEs(projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n-\t// [START iot_create_es_device]\n+// [START iot_create_es_device]\n+\n+// createES creates a device in a registry with ES credentials.\n+func createES(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -257,15 +279,17 @@\nfunc createEs(projectID string, region string, registry string, deviceID string,\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully created device.\")\n-\t// [END iot_create_es_device]\n+\tfmt.Fprintln(w, \"Successfully created ESA device\")\n \n \treturn response, err\n }\n \n-// createRsa creates a device in a registry with RS credentials\n-func createRsa(projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n-\t// [START iot_create_rsa_device]\n+// [END iot_create_es_device]\n+\n+// [START iot_create_rsa_device]\n+\n+// createRSA creates a device in a registry with RS credentials.\n+func createRSA(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -301,15 +325,17 @@\nfunc createRsa(projectID string, region string, registry string, deviceID string\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully created device.\")\n-\t// [END iot_create_rsa_device]\n+\tfmt.Fprintln(w, \"Successfully created RSA device\")\n \n \treturn response, err\n }\n \n-// createUnauth creates a device in a registry without credentials\n-func createUnauth(projectID string, region string, registry string, deviceID string) (*cloudiot.Device, error) {\n-\t// [START iot_create_unauth_device]\n+// [END iot_create_rsa_device]\n+\n+// [START iot_create_unauth_device]\n+\n+// createUnauth creates a device in a registry without credentials.\n+func createUnauth(w io.Writer, projectID string, region string, registry string, deviceID string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -331,15 +357,17 @@\nfunc createUnauth(projectID string, region string, registry string, deviceID str\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully created device.\")\n-\t// [END iot_create_unauth_device]\n+\tfmt.Fprintln(w, \"Successfully created device without credentials\")\n \n \treturn response, err\n }\n \n-// deleteDevice deletes a device from a registry\n-func deleteDevice(projectID string, region string, registry string, deviceID string) (*cloudiot.Empty, error) {\n-\t// [START iot_delete_device]\n+// [END iot_create_unauth_device]\n+\n+// [START iot_delete_device]\n+\n+// deleteDevice deletes a device from a registry.\n+func deleteDevice(w io.Writer, projectID string, region string, registry string, deviceID string) (*cloudiot.Empty, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -358,15 +386,17 @@\nfunc deleteDevice(projectID string, region string, registry string, deviceID str\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Deleted device!\")\n-\t// [END iot_delete_device]\n+\tfmt.Fprintf(w, \"Deleted device: %s\\n\", deviceID)\n \n \treturn response, err\n }\n \n-// getDevice retrieves a specific device and prints its details\n-func getDevice(projectID string, region string, registry string, device string) (*cloudiot.Device, error) {\n-\t// [START iot_get_device]\n+// [END iot_delete_device]\n+\n+// [START iot_get_device]\n+\n+// getDevice retrieves a specific device and prints its details.\n+func getDevice(w io.Writer, projectID string, region string, registry string, device string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -385,26 +415,28 @@\nfunc getDevice(projectID string, region string, registry string, device string)\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"\\tId: \", response.Id)\n+\tfmt.Fprintf(w, \"\\tId: %s\\n\", response.Id)\n \tfor _, credential := range response.Credentials {\n-\t\tfmt.Println(\"\\t\\tCredential Expire: \", credential.ExpirationTime)\n-\t\tfmt.Println(\"\\t\\tCredential Type: \", credential.PublicKey.Format)\n-\t\tfmt.Println(\"\\t\\t--------\")\n+\t\tfmt.Fprintf(w, \"\\t\\tCredential Expire: %s\\n\", credential.ExpirationTime)\n+\t\tfmt.Fprintf(w, \"\\t\\tCredential Type: %s\\n\", credential.PublicKey.Format)\n+\t\tfmt.Fprintln(w, \"\\t\\t--------\")\n \t}\n-\tfmt.Println(\"\\tLast Config Ack: \", response.LastConfigAckTime)\n-\tfmt.Println(\"\\tLast Config Send: \", response.LastConfigSendTime)\n-\tfmt.Println(\"\\tLast Event Time: \", response.LastEventTime)\n-\tfmt.Println(\"\\tLast Heartbeat Time: \", response.LastHeartbeatTime)\n-\tfmt.Println(\"\\tLast State Time: \", response.LastStateTime)\n-\tfmt.Println(\"\\tNumId: \", response.NumId)\n+\tfmt.Fprintf(w, \"\\tLast Config Ack: %s\\n\", response.LastConfigAckTime)\n+\tfmt.Fprintf(w, \"\\tLast Config Send: %s\\n\", response.LastConfigSendTime)\n+\tfmt.Fprintf(w, \"\\tLast Event Time: %s\\n\", response.LastEventTime)\n+\tfmt.Fprintf(w, \"\\tLast Heartbeat Time: %s\\n\", response.LastHeartbeatTime)\n+\tfmt.Fprintf(w, \"\\tLast State Time: %s\\n\", response.LastStateTime)\n+\tfmt.Fprintf(w, \"\\tNumId: %d\\n\", response.NumId)\n \n \treturn response, err\n-\t// [END iot_get_device]\n }\n \n-// getDeviceConfigs retrieves and lists device configurations\n-func getDeviceConfigs(projectID string, region string, registry string, device string) ([]*cloudiot.DeviceConfig, error) {\n-\t// [START iot_get_device_configs]\n+// [END iot_get_device]\n+\n+// [START iot_get_device_configs]\n+\n+// getDeviceConfigs retrieves and lists device configurations.\n+func getDeviceConfigs(w io.Writer, projectID string, region string, registry string, device string) ([]*cloudiot.DeviceConfig, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -424,16 +456,18 @@\nfunc getDeviceConfigs(projectID string, region string, registry string, device s\n \t}\n \n \tfor _, config := range response.DeviceConfigs {\n-\t\tfmt.Println(config.Version, \" : \", config.BinaryData)\n+\t\tfmt.Fprintf(w, \"%d : %s\\n\", config.Version, config.BinaryData)\n \t}\n-\t// [END iot_get_device_configs]\n \n \treturn response.DeviceConfigs, err\n }\n \n-// getDeviceStates retrieves and lists device states\n-func getDeviceStates(projectID string, region string, registry string, device string) ([]*cloudiot.DeviceState, error) {\n-\t// [START iot_get_device_state]\n+// [END iot_get_device_configs]\n+\n+// [START iot_get_device_state]\n+\n+// getDeviceStates retrieves and lists device states.\n+func getDeviceStates(w io.Writer, projectID string, region string, registry string, device string) ([]*cloudiot.DeviceState, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -452,19 +486,21 @@\nfunc getDeviceStates(projectID string, region string, registry string, device st\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully retrieved device states!\")\n+\tfmt.Fprintln(w, \"Successfully retrieved device states!\")\n \n \tfor _, state := range response.DeviceStates {\n-\t\tfmt.Println(state.UpdateTime, \" : \", state.BinaryData)\n+\t\tfmt.Fprintf(w, \"%s : %s\\n\", state.UpdateTime, state.BinaryData)\n \t}\n-\t// [END iot_get_device_state]\n \n \treturn response.DeviceStates, err\n }\n \n-// listDevices gets the identifiers of devices given a registry name\n-func listDevices(projectID string, region string, registry string) ([]*cloudiot.Device, error) {\n-\t// [START iot_list_devices]\n+// [END iot_get_device_state]\n+\n+// [START iot_list_devices]\n+\n+// listDevices gets the identifiers of devices given a registry name.\n+func listDevices(w io.Writer, projectID string, region string, registry string) ([]*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -483,18 +519,20 @@\nfunc listDevices(projectID string, region string, registry string) ([]*cloudiot.\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Devices:\")\n+\tfmt.Fprintln(w, \"Devices:\")\n \tfor _, device := range response.Devices {\n-\t\tfmt.Println(\"\\t\", device.Id)\n+\t\tfmt.Fprintf(w, \"\\t%s\\n\", device.Id)\n \t}\n-\t// [END iot_list_devices]\n \n \treturn response.Devices, err\n }\n \n-// patchDeviceEs patches a device to use ES credentials\n-func patchDeviceEs(projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n-\t// [START iot_patch_es]\n+// [END iot_list_devices]\n+\n+// [START iot_patch_es]\n+\n+// patchDeviceES patches a device to use ES credentials.\n+func patchDeviceES(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -531,15 +569,17 @@\nfunc patchDeviceEs(projectID string, region string, registry string, deviceID st\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully patched device.\")\n-\t// [END iot_patch_es]\n+\tfmt.Fprintln(w, \"Successfully patched device with ES credentials\")\n \n \treturn response, err\n }\n \n-// patchDeviceRsa patches a device to use RSA credentials\n-func patchDeviceRsa(projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n-\t// [START iot_patch_rsa]\n+// [END iot_patch_es]\n+\n+// [START iot_patch_rsa]\n+\n+// patchDeviceRSA patches a device to use RSA credentials.\n+func patchDeviceRSA(w io.Writer, projectID string, region string, registry string, deviceID string, keyPath string) (*cloudiot.Device, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -576,15 +616,17 @@\nfunc patchDeviceRsa(projectID string, region string, registry string, deviceID s\n \t\treturn nil, err\n \t}\n \n-\tfmt.Println(\"Successfully patched device.\")\n-\t// [END iot_patch_rsa]\n+\tfmt.Fprintln(w, \"Successfully patched device\")\n \n \treturn response, err\n }\n \n+// [END iot_patch_rsa]\n+\n+// [START iot_set_device_config]\n+\n // setConfig sends a configuration change to a device.\n-func setConfig(projectID string, region string, registry string, deviceID string, configData string) (*cloudiot.DeviceConfig, error) {\n-\t// [START iot_set_device_config]\n+func setConfig(w io.Writer, projectID string, region string, registry string, deviceID string, configData string, format string) (*cloudiot.DeviceConfig, error) {\n \t// Authorize the client using Application Default Credentials.\n \t// See https://g.co/dv/identity/protocols/application-default-credentials\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -598,7 +640,7 @@\nfunc setConfig(projectID string, region string, registry string, deviceID string\n \t}\n \n \treq := cloudiot.ModifyCloudToDeviceConfigRequest{\n-\t\tBinaryData: configData,\n+\t\tBinaryData: b64.StdEncoding.EncodeToString([]byte(configData)),\n \t}\n \n \tpath := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, deviceID)",
        "comments": [],
        "commit_messages": [
            "update manager functions with io.Writer and add command test"
        ],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -607,12 +649,47 @@\nfunc setConfig(projectID string, region string, registry string, deviceID string\n \t\treturn nil, err\n \t}\n \n-\tfmt.Fprintf(os.Stdout, \"Config set!\\nVersion now: %d\", response.Version)\n-\t// [END iot_set_device_config]\n+\tfmt.Fprintf(w, \"Config set!\\nVersion now: %d\\n\", response.Version)\n \n \treturn response, err\n }\n \n+// [END iot_set_device_config]\n+\n+// [START iot_send_command]\n+\n+// sendCommand sends a command to a device listening for commands.\n+func sendCommand(w io.Writer, projectID string, region string, registry string, deviceID string, sendData string) (*cloudiot.SendCommandToDeviceResponse, error) {\n+\t// Authorize the client using Application Default Credentials.\n+\t// See https://g.co/dv/identity/protocols/application-default-credentials\n+\tctx := context.Background()\n+\thttpClient, err := google.DefaultClient(ctx, cloudiot.CloudPlatformScope)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tclient, err := cloudiot.New(httpClient)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\treq := cloudiot.SendCommandToDeviceRequest{\n+\t\tBinaryData: b64.StdEncoding.EncodeToString([]byte(sendData)),\n+\t}\n+\n+\tname := fmt.Sprintf(\"projects/%s/locations/%s/registries/%s/devices/%s\", projectID, region, registry, deviceID)\n+\n+\tresponse, err := client.Projects.Locations.Registries.Devices.SendCommandToDevice(name, &req).Do()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tfmt.Fprintln(w, \"Sent command to device\")\n+\n+\treturn response, err\n+}\n+\n+// [END iot_send_command]\n+\n type command struct {\n \tname string\n \tfn   interface{}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -638,22 +715,23 @@\nfunc main() {\n \t\t{\"deleteRegistry\", deleteRegistry, []string{\"cloud-region\", \"registry-id\"}},\n \t\t{\"getRegistry\", getRegistry, []string{\"cloud-region\", \"registry-id\"}},\n \t\t{\"listRegistries\", listRegistries, []string{\"cloud-region\"}},\n-\t\t{\"getRegistryIam\", getRegistryIam, []string{\"cloud-region\", \"registry-id\"}},\n-\t\t{\"setRegistryIam\", setRegistryIam, []string{\"cloud-region\", \"registry-id\", \"member\", \"role\"}},\n+\t\t{\"getRegistryIAM\", getRegistryIAM, []string{\"cloud-region\", \"registry-id\"}},\n+\t\t{\"setRegistryIAM\", setRegistryIAM, []string{\"cloud-region\", \"registry-id\", \"member\", \"role\"}},\n \t}\n \n \tdeviceManagementCommands := []command{\n-\t\t{\"createEs\", createEs, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n-\t\t{\"createRsa\", createRsa, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n+\t\t{\"createES\", createES, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n+\t\t{\"createRSA\", createRSA, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n \t\t{\"createUnauth\", createUnauth, []string{\"cloud-region\", \"registry-id\", \"device-id\"}},\n \t\t{\"deleteDevice\", deleteDevice, []string{\"cloud-region\", \"registry-id\", \"device-id\"}},\n \t\t{\"getDevice\", getDevice, []string{\"cloud-region\", \"registry-id\", \"device-id\"}},\n \t\t{\"getDeviceConfigs\", getDeviceConfigs, []string{\"cloud-region\", \"registry-id\", \"device-id\"}},\n \t\t{\"getDeviceStates\", getDeviceStates, []string{\"cloud-region\", \"registry-id\", \"device-id\"}},\n \t\t{\"listDevices\", listDevices, []string{\"cloud-region\", \"registry-id\"}},\n-\t\t{\"patchDeviceEs\", patchDeviceEs, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n-\t\t{\"patchDeviceRsa\", patchDeviceRsa, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n+\t\t{\"patchDevice\", patchDeviceES, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n+\t\t{\"patchDeviceRSA\", patchDeviceRSA, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"keyfile-path\"}},\n \t\t{\"setConfig\", setConfig, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"config-data\"}},\n+\t\t{\"sendCommand\", sendCommand, []string{\"cloud-region\", \"registry-id\", \"device-id\", \"send-data\"}},\n \t}\n \n \tvar commands []command",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "iot: add sample for iot core commands ",
        "pr_number": 694,
        "file_name": "iot/manager/manager.go",
        "code_diff": "@@ -676,7 +754,7 @@\nfunc main() {\n \t}\n \tflag.Parse()\n \n-\t// Retrieve project ID from console\n+\t// Retrieve project ID from console.\n \tprojectID := os.Getenv(\"GCLOUD_PROJECT\")\n \tif projectID == \"\" {\n \t\tprojectID = os.Getenv(\"GOOGLE_CLOUD_PROJECT\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "70b7fc829f4f7c623b952763be331f6d2daacc31"
    },
    {
        "pr_title": "appengine_flexible/pubsub: verify token and log startup",
        "pr_number": 690,
        "file_name": "appengine_flexible/pubsub/pubsub.go",
        "code_diff": "@@ -16,7 +16,6 @@\nimport (\n \t\"sync\"\n \n \t\"cloud.google.com/go/pubsub\"\n-\t\"google.golang.org/appengine\"\n )\n \n var (",
        "comments": [],
        "commit_messages": [
            "appengine_flexible/pubsub: verify token and log startup"
        ],
        "last_commit_sha": "8bbdf56ab23de9380b68c94998773a038669ed26"
    },
    {
        "pr_title": "appengine_flexible/pubsub: verify token and log startup",
        "pr_number": 690,
        "file_name": "appengine_flexible/pubsub/pubsub.go",
        "code_diff": "@@ -25,6 +24,9 @@\nvar (\n \t// Messages received by this instance.\n \tmessagesMu sync.Mutex\n \tmessages   []string\n+\n+\t// token is used to verify push requests.\n+\ttoken = mustGetenv(\"PUBSUB_VERIFICATION_TOKEN\")\n )\n \n const maxMessages = 10",
        "comments": [],
        "commit_messages": [
            "appengine_flexible/pubsub: verify token and log startup"
        ],
        "last_commit_sha": "8bbdf56ab23de9380b68c94998773a038669ed26"
    },
    {
        "pr_title": "appengine_flexible/pubsub: verify token and log startup",
        "pr_number": 690,
        "file_name": "appengine_flexible/pubsub/pubsub.go",
        "code_diff": "@@ -37,9 +39,9 @@\nfunc main() {\n \t\tlog.Fatal(err)\n \t}\n \n-\t// Create topic if it doesn't exist.\n \ttopicName := mustGetenv(\"PUBSUB_TOPIC\")\n \ttopic = client.Topic(topicName)\n+\n \t// Create the topic if it doesn't exist.\n \texists, err := topic.Exists(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "appengine_flexible/pubsub: verify token and log startup"
        ],
        "last_commit_sha": "8bbdf56ab23de9380b68c94998773a038669ed26"
    },
    {
        "pr_title": "appengine_flexible/pubsub: verify token and log startup",
        "pr_number": 690,
        "file_name": "appengine_flexible/pubsub/pubsub.go",
        "code_diff": "@@ -57,7 +59,14 @@\nfunc main() {\n \thttp.HandleFunc(\"/pubsub/publish\", publishHandler)\n \thttp.HandleFunc(\"/pubsub/push\", pushHandler)\n \n-\tappengine.Main()\n+\tport := os.Getenv(\"PORT\")\n+\tif port == \"\" {\n+\t\tport = \"8080\"\n+\t\tlog.Printf(\"Defaulting to port %s\", port)\n+\t}\n+\n+\tlog.Printf(\"Listening on port %s\", port)\n+\tlog.Fatal(http.ListenAndServe(fmt.Sprintf(\":%s\", port), nil))\n }\n \n func mustGetenv(k string) string {",
        "comments": [],
        "commit_messages": [
            "appengine_flexible/pubsub: verify token and log startup"
        ],
        "last_commit_sha": "8bbdf56ab23de9380b68c94998773a038669ed26"
    },
    {
        "pr_title": "firestore: add regions sample data and two queries",
        "pr_number": 659,
        "file_name": "firestore/firestore_snippets/main.go",
        "code_diff": "@@ -15,13 +15,15 @@\nimport (\n )\n \n // [START fs_class_definition]\n+\n // City represents a city.\n type City struct {\n-\tName       string `firestore:\"name,omitempty\"`\n-\tState      string `firestore:\"state,omitempty\"`\n-\tCountry    string `firestore:\"country,omitempty\"`\n-\tCapital    bool   `firestore:\"capital,omitempty\"`\n-\tPopulation int64  `firestore:\"population,omitempty\"`\n+\tName       string   `firestore:\"name,omitempty\"`\n+\tState      string   `firestore:\"state,omitempty\"`\n+\tCountry    string   `firestore:\"country,omitempty\"`\n+\tCapital    bool     `firestore:\"capital,omitempty\"`\n+\tPopulation int64    `firestore:\"population,omitempty\"`\n+\tRegions    []string `firestore:\"regions,omitempty\"`\n }\n \n // [END fs_class_definition]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "00594c486c4f729613d1b8fd5d18da637c0ba33d"
    },
    {
        "pr_title": "firestore: add regions sample data and two queries",
        "pr_number": 659,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage main\n // [START fs_dependencies]\n import (\n \t\"context\"\n+\t\"fmt\"\n \n \t\"cloud.google.com/go/firestore\"\n )",
        "comments": [],
        "commit_messages": [
            "Add Firestore Regions sample data and two queries."
        ],
        "last_commit_sha": "00594c486c4f729613d1b8fd5d18da637c0ba33d"
    },
    {
        "pr_title": "firestore: add regions sample data and two queries",
        "pr_number": 659,
        "file_name": "firestore/firestore_snippets/query.go",
        "code_diff": "@@ -19,11 +20,36 @@\nfunc prepareQuery(ctx context.Context, client *firestore.Client) error {\n \t\tid string\n \t\tc  City\n \t}{\n-\t\t{id: \"SF\", c: City{Name: \"San Francisco\", State: \"CA\", Country: \"USA\", Capital: false, Population: 860000}},\n-\t\t{id: \"LA\", c: City{Name: \"Los Angeles\", State: \"CA\", Country: \"USA\", Capital: false, Population: 3900000}},\n-\t\t{id: \"DC\", c: City{Name: \"Washington D.C.\", Country: \"USA\", Capital: false, Population: 680000}},\n-\t\t{id: \"TOK\", c: City{Name: \"Tokyo\", Country: \"Japan\", Capital: true, Population: 9000000}},\n-\t\t{id: \"BJ\", c: City{Name: \"Beijing\", Country: \"China\", Capital: true, Population: 21500000}},\n+\t\t{\n+\t\t\tid: \"SF\",\n+\t\t\tc: City{Name: \"San Francisco\", State: \"CA\", Country: \"USA\",\n+\t\t\t\tCapital: false, Population: 860000,\n+\t\t\t\tRegions: []string{\"west_coast\", \"norcal\"}},\n+\t\t},\n+\t\t{\n+\t\t\tid: \"LA\",\n+\t\t\tc: City{Name: \"Los Angeles\", State: \"CA\", Country: \"USA\",\n+\t\t\t\tCapital: false, Population: 3900000,\n+\t\t\t\tRegions: []string{\"west_coast\", \"socal\"}},\n+\t\t},\n+\t\t{\n+\t\t\tid: \"DC\",\n+\t\t\tc: City{Name: \"Washington D.C.\", Country: \"USA\",\n+\t\t\t\tCapital: false, Population: 680000,\n+\t\t\t\tRegions: []string{\"east_coast\"}},\n+\t\t},\n+\t\t{\n+\t\t\tid: \"TOK\",\n+\t\t\tc: City{Name: \"Tokyo\", Country: \"Japan\",\n+\t\t\t\tCapital: true, Population: 9000000,\n+\t\t\t\tRegions: []string{\"kanto\", \"honshu\"}},\n+\t\t},\n+\t\t{\n+\t\t\tid: \"BJ\",\n+\t\t\tc: City{Name: \"Beijing\", Country: \"China\",\n+\t\t\t\tCapital: true, Population: 21500000,\n+\t\t\t\tRegions: []string{\"jingjinji\", \"hebei\"}},\n+\t\t},\n \t}\n \tfor _, c := range cities {\n \t\tif _, err := client.Collection(\"cities\").Doc(c.id).Set(ctx, c.c); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "00594c486c4f729613d1b8fd5d18da637c0ba33d"
    },
    {
        "pr_title": "Added Spanner DML/PDML samples.",
        "pr_number": 643,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -55,6 +55,16 @@\nvar (\n \t\t\"querywitharrayofstruct\":     queryWithArrayOfStruct,\n \t\t\"querywithstructfield\":       queryWithStructField,\n \t\t\"querywithnestedstructfield\": queryWithNestedStructField,\n+\t\t\"dmlinsert\":                  insertUsingDML,\n+\t\t\"dmlupdate\":                  updateUsingDML,\n+\t\t\"dmldelete\":                  deleteUsingDML,\n+\t\t\"dmlwithtimestamp\":           updateUsingDMLWithTimestamp,\n+\t\t\"dmlwriteread\":               writeAndReadUsingDML,\n+\t\t\"dmlupdatestruct\":            updateUsingDMLStruct,\n+\t\t\"dmlwrite\":                   writeUsingDML,\n+\t\t\"dmlwritetxn\":                writeWithTransactionUsingDML,\n+\t\t\"dmlupdatepart\":              updateUsingPartitionedDML,\n+\t\t\"dmldeletepart\":              deleteUsingPartitionedDML,\n \t}\n \n \tadminCommands = map[string]adminCommand{",
        "comments": [],
        "commit_messages": [
            "Added Spanner DML/PDML samples."
        ],
        "last_commit_sha": "65d6d3f3db510d29cf7581f04dc6019e74969b97"
    },
    {
        "pr_title": "Added Spanner DML/PDML samples.",
        "pr_number": 643,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -241,11 +251,11 @@\nfunc queryWithStruct(ctx context.Context, w io.Writer, client *spanner.Client) e\n \n \t// [START spanner_create_struct_with_data]\n \n-\ttype nameStruct struct {\n+\ttype name struct {\n \t\tFirstName string\n \t\tLastName  string\n \t}\n-\tvar singerInfo = nameStruct{\"Elena\", \"Campbell\"}\n+\tvar singerInfo = name{\"Elena\", \"Campbell\"}\n \n \t// [END spanner_create_struct_with_data]",
        "comments": [],
        "commit_messages": [
            "Address feedback."
        ],
        "last_commit_sha": "65d6d3f3db510d29cf7581f04dc6019e74969b97"
    },
    {
        "pr_title": "Added Spanner DML/PDML samples.",
        "pr_number": 643,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -866,7 +876,7 @@\nfunc updateWithTimestamp(ctx context.Context, w io.Writer, client *spanner.Clien\n func queryWithTimestamp(ctx context.Context, w io.Writer, client *spanner.Client) error {\n \tstmt := spanner.Statement{\n \t\tSQL: `SELECT SingerId, AlbumId, MarketingBudget, LastUpdateTime\n-\t    FROM Albums ORDER BY LastUpdateTime DESC`}\n+\t\t\t\tFROM Albums ORDER BY LastUpdateTime DESC`}\n \titer := client.Single().Query(ctx, stmt)\n \tdefer iter.Stop()\n \tfor {",
        "comments": [],
        "commit_messages": [
            "Fix line length and SQL spacing."
        ],
        "last_commit_sha": "65d6d3f3db510d29cf7581f04dc6019e74969b97"
    },
    {
        "pr_title": "Added Spanner DML/PDML samples.",
        "pr_number": 643,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -906,10 +916,272 @@\nfunc queryWithTimestamp(ctx context.Context, w io.Writer, client *spanner.Client\n \n // [END spanner_query_data_with_timestamp_column]\n \n+// [START spanner_dml_standard_insert]\n+\n+func insertUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\tstmt := spanner.Statement{\n+\t\t\tSQL: `INSERT Singers (SingerId, FirstName, LastName)\n+\t\t\t\t\tVALUES (10, 'Virginia', 'Watson')`,\n+\t\t}\n+\t\trowCount, err := txn.Update(ctx, stmt)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d record(s) inserted.\\n\", rowCount)\n+\t\treturn nil\n+\t})\n+\treturn err\n+}\n+\n+// [END spanner_dml_standard_insert]\n+\n+// [START spanner_dml_standard_update]\n+\n+func updateUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\tstmt := spanner.Statement{\n+\t\t\tSQL: `UPDATE Albums\n+\t\t\t\tSET MarketingBudget = MarketingBudget * 2\n+\t\t\t\tWHERE SingerId = 1 and AlbumId = 1`,\n+\t\t}\n+\t\trowCount, err := txn.Update(ctx, stmt)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d record(s) updated.\\n\", rowCount)\n+\t\treturn nil\n+\t})\n+\treturn err\n+}\n+\n+// [END spanner_dml_standard_update]\n+\n+// [START spanner_dml_standard_delete]\n+\n+func deleteUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\tstmt := spanner.Statement{SQL: `DELETE Singers WHERE FirstName = 'Alice'`}\n+\t\trowCount, err := txn.Update(ctx, stmt)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d record(s) deleted.\\n\", rowCount)\n+\t\treturn nil\n+\t})\n+\treturn err\n+}\n+\n+// [END spanner_dml_standard_delete]\n+\n+// [START spanner_dml_standard_update_with_timestamp]\n+\n+func updateUsingDMLWithTimestamp(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\tstmt := spanner.Statement{\n+\t\t\tSQL: `UPDATE Albums\n+\t\t\t\tSET LastUpdateTime = PENDING_COMMIT_TIMESTAMP()\n+\t\t\t\tWHERE SingerId = 1`,\n+\t\t}\n+\t\trowCount, err := txn.Update(ctx, stmt)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d record(s) updated.\\n\", rowCount)\n+\t\treturn nil\n+\t})\n+\treturn err\n+}\n+\n+// [END spanner_dml_standard_update_with_timestamp]\n+\n+// [START spanner_dml_write_then_read]\n+\n+func writeAndReadUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\t// Insert Record\n+\t\tstmt := spanner.Statement{\n+\t\t\tSQL: `INSERT Singers (SingerId, FirstName, LastName)\n+\t\t\t\tVALUES (11, 'Timothy', 'Campbell')`,\n+\t\t}\n+\t\trowCount, err := txn.Update(ctx, stmt)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d record(s) inserted.\\n\", rowCount)\n+\n+\t\t// Read newly inserted record\n+\t\tstmt = spanner.Statement{SQL: `SELECT FirstName, LastName FROM Singers WHERE SingerId = 11`}\n+\t\titer := txn.Query(ctx, stmt)\n+\t\tdefer iter.Stop()\n+\n+\t\tfor {\n+\t\t\trow, err := iter.Next()\n+\t\t\tif err == iterator.Done || err != nil {\n+\t\t\t\tbreak\n+\t\t\t}\n+\t\t\tvar firstName, lastName string\n+\t\t\tif err := row.ColumnByName(\"FirstName\", &firstName); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tif err := row.ColumnByName(\"LastName\", &lastName); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tfmt.Fprintf(w, \"Found record name with %s, %s\", firstName, lastName)\n+\t\t}\n+\t\treturn err\n+\t})\n+\treturn err\n+}\n+\n+// [END spanner_dml_write_then_read]\n+\n+// [START spanner_dml_structs]\n+\n+func updateUsingDMLStruct(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\ttype name struct {\n+\t\t\tFirstName string\n+\t\t\tLastName  string\n+\t\t}\n+\t\tvar singerInfo = name{\"Timothy\", \"Campbell\"}\n+\n+\t\tstmt := spanner.Statement{\n+\t\t\tSQL: `Update Singers Set LastName = 'Grant' \n+\t\t\t\tWHERE STRUCT<FirstName String, LastName String>(Firstname, LastName) = @name`,\n+\t\t\tParams: map[string]interface{}{\"name\": singerInfo},\n+\t\t}\n+\t\trowCount, err := txn.Update(ctx, stmt)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d record(s) inserted.\\n\", rowCount)\n+\t\treturn nil\n+\t})\n+\treturn err\n+}\n+\n+// [END spanner_dml_structs]\n+\n+// [START spanner_dml_getting_started_insert]\n+\n+func writeUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\tstmt := spanner.Statement{\n+\t\t\tSQL: `INSERT Singers (SingerId, FirstName, LastName) VALUES\n+\t\t\t\t(12, 'Melissa', 'Garcia'),\n+\t\t\t\t(13, 'Russell', 'Morales'),\n+\t\t\t\t(14, 'Jacqueline', 'Long'),\n+\t\t\t\t(15, 'Dylan', 'Shaw')`,\n+\t\t}\n+\t\trowCount, err := txn.Update(ctx, stmt)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d record(s) inserted.\\n\", rowCount)\n+\t\treturn err\n+\t})\n+\treturn err\n+}\n+\n+// [END spanner_dml_getting_started_insert]\n+\n+// [START spanner_dml_getting_started_update]\n+\n+func writeWithTransactionUsingDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\t// getBudget returns the budget for a record with a given albumId and singerId.\n+\t\tgetBudget := func(albumID, singerID int64) (int64, error) {\n+\t\t\tkey := spanner.Key{albumID, singerID}\n+\t\t\trow, err := txn.ReadRow(ctx, \"Albums\", key, []string{\"MarketingBudget\"})\n+\t\t\tif err != nil {\n+\t\t\t\treturn 0, err\n+\t\t\t}\n+\t\t\tvar budget int64\n+\t\t\tif err := row.Column(0, &budget); err != nil {\n+\t\t\t\treturn 0, err\n+\t\t\t}\n+\t\t\treturn budget, nil\n+\t\t}\n+\t\t// updateBudget updates the budget for a record with a given albumId and singerId.\n+\t\tupdateBudget := func(singerID, albumID, albumBudget int64) error {\n+\t\t\tstmt := spanner.Statement{\n+\t\t\t\tSQL: `UPDATE Albums\n+\t\t\t\t\tSET MarketingBudget = @AlbumBudget\n+\t\t\t\t\tWHERE SingerId = @SingerId and AlbumId = @AlbumId`,\n+\t\t\t\tParams: map[string]interface{}{\n+\t\t\t\t\t\"SingerId\":    singerID,\n+\t\t\t\t\t\"AlbumId\":     albumID,\n+\t\t\t\t\t\"AlbumBudget\": albumBudget,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t\t_, err := txn.Update(ctx, stmt)\n+\t\t\treturn err\n+\t\t}\n+\n+\t\t// Transfer the marketing budget from one album to another. By keeping the actions\n+\t\t// in a single transaction, it ensures the movement is atomic.\n+\t\tconst transferAmt = 200000\n+\t\tvar album1budget, album2budget int64\n+\t\tvar err error\n+\t\tif album1budget, err = getBudget(1, 1); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\t// The transaction will only be committed if this condition still holds at the time\n+\t\t// of commit. Otherwise it will be aborted and the callable will be rerun by the\n+\t\t// client library.\n+\t\tif album1budget >= transferAmt {\n+\t\t\tif album2budget, err = getBudget(2, 2); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tif err = updateBudget(1, 1, album1budget-transferAmt); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tif err = updateBudget(2, 2, album2budget+transferAmt); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tfmt.Fprintf(w, \"Moved %d from Album1's MarketingBudget to Album2's.\", transferAmt)\n+\t\t}\n+\t\treturn nil\n+\t})\n+\treturn err\n+}\n+\n+// [END spanner_dml_getting_started_update]\n+\n+// [START spanner_dml_partitioned_update]\n+\n+func updateUsingPartitionedDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tstmt := spanner.Statement{SQL: \"UPDATE Albums SET MarketingBudget = 100000 WHERE SingerId > 1\"}\n+\trowCount, err := client.PartitionedUpdate(ctx, stmt)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"%d record(s) updated.\\n\", rowCount)\n+\treturn nil\n+}\n+\n+// [END spanner_dml_partitioned_update]\n+\n+// [START spanner_dml_partitioned_delete]\n+\n+func deleteUsingPartitionedDML(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tstmt := spanner.Statement{SQL: \"DELETE Singers WHERE SingerId > 10\"}\n+\trowCount, err := client.PartitionedUpdate(ctx, stmt)\n+\tif err != nil {\n+\t\treturn err\n+\n+\t}\n+\tfmt.Fprintf(w, \"%d record(s) deleted.\", rowCount)\n+\treturn nil\n+}\n+\n+// [END spanner_dml_partitioned_delete]\n+\n func queryNewTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n \tstmt := spanner.Statement{\n \t\tSQL: `SELECT SingerId, VenueId, EventDate, Revenue, LastUpdateTime FROM Performances\n-\t\t  ORDER BY LastUpdateTime DESC`}\n+\t\t\tORDER BY LastUpdateTime DESC`}\n \titer := client.Single().Query(ctx, stmt)\n \tdefer iter.Stop()\n \tfor {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "65d6d3f3db510d29cf7581f04dc6019e74969b97"
    },
    {
        "pr_title": "Added Spanner DML/PDML samples.",
        "pr_number": 643,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -35,16 +35,25 @@\nfunc TestSample(t *testing.T) {\n \n \tassertContains := func(out string, sub string) {\n \t\tif !strings.Contains(out, sub) {\n-\t\t\tt.Errorf(\"got output %q; want it to contain %s\", out, sub)\n+\t\t\tt.Errorf(\"got output %q; want it to contain %q\", out, sub)\n \t\t}\n \t}\n \trunCommand := func(t *testing.T, cmd string, dbName string) string {\n+\t\tt.Helper()\n \t\tvar b bytes.Buffer\n \t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName); err != nil {\n \t\t\tt.Errorf(\"run(%q, %q): %v\", cmd, dbName, err)\n \t\t}\n \t\treturn b.String()\n \t}\n+\tmustRunCommand := func(t *testing.T, cmd string, dbName string) string {\n+\t\tt.Helper()\n+\t\tvar b bytes.Buffer\n+\t\tif err := run(context.Background(), adminClient, dataClient, &b, cmd, dbName); err != nil {\n+\t\t\tt.Fatalf(\"run(%q, %q): %v\", cmd, dbName, err)\n+\t\t}\n+\t\treturn b.String()\n+\t}\n \n \tdefer func() {\n \t\ttestutil.Retry(t, 10, time.Second, func(r *testutil.R) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "65d6d3f3db510d29cf7581f04dc6019e74969b97"
    },
    {
        "pr_title": "Added Spanner DML/PDML samples.",
        "pr_number": 643,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -57,7 +66,7 @@\nfunc TestSample(t *testing.T) {\n \n \t// We execute all the commands of the tutorial code. These commands have to be run in a specific\n \t// order since in many cases earlier commands setup the database for the subsequent commands.\n-\trunCommand(t, \"createdatabase\", dbName)\n+\tmustRunCommand(t, \"createdatabase\", dbName)\n \trunCommand(t, \"write\", dbName)\n \twriteTime := time.Now()",
        "comments": [],
        "commit_messages": [
            "Added Spanner DML/PDML samples."
        ],
        "last_commit_sha": "65d6d3f3db510d29cf7581f04dc6019e74969b97"
    },
    {
        "pr_title": "Added Spanner DML/PDML samples.",
        "pr_number": 643,
        "file_name": "spanner/spanner_snippets/snippet_test.go",
        "code_diff": "@@ -94,7 +103,7 @@\nfunc TestSample(t *testing.T) {\n \t}\n \n \t// Wait at least 15 seconds since the write.\n-\ttime.Sleep(time.Now().Add(16 * time.Second).Sub(writeTime))\n+\ttime.Sleep(time.Until(writeTime.Add(16 * time.Second)))\n \tout = runCommand(t, \"readstaledata\", dbName)\n \tassertContains(out, \"Go, Go, Go\")\n \tassertContains(out, \"Forever Hold Your Peace\")",
        "comments": [],
        "commit_messages": [
            "Added Spanner DML/PDML samples."
        ],
        "last_commit_sha": "65d6d3f3db510d29cf7581f04dc6019e74969b97"
    },
    {
        "pr_title": "vision/detect: add localize objects samples",
        "pr_number": 635,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -562,6 +562,52 @@\nfunc detectAsyncDocument(w io.Writer, gcsSourceURI, gcsDestinationURI string) er\n \n // [END vision_text_detection_pdf]\n \n+// [START vision_localize_objects]\n+\n+// localizeObjects gets objects and bounding boxes from the Vision API for an image at the given file path.\n+func localizeObjects(w io.Writer, file string) error {\n+\tctx := context.Background()\n+\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tf, err := os.Open(file)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer f.Close()\n+\n+\timage, err := vision.NewImageFromReader(f)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tannotations, err := client.LocalizeObjects(ctx, image, nil)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif len(annotations) == 0 {\n+\t\tfmt.Fprintln(w, \"No objects found.\")\n+\t\treturn nil\n+\t}\n+\n+\tfmt.Fprintln(w, \"Objects:\")\n+\tfor _, annotation := range annotations {\n+\t\tfmt.Fprintln(w, annotation.Name)\n+\t\tfmt.Fprintln(w, annotation.Score)\n+\n+\t\tfor _, v := range annotation.BoundingPoly.NormalizedVertices {\n+\t\t\tfmt.Fprintf(w, \"(%f,%f)\\n\", v.X, v.Y)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+// [END vision_localize_objects]\n+\n func init() {\n \t// Refer to these functions so that goimports is happy before boilerplate is inserted.\n \t_ = context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "f1679c8ab191fbda1eb363674d537f07417549a6"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -5,6 +5,8 @@\n// Samples for asymmetric keys feature of Cloud Key Management Service: https://cloud.google.com/kms/\n package samples\n \n+// [START kms_get_asymmetric_public]\n+\n import (\n \t\"context\"\n \t\"crypto\"",
        "comments": [],
        "commit_messages": [
            "added region tag for imports"
        ],
        "last_commit_sha": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -23,6 +25,8 @@\nimport (\n \t\"google.golang.org/api/cloudkms/v1\"\n )\n \n+// [END kms_get_asymmetric_public]\n+\n // [START kms_get_asymmetric_public]\n \n // getAsymmetricPublicKey retrieves the public key from a saved asymmetric key pair on KMS.",
        "comments": [],
        "commit_messages": [
            "added region tag for imports"
        ],
        "last_commit_sha": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -46,54 +50,54 @@\nfunc getAsymmetricPublicKey(ctx context.Context, client *cloudkms.Service, keyPa\n // [START kms_decrypt_rsa]\n \n // decryptRSA will attempt to decrypt a given ciphertext with an 'RSA_DECRYPT_OAEP_2048_SHA256' private key.stored on Cloud KMS\n-func decryptRSA(ctx context.Context, client *cloudkms.Service, ciphertext, keyPath string) (string, error) {\n+func decryptRSA(ctx context.Context, client *cloudkms.Service, keyPath string, ciphertext []byte) ([]byte, error) {\n \tdecryptRequest := &cloudkms.AsymmetricDecryptRequest{\n-\t\tCiphertext: ciphertext,\n+\t\tCiphertext: base64.StdEncoding.EncodeToString(ciphertext),\n \t}\n \tresponse, err := client.Projects.Locations.KeyRings.CryptoKeys.CryptoKeyVersions.\n \t\tAsymmetricDecrypt(keyPath, decryptRequest).Context(ctx).Do()\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"decryption request failed: %+v\", err)\n+\t\treturn nil, fmt.Errorf(\"decryption request failed: %+v\", err)\n \t}\n-\tmessage, err := base64.StdEncoding.DecodeString(response.Plaintext)\n+\tplaintext, err := base64.StdEncoding.DecodeString(response.Plaintext)\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"failed to decode decryted string: %+v\", err)\n+\t\treturn nil, fmt.Errorf(\"failed to decode decryted string: %+v\", err)\n \n \t}\n-\treturn string(message), nil\n+\treturn plaintext, nil\n }\n \n // [END kms_decrypt_rsa]\n \n // [START kms_encrypt_rsa]\n \n-// encryptRSA will encrypt a message locally using an 'RSA_DECRYPT_OAEP_2048_SHA256' public key retrieved from Cloud KMS\n-func encryptRSA(ctx context.Context, client *cloudkms.Service, message, keyPath string) (string, error) {\n+// encryptRSA will encrypt data locally using an 'RSA_DECRYPT_OAEP_2048_SHA256' public key retrieved from Cloud KMS\n+func encryptRSA(ctx context.Context, client *cloudkms.Service, keyPath string, plaintext []byte) ([]byte, error) {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {\n-\t\treturn \"\", err\n+\t\treturn nil, err\n \t}\n \n \t// Perform type assertion to get the RSA key.\n \trsaKey := abstractKey.(*rsa.PublicKey)\n \n-\tciphertextBytes, err := rsa.EncryptOAEP(sha256.New(), rand.Reader, rsaKey, []byte(message), nil)\n+\tciphertext, err := rsa.EncryptOAEP(sha256.New(), rand.Reader, rsaKey, plaintext, nil)\n \tif err != nil {\n-\t\treturn \"\", fmt.Errorf(\"encryption failed: %+v\", err)\n+\t\treturn nil, fmt.Errorf(\"encryption failed: %+v\", err)\n \t}\n-\treturn base64.StdEncoding.EncodeToString(ciphertextBytes), nil\n+\treturn ciphertext, nil\n }\n \n // [END kms_encrypt_rsa]\n \n // [START kms_sign_asymmetric]\n \n // signAsymmetric will sign a plaintext message using a saved asymmetric private key.\n-func signAsymmetric(ctx context.Context, client *cloudkms.Service, message, keyPath string) (string, error) {\n+func signAsymmetric(ctx context.Context, client *cloudkms.Service, keyPath string, message []byte) (string, error) {\n \t// Note: some key algorithms will require a different hash function.\n \t// For example, EC_SIGN_P384_SHA384 requires SHA-384.\n \tdigest := sha256.New()\n-\tdigest.Write([]byte(message))\n+\tdigest.Write(message)\n \tdigestStr := base64.StdEncoding.EncodeToString(digest.Sum(nil))\n \n \tasymmetricSignRequest := &cloudkms.AsymmetricSignRequest{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -116,8 +120,8 @@\nfunc signAsymmetric(ctx context.Context, client *cloudkms.Service, message, keyP\n \n // [START kms_verify_signature_rsa]\n \n-// verifySignatureRSA will verify that an 'RSA_SIGN_PSS_2048_SHA256' signature is valid for a given plaintext message.\n-func verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature, message, keyPath string) error {\n+// verifySignatureRSA will verify that an 'RSA_SIGN_PSS_2048_SHA256' signature is valid for a given message.\n+func verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature, keyPath string, message []byte) error {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -130,7 +134,7 @@\nfunc verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature\n \n \t}\n \tdigest := sha256.New()\n-\tdigest.Write([]byte(message))\n+\tdigest.Write(message)\n \thash := digest.Sum(nil)\n \n \tpssOptions := rsa.PSSOptions{SaltLength: len(hash), Hash: crypto.SHA256}",
        "comments": [],
        "commit_messages": [
            "signature functions use byte array"
        ],
        "last_commit_sha": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -145,8 +149,8 @@\nfunc verifySignatureRSA(ctx context.Context, client *cloudkms.Service, signature\n \n // [START kms_verify_signature_ec]\n \n-// verifySignatureEC will verify that an 'EC_SIGN_P256_SHA256' signature is valid for a given plaintext message.\n-func verifySignatureEC(ctx context.Context, client *cloudkms.Service, signature, message, keyPath string) error {\n+// verifySignatureEC will verify that an 'EC_SIGN_P256_SHA256' signature is valid for a given message.\n+func verifySignatureEC(ctx context.Context, client *cloudkms.Service, signature, keyPath string, message []byte) error {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -6,9 +6,11 @@\npackage samples\n \n import (\n+\t\"bytes\"\n \t\"context\"\n \t\"crypto/ecdsa\"\n \t\"crypto/rsa\"\n+\t\"encoding/base64\"\n \t\"os\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "encrypt/decrypt uses bytes instead of string"
        ],
        "last_commit_sha": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -136,7 +138,8 @@\nfunc TestRSAEncryptDecrypt(t *testing.T) {\n \t\tt.Fatalf(\"intial variable setup failed: %v\", err)\n \t}\n \n-\tciphertext, err := encryptRSA(v.ctx, v.client, v.message, v.rsaDecryptPath)\n+\tcipherBytes, err := encryptRSA(v.ctx, v.client, v.rsaDecryptPath, []byte(v.message))\n+\tciphertext := base64.StdEncoding.EncodeToString(cipherBytes)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_messages": [
            "encrypt/decrypt uses bytes instead of string"
        ],
        "last_commit_sha": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -146,12 +149,16 @@\nfunc TestRSAEncryptDecrypt(t *testing.T) {\n \tif ciphertext[len(ciphertext)-2:] != \"==\" {\n \t\tt.Errorf(\"ciphertet ending: %s; want: %s\", ciphertext[len(ciphertext)-2:], \"==\")\n \t}\n-\tplaintext, err := decryptRSA(v.ctx, v.client, ciphertext, v.rsaDecryptPath)\n+\tplainBytes, err := decryptRSA(v.ctx, v.client, v.rsaDecryptPath, cipherBytes)\n \tif err != nil {\n \t\tt.Fatalf(\"decryptRSA(%s, %s): %v\", ciphertext, v.rsaDecryptPath, err)\n \t}\n-\tif v.message != plaintext {\n-\t\tt.Errorf(\"failed to decypt expected plaintext: want %s, got %s\", plaintext, v.message)\n+\tif !bytes.Equal(plainBytes, []byte(v.message)) {\n+\t\tt.Fatalf(\"decrypted plaintext does not match input message: want %s, got %s\", []byte(v.message), plainBytes)\n+\t}\n+\tplaintext := string(plainBytes)\n+\tif plaintext != v.message {\n+\t\tt.Fatalf(\"failed to decypt expected plaintext: want %s, got %s\", v.message, plaintext)\n \t}\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -162,7 +169,7 @@\nfunc TestRSASignVerify(t *testing.T) {\n \t\tt.Fatalf(\"intial variable setup failed: %v\", err)\n \t}\n \n-\tsig, err := signAsymmetric(v.ctx, v.client, v.message, v.rsaSignPath)\n+\tsig, err := signAsymmetric(v.ctx, v.client, v.rsaSignPath, []byte(v.message))\n \tif err != nil {\n \t\tt.Fatalf(\"signAsymmetric(%s, %s): %v\", v.message, v.rsaSignPath, err)\n \t}",
        "comments": [],
        "commit_messages": [
            "signature functions use byte array"
        ],
        "last_commit_sha": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "KMS changes",
        "pr_number": 632,
        "file_name": "kms/asymmetric/samples_test.go",
        "code_diff": "@@ -172,10 +179,11 @@\nfunc TestRSASignVerify(t *testing.T) {\n \tif sig[len(sig)-2:] != \"==\" {\n \t\tt.Errorf(\"sig ending: %s; want: %s\", sig[len(sig)-2:], \"==\")\n \t}\n-\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.message, v.rsaSignPath); err != nil {\n+\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.rsaSignPath, []byte(v.message)); err != nil {\n \t\tt.Fatalf(\"verifySignatureRSA(%s, %s, %s): %v\", sig, v.message, v.rsaSignPath, err)\n \t}\n-\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.message+\".\", v.rsaSignPath); err == nil {\n+\tchanged := v.message + \".\"\n+\tif err = verifySignatureRSA(v.ctx, v.client, sig, v.rsaSignPath, []byte(changed)); err == nil {\n \t\tt.Errorf(\"verification for modified message should fail\")\n \t}\n }",
        "comments": [],
        "commit_messages": [
            "signature functions use byte array"
        ],
        "last_commit_sha": "91db3c12caa5ba424a08e6405702986fb2586267"
    },
    {
        "pr_title": "[Storage] Bucket Lock",
        "pr_number": 631,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -9,6 +9,7 @@\npackage main\n \n import (\n \t\"context\"\n+\t\"errors\"\n \t\"fmt\"\n \t\"log\"\n \t\"os\"",
        "comments": [],
        "commit_messages": [
            "Add Bucket lock samples with tests"
        ],
        "last_commit_sha": "46bd6905c082937de610f7dac0cca55be7190581"
    },
    {
        "pr_title": "[Storage] Bucket Lock",
        "pr_number": 631,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -197,14 +198,146 @@\nfunc removeUser(c *storage.Client, bucketName string) error {\n \treturn nil\n }\n \n+func setRetentionPolicy(c *storage.Client, bucketName string, retentionPeriod time.Duration) error {\n+\tctx := context.Background()\n+\n+\t// [START storage_set_retention_policy]\n+\tbucket := c.Bucket(bucketName)\n+\tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n+\t\tRetentionPolicy: &storage.RetentionPolicy{\n+\t\t\tRetentionPeriod: retentionPeriod,\n+\t\t},\n+\t}\n+\tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END storage_set_retention_policy]\n+\treturn nil\n+}\n+\n+func removeRetentionPolicy(c *storage.Client, bucketName string) error {\n+\tctx := context.Background()\n+\n+\t// [START storage_remove_retention_policy]\n+\tbucket := c.Bucket(bucketName)\n+\n+\tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif attrs.RetentionPolicy.IsLocked {\n+\t\treturn errors.New(\"retention policy is locked\")\n+\t}\n+\n+\tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n+\t\tRetentionPolicy: &storage.RetentionPolicy{},\n+\t}\n+\tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END storage_remove_retention_policy]\n+\treturn nil\n+}\n+\n+func lockRetentionPolicy(c *storage.Client, bucketName string) error {\n+\tctx := context.Background()\n+\n+\t// [START storage_lock_retention_policy]\n+\tbucket := c.Bucket(bucketName)\n+\tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tconditions := storage.BucketConditions{\n+\t\tMetagenerationMatch: attrs.MetaGeneration,\n+\t}\n+\tif err := bucket.If(conditions).LockRetentionPolicy(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\n+\tlockedAttrs, err := c.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tlog.Printf(\"Retention policy for %v is now locked\\n\", bucketName)\n+\tlog.Printf(\"Retention policy effective as of %v\\n\",\n+\t\tlockedAttrs.RetentionPolicy.EffectiveTime)\n+\t// [END storage_lock_retention_policy]\n+\treturn nil\n+}\n+\n+func getRetentionPolicy(c *storage.Client, bucketName string) (*storage.BucketAttrs, error) {\n+\tctx := context.Background()\n+\n+\t// [START storage_get_retention_policy]\n+\tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tif attrs.RetentionPolicy != nil {\n+\t\tlog.Print(\"Retention Policy\\n\")\n+\t\tlog.Printf(\"period: %v\\n\", attrs.RetentionPolicy.RetentionPeriod)\n+\t\tlog.Printf(\"effective time: %v\\n\", attrs.RetentionPolicy.EffectiveTime)\n+\t\tlog.Printf(\"policy locked: %v\\n\", attrs.RetentionPolicy.IsLocked)\n+\t}\n+\t// [END storage_get_retention_policy]\n+\treturn attrs, nil\n+}\n+\n+func enableDefaultEventBasedHold(c *storage.Client, bucketName string) error {\n+\tctx := context.Background()\n+\n+\t// [START storage_enable_default_event_based_hold]\n+\tbucket := c.Bucket(bucketName)\n+\tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n+\t\tDefaultEventBasedHold: true,\n+\t}\n+\tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END storage_enable_default_event_based_hold]\n+\treturn nil\n+}\n+\n+func disableDefaultEventBasedHold(c *storage.Client, bucketName string) error {\n+\tctx := context.Background()\n+\n+\t// [START storage_disable_default_event_based_hold]\n+\tbucket := c.Bucket(bucketName)\n+\tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n+\t\tDefaultEventBasedHold: false,\n+\t}\n+\tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END storage_disable_default_event_based_hold]\n+\treturn nil\n+}\n+\n+func getDefaultEventBasedHold(c *storage.Client, bucketName string) (*storage.BucketAttrs, error) {\n+\tctx := context.Background()\n+\n+\t// [START storage_get_default_event_based_hold]\n+\tattrs, err := c.Bucket(bucketName).Attrs(ctx)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tlog.Printf(\"Default event-based hold enabled? %t\\n\",\n+\t\tattrs.DefaultEventBasedHold)\n+\t// [END storage_get_default_event_based_hold]\n+\treturn attrs, nil\n+}\n+\n func enableRequesterPays(c *storage.Client, bucketName string) error {\n \tctx := context.Background()\n \n \t// [START enable_requester_pays]\n \tbucket := c.Bucket(bucketName)\n-\tif _, err := bucket.Update(ctx, storage.BucketAttrsToUpdate{\n+\tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tRequesterPays: true,\n-\t}); err != nil {\n+\t}\n+\tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}\n \t// [END enable_requester_pays]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "46bd6905c082937de610f7dac0cca55be7190581"
    },
    {
        "pr_title": "[Storage] Bucket Lock",
        "pr_number": 631,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -216,9 +349,10 @@\nfunc disableRequesterPays(c *storage.Client, bucketName string) error {\n \n \t// [START disable_requester_pays]\n \tbucket := c.Bucket(bucketName)\n-\tif _, err := bucket.Update(ctx, storage.BucketAttrsToUpdate{\n+\tbucketAttrsToUpdate := storage.BucketAttrsToUpdate{\n \t\tRequesterPays: false,\n-\t}); err != nil {\n+\t}\n+\tif _, err := bucket.Update(ctx, bucketAttrsToUpdate); err != nil {\n \t\treturn err\n \t}\n \t// [END disable_requester_pays]",
        "comments": [],
        "commit_messages": [
            "Addressing some feedback"
        ],
        "last_commit_sha": "46bd6905c082937de610f7dac0cca55be7190581"
    },
    {
        "pr_title": "[Storage] Bucket Lock",
        "pr_number": 631,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -233,7 +367,7 @@\nfunc checkRequesterPays(c *storage.Client, bucketName string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tfmt.Printf(\"Is requester pays enabled? %v\\n\", attrs.RequesterPays)\n+\tlog.Printf(\"Is requester pays enabled? %v\\n\", attrs.RequesterPays)\n \t// [END get_requester_pays_status]\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [
            "Address some testing feedback"
        ],
        "last_commit_sha": "46bd6905c082937de610f7dac0cca55be7190581"
    },
    {
        "pr_title": "[Storage] Bucket Lock",
        "pr_number": 631,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -7,6 +7,8 @@\npackage main\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n+\t\"log\"\n \t\"os\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [
            "Address some testing feedback"
        ],
        "last_commit_sha": "46bd6905c082937de610f7dac0cca55be7190581"
    },
    {
        "pr_title": "[Storage] Bucket Lock",
        "pr_number": 631,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -21,6 +23,14 @@\nvar (\n \tbucketName    string\n )\n \n+func TestMain(m *testing.M) {\n+\t// These functions are noisy.\n+\tlog.SetOutput(ioutil.Discard)\n+\ts := m.Run()\n+\tlog.SetOutput(os.Stderr)\n+\tos.Exit(s)\n+}\n+\n func setup(t *testing.T) {\n \ttc := testutil.SystemTest(t)",
        "comments": [],
        "commit_messages": [
            "Address some testing feedback"
        ],
        "last_commit_sha": "46bd6905c082937de610f7dac0cca55be7190581"
    },
    {
        "pr_title": "[Storage] Bucket Lock",
        "pr_number": 631,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -8,6 +8,7 @@\nimport (\n \t\"bytes\"\n \t\"context\"\n \t\"fmt\"\n+\t\"io/ioutil\"\n \t\"log\"\n \t\"os\"\n \t\"strings\"",
        "comments": [],
        "commit_messages": [
            "Address some testing feedback"
        ],
        "last_commit_sha": "46bd6905c082937de610f7dac0cca55be7190581"
    },
    {
        "pr_title": "[Storage] Bucket Lock",
        "pr_number": 631,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -21,6 +22,13 @@\nimport (\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n+func TestMain(m *testing.M) {\n+\t// These functions are noisy.\n+\tlog.SetOutput(ioutil.Discard)\n+\ts := m.Run()\n+\tlog.SetOutput(os.Stderr)\n+\tos.Exit(s)\n+}\n func TestObjects(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "Address some testing feedback"
        ],
        "last_commit_sha": "46bd6905c082937de610f7dac0cca55be7190581"
    },
    {
        "pr_title": "[Storage] Bucket Lock",
        "pr_number": 631,
        "file_name": "storage/objects/main_test.go",
        "code_diff": "@@ -206,6 +214,82 @@\nfunc TestKMSObjects(t *testing.T) {\n \t}\n }\n \n+func TestObjectBucketLock(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tctx := context.Background()\n+\tclient, err := storage.NewClient(ctx)\n+\tif err != nil {\n+\t\tlog.Fatal(err)\n+\t}\n+\n+\tvar (\n+\t\tbucketName = tc.ProjectID + \"-retent-samples-object-bucket\"\n+\n+\t\tobjectName = \"foo.txt\"\n+\n+\t\tretentionPeriod = 5 * time.Second\n+\t)\n+\n+\tcleanBucket(t, ctx, client, tc.ProjectID, bucketName)\n+\tbucket := client.Bucket(bucketName)\n+\n+\tif err := write(client, bucketName, objectName); err != nil {\n+\t\tt.Fatalf(\"write(%q): %v\", objectName, err)\n+\t}\n+\tif _, err := bucket.Update(ctx, storage.BucketAttrsToUpdate{\n+\t\tRetentionPolicy: &storage.RetentionPolicy{\n+\t\t\tRetentionPeriod: retentionPeriod,\n+\t\t},\n+\t}); err != nil {\n+\t\tt.Errorf(\"unable to set retention policy (%q): %v\", bucketName, err)\n+\t}\n+\tif err := setEventBasedHold(client, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"unable to set event-based hold (%q/%q): %v\", bucketName, objectName, err)\n+\t}\n+\toAttrs, err := attrs(client, bucketName, objectName)\n+\tif err != nil {\n+\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t}\n+\tif !oAttrs.EventBasedHold {\n+\t\tt.Errorf(\"event-based hold is not enabled\")\n+\t}\n+\tif err := releaseEventBasedHold(client, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"unable to set event-based hold (%q/%q): %v\", bucketName, objectName, err)\n+\t}\n+\toAttrs, err = attrs(client, bucketName, objectName)\n+\tif err != nil {\n+\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t}\n+\tif oAttrs.EventBasedHold {\n+\t\tt.Errorf(\"event-based hold is not disabled\")\n+\t}\n+\tif _, err := bucket.Update(ctx, storage.BucketAttrsToUpdate{\n+\t\tRetentionPolicy: &storage.RetentionPolicy{},\n+\t}); err != nil {\n+\t\tt.Errorf(\"unable to remove retention policy (%q): %v\", bucketName, err)\n+\t}\n+\tif err := setTemporaryHold(client, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"unable to set temporary hold (%q/%q): %v\", bucketName, objectName, err)\n+\t}\n+\toAttrs, err = attrs(client, bucketName, objectName)\n+\tif err != nil {\n+\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t}\n+\tif !oAttrs.TemporaryHold {\n+\t\tt.Errorf(\"temporary hold is not disabled\")\n+\t}\n+\tif err := releaseTemporaryHold(client, bucketName, objectName); err != nil {\n+\t\tt.Errorf(\"unable to release temporary hold (%q/%q): %v\", bucketName, objectName, err)\n+\t}\n+\toAttrs, err = attrs(client, bucketName, objectName)\n+\tif err != nil {\n+\t\tt.Errorf(\"cannot get object metadata: %v\", err)\n+\t}\n+\tif oAttrs.TemporaryHold {\n+\t\tt.Errorf(\"temporary hold is not disabled\")\n+\t}\n+}\n+\n // cleanBucket ensures there's a fresh bucket with a given name, deleting the existing bucket if it already exists.\n func cleanBucket(t *testing.T, ctx context.Context, client *storage.Client, projectID, bucket string) {\n \tb := client.Bucket(bucket)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "46bd6905c082937de610f7dac0cca55be7190581"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -33,6 +33,7 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_create_table_clustered]\n \t// [START bigquery_create_table_cmek]\n \t// [START bigquery_create_table_partitioned]\n+\t// [START bigquery_create_view]\n \t// [START bigquery_delete_dataset]\n \t// [START bigquery_delete_label_dataset]\n \t// [START bigquery_delete_label_table]",
        "comments": [],
        "commit_messages": [
            "BigQuery: more snippets (csv, json, view)"
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -45,6 +46,8 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_get_job]\n \t// [START bigquery_get_table]\n \t// [START bigquery_get_table_labels]\n+\t// [START bigquery_get_view]\n+\t// [START bigquery_grant_view_access]\n \t// [START bigquery_label_dataset]\n \t// [START bigquery_label_table]\n \t// [START bigquery_list_datasets]",
        "comments": [],
        "commit_messages": [
            "BigQuery: more snippets (csv, json, view)"
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -54,9 +57,11 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_load_from_file]\n \t// [START bigquery_load_table_clustered]\n \t// [START bigquery_load_table_gcs_csv]\n+\t// [START bigquery_load_table_gcs_csv_truncate]\n \t// [START bigquery_load_table_gcs_json]\n \t// [START bigquery_load_table_gcs_json_autodetect]\n \t// [START bigquery_load_table_gcs_json_cmek]\n+\t// [START bigquery_load_table_gcs_json_truncate]\n \t// [START bigquery_load_table_gcs_orc]\n \t// [START bigquery_load_table_gcs_orc_truncate]\n \t// [START bigquery_load_table_gcs_parquet]",
        "comments": [],
        "commit_messages": [
            "BigQuery: more snippets (csv, json, view)"
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -88,6 +93,7 @@\nfunc noOpCommentFunc() {\n \t// [START bigquery_update_table_cmek]\n \t// [START bigquery_update_table_description]\n \t// [START bigquery_update_table_expiration]\n+\t// [START bigquery_update_view_query]\n \t// To run this sample, you will need to create (or reuse) a context and\n \t// an instance of the bigquery client.  For example:\n \t// import \"cloud.google.com/go/bigquery\"",
        "comments": [],
        "commit_messages": [
            "BigQuery: more snippets (csv, json, view)"
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -106,6 +112,7 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_create_table_clustered]\n \t// [END bigquery_create_table_cmek]\n \t// [END bigquery_create_table_partitioned]\n+\t// [END bigquery_create_view]\n \t// [END bigquery_delete_dataset]\n \t// [END bigquery_delete_label_dataset]\n \t// [END bigquery_delete_label_table]",
        "comments": [],
        "commit_messages": [
            "BigQuery: more snippets (csv, json, view)"
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -118,6 +125,8 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_get_job]\n \t// [END bigquery_get_table]\n \t// [END bigquery_get_table_labels]\n+\t// [END bigquery_get_view]\n+\t// [END bigquery_grant_view_access]\n \t// [END bigquery_label_dataset]\n \t// [END bigquery_label_table]\n \t// [END bigquery_list_datasets]",
        "comments": [],
        "commit_messages": [
            "BigQuery: more snippets (csv, json, view)"
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -127,9 +136,11 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_load_from_file]\n \t// [END bigquery_load_table_clustered]\n \t// [END bigquery_load_table_gcs_csv]\n+\t// [END bigquery_load_table_gcs_csv_truncate]\n \t// [END bigquery_load_table_gcs_json]\n \t// [END bigquery_load_table_gcs_json_autodetect]\n \t// [END bigquery_load_table_gcs_json_cmek]\n+\t// [END bigquery_load_table_gcs_json_truncate]\n \t// [END bigquery_load_table_gcs_orc]\n \t// [END bigquery_load_table_gcs_orc_truncate]\n \t// [END bigquery_load_table_gcs_parquet]",
        "comments": [],
        "commit_messages": [
            "BigQuery: more snippets (csv, json, view)"
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -161,6 +172,7 @@\nfunc noOpCommentFunc() {\n \t// [END bigquery_update_dataset_expiration]\n \t// [END bigquery_update_table_description]\n \t// [END bigquery_update_table_expiration]\n+\t// [END bigquery_update_view_query]\n }\n \n func cancelJob(client *bigquery.Client, jobID string) error {",
        "comments": [],
        "commit_messages": [
            "BigQuery: more snippets (csv, json, view)"
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -187,6 +199,22 @@\nfunc createDataset(client *bigquery.Client, datasetID string) error {\n \treturn nil\n }\n \n+func createView(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_create_view]\n+\tmeta := &bigquery.TableMetadata{\n+\t\t// This example shows how to create a view of the shakespeare sample dataset, which\n+\t\t// provides word frequency information.  This view restricts the results to only contain\n+\t\t// results for works that contain the \"king\" in the title, e.g. King Lear, King Henry V, etc.\n+\t\tViewQuery: \"SELECT word, word_count, corpus, corpus_date FROM `bigquery-public-data.samples.shakespeare` WHERE corpus LIKE '%king%'\",\n+\t}\n+\tif err := client.Dataset(datasetID).Table(tableID).Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_create_view]\n+\treturn nil\n+}\n+\n func updateDatasetDescription(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_description]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -817,6 +845,84 @@\nfunc updateTableExpiration(client *bigquery.Client, datasetID, tableID string) e\n \n }\n \n+func getView(client *bigquery.Client, datasetID, viewID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_view]\n+\tview := client.Dataset(datasetID).Table(viewID)\n+\tmeta, err := view.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Printf(\"View %s, query: %s\\n\", view.FullyQualifiedName(), meta.ViewQuery)\n+\t// [END bigquery_get_view]\n+\treturn nil\n+}\n+\n+func updateView(client *bigquery.Client, datasetID, viewID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_view_query]\n+\tview := client.Dataset(datasetID).Table(viewID)\n+\tmeta, err := view.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tnewMeta := bigquery.TableMetadataToUpdate{\n+\t\t// This example updates a view into the shakespeare dataset to exclude works named after kings.\n+\t\tViewQuery: \"SELECT word, word_count, corpus, corpus_date FROM `bigquery-public-data.samples.shakespeare` WHERE corpus NOT LIKE '%king%'\",\n+\t}\n+\n+\tif _, err := view.Update(ctx, newMeta, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_view_query]\n+\treturn nil\n+}\n+\n+func updateViewDelegated(client *bigquery.Client, srcDatasetID, viewDatasetID, viewID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_grant_view_access]\n+\tsrcDataset := client.Dataset(srcDatasetID)\n+\tviewDataset := client.Dataset(viewDatasetID)\n+\tview := viewDataset.Table(viewID)\n+\n+\t// First, we'll add a group to the ACL for the dataset containing the view.  This will allow users within\n+\t// that group to query the view, but they must have direct access to any tables referenced by the view.\n+\tvMeta, err := viewDataset.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tvUpdateMeta := bigquery.DatasetMetadataToUpdate{\n+\t\tAccess: append(vMeta.Access, &bigquery.AccessEntry{\n+\t\t\tRole:       bigquery.ReaderRole,\n+\t\t\tEntityType: bigquery.GroupEmailEntity,\n+\t\t\tEntity:     \"example-analyst-group@google.com\",\n+\t\t}),\n+\t}\n+\tif _, err := viewDataset.Update(ctx, vUpdateMeta, vMeta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Now, we'll authorize a specific view against a source dataset, delegating access enforcement.\n+\t// Once this has been completed, members of the group previously added to the view dataset's ACL\n+\t// no longer require access to the source dataset to successfully query the view.\n+\tsrcMeta, err := srcDataset.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tsrcUpdateMeta := bigquery.DatasetMetadataToUpdate{\n+\t\tAccess: append(srcMeta.Access, &bigquery.AccessEntry{\n+\t\t\tEntityType: bigquery.ViewEntity,\n+\t\t\tView:       view,\n+\t\t}),\n+\t}\n+\tif _, err := srcDataset.Update(ctx, srcUpdateMeta, srcMeta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_grant_view_access]\n+\treturn nil\n+}\n+\n func tableLabels(client *bigquery.Client, w io.Writer, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_table_labels]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1356,6 +1462,19 @@\nfunc deleteAndUndeleteTable(client *bigquery.Client, datasetID, tableID string)\n \t// Record the current time.  We'll use this as the snapshot time\n \t// for recovering the table.\n \tsnapTime := time.Now()\n+\t// [END bigquery_undelete_table]\n+\t// Because this test immediately creates the test resource and deletes it, it is sensitive\n+\t// to timing variance between the client and backend.  We correct for that by choosing the latter\n+\t// of the \"current\" local time, and the backend's report of the creation time of the table.\n+\tmeta, err := ds.Table(tableID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif snapTime.Before(meta.CreationTime) {\n+\t\tsnapTime = time.Time(meta.CreationTime)\n+\t}\n+\t// [START bigquery_undelete_table]\n \n \t// \"Accidentally\" delete the table.\n \tif err := client.Dataset(datasetID).Table(tableID).Delete(ctx); err != nil {",
        "comments": [],
        "commit_messages": [
            "Fix flake in undelete test, address view definition issues"
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1462,12 +1581,63 @@\nfunc importCSVExplicitSchema(client *bigquery.Client, datasetID, tableID string)\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_csv]\n \treturn nil\n }\n \n+func importCSVAutodetectSchema(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_csv_autodetect]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.csv\")\n+\tgcsRef.SourceFormat = bigquery.CSV\n+\tgcsRef.AutoDetect = true\n+\tgcsRef.SkipLeadingRows = 1\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_csv_autodetect]\n+\treturn nil\n+}\n+\n+func importCSVTruncate(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_csv_truncate]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.csv\")\n+\tgcsRef.SourceFormat = bigquery.CSV\n+\tgcsRef.AutoDetect = true\n+\tgcsRef.SkipLeadingRows = 1\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\tloader.WriteDisposition = bigquery.WriteTruncate\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_csv_truncate]\n+\treturn nil\n+}\n+\n func importJSONExplicitSchema(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_table_gcs_json]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1490,7 +1660,7 @@\nfunc importJSONExplicitSchema(client *bigquery.Client, datasetID, tableID string\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_json]\n \treturn nil",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments."
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1515,7 +1685,7 @@\nfunc importJSONAutodetectSchema(client *bigquery.Client, datasetID, tableID stri\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_json_autodetect]\n \treturn nil",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments."
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1544,13 +1714,39 @@\nfunc importJSONWithCMEK(client *bigquery.Client, datasetID, tableID string) erro\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \n \t// [END bigquery_load_table_gcs_json_cmek]\n \treturn nil\n }\n \n+func importJSONTruncate(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_json_truncate]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.json\")\n+\tgcsRef.SourceFormat = bigquery.JSON\n+\tgcsRef.AutoDetect = true\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\tloader.WriteDisposition = bigquery.WriteTruncate\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n+\t}\n+\n+\t// [END bigquery_load_table_gcs_json_truncate]\n+\treturn nil\n+}\n+\n func importORC(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_table_gcs_orc]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1568,7 +1764,7 @@\nfunc importORC(client *bigquery.Client, datasetID, tableID string) error {\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_orc]\n \treturn nil",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments."
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1594,7 +1790,7 @@\nfunc importORCTruncate(client *bigquery.Client, datasetID, tableID string) error\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_orc_truncate]\n \treturn nil",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments."
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1618,7 +1814,7 @@\nfunc importParquet(client *bigquery.Client, datasetID, tableID string) error {\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_parquet]\n \treturn nil",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments."
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1643,7 +1839,7 @@\nfunc importParquetTruncate(client *bigquery.Client, datasetID, tableID string) e\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_gcs_parquet_truncate]\n \treturn nil",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments."
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1676,7 +1872,7 @@\nfunc importPartitionedSampleTable(client *bigquery.Client, destDatasetID, destTa\n \t}\n \n \tif status.Err() != nil {\n-\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t\treturn fmt.Errorf(\"job completed with error: %v\", status.Err())\n \t}\n \t// [END bigquery_load_table_partitioned]\n \treturn nil",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments."
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -278,6 +278,46 @@\nfunc TestAll(t *testing.T) {\n \n }\n \n+// Exercise BigQuery logical views.\n+func TestViews(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n+\tctx := context.Background()\n+\n+\tclient, err := bigquery.NewClient(ctx, tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tsrcDatasetID := uniqueBQName(\"golang_example_view_source\")\n+\tif err := createDataset(client, srcDatasetID); err != nil {\n+\t\tt.Errorf(\"createDataset(%q): %v\", srcDatasetID, err)\n+\t}\n+\tdefer client.Dataset(srcDatasetID).DeleteWithContents(ctx)\n+\tviewDatasetID := uniqueBQName(\"golang_example_view_container\")\n+\tif err := createDataset(client, viewDatasetID); err != nil {\n+\t\tt.Errorf(\"createDataset(%q): %v\", viewDatasetID, err)\n+\t}\n+\tdefer client.Dataset(viewDatasetID).DeleteWithContents(ctx)\n+\n+\tviewID := uniqueBQName(\"golang_example_view\")\n+\n+\tif err := createView(client, viewDatasetID, viewID); err != nil {\n+\t\tt.Fatalf(\"createView(dataset:%q view:%q): %v\", viewDatasetID, viewID, err)\n+\t}\n+\n+\tif err := getView(client, viewDatasetID, viewID); err != nil {\n+\t\tt.Fatalf(\"getView(dataset:%q view:%q): %v\", viewDatasetID, viewID, err)\n+\t}\n+\n+\tif err := updateView(client, viewDatasetID, viewID); err != nil {\n+\t\tt.Fatalf(\"updateView(dataset:%q view:%q): %v\", viewDatasetID, viewID, err)\n+\t}\n+\n+\tif err := updateViewDelegated(client, srcDatasetID, viewDatasetID, viewID); err != nil {\n+\t\tt.Fatalf(\"updateViewDelegated(srcdataset:%q viewdataset:%q view:%q): %v\", srcDatasetID, viewDatasetID, viewID, err)\n+\t}\n+\n+}\n+\n func TestImportExport(t *testing.T) {\n \ttc := testutil.EndToEndTest(t)\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "BigQuery: more snippets (csv, json, view)"
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "BigQuery: new snippets",
        "pr_number": 625,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -303,6 +343,16 @@\nfunc TestImportExport(t *testing.T) {\n \t\tt.Fatalf(\"importCSVFromFile(dataset:%q table:%q filename:%q): %v\", datasetID, tableID, filename, err)\n \t}\n \n+\tautoCSV := uniqueBQName(\"golang_example_csv_autodetect\")\n+\tif err := importCSVAutodetectSchema(client, datasetID, autoCSV); err != nil {\n+\t\tt.Fatalf(\"importCSVAutodetectSchema(dataset:%q table:%q): %v\", datasetID, autoCSV, err)\n+\t}\n+\n+\tautoCSVTruncate := uniqueBQName(\"golang_example_csv_truncate\")\n+\tif err := importCSVTruncate(client, datasetID, autoCSVTruncate); err != nil {\n+\t\tt.Fatalf(\"importCSVTruncate(dataset:%q table:%q): %v\", datasetID, autoCSVTruncate, err)\n+\t}\n+\n \texplicitCSV := uniqueBQName(\"golang_example_dataset_importcsv_explicit\")\n \tif err := importCSVExplicitSchema(client, datasetID, explicitCSV); err != nil {\n \t\tt.Fatalf(\"importCSVExplicitSchema(dataset:%q table:%q): %v\", datasetID, explicitCSV, err)",
        "comments": [],
        "commit_messages": [
            "BigQuery: more snippets (csv, json, view)"
        ],
        "last_commit_sha": "6cb33f1db41fe40cff0735d4be715fdf1071ea30"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage main\n import (\n \t\"context\"\n \t\"errors\"\n+\t\"log\"\n \t\"time\"\n \n \t\"google.golang.org/api/iterator\"",
        "comments": [
            {
                "comment": "It's more common to return the error here. It's OK to log and return then return `nil` below. The semantics are the same, but it's easier to read.",
                "position": 14
            },
            {
                "comment": "If the return is inside the region tags but the function declaration isn't, the return doesn't make sense  in the scope of the snippet. ",
                "position": 14
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -22,10 +23,11 @@\nfunc addDocAsMap(ctx context.Context, client *firestore.Client) error {\n \t\t\"country\": \"USA\",\n \t})\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_simple_doc_as_map]\n-\treturn nil\n+\treturn err\n }\n \n func addDocDataTypes(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -44,21 +46,23 @@\nfunc addDocDataTypes(ctx context.Context, client *firestore.Client) error {\n \n \t_, err := client.Collection(\"data\").Doc(\"one\").Set(ctx, doc)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_doc_data_types]\n-\treturn nil\n+\treturn err\n }\n \n func addDocWithID(ctx context.Context, client *firestore.Client) error {\n \tvar data = make(map[string]interface{})\n \t// [START fs_add_doc_with_id]\n \t_, err := client.Collection(\"cities\").Doc(\"new-city-id\").Set(ctx, data)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_doc_with_id]\n-\treturn nil\n+\treturn err\n }\n \n func addDocWithoutID(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -68,10 +72,11 @@\nfunc addDocWithoutID(ctx context.Context, client *firestore.Client) error {\n \t\t\"country\": \"Japan\",\n \t})\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_doc_auto_id]\n-\treturn nil\n+\treturn err\n }\n \n func addDocAsEntity(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -82,10 +87,11 @@\nfunc addDocAsEntity(ctx context.Context, client *firestore.Client) error {\n \t}\n \t_, err := client.Collection(\"cities\").Doc(\"LA\").Set(ctx, city)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_simple_doc_as_entity]\n-\treturn nil\n+\treturn err\n }\n \n func addDocAfterAutoGeneratedID(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -100,10 +106,11 @@\nfunc addDocAfterAutoGeneratedID(ctx context.Context, client *firestore.Client) e\n \t// later...\n \t_, err := ref.Set(ctx, data)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_add_doc_data_after_auto_id]\n-\treturn nil\n+\treturn err\n }\n \n func updateDoc(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -112,10 +119,11 @@\nfunc updateDoc(ctx context.Context, client *firestore.Client) error {\n \t\t\"capital\": true,\n \t}, firestore.MergeAll)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_update_doc]\n-\treturn nil\n+\treturn err\n }\n \n func updateDocCreateIfMissing(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -125,10 +133,11 @@\nfunc updateDocCreateIfMissing(ctx context.Context, client *firestore.Client) err\n \t}, firestore.MergeAll)\n \n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_update_create_if_missing]\n-\treturn nil\n+\treturn err\n }\n \n func updateDocMultiple(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -145,10 +154,11 @@\nfunc updateDocMultiple(ctx context.Context, client *firestore.Client) error {\n \t\t\"areaInSquareMiles\": 573.0,\n \t}, firestore.MergeAll)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_update_multiple_fields]\n-\treturn nil\n+\treturn err\n }\n \n func updateDocNested(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -164,23 +174,24 @@\nfunc updateDocNested(ctx context.Context, client *firestore.Client) error {\n \t}\n \n \t// [START_EXCLUDE]\n-\t_, err := client.Collection(\"users\").Doc(\"frank\").Set(ctx, initialData)\n-\tif err != nil {\n+\n+\tif _, err := client.Collection(\"users\").Doc(\"frank\").Set(ctx, initialData); err != nil {\n \t\treturn err\n \t}\n \t// [END_EXCLUDE]\n \n-\t_, err = client.Collection(\"users\").Doc(\"frank\").Set(ctx, map[string]interface{}{\n+\t_, err := client.Collection(\"users\").Doc(\"frank\").Set(ctx, map[string]interface{}{\n \t\t\"age\": 13,\n \t\t\"favorites\": map[string]interface{}{\n \t\t\t\"color\": \"Red\",\n \t\t},\n \t}, firestore.MergeAll)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_update_nested_fields]\n-\treturn nil\n+\treturn err\n }\n \n func updateDocServerTimestamp(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -196,20 +207,22 @@\nfunc updateDocServerTimestamp(ctx context.Context, client *firestore.Client) err\n \t\t\"timestamp\": firestore.ServerTimestamp,\n \t}, firestore.MergeAll)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_update_server_timestamp]\n-\treturn nil\n+\treturn err\n }\n \n func deleteDoc(ctx context.Context, client *firestore.Client) error {\n \t// [START fs_delete_doc]\n \t_, err := client.Collection(\"cities\").Doc(\"DC\").Delete(ctx)\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_delete_doc]\n-\treturn nil\n+\treturn err\n }\n \n func deleteField(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -221,7 +234,8 @@\nfunc deleteField(ctx context.Context, client *firestore.Client) error {\n \t\t},\n \t})\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_delete_field]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -230,7 +244,7 @@\nfunc deleteField(ctx context.Context, client *firestore.Client) error {\n \t// Set(ctx, map[string]interface{}{\n \t//\t\"capital\": firestore.Delete,\n \t//})\n-\treturn nil\n+\treturn err\n }\n \n // [START fs_delete_collection]",
        "comments": [],
        "commit_messages": [
            "Update firestore_snippets error handling."
        ],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -299,10 +313,11 @@\nfunc runSimpleTransaction(ctx context.Context, client *firestore.Client) error {\n \t\t}, firestore.MergeAll)\n \t})\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors appropriately in this section.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_run_simple_transaction]\n-\treturn nil\n+\treturn err\n }\n \n func infoTransaction(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "firestore: update error handling",
        "pr_number": 624,
        "file_name": "firestore/firestore_snippets/save.go",
        "code_diff": "@@ -326,10 +341,11 @@\nfunc infoTransaction(ctx context.Context, client *firestore.Client) error {\n \t\treturn errors.New(\"population is too big\")\n \t})\n \tif err != nil {\n-\t\treturn err\n+\t\t// Handle any errors in an appropriate way, such as returning them.\n+\t\tlog.Printf(\"An error has occurred: %s\", err)\n \t}\n \t// [END fs_return_info_transaction]\n-\treturn nil\n+\treturn err\n }\n \n func batchWrite(ctx context.Context, client *firestore.Client) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "6795433569db0ed05eb9d3d334361d9e0d3f8444"
    },
    {
        "pr_title": "profiler: add function to hotapp which repeatedly allocates memory",
        "pr_number": 621,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -64,7 +64,7 @@\nfunc waitImpl() {\n // Simulates a memory-hungry function. It calls an \"impl\" function to produce\n // a bit deeper stacks in the profiler visualization, merely for illustration\n // purpose.\n-func alloc() {\n+func allocOnce() {\n \tallocImpl()\n }",
        "comments": [],
        "commit_messages": [
            "Rename alloc() to allocOnce()"
        ],
        "last_commit_sha": "a098fbee31d19f7e3c1280873c73f1650c8a42d3"
    },
    {
        "pr_title": "profiler: add function to hotapp which repeatedly allocates memory",
        "pr_number": 621,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -75,6 +75,18 @@\nfunc allocImpl() {\n \t}\n }\n \n+// allocMany simulates a function which allocates a lot of memory, but does not\n+// hold on to that memory.\n+func allocMany() {\n+\t// Allocate 1 MiB of 64 KiB chunks repeatedly.\n+\tfor {\n+\t\tfor i := 0; i < 16; i++ {\n+\t\t\t_ = make([]byte, 64*1024)\n+\t\t}\n+\t\ttime.Sleep(100 * time.Millisecond)\n+\t}\n+}\n+\n // Simulates a CPU-intensive computation.\n func busyloop() {\n \tfor {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "a098fbee31d19f7e3c1280873c73f1650c8a42d3"
    },
    {
        "pr_title": "docs/appengine: move defer sample to another file",
        "pr_number": 617,
        "file_name": "docs/appengine/taskqueue/push/taskqueue_push.go",
        "code_diff": "@@ -7,13 +7,11 @@\npackage counter\n \n import (\n-\t\"context\"\n \t\"html/template\"\n \t\"net/http\"\n \n \t\"google.golang.org/appengine\"\n \t\"google.golang.org/appengine/datastore\"\n-\t\"google.golang.org/appengine/delay\"\n \t\"google.golang.org/appengine/log\"\n \t\"google.golang.org/appengine/taskqueue\"\n )",
        "comments": [],
        "commit_messages": [
            "docs/appengine: move defer sample to another file\n\nThis also deletes the URL_endpoints sample since it's not used."
        ],
        "last_commit_sha": "4291ea774cee9a05fc0ed9ee13b2d258b4481706"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -7,9 +7,13 @@\npackage main\n \n import (\n+\t\"errors\"\n \t\"fmt\"\n \t\"log\"\n \t\"os\"\n+\t\"strconv\"\n+\t\"sync\"\n+\t\"sync/atomic\"\n \t\"time\"\n \n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Publish that scales with asynchronous error handling",
        "pr_number": 588,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -52,6 +56,11 @@\nfunc main() {\n \t\tlog.Fatalf(\"Failed to publish: %v\", err)\n \t}\n \n+\t// Publish 10 messages with asynchronous error handling.\n+\tif err := publishThatScales(client, topic, 10); err != nil {\n+\t\tlog.Fatalf(\"Failed to publish: %v\", err)\n+\t}\n+\n \t// Delete the topic.\n \tif err := delete(client, topic); err != nil {\n \t\tlog.Fatalf(\"Failed to delete the topic: %v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "35faaaea0d99e7cfffec10b07520694e41f67dae"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-1/main.go",
        "code_diff": "@@ -4,23 +4,23 @@\npackage main\n \n-// [START import_statements]\n+// [START gae_go_env_import]\n import (\n \t\"fmt\"\n \t\"net/http\"\n \n \t\"google.golang.org/appengine\" // Required external App Engine library\n )\n \n-// [END import_statements]\n-// [START main_func]\n+// [END gae_go_env_import]\n+// [START gae_go_env_main]\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)\n \tappengine.Main() // Starts the server to receive requests\n }\n \n-// [END main_func]\n-// [START indexHandler]\n+// [END gae_go_env_main]\n+// [START gae_go_env_index]\n func indexHandler(w http.ResponseWriter, r *http.Request) {\n \t// if statement redirects all invalid URLs to the root homepage.\n \t// Ex: if URL is http://[YOUR_PROJECT_ID].appspot.com/FOO, it will be",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-3/main.go",
        "code_diff": "@@ -5,28 +5,28 @@\npackage main\n \n import (\n-\t// [START import]\n+\t// [START gae_go_env_template_import]\n \t\"fmt\"\n \t\"html/template\"\n-\t// [END import]\n+\t// [END gae_go_env_template_import]\n \t\"net/http\"\n \n \t\"google.golang.org/appengine\"\n )\n \n-// [START templ_variable]\n+// [START gae_go_env_template_vars]\n var (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [END templ_variable]\n-// [START templ_params]\n+// [END gae_go_env_template_vars]\n+// [START gae_go_env_template_params]\n type templateParams struct {\n \tNotice string\n \tName   string\n }\n \n-// [END templ_params]\n+// [END gae_go_env_template_params]\n func main() {\n \thttp.HandleFunc(\"/\", indexHandler)\n \tappengine.Main()",
        "comments": [],
        "commit_messages": [
            "region tags: gophers"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-3/main.go",
        "code_diff": "@@ -37,7 +37,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\thttp.Redirect(w, r, \"/\", http.StatusFound)\n \t\treturn\n \t}\n-\t// [START handling]\n+\t// [START gae_go_env_handling]\n \tparams := templateParams{}\n \n \tif r.Method == \"GET\" {",
        "comments": [],
        "commit_messages": [
            "region tags: gophers"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -11,36 +11,36 @@\nimport (\n \n \t\"google.golang.org/appengine\"\n \n-\t// [START imports]\n+\t// [START gae_go_env_data_imports]\n \t\"time\"\n \n \t\"google.golang.org/appengine/datastore\"\n \t\"google.golang.org/appengine/log\"\n-\t// [END imports]\n+\t// [END gae_go_env_data_imports]\n )\n \n var (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [START post_struct]\n+// [START gae_go_env_post_struct]\n type Post struct {\n \tAuthor  string\n \tMessage string\n \tPosted  time.Time\n }\n \n-// [END post_struct]\n+// [END gae_go_env_post_struct]\n \n type templateParams struct {\n \tNotice string\n \n \tName string\n-\t// [START added_templateParams_fields]\n+\t// [START gae_go_env_template_params_fields]\n \tMessage string\n \n \tPosts []Post\n-\t// [END added_templateParams_fields]\n+\t// [END gae_go_env_template_params_fields]\n \n }",
        "comments": [],
        "commit_messages": [
            "region tags: gophers"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -54,37 +54,37 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\thttp.Redirect(w, r, \"/\", http.StatusFound)\n \t\treturn\n \t}\n-\t// [START new_context]\n+\t// [START gae_go_env_new_context]\n \tctx := appengine.NewContext(r)\n-\t// [END new_context]\n+\t// [END gae_go_env_new_context]\n \tparams := templateParams{}\n \n-\t// [START new_query]\n+\t// [START gae_go_env_new_query]\n \tq := datastore.NewQuery(\"Post\").Order(\"-Posted\").Limit(20)\n-\t// [END new_query]\n-\t// [START get_posts]\n+\t// [END gae_go_env_new_query]\n+\t// [START gae_go_env_get_posts]\n \tif _, err := q.GetAll(ctx, &params.Posts); err != nil {\n \t\tlog.Errorf(ctx, \"Getting posts: %v\", err)\n \t\tw.WriteHeader(http.StatusInternalServerError)\n \t\tparams.Notice = \"Couldn't get latest posts. Refresh?\"\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n-\t// [END get_posts]\n+\t// [END gae_go_env_get_posts]\n \n \tif r.Method == \"GET\" {\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n \n \t// It's a POST request, so handle the form submission.\n-\t// [START new_post]\n+\t// [START gae_go_env_new_post]\n \tpost := Post{\n \t\tAuthor:  r.FormValue(\"name\"),\n \t\tMessage: r.FormValue(\"message\"),\n \t\tPosted:  time.Now(),\n \t}\n-\t// [END new_post]\n+\t// [END gae_go_env_new_post]\n \tif post.Author == \"\" {\n \t\tpost.Author = \"Anonymous Gopher\"\n \t}",
        "comments": [],
        "commit_messages": [
            "region tags: gophers"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-4/main.go",
        "code_diff": "@@ -96,10 +96,10 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t\tindexTemplate.Execute(w, params)\n \t\treturn\n \t}\n-\t// [START new_key]\n+\t// [START gae_go_env_new_key]\n \tkey := datastore.NewIncompleteKey(ctx, \"Post\", nil)\n-\t// [END new_key]\n-\t// [START add_post]\n+\t// [END gae_go_env_new_key]\n+\t// [START gae_go_env_add_post]\n \tif _, err := datastore.Put(ctx, key, &post); err != nil {\n \t\tlog.Errorf(ctx, \"datastore.Put: %v\", err)",
        "comments": [],
        "commit_messages": [
            "region tags: gophers"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -10,16 +10,16 @@\nimport (\n \t\"net/http\"\n \t\"time\"\n \n-\t// [START imports]\n+\t// [START gae_go_env_firebase_imports]\n \tfirebase \"firebase.google.com/go\"\n-\t// [END imports]\n+\t// [END gae_go_env_firebase_imports]\n \n \t\"google.golang.org/appengine\"\n \t\"google.golang.org/appengine/datastore\"\n \t\"google.golang.org/appengine/log\"\n )\n \n-// [START new_variable]\n+// [START gae_go_env_new_variable]\n \n var (\n \tfirebaseConfig = &firebase.Config{",
        "comments": [],
        "commit_messages": [
            "region tags: gophers"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -30,9 +30,9 @@\nvar (\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )\n \n-// [END new_variable]\n+// [END gae_go_env_new_variable]\n \n-// [START new_post_field]\n+// [START gae_go_env_new_post_field]\n \n type Post struct {\n \tAuthor  string",
        "comments": [],
        "commit_messages": [
            "region tags: gophers"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -41,7 +41,7 @@\ntype Post struct {\n \tPosted  time.Time\n }\n \n-// [END new_post_field]\n+// [END gae_go_env_new_post_field]\n \n type templateParams struct {\n \tNotice  string",
        "comments": [],
        "commit_messages": [
            "region tags: gophers"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -78,7 +78,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \t}\n \t// It's a POST request, so handle the form submission.\n \n-\t// [START firebase_token]\n+\t// [START gae_go_env_firebase_token]\n \tmessage := r.FormValue(\"message\")\n \n \t// Create a new Firebase App.",
        "comments": [],
        "commit_messages": [
            "region tags: gophers"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-5/static/index.js",
        "code_diff": "@@ -3,7 +3,7 @@\nwindow.addEventListener('load', function () {\n     firebase.auth().signOut();\n   };\n \n-  // [START UIconfig_variable]\n+  // [START gae_go_env_ui_config]\n   // FirebaseUI config.\n   var uiConfig = {\n     signInSuccessUrl: '/',",
        "comments": [],
        "commit_messages": [
            "region tags: gophers"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "appengine/gophers/gophers-5/static/index.js",
        "code_diff": "@@ -19,9 +19,9 @@\nwindow.addEventListener('load', function () {\n     // Terms of service url.\n     tosUrl: '<your-tos-url>'\n   };\n-  // [END UIconfig_variable]\n+  // [END gae_go_env_ui_config]\n \n-  // [START auth_request]\n+  // [START gae_go_env_auth_request]\n   firebase.auth().onAuthStateChanged(function (user) {\n     if (user) {\n       // User is signed in.",
        "comments": [],
        "commit_messages": [
            "region tags: gophers"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/appidentity/appidentity.go",
        "code_diff": "@@ -4,7 +4,7 @@\npackage sample\n \n-// [START asserting_identity_to_Google_APIs]\n+// [START gae_go_app_identity]\n import (\n \t\"net/http\"",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -14,7 +14,7 @@\nimport (\n )\n \n func sampleHandler(w http.ResponseWriter, r *http.Request) {\n-\t// [START uploading_a_blob_2]\n+\t// [START gae_blobstore_upload_form]\n \tvar rootTemplate = template.Must(template.New(\"root\").Parse(rootTemplateHTML))\n \n \tconst rootTemplateHTML = `",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -24,16 +24,16 @@\nUpload File: <input type=\"file\" name=\"file\"><br>\n <input type=\"submit\" name=\"submit\" value=\"Submit\">\n </form></body></html>\n `\n-\t// [END uploading_a_blob_2]\n+\t// [END gae_blobstore_upload_form]\n \n-\t// [START uploading_a_blob_1]\n+\t// [START gae_blobstore_upload_url]\n \tctx := appengine.NewContext(r)\n \tuploadURL, err := blobstore.UploadURL(ctx, \"/upload\", nil)\n \tif err != nil {\n \t\tserveError(ctx, w, err)\n \t\treturn\n \t}\n-\t// [END uploading_a_blob_1]\n+\t// [END gae_blobstore_upload_url]\n \n \tw.Header().Set(\"Content-Type\", \"text/html\")\n \terr = rootTemplate.Execute(w, uploadURL)",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -43,7 +43,7 @@\nUpload File: <input type=\"file\" name=\"file\"><br>\n }\n \n func sampleHandler2(w http.ResponseWriter, r *http.Request) {\n-\t// [START uploading_a_blob_3]\n+\t// [START gae_blobstore_upload_handler]\n \tctx := appengine.NewContext(r)\n \tblobs, _, err := blobstore.ParseUpload(r)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/blobstore/blobstore.go",
        "code_diff": "@@ -57,16 +57,15 @@\nfunc sampleHandler2(w http.ResponseWriter, r *http.Request) {\n \t\treturn\n \t}\n \thttp.Redirect(w, r, \"/serve/?blobKey=\"+string(file[0].BlobKey), http.StatusFound)\n-\t// [END uploading_a_blob_3]\n+\t// [END gae_blobstore_upload_handler]\n \n-\t// [START serving_a_blob]\n+\t// [START gae_blobstore_serving]\n \tblobstore.Send(w, appengine.BlobKey(r.FormValue(\"blobKey\")))\n-\t// [END serving_a_blob]\n+\t// [END gae_blobstore_serving]\n }\n \n /* Requires old package (import \"appengine/blobstore\")\n \n-// [START writing_files_to_the_Blobstore]\n var k appengine.BlobKey\n bw, err := blobstore.Create(ctx, \"application/octet-stream\")\n if err != nil {",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/blobstore/complete.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START complete_sample_application]\n+// [START gae_blobstore_sample]\n \n package blobstore_example",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/capabilities/capability.go",
        "code_diff": "@@ -13,7 +13,7 @@\nimport (\n \t\"google.golang.org/appengine/capability\"\n )\n \n-// [START datastore_lookup]\n+// [START gae_go_capabilities_lookup]\n func handler(w http.ResponseWriter, r *http.Request) {\n \tctx := appengine.NewContext(r)\n \tif !capability.Enabled(ctx, \"datastore_v3\", \"*\") {",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -18,7 +18,7 @@\nimport (\n var maxHeight int\n var minBirthYear, maxBirthYear int\n \n-// [START interface]\n+// [START gae_go_datastore_interface]\n type Person struct {\n \tFirstName string\n \tLastName  string",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -45,48 +45,48 @@\nfunc handle(w http.ResponseWriter, r *http.Request) {\n \t// ...\n }\n \n-// [END interface]\n+// [END gae_go_datastore_interface]\n \n func example() {\n \tvar lastSeenKey *datastore.Key\n \n-\t// [START key_filter_example]\n+\t// [START gae_go_datastore_key_filter]\n \tq := datastore.NewQuery(\"Person\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END key_filter_example]\n+\t// [END gae_go_datastore_key_filter]\n \t_ = q\n }\n \n func example2() {\n-\t// [START property_filter_example]\n+\t// [START gae_go_datastore_property_filter]\n \tq := datastore.NewQuery(\"Person\").Filter(\"Height <=\", maxHeight)\n-\t// [END property_filter_example]\n+\t// [END gae_go_datastore_property_filter]\n \t_ = q\n }\n \n func example3() {\n \tvar ancestorKey *datastore.Key\n \n-\t// [START ancestor_filter_example]\n+\t// [START gae_go_datastore_ancestor_filter]\n \tq := datastore.NewQuery(\"Person\").Ancestor(ancestorKey)\n-\t// [END ancestor_filter_example]\n+\t// [END gae_go_datastore_ancestor_filter]\n \t_ = q\n }\n \n func example4() {\n-\t// [START sort_order_example]\n+\t// [START gae_go_datastore_sort_order]\n \t// Order alphabetically by last name:\n \tq := datastore.NewQuery(\"Person\").Order(\"LastName\")\n \n \t// Order by height, tallest to shortest:\n \tq = datastore.NewQuery(\"Person\").Order(\"-Height\")\n-\t// [END sort_order_example]\n+\t// [END gae_go_datastore_sort_order]\n \t_ = q\n }\n \n func example5() {\n-\t// [START multiple_sort_orders_example]\n+\t// [START gae_go_datastore_multiple_sort_orders]\n \tq := datastore.NewQuery(\"Person\").Order(\"LastName\").Order(\"-Height\")\n-\t// [END multiple_sort_orders_example]\n+\t// [END gae_go_datastore_multiple_sort_orders]\n \t_ = q\n }",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -96,7 +96,7 @@\nfunc example6() {\n \t}\n \tvar ctx context.Context\n \n-\t// [START ancestor_query_example]\n+\t// [START gae_go_datastore_ancestor_query]\n \t// Create two Photo entities in the datastore with a Person as their ancestor.\n \ttomKey := datastore.NewKey(ctx, \"Person\", \"Tom\", 0, nil)",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -117,101 +117,101 @@\nfunc example6() {\n \t_, err = q.GetAll(ctx, &photos)\n \t// check err\n \t// do something with photos\n-\t// [END ancestor_query_example]\n+\t// [END gae_go_datastore_ancestor_query]\n \t_ = err\n \t_ = photos\n }\n \n func example7() {\n-\t// [START keys_only_example]\n+\t// [START gae_go_datastore_keys_only]\n \tq := datastore.NewQuery(\"Person\").KeysOnly()\n-\t// [END keys_only_example]\n+\t// [END gae_go_datastore_keys_only]\n \t_ = q\n }\n \n func example8() {\n-\t// [START inequality_filters_one_property_valid_example_1]\n+\t// [START gae_go_datastore_inequality_filters_one_property_valid_1]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"BirthYear <=\", maxBirthYear)\n-\t// [END inequality_filters_one_property_valid_example_1]\n+\t// [END gae_go_datastore_inequality_filters_one_property_valid_1]\n \t_ = q\n }\n \n func example9() {\n-\t// [START inequality_filters_one_property_invalid_example]\n+\t// [START gae_go_datastore_inequality_filters_one_property_invalid]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"Height <=\", maxHeight) // ERROR\n-\t// [END inequality_filters_one_property_invalid_example]\n+\t// [END gae_go_datastore_inequality_filters_one_property_invalid]\n \t_ = q\n }\n \n func example10() {\n \tvar targetLastName, targetCity string\n \n-\t// [START inequality_filters_one_property_valid_example_2]\n+\t// [START gae_go_datastore_inequality_filters_one_property_valid_2]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"LastName =\", targetLastName).\n \t\tFilter(\"City =\", targetCity).\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tFilter(\"BirthYear <=\", maxBirthYear)\n-\t// [END inequality_filters_one_property_valid_example_2]\n+\t// [END gae_go_datastore_inequality_filters_one_property_valid_2]\n \t_ = q\n }\n \n func example11() {\n-\t// [START inequality_filters_sort_orders_valid_example]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_valid]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"BirthYear\").\n \t\tOrder(\"LastName\")\n-\t// [END inequality_filters_sort_orders_valid_example]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_valid]\n \t_ = q\n }\n \n func example12() {\n-\t// [START inequality_filters_sort_orders_invalid_example_1]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_invalid_1]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"LastName\") // ERROR\n-\t// [END inequality_filters_sort_orders_invalid_example_1]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_invalid_1]\n \t_ = q\n }\n \n func example13() {\n-\t// [START inequality_filters_sort_orders_invalid_example_2]\n+\t// [START gae_go_datastore_inequality_filters_sort_orders_invalid_2]\n \tq := datastore.NewQuery(\"Person\").\n \t\tFilter(\"BirthYear >=\", minBirthYear).\n \t\tOrder(\"LastName\").\n \t\tOrder(\"BirthYear\") // ERROR\n-\t// [END inequality_filters_sort_orders_invalid_example_2]\n+\t// [END gae_go_datastore_inequality_filters_sort_orders_invalid_2]\n \t_ = q\n }\n \n func example14() {\n-\t// [START surprising_behavior_example_1]\n+\t// [START gae_go_datastore_surprising_behavior_1]\n \tq := datastore.NewQuery(\"Widget\").\n \t\tFilter(\"x >\", 1).\n \t\tFilter(\"x <\", 2)\n-\t// [END surprising_behavior_example_1]\n+\t// [END gae_go_datastore_surprising_behavior_1]\n \t_ = q\n }\n \n func example15() {\n-\t// [START surprising_behavior_example_2]\n+\t// [START gae_go_datastore_surprising_behavior_2]\n \tq := datastore.NewQuery(\"Widget\").\n \t\tFilter(\"x =\", 1).\n \t\tFilter(\"x =\", 2)\n-\t// [END surprising_behavior_example_2]\n+\t// [END gae_go_datastore_surprising_behavior_2]\n \t_ = q\n }\n \n func doSomething(k *datastore.Key, p Person) {}\n \n func example16() {\n \tvar ctx context.Context\n-\t// [START retrieval_example]\n+\t// [START gae_go_datastore_retrieval]\n \tq := datastore.NewQuery(\"Person\")\n \tt := q.Run(ctx)\n \tfor {",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -227,13 +227,13 @@\nfunc example16() {\n \t\t// Do something with Person p and Key k\n \t\tdoSomething(k, p)\n \t}\n-\t// [END retrieval_example]\n+\t// [END gae_go_datastore_retrieval]\n }\n \n func example17() {\n \tvar ctx context.Context\n \n-\t// [START all_entities_retrieval_example]\n+\t// [START gae_go_datastore_all_entities_retrieval]\n \tq := datastore.NewQuery(\"Person\")\n \tvar people []Person\n \tkeys, err := q.GetAll(ctx, &people)",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -246,13 +246,13 @@\nfunc example17() {\n \t\t// Do something with Person p and Key k\n \t\tdoSomething(k, p)\n \t}\n-\t// [END all_entities_retrieval_example]\n+\t// [END gae_go_datastore_all_entities_retrieval]\n }\n \n func example18() {\n \tvar ctx context.Context\n \n-\t// [START query_limit_example]\n+\t// [START gae_go_datastore_query_limit]\n \tq := datastore.NewQuery(\"Person\").Order(\"-Height\").Limit(5)\n \tvar people []Person\n \t_, err := q.GetAll(ctx, &people)",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -261,21 +261,19 @@\nfunc example18() {\n \tfor _, p := range people {\n \t\tlog.Infof(ctx, \"%s %s, %d inches tall\", p.FirstName, p.LastName, p.Height)\n \t}\n-\t// [END query_limit_example]\n+\t// [END gae_go_datastore_query_limit]\n \t_ = err\n }\n \n func example19() {\n-\t// [START query_offset_example]\n \tq := datastore.NewQuery(\"Person\").Order(\"-Height\").Limit(5).Offset(5)\n-\t// [END query_offset_example]\n \t_ = q\n }\n \n func example20() {\n \tvar ctx context.Context\n \n-\t// [START cursors]\n+\t// [START gae_go_datastore_cursors]\n \t// Create a query for all Person entities.\n \tq := datastore.NewQuery(\"Person\")",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -310,24 +308,24 @@\nfunc example20() {\n \t\t\tValue: []byte(cursor.String()),\n \t\t})\n \t}\n-\t// [END cursors]\n+\t// [END gae_go_datastore_cursors]\n }\n \n func example21() {\n \tvar lastSeenKey *datastore.Key\n \n-\t// [START kindless_query_example]\n+\t// [START gae_go_datastore_kindless_query]\n \tq := datastore.NewQuery(\"\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_query_example]\n+\t// [END gae_go_datastore_kindless_query]\n \t_ = q\n }\n \n func example22() {\n \tvar ancestorKey, lastSeenKey *datastore.Key\n \n-\t// [START kindless_ancestor_key_query_example]\n+\t// [START gae_go_datastore_kindless_ancestor_key_query]\n \tq := datastore.NewQuery(\"\").Ancestor(ancestorKey).Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_ancestor_key_query_example]\n+\t// [END gae_go_datastore_kindless_ancestor_key_query]\n \t_ = q\n }",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/datastore/queries/queries.go",
        "code_diff": "@@ -339,7 +337,7 @@\nfunc example23() {\n \tvar ctx context.Context\n \tdoSomething := func(x interface{}) {}\n \n-\t// [START kindless_ancestor_query_example]\n+\t// [START gae_go_datastore_kindless_ancestor_query]\n \ttomKey := datastore.NewKey(ctx, \"Person\", \"Tom\", 0, nil)\n \n \tweddingPhoto := &Photo{URL: \"http://example.com/some/path/to/wedding_photo.jpg\"}",
        "comments": [],
        "commit_messages": [
            "region tags datastore"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/logs/logs.go",
        "code_diff": "@@ -2,8 +2,6 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START sample_code]\n-\n // This sample gets the app displays 5 log Records at a time, including all\n // AppLogs, with a Next link to let the user page through the results using the\n // Record's Offset property.",
        "comments": [],
        "commit_messages": [
            "log region tags"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "Update Region Tags - GAE",
        "pr_number": 587,
        "file_name": "docs/appengine/logs/writing_logs.go",
        "code_diff": "@@ -4,7 +4,7 @@\npackage app\n \n-// [START sample]\n+// [START gae_writing_logs]\n import (\n \t\"net/http\"",
        "comments": [],
        "commit_messages": [
            "log region tags"
        ],
        "last_commit_sha": "0af8a00007ab891bf870858971b3db0852a30f09"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -45,7 +45,7 @@\nfunc getAsymmetricPublicKey(ctx context.Context, client *cloudkms.Service, keyPa\n \n // [START kms_decrypt_rsa]\n \n-// decryptRSA will attempt to decrypt a given ciphertext with saved a RSA key.\n+// decryptRSA will attempt to decrypt a given ciphertext with an 'RSA_DECRYPT_OAEP_2048_SHA256' private key.stored on Cloud KMS\n func decryptRSA(ctx context.Context, client *cloudkms.Service, ciphertext, keyPath string) (string, error) {\n \tdecryptRequest := &cloudkms.AsymmetricDecryptRequest{\n \t\tCiphertext: ciphertext,",
        "comments": [],
        "commit_messages": [
            "clarified key usage details"
        ],
        "last_commit_sha": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -67,7 +67,7 @@\nfunc decryptRSA(ctx context.Context, client *cloudkms.Service, ciphertext, keyPa\n \n // [START kms_encrypt_rsa]\n \n-// encryptRSA creates a ciphertext from a plain message using a RSA public key saved at the specified keyPath.\n+// encryptRSA will encrypt a message locally using an 'RSA_DECRYPT_OAEP_2048_SHA256' public key retrieved from Cloud KMS\n func encryptRSA(ctx context.Context, client *cloudkms.Service, message, keyPath string) (string, error) {\n \tabstractKey, err := getAsymmetricPublicKey(ctx, client, keyPath)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "clarified key usage details"
        ],
        "last_commit_sha": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "kms: clarify asymmetric text usage",
        "pr_number": 584,
        "file_name": "kms/asymmetric/samples.go",
        "code_diff": "@@ -90,7 +90,8 @@\nfunc encryptRSA(ctx context.Context, client *cloudkms.Service, message, keyPath\n \n // signAsymmetric will sign a plaintext message using a saved asymmetric private key.\n func signAsymmetric(ctx context.Context, client *cloudkms.Service, message, keyPath string) (string, error) {\n-\t// Find the hash of the plaintext message.\n+\t// Note: some key algorithms will require a different hash function.\n+\t// For example, EC_SIGN_P384_SHA384 requires SHA-384.\n \tdigest := sha256.New()\n \tdigest.Write([]byte(message))\n \tdigestStr := base64.StdEncoding.EncodeToString(digest.Sum(nil))",
        "comments": [],
        "commit_messages": [
            "clarified key usage details"
        ],
        "last_commit_sha": "39e04acbc4265e94617bd81602edf8812a2a54c3"
    },
    {
        "pr_title": "appengine/gophers: log auth error messages",
        "pr_number": 582,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -85,6 +85,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \tapp, err := firebase.NewApp(ctx, firebaseConfig)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"firebase.NewApp: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c04f01c3d38b8e6bfb7c2d5519ef3c2b84ab220f"
    },
    {
        "pr_title": "appengine/gophers: log auth error messages",
        "pr_number": 582,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -93,6 +94,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \tauth, err := app.Auth(ctx)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"app.Auth: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c04f01c3d38b8e6bfb7c2d5519ef3c2b84ab220f"
    },
    {
        "pr_title": "appengine/gophers: log auth error messages",
        "pr_number": 582,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -101,6 +103,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \ttok, err := auth.VerifyIDTokenAndCheckRevoked(ctx, r.FormValue(\"token\"))\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"auth.VerifyIDAndCheckRevoked: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c04f01c3d38b8e6bfb7c2d5519ef3c2b84ab220f"
    },
    {
        "pr_title": "appengine/gophers: log auth error messages",
        "pr_number": 582,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -217,6 +217,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \tapp, err := firebase.NewApp(ctx, firebaseConfig)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"firebase.NewApp: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c04f01c3d38b8e6bfb7c2d5519ef3c2b84ab220f"
    },
    {
        "pr_title": "appengine/gophers: log auth error messages",
        "pr_number": 582,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -225,6 +226,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \tauth, err := app.Auth(ctx)\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"app.Auth: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c04f01c3d38b8e6bfb7c2d5519ef3c2b84ab220f"
    },
    {
        "pr_title": "appengine/gophers: log auth error messages",
        "pr_number": 582,
        "file_name": "appengine/gophers/gophers-6/main.go",
        "code_diff": "@@ -233,6 +235,7 @@\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n \ttok, err := auth.VerifyIDTokenAndCheckRevoked(ctx, r.FormValue(\"token\"))\n \tif err != nil {\n \t\tparams.Notice = \"Couldn't authenticate. Try logging in again?\"\n+\t\tlog.Errorf(ctx, \"auth.VerifyIDAndCheckRevoked: %v\", err)\n \t\tparams.Message = message // Preserve their message so they can try again.\n \t\tindexTemplate.Execute(w, params)\n \t\treturn",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "c04f01c3d38b8e6bfb7c2d5519ef3c2b84ab220f"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -16,115 +16,161 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n-// Use a common block to inline comments related to importing the library\n-// and constructing a client.\n-// [START bigquery_browse_table]\n-// [START bigquery_copy_table]\n-// [START bigquery_copy_table_multiple_source]\n-// [START bigquery_create_dataset]\n-// [START bigquery_create_table]\n-// [START bigquery_create_table_clustered]\n-// [START bigquery_create_table_partitioned]\n-// [START bigquery_delete_dataset]\n-// [START bigquery_delete_label_dataset]\n-// [START bigquery_delete_label_table]\n-// [START bigquery_delete_table]\n-// [START bigquery_extract_table]\n-// [START bigquery_extract_table_compressed]\n-// [START bigquery_extract_table_json]\n-// [START bigquery_get_dataset]\n-// [START bigquery_get_dataset_labels]\n-// [START bigquery_get_table]\n-// [START bigquery_get_table_labels]\n-// [START bigquery_label_dataset]\n-// [START bigquery_label_table]\n-// [START bigquery_list_datasets]\n-// [START bigquery_list_datasets_by_label]\n-// [START bigquery_list_jobs]\n-// [START bigquery_list_tables]\n-// [START bigquery_load_from_file]\n-// [START bigquery_load_table_clustered]\n-// [START bigquery_load_table_gcs_csv]\n-// [START bigquery_load_table_gcs_json]\n-// [START bigquery_load_table_gcs_json_autodetect]\n-// [START bigquery_load_table_partitioned]\n-// [START bigquery_query]\n-// [START bigquery_query_batch]\n-// [START bigquery_query_clustered_table]\n-// [START bigquery_query_destination_table]\n-// [START bigquery_query_dry_run]\n-// [START bigquery_query_legacy]\n-// [START bigquery_query_legacy_large_results]\n-// [START bigquery_query_no_cache]\n-// [START bigquery_query_params_arrays]\n-// [START bigquery_query_params_named]\n-// [START bigquery_query_params_positional]\n-// [START bigquery_query_params_structs]\n-// [START bigquery_query_params_timestamps]\n-// [START bigquery_query_partitioned_table]\n-// [START bigquery_table_insert_rows]\n-// [START bigquery_undelete_table]\n-// [START bigquery_update_dataset_access]\n-// [START bigquery_update_dataset_description]\n-// [START bigquery_update_dataset_expiration]\n-// [START bigquery_update_table_description]\n-// [START bigquery_update_table_expiration]\n-// To run this sample, you will need to create (or reuse) a context and\n-// an instance of the bigquery client.  For example:\n-// import \"cloud.google.com/go/bigquery\"\n-// ctx := context.Background()\n-// client, err := bigquery.NewClient(ctx, \"your-project-id\")\n-// [END bigquery_browse_table]\n-// [END bigquery_copy_table]\n-// [END bigquery_copy_table_multiple_source]\n-// [END bigquery_create_dataset]\n-// [END bigquery_create_table]\n-// [END bigquery_create_table_clustered]\n-// [END bigquery_create_table_partitioned]\n-// [END bigquery_delete_dataset]\n-// [END bigquery_delete_label_dataset]\n-// [END bigquery_delete_label_table]\n-// [END bigquery_delete_table]\n-// [END bigquery_extract_table]\n-// [END bigquery_extract_table_compressed]\n-// [END bigquery_extract_table_json]\n-// [END bigquery_get_dataset]\n-// [END bigquery_get_dataset_labels]\n-// [END bigquery_get_table]\n-// [END bigquery_get_table_labels]\n-// [END bigquery_label_dataset]\n-// [END bigquery_label_table]\n-// [END bigquery_list_datasets]\n-// [END bigquery_list_datasets_by_label]\n-// [END bigquery_list_jobs]\n-// [END bigquery_list_tables]\n-// [END bigquery_load_from_file]\n-// [END bigquery_load_table_clustered]\n-// [END bigquery_load_table_gcs_csv]\n-// [END bigquery_load_table_gcs_json]\n-// [END bigquery_load_table_gcs_json_autodetect]\n-// [END bigquery_load_table_partitioned]\n-// [END bigquery_query]\n-// [END bigquery_query_batch]\n-// [END bigquery_query_clustered_table]\n-// [END bigquery_query_destination_table]\n-// [END bigquery_query_dry_run]\n-// [END bigquery_query_legacy]\n-// [END bigquery_query_legacy_large_results]\n-// [END bigquery_query_no_cache]\n-// [END bigquery_query_params_arrays]\n-// [END bigquery_query_params_named]\n-// [END bigquery_query_params_positional]\n-// [END bigquery_query_params_structs]\n-// [END bigquery_query_params_timestamps]\n-// [END bigquery_query_partitioned_table]\n-// [END bigquery_table_insert_rows]\n-// [END bigquery_undelete_table]\n-// [END bigquery_update_dataset_access]\n-// [END bigquery_update_dataset_description]\n-// [END bigquery_update_dataset_expiration]\n-// [END bigquery_update_table_description]\n-// [END bigquery_update_table_expiration]\n+func noOpCommentFunc() {\n+\t// Use a common block to inline comments related to importing the library\n+\t// and constructing a client.  Inside a func to ensure the indentation is\n+\t// consistent between multiple includes.\n+\t// [START bigquery_add_empty_column]\n+\t// [START bigquery_add_column_query_append]\n+\t// [START bigquery_browse_table]\n+\t// [START bigquery_cancel_job]\n+\t// [START bigquery_copy_table]\n+\t// [START bigquery_copy_table_cmek]\n+\t// [START bigquery_copy_table_multiple_source]\n+\t// [START bigquery_create_dataset]\n+\t// [START bigquery_create_table]\n+\t// [START bigquery_create_table_clustered]\n+\t// [START bigquery_create_table_cmek]\n+\t// [START bigquery_create_table_partitioned]\n+\t// [START bigquery_delete_dataset]\n+\t// [START bigquery_delete_label_dataset]\n+\t// [START bigquery_delete_label_table]\n+\t// [START bigquery_delete_table]\n+\t// [START bigquery_extract_table]\n+\t// [START bigquery_extract_table_compressed]\n+\t// [START bigquery_extract_table_json]\n+\t// [START bigquery_get_dataset]\n+\t// [START bigquery_get_dataset_labels]\n+\t// [START bigquery_get_job]\n+\t// [START bigquery_get_table]\n+\t// [START bigquery_get_table_labels]\n+\t// [START bigquery_label_dataset]\n+\t// [START bigquery_label_table]\n+\t// [START bigquery_list_datasets]\n+\t// [START bigquery_list_datasets_by_label]\n+\t// [START bigquery_list_jobs]\n+\t// [START bigquery_list_tables]\n+\t// [START bigquery_load_from_file]\n+\t// [START bigquery_load_table_clustered]\n+\t// [START bigquery_load_table_gcs_csv]\n+\t// [START bigquery_load_table_gcs_json]\n+\t// [START bigquery_load_table_gcs_json_autodetect]\n+\t// [START bigquery_load_table_gcs_json_cmek]\n+\t// [START bigquery_load_table_gcs_orc]\n+\t// [START bigquery_load_table_gcs_orc_truncate]\n+\t// [START bigquery_load_table_gcs_parquet]\n+\t// [START bigquery_load_table_gcs_parquet_truncate]\n+\t// [START bigquery_load_table_partitioned]\n+\t// [START bigquery_nested_repeated_schema]\n+\t// [START bigquery_query]\n+\t// [START bigquery_query_batch]\n+\t// [START bigquery_query_clustered_table]\n+\t// [START bigquery_query_destination_table]\n+\t// [START bigquery_query_dry_run]\n+\t// [START bigquery_query_legacy]\n+\t// [START bigquery_query_legacy_large_results]\n+\t// [START bigquery_query_no_cache]\n+\t// [START bigquery_query_params_arrays]\n+\t// [START bigquery_query_params_named]\n+\t// [START bigquery_query_params_positional]\n+\t// [START bigquery_query_params_structs]\n+\t// [START bigquery_query_params_timestamps]\n+\t// [START bigquery_query_partitioned_table]\n+\t// [START bigquery_relax_column]\n+\t// [START bigquery_relax_column_load_append]\n+\t// [START bigquery_relax_column_query_append]\n+\t// [START bigquery_table_insert_rows]\n+\t// [START bigquery_undelete_table]\n+\t// [START bigquery_update_dataset_access]\n+\t// [START bigquery_update_dataset_description]\n+\t// [START bigquery_update_dataset_expiration]\n+\t// [START bigquery_update_table_cmek]\n+\t// [START bigquery_update_table_description]\n+\t// [START bigquery_update_table_expiration]\n+\t// To run this sample, you will need to create (or reuse) a context and\n+\t// an instance of the bigquery client.  For example:\n+\t// import \"cloud.google.com/go/bigquery\"\n+\t// ctx := context.Background()\n+\t// client, err := bigquery.NewClient(ctx, \"your-project-id\")\n+\t// [END bigquery_add_empty_column]\n+\t// [END bigquery_add_column_query_append]\n+\t// [END bigquery_browse_table]\n+\t// [END bigquery_cancel_job]\n+\t// [END bigquery_copy_table]\n+\t// [END bigquery_copy_table_cmek]\n+\t// [END bigquery_copy_table_multiple_source]\n+\t// [END bigquery_create_dataset]\n+\t// [END bigquery_create_table]\n+\t// [END bigquery_create_table_clustered]\n+\t// [END bigquery_create_table_cmek]\n+\t// [END bigquery_create_table_partitioned]\n+\t// [END bigquery_delete_dataset]\n+\t// [END bigquery_delete_label_dataset]\n+\t// [END bigquery_delete_label_table]\n+\t// [END bigquery_delete_table]\n+\t// [END bigquery_extract_table]\n+\t// [END bigquery_extract_table_compressed]\n+\t// [END bigquery_extract_table_json]\n+\t// [END bigquery_get_dataset]\n+\t// [END bigquery_get_dataset_labels]\n+\t// [END bigquery_get_job]\n+\t// [END bigquery_get_table]\n+\t// [END bigquery_get_table_labels]\n+\t// [END bigquery_label_dataset]\n+\t// [END bigquery_label_table]\n+\t// [END bigquery_list_datasets]\n+\t// [END bigquery_list_datasets_by_label]\n+\t// [END bigquery_list_jobs]\n+\t// [END bigquery_list_tables]\n+\t// [END bigquery_load_from_file]\n+\t// [END bigquery_load_table_clustered]\n+\t// [END bigquery_load_table_gcs_csv]\n+\t// [END bigquery_load_table_gcs_json]\n+\t// [END bigquery_load_table_gcs_json_autodetect]\n+\t// [END bigquery_load_table_gcs_json_cmek]\n+\t// [END bigquery_load_table_gcs_orc]\n+\t// [END bigquery_load_table_gcs_orc_truncate]\n+\t// [END bigquery_load_table_gcs_parquet]\n+\t// [END bigquery_load_table_gcs_parquet_truncate]\n+\t// [END bigquery_load_table_partitioned]\n+\t// [END bigquery_nested_repeated_schema]\n+\t// [END bigquery_query]\n+\t// [END bigquery_query_batch]\n+\t// [END bigquery_query_clustered_table]\n+\t// [END bigquery_query_destination_table]\n+\t// [END bigquery_query_dry_run]\n+\t// [END bigquery_query_legacy]\n+\t// [END bigquery_query_legacy_large_results]\n+\t// [END bigquery_query_no_cache]\n+\t// [END bigquery_query_params_arrays]\n+\t// [END bigquery_query_params_named]\n+\t// [END bigquery_query_params_positional]\n+\t// [END bigquery_query_params_structs]\n+\t// [END bigquery_query_params_timestamps]\n+\t// [END bigquery_query_partitioned_table]\n+\t// [END bigquery_relax_column]\n+\t// [END bigquery_relax_column_load_append]\n+\t// [END bigquery_relax_column_query_append]\n+\t// [END bigquery_table_insert_rows]\n+\t// [END bigquery_undelete_table]\n+\t// [END bigquery_update_dataset_access]\n+\t// [END bigquery_update_table_cmek]\n+\t// [END bigquery_update_dataset_description]\n+\t// [END bigquery_update_dataset_expiration]\n+\t// [END bigquery_update_table_description]\n+\t// [END bigquery_update_table_expiration]\n+}\n+\n+func cancelJob(client *bigquery.Client, jobID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_cancel_job]\n+\tjob, err := client.JobFromID(ctx, jobID)\n+\tif err != nil {\n+\t\treturn nil\n+\t}\n+\treturn job.Cancel(ctx)\n+\t// [END bigquery_cancel_job]\n+}\n \n func createDataset(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()",
        "comments": [
            {
                "comment": "\ud83d\udc4d on alphabetizing this.",
                "position": 117
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -407,6 +453,197 @@\nfunc createTableExplicitSchema(client *bigquery.Client, datasetID, tableID strin\n \treturn nil\n }\n \n+func createTableComplexSchema(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_nested_repeated_schema]\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"id\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"first_name\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"last_name\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"dob\", Type: bigquery.DateFieldType},\n+\t\t{Name: \"addresses\",\n+\t\t\tType:     bigquery.RecordFieldType,\n+\t\t\tRepeated: true,\n+\t\t\tSchema: bigquery.Schema{\n+\t\t\t\t{Name: \"status\", Type: bigquery.StringFieldType},\n+\t\t\t\t{Name: \"address\", Type: bigquery.StringFieldType},\n+\t\t\t\t{Name: \"city\", Type: bigquery.StringFieldType},\n+\t\t\t\t{Name: \"state\", Type: bigquery.StringFieldType},\n+\t\t\t\t{Name: \"zip\", Type: bigquery.StringFieldType},\n+\t\t\t\t{Name: \"numberOfYears\", Type: bigquery.StringFieldType},\n+\t\t\t}},\n+\t}\n+\n+\tmetaData := &bigquery.TableMetadata{\n+\t\tSchema: sampleSchema,\n+\t}\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, metaData); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Printf(\"created table %s\\n\", tableRef.FullyQualifiedName())\n+\t// [END bigquery_nested_repeated_schema]\n+\treturn nil\n+}\n+\n+func createTableWithCMEK(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_create_table_cmek]\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tmeta := &bigquery.TableMetadata{\n+\t\tEncryptionConfig: &bigquery.EncryptionConfig{\n+\t\t\t// TODO: Replace this key with a key you have created in Cloud KMS.\n+\t\t\tKMSKeyName: \"projects/cloud-samples-tests/locations/us-central1/keyRings/test/cryptoKeys/test\",\n+\t\t},\n+\t}\n+\tif err := tableRef.Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_create_table_cmek]\n+\treturn nil\n+}\n+\n+func relaxTableAPI(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"full_name\", Type: bigquery.StringFieldType, Required: true},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType, Required: true},\n+\t}\n+\toriginal := &bigquery.TableMetadata{\n+\t\tSchema: sampleSchema,\n+\t}\n+\tif err := client.Dataset(datasetID).Table(tableID).Create(ctx, original); err != nil {\n+\t\treturn err\n+\t}\n+\t// [START bigquery_relax_column]\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tableRef.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Iterate through the schema to set all Required fields to false (nullable).\n+\tvar relaxed bigquery.Schema\n+\tfor _, v := range meta.Schema {\n+\t\tv.Required = false\n+\t\trelaxed = append(relaxed, v)\n+\t}\n+\tnewMeta := bigquery.TableMetadataToUpdate{\n+\t\tSchema: relaxed,\n+\t}\n+\tif _, err := tableRef.Update(ctx, newMeta, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END  bigquery_relax_column]\n+\treturn nil\n+}\n+\n+func relaxTableImport(client *bigquery.Client, datasetID, tableID, filename string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_relax_column_load_append]\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"full_name\", Type: bigquery.StringFieldType, Required: true},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType, Required: true},\n+\t}\n+\tmeta := &bigquery.TableMetadata{\n+\t\tSchema: sampleSchema,\n+\t}\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\t// Now, import data from a local file, but specify relaxation of required\n+\t// fields as a side effect while the data is appended.\n+\tf, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tsource := bigquery.NewReaderSource(f)\n+\tsource.AutoDetect = true   // Allow BigQuery to determine schema.\n+\tsource.SkipLeadingRows = 1 // CSV has a single header line.\n+\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(source)\n+\tloader.SchemaUpdateOptions = []string{\"ALLOW_FIELD_RELAXATION\"}\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END  bigquery_relax_column_load_append]\n+\treturn nil\n+}\n+\n+func relaxTableQuery(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_relax_column_query_append]\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"full_name\", Type: bigquery.StringFieldType, Required: true},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType, Required: true},\n+\t}\n+\tmeta := &bigquery.TableMetadata{\n+\t\tSchema: sampleSchema,\n+\t}\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, meta); err != nil {\n+\t\treturn err\n+\t}\n+\t// Now, append a query result that includes nulls, but allow the job to relax\n+\t// all required columns.\n+\tq := client.Query(\"SELECT \\\"Beyonce\\\" as full_name\")\n+\tq.QueryConfig.Dst = client.Dataset(datasetID).Table(tableID)\n+\tq.SchemaUpdateOptions = []string{\"ALLOW_FIELD_RELAXATION\"}\n+\tq.WriteDisposition = bigquery.WriteAppend\n+\tq.Location = \"US\"\n+\tjob, err := q.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t_, err = job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_relax_column_query_append]\n+\treturn nil\n+}\n+\n+func createTableAndWiden(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_add_column_query_append]\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"full_name\", Type: bigquery.StringFieldType, Required: true},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType, Required: true},\n+\t}\n+\toriginal := &bigquery.TableMetadata{\n+\t\tSchema: sampleSchema,\n+\t}\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, original); err != nil {\n+\t\treturn err\n+\t}\n+\t// Our table has two columns.  We'll introduce a new favorite_color column via\n+\t// a subsequent query that appends to the table.\n+\tq := client.Query(\"SELECT \\\"Timmy\\\" as full_name, 85 as age, \\\"Blue\\\" as favorite_color\")\n+\tq.SchemaUpdateOptions = []string{\"ALLOW_FIELD_ADDITION\"}\n+\tq.QueryConfig.Dst = client.Dataset(datasetID).Table(tableID)\n+\tq.WriteDisposition = bigquery.WriteAppend\n+\tq.Location = \"US\"\n+\tjob, err := q.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t_, err = job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_add_column_query_append]\n+\treturn nil\n+}\n+\n func createTablePartitioned(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_create_table_partitioned]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -457,6 +694,48 @@\nfunc createTableClustered(client *bigquery.Client, datasetID, tableID string) er\n \treturn nil\n }\n \n+func updateTableAddColumn(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_add_empty_column]\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tableRef.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tnewSchema := append(meta.Schema,\n+\t\t&bigquery.FieldSchema{Name: \"phone\", Type: bigquery.StringFieldType},\n+\t)\n+\tupdate := bigquery.TableMetadataToUpdate{\n+\t\tSchema: newSchema,\n+\t}\n+\tif _, err := tableRef.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_add_empty_column]\n+\treturn nil\n+}\n+\n+func updateTableChangeCMEK(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_table_cmek]\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tableRef.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tupdate := bigquery.TableMetadataToUpdate{\n+\t\tEncryptionConfig: &bigquery.EncryptionConfig{\n+\t\t\t// TODO: Replace this key with a key you have created in Cloud KMS.\n+\t\t\tKMSKeyName: \"projects/cloud-samples-tests/locations/us-central1/keyRings/test/cryptoKeys/otherkey\",\n+\t\t},\n+\t}\n+\tif _, err := tableRef.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_table_cmek]\n+\treturn nil\n+}\n+\n func updateTableDescription(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_table_description]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -696,6 +975,21 @@\nfunc queryWithDestination(client *bigquery.Client, destDatasetID, destTableID st\n \treturn runAndRead(ctx, client, q)\n }\n \n+func queryWithDestinationCMEK(client *bigquery.Client, destDatasetID, destTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_destination_table_cmek]\n+\tq := client.Query(\"SELECT 17 as my_col\")\n+\tq.Location = \"US\" // Location must match the dataset(s) referenced in query.\n+\tq.QueryConfig.Dst = client.Dataset(destDatasetID).Table(destTableID)\n+\tq.DestinationEncryptionConfig = &bigquery.EncryptionConfig{\n+\t\t// TODO: Replace this key with a key you have created in Cloud KMS.\n+\t\tKMSKeyName: \"projects/cloud-samples-tests/locations/us-central1/keyRings/test/cryptoKeys/test\",\n+\t}\n+\treturn runAndRead(ctx, client, q)\n+\t// [END bigquery_query_destination_table_cmek]\n+\n+}\n+\n func queryLegacy(client *bigquery.Client, sqlString string) error {\n \tctx := context.Background()\n \t// [START bigquery_query_legacy]",
        "comments": [],
        "commit_messages": [
            "BigQuery: CMEK (create / update / query)"
        ],
        "last_commit_sha": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -913,6 +1207,30 @@\nfunc copyTable(client *bigquery.Client, datasetID, srcID, dstID string) error {\n \treturn nil\n }\n \n+func copyTableWithCMEK(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_copy_table_cmek]\n+\tsrcTable := client.DatasetInProject(\"bigquery-public-data\", \"samples\").Table(\"shakespeare\")\n+\tcopier := client.Dataset(datasetID).Table(tableID).CopierFrom(srcTable)\n+\tcopier.DestinationEncryptionConfig = &bigquery.EncryptionConfig{\n+\t\t// TODO: Replace this key with a key you have created in Cloud KMS.\n+\t\tKMSKeyName: \"projects/cloud-samples-tests/locations/us-central1/keyRings/test/cryptoKeys/test\",\n+\t}\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_copy_table_cmek]\n+\treturn nil\n+}\n+\n // generateTableCTAS creates a quick table by issuing a CREATE TABLE AS SELECT\n // query.\n func generateTableCTAS(client *bigquery.Client, datasetID, tableID string) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1027,6 +1345,30 @@\nfunc deleteAndUndeleteTable(client *bigquery.Client, datasetID, tableID string)\n \n }\n \n+func getJobInfo(client *bigquery.Client, jobID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_job]\n+\tjob, err := client.JobFromID(ctx, jobID)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tstatus := job.LastStatus()\n+\tstate := \"Unknown\"\n+\tswitch status.State {\n+\tcase bigquery.Pending:\n+\t\tstate = \"Pending\"\n+\tcase bigquery.Running:\n+\t\tstate = \"Running\"\n+\tcase bigquery.Done:\n+\t\tstate = \"Done\"\n+\t}\n+\tfmt.Printf(\"Job %s was created %v and is in state %s\\n\",\n+\t\tjobID, status.Statistics.CreationTime, state)\n+\t// [END bigquery_get_job]\n+\treturn nil\n+}\n+\n func importCSVFromFile(client *bigquery.Client, datasetID, tableID, filename string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_from_file]",
        "comments": [],
        "commit_messages": [
            "BigQuery: job metadata fetch, job cancel"
        ],
        "last_commit_sha": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1136,6 +1478,134 @@\nfunc importJSONAutodetectSchema(client *bigquery.Client, datasetID, tableID stri\n \treturn nil\n }\n \n+func importJSONWithCMEK(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_json_cmek]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.json\")\n+\tgcsRef.SourceFormat = bigquery.JSON\n+\tgcsRef.AutoDetect = true\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\tloader.WriteDisposition = bigquery.WriteEmpty\n+\tloader.DestinationEncryptionConfig = &bigquery.EncryptionConfig{\n+\t\t// TODO: Replace this key with a key you have created in KMS.\n+\t\tKMSKeyName: \"projects/cloud-samples-tests/locations/us-central1/keyRings/test/cryptoKeys/test\",\n+\t}\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\n+\t// [END bigquery_load_table_gcs_json_cmek]\n+\treturn nil\n+}\n+\n+func importORC(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_orc]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.orc\")\n+\tgcsRef.SourceFormat = bigquery.ORC\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_orc]\n+\treturn nil\n+}\n+\n+func importORCTruncate(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_orc_truncate]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.orc\")\n+\tgcsRef.SourceFormat = bigquery.ORC\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\t// Default for import jobs is to append data to a table.  WriteTruncate\n+\t// specifies that existing data should instead be replaced/overwritten.\n+\tloader.WriteDisposition = bigquery.WriteTruncate\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_orc_truncate]\n+\treturn nil\n+}\n+\n+func importParquet(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_parquet]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.parquet\")\n+\tgcsRef.SourceFormat = bigquery.Parquet\n+\tgcsRef.AutoDetect = true\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_parquet]\n+\treturn nil\n+}\n+\n+func importParquetTruncate(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_parquet_truncate]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.parquet\")\n+\tgcsRef.SourceFormat = bigquery.Parquet\n+\tgcsRef.AutoDetect = true\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\tloader.WriteDisposition = bigquery.WriteTruncate\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_parquet_truncate]\n+\treturn nil\n+}\n+\n func importPartitionedSampleTable(client *bigquery.Client, destDatasetID, destTableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_table_partitioned]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1304,6 +1774,7 @@\nfunc exportSampleTableAsJSON(client *bigquery.Client, gcsURI string) error {\n func runAndRead(ctx context.Context, client *bigquery.Client, q *bigquery.Query) error {\n \t// [START bigquery_query]\n \t// [START bigquery_query_destination_table]\n+\t// [START bigquery_query_destination_table_cmek]\n \t// [START bigquery_query_legacy]\n \t// [START bigquery_query_legacy_large_results]\n \t// [START bigquery_query_no_cache]",
        "comments": [],
        "commit_messages": [
            "BigQuery: CMEK (create / update / query)"
        ],
        "last_commit_sha": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -118,13 +118,35 @@\nfunc TestAll(t *testing.T) {\n \tif err := createTableExplicitSchema(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"createTableExplicitSchema(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n+\tcomplex := uniqueBQName(\"golang_example_table_complex\")\n+\tif err := createTableComplexSchema(client, datasetID, complex); err != nil {\n+\t\tt.Errorf(\"createTableComplexSchema(dataset:%q table:%q): %v\", datasetID, complex, err)\n+\t}\n+\n+\ttableCMEK := uniqueBQName(\"golang_example_table_cmek\")\n+\tif err := createTableWithCMEK(client, datasetID, tableCMEK); err != nil {\n+\t\tt.Errorf(\"createTableWithCMEK(dataset:%q table:%q): %v\", datasetID, tableCMEK, err)\n+\t}\n+\n+\trequired := uniqueBQName(\"golang_example_table_required\")\n+\tif err := relaxTableAPI(client, datasetID, required); err != nil {\n+\t\tt.Errorf(\"relaxTableApi(dataset:%q table:%q): %v\", datasetID, required, err)\n+\t}\n+\n+\twiden := uniqueBQName(\"golang_example_table_widen\")\n+\tif err := createTableAndWiden(client, datasetID, widen); err != nil {\n+\t\tt.Errorf(\"createTableAndWiden(dataset:%q table:%q): %v\", datasetID, widen, err)\n+\t}\n \n \tif err := updateTableDescription(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"updateTableDescription(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n \tif err := updateTableExpiration(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"updateTableExpiration(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n+\tif err := updateTableAddColumn(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"updateTableAddColumn(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\t}\n \tif err := addTableLabel(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"updateTableAddLabel(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -198,6 +220,23 @@\nfunc TestAll(t *testing.T) {\n \tif err := queryWithDestination(client, datasetID, persisted); err != nil {\n \t\tt.Errorf(\"queryWithDestination(dataset:%q table:%q): %v\", datasetID, persisted, err)\n \t}\n+\tpersistedCMEK := uniqueBQName(\"golang_example_table_queryresult_cmek\")\n+\tif err := queryWithDestinationCMEK(client, datasetID, persistedCMEK); err != nil {\n+\t\tt.Errorf(\"queryWithDestinationCMEK(dataset:%q table:%q): %v\", datasetID, persistedCMEK, err)\n+\t}\n+\n+\t// Control a job lifecycle explicitly: create, report status, cancel.\n+\texampleJobID := uniqueBQName(\"golang_example_job\")\n+\tq := client.Query(\"Select 17 as foo\")\n+\tq.JobID = exampleJobID\n+\tq.Priority = bigquery.BatchPriority\n+\tq.Run(ctx)\n+\tif err := getJobInfo(client, exampleJobID); err != nil {\n+\t\tt.Errorf(\"getJobInfo(%s): %v\", exampleJobID, err)\n+\t}\n+\tif err := cancelJob(client, exampleJobID); err != nil {\n+\t\tt.Errorf(\"cancelJobInfo(%s): %v\", exampleJobID, err)\n+\t}\n \n \t// Print information about tables (extended and simple).\n \tif err := printTableInfo(client, datasetID, inferred); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "BigQuery: many new samples",
        "pr_number": 562,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -222,6 +261,10 @@\nfunc TestAll(t *testing.T) {\n \tif err := copyMultiTable(client, datasetID, dstTableID); err != nil {\n \t\tt.Errorf(\"copyMultiTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n \t}\n+\tdstTableID = uniqueBQName(\"golang_example_copycmek\")\n+\tif err := copyTableWithCMEK(client, datasetID, dstTableID); err != nil {\n+\t\tt.Errorf(\"copyTableWithCMEK(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n+\t}\n \n \tif err := listJobs(client); err != nil {\n \t\tt.Errorf(\"listJobs: %v\", err)",
        "comments": [],
        "commit_messages": [
            "BigQuery: copy with CMEK"
        ],
        "last_commit_sha": "cb2a1cda744cee2ace85f224a65fb31ed63a5314"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/analytics/analytics.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_analytics_track_event]\n+\n // Sample analytics demonstrates Google Analytics calls from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/cloudsql/cloudsql.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_mysql_app]\n+\n // Sample cloudsql demonstrates usage of Cloud SQL from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/cloudsql_postgres/cloudsql.go",
        "code_diff": "@@ -4,6 +4,8 @@\n// +build go1.8\n \n+// [START gae_flex_postgres_app]\n+\n // Sample cloudsql demonstrates usage of Cloud SQL from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/datastore/datastore.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_datastore_app]\n+\n // Sample datastore demonstrates use of the cloud.google.com/go/datastore package from App Engine flexible.\n package main",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/mailgun/mailgun.go",
        "code_diff": "@@ -16,11 +16,8 @@\nimport (\n \t\"google.golang.org/appengine\"\n )\n \n-// [START import]\n import \"github.com/mailgun/mailgun-go\"\n \n-// [END import]\n-\n func main() {\n \thttp.HandleFunc(\"/send_simple\", sendSimpleMessageHandler)\n \thttp.HandleFunc(\"/send_complex\", sendComplexMessageHandler)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/mailgun/mailgun.go",
        "code_diff": "@@ -49,6 +46,7 @@\nfunc mustGetenv(k string) string {\n \treturn v\n }\n \n+// [START gae_flex_mailgun_simple_message]\n func sendSimpleMessageHandler(w http.ResponseWriter, r *http.Request) {\n \tmsg, id, err := mailgunClient.Send(mailgunClient.NewMessage(\n \t\t/* From */ fmt.Sprintf(\"Excited User <mailgun@%s>\", mailgunDomain),",
        "comments": [],
        "commit_messages": [
            "mailgun, memcache, redis"
        ],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/mailgun/mailgun.go",
        "code_diff": "@@ -65,6 +63,9 @@\nfunc sendSimpleMessageHandler(w http.ResponseWriter, r *http.Request) {\n \tw.Write([]byte(\"Message sent!\"))\n }\n \n+// [END gae_flex_mailgun_simple_message]\n+\n+// [START gae_flex_mailgun_complex_message]\n func sendComplexMessageHandler(w http.ResponseWriter, r *http.Request) {\n \tmessage := mailgunClient.NewMessage(\n \t\t/* From */ fmt.Sprintf(\"Excited User <mailgun@%s>\", mailgunDomain),",
        "comments": [],
        "commit_messages": [
            "mailgun, memcache, redis"
        ],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/mailjet/mailjet.go",
        "code_diff": "@@ -14,10 +14,10 @@\nimport (\n \t\"google.golang.org/appengine\"\n )\n \n-// [START import]\n+// [START gae_flex_mailjet_config]\n import \"github.com/mailjet/mailjet-apiv3-go\"\n \n-// [END import]\n+// [END gae_flex_mailjet_config]\n \n func main() {\n \thttp.HandleFunc(\"/send\", sendEmail)",
        "comments": [],
        "commit_messages": [
            "mailjet, sendgrid"
        ],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/mailjet/mailjet.go",
        "code_diff": "@@ -42,6 +42,7 @@\nfunc mustGetenv(k string) string {\n \treturn v\n }\n \n+// [START gae_flex_mailjet_send_email]\n func sendEmail(w http.ResponseWriter, r *http.Request) {\n \tto := r.FormValue(\"to\")\n \tif to == \"\" {",
        "comments": [],
        "commit_messages": [
            "mailjet, sendgrid"
        ],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/memcache/memcache.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_redislabs_memcache]\n+\n // Sample memcache demonstrates use of a memcached client from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/redis/redis.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_golang_redis]\n+\n // Sample redis demonstrates use of a redis client from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/sendgrid/sendgrid.go",
        "code_diff": "@@ -14,10 +14,10 @@\nimport (\n \t\"google.golang.org/appengine\"\n )\n \n-// [START import]\n+// [START gae_flex_sendgrid_import]\n import \"gopkg.in/sendgrid/sendgrid-go.v2\"\n \n-// [END import]\n+// [END gae_flex_sendgrid_import]\n \n func main() {\n \thttp.HandleFunc(\"/sendmail\", sendMailHandler)",
        "comments": [],
        "commit_messages": [
            "mailjet, sendgrid"
        ],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/sendgrid/sendgrid.go",
        "code_diff": "@@ -35,6 +35,7 @@\nfunc init() {\n \tsendgridClient = sendgrid.NewSendGridClientWithApiKey(sendgridKey)\n }\n \n+// [START gae_flex_sendgrid]\n func sendMailHandler(w http.ResponseWriter, r *http.Request) {\n \tm := sendgrid.NewMail()\n \tm.AddTo(\"example@email.com\")",
        "comments": [],
        "commit_messages": [
            "mailjet, sendgrid"
        ],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/static_files/staticfiles.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_golang_static_files]\n+\n // Package static demonstrates a static file handler for App Engine flexible environment.\n package main",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "appengine_flexible/storage/storage.go",
        "code_diff": "@@ -2,6 +2,8 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n+// [START gae_flex_storage_app]\n+\n // Sample storage demonstrates use of the cloud.google.com/go/storage package from App Engine flexible environment.\n package main",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "docs/appengine/requests/helloworld.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START requests_and_HTTP]\n+// [START gae_golang_request_example]\n package hello\n \n import (",
        "comments": [],
        "commit_messages": [
            "region tags: request/logging example"
        ],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "update Region tags",
        "pr_number": 557,
        "file_name": "docs/appengine/requests/logging.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START logging]\n+// [START gae_golang_logging_example]\n package hello\n \n import (",
        "comments": [],
        "commit_messages": [
            "region tags: request/logging example"
        ],
        "last_commit_sha": "0567b382ac8bd695e07b8563243feb1c6ab31e8a"
    },
    {
        "pr_title": "BigQuery: snippets for partitioning and clustering.",
        "pr_number": 553,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -16,6 +16,116 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n+// Use a common block to inline comments related to importing the library\n+// and constructing a client.\n+// [START bigquery_browse_table]\n+// [START bigquery_copy_table]\n+// [START bigquery_copy_table_multiple_source]\n+// [START bigquery_create_dataset]\n+// [START bigquery_create_table]\n+// [START bigquery_create_table_clustered]\n+// [START bigquery_create_table_partitioned]\n+// [START bigquery_delete_dataset]\n+// [START bigquery_delete_label_dataset]\n+// [START bigquery_delete_label_table]\n+// [START bigquery_delete_table]\n+// [START bigquery_extract_table]\n+// [START bigquery_extract_table_compressed]\n+// [START bigquery_extract_table_json]\n+// [START bigquery_get_dataset]\n+// [START bigquery_get_dataset_labels]\n+// [START bigquery_get_table]\n+// [START bigquery_get_table_labels]\n+// [START bigquery_label_dataset]\n+// [START bigquery_label_table]\n+// [START bigquery_list_datasets]\n+// [START bigquery_list_datasets_by_label]\n+// [START bigquery_list_jobs]\n+// [START bigquery_list_tables]\n+// [START bigquery_load_from_file]\n+// [START bigquery_load_table_clustered]\n+// [START bigquery_load_table_gcs_csv]\n+// [START bigquery_load_table_gcs_json]\n+// [START bigquery_load_table_gcs_json_autodetect]\n+// [START bigquery_load_table_partitioned]\n+// [START bigquery_query]\n+// [START bigquery_query_batch]\n+// [START bigquery_query_clustered_table]\n+// [START bigquery_query_destination_table]\n+// [START bigquery_query_dry_run]\n+// [START bigquery_query_legacy]\n+// [START bigquery_query_legacy_large_results]\n+// [START bigquery_query_no_cache]\n+// [START bigquery_query_params_arrays]\n+// [START bigquery_query_params_named]\n+// [START bigquery_query_params_positional]\n+// [START bigquery_query_params_structs]\n+// [START bigquery_query_params_timestamps]\n+// [START bigquery_query_partitioned_table]\n+// [START bigquery_table_insert_rows]\n+// [START bigquery_undelete_table]\n+// [START bigquery_update_dataset_access]\n+// [START bigquery_update_dataset_description]\n+// [START bigquery_update_dataset_expiration]\n+// [START bigquery_update_table_description]\n+// [START bigquery_update_table_expiration]\n+// To run this sample, you will need to create (or reuse) a context and\n+// an instance of the bigquery client.  For example:\n+// import \"cloud.google.com/go/bigquery\"\n+// ctx := context.Background()\n+// client, err := bigquery.NewClient(ctx, \"your-project-id\")\n+// [END bigquery_browse_table]\n+// [END bigquery_copy_table]\n+// [END bigquery_copy_table_multiple_source]\n+// [END bigquery_create_dataset]\n+// [END bigquery_create_table]\n+// [END bigquery_create_table_clustered]\n+// [END bigquery_create_table_partitioned]\n+// [END bigquery_delete_dataset]\n+// [END bigquery_delete_label_dataset]\n+// [END bigquery_delete_label_table]\n+// [END bigquery_delete_table]\n+// [END bigquery_extract_table]\n+// [END bigquery_extract_table_compressed]\n+// [END bigquery_extract_table_json]\n+// [END bigquery_get_dataset]\n+// [END bigquery_get_dataset_labels]\n+// [END bigquery_get_table]\n+// [END bigquery_get_table_labels]\n+// [END bigquery_label_dataset]\n+// [END bigquery_label_table]\n+// [END bigquery_list_datasets]\n+// [END bigquery_list_datasets_by_label]\n+// [END bigquery_list_jobs]\n+// [END bigquery_list_tables]\n+// [END bigquery_load_from_file]\n+// [END bigquery_load_table_clustered]\n+// [END bigquery_load_table_gcs_csv]\n+// [END bigquery_load_table_gcs_json]\n+// [END bigquery_load_table_gcs_json_autodetect]\n+// [END bigquery_load_table_partitioned]\n+// [END bigquery_query]\n+// [END bigquery_query_batch]\n+// [END bigquery_query_clustered_table]\n+// [END bigquery_query_destination_table]\n+// [END bigquery_query_dry_run]\n+// [END bigquery_query_legacy]\n+// [END bigquery_query_legacy_large_results]\n+// [END bigquery_query_no_cache]\n+// [END bigquery_query_params_arrays]\n+// [END bigquery_query_params_named]\n+// [END bigquery_query_params_positional]\n+// [END bigquery_query_params_structs]\n+// [END bigquery_query_params_timestamps]\n+// [END bigquery_query_partitioned_table]\n+// [END bigquery_table_insert_rows]\n+// [END bigquery_undelete_table]\n+// [END bigquery_update_dataset_access]\n+// [END bigquery_update_dataset_description]\n+// [END bigquery_update_dataset_expiration]\n+// [END bigquery_update_table_description]\n+// [END bigquery_update_table_expiration]\n+\n func createDataset(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_create_dataset]",
        "comments": [
            {
                "comment": "This is the norm for the other snippets, but any particular reason to leave the `ctx` line out of the snippet?",
                "position": 123
            },
            {
                "comment": "The decision predates me, but context construction feels very similar to the client creation. I'll add a comment to the shared include block to demonstrate background context creation as well as client creation.",
                "position": 123
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "b76562f688074064ce858b227efb815a6de9f30f"
    },
    {
        "pr_title": "BigQuery: snippets for partitioning and clustering.",
        "pr_number": 553,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -297,6 +407,56 @@\nfunc createTableExplicitSchema(client *bigquery.Client, datasetID, tableID strin\n \treturn nil\n }\n \n+func createTablePartitioned(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_create_table_partitioned]\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"name\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"post_abbr\", Type: bigquery.IntegerFieldType},\n+\t\t{Name: \"date\", Type: bigquery.DateFieldType},\n+\t}\n+\tmetadata := &bigquery.TableMetadata{\n+\t\tTimePartitioning: &bigquery.TimePartitioning{\n+\t\t\tField:      \"date\",\n+\t\t\tExpiration: 90 * 24 * time.Hour,\n+\t\t},\n+\t\tSchema: sampleSchema,\n+\t}\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, metadata); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_create_table_partitioned]\n+\treturn nil\n+}\n+\n+func createTableClustered(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_create_table_clustered]\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"timestamp\", Type: bigquery.TimestampFieldType},\n+\t\t{Name: \"origin\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"destination\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"amount\", Type: bigquery.NumericFieldType},\n+\t}\n+\tmetaData := &bigquery.TableMetadata{\n+\t\tSchema: sampleSchema,\n+\t\tTimePartitioning: &bigquery.TimePartitioning{\n+\t\t\tField:      \"timestamp\",\n+\t\t\tExpiration: 90 * 24 * time.Hour,\n+\t\t},\n+\t\tClustering: &bigquery.Clustering{\n+\t\t\tFields: []string{\"origin\", \"destination\"},\n+\t\t},\n+\t}\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, metaData); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_create_table_partitioned]\n+\treturn nil\n+}\n+\n func updateTableDescription(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_table_description]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b76562f688074064ce858b227efb815a6de9f30f"
    },
    {
        "pr_title": "BigQuery: snippets for partitioning and clustering.",
        "pr_number": 553,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -666,6 +826,37 @@\nfunc queryWithStructParam(client *bigquery.Client) error {\n \treturn runAndRead(ctx, client, q)\n }\n \n+func queryPartitionedTable(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_partitioned_table]\n+\tq := client.Query(fmt.Sprintf(\"SELECT * FROM `%s.%s` WHERE `date` BETWEEN DATE('1800-01-01') AND DATE('1899-12-31')\", datasetID, tableID))\n+\t// [END bigquery_query_partitioned_table]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryClusteredTable(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_clustered_table]\n+\tq := client.Query(fmt.Sprintf(`\n+\tSELECT\n+\t  COUNT(1) as transactions,\n+\t  SUM(amount) as total_paid,\n+\t  COUNT(DISTINCT destination) as distinct_recipients\n+    FROM\n+\t  `+\"`%s.%s`\"+`\n+\t WHERE\n+\t    timestamp > TIMESTAMP('2015-01-01')\n+\t\tAND origin = @wallet`, datasetID, tableID))\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"wallet\",\n+\t\t\tValue: \"wallet00001866cb7e0f09a890\",\n+\t\t},\n+\t}\n+\t// [END bigquery_query_clustered_table]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n func printTableInfo(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_table]",
        "comments": [],
        "commit_messages": [
            "BigQuery: add partition and clustering snippets."
        ],
        "last_commit_sha": "b76562f688074064ce858b227efb815a6de9f30f"
    },
    {
        "pr_title": "BigQuery: snippets for partitioning and clustering.",
        "pr_number": 553,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -945,6 +1136,75 @@\nfunc importJSONAutodetectSchema(client *bigquery.Client, datasetID, tableID stri\n \treturn nil\n }\n \n+func importPartitionedSampleTable(client *bigquery.Client, destDatasetID, destTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_partitioned]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states-by-date.csv\")\n+\tgcsRef.SkipLeadingRows = 1\n+\tgcsRef.Schema = bigquery.Schema{\n+\t\t{Name: \"name\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"post_abbr\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"date\", Type: bigquery.DateFieldType},\n+\t}\n+\tloader := client.Dataset(destDatasetID).Table(destTableID).LoaderFrom(gcsRef)\n+\tloader.TimePartitioning = &bigquery.TimePartitioning{\n+\t\tField:      \"date\",\n+\t\tExpiration: 90 * 24 * time.Hour,\n+\t}\n+\tloader.WriteDisposition = bigquery.WriteEmpty\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_partitioned]\n+\treturn nil\n+}\n+\n+func importClusteredSampleTable(client *bigquery.Client, destDatasetID, destTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_clustered]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/sample-transactions/transactions.csv\")\n+\tgcsRef.SkipLeadingRows = 1\n+\tgcsRef.Schema = bigquery.Schema{\n+\t\t{Name: \"timestamp\", Type: bigquery.TimestampFieldType},\n+\t\t{Name: \"origin\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"destination\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"amount\", Type: bigquery.NumericFieldType},\n+\t}\n+\tloader := client.Dataset(destDatasetID).Table(destTableID).LoaderFrom(gcsRef)\n+\tloader.TimePartitioning = &bigquery.TimePartitioning{\n+\t\tField: \"timestamp\",\n+\t}\n+\tloader.Clustering = &bigquery.Clustering{\n+\t\tFields: []string{\"origin\", \"destination\"},\n+\t}\n+\tloader.WriteDisposition = bigquery.WriteEmpty\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_clustered]\n+\treturn nil\n+}\n+\n func exportSampleTableAsCSV(client *bigquery.Client, gcsURI string) error {\n \tctx := context.Background()\n \t// [START bigquery_extract_table]",
        "comments": [],
        "commit_messages": [
            "BigQuery: add partition and clustering snippets."
        ],
        "last_commit_sha": "b76562f688074064ce858b227efb815a6de9f30f"
    },
    {
        "pr_title": "BigQuery: snippets for partitioning and clustering.",
        "pr_number": 553,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -1052,6 +1312,8 @@\nfunc runAndRead(ctx context.Context, client *bigquery.Client, q *bigquery.Query)\n \t// [START bigquery_query_params_positional]\n \t// [START bigquery_query_params_timestamps]\n \t// [START bigquery_query_params_structs]\n+\t// [START bigquery_query_partitioned_table]\n+\t// [START bigquery_query_clustered_table]\n \tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [
            "BigQuery: add partition and clustering snippets."
        ],
        "last_commit_sha": "b76562f688074064ce858b227efb815a6de9f30f"
    },
    {
        "pr_title": "monitoring/uptime: add update sample",
        "pr_number": 547,
        "file_name": "monitoring/uptime/uptime.go",
        "code_diff": "@@ -1,4 +1,4 @@\n-// Copyright 2017 Google Inc. All rights reserved.\n+// Copyright 2018 Google Inc. All rights reserved.\n // Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.",
        "comments": [],
        "commit_messages": [
            "monitoring/uptime: return configs and errors\n\nThis also standardizes variable naming for configs (to `config`)."
        ],
        "last_commit_sha": "6e780460158d21afb673c90ab816411ddc5a1573"
    },
    {
        "pr_title": "monitoring/uptime: add update sample",
        "pr_number": 547,
        "file_name": "monitoring/uptime/uptime.go",
        "code_diff": "@@ -8,24 +8,24 @@\npackage uptime\n import (\n \t\"fmt\"\n \t\"io\"\n-\t\"log\"\n \n \tmonitoring \"cloud.google.com/go/monitoring/apiv3\"\n \t\"github.com/golang/protobuf/ptypes/duration\"\n \t\"golang.org/x/net/context\"\n \t\"google.golang.org/api/iterator\"\n \t\"google.golang.org/genproto/googleapis/api/monitoredres\"\n \tmonitoringpb \"google.golang.org/genproto/googleapis/monitoring/v3\"\n+\t\"google.golang.org/genproto/protobuf/field_mask\"\n )\n \n // [START monitoring_uptime_check_create]\n \n // create creates an example uptime check.\n-func create(w io.Writer, projectID string) {\n+func create(w io.Writer, projectID string) (*monitoringpb.UptimeCheckConfig, error) {\n \tctx := context.Background()\n \tclient, err := monitoring.NewUptimeCheckClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\treturn nil, fmt.Errorf(\"NewUptimeCheckClient: %v\", err)\n \t}\n \tdefer client.Close()\n \treq := &monitoringpb.CreateUptimeCheckConfigRequest{",
        "comments": [
            {
                "comment": "\ud83d\udc4d ",
                "position": 30
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "6e780460158d21afb673c90ab816411ddc5a1573"
    },
    {
        "pr_title": "monitoring/uptime: add update sample",
        "pr_number": 547,
        "file_name": "monitoring/uptime/uptime.go",
        "code_diff": "@@ -50,23 +50,24 @@\nfunc create(w io.Writer, projectID string) {\n \t\t\tPeriod:  &duration.Duration{Seconds: 300},\n \t\t},\n \t}\n-\tuc, err := client.CreateUptimeCheckConfig(ctx, req)\n+\tconfig, err := client.CreateUptimeCheckConfig(ctx, req)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\treturn nil, fmt.Errorf(\"CreateUptimeCheckConfig: %v\", err)\n \t}\n-\tfmt.Fprintf(w, \"Successfully created uptime check %q\\n\", uc.GetDisplayName())\n+\tfmt.Fprintf(w, \"Successfully created uptime check %q\\n\", config.GetDisplayName())\n+\treturn config, nil\n }\n \n // [END monitoring_uptime_check_create]\n \n // [START monitoring_uptime_check_list_configs]\n \n // list is an example of listing the uptime checks in projectID.\n-func list(w io.Writer, projectID string) {\n+func list(w io.Writer, projectID string) error {\n \tctx := context.Background()\n \tclient, err := monitoring.NewUptimeCheckClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\treturn fmt.Errorf(\"NewUptimeCheckClient: %v\", err)\n \t}\n \tdefer client.Close()\n \treq := &monitoringpb.ListUptimeCheckConfigsRequest{",
        "comments": [],
        "commit_messages": [
            "monitoring/uptime: return configs and errors\n\nThis also standardizes variable naming for configs (to `config`)."
        ],
        "last_commit_sha": "6e780460158d21afb673c90ab816411ddc5a1573"
    },
    {
        "pr_title": "monitoring/uptime: add update sample",
        "pr_number": 547,
        "file_name": "monitoring/uptime/uptime.go",
        "code_diff": "@@ -79,23 +80,24 @@\nfunc list(w io.Writer, projectID string) {\n \t\t\tbreak\n \t\t}\n \t\tif err != nil {\n-\t\t\tlog.Fatalf(\"Error getting uptime checks: %v\", err)\n+\t\t\treturn fmt.Errorf(\"ListUptimeCheckConfigs: %v\", err)\n \t\t}\n \t\tfmt.Fprintln(w, config)\n \t}\n \tfmt.Fprintln(w, \"Done listing uptime checks\")\n+\treturn nil\n }\n \n // [END monitoring_uptime_check_list_configs]\n \n // [START monitoring_uptime_check_list_ips]\n \n // listIPs is an example of listing uptime check IPs.\n-func listIPs(w io.Writer) {\n+func listIPs(w io.Writer) error {\n \tctx := context.Background()\n \tclient, err := monitoring.NewUptimeCheckClient(ctx)\n \tif err != nil {\n-\t\tlog.Fatal(err)\n+\t\treturn fmt.Errorf(\"NewUptimeCheckClient: %v\", err)\n \t}\n \tdefer client.Close()\n \treq := &monitoringpb.ListUptimeCheckIpsRequest{}",
        "comments": [],
        "commit_messages": [
            "monitoring/uptime: return configs and errors\n\nThis also standardizes variable naming for configs (to `config`)."
        ],
        "last_commit_sha": "6e780460158d21afb673c90ab816411ddc5a1573"
    },
    {
        "pr_title": "monitoring/uptime: add update sample",
        "pr_number": 547,
        "file_name": "monitoring/uptime/uptime.go",
        "code_diff": "@@ -106,11 +108,12 @@\nfunc listIPs(w io.Writer) {\n \t\t\tbreak\n \t\t}\n \t\tif err != nil {\n-\t\t\tlog.Fatalf(\"Error getting uptime checks: %v\", err)\n+\t\t\treturn fmt.Errorf(\"ListUptimeCheckIps: %v\", err)\n \t\t}\n \t\tfmt.Fprintln(w, config)\n \t}\n \tfmt.Fprintln(w, \"Done listing uptime check IPs\")\n+\treturn nil\n }\n \n // [END monitoring_uptime_check_list_ips]",
        "comments": [],
        "commit_messages": [
            "monitoring/uptime: return configs and errors\n\nThis also standardizes variable naming for configs (to `config`)."
        ],
        "last_commit_sha": "6e780460158d21afb673c90ab816411ddc5a1573"
    },
    {
        "pr_title": "monitoring/uptime: add update sample",
        "pr_number": 547,
        "file_name": "monitoring/uptime/uptime_test.go",
        "code_diff": "@@ -1,37 +1,38 @@\n-// Copyright 2017 Google Inc. All rights reserved.\n+// Copyright 2018 Google Inc. All rights reserved.\n // Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n package uptime\n \n import (\n \t\"bytes\"\n-\t\"log\"\n+\t\"io/ioutil\"\n \t\"strings\"\n \t\"testing\"\n \n-\tmonitoring \"cloud.google.com/go/monitoring/apiv3\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n-\t\"github.com/golang/protobuf/ptypes/duration\"\n-\t\"golang.org/x/net/context\"\n-\t\"google.golang.org/genproto/googleapis/api/monitoredres\"\n-\tmonitoringpb \"google.golang.org/genproto/googleapis/monitoring/v3\"\n )\n \n func TestCreate(t *testing.T) {\n \tc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)\n-\tcreate(buf, c.ProjectID)\n+\tconfig, err := create(buf, c.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"create: %v\", err)\n+\t}\n \twant := \"Successfully\"\n \tif got := buf.String(); !strings.Contains(got, want) {\n \t\tt.Errorf(\"%q not found in output: %q\", want, got)\n \t}\n+\tdelete(ioutil.Discard, config.GetName())\n }\n \n func TestList(t *testing.T) {\n \tc := testutil.SystemTest(t)\n \tbuf := new(bytes.Buffer)\n-\tlist(buf, c.ProjectID)\n+\tif err := list(buf, c.ProjectID); err != nil {\n+\t\tt.Fatalf(\"list: %v\", err)\n+\t}\n \twant := \"Done\"\n \tif got := buf.String(); !strings.Contains(got, want) {\n \t\tt.Errorf(\"%q not found in output: %q\", want, got)",
        "comments": [
            {
                "comment": "It looks like TestList could run after TestCreate and be affected by created monitors, in that case, some logging aimed at troubleshooting support in the event delete fails might be helpful.",
                "position": 35
            },
            {
                "comment": "`TestList` should work no matter how many monitors there are. This is more of a best-effort delete -- OK if it doesn't work. Does that make sense?",
                "position": 35
            },
            {
                "comment": "\ud83d\udc4d ",
                "position": 35
            }
        ],
        "commit_messages": [
            "monitoring/uptime: return configs and errors\n\nThis also standardizes variable naming for configs (to `config`)."
        ],
        "last_commit_sha": "6e780460158d21afb673c90ab816411ddc5a1573"
    },
    {
        "pr_title": "profiler: Add flags to configure version and function skew",
        "pr_number": 527,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -9,6 +9,7 @@\npackage main\n \n import (\n+\t\"flag\"\n \t\"log\"\n \t\"runtime\"\n \t\"sync\"",
        "comments": [],
        "commit_messages": [
            "Add flags to configure version and function skew."
        ],
        "last_commit_sha": "1102060fbd30f21e3f13b72e76d8bd6baaaac1e0"
    },
    {
        "pr_title": "profiler: Add flags to configure version and function skew",
        "pr_number": 527,
        "file_name": "profiler/hotapp/main.go",
        "code_diff": "@@ -17,11 +18,16 @@\nimport (\n \t\"cloud.google.com/go/profiler\"\n )\n \n-// There are several goroutines continuously fighting for this mutex.\n-var mu sync.Mutex\n-\n-// Some allocated memory. Held in a global variable to protect it from GC.\n-var mem [][]byte\n+var (\n+\t// Service version to configure.\n+\tversion = flag.String(\"version\", \"1.0.0\", \"service version\")\n+\t// Skew of foo1 function over foo2, in the CPU busyloop, to simulate diff.\n+\tskew = flag.Int(\"skew\", 100, \"skew of foo2 over foo1: foo2 will consume skew/100 CPU time compared to foo1 (default is no skew)\")\n+\t// There are several goroutines continuously fighting for this mutex.\n+\tmu sync.Mutex\n+\t// Some allocated memory. Held in a global variable to protect it from GC.\n+\tmem [][]byte\n+)\n \n func sleepLocked(d time.Duration) {\n \tmu.Lock()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "1102060fbd30f21e3f13b72e76d8bd6baaaac1e0"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -480,6 +480,59 @@\nfunc detectLogos(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [START vision_detect_async_document]\n+\n+// detectAsyncDocument does Optical Character Recognition (OCR) on a PDF file\n+// stored in GCS.\n+func detectAsyncDocument(w io.Writer, gcsSourceURI, gcsDestinationURI string) error {\n+\tctx := context.Background()\n+\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\trequest := &visionpb.AsyncBatchAnnotateFilesRequest{\n+\t\tRequests: []*visionpb.AsyncAnnotateFileRequest{\n+\t\t\t{\n+\t\t\t\tFeatures: []*visionpb.Feature{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tType: visionpb.Feature_DOCUMENT_TEXT_DETECTION,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tInputConfig: &visionpb.InputConfig{\n+\t\t\t\t\tGcsSource: &visionpb.GcsSource{Uri: gcsSourceURI},\n+\t\t\t\t\t// Supported MimeTypes are: \"application/pdf\" and \"image/tiff\".\n+\t\t\t\t\tMimeType: \"application/pdf\",\n+\t\t\t\t},\n+\t\t\t\tOutputConfig: &visionpb.OutputConfig{\n+\t\t\t\t\tGcsDestination: &visionpb.GcsDestination{Uri: gcsDestinationURI},\n+\t\t\t\t\t// How many pages should be grouped into each json output file.\n+\t\t\t\t\tBatchSize: 2,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\toperation, err := client.AsyncBatchAnnotateFiles(ctx, request)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Fprintf(w, \"Waiting for the operation to finish.\")\n+\n+\tresp, err := operation.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Fprintf(w, \"%v\", resp)\n+\n+\treturn nil\n+}\n+\n+// [END vision_detect_async_document]\n+\n func init() {\n \t// Refer to these functions so that goimports is happy before boilerplate is inserted.\n \t_ = context.Background()",
        "comments": [],
        "commit_messages": [
            "Add tests for vision async detect document OCR"
        ],
        "last_commit_sha": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "Add samples for vision async detect document OCR",
        "pr_number": 523,
        "file_name": "vision/detect/detect_test.go",
        "code_diff": "@@ -6,9 +6,15 @@\npackage main\n \n import (\n \t\"bytes\"\n+\t\"fmt\"\n \t\"io\"\n \t\"strings\"\n \t\"testing\"\n+\t\"time\"\n+\n+\t\"cloud.google.com/go/storage\"\n+\t\"golang.org/x/net/context\"\n+\t\"google.golang.org/api/iterator\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_messages": [
            "Add tests for vision async detect document OCR"
        ],
        "last_commit_sha": "94b93b804dc0dcdc4badd85c1732e5b4520f80e3"
    },
    {
        "pr_title": "dlp: add autoPopulateTimespan option for creating job triggers",
        "pr_number": 518,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -37,13 +37,14 @@\nfunc bytesTypeValues() string {\n }\n \n var (\n-\tproject           = flag.String(\"project\", \"\", \"Project ID (required)\")\n-\tlanguageCode      = flag.String(\"languageCode\", \"en-US\", \"Language code for infoTypes\")\n-\tinfoTypesString   = flag.String(\"infoTypes\", \"PHONE_NUMBER,EMAIL_ADDRESS,CREDIT_CARD_NUMBER,US_SOCIAL_SECURITY_NUMBER\", \"Info types to inspect*, redactImage, createTrigger, and createInspectTemplate\")\n-\tminLikelihoodFlag = flag.String(\"minLikelihood\", \"LIKELIHOOD_UNSPECIFIED\", fmt.Sprintf(\"Minimum likelihood value for inspect*, redactImage, createTrigger, and createInspectTemplate [%v]\", minLikelihoodValues()))\n-\tbytesTypeFlag     = flag.String(\"bytesType\", \"BYTES_TYPE_UNSPECIFIED\", fmt.Sprintf(\"Bytes type of input file for inspectFile and redactImage [%v]\", bytesTypeValues()))\n-\tmaxFindings       = flag.Int(\"maxFindings\", 0, \"Number of results for inspect*, createTrigger, and createInspectTemplate (default 0 (no limit))\")\n-\tincludeQuote      = flag.Bool(\"includeQuote\", false, \"Include a quote of findings for inspect* (default false)\")\n+\tproject              = flag.String(\"project\", \"\", \"Project ID (required)\")\n+\tlanguageCode         = flag.String(\"languageCode\", \"en-US\", \"Language code for infoTypes\")\n+\tinfoTypesString      = flag.String(\"infoTypes\", \"PHONE_NUMBER,EMAIL_ADDRESS,CREDIT_CARD_NUMBER,US_SOCIAL_SECURITY_NUMBER\", \"Info types to inspect*, redactImage, createTrigger, and createInspectTemplate\")\n+\tminLikelihoodFlag    = flag.String(\"minLikelihood\", \"LIKELIHOOD_UNSPECIFIED\", fmt.Sprintf(\"Minimum likelihood value for inspect*, redactImage, createTrigger, and createInspectTemplate [%v]\", minLikelihoodValues()))\n+\tbytesTypeFlag        = flag.String(\"bytesType\", \"BYTES_TYPE_UNSPECIFIED\", fmt.Sprintf(\"Bytes type of input file for inspectFile and redactImage [%v]\", bytesTypeValues()))\n+\tmaxFindings          = flag.Int(\"maxFindings\", 0, \"Number of results for inspect*, createTrigger, and createInspectTemplate (default 0 (no limit))\")\n+\tautoPopulateTimespan = flag.Bool(\"autoPopulateTimespan\", false, \"Limit scan to new content only (default false)\")\n+\tincludeQuote         = flag.Bool(\"includeQuote\", false, \"Include a quote of findings for inspect* (default false)\")\n )\n \n func main() {",
        "comments": [],
        "commit_messages": [
            "DLP: Add autoPopulateTimespan option for creating job triggers."
        ],
        "last_commit_sha": "66f9a0846272aae6568dfba75b72d4856f0764ee"
    },
    {
        "pr_title": "dlp: add autoPopulateTimespan option for creating job triggers",
        "pr_number": 518,
        "file_name": "dlp/dlp_snippets/triggers.go",
        "code_diff": "@@ -22,7 +22,7 @@\nimport (\n // [START dlp_create_trigger]\n \n // createTrigger creates a trigger with the given configuration.\n-func createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, triggerID, displayName, description, bucketName string, scanPeriod int64, infoTypes []string) {\n+func createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, triggerID, displayName, description, bucketName string, autoPopulateTimespan bool, scanPeriodDays int64, infoTypes []string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {",
        "comments": [],
        "commit_messages": [
            "DLP: Add autoPopulateTimespan option for creating job triggers."
        ],
        "last_commit_sha": "66f9a0846272aae6568dfba75b72d4856f0764ee"
    },
    {
        "pr_title": "dlp: add autoPopulateTimespan option for creating job triggers",
        "pr_number": 518,
        "file_name": "dlp/dlp_snippets/triggers.go",
        "code_diff": "@@ -44,7 +44,7 @@\nfunc createTrigger(w io.Writer, client *dlp.Client, project string, minLikelihoo\n \t\t\t\t\t\tSchedule: &dlppb.Schedule{\n \t\t\t\t\t\t\tOption: &dlppb.Schedule_RecurrencePeriodDuration{\n \t\t\t\t\t\t\t\tRecurrencePeriodDuration: &duration.Duration{\n-\t\t\t\t\t\t\t\t\tSeconds: scanPeriod * 60 * 60 * 24, // Trigger the scan daily\n+\t\t\t\t\t\t\t\t\tSeconds: scanPeriodDays * 60 * 60 * 24, // Days to seconds.\n \t\t\t\t\t\t\t\t},\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t},",
        "comments": [],
        "commit_messages": [
            "DLP: Add autoPopulateTimespan option for creating job triggers."
        ],
        "last_commit_sha": "66f9a0846272aae6568dfba75b72d4856f0764ee"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/deid.go",
        "code_diff": "@@ -18,12 +18,20 @@\nimport (\n \n // [START dlp_deidentify_masking]\n \n-// mask deidentifies the input by masking all info types with maskingCharacter and\n-// prints the result to w.\n-func mask(w io.Writer, client *dlp.Client, project, input, maskingCharacter string, numberToMask int32) {\n+// mask deidentifies the input by masking all provided info types with maskingCharacter\n+// and prints the result to w.\n+func mask(w io.Writer, client *dlp.Client, project, input string, infoTypes []string, maskingCharacter string, numberToMask int32) {\n+\t// Convert the info type strings to a list of InfoTypes.\n+\tvar i []*dlppb.InfoType\n+\tfor _, it := range infoTypes {\n+\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\t}\n \t// Create a configured request.\n \treq := &dlppb.DeidentifyContentRequest{\n \t\tParent: \"projects/\" + project,\n+\t\tInspectConfig: &dlppb.InspectConfig{\n+\t\t\tInfoTypes: i,\n+\t\t},\n \t\tDeidentifyConfig: &dlppb.DeidentifyConfig{\n \t\t\tTransformation: &dlppb.DeidentifyConfig_InfoTypeTransformations{\n \t\t\t\tInfoTypeTransformations: &dlppb.InfoTypeTransformations{",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/deid.go",
        "code_diff": "@@ -121,7 +129,12 @@\nfunc deidentifyDateShift(w io.Writer, client *dlp.Client, project string, lowerB\n // full KMS key resource name used to wrap the key. surrogateInfoType is an\n // optional identifier needed for reidentification. surrogateInfoType can be any\n // value not found in your input.\n-func deidentifyFPE(w io.Writer, client *dlp.Client, project, input, keyFileName, cryptoKeyName, surrogateInfoType string) {\n+func deidentifyFPE(w io.Writer, client *dlp.Client, project, input string, infoTypes []string, keyFileName, cryptoKeyName, surrogateInfoType string) {\n+\t// Convert the info type strings to a list of InfoTypes.\n+\tvar i []*dlppb.InfoType\n+\tfor _, it := range infoTypes {\n+\t\ti = append(i, &dlppb.InfoType{Name: it})\n+\t}\n \t// Read the key file.\n \tkeyBytes, err := ioutil.ReadFile(keyFileName)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "Add info types to deid methods."
        ],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -9,6 +9,7 @@\nimport (\n \t\"io\"\n \t\"io/ioutil\"\n \t\"log\"\n+\t\"strings\"\n \n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_messages": [
            "Add missing import"
        ],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -20,18 +21,49 @@\nimport (\n // [START dlp_inspect_string]\n \n // inspectString searches for the given infoTypes in the input.\n-func inspectString(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, input string) {\n+func inspectString(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, input string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \t// Create a configured request.\n \treq := &dlppb.InspectContentRequest{\n \t\tParent: \"projects/\" + project,\n \t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\tInfoTypes:     i,\n-\t\t\tMinLikelihood: minLikelihood,\n+\t\t\tInfoTypes:       i,\n+\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\tMinLikelihood:   minLikelihood,\n \t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t},",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -58,12 +90,42 @@\nfunc inspectString(w io.Writer, client *dlp.Client, project string, minLikelihoo\n // [START dlp_inspect_file]\n \n // inspectFile searches for the given info types in the given Reader (with the given bytesType).\n-func inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, bytesType dlppb.ByteContentItem_BytesType, input io.Reader) {\n+func inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, bytesType dlppb.ByteContentItem_BytesType, input io.Reader) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \tb, err := ioutil.ReadAll(input)\n \tif err != nil {\n \t\tlog.Fatalf(\"error reading file: %v\", err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -72,8 +134,9 @@\nfunc inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood\n \treq := &dlppb.InspectContentRequest{\n \t\tParent: \"projects/\" + project,\n \t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\tInfoTypes:     i,\n-\t\t\tMinLikelihood: minLikelihood,\n+\t\t\tInfoTypes:       i,\n+\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\tMinLikelihood:   minLikelihood,\n \t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t},",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -103,12 +166,42 @@\nfunc inspectFile(w io.Writer, client *dlp.Client, project string, minLikelihood\n // [START dlp_inspect_gcs]\n \n // inspectGCSFile searches for the given info types in the given file.\n-func inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, pubSubTopic, pubSubSub, bucketName, fileName string) {\n+func inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, pubSubTopic, pubSubSub, bucketName, fileName string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -145,8 +238,9 @@\nfunc inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikeliho\n \t\t\t\t},\n \t\t\t\t// InspectConfig describes what fields to look for.\n \t\t\t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\t\t\tInfoTypes:     i,\n-\t\t\t\t\tMinLikelihood: minLikelihood,\n+\t\t\t\t\tInfoTypes:       i,\n+\t\t\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\t\t\tMinLikelihood:   minLikelihood,\n \t\t\t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t\t\t},",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -207,12 +301,42 @@\nfunc inspectGCSFile(w io.Writer, client *dlp.Client, project string, minLikeliho\n // [START dlp_inspect_datastore]\n \n // inspectDatastore searches for the given info types in the given dataset kind.\n-func inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, pubSubTopic, pubSubSub, dataProject, namespaceID, kind string) {\n+func inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, pubSubTopic, pubSubSub, dataProject, namespaceID, kind string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -253,8 +377,9 @@\nfunc inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikeli\n \t\t\t\t},\n \t\t\t\t// InspectConfig describes what fields to look for.\n \t\t\t\tInspectConfig: &dlppb.InspectConfig{\n-\t\t\t\t\tInfoTypes:     i,\n-\t\t\t\t\tMinLikelihood: minLikelihood,\n+\t\t\t\t\tInfoTypes:       i,\n+\t\t\t\t\tCustomInfoTypes: customInfoTypes,\n+\t\t\t\t\tMinLikelihood:   minLikelihood,\n \t\t\t\t\tLimits: &dlppb.InspectConfig_FindingLimits{\n \t\t\t\t\t\tMaxFindingsPerRequest: maxFindings,\n \t\t\t\t\t},",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect.go",
        "code_diff": "@@ -315,12 +440,42 @@\nfunc inspectDatastore(w io.Writer, client *dlp.Client, project string, minLikeli\n // [START dlp_inspect_bigquery]\n \n // inspectBigquery searches for the given info types in the given Bigquery dataset table.\n-func inspectBigquery(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, pubSubTopic, pubSubSub, dataProject, datasetID, tableID string) {\n+func inspectBigquery(w io.Writer, client *dlp.Client, project string, minLikelihood dlppb.Likelihood, maxFindings int32, includeQuote bool, infoTypes []string, customDictionaries []string, customRegexes []string, pubSubTopic, pubSubSub, dataProject, datasetID, tableID string) {\n \t// Convert the info type strings to a list of InfoTypes.\n \tvar i []*dlppb.InfoType\n \tfor _, it := range infoTypes {\n \t\ti = append(i, &dlppb.InfoType{Name: it})\n \t}\n+\t// Convert the custom dictionary word lists and custom regexes to a list of CustomInfoTypes.\n+\tvar customInfoTypes []*dlppb.CustomInfoType\n+\tfor idx, it := range customDictionaries {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_DICTIONARY_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Dictionary_{\n+\t\t\t\tDictionary: &dlppb.CustomInfoType_Dictionary{\n+\t\t\t\t\tSource: &dlppb.CustomInfoType_Dictionary_WordList_{\n+\t\t\t\t\t\tWordList: &dlppb.CustomInfoType_Dictionary_WordList{\n+\t\t\t\t\t\t\tWords: strings.Split(it, \",\"),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n+\tfor idx, it := range customRegexes {\n+\t\tcustomInfoTypes = append(customInfoTypes, &dlppb.CustomInfoType{\n+\t\t\tInfoType: &dlppb.InfoType{\n+\t\t\t\tName: fmt.Sprintf(\"CUSTOM_REGEX_%d\", idx),\n+\t\t\t},\n+\t\t\tType: &dlppb.CustomInfoType_Regex_{\n+\t\t\t\tRegex: &dlppb.CustomInfoType_Regex{\n+\t\t\t\t\tPattern: it,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t})\n+\t}\n \n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -33,14 +33,23 @@\nfunc TestInspectString(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, test.s)\n+\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, test.s)\n \t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n \t\t\tif test.want {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n \t\t\t} else {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n \t\t\t}\n \t\t}\n+\t\tbuf.Reset()\n+\t\tinspectString(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, test.s)\n+\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n+\t\t\tif test.want {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n+\t\t\t} else {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\t}\n+\t\t}\n \t}\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -60,14 +69,23 @@\nfunc TestInspectFile(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n+\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, nil, nil, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n \t\tif got := buf.String(); test.want != strings.Contains(got, \"US_SOCIAL_SECURITY_NUMBER\") {\n \t\t\tif test.want {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'US_SOCIAL_SECURITY_NUMBER' substring\", test.s, got)\n \t\t\t} else {\n \t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'US_SOCIAL_SECURITY_NUMBER'\", test.s, got)\n \t\t\t}\n \t\t}\n+\t\tbuf.Reset()\n+\t\tinspectFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, nil, []string{\"SSN\"}, []string{\"\\\\d{9}\"}, dlppb.ByteContentItem_TEXT_UTF8, strings.NewReader(test.s))\n+\t\tif got := buf.String(); test.want != strings.Contains(got, \"CUSTOM_DICTIONARY_0\") && strings.Contains(got, \"CUSTOM_REGEX_0\") {\n+\t\t\tif test.want {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0' substring\", test.s, got)\n+\t\t\t} else {\n+\t\t\t\tt.Errorf(\"inspectString(%s) = %q, want to not contain 'CUSTOM_DICTIONARY_0' and 'CUSTOM_REGEX_0'\", test.s, got)\n+\t\t\t}\n+\t\t}\n \t}\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -139,7 +157,7 @@\nfunc TestInspectGCS(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectGCSFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, \"test-topic\", \"test-sub\", bucketName, test.fileName)\n+\t\tinspectGCSFile(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, \"test-topic\", \"test-sub\", bucketName, test.fileName)\n \t\tif got := buf.String(); !strings.Contains(got, test.want) {\n \t\t\tt.Errorf(\"inspectString(%s) = %q, want %q substring\", test.fileName, got, test.want)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "Added custom info type tests to inspect_test.go"
        ],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/inspect_test.go",
        "code_diff": "@@ -199,7 +217,7 @@\nfunc TestInspectDatastore(t *testing.T) {\n \t}\n \tfor _, test := range tests {\n \t\tbuf := new(bytes.Buffer)\n-\t\tinspectDatastore(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, \"test-topic\", \"test-sub\", projectID, \"\", test.kind)\n+\t\tinspectDatastore(buf, client, projectID, dlppb.Likelihood_POSSIBLE, 0, true, []string{\"US_SOCIAL_SECURITY_NUMBER\"}, []string{}, []string{}, \"test-topic\", \"test-sub\", projectID, \"\", test.kind)\n \t\tif got := buf.String(); !strings.Contains(got, test.want) {\n \t\t\tt.Errorf(\"inspectDatastore(%s) = %q, want %q substring\", test.kind, got, test.want)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "Added custom info type tests to inspect_test.go"
        ],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -37,14 +37,16 @@\nfunc bytesTypeValues() string {\n }\n \n var (\n-\tproject              = flag.String(\"project\", \"\", \"Project ID (required)\")\n-\tlanguageCode         = flag.String(\"languageCode\", \"en-US\", \"Language code for infoTypes\")\n-\tinfoTypesString      = flag.String(\"infoTypes\", \"PHONE_NUMBER,EMAIL_ADDRESS,CREDIT_CARD_NUMBER,US_SOCIAL_SECURITY_NUMBER\", \"Info types to inspect*, redactImage, createTrigger, and createInspectTemplate\")\n-\tminLikelihoodFlag    = flag.String(\"minLikelihood\", \"LIKELIHOOD_UNSPECIFIED\", fmt.Sprintf(\"Minimum likelihood value for inspect*, redactImage, createTrigger, and createInspectTemplate [%v]\", minLikelihoodValues()))\n-\tbytesTypeFlag        = flag.String(\"bytesType\", \"BYTES_TYPE_UNSPECIFIED\", fmt.Sprintf(\"Bytes type of input file for inspectFile and redactImage [%v]\", bytesTypeValues()))\n-\tmaxFindings          = flag.Int(\"maxFindings\", 0, \"Number of results for inspect*, createTrigger, and createInspectTemplate (default 0 (no limit))\")\n-\tautoPopulateTimespan = flag.Bool(\"autoPopulateTimespan\", false, \"Limit scan to new content only (default false)\")\n-\tincludeQuote         = flag.Bool(\"includeQuote\", false, \"Include a quote of findings for inspect* (default false)\")\n+\tproject                = flag.String(\"project\", \"\", \"Project ID (required)\")\n+\tlanguageCode           = flag.String(\"languageCode\", \"en-US\", \"Language code for infoTypes\")\n+\tinfoTypesString        = flag.String(\"infoTypes\", \"PHONE_NUMBER,EMAIL_ADDRESS,CREDIT_CARD_NUMBER,US_SOCIAL_SECURITY_NUMBER\", \"Info types to inspect*, redactImage, createTrigger, and createInspectTemplate\")\n+\tcustomDictionaryString = flag.String(\"customDictionary\", \"\", \"Custom dictionary for inspect*\")\n+\tcustomRegexString      = flag.String(\"customRegex\", \"\", \"Custom regex for inspect*\")\n+\tminLikelihoodFlag      = flag.String(\"minLikelihood\", \"LIKELIHOOD_UNSPECIFIED\", fmt.Sprintf(\"Minimum likelihood value for inspect*, redactImage, createTrigger, and createInspectTemplate [%v]\", minLikelihoodValues()))\n+\tbytesTypeFlag          = flag.String(\"bytesType\", \"BYTES_TYPE_UNSPECIFIED\", fmt.Sprintf(\"Bytes type of input file for inspectFile and redactImage [%v]\", bytesTypeValues()))\n+\tmaxFindings            = flag.Int(\"maxFindings\", 0, \"Number of results for inspect*, createTrigger, and createInspectTemplate (default 0 (no limit))\")\n+\tautoPopulateTimespan   = flag.Bool(\"autoPopulateTimespan\", false, \"Limit scan to new content only (default false)\")\n+\tincludeQuote           = flag.Bool(\"includeQuote\", false, \"Include a quote of findings for inspect* (default false)\")\n )\n \n func main() {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -58,6 +60,14 @@\nfunc main() {\n \tflag.Parse()\n \n \tinfoTypesList := strings.Split(*infoTypesString, \",\")\n+\tvar customDictionariesList []string\n+\tif *customDictionaryString != \"\" {\n+\t\tcustomDictionariesList = []string{*customDictionaryString}\n+\t}\n+\tvar customRegexesList []string\n+\tif *customRegexString != \"\" {\n+\t\tcustomRegexesList = []string{*customRegexString}\n+\t}\n \n \tif *project == \"\" {\n \t\tfmt.Fprintf(os.Stderr, \"Must provide a -project\\n\\n\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "dlp: add samples for custom info types",
        "pr_number": 511,
        "file_name": "dlp/dlp_snippets/main.go",
        "code_diff": "@@ -88,23 +98,23 @@\nfunc main() {\n \t\tos.Exit(1)\n \tcase \"inspect\":\n \t\tcheckNArg(1)\n-\t\tinspectString(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1))\n+\t\tinspectString(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1))\n \tcase \"inspectFile\":\n \t\tcheckNArg(1)\n \t\tf, err := os.Open(flag.Arg(1))\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"error opening file: %v\", err)\n \t\t}\n-\t\tinspectFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, bytesType, f)\n+\t\tinspectFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, bytesType, f)\n \tcase \"inspectGCSFile\":\n \t\tcheckNArg(4)\n-\t\tinspectGCSFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4))\n+\t\tinspectGCSFile(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4))\n \tcase \"inspectDatastore\":\n \t\tcheckNArg(5)\n-\t\tinspectDatastore(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n+\t\tinspectDatastore(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n \tcase \"inspectBigquery\":\n \t\tcheckNArg(5)\n-\t\tinspectBigquery(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n+\t\tinspectBigquery(os.Stdout, client, *project, minLikelihood, int32(*maxFindings), *includeQuote, infoTypesList, customDictionariesList, customRegexesList, flag.Arg(1), flag.Arg(2), flag.Arg(3), flag.Arg(4), flag.Arg(5))\n \n \tcase \"redactImage\":\n \t\tcheckNArg(2)",
        "comments": [],
        "commit_messages": [
            "Add custom info types to main.go"
        ],
        "last_commit_sha": "629f62f665d6729e084b6b5e02222ca58df63330"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -33,14 +33,14 @@\nfunc updateDatasetDescription(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_description]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n \t\tDescription: \"Updated Description.\",\n \t}\n-\tif _, err = ds.Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err = ds.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_description]",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments"
        ],
        "last_commit_sha": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -51,14 +51,14 @@\nfunc updateDatasetDefaultExpiration(client *bigquery.Client, datasetID string) e\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_expiration]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n \t\tDefaultTableExpiration: 24 * time.Hour,\n \t}\n-\tif _, err := client.Dataset(datasetID).Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err := client.Dataset(datasetID).Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_expiration]",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments"
        ],
        "last_commit_sha": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -69,13 +69,13 @@\nfunc updateDatasetAccessControl(client *bigquery.Client, datasetID string) error\n \tctx := context.Background()\n \t// [START bigquery_update_dataset_access]\n \tds := client.Dataset(datasetID)\n-\toriginal, err := ds.Metadata(ctx)\n+\tmeta, err := ds.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \t// Append a new access control entry to the existing access list.\n-\tchanges := bigquery.DatasetMetadataToUpdate{\n-\t\tAccess: append(original.Access, &bigquery.AccessEntry{\n+\tupdate := bigquery.DatasetMetadataToUpdate{\n+\t\tAccess: append(meta.Access, &bigquery.AccessEntry{\n \t\t\tRole:       bigquery.ReaderRole,\n \t\t\tEntityType: bigquery.UserEmailEntity,\n \t\t\tEntity:     \"sample.bigquery.dev@gmail.com\"},",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments"
        ],
        "last_commit_sha": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -84,13 +84,67 @@\nfunc updateDatasetAccessControl(client *bigquery.Client, datasetID string) error\n \n \t// Leverage the ETag for the update to assert there's been no modifications to the\n \t// dataset since the metadata was originally read.\n-\tif _, err := ds.Update(ctx, changes, original.ETag); err != nil {\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_dataset_access]\n \treturn nil\n }\n \n+func datasetLabels(client *bigquery.Client, w io.Writer, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_dataset_labels]\n+\tmeta, err := client.Dataset(datasetID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Dataset %s labels:\\n\", datasetID)\n+\tif len(meta.Labels) == 0 {\n+\t\tfmt.Fprintln(w, \"Dataset has no labels defined.\")\n+\t\treturn nil\n+\t}\n+\tfor k, v := range meta.Labels {\n+\t\tfmt.Fprintf(w, \"\\t%s:%s\\n\", k, v)\n+\t}\n+\t// [END bigquery_get_dataset_labels]\n+\treturn nil\n+}\n+\n+func addDatasetLabel(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_label_dataset]\n+\tds := client.Dataset(datasetID)\n+\tmeta, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tupdate := bigquery.DatasetMetadataToUpdate{}\n+\tupdate.SetLabel(\"color\", \"green\")\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_label_dataset]\n+\treturn nil\n+}\n+\n+func deleteDatasetLabel(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_delete_label_dataset]\n+\tds := client.Dataset(datasetID)\n+\tmeta, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tupdate := bigquery.DatasetMetadataToUpdate{}\n+\tupdate.DeleteLabel(\"color\")\n+\tif _, err := ds.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_delete_label_dataset]\n+\treturn nil\n+}\n+\n func deleteEmptyDataset(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_delete_dataset]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -116,6 +170,25 @@\nfunc listDatasets(client *bigquery.Client) error {\n \treturn nil\n }\n \n+func listDatasetsByLabel(client *bigquery.Client, w io.Writer) error {\n+\tctx := context.Background()\n+\t// [START bigquery_list_datasets_by_label]\n+\tit := client.Datasets(ctx)\n+\tit.Filter = \"labels.color:green\"\n+\tfor {\n+\t\tdataset, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"dataset: %s\\n\", dataset.DatasetID)\n+\t}\n+\t// [END bigquery_list_datasets_by_label]\n+\treturn nil\n+}\n+\n func printDatasetInfo(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_dataset]",
        "comments": [],
        "commit_messages": [
            "BigQuery: label examples"
        ],
        "last_commit_sha": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -149,6 +222,33 @@\nfunc printDatasetInfo(client *bigquery.Client, datasetID string) error {\n \treturn nil\n }\n \n+func listJobs(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_list_jobs]\n+\tit := client.Jobs(ctx)\n+\tfor i := 0; i < 10; i++ {\n+\t\tj, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tstate := \"Unknown\"\n+\t\tswitch j.LastStatus().State {\n+\t\tcase bigquery.Pending:\n+\t\t\tstate = \"Pending\"\n+\t\tcase bigquery.Running:\n+\t\t\tstate = \"Running\"\n+\t\tcase bigquery.Done:\n+\t\t\tstate = \"Done\"\n+\t\t}\n+\t\tfmt.Printf(\"Job %s in state %s\\n\", j.ID(), state)\n+\t}\n+\t// [END bigquery_list_jobs]\n+\treturn nil\n+}\n+\n // Item represents a row item.\n type Item struct {\n \tName string",
        "comments": [],
        "commit_messages": [
            "BigQuery: label examples"
        ],
        "last_commit_sha": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -211,14 +311,14 @@\nfunc updateTableDescription(client *bigquery.Client, datasetID, tableID string)\n \tctx := context.Background()\n \t// [START bigquery_update_table_description]\n \ttableRef := client.Dataset(datasetID).Table(tableID)\n-\toriginal, err := tableRef.Metadata(ctx)\n+\tmeta, err := tableRef.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tnewMeta := bigquery.TableMetadataToUpdate{\n+\tupdate := bigquery.TableMetadataToUpdate{\n \t\tDescription: \"Updated description.\",\n \t}\n-\tif _, err = tableRef.Update(ctx, newMeta, original.ETag); err != nil {\n+\tif _, err = tableRef.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_table_description]",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments"
        ],
        "last_commit_sha": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -230,21 +330,75 @@\nfunc updateTableExpiration(client *bigquery.Client, datasetID, tableID string) e\n \tctx := context.Background()\n \t// [START bigquery_update_table_expiration]\n \ttableRef := client.Dataset(datasetID).Table(tableID)\n-\toriginal, err := tableRef.Metadata(ctx)\n+\tmeta, err := tableRef.Metadata(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tnewMeta := bigquery.TableMetadataToUpdate{\n+\tupdate := bigquery.TableMetadataToUpdate{\n \t\tExpirationTime: time.Now().Add(time.Duration(5*24) * time.Hour), // table expiration in 5 days.\n \t}\n-\tif _, err = tableRef.Update(ctx, newMeta, original.ETag); err != nil {\n+\tif _, err = tableRef.Update(ctx, update, meta.ETag); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_update_table_expiration]\n \treturn nil\n \n }\n \n+func tableLabels(client *bigquery.Client, w io.Writer, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_table_labels]\n+\tmeta, err := client.Dataset(datasetID).Table(tableID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Table %s labels:\\n\", datasetID)\n+\tif len(meta.Labels) == 0 {\n+\t\tfmt.Println(\"Table has no labels defined.\")\n+\t\treturn nil\n+\t}\n+\tfor k, v := range meta.Labels {\n+\t\tfmt.Fprintf(w, \"\\t%s:%s\\n\", k, v)\n+\t}\n+\t// [END bigquery_get_table_labels]\n+\treturn nil\n+}\n+\n+func addTableLabel(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_label_table]\n+\ttbl := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tbl.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tupdate := bigquery.TableMetadataToUpdate{}\n+\tupdate.SetLabel(\"color\", \"green\")\n+\tif _, err := tbl.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_label_table]\n+\treturn nil\n+}\n+\n+func deleteTableLabel(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_delete_label_table]\n+\ttbl := client.Dataset(datasetID).Table(tableID)\n+\tmeta, err := tbl.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tupdate := bigquery.TableMetadataToUpdate{}\n+\tupdate.DeleteLabel(\"color\")\n+\tif _, err := tbl.Update(ctx, update, meta.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_delete_label_table]\n+\treturn nil\n+}\n+\n func listTables(client *bigquery.Client, w io.Writer, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_list_tables]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -63,6 +63,32 @@\nfunc TestAll(t *testing.T) {\n \tif err := updateDatasetAccessControl(client, datasetID); err != nil {\n \t\tt.Errorf(\"updateDataSetAccessControl(%q): %v\", datasetID, err)\n \t}\n+\tif err := addDatasetLabel(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n+\t}\n+\n+\tbuf := &bytes.Buffer{}\n+\tif err := datasetLabels(client, buf, datasetID); err != nil {\n+\t\tt.Errorf(\"getDatasetLabels(%q): %v\", datasetID, err)\n+\t}\n+\twant := \"color:green\"\n+\tif got := buf.String(); !strings.Contains(got, want) {\n+\t\tt.Errorf(\"getDatasetLabel(%q) expected %q to contain %q\", datasetID, got, want)\n+\t}\n+\n+\tif err := addDatasetLabel(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetAddLabel: %v\", err)\n+\t}\n+\tbuf.Reset()\n+\tif err := listDatasetsByLabel(client, buf); err != nil {\n+\t\tt.Errorf(\"listDatasetsByLabel: %v\", err)\n+\t}\n+\tif got := buf.String(); !strings.Contains(got, datasetID) {\n+\t\tt.Errorf(\"listDatasetsByLabel expected %q to contain %q\", got, want)\n+\t}\n+\tif err := deleteDatasetLabel(client, datasetID); err != nil {\n+\t\tt.Errorf(\"updateDatasetDeleteLabel: %v\", err)\n+\t}\n \n \t// Test empty dataset creation/ttl/delete.\n \tdeletionDatasetID := uniqueBQName(\"golang_example_quickdelete\")",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "BigQuery: snippets related to Labels functionality.",
        "pr_number": 507,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -103,8 +129,14 @@\nfunc TestAll(t *testing.T) {\n \tif err := updateTableExpiration(client, datasetID, explicit); err != nil {\n \t\tt.Errorf(\"updateTableExpiration(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n+\tif err := addTableLabel(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"updateTableAddLabel(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\t}\n+\tif err := deleteTableLabel(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"updateTableAddLabel(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\t}\n \n-\tbuf := &bytes.Buffer{}\n+\tbuf.Reset()\n \tif err := listTables(client, buf, datasetID); err != nil {\n \t\tt.Errorf(\"listTables(%q): %v\", datasetID, err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "bd3839de8392524c6ce2ab709c775837b38f6dbe"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -279,32 +279,6 @@\nfunc insertRows(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n-func listRows(client *bigquery.Client, datasetID, tableID string) error {\n-\tctx := context.Background()\n-\tq := client.Query(fmt.Sprintf(`\n-\t\tSELECT name, age\n-\t\tFROM %s.%s\n-\t\tWHERE age >= 20\n-\t`, datasetID, tableID))\n-\tit, err := q.Read(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\tfor {\n-\t\tvar row []bigquery.Value\n-\t\terr := it.Next(&row)\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Println(row)\n-\t}\n-\treturn nil\n-}\n-\n func queryBasic(client *bigquery.Client) error {\n \tctx := context.Background()\n \t// [START bigquery_query]",
        "comments": [],
        "commit_messages": [
            "BigQuery: minor refactors."
        ],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -328,35 +302,9 @@\nfunc queryDisableCache(client *bigquery.Client) error {\n \tq.DisableQueryCache = true\n \t// Location must match that of the dataset(s) referenced in the query.\n \tq.Location = \"US\"\n-\n-\tjob, err := q.Run(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\t// Wait until async querying is done.\n-\tstatus, err := job.Wait(ctx)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tif err := status.Err(); err != nil {\n-\t\treturn err\n-\t}\n-\n-\tit, err := job.Read(ctx)\n-\tfor {\n-\t\tvar row []bigquery.Value\n-\t\terr := it.Next(&row)\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Println(row)\n-\t}\n \t// [END bigquery_query_no_cache]\n-\treturn nil\n+\n+\treturn runAndRead(ctx, client, q)\n }\n \n func queryBatch(client *bigquery.Client, dstDatasetID, dstTableID string) error {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -409,13 +357,12 @@\nfunc queryDryRun(client *bigquery.Client) error {\n \tctx := context.Background()\n \t// [START bigquery_query_dry_run]\n \tq := client.Query(`\n-\t\tSELECT \n-\t\t   name,\n-\t\t   COUNT(*) as name_count\n-\t\tFROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n-\t\tWHERE state = 'WA' \n-\t\tGROUP BY name\n-\t\t`)\n+\tSELECT\n+\t\tname,\n+\t\tCOUNT(*) as name_count\n+\tFROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n+\tWHERE state = 'WA'\n+\tGROUP BY name`)\n \tq.DryRun = true\n \t// Location must match that of the dataset(s) referenced in the query.\n \tq.Location = \"US\"",
        "comments": [],
        "commit_messages": [
            "BigQuery: minor refactors."
        ],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -430,7 +377,6 @@\nfunc queryDryRun(client *bigquery.Client) error {\n \t\treturn err\n \t}\n \tfmt.Printf(\"This query will process %d bytes\\n\", status.Statistics.TotalBytesProcessed)\n-\n \t// [END bigquery_query_dry_run]\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [
            "BigQuery: minor refactors."
        ],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -956,6 +902,7 @@\nfunc runAndRead(ctx context.Context, client *bigquery.Client, q *bigquery.Query)\n \t// [START bigquery_query_destination_table]\n \t// [START bigquery_query_legacy]\n \t// [START bigquery_query_legacy_large_results]\n+\t// [START bigquery_query_no_cache]\n \t// [START bigquery_query_params_arrays]\n \t// [START bigquery_query_params_named]\n \t// [START bigquery_query_params_positional]",
        "comments": [],
        "commit_messages": [
            "BigQuery: minor refactors."
        ],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -7,6 +7,7 @@\npackage snippets\n import (\n \t\"bytes\"\n \t\"fmt\"\n+\t\"regexp\"\n \t\"strings\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -18,6 +19,31 @@\nimport (\n \t\"google.golang.org/api/iterator\"\n )\n \n+// uniqueBQName returns a more unique name for a BigQuery resource.\n+func uniqueBQName(prefix string) string {\n+\tt := time.Now()\n+\treturn fmt.Sprintf(\"%s_%d\", sanitize(prefix, '_'), t.Unix())\n+}\n+\n+// uniqueBucketName returns a more unique name cloud storage bucket.\n+func uniqueBucketName(prefix, projectID string) string {\n+\tt := time.Now()\n+\tf := fmt.Sprintf(\"%s-%s-%d\", sanitize(prefix, '-'), sanitize(projectID, '-'), t.Unix())\n+\t// bucket max name length is 63 chars, so we truncate.\n+\tif len(f) > 63 {\n+\t\treturn f[:63]\n+\t}\n+\treturn f\n+}\n+\n+func sanitize(s string, allowedSeparator rune) string {\n+\tpattern := fmt.Sprintf(\"[^a-zA-Z0-9%s]\", string(allowedSeparator))\n+\treg, err := regexp.Compile(pattern)\n+\tif err != nil {\n+\t\treturn s\n+\t}\n+\treturn reg.ReplaceAllString(s, \"\")\n+}\n func TestAll(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -27,7 +53,7 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \n-\tdatasetID := fmt.Sprintf(\"golang_example_dataset_%d\", time.Now().Unix())\n+\tdatasetID := uniqueBQName(\"golang_example_dataset\")\n \tif err := createDataset(client, datasetID); err != nil {\n \t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -39,7 +65,7 @@\nfunc TestAll(t *testing.T) {\n \t}\n \n \t// Test empty dataset creation/ttl/delete.\n-\tdeletionDatasetID := fmt.Sprintf(\"%s_quickdelete\", datasetID)\n+\tdeletionDatasetID := uniqueBQName(\"golang_example_quickdelete\")\n \tif err := createDataset(client, deletionDatasetID); err != nil {\n \t\tt.Errorf(\"createDataset(%q): %v\", deletionDatasetID, err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -57,9 +83,9 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"listDatasets: %v\", err)\n \t}\n \n-\tinferred := fmt.Sprintf(\"golang_example_table_inferred_%d\", time.Now().Unix())\n-\texplicit := fmt.Sprintf(\"golang_example_table_explicit_%d\", time.Now().Unix())\n-\tempty := fmt.Sprintf(\"golang_example_table_emptyschema_%d\", time.Now().Unix())\n+\tinferred := uniqueBQName(\"golang_example_table_inferred\")\n+\texplicit := uniqueBQName(\"golang_example_table_explicit\")\n+\tempty := uniqueBQName(\"golang_example_table_emptyschema\")\n \n \tif err := createTableInferredSchema(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"createTableInferredSchema(dataset:%q table:%q): %v\", datasetID, inferred, err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -101,17 +127,14 @@\nfunc TestAll(t *testing.T) {\n \tif err := insertRows(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"insertRows(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := listRows(client, datasetID, inferred); err != nil {\n-\t\tt.Errorf(\"listRows(dataset:%q table:%q): %v\", datasetID, inferred, err)\n-\t}\n \tif err := browseTable(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"browseTable(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n \n \tif err := queryBasic(client); err != nil {\n \t\tt.Errorf(\"queryBasic: %v\", err)\n \t}\n-\tbatchTable := fmt.Sprintf(\"golang_example_batchresults_%d\", time.Now().Unix())\n+\tbatchTable := uniqueBQName(\"golang_example_batchresults\")\n \tif err := queryBatch(client, datasetID, batchTable); err != nil {\n \t\tt.Errorf(\"queryBatch(dataset:%q table:%q): %v\", datasetID, batchTable, err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -125,7 +148,7 @@\nfunc TestAll(t *testing.T) {\n \tif err := queryLegacy(client, sql); err != nil {\n \t\tt.Errorf(\"queryLegacy: %v\", err)\n \t}\n-\tlargeResults := fmt.Sprintf(\"golang_example_legacy_largeresults_%d\", time.Now().Unix())\n+\tlargeResults := uniqueBQName(\"golang_example_legacy_largeresults\")\n \tif err := queryLegacyLargeResults(client, datasetID, largeResults); err != nil {\n \t\tt.Errorf(\"queryLegacyLargeResults(dataset:%q table:%q): %v\", datasetID, largeResults, err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -146,7 +169,7 @@\nfunc TestAll(t *testing.T) {\n \t}\n \n \t// Run query variations\n-\tpersisted := fmt.Sprintf(\"golang_example_table_queryresult_%d\", time.Now().Unix())\n+\tpersisted := uniqueBQName(\"golang_example_table_queryresult\")\n \tif err := queryWithDestination(client, datasetID, persisted); err != nil {\n \t\tt.Errorf(\"queryWithDestination(dataset:%q table:%q): %v\", datasetID, persisted, err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -159,7 +182,7 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"printTableInfo(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n \n-\tdstTableID := fmt.Sprintf(\"golang_example_tabledst_%d\", time.Now().Unix())\n+\tdstTableID := uniqueBQName(\"golang_example_tabledst\")\n \tif err := copyTable(client, datasetID, inferred, dstTableID); err != nil {\n \t\tt.Errorf(\"copyTable(dataset:%q src:%q dst:%q): %v\", datasetID, inferred, dstTableID, err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -170,7 +193,7 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"undeleteTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n \t}\n \n-\tdstTableID = fmt.Sprintf(\"golang_multicopydest_%d\", time.Now().Unix())\n+\tdstTableID = uniqueBQName(\"golang_multicopydest\")\n \tif err := copyMultiTable(client, datasetID, dstTableID); err != nil {\n \t\tt.Errorf(\"copyMultiTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "Cleanup",
        "pr_number": 503,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -190,8 +213,8 @@\nfunc TestImportExport(t *testing.T) {\n \t\tt.Fatal(err)\n \t}\n \n-\tdatasetID := fmt.Sprintf(\"golang_example_dataset_importexport_%d\", time.Now().Unix())\n-\ttableID := fmt.Sprintf(\"golang_example_dataset_importexport_%d\", time.Now().Unix())\n+\tdatasetID := uniqueBQName(\"golang_example_dataset_importexport\")\n+\ttableID := uniqueBQName(\"golang_example_dataset_importexport\")\n \tif err := createDataset(client, datasetID); err != nil {\n \t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d4abd6633fe13cd48c85130e760ed7b666d37744"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -305,15 +305,29 @@\nfunc listRows(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n-func basicQuery(client *bigquery.Client, datasetID, tableID string) error {\n+func queryBasic(client *bigquery.Client) error {\n \tctx := context.Background()\n \t// [START bigquery_query]\n+\n \tq := client.Query(\n \t\t\"SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` \" +\n \t\t\t\"WHERE state = \\\"TX\\\" \" +\n \t\t\t\"LIMIT 100\")\n \t// Location must match that of the dataset(s) referenced in the query.\n \tq.Location = \"US\"\n+\t// [END bigquery_query]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryDisableCache(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_no_cache]\n+\n+\tq := client.Query(\n+\t\t\"SELECT corpus FROM `bigquery-public-data.samples.shakespeare` GROUP BY corpus;\")\n+\tq.DisableQueryCache = true\n+\t// Location must match that of the dataset(s) referenced in the query.\n+\tq.Location = \"US\"\n \n \tjob, err := q.Run(ctx)\n \tif err != nil {",
        "comments": [
            {
                "comment": "Nice",
                "position": 329
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -341,70 +355,227 @@\nfunc basicQuery(client *bigquery.Client, datasetID, tableID string) error {\n \t\t}\n \t\tfmt.Println(row)\n \t}\n-\t// [END bigquery_query]\n+\t// [END bigquery_query_no_cache]\n \treturn nil\n }\n \n-func queryWithDestination(client *bigquery.Client, destDatasetID, destTableID string) error {\n+func queryBatch(client *bigquery.Client, dstDatasetID, dstTableID string) error {\n \tctx := context.Background()\n-\t// [START bigquery_query_destination_table]\n-\tdestRef := client.Dataset(destDatasetID).Table(destTableID)\n-\tq := client.Query(\"SELECT 17 as my_col\")\n-\tq.Location = \"US\" // Location must match the dataset(s) referenced in query.\n-\tq.QueryConfig.Dst = destRef\n-\n-\t// Run job, then wait until asyncronous execution is complete.\n+\t// [START bigquery_query_batch]\n+\t// Build an aggregate table.\n+\tq := client.Query(`\n+\t\tSELECT\n+  \t\t\tcorpus,\n+  \t\t\tSUM(word_count) as total_words,\n+  \t\t\tCOUNT(1) as unique_words\n+\t\tFROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+\t\tGROUP BY corpus;`)\n+\tq.Priority = bigquery.BatchPriority\n+\tq.QueryConfig.Dst = client.Dataset(dstDatasetID).Table(dstTableID)\n+\n+\t// Start the job.\n \tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tstatus, err := job.Wait(ctx)\n+\t// Job is started and will progress without interaction.\n+\t// To simulate other work being done, sleep a few seconds.\n+\ttime.Sleep(5 * time.Second)\n+\tstatus, err := job.Status(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tif err := status.Err(); err != nil {\n-\t\treturn err\n-\t}\n-\t// At this point, the query has completed and results are persisted to the\n-\t// destination table.  You can also choose to read from the table.\n-\tit, err := job.Read(ctx)\n-\tfor {\n-\t\tvar row []bigquery.Value\n-\t\terr := it.Next(&row)\n-\t\tif err == iterator.Done {\n-\t\t\tbreak\n-\t\t}\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t\tfmt.Println(row)\n+\n+\tstate := \"Unknown\"\n+\tswitch status.State {\n+\tcase bigquery.Pending:\n+\t\tstate = \"Pending\"\n+\tcase bigquery.Running:\n+\t\tstate = \"Running\"\n+\tcase bigquery.Done:\n+\t\tstate = \"Done\"\n \t}\n-\t// [END bigquery_query_destination_table]\n+\t// You can continue to monitor job progress until it reaches\n+\t// the Done state by polling periodically.  In this example,\n+\t// we print the latest status.\n+\tfmt.Printf(\"Job %s in Location %s currently in state: %s\\n\", job.ID(), job.Location(), state)\n+\n+\t// [END bigquery_query_batch]\n+\tjob.Cancel(ctx)\n \treturn nil\n }\n \n-func queryLegacy(client *bigquery.Client, sqlString string) error {\n+func queryDryRun(client *bigquery.Client) error {\n \tctx := context.Background()\n-\t// [START bigquery_query_legacy]\n-\tq := client.Query(sqlString)\n-\tq.UseLegacySQL = true\n+\t// [START bigquery_query_dry_run]\n+\tq := client.Query(`\n+\t\tSELECT \n+\t\t   name,\n+\t\t   COUNT(*) as name_count\n+\t\tFROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n+\t\tWHERE state = 'WA' \n+\t\tGROUP BY name\n+\t\t`)\n+\tq.DryRun = true\n+\t// Location must match that of the dataset(s) referenced in the query.\n+\tq.Location = \"US\"\n \n-\t// Run job, then wait until asyncronous execution is complete.\n \tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tstatus, err := job.Wait(ctx)\n+\t// Dry run is not asynchronous, so get the latest status and statistics.\n+\tstatus := job.LastStatus()\n \tif err != nil {\n \t\treturn err\n \t}\n-\tif err := status.Err(); err != nil {\n-\t\treturn err\n-\t}\n-\t// [END bigquery_query_legacy]\n+\tfmt.Printf(\"This query will process %d bytes\\n\", status.Statistics.TotalBytesProcessed)\n+\n+\t// [END bigquery_query_dry_run]\n \treturn nil\n }\n \n+func queryWithDestination(client *bigquery.Client, destDatasetID, destTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_destination_table]\n+\n+\tq := client.Query(\"SELECT 17 as my_col\")\n+\tq.Location = \"US\" // Location must match the dataset(s) referenced in query.\n+\tq.QueryConfig.Dst = client.Dataset(destDatasetID).Table(destTableID)\n+\t// [END bigquery_query_destination_table]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryLegacy(client *bigquery.Client, sqlString string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_legacy]\n+\tq := client.Query(sqlString)\n+\tq.UseLegacySQL = true\n+\n+\t// [END bigquery_query_legacy]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryLegacyLargeResults(client *bigquery.Client, dstDatasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_legacy_large_results]\n+\tq := client.Query(\n+\t\t\"SELECT corpus FROM [bigquery-public-data:samples.shakespeare] GROUP BY corpus;\")\n+\tq.UseLegacySQL = true\n+\tq.AllowLargeResults = true\n+\tq.QueryConfig.Dst = client.Dataset(dstDatasetID).Table(dstTableID)\n+\t// [END bigquery_query_legacy_large_results]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithArrayParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_arrays]\n+\tq := client.Query(\n+\t\t`SELECT\n+\t\t\tname,\n+\t\t\tsum(number) as count \n+        FROM ` + \"`bigquery-public-data.usa_names.usa_1910_2013`\" + `\n+\t\tWHERE\n+\t\t\tgender = @gender\n+        \tAND state IN UNNEST(@states)\n+\t\tGROUP BY\n+\t\t\tname\n+\t\tORDER BY\n+\t\t\tcount DESC\n+\t\tLIMIT 10;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"gender\",\n+\t\t\tValue: \"M\",\n+\t\t},\n+\t\t{\n+\t\t\tName:  \"states\",\n+\t\t\tValue: []string{\"WA\", \"WI\", \"WV\", \"WY\"},\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_arrays]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithNamedParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_named]\n+\tq := client.Query(\n+\t\t`SELECT word, word_count\n+        FROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+        WHERE corpus = @corpus\n+        AND word_count >= @min_word_count\n+        ORDER BY word_count DESC;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"corpus\",\n+\t\t\tValue: \"romeoandjuliet\",\n+\t\t},\n+\t\t{\n+\t\t\tName:  \"min_word_count\",\n+\t\t\tValue: 250,\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_named]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithPositionalParams(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_positional]\n+\tq := client.Query(\n+\t\t`SELECT word, word_count\n+        FROM ` + \"`bigquery-public-data.samples.shakespeare`\" + `\n+        WHERE corpus = ?\n+        AND word_count >= ?\n+        ORDER BY word_count DESC;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tValue: \"romeoandjuliet\",\n+\t\t},\n+\t\t{\n+\t\t\tValue: 250,\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_positional]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithTimestampParam(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_timestamps]\n+\tq := client.Query(\n+\t\t`SELECT TIMESTAMP_ADD(@ts_value, INTERVAL 1 HOUR);`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"ts_value\",\n+\t\t\tValue: time.Date(2016, 12, 7, 8, 0, 0, 0, time.UTC),\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_timestamps]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n+func queryWithStructParam(client *bigquery.Client) error {\n+\tctx := context.Background()\n+\t// [START bigquery_query_params_structs]\n+\ttype MyStruct struct {\n+\t\tX int64\n+\t\tY string\n+\t}\n+\tq := client.Query(\n+\t\t`SELECT @struct_value as s;`)\n+\tq.Parameters = []bigquery.QueryParameter{\n+\t\t{\n+\t\t\tName:  \"struct_value\",\n+\t\t\tValue: MyStruct{X: 1, Y: \"foo\"},\n+\t\t},\n+\t}\n+\t// [END bigquery_query_params_structs]\n+\treturn runAndRead(ctx, client, q)\n+}\n+\n func printTableInfo(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_get_table]",
        "comments": [
            {
                "comment": "Nice. I presume this is slotted for https://cloud.google.com/bigquery/docs/managing-tables#undeletetable ?",
                "position": 369
            },
            {
                "comment": "That's the plan.",
                "position": 369
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -461,6 +632,66 @@\nfunc copyTable(client *bigquery.Client, datasetID, srcID, dstID string) error {\n \treturn nil\n }\n \n+// generateTableCTAS creates a quick table by issuing a CREATE TABLE AS SELECT\n+// query.\n+func generateTableCTAS(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\tq := client.Query(\n+\t\tfmt.Sprintf(\n+\t\t\t`CREATE TABLE %s.%s \n+\t\tAS\n+\t\tSELECT\n+\t\t  2000 + CAST(18 * RAND() as INT64) as year,\n+\t\t  IF(RAND() > 0.5,\"foo\",\"bar\") as token\n+\t\tFROM\n+\t\t  UNNEST(GENERATE_ARRAY(0,5,1)) as r`, datasetID, tableID))\n+\tjob, err := q.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\treturn nil\n+}\n+\n+func copyMultiTable(client *bigquery.Client, datasetID, dstTableID string) error {\n+\tctx := context.Background()\n+\t// Generate some dummy tables via a quick CTAS.\n+\tif err := generateTableCTAS(client, datasetID, \"table1\"); err != nil {\n+\t\treturn err\n+\t}\n+\tif err := generateTableCTAS(client, datasetID, \"table2\"); err != nil {\n+\t\treturn err\n+\t}\n+\t// [START bigquery_copy_table_multiple_source]\n+\tdataset := client.Dataset(datasetID)\n+\n+\tsrcTableIDs := []string{\"table1\", \"table2\"}\n+\tvar tableRefs []*bigquery.Table\n+\tfor _, v := range srcTableIDs {\n+\t\ttableRefs = append(tableRefs, dataset.Table(v))\n+\t}\n+\tcopier := dataset.Table(dstTableID).CopierFrom(tableRefs...)\n+\tcopier.WriteDisposition = bigquery.WriteTruncate\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_copy_table_multiple_source]\n+\treturn nil\n+}\n func deleteTable(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_delete_table]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -472,6 +703,49 @@\nfunc deleteTable(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n+func deleteAndUndeleteTable(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_undelete_table]\n+\n+\tds := client.Dataset(datasetID)\n+\tif _, err := ds.Table(tableID).Metadata(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\t// Record the current time.  We'll use this as the snapshot time\n+\t// for recovering the table.\n+\tsnapTime := time.Now()\n+\n+\t// \"Accidentally\" delete the table.\n+\tif err := client.Dataset(datasetID).Table(tableID).Delete(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Construct the restore-from tableID using a snapshot decorator.\n+\tsnapshotTableID := fmt.Sprintf(\"%s@%d\", tableID, snapTime.UnixNano()/1e6)\n+\t// Choose a new table ID for the recovered table data.\n+\trecoverTableID := fmt.Sprintf(\"%s_recovered\", tableID)\n+\n+\t// Construct and run a copy job.\n+\tcopier := ds.Table(recoverTableID).CopierFrom(ds.Table(snapshotTableID))\n+\tcopier.WriteDisposition = bigquery.WriteTruncate\n+\tjob, err := copier.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := status.Err(); err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// [END bigquery_undelete_table]\n+\tds.Table(recoverTableID).Delete(ctx)\n+\treturn nil\n+\n+}\n+\n func importCSVFromFile(client *bigquery.Client, datasetID, tableID, filename string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_from_file]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -122,8 +122,42 @@\nfunc TestAll(t *testing.T) {\n \tif err := browseTable(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"browseTable(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := basicQuery(client, datasetID, inferred); err != nil {\n-\t\tt.Errorf(\"basicQuery(dataset:%q table:%q): %v\", datasetID, inferred, err)\n+\n+\tif err := queryBasic(client); err != nil {\n+\t\tt.Errorf(\"queryBasic: %v\", err)\n+\t}\n+\tbatchTable := fmt.Sprintf(\"golang_example_batchresults_%d\", time.Now().Unix())\n+\tif err := queryBatch(client, datasetID, batchTable); err != nil {\n+\t\tt.Errorf(\"queryBatch(dataset:%q table:%q): %v\", datasetID, batchTable, err)\n+\t}\n+\tif err := queryDisableCache(client); err != nil {\n+\t\tt.Errorf(\"queryBasicDisableCache: %v\", err)\n+\t}\n+\tif err := queryDryRun(client); err != nil {\n+\t\tt.Errorf(\"queryDryRun: %v\", err)\n+\t}\n+\tsql := \"SELECT 17 as foo\"\n+\tif err := queryLegacy(client, sql); err != nil {\n+\t\tt.Errorf(\"queryLegacy: %v\", err)\n+\t}\n+\tlargeResults := fmt.Sprintf(\"golang_example_legacy_largeresults_%d\", time.Now().Unix())\n+\tif err := queryLegacyLargeResults(client, datasetID, largeResults); err != nil {\n+\t\tt.Errorf(\"queryLegacyLargeResults(dataset:%q table:%q): %v\", datasetID, largeResults, err)\n+\t}\n+\tif err := queryWithArrayParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithArrayParams: %v\", err)\n+\t}\n+\tif err := queryWithNamedParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithNamedParams: %v\", err)\n+\t}\n+\tif err := queryWithPositionalParams(client); err != nil {\n+\t\tt.Errorf(\"queryWithPositionalParams: %v\", err)\n+\t}\n+\tif err := queryWithTimestampParam(client); err != nil {\n+\t\tt.Errorf(\"queryWithTimestampParam: %v\", err)\n+\t}\n+\tif err := queryWithStructParam(client); err != nil {\n+\t\tt.Errorf(\"queryWithStructParam: %v\", err)\n \t}\n \n \t// Run query variations",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "BigQuery: additional snippets",
        "pr_number": 498,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -132,11 +166,6 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"queryWithDestination(dataset:%q table:%q): %v\", datasetID, persisted, err)\n \t}\n \n-\tsql := \"SELECT 17 as foo\"\n-\tif err := queryLegacy(client, sql); err != nil {\n-\t\tt.Errorf(\"queryLegacy: %v\", err)\n-\t}\n-\n \t// Print information about tables (extended and simple).\n \tif err := printTableInfo(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"printTableInfo(dataset:%q table:%q): %v\", datasetID, inferred, err)",
        "comments": [],
        "commit_messages": [
            "BigQuery: additional snippets\n\n[START bigquery_copy_table_multiple_source]\n[START bigquery_query]\n[START bigquery_query_batch]\n[START bigquery_query_destination_table]\n[START bigquery_query_dry_run]\n[START bigquery_query_legacy]\n[START bigquery_query_no_cache]\n[START bigquery_query_params_arrays]\n[START bigquery_query_params_named]\n[START bigquery_query_params_positional]\n[START bigquery_query_params_structs]\n[START bigquery_query_params_timestamps]\n[START bigquery_undelete_table]"
        ],
        "last_commit_sha": "11e2b651b6e6548b1fc23bf513f6f787e0d22580"
    },
    {
        "pr_title": "oauth: add explicit snippets",
        "pr_number": 497,
        "file_name": "auth/snippets.go",
        "code_diff": "@@ -14,12 +14,14 @@\nimport (\n \t\"golang.org/x/oauth2/google\"\n \tcloudkms \"google.golang.org/api/cloudkms/v1\"\n \t\"google.golang.org/api/iterator\"\n+\t\"google.golang.org/api/option\"\n )\n \n-func adc() {\n-\tctx := context.Background()\n+// [START auth_cloud_implicit]\n \n-\t// [START auth_cloud_implicit]\n+// implicit uses Application Default Credentials to authenticate.\n+func implicit() {\n+\tctx := context.Background()\n \n \t// For API packages whose import path is starting with \"cloud.google.com/go\",\n \t// such as cloud.google.com/go/storage in this case, if there are no credentials",
        "comments": [],
        "commit_messages": [
            "auth: add explicit snippets"
        ],
        "last_commit_sha": "c45537f3068924a11a11eb823e517a406f29d012"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "videointelligence/video_analyze/video_analyze.go",
        "code_diff": "@@ -16,6 +16,8 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n+// [START video_analyze_labels_local]\n+\n func label(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -15,6 +15,8 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n+// [START video_analyze_labels_gcs]\n+\n func labelURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -63,6 +65,10 @@\nfunc labelURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [END video_analyze_labels_gcs]\n+\n+// [START video_analyze_shots]\n+\n func shotChangeURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Update Video Detect region tags.",
        "pr_number": 494,
        "file_name": "videointelligence/video_analyze/video_analyze_gcs.go",
        "code_diff": "@@ -97,6 +103,10 @@\nfunc shotChangeURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [START video_analyze_shots]\n+\n+// [START video_analyze_explicit_content]\n+\n func explicitContentURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \tclient, err := video.NewClient(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "16ebf2e419a2f342aae929e769055b58a8eb3393"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -28,40 +28,40 @@\ntype Task struct {\n }\n \n func SnippetNewIncompleteKey() {\n-\t// [START incomplete_key]\n+\t// [START datastore_incomplete_key]\n \ttaskKey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [END incomplete_key]\n+\t// [END datastore_incomplete_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey() {\n-\t// [START named_key]\n+\t// [START datastore_named_key]\n \ttaskKey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [END named_key]\n+\t// [END datastore_named_key]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withParent() {\n-\t// [START key_with_parent]\n+\t// [START datastore_key_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_parent]\n+\t// [END datastore_key_with_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetNewKey_withMultipleParents() {\n-\t// [START key_with_multilevel_parent]\n+\t// [START datastore_key_with_multilevel_parent]\n \tuserKey := datastore.NameKey(\"User\", \"alice\", nil)\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", userKey)\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", parentKey)\n-\t// [END key_with_multilevel_parent]\n+\t// [END datastore_key_with_multilevel_parent]\n \t_ = taskKey // Use the task key for datastore operations.\n }\n \n func SnippetClient_Put() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START entity_with_parent]\n+\t// [START datastore_entity_with_parent]\n \tparentKey := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tkey := datastore.IncompleteKey(\"Task\", parentKey)",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -75,12 +75,12 @@\nfunc SnippetClient_Put() {\n \t// A complete key is assigned to the entity when it is Put.\n \tvar err error\n \tkey, err = client.Put(ctx, key, &task)\n-\t// [END entity_with_parent]\n+\t// [END datastore_entity_with_parent]\n \t_ = err // Make sure you check err.\n }\n \n func Snippet_properties() {\n-\t// [START properties]\n+\t// [START datastore_properties]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -97,12 +97,12 @@\nfunc Snippet_properties() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END properties]\n+\t// [END datastore_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_sliceProperties() {\n-\t// [START array_value]\n+\t// [START datastore_array_value]\n \ttype Task struct {\n \t\tTags          []string\n \t\tCollaborators []string",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -111,12 +111,12 @@\nfunc Snippet_sliceProperties() {\n \t\tTags:          []string{\"fun\", \"programming\"},\n \t\tCollaborators: []string{\"alice\", \"bob\"},\n \t}\n-\t// [END array_value]\n+\t// [END datastore_array_value]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_basicEntity() {\n-\t// [START basic_entity]\n+\t// [START datastore_basic_entity]\n \ttype Task struct {\n \t\tCategory        string\n \t\tDone            bool",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -133,7 +133,7 @@\nfunc Snippet_basicEntity() {\n \t\tPercentComplete: 10.0,\n \t\tCreated:         time.Now(),\n \t}\n-\t// [END basic_entity]\n+\t// [END datastore_basic_entity]\n \t_ = task // Use the task in a datastore Put operation.\n }",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -142,9 +142,9 @@\nfunc SnippetClient_Put_upsert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := &Task{} // Populated with appropriate data.\n \tkey := datastore.IncompleteKey(\"Task\", nil)\n-\t// [START upsert]\n+\t// [START datastore_upsert]\n \tkey, err := client.Put(ctx, key, task)\n-\t// [END upsert]\n+\t// [END datastore_upsert]\n \t_ = err // Make sure you check err.\n \t_ = key // key is the complete key for the newly stored task\n }",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -154,7 +154,7 @@\nfunc SnippetTransaction_insert() {\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttask := Task{} // Populated with appropriate data.\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START insert]\n+\t// [START datastore_insert]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\t// We first check that there is no entity stored with the given key.\n \t\tvar empty Task",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -165,26 +165,26 @@\nfunc SnippetTransaction_insert() {\n \t\t_, err := tx.Put(taskKey, &task)\n \t\treturn err\n \t})\n-\t// [END insert]\n+\t// [END datastore_insert]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_Get() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START lookup]\n+\t// [START datastore_lookup]\n \tvar task Task\n \terr := client.Get(ctx, taskKey, &task)\n-\t// [END lookup]\n+\t// [END datastore_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetTransaction_update() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \ttaskKey := datastore.NameKey(\"Task\", \"sampleTask\", nil)\n-\t// [START update]\n+\t// [START datastore_update]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -200,23 +200,23 @@\nfunc SnippetTransaction_update() {\n \tif _, err := tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END update]\n+\t// [END datastore_update]\n }\n \n func SnippetClient_Delete() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START delete]\n+\t// [START datastore_delete]\n \terr := client.Delete(ctx, key)\n-\t// [END delete]\n+\t// [END datastore_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_PutMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START batch_upsert]\n+\t// [START datastore_batch_upsert]\n \ttasks := []*Task{\n \t\t{\n \t\t\tCategory:    \"Personal\",",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -237,7 +237,7 @@\nfunc SnippetClient_PutMulti() {\n \t}\n \n \tkeys, err := client.PutMulti(ctx, keys, tasks)\n-\t// [END batch_upsert]\n+\t// [END datastore_batch_upsert]\n \t_ = err  // Make sure you check err.\n \t_ = keys // keys now has the complete keys for the newly stored tasks.\n }",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -246,33 +246,33 @@\nfunc SnippetClient_GetMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_lookup]\n+\t// [START datastore_batch_lookup]\n \tvar tasks []*Task\n \terr := client.GetMulti(ctx, taskKeys, &tasks)\n-\t// [END batch_lookup]\n+\t// [END datastore_batch_lookup]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetClient_DeleteMulti() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar taskKeys []*datastore.Key // Populated with incomplete keys.\n-\t// [START batch_delete]\n+\t// [START datastore_batch_delete]\n \terr := client.DeleteMulti(ctx, taskKeys)\n-\t// [END batch_delete]\n+\t// [END datastore_batch_delete]\n \t_ = err // Make sure you check err.\n }\n \n func SnippetQuery_basic() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START basic_query]\n+\t// [START datastore_basic_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Priority >=\", 4).\n \t\tOrder(\"-Priority\")\n-\t// [END basic_query]\n-\t// [START run_query]\n+\t// [END datastore_basic_query]\n+\t// [START datastore_run_query]\n \tit := client.Run(ctx, query)\n \tfor {\n \t\tvar task Task",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -285,75 +285,75 @@\nfunc SnippetQuery_basic() {\n \t\t}\n \t\tfmt.Printf(\"Task %q, Priority %d\\n\", task.Description, task.Priority)\n \t}\n-\t// [END run_query]\n+\t// [END datastore_run_query]\n }\n \n func SnippetQuery_propertyFilter() {\n-\t// [START property_filter]\n+\t// [START datastore_property_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false)\n-\t// [END property_filter]\n+\t// [END datastore_property_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_compositeFilter() {\n-\t// [START composite_filter]\n+\t// [START datastore_composite_filter]\n \tquery := datastore.NewQuery(\"Task\").Filter(\"Done =\", false).Filter(\"Priority =\", 4)\n-\t// [END composite_filter]\n+\t// [END datastore_composite_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_keyFilter() {\n-\t// [START key_filter]\n+\t// [START datastore_key_filter]\n \tkey := datastore.NameKey(\"Task\", \"someTask\", nil)\n \tquery := datastore.NewQuery(\"Task\").Filter(\"__key__ >\", key)\n-\t// [END key_filter]\n+\t// [END datastore_key_filter]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortAscending() {\n-\t// [START ascending_sort]\n+\t// [START datastore_ascending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"created\")\n-\t// [END ascending_sort]\n+\t// [END datastore_ascending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortDescending() {\n-\t// [START descending_sort]\n+\t// [START datastore_descending_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-created\")\n-\t// [END descending_sort]\n+\t// [END datastore_descending_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_sortMulti() {\n-\t// [START multi_sort]\n+\t// [START datastore_multi_sort]\n \tquery := datastore.NewQuery(\"Task\").Order(\"-priority\").Order(\"created\")\n-\t// [END multi_sort]\n+\t// [END datastore_multi_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_kindless() {\n \tvar lastSeenKey *datastore.Key\n-\t// [START kindless_query]\n+\t// [START datastore_kindless_query]\n \tquery := datastore.NewQuery(\"\").Filter(\"__key__ >\", lastSeenKey)\n-\t// [END kindless_query]\n+\t// [END datastore_kindless_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Ancestor() {\n-\t// [START ancestor_query]\n+\t// [START datastore_ancestor_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor)\n-\t// [END ancestor_query]\n+\t// [END datastore_ancestor_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Project() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START projection_query]\n+\t// [START datastore_projection_query]\n \tquery := datastore.NewQuery(\"Task\").Project(\"Priority\", \"PercentComplete\")\n-\t// [END projection_query]\n-\t// [START run_query_projection]\n+\t// [END datastore_projection_query]\n+\t// [START datastore_run_query_projection]\n \tvar priorities []int\n \tvar percents []float64\n \tit := client.Run(ctx, query)",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -367,130 +367,130 @@\nfunc SnippetQuery_Project() {\n \t\tpriorities = append(priorities, task.Priority)\n \t\tpercents = append(percents, task.PercentComplete)\n \t}\n-\t// [END run_query_projection]\n+\t// [END datastore_run_query_projection]\n }\n \n func SnippetQuery_KeysOnly() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START keys_only_query]\n+\t// [START datastore_keys_only_query]\n \tquery := datastore.NewQuery(\"Task\").KeysOnly()\n-\t// [END keys_only_query]\n-\t// [START run_keys_only_query]\n+\t// [END datastore_keys_only_query]\n+\t// [START datastore_run_keys_only_query]\n \tkeys, err := client.GetAll(ctx, query, nil)\n-\t// [END run_keys_only_query]\n+\t// [END datastore_run_keys_only_query]\n \t_ = err  // Make sure you check err.\n \t_ = keys // Keys contains keys for all stored tasks.\n }\n \n func SnippetQuery_Distinct() {\n-\t// [START distinct_query]\n+\t// [START datastore_distinct_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tProject(\"Priority\", \"PercentComplete\").\n \t\tDistinct().\n \t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_query]\n+\t// [END datastore_distinct_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_DistinctOn() {\n-\t// [START distinct_on_query]\n+\t// [START datastore_distinct_on_query]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tProject(\"Priority\", \"Category\").\n \t\tDistinctOn(\"Category\").\n \t\tOrder(\"Category\").Order(\"Priority\")\n-\t// [END distinct_on_query]\n+\t// [END datastore_distinct_on_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayInequality() {\n-\t// [START array_value_inequality_range]\n+\t// [START datastore_array_value_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag >\", \"learn\").\n \t\tFilter(\"Tag <\", \"math\")\n-\t// [END array_value_inequality_range]\n+\t// [END datastore_array_value_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_arrayEquality() {\n-\t// [START array_value_equality]\n+\t// [START datastore_array_value_equality]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Tag =\", \"fun\").\n \t\tFilter(\"Tag =\", \"programming\")\n-\t// [END array_value_equality]\n+\t// [END datastore_array_value_equality]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_inequality() {\n-\t// [START inequality_range]\n+\t// [START datastore_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END inequality_range]\n+\t// [END datastore_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_Filter_invalidInequality() {\n-\t// [START inequality_invalid]\n+\t// [START datastore_inequality_invalid]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Priority >\", 3)\n-\t// [END inequality_invalid]\n+\t// [END datastore_inequality_invalid]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Filter_mixed() {\n-\t// [START equal_and_inequality_range]\n+\t// [START datastore_equal_and_inequality_range]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority =\", 4).\n \t\tFilter(\"Done =\", false).\n \t\tFilter(\"Created >\", time.Date(1990, 1, 1, 0, 0, 0, 0, time.UTC)).\n \t\tFilter(\"Created <\", time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC))\n-\t// [END equal_and_inequality_range]\n+\t// [END datastore_equal_and_inequality_range]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_inequalitySort() {\n-\t// [START inequality_sort]\n+\t// [START datastore_inequality_sort]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Priority\").\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort]\n+\t// [END datastore_inequality_sort]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_invalidInequalitySortA() {\n-\t// [START inequality_sort_invalid_not_same]\n+\t// [START datastore_inequality_sort_invalid_not_same]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\")\n-\t// [END inequality_sort_invalid_not_same]\n+\t// [END datastore_inequality_sort_invalid_not_same]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_invalidInequalitySortB() {\n-\t// [START inequality_sort_invalid_not_first]\n+\t// [START datastore_inequality_sort_invalid_not_first]\n \tquery := datastore.NewQuery(\"Task\").\n \t\tFilter(\"Priority >\", 3).\n \t\tOrder(\"Created\").\n \t\tOrder(\"Priority\")\n-\t// [END inequality_sort_invalid_not_first]\n+\t// [END datastore_inequality_sort_invalid_not_first]\n \t_ = query // The query is invalid.\n }\n \n func SnippetQuery_Limit() {\n-\t// [START limit]\n+\t// [START datastore_limit]\n \tquery := datastore.NewQuery(\"Task\").Limit(5)\n-\t// [END limit]\n+\t// [END datastore_limit]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetIterator_Cursor() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tcursorStr := \"\"\n-\t// [START cursor_paging]\n+\t// [START datastore_cursor_paging]\n \tconst pageSize = 5\n \tquery := datastore.NewQuery(\"Tasks\").Limit(pageSize)\n \tif cursorStr != \"\" {",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -516,42 +516,42 @@\nfunc SnippetIterator_Cursor() {\n \n \t// Get the cursor for the next page of results.\n \tnextCursor, err := it.Cursor()\n-\t// [END cursor_paging]\n+\t// [END datastore_cursor_paging]\n \t_ = err        // Check the error.\n \t_ = nextCursor // Use nextCursor.String as the next page's token.\n }\n \n func SnippetQuery_EventualConsistency() {\n-\t// [START eventual_consistent_query]\n+\t// [START datastore_eventual_consistent_query]\n \tancestor := datastore.NameKey(\"TaskList\", \"default\", nil)\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).EventualConsistency()\n-\t// [END eventual_consistent_query]\n+\t// [END datastore_eventual_consistent_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func SnippetQuery_unindexed() {\n-\t// [START unindexed_property_query]\n+\t// [START datastore_unindexed_property_query]\n \tquery := datastore.NewQuery(\"Tasks\").Filter(\"Description =\", \"A task description\")\n-\t// [END unindexed_property_query]\n+\t// [END datastore_unindexed_property_query]\n \t_ = query // Use client.Run or client.GetAll to execute the query.\n }\n \n func Snippet_explodingProperties() {\n-\t// [START exploding_properties]\n+\t// [START datastore_exploding_properties]\n \ttask := &Task{\n \t\tTags:          []string{\"fun\", \"programming\", \"learn\"},\n \t\tCollaborators: []string{\"alice\", \"bob\", \"charlie\"},\n \t\tCreated:       time.Now(),\n \t}\n-\t// [END exploding_properties]\n+\t// [END datastore_exploding_properties]\n \t_ = task // Use the task in a datastore Put operation.\n }\n \n func Snippet_Transaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_update]\n+\t// [START datastore_transactional_update]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -576,14 +576,14 @@\nfunc Snippet_Transaction() {\n \tif _, err = tx.Commit(); err != nil {\n \t\tlog.Fatalf(\"tx.Commit: %v\", err)\n \t}\n-\t// [END transactional_update]\n+\t// [END datastore_transactional_update]\n }\n \n func Snippet_Client_RunInTransaction() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tvar to, from *datastore.Key\n-\t// [START transactional_retry]\n+\t// [START datastore_transactional_retry]\n \ttype BankAccount struct {\n \t\tBalance int\n \t}",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -600,15 +600,15 @@\nfunc Snippet_Client_RunInTransaction() {\n \t\t_, err := tx.PutMulti(keys, accs)\n \t\treturn err\n \t})\n-\t// [END transactional_retry]\n+\t// [END datastore_transactional_retry]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_getOrCreate() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n \tkey := datastore.NameKey(\"Task\", \"sampletask\", nil)\n-\t// [START transactional_get_or_create]\n+\t// [START datastore_transactional_get_or_create]\n \t_, err := client.RunInTransaction(ctx, func(tx *datastore.Transaction) error {\n \t\tvar task Task\n \t\tif err := tx.Get(key, &task); err != datastore.ErrNoSuchEntity {",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -622,14 +622,14 @@\nfunc SnippetTransaction_getOrCreate() {\n \t\t})\n \t\treturn err\n \t})\n-\t// [END transactional_get_or_create]\n+\t// [END datastore_transactional_get_or_create]\n \t_ = err // Check error.\n }\n \n func SnippetTransaction_runQuery() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START transactional_single_entity_group_read_only]\n+\t// [START datastore_transactional_single_entity_group_read_only]\n \ttx, err := client.NewTransaction(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"client.NewTransaction: %v\", err)",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -640,14 +640,14 @@\nfunc SnippetTransaction_runQuery() {\n \tquery := datastore.NewQuery(\"Task\").Ancestor(ancestor).Transaction(tx)\n \tvar tasks []Task\n \t_, err = client.GetAll(ctx, query, &tasks)\n-\t// [END transactional_single_entity_group_read_only]\n+\t// [END datastore_transactional_single_entity_group_read_only]\n \t_ = err // Check error.\n }\n \n func Snippet_metadataNamespaces() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START namespace_run_query]\n+\t// [START datastore_namespace_run_query]\n \tconst (\n \t\tstartNamespace = \"g\"\n \t\tendNamespace   = \"h\"",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -665,13 +665,13 @@\nfunc Snippet_metadataNamespaces() {\n \tfor _, k := range keys {\n \t\tnamespaces = append(namespaces, k.Name)\n \t}\n-\t// [END namespace_run_query]\n+\t// [END datastore_namespace_run_query]\n }\n \n func Snippet_metadataKinds() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START kind_run_query]\n+\t// [START datastore_kind_run_query]\n \tquery := datastore.NewQuery(\"__kind__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -682,13 +682,13 @@\nfunc Snippet_metadataKinds() {\n \tfor _, k := range keys {\n \t\tkinds = append(kinds, k.Name)\n \t}\n-\t// [END kind_run_query]\n+\t// [END datastore_kind_run_query]\n }\n \n func Snippet_metadataProperties() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_run_query]\n+\t// [START datastore_property_run_query]\n \tquery := datastore.NewQuery(\"__property__\").KeysOnly()\n \tkeys, err := client.GetAll(ctx, query, nil)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/snippets/snippet_test.go",
        "code_diff": "@@ -701,13 +701,13 @@\nfunc Snippet_metadataProperties() {\n \t\tkind := k.Parent.Name\n \t\tprops[kind] = append(props[kind], prop)\n \t}\n-\t// [END property_run_query]\n+\t// [END datastore_property_run_query]\n }\n \n func Snippet_metadataPropertiesForKind() {\n \tctx := context.Background()\n \tclient, _ := datastore.NewClient(ctx, \"my-proj\")\n-\t// [START property_by_kind_run_query]\n+\t// [START datastore_property_by_kind_run_query]\n \tkindKey := datastore.NameKey(\"__kind__\", \"Task\", nil)\n \tquery := datastore.NewQuery(\"__property__\").Ancestor(kindKey)",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -2,7 +2,7 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// [START all]\n+// [START datastore_all]\n \n // A simple command-line task list manager to demonstrate using the\n // cloud.google.com/go/datastore package.",
        "comments": [
            {
                "comment": "Is this the canonical name of this region?",
                "position": 5
            },
            {
                "comment": "I'm not sure if this is used at all, but am fixing it now incase it is used in the future.",
                "position": 5
            }
        ],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -29,10 +29,10 @@\nfunc main() {\n \tif projID == \"\" {\n \t\tlog.Fatal(`You need to set the environment variable \"DATASTORE_PROJECT_ID\"`)\n \t}\n-\t// [START build_service]\n+\t// [START datastore_build_service]\n \tctx := context.Background()\n \tclient, err := datastore.NewClient(ctx, projID)\n-\t// [END build_service]\n+\t// [END datastore_build_service]\n \tif err != nil {\n \t\tlog.Fatalf(\"Could not create datastore client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -107,7 +107,7 @@\nfunc main() {\n \t}\n }\n \n-// [START add_entity]\n+// [START datastore_add_entity]\n // Task is the model used to store tasks in the datastore.\n type Task struct {\n \tDesc    string    `datastore:\"description\"`",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -127,9 +127,9 @@\nfunc AddTask(ctx context.Context, client *datastore.Client, desc string) (*datas\n \treturn client.Put(ctx, key, task)\n }\n \n-// [END add_entity]\n+// [END datastore_add_entity]\n \n-// [START update_entity]\n+// [START datastore_update_entity]\n // MarkDone marks the task done with the given ID.\n func MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error {\n \t// Create a key using the given integer ID.",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -148,9 +148,9 @@\nfunc MarkDone(ctx context.Context, client *datastore.Client, taskID int64) error\n \treturn err\n }\n \n-// [END update_entity]\n+// [END datastore_update_entity]\n \n-// [START retrieve_entities]\n+// [START datastore_retrieve_entities]\n // ListTasks returns all the tasks in ascending order of creation time.\n func ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \tvar tasks []*Task",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -170,17 +170,17 @@\nfunc ListTasks(ctx context.Context, client *datastore.Client) ([]*Task, error) {\n \treturn tasks, nil\n }\n \n-// [END retrieve_entities]\n+// [END datastore_retrieve_entities]\n \n-// [START delete_entity]\n+// [START datastore_delete_entity]\n // DeleteTask deletes the task with the given ID.\n func DeleteTask(ctx context.Context, client *datastore.Client, taskID int64) error {\n \treturn client.Delete(ctx, datastore.IDKey(\"Task\", taskID, nil))\n }\n \n-// [END delete_entity]\n+// [END datastore_delete_entity]\n \n-// [START format_results]\n+// [START datastore_format_results]\n // PrintTasks prints the tasks to the given writer.\n func PrintTasks(w io.Writer, tasks []*Task) {\n \t// Use a tab writer to help make results pretty.",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "Updating all the region tags to have a prefix of datastore",
        "pr_number": 493,
        "file_name": "datastore/tasks/tasks.go",
        "code_diff": "@@ -196,7 +196,7 @@\nfunc PrintTasks(w io.Writer, tasks []*Task) {\n \ttw.Flush()\n }\n \n-// [END format_results]\n+// [END datastore_format_results]\n \n func usage() {\n \tfmt.Print(`Usage:",
        "comments": [],
        "commit_messages": [
            "[DO NOT MERGE] Updating all the region tags to have a prefix of datastore"
        ],
        "last_commit_sha": "f80fd75977e6d7d31e10f7f8248d598864cd79a7"
    },
    {
        "pr_title": "translate: Add region tags for Translate samples",
        "pr_number": 492,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -38,6 +38,8 @@\nfunc createClientWithKey() {\n \tfmt.Printf(\"%#v\", resp)\n }\n \n+// [START translate_translate_text]\n+\n func translateText(targetLanguage, text string) (string, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "translate: add region tags"
        ],
        "last_commit_sha": "922fe1ef4e1a9ae64844c71bebf53c70af6cf10f"
    },
    {
        "pr_title": "translate: Add region tags for Translate samples",
        "pr_number": 492,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -59,6 +61,9 @@\nfunc translateText(targetLanguage, text string) (string, error) {\n \treturn resp[0].Text, nil\n }\n \n+// [END translate_translate_text]\n+// [START translate_detect_language]\n+\n func detectLanguage(text string) (*translate.Detection, error) {\n \tctx := context.Background()\n \tclient, err := translate.NewClient(ctx)",
        "comments": [],
        "commit_messages": [
            "translate: add region tags"
        ],
        "last_commit_sha": "922fe1ef4e1a9ae64844c71bebf53c70af6cf10f"
    },
    {
        "pr_title": "translate: Add region tags for Translate samples",
        "pr_number": 492,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -74,6 +79,10 @@\nfunc detectLanguage(text string) (*translate.Detection, error) {\n \treturn &lang[0][0], nil\n }\n \n+// [END translate_detect_language]\n+// [START translate_list_codes]\n+// [START translate_list_language_names]\n+\n func listSupportedLanguages(w io.Writer, targetLanguage string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "translate: add region tags"
        ],
        "last_commit_sha": "922fe1ef4e1a9ae64844c71bebf53c70af6cf10f"
    },
    {
        "pr_title": "translate: Add region tags for Translate samples",
        "pr_number": 492,
        "file_name": "translate/snippets/snippet.go",
        "code_diff": "@@ -100,6 +109,11 @@\nfunc listSupportedLanguages(w io.Writer, targetLanguage string) error {\n \treturn nil\n }\n \n+// [END translate_list_language_names]\n+// [END translate_list_codes]\n+\n+// [START translate_text_with_model]\n+\n func translateTextWithModel(targetLanguage, text, model string) (string, error) {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "translate: add region tags"
        ],
        "last_commit_sha": "922fe1ef4e1a9ae64844c71bebf53c70af6cf10f"
    },
    {
        "pr_title": "BigQuery:  more snippets",
        "pr_number": 476,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -116,6 +116,39 @@\nfunc listDatasets(client *bigquery.Client) error {\n \treturn nil\n }\n \n+func printDatasetInfo(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_dataset]\n+\tmeta, err := client.Dataset(datasetID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tfmt.Printf(\"Dataset ID: %s\\n\", datasetID)\n+\tfmt.Printf(\"Description: %s\\n\", meta.Description)\n+\tfmt.Println(\"Labels:\")\n+\tfor k, v := range meta.Labels {\n+\t\tfmt.Printf(\"\\t%s: %s\", k, v)\n+\t}\n+\tfmt.Println(\"Tables:\")\n+\tit := client.Dataset(datasetID).Tables(ctx)\n+\n+\tcnt := 0\n+\tfor {\n+\t\tt, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tcnt++\n+\t\tfmt.Printf(\"\\t%s\\n\", t.TableID)\n+\t}\n+\tif cnt == 0 {\n+\t\tfmt.Println(\"\\tThis dataset does not contain any tables.\")\n+\t}\n+\t// [END bigquery_get_dataset]\n+\treturn nil\n+}\n+\n // Item represents a row item.\n type Item struct {\n \tName string",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "badab496b6d78c5b1296af6aa014b562b316c0c0"
    },
    {
        "pr_title": "BigQuery:  more snippets",
        "pr_number": 476,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -17,8 +17,6 @@\nimport (\n \t\"cloud.google.com/go/storage\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n \t\"golang.org/x/net/context\"\n-\t\"golang.org/x/oauth2/google\"\n-\trawbq \"google.golang.org/api/bigquery/v2\"\n \t\"google.golang.org/api/iterator\"\n )",
        "comments": [],
        "commit_messages": [
            "BigQuery:  more snippets and regions"
        ],
        "last_commit_sha": "badab496b6d78c5b1296af6aa014b562b316c0c0"
    },
    {
        "pr_title": "BigQuery:  more snippets",
        "pr_number": 476,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -48,6 +46,8 @@\nfunc TestAll(t *testing.T) {\n \tif err := createDataset(client, datasetID); err != nil {\n \t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n \t}\n+\t// Cleanup dataset at end of test.\n+\tdefer client.Dataset(datasetID).DeleteWithContents(ctx)\n \n \tif err := updateDatasetAccessControl(client, datasetID); err != nil {\n \t\tt.Errorf(\"updateDataSetAccessControl(%q): %v\", datasetID, err)",
        "comments": [],
        "commit_messages": [
            "Address reviewer comments."
        ],
        "last_commit_sha": "badab496b6d78c5b1296af6aa014b562b316c0c0"
    },
    {
        "pr_title": "BigQuery:  more snippets",
        "pr_number": 476,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -108,6 +108,10 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"want table list %q to contain table %q\", got, empty)\n \t}\n \n+\tif err := printDatasetInfo(client, datasetID); err != nil {\n+\t\tt.Errorf(\"printDatasetInfo: %v\", err)\n+\t}\n+\n \t// Stream data, read, query the inferred schema table.\n \tif err := insertRows(client, datasetID, inferred); err != nil {\n \t\tt.Errorf(\"insertRows(dataset:%q table:%q): %v\", datasetID, inferred, err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "badab496b6d78c5b1296af6aa014b562b316c0c0"
    },
    {
        "pr_title": "BigQuery:  more snippets",
        "pr_number": 476,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -122,12 +126,23 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"basicQuery(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n \n+\t// Run query variations\n+\tpersisted := fmt.Sprintf(\"golang_example_table_queryresult_%d\", time.Now().Unix())\n+\tif err := queryWithDestination(client, datasetID, persisted); err != nil {\n+\t\tt.Errorf(\"queryWithDestination(dataset:%q table:%q): %v\", datasetID, persisted, err)\n+\t}\n+\n+\tsql := \"SELECT 17 as foo\"\n+\tif err := queryLegacy(client, sql); err != nil {\n+\t\tt.Errorf(\"queryLegacy: %v\", err)\n+\t}\n+\n \t// Print information about tables (extended and simple).\n-\tif err := printTableMetadataSimple(client, datasetID, inferred); err != nil {\n-\t\tt.Errorf(\"printTableMetadata(dataset:%q table:%q): %v\", datasetID, inferred, err)\n+\tif err := printTableInfo(client, datasetID, inferred); err != nil {\n+\t\tt.Errorf(\"printTableInfo(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := printTableMetadataSimple(client, datasetID, explicit); err != nil {\n-\t\tt.Errorf(\"printTableMetadata(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\tif err := printTableInfo(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"printTableInfo(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n \n \tdstTableID := fmt.Sprintf(\"golang_example_tabledst_%d\", time.Now().Unix())",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "badab496b6d78c5b1296af6aa014b562b316c0c0"
    },
    {
        "pr_title": "BigQuery:  more snippets",
        "pr_number": 476,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -141,25 +156,6 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)\n \t}\n \n-\tdeleteDataset(t, ctx, datasetID)\n-}\n-\n-func deleteDataset(t *testing.T, ctx context.Context, datasetID string) {\n-\ttc := testutil.SystemTest(t)\n-\thc, err := google.DefaultClient(ctx, rawbq.CloudPlatformScope)\n-\tif err != nil {\n-\t\tt.Errorf(\"DefaultClient: %v\", err)\n-\t}\n-\ts, err := rawbq.New(hc)\n-\tif err != nil {\n-\t\tt.Errorf(\"bigquery.New: %v\", err)\n-\t}\n-\tcall := s.Datasets.Delete(tc.ProjectID, datasetID)\n-\tcall.DeleteContents(true)\n-\tcall.Context(ctx)\n-\tif err := call.Do(); err != nil {\n-\t\tt.Errorf(\"deleteDataset(%q): %v\", datasetID, err)\n-\t}\n }\n \n func TestImportExport(t *testing.T) {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "badab496b6d78c5b1296af6aa014b562b316c0c0"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -5,6 +5,7 @@\n// Command simpleapp queries the Stack Overflow public dataset in Google BigQuery.\n package main\n \n+// [START bigquery_simple_app_all]\n // [START bigquery_simple_app_deps]\n import (\n \t\"fmt\"",
        "comments": [],
        "commit_messages": [
            "add bigquery_simple_app_query and bigquery_simple_app_all region tags"
        ],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -47,6 +48,7 @@\nfunc query(proj string) (*bigquery.RowIterator, error) {\n \t}\n \t// [END bigquery_simple_app_client]\n \n+\t// [START bigquery_simple_app_query]\n \tquery := client.Query(\n \t\t`SELECT\n \t\t\tCONCAT(",
        "comments": [],
        "commit_messages": [
            "add bigquery_simple_app_query and bigquery_simple_app_all region tags"
        ],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -58,6 +60,7 @@\nfunc query(proj string) (*bigquery.RowIterator, error) {\n \t\tORDER BY view_count DESC\n \t\tLIMIT 10;`)\n \treturn query.Read(ctx)\n+\t// [END bigquery_simple_app_query]\n }\n \n // [START bigquery_simple_app_print]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -19,7 +19,10 @@\nimport (\n func createDataset(client *bigquery.Client, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_create_dataset]\n-\tif err := client.Dataset(datasetID).Create(ctx, &bigquery.DatasetMetadata{}); err != nil {\n+\tmeta := &bigquery.DatasetMetadata{\n+\t\tLocation: \"US\", // Create the dataset in the US.\n+\t}\n+\tif err := client.Dataset(datasetID).Create(ctx, meta); err != nil {\n \t\treturn err\n \t}\n \t// [END bigquery_create_dataset]",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -70,7 +73,7 @@\nfunc updateDatasetAccessControl(client *bigquery.Client, datasetID string) error\n \tif err != nil {\n \t\treturn err\n \t}\n-\t// Append a new access control entry to the existing access list\n+\t// Append a new access control entry to the existing access list.\n \tchanges := bigquery.DatasetMetadataToUpdate{\n \t\tAccess: append(original.Access, &bigquery.AccessEntry{\n \t\t\tRole:       bigquery.ReaderRole,",
        "comments": [],
        "commit_messages": [
            "Address review comments."
        ],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -113,27 +116,23 @@\nfunc listDatasets(client *bigquery.Client) error {\n \treturn nil\n }\n \n-// [START bigquery_create_table]\n-\n // Item represents a row item.\n type Item struct {\n-\tName  string\n-\tCount int\n+\tName string\n+\tAge  int\n }\n \n // Save implements the ValueSaver interface.\n func (i *Item) Save() (map[string]bigquery.Value, string, error) {\n \treturn map[string]bigquery.Value{\n-\t\t\"Name\":  i.Name,\n-\t\t\"Count\": i.Count,\n+\t\t\"Name\": i.Name,\n+\t\t\"Age\":  i.Age,\n \t}, \"\", nil\n }\n \n-// [END bigquery_create_table]\n-\n-func createTable(client *bigquery.Client, datasetID, tableID string) error {\n+func createTableInferredSchema(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n-\t// [START bigquery_create_table]\n+\t// bigquery.InferSchema infers BQ schema from native Go types.\n \tschema, err := bigquery.InferSchema(Item{})\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -142,10 +141,77 @@\nfunc createTable(client *bigquery.Client, datasetID, tableID string) error {\n \tif err := table.Create(ctx, &bigquery.TableMetadata{Schema: schema}); err != nil {\n \t\treturn err\n \t}\n+\treturn nil\n+}\n+\n+func createTableExplicitSchema(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_create_table]\n+\tsampleSchema := bigquery.Schema{\n+\t\t{Name: \"full_name\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"age\", Type: bigquery.IntegerFieldType},\n+\t}\n+\n+\tmetaData := &bigquery.TableMetadata{\n+\t\tSchema:         sampleSchema,\n+\t\tExpirationTime: time.Now().AddDate(1, 0, 0), // Table will be automatically deleted in 1 year.\n+\t}\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\tif err := tableRef.Create(ctx, metaData); err != nil {\n+\t\treturn err\n+\t}\n \t// [END bigquery_create_table]\n \treturn nil\n }\n \n+func createTableEmptySchema(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_create_table_without_schema]\n+\tif err := client.Dataset(datasetID).Table(tableID).Create(ctx, nil); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_create_table_without_schema]\n+\treturn nil\n+}\n+\n+func updateTableDescription(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_table_description]\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\toriginal, err := tableRef.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tnewMeta := bigquery.TableMetadataToUpdate{\n+\t\tDescription: \"Updated description.\",\n+\t}\n+\tif _, err = tableRef.Update(ctx, newMeta, original.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_table_description]\n+\treturn nil\n+\n+}\n+\n+func updateTableExpiration(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_table_expiration]\n+\ttableRef := client.Dataset(datasetID).Table(tableID)\n+\toriginal, err := tableRef.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tnewMeta := bigquery.TableMetadataToUpdate{\n+\t\tExpirationTime: time.Now().Add(time.Duration(5*24) * time.Hour), // table expiration in 5 days.\n+\t}\n+\tif _, err = tableRef.Update(ctx, newMeta, original.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_table_expiration]\n+\treturn nil\n+\n+}\n+\n func listTables(client *bigquery.Client, w io.Writer, datasetID string) error {\n \tctx := context.Background()\n \t// [START bigquery_list_tables]",
        "comments": [
            {
                "comment": "Function name seems a little off. Is this sample worth keeping around at all?",
                "position": 156
            },
            {
                "comment": "I left in the example method in and deferred the decision to cull it.  It was part of the snippets that demonstrate mapping BQ schema and results back/forth from native Go types.  I suspect the right thing to do is move it wholly to the client library docs or have a one-off example of working with Go type mappings and the ValueSaver interface.",
                "position": 156
            },
            {
                "comment": "Okay.\r\n\r\nWe tend to be pretty liberal about deleting samples that aren't referenced from anywhere. If someone really wants it they can get it from the git history, but I'm fine leaving it in for now if you have plans to migrate it.",
                "position": 156
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -166,28 +232,26 @@\nfunc listTables(client *bigquery.Client, w io.Writer, datasetID string) error {\n \n func insertRows(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n-\t// [START bigquery_insert_stream]\n+\t// [START bigquery_table_insert_rows]\n \tu := client.Dataset(datasetID).Table(tableID).Uploader()\n \titems := []*Item{\n \t\t// Item implements the ValueSaver interface.\n-\t\t{Name: \"n1\", Count: 7},\n-\t\t{Name: \"n2\", Count: 2},\n-\t\t{Name: \"n3\", Count: 1},\n+\t\t{Name: \"Phred Phlyntstone\", Age: 32},\n+\t\t{Name: \"Wylma Phlyntstone\", Age: 29},\n \t}\n \tif err := u.Put(ctx, items); err != nil {\n \t\treturn err\n \t}\n-\t// [END bigquery_insert_stream]\n+\t// [END bigquery_table_insert_rows]\n \treturn nil\n }\n \n func listRows(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n-\t// [START bigquery_list_rows]\n \tq := client.Query(fmt.Sprintf(`\n-\t\tSELECT name, count\n+\t\tSELECT name, age\n \t\tFROM %s.%s\n-\t\tWHERE count >= 5\n+\t\tWHERE age >= 20\n \t`, datasetID, tableID))\n \tit, err := q.Read(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "Sample updates (and region maintenance).\n\nadd: bigquery_load_table_gcs_csv\nadd: bigquery_update_table_description\nadd: bigquery_update_table_expiration\n\nrename/update: bigquery_insert_stream -> bigquery_table_insert_rows\nrename/update: bigquery_async_query -> bigquery_query\nrename/update: bigquery_import_from_file -> bigquery_load_from_file\n\nremove region tag: bigquery_list_rows\nremove region and impl: bigquery_export_gcs\nremove region and impl: bigquery_import_from_gcs\n\nother changes:\n* add Location to createDataset\n* add file testdata/people.csv for loading CSV via POST-based data ingestion"
        ],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -205,17 +269,19 @@\nfunc listRows(client *bigquery.Client, datasetID, tableID string) error {\n \t\t}\n \t\tfmt.Println(row)\n \t}\n-\t// [END bigquery_list_rows]\n \treturn nil\n }\n \n-func asyncQuery(client *bigquery.Client, datasetID, tableID string) error {\n+func basicQuery(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n-\t// [START bigquery_async_query]\n-\tq := client.Query(fmt.Sprintf(`\n-\t\tSELECT name, count\n-\t\tFROM %s.%s\n-\t`, datasetID, tableID))\n+\t// [START bigquery_query]\n+\tq := client.Query(\n+\t\t\"SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` \" +\n+\t\t\t\"WHERE state = \\\"TX\\\" \" +\n+\t\t\t\"LIMIT 100\")\n+\t// Location must match that of the dataset(s) referenced in the query.\n+\tq.Location = \"US\"\n+\n \tjob, err := q.Run(ctx)\n \tif err != nil {\n \t\treturn err",
        "comments": [],
        "commit_messages": [
            "Sample updates (and region maintenance).\n\nadd: bigquery_load_table_gcs_csv\nadd: bigquery_update_table_description\nadd: bigquery_update_table_expiration\n\nrename/update: bigquery_insert_stream -> bigquery_table_insert_rows\nrename/update: bigquery_async_query -> bigquery_query\nrename/update: bigquery_import_from_file -> bigquery_load_from_file\n\nremove region tag: bigquery_list_rows\nremove region and impl: bigquery_export_gcs\nremove region and impl: bigquery_import_from_gcs\n\nother changes:\n* add Location to createDataset\n* add file testdata/people.csv for loading CSV via POST-based data ingestion"
        ],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -242,7 +308,22 @@\nfunc asyncQuery(client *bigquery.Client, datasetID, tableID string) error {\n \t\t}\n \t\tfmt.Println(row)\n \t}\n-\t// [END bigquery_async_query]\n+\t// [END bigquery_query]\n+\treturn nil\n+}\n+\n+func printTableMetadataSimple(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_get_table]\n+\tmeta, err := client.Dataset(datasetID).Table(tableID).Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// Print basic information about the table.\n+\tfmt.Printf(\"Schema has %d top-level fields\\n\", len(meta.Schema))\n+\tfmt.Printf(\"Description: %s\\n\", meta.Description)\n+\tfmt.Printf(\"Row in managed storage: %d\\n\", meta.NumRows)\n+\t// [END bigquery_get_table]\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -298,17 +379,18 @@\nfunc deleteTable(client *bigquery.Client, datasetID, tableID string) error {\n \treturn nil\n }\n \n-func importFromGCS(client *bigquery.Client, datasetID, tableID, gcsURI string) error {\n+func importCSVFromFile(client *bigquery.Client, datasetID, tableID, filename string) error {\n \tctx := context.Background()\n-\t// [START bigquery_import_from_gcs]\n-\t// For example, \"gs://data-bucket/path/to/data.csv\"\n-\tgcsRef := bigquery.NewGCSReference(gcsURI)\n-\tgcsRef.AllowJaggedRows = true\n-\t// TODO: set other options on the GCSReference.\n+\t// [START bigquery_load_from_file]\n+\tf, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tsource := bigquery.NewReaderSource(f)\n+\tsource.AutoDetect = true   // Allow BigQuery to determine schema.\n+\tsource.SkipLeadingRows = 1 // CSV has a single header line.\n \n-\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n-\tloader.CreateDisposition = bigquery.CreateNever\n-\t// TODO: set other options on the Loader.\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(source)\n \n \tjob, err := loader.Run(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -321,24 +403,49 @@\nfunc importFromGCS(client *bigquery.Client, datasetID, tableID, gcsURI string) e\n \tif err := status.Err(); err != nil {\n \t\treturn err\n \t}\n-\t// [END bigquery_import_from_gcs]\n+\t// [END bigquery_load_from_file]\n \treturn nil\n }\n \n-func importFromFile(client *bigquery.Client, datasetID, tableID, filename string) error {\n+func importCSVExplicitSchema(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n-\t// [START bigquery_import_from_file]\n-\tf, err := os.Open(filename)\n+\t// [START bigquery_load_table_gcs_csv]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.csv\")\n+\tgcsRef.SkipLeadingRows = 1\n+\tgcsRef.Schema = bigquery.Schema{\n+\t\t{Name: \"name\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"post_abbr\", Type: bigquery.StringFieldType},\n+\t}\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\tloader.WriteDisposition = bigquery.WriteEmpty\n+\n+\tjob, err := loader.Run(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tstatus, err := job.Wait(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tsource := bigquery.NewReaderSource(f)\n-\tsource.AllowJaggedRows = true\n-\t// TODO: set other options on the GCSReference.\n \n-\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(source)\n-\tloader.CreateDisposition = bigquery.CreateNever\n-\t// TODO: set other options on the Loader.\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n+\t}\n+\t// [END bigquery_load_table_gcs_csv]\n+\treturn nil\n+}\n+\n+func importJSONExplicitSchema(client *bigquery.Client, datasetID, tableID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_load_table_gcs_json]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.json\")\n+\tgcsRef.SourceFormat = bigquery.JSON\n+\tgcsRef.Schema = bigquery.Schema{\n+\t\t{Name: \"name\", Type: bigquery.StringFieldType},\n+\t\t{Name: \"post_abbr\", Type: bigquery.StringFieldType},\n+\t}\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\tloader.WriteDisposition = bigquery.WriteEmpty\n \n \tjob, err := loader.Run(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -348,34 +455,36 @@\nfunc importFromFile(client *bigquery.Client, datasetID, tableID, filename string\n \tif err != nil {\n \t\treturn err\n \t}\n-\tif err := status.Err(); err != nil {\n-\t\treturn err\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n \t}\n-\t// [END bigquery_import_from_file]\n+\t// [END bigquery_load_table_gcs_json]\n \treturn nil\n }\n \n-func exportToGCS(client *bigquery.Client, datasetID, tableID, gcsURI string) error {\n+func importJSONAutodetectSchema(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n-\t// [START bigquery_export_gcs]\n-\t// For example, \"gs://data-bucket/path/to/data.csv\"\n-\tgcsRef := bigquery.NewGCSReference(gcsURI)\n-\tgcsRef.FieldDelimiter = \",\"\n+\t// [START bigquery_load_table_gcs_json_autodetect]\n+\tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.json\")\n+\tgcsRef.SourceFormat = bigquery.JSON\n+\tgcsRef.AutoDetect = true\n+\tloader := client.Dataset(datasetID).Table(tableID).LoaderFrom(gcsRef)\n+\tloader.WriteDisposition = bigquery.WriteEmpty\n \n-\textractor := client.Dataset(datasetID).Table(tableID).ExtractorTo(gcsRef)\n-\textractor.DisableHeader = true\n-\tjob, err := extractor.Run(ctx)\n+\tjob, err := loader.Run(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \tstatus, err := job.Wait(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n-\tif err := status.Err(); err != nil {\n-\t\treturn err\n+\n+\tif status.Err() != nil {\n+\t\treturn fmt.Errorf(\"Job completed with error: %v\", status.Err())\n \t}\n-\t// [END bigquery_export_gcs]\n+\t// [END bigquery_load_table_gcs_json_autodetect]\n \treturn nil\n }",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -392,8 +501,8 @@\nfunc exportSampleTableAsCSV(client *bigquery.Client, gcsURI string) error {\n \n \textractor := client.DatasetInProject(srcProject, srcDataset).Table(srcTable).ExtractorTo(gcsRef)\n \textractor.DisableHeader = true\n-\t// You can choose to run the job in a specific location for more complex data locality scenarios\n-\t// Ex: In this example, source dataset and GCS bucket are in the US\n+\t// You can choose to run the job in a specific location for more complex data locality scenarios.\n+\t// Ex: In this example, source dataset and GCS bucket are in the US.\n \textractor.Location = \"US\"\n \n \tjob, err := extractor.Run(ctx)",
        "comments": [],
        "commit_messages": [
            "Address review comments."
        ],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -424,8 +533,8 @@\nfunc exportSampleTableAsCompressedCSV(client *bigquery.Client, gcsURI string) er\n \n \textractor := client.DatasetInProject(srcProject, srcDataset).Table(srcTable).ExtractorTo(gcsRef)\n \textractor.DisableHeader = true\n-\t// You can choose to run the job in a specific location for more complex data locality scenarios\n-\t// Ex: In this example, source dataset and GCS bucket are in the US\n+\t// You can choose to run the job in a specific location for more complex data locality scenarios.\n+\t// Ex: In this example, source dataset and GCS bucket are in the US.\n \textractor.Location = \"US\"\n \n \tjob, err := extractor.Run(ctx)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -455,8 +564,8 @@\nfunc exportSampleTableAsJSON(client *bigquery.Client, gcsURI string) error {\n \tgcsRef.DestinationFormat = bigquery.JSON\n \n \textractor := client.DatasetInProject(srcProject, srcDataset).Table(srcTable).ExtractorTo(gcsRef)\n-\t// You can choose to run the job in a specific location for more complex data locality scenarios\n-\t// Ex: In this example, source dataset and GCS bucket are in the US\n+\t// You can choose to run the job in a specific location for more complex data locality scenarios.\n+\t// Ex: In this example, source dataset and GCS bucket are in the US.\n \textractor.Location = \"US\"\n \n \tjob, err := extractor.Run(ctx)",
        "comments": [],
        "commit_messages": [
            "Address review comments."
        ],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -53,7 +53,7 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"updateDataSetAccessControl(%q): %v\", datasetID, err)\n \t}\n \n-\t// test empty dataset creation/ttl/delete\n+\t// Test empty dataset creation/ttl/delete.\n \tdeletionDatasetID := fmt.Sprintf(\"%s_quickdelete\", datasetID)\n \tif err := createDataset(client, deletionDatasetID); err != nil {\n \t\tt.Errorf(\"createDataset(%q): %v\", deletionDatasetID, err)",
        "comments": [],
        "commit_messages": [
            "Correct error message formatting"
        ],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": " BigQuery sample updates and region tag changes.",
        "pr_number": 473,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -72,36 +72,70 @@\nfunc TestAll(t *testing.T) {\n \t\tt.Errorf(\"listDatasets: %v\", err)\n \t}\n \n-\ttableID := fmt.Sprintf(\"golang_example_table_%d\", time.Now().Unix())\n-\tif err := createTable(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"createTable(dataset:%q  table:%q): %v\", datasetID, tableID, err)\n+\tinferred := fmt.Sprintf(\"golang_example_table_inferred_%d\", time.Now().Unix())\n+\texplicit := fmt.Sprintf(\"golang_example_table_explicit_%d\", time.Now().Unix())\n+\tempty := fmt.Sprintf(\"golang_example_table_emptyschema_%d\", time.Now().Unix())\n+\n+\tif err := createTableInferredSchema(client, datasetID, inferred); err != nil {\n+\t\tt.Errorf(\"createTableInferredSchema(dataset:%q table:%q): %v\", datasetID, inferred, err)\n+\t}\n+\tif err := createTableExplicitSchema(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"createTableExplicitSchema(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\t}\n+\tif err := createTableEmptySchema(client, datasetID, empty); err != nil {\n+\t\tt.Errorf(\"createTableEmptySchema(dataset:%q table:%q): %v\", datasetID, empty, err)\n+\t}\n+\n+\tif err := updateTableDescription(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"updateTableDescription(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n+\tif err := updateTableExpiration(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"updateTableExpiration(dataset:%q table:%q): %v\", datasetID, explicit, err)\n+\t}\n+\n \tbuf := &bytes.Buffer{}\n \tif err := listTables(client, buf, datasetID); err != nil {\n \t\tt.Errorf(\"listTables(%q): %v\", datasetID, err)\n \t}\n-\tif got := buf.String(); !strings.Contains(got, tableID) {\n-\t\tt.Errorf(\"want table list %q to contain table %q\", got, tableID)\n+\t// Ensure all three tables are in the list.\n+\tif got := buf.String(); !strings.Contains(got, inferred) {\n+\t\tt.Errorf(\"want table list %q to contain table %q\", got, inferred)\n+\t}\n+\tif got := buf.String(); !strings.Contains(got, explicit) {\n+\t\tt.Errorf(\"want table list %q to contain table %q\", got, explicit)\n+\t}\n+\tif got := buf.String(); !strings.Contains(got, empty) {\n+\t\tt.Errorf(\"want table list %q to contain table %q\", got, empty)\n \t}\n-\tif err := insertRows(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"insertRows(dataset:%q table:%q): %v\", datasetID, tableID, err)\n+\n+\t// Stream data, read, query the inferred schema table.\n+\tif err := insertRows(client, datasetID, inferred); err != nil {\n+\t\tt.Errorf(\"insertRows(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := listRows(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"listRows(dataset:%q table:%q): %v\", datasetID, tableID, err)\n+\tif err := listRows(client, datasetID, inferred); err != nil {\n+\t\tt.Errorf(\"listRows(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := browseTable(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"browseTable(dataset:%q table:%q): %v\", datasetID, tableID, err)\n+\tif err := browseTable(client, datasetID, inferred); err != nil {\n+\t\tt.Errorf(\"browseTable(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n-\tif err := asyncQuery(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"failed to async query: %v\", err)\n+\tif err := basicQuery(client, datasetID, inferred); err != nil {\n+\t\tt.Errorf(\"basicQuery(dataset:%q table:%q): %v\", datasetID, inferred, err)\n+\t}\n+\n+\t// Print information about tables (extended and simple).\n+\tif err := printTableMetadataSimple(client, datasetID, inferred); err != nil {\n+\t\tt.Errorf(\"printTableMetadata(dataset:%q table:%q): %v\", datasetID, inferred, err)\n+\t}\n+\tif err := printTableMetadataSimple(client, datasetID, explicit); err != nil {\n+\t\tt.Errorf(\"printTableMetadata(dataset:%q table:%q): %v\", datasetID, explicit, err)\n \t}\n \n \tdstTableID := fmt.Sprintf(\"golang_example_tabledst_%d\", time.Now().Unix())\n-\tif err := copyTable(client, datasetID, tableID, dstTableID); err != nil {\n-\t\tt.Errorf(\"failed to copy table (dataset:%q src:%q dst:%q): %v\", datasetID, tableID, dstTableID, err)\n+\tif err := copyTable(client, datasetID, inferred, dstTableID); err != nil {\n+\t\tt.Errorf(\"copyTable(dataset:%q src:%q dst:%q): %v\", datasetID, inferred, dstTableID, err)\n \t}\n-\tif err := deleteTable(client, datasetID, tableID); err != nil {\n-\t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, tableID, err)\n+\tif err := deleteTable(client, datasetID, inferred); err != nil {\n+\t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, inferred, err)\n \t}\n \tif err := deleteTable(client, datasetID, dstTableID); err != nil {\n \t\tt.Errorf(\"deleteTable(dataset:%q table:%q): %v\", datasetID, dstTableID, err)",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "d2676d617d3c367aab93d2a4ae4ce702bb3f87ef"
    },
    {
        "pr_title": "Add more Go samples for BigQuery:",
        "pr_number": 469,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -19,6 +19,7 @@\nimport (\n \t\"golang.org/x/net/context\"\n \t\"golang.org/x/oauth2/google\"\n \trawbq \"google.golang.org/api/bigquery/v2\"\n+\t\"google.golang.org/api/iterator\"\n )\n \n func init() {",
        "comments": [],
        "commit_messages": [
            "Address location comment, make GCS bucket cleanup more general."
        ],
        "last_commit_sha": "45ffa09ac36bc8d1e9c2853df9d7c2d3826295d7"
    },
    {
        "pr_title": "Add more Go samples for BigQuery:",
        "pr_number": 469,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -143,7 +144,7 @@\nfunc TestImportExport(t *testing.T) {\n \tdatasetID := fmt.Sprintf(\"golang_example_dataset_importexport_%d\", time.Now().Unix())\n \ttableID := fmt.Sprintf(\"golang_example_dataset_importexport_%d\", time.Now().Unix())\n \tif err := createDataset(client, datasetID); err != nil {\n-\t\tt.Errorf(\"failed to create dataset: %v\", err)\n+\t\tt.Errorf(\"createDataset(%q): %v\", datasetID, err)\n \t}\n \tschema := bigquery.Schema{\n \t\t&bigquery.FieldSchema{Name: \"Year\", Type: bigquery.IntegerFieldType},",
        "comments": [],
        "commit_messages": [
            "Add more Go samples for BigQuery:\n\nbigquery_extract_table\nbigquery_extract_table_json\n\nAdditionally, make error reporting in snippet_test.go more informative."
        ],
        "last_commit_sha": "45ffa09ac36bc8d1e9c2853df9d7c2d3826295d7"
    },
    {
        "pr_title": "Add more Go samples for BigQuery:",
        "pr_number": 469,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -152,22 +153,23 @@\nfunc TestImportExport(t *testing.T) {\n \tif err := client.Dataset(datasetID).Table(tableID).Create(ctx, &bigquery.TableMetadata{\n \t\tSchema: schema,\n \t}); err != nil {\n-\t\tt.Errorf(\"failed to create dataset: %v\", err)\n+\t\tt.Errorf(\"table creation failed (dataset:%q table:%q): %v\", datasetID, tableID, err)\n \t}\n \tdefer deleteDataset(t, ctx, datasetID)\n \n-\tif err := importFromFile(client, datasetID, tableID, \"testdata/olympics.csv\"); err != nil {\n-\t\tt.Fatalf(\"failed to import from file: %v\", err)\n+\tfilename := \"testdata/olympics.csv\"\n+\tif err := importFromFile(client, datasetID, tableID, filename); err != nil {\n+\t\tt.Fatalf(\"importFromFile(dataset:%q table:%q filename:%q): %v\", datasetID, tableID, filename, err)\n \t}\n \n \tjsonTableExplicit := fmt.Sprintf(\"golang_example_dataset_importjson_explicit_%d\", time.Now().Unix())\n \tif err := importJSONExplicitSchema(client, datasetID, jsonTableExplicit); err != nil {\n-\t\tt.Fatalf(\"Failed to ingest JSON sample with explicit schema: %v\", err)\n+\t\tt.Fatalf(\"importJSONExplicitSchema(dataset:%q table:%q): %v\", datasetID, jsonTableExplicit, err)\n \t}\n \n \tjsonTableAutodetect := fmt.Sprintf(\"golang_example_dataset_importjson_autodetect_%d\", time.Now().Unix())\n \tif err := importJSONAutodetectSchema(client, datasetID, jsonTableAutodetect); err != nil {\n-\t\tt.Fatalf(\"Failed to ingest JSON sample with explicit schema: %v\", err)\n+\t\tt.Fatalf(\"importJSONAutodetectSchema(dataset:%q table:%q): %v\", datasetID, jsonTableAutodetect, err)\n \t}\n \n \tbucket := fmt.Sprintf(\"golang-example-bigquery-importexport-bucket-%d\", time.Now().Unix())",
        "comments": [],
        "commit_messages": [
            "Add more Go samples for BigQuery:\n\nbigquery_extract_table\nbigquery_extract_table_json\n\nAdditionally, make error reporting in snippet_test.go more informative."
        ],
        "last_commit_sha": "45ffa09ac36bc8d1e9c2853df9d7c2d3826295d7"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -44,15 +44,23 @@\nvar (\n \t\t\"querywithtimestamp\":  queryWithTimestamp,\n \t\t\"writewithtimestamp\":  writeWithTimestamp,\n \t\t\"querynewtable\":       queryNewTable,\n+\t\t\"writetodocstable\":    writeToDocumentsTable,\n+\t\t\"updatedocstable\":     updateDocumentsTable,\n+\t\t\"querydocstable\":      queryDocumentsTable,\n+\t\t\"writewithhistory\":    writeWithHistory,\n+\t\t\"updatewithhistory\":   updateWithHistory,\n+\t\t\"querywithhistory\":    queryWithHistory,\n \t}\n \n \tadminCommands = map[string]adminCommand{\n-\t\t\"createdatabase\":           createDatabase,\n-\t\t\"addnewcolumn\":             addNewColumn,\n-\t\t\"addindex\":                 addIndex,\n-\t\t\"addstoringindex\":          addStoringIndex,\n-\t\t\"addcommittimestamp\":       addCommitTimestamp,\n-\t\t\"createtablewithtimestamp\": createTableWithTimestamp,\n+\t\t\"createdatabase\":                  createDatabase,\n+\t\t\"addnewcolumn\":                    addNewColumn,\n+\t\t\"addindex\":                        addIndex,\n+\t\t\"addstoringindex\":                 addStoringIndex,\n+\t\t\"addcommittimestamp\":              addCommitTimestamp,\n+\t\t\"createtablewithtimestamp\":        createTableWithTimestamp,\n+\t\t\"createtabledocswithtimestamp\":    createTableDocumentsWithTimestamp,\n+\t\t\"createtabledocswithhistorytable\": createTableDocumentsWithHistoryTable,\n \t}\n )",
        "comments": [],
        "commit_messages": [
            "Address Review Comments."
        ],
        "last_commit_sha": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -121,6 +129,55 @@\nfunc createTableWithTimestamp(ctx context.Context, w io.Writer, adminClient *dat\n \n // [END spanner_create_table_with_timestamp_column]\n \n+func createTableDocumentsWithTimestamp(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t`CREATE TABLE DocumentsWithTimestamp(\n+\t\t\t\tUserId INT64 NOT NULL,\n+\t\t\t\tDocumentId INT64 NOT NULL,\n+\t\t\t    Timestamp TIMESTAMP NOT NULL OPTIONS(allow_commit_timestamp=true),\n+\t\t\t\tContents STRING(MAX) NOT NULL\n+\t\t\t) PRIMARY KEY(UserId, DocumentId)`,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Created DocumentsWithTimestamp table in database [%s]\\n\", database)\n+\treturn nil\n+}\n+\n+func createTableDocumentsWithHistoryTable(ctx context.Context, w io.Writer, adminClient *database.DatabaseAdminClient, database string) error {\n+\top, err := adminClient.UpdateDatabaseDdl(ctx, &adminpb.UpdateDatabaseDdlRequest{\n+\t\tDatabase: database,\n+\t\tStatements: []string{\n+\t\t\t`CREATE TABLE Documents(\n+\t\t\t\tUserId INT64 NOT NULL,\n+\t\t\t\tDocumentId INT64 NOT NULL,\n+\t\t\t\tContents STRING(MAX) NOT NULL\n+\t\t\t) PRIMARY KEY(UserId, DocumentId)`,\n+\t\t\t`CREATE TABLE DocumentHistory(\n+\t\t\t\tUserId INT64 NOT NULL,\n+\t\t\t\tDocumentId INT64 NOT NULL,\n+\t\t\t\tTimestamp TIMESTAMP NOT NULL OPTIONS(allow_commit_timestamp=true),\n+\t\t\t\tPreviousContents STRING(MAX)\n+\t\t\t) PRIMARY KEY(UserId, DocumentId, Timestamp), INTERLEAVE IN PARENT Documents ON DELETE NO ACTION`,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tif err := op.Wait(ctx); err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Fprintf(w, \"Created Documents and DocumentHistory tables in database [%s]\\n\", database)\n+\treturn nil\n+}\n+\n // [START spanner_insert_data]\n \n func write(ctx context.Context, w io.Writer, client *spanner.Client) error {",
        "comments": [],
        "commit_messages": [
            "Address Review Comments."
        ],
        "last_commit_sha": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "Add Spanner Change Log sample using commit timestamp.",
        "pr_number": 458,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -703,6 +760,185 @@\nfunc queryNewTable(ctx context.Context, w io.Writer, client *spanner.Client) err\n \t}\n }\n \n+func writeToDocumentsTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tdocumentsColumns := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"Contents\"}\n+\tm := []*spanner.Mutation{\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, \"Hello World 1\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{1, 2, spanner.CommitTimestamp, \"Hello World 2\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, \"Hello World 3\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{2, 4, spanner.CommitTimestamp, \"Hello World 4\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, \"Hello World 5\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{3, 6, spanner.CommitTimestamp, \"Hello World 6\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{3, 7, spanner.CommitTimestamp, \"Hello World 7\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{3, 8, spanner.CommitTimestamp, \"Hello World 8\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{3, 9, spanner.CommitTimestamp, \"Hello World 9\"}),\n+\t\tspanner.InsertOrUpdate(\"DocumentsWithTimestamp\", documentsColumns,\n+\t\t\t[]interface{}{3, 10, spanner.CommitTimestamp, \"Hello World 10\"}),\n+\t}\n+\t_, err := client.Apply(ctx, m)\n+\treturn err\n+}\n+\n+func updateDocumentsTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tcols := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"Contents\"}\n+\t_, err := client.Apply(ctx, []*spanner.Mutation{\n+\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n+\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, \"Hello World 1 Updated\"}),\n+\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n+\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, \"Hello World 3 Updated\"}),\n+\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n+\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, \"Hello World 5 Updated\"}),\n+\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n+\t\t\t[]interface{}{3, 7, spanner.CommitTimestamp, \"Hello World 7 Updated\"}),\n+\t\tspanner.Update(\"DocumentsWithTimestamp\", cols,\n+\t\t\t[]interface{}{3, 9, spanner.CommitTimestamp, \"Hello World 9 Updated\"}),\n+\t})\n+\treturn err\n+}\n+\n+func queryDocumentsTable(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tstmt := spanner.Statement{SQL: `SELECT UserId, DocumentId, Timestamp, Contents FROM DocumentsWithTimestamp\n+\t\tORDER BY Timestamp DESC Limit 5`}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar userID, documentID int64\n+\t\tvar timestamp time.Time\n+\t\tvar contents string\n+\t\tif err := row.Columns(&userID, &documentID, &timestamp, &contents); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %d %s %s\\n\", userID, documentID, timestamp, contents)\n+\t}\n+}\n+\n+func writeWithHistory(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\tdocumentsColumns := []string{\"UserId\", \"DocumentId\", \"Contents\"}\n+\t\tdocumentHistoryColumns := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"PreviousContents\"}\n+\t\ttxn.BufferWrite([]*spanner.Mutation{\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{1, 1, \"Hello World 1\"}),\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{1, 2, \"Hello World 2\"}),\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{1, 3, \"Hello World 3\"}),\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{2, 4, \"Hello World 4\"}),\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{2, 5, \"Hello World 5\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, \"Hello World 1\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{1, 2, spanner.CommitTimestamp, \"Hello World 2\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, \"Hello World 3\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{2, 4, spanner.CommitTimestamp, \"Hello World 4\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, \"Hello World 5\"}),\n+\t\t})\n+\t\treturn nil\n+\t})\n+\treturn err\n+}\n+\n+func updateWithHistory(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\t_, err := client.ReadWriteTransaction(ctx, func(ctx context.Context, txn *spanner.ReadWriteTransaction) error {\n+\t\t// Create anonymous function \"getContents\" to read the current value of the Contents column for a given row.\n+\t\tgetContents := func(key spanner.Key) (string, error) {\n+\t\t\trow, err := txn.ReadRow(ctx, \"Documents\", key, []string{\"Contents\"})\n+\t\t\tif err != nil {\n+\t\t\t\treturn \"\", err\n+\t\t\t}\n+\t\t\tvar content string\n+\t\t\tif err := row.Column(0, &content); err != nil {\n+\t\t\t\treturn \"\", err\n+\t\t\t}\n+\t\t\treturn content, nil\n+\t\t}\n+\t\t// Create two string arrays corresponding to the columns in each table.\n+\t\tdocumentsColumns := []string{\"UserId\", \"DocumentId\", \"Contents\"}\n+\t\tdocumentHistoryColumns := []string{\"UserId\", \"DocumentId\", \"Timestamp\", \"PreviousContents\"}\n+\t\t// Get row's Contents before updating.\n+\t\tpreviousContents, err := getContents(spanner.Key{1, 1})\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\t// Update row's Contents while saving previous Contents in DocumentHistory table.\n+\t\ttxn.BufferWrite([]*spanner.Mutation{\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{1, 1, \"Hello World 1 Updated\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{1, 1, spanner.CommitTimestamp, previousContents}),\n+\t\t})\n+\t\tpreviousContents, err = getContents(spanner.Key{1, 3})\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\ttxn.BufferWrite([]*spanner.Mutation{\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{1, 3, \"Hello World 3 Updated\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{1, 3, spanner.CommitTimestamp, previousContents}),\n+\t\t})\n+\t\tpreviousContents, err = getContents(spanner.Key{2, 5})\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\ttxn.BufferWrite([]*spanner.Mutation{\n+\t\t\tspanner.InsertOrUpdate(\"Documents\", documentsColumns,\n+\t\t\t\t[]interface{}{2, 5, \"Hello World 5 Updated\"}),\n+\t\t\tspanner.InsertOrUpdate(\"DocumentHistory\", documentHistoryColumns,\n+\t\t\t\t[]interface{}{2, 5, spanner.CommitTimestamp, previousContents}),\n+\t\t})\n+\t\treturn nil\n+\t})\n+\treturn err\n+}\n+\n+func queryWithHistory(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\tstmt := spanner.Statement{\n+\t\tSQL: `SELECT d.UserId, d.DocumentId, d.Contents, dh.Timestamp, dh.PreviousContents\n+\t\t\t\tFROM Documents d JOIN DocumentHistory dh\n+\t\t\t\tON dh.UserId = d.UserId AND dh.DocumentId = d.DocumentId\n+\t\t\t\tORDER BY dh.Timestamp DESC LIMIT 3`}\n+\titer := client.Single().Query(ctx, stmt)\n+\tdefer iter.Stop()\n+\tfor {\n+\t\trow, err := iter.Next()\n+\t\tif err == iterator.Done {\n+\t\t\treturn nil\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar userID, documentID int64\n+\t\tvar timestamp time.Time\n+\t\tvar contents, previousContents string\n+\t\tif err := row.Columns(&userID, &documentID, &contents, &timestamp, &previousContents); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Fprintf(w, \"%d %d %s %s %s\\n\", userID, documentID, contents, timestamp, previousContents)\n+\t}\n+}\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [
            "Address Review Comments."
        ],
        "last_commit_sha": "492adaea1128203fbbc3e22d3ff6ee49ac693dc8"
    },
    {
        "pr_title": "storage/buckets: use ProjectID for test buckets",
        "pr_number": 457,
        "file_name": "storage/buckets/main.go",
        "code_diff": "@@ -78,7 +78,7 @@\nfunc main() {\n \t}\n \n \t// delete the bucket\n-\tif err := delete(client, name); err != nil {\n+\tif err := deleteBucket(client, name); err != nil {\n \t\tlog.Fatal(err)\n \t}\n \tfmt.Printf(\"deleted bucket: %v\\n\", name)",
        "comments": [],
        "commit_messages": [
            "storage/buckets: style cleanup"
        ],
        "last_commit_sha": "b459d675cb467596926bb1c8f62f99a93341a670"
    },
    {
        "pr_title": "storage/buckets: use ProjectID for test buckets",
        "pr_number": 457,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -5,7 +5,6 @@\npackage main\n \n import (\n-\t\"fmt\"\n \t\"testing\"\n \t\"time\"",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b459d675cb467596926bb1c8f62f99a93341a670"
    },
    {
        "pr_title": "storage/buckets: use ProjectID for test buckets",
        "pr_number": 457,
        "file_name": "storage/buckets/main_test.go",
        "code_diff": "@@ -15,42 +14,45 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n-var bucketName = fmt.Sprintf(\"golang-example-buckets-%d\", time.Now().Unix())\n+var (\n+\tstorageClient *storage.Client\n+\tbucketName    string\n+)\n \n-func setup(t *testing.T) *storage.Client {\n+func TestCreate(t *testing.T) {\n+\ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tclient, err := storage.NewClient(ctx)\n+\tvar err error\n+\tstorageClient, err = storage.NewClient(ctx)\n \tif err != nil {\n \t\tt.Fatalf(\"failed to create client: %v\", err)\n \t}\n-\treturn client\n-}\n \n-func TestCreate(t *testing.T) {\n-\ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n-\tif err := create(c, tc.ProjectID, bucketName); err != nil {\n+\tbucketName = tc.ProjectID + \"-storage-buckets-tests\"\n+\t// Clean up bucket before running tests.\n+\tdeleteBucket(storageClient, bucketName)\n+\tif err := create(storageClient, tc.ProjectID, bucketName); err != nil {\n \t\tt.Fatalf(\"failed to create bucket (%q): %v\", bucketName, err)\n \t}\n }\n \n func TestCreateWithAttrs(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n \tname := bucketName + \"-attrs\"\n-\tif err := createWithAttrs(c, tc.ProjectID, name); err != nil {\n-\t\tt.Fatalf(\"failed to create bucket (%q): %v\", bucketName, err)\n+\t// Clean up bucket before running test.\n+\tdeleteBucket(storageClient, name)\n+\tif err := createWithAttrs(storageClient, tc.ProjectID, name); err != nil {\n+\t\tt.Fatalf(\"failed to create bucket (%q): %v\", name, err)\n \t}\n-\tif err := delete(c, name); err != nil {\n-\t\tt.Fatalf(\"failed to delete bucket (%q): %v\", bucketName, err)\n+\tif err := deleteBucket(storageClient, name); err != nil {\n+\t\tt.Fatalf(\"failed to delete bucket (%q): %v\", name, err)\n \t}\n }\n \n func TestList(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n-\tc := setup(t)\n-\tbuckets, err := list(c, tc.ProjectID)\n+\tbuckets, err := list(storageClient, tc.ProjectID)\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "b459d675cb467596926bb1c8f62f99a93341a670"
    },
    {
        "pr_title": "Add three new BigQuery snippets, and address minor nits.",
        "pr_number": 449,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -9,6 +9,7 @@\nimport (\n \t\"fmt\"\n \t\"io\"\n \t\"os\"\n+\t\"time\"\n \n \t\"cloud.google.com/go/bigquery\"\n \t\"golang.org/x/net/context\"",
        "comments": [
            {
                "comment": "Looks like `updateDatasetDescription` checks `ds.Metadata`, but `updateDatasetDefaultExpiration` and `deleteEmptyDataset` don't. Is that intentional? I don't quite understand `original.ETag` and when to use it, either.",
                "position": 12
            },
            {
                "comment": "It was intentional.  Per offline discussion with tswast, samples will leverage use of the ETag for safe updates.",
                "position": 12
            }
        ],
        "commit_messages": [
            "Add three new BigQuery snippets, and address minor nits.\n\nNew snippets:\nbigquery_update_dataset_description\nbigquery_update_dataset_expiration\nbigquery_delete_dataset"
        ],
        "last_commit_sha": "8f5beae5bb9890974d57b6878e8b5a57f81661c4"
    },
    {
        "pr_title": "Add three new BigQuery snippets, and address minor nits.",
        "pr_number": 449,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -25,6 +26,53 @@\nfunc createDataset(client *bigquery.Client, datasetID string) error {\n \treturn nil\n }\n \n+func updateDatasetDescription(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_dataset_description]\n+\tds := client.Dataset(datasetID)\n+\toriginal, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tchanges := bigquery.DatasetMetadataToUpdate{\n+\t\tDescription: \"Updated Description.\",\n+\t}\n+\t_, err = ds.Update(ctx, changes, original.ETag)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_dataset_description]\n+\treturn nil\n+}\n+\n+func updateDatasetDefaultExpiration(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_update_dataset_expiration]\n+\tds := client.Dataset(datasetID)\n+\toriginal, err := ds.Metadata(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tchanges := bigquery.DatasetMetadataToUpdate{\n+\t\tDefaultTableExpiration: 24 * time.Hour,\n+\t}\n+\tif _, err := client.Dataset(datasetID).Update(ctx, changes, original.ETag); err != nil {\n+\t\treturn err\n+\t}\n+\t// [END bigquery_update_dataset_expiration]\n+\treturn nil\n+}\n+\n+func deleteEmptyDataset(client *bigquery.Client, datasetID string) error {\n+\tctx := context.Background()\n+\t// [START bigquery_delete_dataset]\n+\tif err := client.Dataset(datasetID).Delete(ctx); err != nil {\n+\t\treturn fmt.Errorf(\"Failed to delete dataset: %v\", err)\n+\t}\n+\t// [END bigquery_delete_dataset]\n+\treturn nil\n+}\n+\n func listDatasets(client *bigquery.Client) error {\n \tctx := context.Background()\n \t// [START bigquery_list_datasets]",
        "comments": [
            {
                "comment": "thank you!",
                "position": 67
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "8f5beae5bb9890974d57b6878e8b5a57f81661c4"
    },
    {
        "pr_title": "Add three new BigQuery snippets, and address minor nits.",
        "pr_number": 449,
        "file_name": "bigquery/snippets/snippet.go",
        "code_diff": "@@ -306,7 +354,7 @@\nfunc exportToGCS(client *bigquery.Client, datasetID, tableID, gcsURI string) err\n \treturn nil\n }\n \n-func importJsonExplicitSchema(client *bigquery.Client, datasetID, tableID string) error {\n+func importJSONExplicitSchema(client *bigquery.Client, datasetID, tableID string) error {\n \tctx := context.Background()\n \t// [START bigquery_load_table_gcs_json]\n \tgcsRef := bigquery.NewGCSReference(\"gs://cloud-samples-data/bigquery/us-states/us-states.json\")",
        "comments": [],
        "commit_messages": [
            "Add three new BigQuery snippets, and address minor nits.\n\nNew snippets:\nbigquery_update_dataset_description\nbigquery_update_dataset_expiration\nbigquery_delete_dataset"
        ],
        "last_commit_sha": "8f5beae5bb9890974d57b6878e8b5a57f81661c4"
    },
    {
        "pr_title": "Add three new BigQuery snippets, and address minor nits.",
        "pr_number": 449,
        "file_name": "bigquery/snippets/snippet_test.go",
        "code_diff": "@@ -42,12 +42,29 @@\nfunc TestAll(t *testing.T) {\n \tif err != nil {\n \t\tt.Fatal(err)\n \t}\n+\n \tdatasetID := fmt.Sprintf(\"golang_example_dataset_%d\", time.Now().Unix())\n \tif err := createDataset(client, datasetID); err != nil {\n \t\tt.Errorf(\"failed to create dataset: %v\", err)\n \t}\n+\n+\t// test empty dataset creation/ttl/delete\n+\tdeletionDatasetID := fmt.Sprintf(\"%s_quickdelete\", datasetID)\n+\tif err := createDataset(client, deletionDatasetID); err != nil {\n+\t\tt.Errorf(\"failed to create ephemeral dataset: %v\", err)\n+\t}\n+\tif err = updateDatasetDefaultExpiration(client, deletionDatasetID); err != nil {\n+\t\tt.Errorf(\"failed to set default table TTL on ephemeral dataset: %v\", err)\n+\t}\n+\tif err := deleteEmptyDataset(client, deletionDatasetID); err != nil {\n+\t\tt.Errorf(\"failed to delete ephemeral dataset: %v\", err)\n+\t}\n+\n+\tif err := updateDatasetDescription(client, datasetID); err != nil {\n+\t\tt.Errorf(\"failed to update dataset description: %v\", err)\n+\t}\n \tif err := listDatasets(client); err != nil {\n-\t\tt.Errorf(\"failed to create dataset: %v\", err)\n+\t\tt.Errorf(\"failed to list dataset: %v\", err)\n \t}\n \n \ttableID := fmt.Sprintf(\"golang_example_table_%d\", time.Now().Unix())",
        "comments": [],
        "commit_messages": [
            "Add three new BigQuery snippets, and address minor nits.\n\nNew snippets:\nbigquery_update_dataset_description\nbigquery_update_dataset_expiration\nbigquery_delete_dataset"
        ],
        "last_commit_sha": "8f5beae5bb9890974d57b6878e8b5a57f81661c4"
    },
    {
        "pr_title": "vision/detect: add web entity geo sample",
        "pr_number": 431,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -16,8 +16,10 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \n-\tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"golang.org/x/net/context\"\n+\n+\tvision \"cloud.google.com/go/vision/apiv1\"\n+\tvisionpb \"google.golang.org/genproto/googleapis/cloud/vision/v1\"\n )\n \n // [END imports]",
        "comments": [
            {
                "comment": "Add `defer client.Close()`?",
                "position": 26
            },
            {
                "comment": "Add `defer client.Close()`?",
                "position": 26
            },
            {
                "comment": "Tests?",
                "position": 19
            },
            {
                "comment": "yep, there's a test (see detect_test.go)",
                "position": 19
            },
            {
                "comment": "hm, good point. could you file a bug - if this is what we want, we should do this for all of the samples.",
                "position": 26
            }
        ],
        "commit_messages": [
            "vision/detect: add web entity geo sample"
        ],
        "last_commit_sha": "20e25c8ef82d741c9df0e13b974934fdf190c8ec"
    },
    {
        "pr_title": "vision/detect: add web entity geo sample",
        "pr_number": 431,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -399,6 +401,49 @@\nfunc detectWeb(w io.Writer, file string) error {\n \n // [END vision_detect_web]\n \n+// [START vision_web_entities_include_geo_results]\n+\n+// detectWebGeo detects geographic metadata from the Vision API for an image at the given file path.\n+func detectWebGeo(w io.Writer, file string) error {\n+\tctx := context.Background()\n+\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tf, err := os.Open(file)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer f.Close()\n+\n+\timage, err := vision.NewImageFromReader(f)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\timageContext := &visionpb.ImageContext{\n+\t\tWebDetectionParams: &visionpb.WebDetectionParams{\n+\t\t\tIncludeGeoResults: true,\n+\t\t},\n+\t}\n+\tweb, err := client.DetectWeb(ctx, image, imageContext)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif len(web.WebEntities) != 0 {\n+\t\tfmt.Fprintln(w, \"Entities:\")\n+\t\tfor _, entity := range web.WebEntities {\n+\t\t\tfmt.Fprintf(w, \"\\t%-12s %s\\n\", entity.EntityId, entity.Description)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+// [END vision_web_entities_include_geo_results]\n+\n // detectLogos gets logos from the Vision API for an image at the given file path.\n func detectLogos(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "vision/detect: add web entity geo sample"
        ],
        "last_commit_sha": "20e25c8ef82d741c9df0e13b974934fdf190c8ec"
    },
    {
        "pr_title": "vision/detect: add web entity geo sample",
        "pr_number": 431,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -19,8 +19,10 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \n-\tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"golang.org/x/net/context\"\n+\n+\tvision \"cloud.google.com/go/vision/apiv1\"\n+\tvisionpb \"google.golang.org/genproto/googleapis/cloud/vision/v1\"\n )\n \n // [END imports]",
        "comments": [],
        "commit_messages": [
            "vision/detect: add web entity geo sample"
        ],
        "last_commit_sha": "20e25c8ef82d741c9df0e13b974934fdf190c8ec"
    },
    {
        "pr_title": "appengine/gophers/6: first version of task queues",
        "pr_number": 430,
        "file_name": "appengine/gophers/gophers-5/main.go",
        "code_diff": "@@ -20,6 +20,11 @@\nimport (\n )\n \n var (\n+\tfirebaseConfig = &firebase.Config{\n+\t\tDatabaseURL:   \"https://console.firebase.google.com > Overview > Add Firebase to your web app\",\n+\t\tProjectID:     \"https://console.firebase.google.com > Overview > Add Firebase to your web app\",\n+\t\tStorageBucket: \"https://console.firebase.google.com > Overview > Add Firebase to your web app\",\n+\t}\n \tindexTemplate = template.Must(template.ParseFiles(\"index.html\"))\n )",
        "comments": [],
        "commit_messages": [
            "appengine/gophers: move Firebase config to a var\n\nThis prevents having to duplicate the bucket name for storing images."
        ],
        "last_commit_sha": "216b0c2f0a4672c37a000b89e37610b1a6833c97"
    },
    {
        "pr_title": "spanner: add BatchQuery sample",
        "pr_number": 409,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -39,6 +39,7 @@\nvar (\n \t\t\"readstoringindex\":    readStoringIndex,\n \t\t\"readonlytransaction\": readOnlyTransaction,\n \t\t\"readstaledata\":       readStaleData,\n+\t\t\"readbatchdata\":       readBatchData,\n \t}\n \n \tadminCommands = map[string]adminCommand{",
        "comments": [],
        "commit_messages": [
            "Add Spanner BatchQuery sample."
        ],
        "last_commit_sha": "52d0c3d6ff534ac953703c6e2917b885342ff469"
    },
    {
        "pr_title": "spanner: add BatchQuery sample",
        "pr_number": 409,
        "file_name": "spanner/spanner_snippets/snippet.go",
        "code_diff": "@@ -485,6 +486,53 @@\nfunc readStaleData(ctx context.Context, w io.Writer, client *spanner.Client) err\n \n // [END spanner_read_stale_data]\n \n+// [START spanner_batch_client]\n+\n+func readBatchData(ctx context.Context, w io.Writer, client *spanner.Client) error {\n+\ttxn, err := client.BatchReadOnlyTransaction(ctx, spanner.StrongRead())\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer txn.Close()\n+\n+\t// Singer represents a row in the Singers table.\n+\ttype Singer struct {\n+\t\tSingerID   int64\n+\t\tFirstName  string\n+\t\tLastName   string\n+\t\tSingerInfo []byte\n+\t}\n+\tstmt := spanner.Statement{SQL: \"SELECT SingerId, FirstName, LastName FROM Singers;\"}\n+\tpartitions, err := txn.PartitionQuery(ctx, stmt, spanner.PartitionOptions{})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\trecordCount := 0\n+\tfor i, p := range partitions {\n+\t\titer := txn.Execute(ctx, p)\n+\t\tdefer iter.Stop()\n+\t\tfor {\n+\t\t\trow, err := iter.Next()\n+\t\t\tif err == iterator.Done {\n+\t\t\t\tbreak\n+\t\t\t} else if err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tvar s Singer\n+\t\t\tif err := row.ToStruct(&s); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tfmt.Fprintf(w, \"Partition (%d) %v\\n\", i, s)\n+\t\t\trecordCount++\n+\t\t}\n+\t}\n+\tfmt.Fprintf(w, \"Total partition count: %v\\n\", len(partitions))\n+\tfmt.Fprintf(w, \"Total record count: %v\\n\", recordCount)\n+\treturn nil\n+}\n+\n+// [END spanner_batch_client]\n+\n func createClients(ctx context.Context, db string) (*database.DatabaseAdminClient, *spanner.Client) {\n \tadminClient, err := database.NewDatabaseAdminClient(ctx)\n \tif err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "52d0c3d6ff534ac953703c6e2917b885342ff469"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -9,15 +9,19 @@\npackage main\n \n+// [START imports]\n import (\n \t\"fmt\"\n \t\"io\"\n \t\"os\"\n+\t\"strings\"\n \n \tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"golang.org/x/net/context\"\n )\n \n+// [END imports]\n+\n func init() {\n \t// Refer to these functions so that goimports is happy before boilerplate is inserted.\n \t_ = context.Background()",
        "comments": [
            {
                "comment": "insert a newline after this region tag. otherwise it becomes part of the godoc comment.",
                "position": 24
            },
            {
                "comment": "@broady : Fixed (and with subsequent region tags, as well)",
                "position": 24
            }
        ],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -170,6 +174,8 @@\nfunc detectText(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [START vision_detect_document]\n+\n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentText(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -197,13 +203,37 @@\nfunc detectDocumentText(w io.Writer, file string) error {\n \tif annotation == nil {\n \t\tfmt.Fprintln(w, \"No text found.\")\n \t} else {\n-\t\tfmt.Fprintln(w, \"Text:\")\n+\t\tfmt.Fprintln(w, \"Document Text:\")\n \t\tfmt.Fprintf(w, \"%q\\n\", annotation.Text)\n+\n+\t\tfmt.Fprintln(w, \"Pages:\")\n+\t\tfor _, page := range annotation.Pages {\n+\t\t\tfmt.Fprintf(w, \"\\tConfidence: %f, Width: %d, Height: %d\\n\", page.Confidence, page.Width, page.Height)\n+\t\t\tfmt.Fprintln(w, \"\\tBlocks:\")\n+\t\t\tfor _, block := range page.Blocks {\n+\t\t\t\tfmt.Fprintf(w, \"\\t\\tConfidence: %f, Block type: %v\\n\", block.Confidence, block.BlockType)\n+\t\t\t\tfmt.Fprintln(w, \"\\t\\tParagraphs:\")\n+\t\t\t\tfor _, paragraph := range block.Paragraphs {\n+\t\t\t\t\tfmt.Fprintf(w, \"\\t\\t\\tConfidence: %f\", paragraph.Confidence)\n+\t\t\t\t\tfmt.Fprintln(w, \"\\t\\t\\tWords:\")\n+\t\t\t\t\tfor _, word := range paragraph.Words {\n+\t\t\t\t\t\tsymbols := make([]string, len(word.Symbols))\n+\t\t\t\t\t\tfor i, s := range word.Symbols {\n+\t\t\t\t\t\t\tsymbols[i] = s.Text\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\twordText := strings.Join(symbols, \"\")\n+\t\t\t\t\t\tfmt.Fprintf(w, \"\\t\\t\\t\\tConfidence: %f, Symbols: %s\\n\", word.Confidence, wordText)\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n \t}\n \n \treturn nil\n }\n \n+// [END vision_detect_document]\n+\n // detectProperties gets image properties from the Vision API for an image at the given file path.\n func detectProperties(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -274,6 +304,8 @@\nfunc detectCropHints(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [START vision_detect_safe_search]\n+\n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearch(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -301,12 +333,17 @@\nfunc detectSafeSearch(w io.Writer, file string) error {\n \tfmt.Fprintln(w, \"Safe Search properties:\")\n \tfmt.Fprintln(w, \"Adult:\", props.Adult)\n \tfmt.Fprintln(w, \"Medical:\", props.Medical)\n+\tfmt.Fprintln(w, \"Racy:\", props.Racy)\n \tfmt.Fprintln(w, \"Spoofed:\", props.Spoof)\n \tfmt.Fprintln(w, \"Violence:\", props.Violence)\n \n \treturn nil\n }\n \n+// [END vision_detect_safe_search]\n+\n+// [START vision_detect_web]\n+\n // detectWeb gets image properties from the Vision API for an image at the given file path.\n func detectWeb(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -350,10 +387,18 @@\nfunc detectWeb(w io.Writer, file string) error {\n \t\t\tfmt.Fprintf(w, \"\\t\\t%-12s %s\\n\", entity.EntityId, entity.Description)\n \t\t}\n \t}\n+\tif len(web.BestGuessLabels) != 0 {\n+\t\tfmt.Fprintln(w, \"\\tBest guess labels:\")\n+\t\tfor _, label := range web.BestGuessLabels {\n+\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", label.Label)\n+\t\t}\n+\t}\n \n \treturn nil\n }\n \n+// [END vision_detect_web]\n+\n // detectLogos gets logos from the Vision API for an image at the given file path.\n func detectLogos(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -506,6 +551,8 @@\nfunc detectTextURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [START vision_detect_document_uri]\n+\n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentTextURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -524,13 +571,37 @@\nfunc detectDocumentTextURI(w io.Writer, file string) error {\n \tif annotation == nil {\n \t\tfmt.Fprintln(w, \"No text found.\")\n \t} else {\n-\t\tfmt.Fprintln(w, \"Text:\")\n+\t\tfmt.Fprintln(w, \"Document Text:\")\n \t\tfmt.Fprintf(w, \"%q\\n\", annotation.Text)\n+\n+\t\tfmt.Fprintln(w, \"Pages:\")\n+\t\tfor _, page := range annotation.Pages {\n+\t\t\tfmt.Fprintf(w, \"\\tConfidence: %f, Width: %d, Height: %d\\n\", page.Confidence, page.Width, page.Height)\n+\t\t\tfmt.Fprintln(w, \"\\tBlocks:\")\n+\t\t\tfor _, block := range page.Blocks {\n+\t\t\t\tfmt.Fprintf(w, \"\\t\\tConfidence: %f, Block type: %v\\n\", block.Confidence, block.BlockType)\n+\t\t\t\tfmt.Fprintln(w, \"\\t\\tParagraphs:\")\n+\t\t\t\tfor _, paragraph := range block.Paragraphs {\n+\t\t\t\t\tfmt.Fprintf(w, \"\\t\\t\\tConfidence: %f\", paragraph.Confidence)\n+\t\t\t\t\tfmt.Fprintln(w, \"\\t\\t\\tWords:\")\n+\t\t\t\t\tfor _, word := range paragraph.Words {\n+\t\t\t\t\t\tsymbols := make([]string, len(word.Symbols))\n+\t\t\t\t\t\tfor i, s := range word.Symbols {\n+\t\t\t\t\t\t\tsymbols[i] = s.Text\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\twordText := strings.Join(symbols, \"\")\n+\t\t\t\t\t\tfmt.Fprintf(w, \"\\t\\t\\t\\tConfidence: %f, Symbols: %s\\n\", word.Confidence, wordText)\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n \t}\n \n \treturn nil\n }\n \n+// [END vision_detect_document_uri]\n+\n // detectProperties gets image properties from the Vision API for an image at the given file path.\n func detectPropertiesURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -583,6 +654,8 @@\nfunc detectCropHintsURI(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [START vision_detect_safe_search_uri]\n+\n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearchURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -601,12 +674,17 @@\nfunc detectSafeSearchURI(w io.Writer, file string) error {\n \tfmt.Fprintln(w, \"Safe Search properties:\")\n \tfmt.Fprintln(w, \"Adult:\", props.Adult)\n \tfmt.Fprintln(w, \"Medical:\", props.Medical)\n+\tfmt.Fprintln(w, \"Racy:\", props.Racy)\n \tfmt.Fprintln(w, \"Spoofed:\", props.Spoof)\n \tfmt.Fprintln(w, \"Violence:\", props.Violence)\n \n \treturn nil\n }\n \n+// [END vision_detect_safe_search_uri]\n+\n+// [START vision_detect_web_uri]\n+\n // detectWeb gets image properties from the Vision API for an image at the given file path.\n func detectWebURI(w io.Writer, file string) error {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/generated/gen.go",
        "code_diff": "@@ -31,6 +31,7 @@\nfunc main() {\n \n \tnormal := string(tmpl)\n \tnormal = strings.Replace(normal, boilerplateSentinel, boilerplate, -1)\n+\tnormal = strings.Replace(normal, regionTagParameter, standardRegionTagParameterValue, -1)\n \tout.WriteString(normal)\n \n \t// Don't do imports twice.",
        "comments": [],
        "commit_messages": [
            "Added region tags through code generator"
        ],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/generated/gen.go",
        "code_diff": "@@ -39,6 +40,7 @@\nfunc main() {\n \n \tgcs := string(tmpl)\n \tgcs = strings.Replace(gcs, boilerplateSentinel, gcsBoilerplate, -1)\n+\tgcs = strings.Replace(gcs, regionTagParameter, gcsRegionTagParameterValue, -1)\n \t// Append suffix to function name.\n \tgcs = strings.Replace(gcs, \"(w io.Writer\", \"URI(w io.Writer\", -1)\n \tout.WriteString(gcs)",
        "comments": [],
        "commit_messages": [
            "Added region tags through code generator"
        ],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -12,15 +12,19 @@\n// `\tvar client *vision.Client // Boilerplate is inserted by gen.go`\n package main\n \n+// [START imports]\n import (\n \t\"fmt\"\n \t\"io\"\n \t\"os\"\n+\t\"strings\"\n \n \tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"golang.org/x/net/context\"\n )\n \n+// [END imports]\n+\n func init() {\n \t// Refer to these functions so that goimports is happy before boilerplate is inserted.\n \t_ = context.Background()",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -109,6 +113,8 @@\nfunc detectText(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [START vision_detect_document{REGION_TAG_PARAMETER}]\n+\n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentText(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -120,13 +126,37 @@\nfunc detectDocumentText(w io.Writer, file string) error {\n \tif annotation == nil {\n \t\tfmt.Fprintln(w, \"No text found.\")\n \t} else {\n-\t\tfmt.Fprintln(w, \"Text:\")\n+\t\tfmt.Fprintln(w, \"Document Text:\")\n \t\tfmt.Fprintf(w, \"%q\\n\", annotation.Text)\n+\n+\t\tfmt.Fprintln(w, \"Pages:\")\n+\t\tfor _, page := range annotation.Pages {\n+\t\t\tfmt.Fprintf(w, \"\\tConfidence: %f, Width: %d, Height: %d\\n\", page.Confidence, page.Width, page.Height)\n+\t\t\tfmt.Fprintln(w, \"\\tBlocks:\")\n+\t\t\tfor _, block := range page.Blocks {\n+\t\t\t\tfmt.Fprintf(w, \"\\t\\tConfidence: %f, Block type: %v\\n\", block.Confidence, block.BlockType)\n+\t\t\t\tfmt.Fprintln(w, \"\\t\\tParagraphs:\")\n+\t\t\t\tfor _, paragraph := range block.Paragraphs {\n+\t\t\t\t\tfmt.Fprintf(w, \"\\t\\t\\tConfidence: %f\", paragraph.Confidence)\n+\t\t\t\t\tfmt.Fprintln(w, \"\\t\\t\\tWords:\")\n+\t\t\t\t\tfor _, word := range paragraph.Words {\n+\t\t\t\t\t\tsymbols := make([]string, len(word.Symbols))\n+\t\t\t\t\t\tfor i, s := range word.Symbols {\n+\t\t\t\t\t\t\tsymbols[i] = s.Text\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\twordText := strings.Join(symbols, \"\")\n+\t\t\t\t\t\tfmt.Fprintf(w, \"\\t\\t\\t\\tConfidence: %f, Symbols: %s\\n\", word.Confidence, wordText)\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n \t}\n \n \treturn nil\n }\n \n+// [END vision_detect_document{REGION_TAG_PARAMETER}]\n+\n // detectProperties gets image properties from the Vision API for an image at the given file path.\n func detectProperties(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -165,6 +195,8 @@\nfunc detectCropHints(w io.Writer, file string) error {\n \treturn nil\n }\n \n+// [START vision_detect_safe_search{REGION_TAG_PARAMETER}]\n+\n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearch(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "New features from latest Vision API update",
        "pr_number": 388,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -176,12 +208,17 @@\nfunc detectSafeSearch(w io.Writer, file string) error {\n \tfmt.Fprintln(w, \"Safe Search properties:\")\n \tfmt.Fprintln(w, \"Adult:\", props.Adult)\n \tfmt.Fprintln(w, \"Medical:\", props.Medical)\n+\tfmt.Fprintln(w, \"Racy:\", props.Racy)\n \tfmt.Fprintln(w, \"Spoofed:\", props.Spoof)\n \tfmt.Fprintln(w, \"Violence:\", props.Violence)\n \n \treturn nil\n }\n \n+// [END vision_detect_safe_search{REGION_TAG_PARAMETER}]\n+\n+// [START vision_detect_web{REGION_TAG_PARAMETER}]\n+\n // detectWeb gets image properties from the Vision API for an image at the given file path.\n func detectWeb(w io.Writer, file string) error {\n \tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "3ed02f0b8f3f91e9ffe738f9eaa44aeded8571f8"
    },
    {
        "pr_title": "BigQuery: rewrite simple app tutorial.",
        "pr_number": 345,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -2,9 +2,10 @@\n// Use of this source code is governed by the Apache 2.0\n // license that can be found in the LICENSE file.\n \n-// Command simpleapp queries the Shakespeare sample dataset in Google BigQuery.\n+// Command simpleapp queries the Stack Overflow public dataset in Google BigQuery.\n package main\n \n+// [START bigquery_simple_app_deps]\n import (\n \t\"fmt\"\n \t\"io\"",
        "comments": [],
        "commit_messages": [
            "BigQuery: rewrite simple app tutorial.\n\n- Add additional region tags to support tutorial rewrite.\n- Use nicer struct read for printing results.\n- Use more relevant query from public datasets."
        ],
        "last_commit_sha": "0263707635dabf592878cb5bd913546761876396"
    },
    {
        "pr_title": "BigQuery: rewrite simple app tutorial.",
        "pr_number": 345,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -17,6 +18,8 @@\nimport (\n \t\"golang.org/x/net/context\"\n )\n \n+// [END bigquery_simple_app_deps]\n+\n func main() {\n \tproj := os.Getenv(\"GOOGLE_CLOUD_PROJECT\")\n \tif proj == \"\" {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0263707635dabf592878cb5bd913546761876396"
    },
    {
        "pr_title": "BigQuery: rewrite simple app tutorial.",
        "pr_number": 345,
        "file_name": "bigquery/simpleapp/simpleapp.go",
        "code_diff": "@@ -35,28 +38,38 @@\nfunc main() {\n \n // query returns a slice of the results of a query.\n func query(proj string) (*bigquery.RowIterator, error) {\n+\t// [START bigquery_simple_app_client]\n \tctx := context.Background()\n \n \tclient, err := bigquery.NewClient(ctx, proj)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n+\t// [END bigquery_simple_app_client]\n \n \tquery := client.Query(\n \t\t`SELECT\n-\t\t APPROX_TOP_COUNT(corpus, 10) as title,\n-\t\t COUNT(*) as unique_words\n-\t\t FROM ` + \"`publicdata.samples.shakespeare`;\")\n-\t// Use standard SQL syntax for queries.\n-\t// See: https://cloud.google.com/bigquery/sql-reference/\n-\tquery.QueryConfig.UseStandardSQL = true\n+\t\t\tCONCAT(\n+\t\t\t\t'https://stackoverflow.com/questions/',\n+\t\t\t\tCAST(id as STRING)) as url,\n+\t\t\tview_count\n+\t\tFROM ` + \"`bigquery-public-data.stackoverflow.posts_questions`\" + `\n+\t\tWHERE tags like '%google-bigquery%'\n+\t\tORDER BY view_count DESC\n+\t\tLIMIT 10;`)\n \treturn query.Read(ctx)\n }\n \n-// printResults prints results from a query to the Shakespeare dataset.\n+// [START bigquery_simple_app_print]\n+type StackOverflowRow struct {\n+\tURL       string `bigquery:\"url\"`\n+\tViewCount int64  `bigquery:\"view_count\"`\n+}\n+\n+// printResults prints results from a query to the Stack Overflow public dataset.\n func printResults(w io.Writer, iter *bigquery.RowIterator) error {\n \tfor {\n-\t\tvar row []bigquery.Value\n+\t\tvar row StackOverflowRow\n \t\terr := iter.Next(&row)\n \t\tif err == iterator.Done {\n \t\t\treturn nil",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "0263707635dabf592878cb5bd913546761876396"
    },
    {
        "pr_title": "docs/appengine: add cloudsql_postgres sample",
        "pr_number": 330,
        "file_name": "docs/appengine/cloudsql/cloudsql.go",
        "code_diff": "@@ -3,7 +3,7 @@\n// license that can be found in the LICENSE file.\n \n // Sample cloudsql demonstrates connection to a Cloud SQL instance from App Engine standard.\n-package cloudsql\n+package main\n \n import (\n \t\"bytes\"",
        "comments": [],
        "commit_messages": [
            "main package"
        ],
        "last_commit_sha": "c8600dba8d9dadcc986bba4aafbf31424dc030e4"
    },
    {
        "pr_title": "docs/appengine: add cloudsql_postgres sample",
        "pr_number": 330,
        "file_name": "docs/appengine/cloudsql/cloudsql.go",
        "code_diff": "@@ -13,11 +13,28 @@\nimport (\n \t\"net/http\"\n \t\"os\"\n \n+\t\"google.golang.org/appengine\"\n+\n \t_ \"github.com/go-sql-driver/mysql\"\n )\n \n-func init() {\n+var db *sql.DB\n+\n+func main() {\n+\tvar (\n+\t\tconnectionName = mustGetenv(\"CLOUDSQL_CONNECTION_NAME\")\n+\t\tuser           = mustGetenv(\"CLOUDSQL_USER\")\n+\t\tpassword       = os.Getenv(\"CLOUDSQL_PASSWORD\") // NOTE: password may be empty\n+\t)\n+\n+\tvar err error\n+\tdb, err = sql.Open(\"mysql\", fmt.Sprintf(\"%s:%s@cloudsql(%s)/\", user, password, connectionName))\n+\tif err != nil {\n+\t\tlog.Fatalf(\"Could not open db: %v\", err)\n+\t}\n+\n \thttp.HandleFunc(\"/\", handler)\n+\tappengine.Main()\n }\n \n func handler(w http.ResponseWriter, r *http.Request) {",
        "comments": [],
        "commit_messages": [
            "background"
        ],
        "last_commit_sha": "c8600dba8d9dadcc986bba4aafbf31424dc030e4"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -14,22 +14,22 @@\nimport (\n \t\"io\"\n \t\"os\"\n \n-\t\"cloud.google.com/go/vision\"\n+\tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"golang.org/x/net/context\"\n )\n \n func init() {\n \t// Refer to these functions so that goimports is happy before boilerplate is inserted.\n \t_ = context.Background()\n-\t_ = vision.NewClient\n+\t_ = vision.ImageAnnotatorClient{}\n \t_ = os.Open\n }\n \n // detectFaces gets faces from the Vision API for an image at the given file path.\n func detectFaces(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -44,31 +44,29 @@\nfunc detectFaces(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tannotations, err := client.DetectFaces(ctx, image, 10)\n+\tannotations, err := client.DetectFaces(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}\n-\n \tif len(annotations) == 0 {\n \t\tfmt.Fprintln(w, \"No faces found.\")\n \t} else {\n \t\tfmt.Fprintln(w, \"Faces:\")\n \t\tfor i, annotation := range annotations {\n \t\t\tfmt.Fprintln(w, \"  Face\", i)\n-\t\t\tfmt.Fprintln(w, \"    Anger:\", annotation.Likelihoods.Anger)\n-\t\t\tfmt.Fprintln(w, \"    Joy:\", annotation.Likelihoods.Joy)\n-\t\t\tfmt.Fprintln(w, \"    Surprise:\", annotation.Likelihoods.Surprise)\n+\t\t\tfmt.Fprintln(w, \"    Anger:\", annotation.AngerLikelihood)\n+\t\t\tfmt.Fprintln(w, \"    Joy:\", annotation.JoyLikelihood)\n+\t\t\tfmt.Fprintln(w, \"    Surprise:\", annotation.SurpriseLikelihood)\n \t\t}\n \t}\n-\n \treturn nil\n }\n \n // detectLabels gets labels from the Vision API for an image at the given file path.\n func detectLabels(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -83,7 +81,7 @@\nfunc detectLabels(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tannotations, err := client.DetectLabels(ctx, image, 10)\n+\tannotations, err := client.DetectLabels(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -104,7 +102,7 @@\nfunc detectLabels(w io.Writer, file string) error {\n func detectLandmarks(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -119,7 +117,7 @@\nfunc detectLandmarks(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tannotations, err := client.DetectLandmarks(ctx, image, 10)\n+\tannotations, err := client.DetectLandmarks(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -140,7 +138,7 @@\nfunc detectLandmarks(w io.Writer, file string) error {\n func detectText(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -155,7 +153,7 @@\nfunc detectText(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tannotations, err := client.DetectTexts(ctx, image, 10)\n+\tannotations, err := client.DetectTexts(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -176,7 +174,7 @@\nfunc detectText(w io.Writer, file string) error {\n func detectDocumentText(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -191,7 +189,7 @@\nfunc detectDocumentText(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tannotation, err := client.DetectDocumentText(ctx, image)\n+\tannotation, err := client.DetectDocumentText(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -206,7 +204,7 @@\nfunc detectDocumentText(w io.Writer, file string) error {\n func detectProperties(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -221,15 +219,18 @@\nfunc detectProperties(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tprops, err := client.DetectImageProps(ctx, image)\n+\tprops, err := client.DetectImageProperties(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \tfmt.Fprintln(w, \"Dominant colors:\")\n-\tfor _, quantized := range props.DominantColors {\n+\tfor _, quantized := range props.DominantColors.Colors {\n \t\tcolor := quantized.Color\n-\t\tfmt.Fprintf(w, \"%2.1f%% - #%02x%02x%02x\\n\", quantized.PixelFraction*100, color.R&0xff, color.G&0xff, color.B&0xff)\n+\t\tr := int(color.Red) & 0xff\n+\t\tg := int(color.Green) & 0xff\n+\t\tb := int(color.Blue) & 0xff\n+\t\tfmt.Fprintf(w, \"%2.1f%% - #%02x%02x%02x\\n\", quantized.PixelFraction*100, r, g, b)\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -239,7 +240,7 @@\nfunc detectProperties(w io.Writer, file string) error {\n func detectCropHints(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -254,14 +255,16 @@\nfunc detectCropHints(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\thints, err := client.CropHints(ctx, image, nil)\n+\tres, err := client.CropHints(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \tfmt.Fprintln(w, \"Crop hints:\")\n-\tfor _, hint := range hints {\n-\t\tfmt.Fprintf(w, \"%v\\n\", hint.BoundingPoly)\n+\tfor _, hint := range res.CropHints {\n+\t\tfor _, v := range hint.BoundingPoly.Vertices {\n+\t\t\tfmt.Fprintf(w, \"(%d,%d)\\n\", v.X, v.Y)\n+\t\t}\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -271,7 +274,7 @@\nfunc detectCropHints(w io.Writer, file string) error {\n func detectSafeSearch(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -286,7 +289,7 @@\nfunc detectSafeSearch(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tprops, err := client.DetectSafeSearch(ctx, image)\n+\tprops, err := client.DetectSafeSearch(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -304,7 +307,7 @@\nfunc detectSafeSearch(w io.Writer, file string) error {\n func detectWeb(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -319,7 +322,7 @@\nfunc detectWeb(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tweb, err := client.DetectWeb(ctx, image)\n+\tweb, err := client.DetectWeb(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -328,19 +331,19 @@\nfunc detectWeb(w io.Writer, file string) error {\n \tif len(web.FullMatchingImages) != 0 {\n \t\tfmt.Fprintln(w, \"\\tFull image matches:\")\n \t\tfor _, full := range web.FullMatchingImages {\n-\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", full.URL)\n+\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", full.Url)\n \t\t}\n \t}\n \tif len(web.PagesWithMatchingImages) != 0 {\n \t\tfmt.Fprintln(w, \"\\tPages with this image:\")\n \t\tfor _, page := range web.PagesWithMatchingImages {\n-\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", page.URL)\n+\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", page.Url)\n \t\t}\n \t}\n \tif len(web.WebEntities) != 0 {\n \t\tfmt.Fprintln(w, \"\\tEntities:\")\n \t\tfor _, entity := range web.WebEntities {\n-\t\t\tfmt.Fprintf(w, \"\\t\\t%-12s %s\\n\", entity.ID, entity.Description)\n+\t\t\tfmt.Fprintf(w, \"\\t\\t%-12s %s\\n\", entity.EntityId, entity.Description)\n \t\t}\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -351,7 +354,7 @@\nfunc detectWeb(w io.Writer, file string) error {\n func detectLogos(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -366,7 +369,7 @@\nfunc detectLogos(w io.Writer, file string) error {\n \tif err != nil {\n \t\treturn err\n \t}\n-\tannotations, err := client.DetectLogos(ctx, image, 10)\n+\tannotations, err := client.DetectLogos(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -386,51 +389,49 @@\nfunc detectLogos(w io.Writer, file string) error {\n func init() {\n \t// Refer to these functions so that goimports is happy before boilerplate is inserted.\n \t_ = context.Background()\n-\t_ = vision.NewClient\n+\t_ = vision.ImageAnnotatorClient{}\n \t_ = os.Open\n }\n \n // detectFaces gets faces from the Vision API for an image at the given file path.\n func detectFacesURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \timage := vision.NewImageFromURI(file)\n-\tannotations, err := client.DetectFaces(ctx, image, 10)\n+\tannotations, err := client.DetectFaces(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}\n-\n \tif len(annotations) == 0 {\n \t\tfmt.Fprintln(w, \"No faces found.\")\n \t} else {\n \t\tfmt.Fprintln(w, \"Faces:\")\n \t\tfor i, annotation := range annotations {\n \t\t\tfmt.Fprintln(w, \"  Face\", i)\n-\t\t\tfmt.Fprintln(w, \"    Anger:\", annotation.Likelihoods.Anger)\n-\t\t\tfmt.Fprintln(w, \"    Joy:\", annotation.Likelihoods.Joy)\n-\t\t\tfmt.Fprintln(w, \"    Surprise:\", annotation.Likelihoods.Surprise)\n+\t\t\tfmt.Fprintln(w, \"    Anger:\", annotation.AngerLikelihood)\n+\t\t\tfmt.Fprintln(w, \"    Joy:\", annotation.JoyLikelihood)\n+\t\t\tfmt.Fprintln(w, \"    Surprise:\", annotation.SurpriseLikelihood)\n \t\t}\n \t}\n-\n \treturn nil\n }\n \n // detectLabels gets labels from the Vision API for an image at the given file path.\n func detectLabelsURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \timage := vision.NewImageFromURI(file)\n-\tannotations, err := client.DetectLabels(ctx, image, 10)\n+\tannotations, err := client.DetectLabels(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -451,13 +452,13 @@\nfunc detectLabelsURI(w io.Writer, file string) error {\n func detectLandmarksURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \timage := vision.NewImageFromURI(file)\n-\tannotations, err := client.DetectLandmarks(ctx, image, 10)\n+\tannotations, err := client.DetectLandmarks(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -478,13 +479,13 @@\nfunc detectLandmarksURI(w io.Writer, file string) error {\n func detectTextURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \timage := vision.NewImageFromURI(file)\n-\tannotations, err := client.DetectTexts(ctx, image, 10)\n+\tannotations, err := client.DetectTexts(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -505,13 +506,13 @@\nfunc detectTextURI(w io.Writer, file string) error {\n func detectDocumentTextURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \timage := vision.NewImageFromURI(file)\n-\tannotation, err := client.DetectDocumentText(ctx, image)\n+\tannotation, err := client.DetectDocumentText(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -526,21 +527,24 @@\nfunc detectDocumentTextURI(w io.Writer, file string) error {\n func detectPropertiesURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \timage := vision.NewImageFromURI(file)\n-\tprops, err := client.DetectImageProps(ctx, image)\n+\tprops, err := client.DetectImageProperties(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \tfmt.Fprintln(w, \"Dominant colors:\")\n-\tfor _, quantized := range props.DominantColors {\n+\tfor _, quantized := range props.DominantColors.Colors {\n \t\tcolor := quantized.Color\n-\t\tfmt.Fprintf(w, \"%2.1f%% - #%02x%02x%02x\\n\", quantized.PixelFraction*100, color.R&0xff, color.G&0xff, color.B&0xff)\n+\t\tr := int(color.Red) & 0xff\n+\t\tg := int(color.Green) & 0xff\n+\t\tb := int(color.Blue) & 0xff\n+\t\tfmt.Fprintf(w, \"%2.1f%% - #%02x%02x%02x\\n\", quantized.PixelFraction*100, r, g, b)\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -550,20 +554,22 @@\nfunc detectPropertiesURI(w io.Writer, file string) error {\n func detectCropHintsURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \timage := vision.NewImageFromURI(file)\n-\thints, err := client.CropHints(ctx, image, nil)\n+\tres, err := client.CropHints(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \tfmt.Fprintln(w, \"Crop hints:\")\n-\tfor _, hint := range hints {\n-\t\tfmt.Fprintf(w, \"%v\\n\", hint.BoundingPoly)\n+\tfor _, hint := range res.CropHints {\n+\t\tfor _, v := range hint.BoundingPoly.Vertices {\n+\t\t\tfmt.Fprintf(w, \"(%d,%d)\\n\", v.X, v.Y)\n+\t\t}\n \t}\n \n \treturn nil",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -573,13 +579,13 @@\nfunc detectCropHintsURI(w io.Writer, file string) error {\n func detectSafeSearchURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \timage := vision.NewImageFromURI(file)\n-\tprops, err := client.DetectSafeSearch(ctx, image)\n+\tprops, err := client.DetectSafeSearch(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -597,13 +603,13 @@\nfunc detectSafeSearchURI(w io.Writer, file string) error {\n func detectWebURI(w io.Writer, file string) error {\n \tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \timage := vision.NewImageFromURI(file)\n-\tweb, err := client.DetectWeb(ctx, image)\n+\tweb, err := client.DetectWeb(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/detect.go",
        "code_diff": "@@ -612,19 +618,19 @@\nfunc detectWebURI(w io.Writer, file string) error {\n \tif len(web.FullMatchingImages) != 0 {\n \t\tfmt.Fprintln(w, \"\\tFull image matches:\")\n \t\tfor _, full := range web.FullMatchingImages {\n-\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", full.URL)\n+\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", full.Url)\n \t\t}\n \t}\n \tif len(web.PagesWithMatchingImages) != 0 {\n \t\tfmt.Fprintln(w, \"\\tPages with this image:\")\n \t\tfor _, page := range web.PagesWithMatchingImages {\n-\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", page.URL)\n+\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", page.Url)\n \t\t}\n \t}\n \tif len(web.WebEntities) != 0 {\n \t\tfmt.Fprintln(w, \"\\tEntities:\")\n \t\tfor _, entity := range web.WebEntities {\n-\t\t\tfmt.Fprintf(w, \"\\t\\t%-12s %s\\n\", entity.ID, entity.Description)\n+\t\t\tfmt.Fprintf(w, \"\\t\\t%-12s %s\\n\", entity.EntityId, entity.Description)\n \t\t}\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/generated/gen.go",
        "code_diff": "@@ -48,11 +48,11 @@\nfunc main() {\n \t}\n }\n \n-const boilerplateSentinel = \"\\tvar client *vision.Client // Boilerplate is inserted by gen.go\\n\"\n+const boilerplateSentinel = \"\\tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go\\n\"\n \n const boilerplate = `\tctx := context.Background()\n \n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -10,52 +10,49 @@\n//   go generate\n // Boilerplate client code is inserted in the sections marked\n // `\tvar client *vision.Client // Boilerplate is inserted by gen.go`\n-\n package main\n \n import (\n \t\"fmt\"\n \t\"io\"\n \t\"os\"\n \n-\t\"cloud.google.com/go/vision\"\n+\tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"golang.org/x/net/context\"\n )\n \n func init() {\n \t// Refer to these functions so that goimports is happy before boilerplate is inserted.\n \t_ = context.Background()\n-\t_ = vision.NewClient\n+\t_ = vision.ImageAnnotatorClient{}\n \t_ = os.Open\n }\n \n // detectFaces gets faces from the Vision API for an image at the given file path.\n func detectFaces(w io.Writer, file string) error {\n-\tvar client *vision.Client // Boilerplate is inserted by gen.go\n-\tannotations, err := client.DetectFaces(ctx, image, 10)\n+\tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go\n+\tannotations, err := client.DetectFaces(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}\n-\n \tif len(annotations) == 0 {\n \t\tfmt.Fprintln(w, \"No faces found.\")\n \t} else {\n \t\tfmt.Fprintln(w, \"Faces:\")\n \t\tfor i, annotation := range annotations {\n \t\t\tfmt.Fprintln(w, \"  Face\", i)\n-\t\t\tfmt.Fprintln(w, \"    Anger:\", annotation.Likelihoods.Anger)\n-\t\t\tfmt.Fprintln(w, \"    Joy:\", annotation.Likelihoods.Joy)\n-\t\t\tfmt.Fprintln(w, \"    Surprise:\", annotation.Likelihoods.Surprise)\n+\t\t\tfmt.Fprintln(w, \"    Anger:\", annotation.AngerLikelihood)\n+\t\t\tfmt.Fprintln(w, \"    Joy:\", annotation.JoyLikelihood)\n+\t\t\tfmt.Fprintln(w, \"    Surprise:\", annotation.SurpriseLikelihood)\n \t\t}\n \t}\n-\n \treturn nil\n }\n \n // detectLabels gets labels from the Vision API for an image at the given file path.\n func detectLabels(w io.Writer, file string) error {\n-\tvar client *vision.Client // Boilerplate is inserted by gen.go\n-\tannotations, err := client.DetectLabels(ctx, image, 10)\n+\tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go\n+\tannotations, err := client.DetectLabels(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -74,8 +71,8 @@\nfunc detectLabels(w io.Writer, file string) error {\n \n // detectLandmarks gets landmarks from the Vision API for an image at the given file path.\n func detectLandmarks(w io.Writer, file string) error {\n-\tvar client *vision.Client // Boilerplate is inserted by gen.go\n-\tannotations, err := client.DetectLandmarks(ctx, image, 10)\n+\tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go\n+\tannotations, err := client.DetectLandmarks(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -94,8 +91,8 @@\nfunc detectLandmarks(w io.Writer, file string) error {\n \n // detectText gets text from the Vision API for an image at the given file path.\n func detectText(w io.Writer, file string) error {\n-\tvar client *vision.Client // Boilerplate is inserted by gen.go\n-\tannotations, err := client.DetectTexts(ctx, image, 10)\n+\tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go\n+\tannotations, err := client.DetectTexts(ctx, image, nil, 10)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -114,8 +111,8 @@\nfunc detectText(w io.Writer, file string) error {\n \n // detectDocumentText gets the full document text from the Vision API for an image at the given file path.\n func detectDocumentText(w io.Writer, file string) error {\n-\tvar client *vision.Client // Boilerplate is inserted by gen.go\n-\tannotation, err := client.DetectDocumentText(ctx, image)\n+\tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go\n+\tannotation, err := client.DetectDocumentText(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -128,41 +125,46 @@\nfunc detectDocumentText(w io.Writer, file string) error {\n \n // detectProperties gets image properties from the Vision API for an image at the given file path.\n func detectProperties(w io.Writer, file string) error {\n-\tvar client *vision.Client // Boilerplate is inserted by gen.go\n-\tprops, err := client.DetectImageProps(ctx, image)\n+\tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go\n+\tprops, err := client.DetectImageProperties(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \tfmt.Fprintln(w, \"Dominant colors:\")\n-\tfor _, quantized := range props.DominantColors {\n+\tfor _, quantized := range props.DominantColors.Colors {\n \t\tcolor := quantized.Color\n-\t\tfmt.Fprintf(w, \"%2.1f%% - #%02x%02x%02x\\n\", quantized.PixelFraction*100, color.R&0xff, color.G&0xff, color.B&0xff)\n+\t\tr := int(color.Red) & 0xff\n+\t\tg := int(color.Green) & 0xff\n+\t\tb := int(color.Blue) & 0xff\n+\t\tfmt.Fprintf(w, \"%2.1f%% - #%02x%02x%02x\\n\", quantized.PixelFraction*100, r, g, b)\n \t}\n \n \treturn nil\n }\n \n // detectCropHints gets suggested croppings the Vision API for an image at the given file path.\n func detectCropHints(w io.Writer, file string) error {\n-\tvar client *vision.Client // Boilerplate is inserted by gen.go\n-\thints, err := client.CropHints(ctx, image, nil)\n+\tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go\n+\tres, err := client.CropHints(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}\n \n \tfmt.Fprintln(w, \"Crop hints:\")\n-\tfor _, hint := range hints {\n-\t\tfmt.Fprintf(w, \"%v\\n\", hint.BoundingPoly)\n+\tfor _, hint := range res.CropHints {\n+\t\tfor _, v := range hint.BoundingPoly.Vertices {\n+\t\t\tfmt.Fprintf(w, \"(%d,%d)\\n\", v.X, v.Y)\n+\t\t}\n \t}\n \n \treturn nil\n }\n \n // detectSafeSearch gets image properties from the Vision API for an image at the given file path.\n func detectSafeSearch(w io.Writer, file string) error {\n-\tvar client *vision.Client // Boilerplate is inserted by gen.go\n-\tprops, err := client.DetectSafeSearch(ctx, image)\n+\tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go\n+\tprops, err := client.DetectSafeSearch(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -178,8 +180,8 @@\nfunc detectSafeSearch(w io.Writer, file string) error {\n \n // detectWeb gets image properties from the Vision API for an image at the given file path.\n func detectWeb(w io.Writer, file string) error {\n-\tvar client *vision.Client // Boilerplate is inserted by gen.go\n-\tweb, err := client.DetectWeb(ctx, image)\n+\tvar client *vision.ImageAnnotatorClient // Boilerplate is inserted by gen.go\n+\tweb, err := client.DetectWeb(ctx, image, nil)\n \tif err != nil {\n \t\treturn err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/detect/generated/sample-template.go",
        "code_diff": "@@ -188,19 +190,19 @@\nfunc detectWeb(w io.Writer, file string) error {\n \tif len(web.FullMatchingImages) != 0 {\n \t\tfmt.Fprintln(w, \"\\tFull image matches:\")\n \t\tfor _, full := range web.FullMatchingImages {\n-\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", full.URL)\n+\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", full.Url)\n \t\t}\n \t}\n \tif len(web.PagesWithMatchingImages) != 0 {\n \t\tfmt.Fprintln(w, \"\\tPages with this image:\")\n \t\tfor _, page := range web.PagesWithMatchingImages {\n-\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", page.URL)\n+\t\t\tfmt.Fprintf(w, \"\\t\\t%s\\n\", page.Url)\n \t\t}\n \t}\n \tif len(web.WebEntities) != 0 {\n \t\tfmt.Fprintln(w, \"\\tEntities:\")\n \t\tfor _, entity := range web.WebEntities {\n-\t\t\tfmt.Fprintf(w, \"\\t\\t%-12s %s\\n\", entity.ID, entity.Description)\n+\t\t\tfmt.Fprintf(w, \"\\t\\t%-12s %s\\n\", entity.EntityId, entity.Description)\n \t\t}\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/label/label.go",
        "code_diff": "@@ -12,7 +12,7 @@\nimport (\n \t\"path/filepath\"\n \n \t// [START imports]\n-\t\"cloud.google.com/go/vision\"\n+\tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"golang.org/x/net/context\"\n \t// [END imports]\n )",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/label/label.go",
        "code_diff": "@@ -23,7 +23,7 @@\nfunc findLabels(file string) ([]string, error) {\n \tctx := context.Background()\n \n \t// Create the client.\n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}",
        "comments": [],
        "commit_messages": [
            "vision: switch to the generated surface\n\nRemove the dependency to cloud.google.com/go/vision and use\nthe new autogenated helpers.\n\nChange-Id: Ibb926273ca192d8dca0b6f3034cd003b4c6df35b"
        ],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "vision: switch to the generated surface",
        "pr_number": 257,
        "file_name": "vision/vision_quickstart/main.go",
        "code_diff": "@@ -12,15 +12,15 @@\nimport (\n \t\"os\"\n \n \t// Imports the Google Cloud Vision API client package.\n-\t\"cloud.google.com/go/vision\"\n+\tvision \"cloud.google.com/go/vision/apiv1\"\n \t\"golang.org/x/net/context\"\n )\n \n func main() {\n \tctx := context.Background()\n \n \t// Creates a client.\n-\tclient, err := vision.NewClient(ctx)\n+\tclient, err := vision.NewImageAnnotatorClient(ctx)\n \tif err != nil {\n \t\tlog.Fatalf(\"Failed to create client: %v\", err)\n \t}",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "10cec382b01641b04ded1f8f14fca38d30d10b75"
    },
    {
        "pr_title": "pubsub: add samples for PushConfig, PublishSettings, and ReceiveSettings",
        "pr_number": 253,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -129,6 +129,38 @@\nfunc pullMsgs(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \treturn nil\n }\n \n+func pullMsgsError(client *pubsub.Client, name string) error {\n+\tctx := context.Background()\n+\t// [START pull_messages_error]\n+\t// If the service returns a non-retryable error, Receive returns that error after\n+\t// all of the outstanding calls to the handler have returned.\n+\terr := client.Subscription(name).Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n+\t\tfmt.Printf(\"Got message: %q\\n\", string(msg.Data))\n+\t\tmsg.Ack()\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// [END pull_messages_error]\n+\treturn nil\n+}\n+\n+func pullMsgsSettings(client *pubsub.Client, name string) error {\n+\tctx := context.Background()\n+\t// [START pull_messages_settings]\n+\tsub := client.Subscription(name)\n+\tsub.ReceiveSettings.MaxOutstandingMessages = 10\n+\terr := sub.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {\n+\t\tfmt.Printf(\"Got message: %q\\n\", string(msg.Data))\n+\t\tmsg.Ack()\n+\t})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\t// [END pull_messages_settings]\n+\treturn nil\n+}\n+\n func create(client *pubsub.Client, name string, topic *pubsub.Topic) error {\n \tctx := context.Background()\n \t// [START create_subscription]",
        "comments": [],
        "commit_messages": [
            "addressed feedback, added Receive flow control samples.\n\nChange-Id: I4f846bcaf07b1a6cd8d4423322830fbc68a4b119"
        ],
        "last_commit_sha": "afbcb595dd8f29ad7cafae30604d2f30e6f98439"
    },
    {
        "pr_title": "pubsub: add samples for PushConfig, PublishSettings, and ReceiveSettings",
        "pr_number": 253,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -10,6 +10,7 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \t\"os\"\n+\t\"time\"\n \n \t// [START imports]\n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_messages": [
            "pubsub: add samples for PushConfig and PublishSettings\n\nChange-Id: I210b770118f37cadc45a88a4be7277714d1cf78a"
        ],
        "last_commit_sha": "afbcb595dd8f29ad7cafae30604d2f30e6f98439"
    },
    {
        "pr_title": "pubsub: add samples for PushConfig, PublishSettings, and ReceiveSettings",
        "pr_number": 253,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -95,6 +96,27 @@\nfunc list(client *pubsub.Client) ([]*pubsub.Topic, error) {\n \t// [END list_topics]\n }\n \n+func listSubscriptions(client *pubsub.Client, topicID string) ([]*pubsub.Subscription, error) {\n+\tctx := context.Background()\n+\n+\t// [START list_topic_subscriptions]\n+\tvar subs []*pubsub.Subscription\n+\n+\tit := client.Topic(topicID).Subscriptions(ctx)\n+\tfor {\n+\t\tsub, err := it.Next()\n+\t\tif err == iterator.Done {\n+\t\t\tbreak\n+\t\t}\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\tsubs = append(subs, sub)\n+\t}\n+\t// [END list_topic_subscriptions]\n+\treturn subs, nil\n+}\n+\n func delete(client *pubsub.Client, topic string) error {\n \tctx := context.Background()\n \t// [START delete_topic]",
        "comments": [],
        "commit_messages": [
            "pubsub: add samples for PushConfig and PublishSettings\n\nChange-Id: I210b770118f37cadc45a88a4be7277714d1cf78a"
        ],
        "last_commit_sha": "afbcb595dd8f29ad7cafae30604d2f30e6f98439"
    },
    {
        "pr_title": "pubsub: use new Subscription.Receive interface",
        "pr_number": 209,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -10,6 +10,7 @@\nimport (\n \t\"fmt\"\n \t\"log\"\n \t\"os\"\n+\t\"sync\"\n \t\"time\"\n \n \t// [START imports]",
        "comments": [],
        "commit_messages": [
            "pubsub: use new Subscription.Receive interface"
        ],
        "last_commit_sha": "3f7aa979fc6083f5a2928a930a16aee835fa13b7"
    },
    {
        "pr_title": "pubsub: add IAM and IAM policy samples",
        "pr_number": 166,
        "file_name": "pubsub/subscriptions/main.go",
        "code_diff": "@@ -18,6 +18,8 @@\nimport (\n \t\"cloud.google.com/go/pubsub\"\n \t\"google.golang.org/api/iterator\"\n \t// [END imports]\n+\n+\t\"cloud.google.com/go/iam\"\n )\n \n func main() {",
        "comments": [],
        "commit_messages": [
            "pubsub: add IAM and IAM policy samples"
        ],
        "last_commit_sha": "744bb51e5f460fc3384061a1bd371f2ef78a1d29"
    },
    {
        "pr_title": "pubsub: add IAM and IAM policy samples",
        "pr_number": 166,
        "file_name": "pubsub/subscriptions/main_test.go",
        "code_diff": "@@ -9,6 +9,7 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n+\t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_messages": [
            "pubsub: add IAM and IAM policy samples"
        ],
        "last_commit_sha": "744bb51e5f460fc3384061a1bd371f2ef78a1d29"
    },
    {
        "pr_title": "pubsub: add IAM and IAM policy samples",
        "pr_number": 166,
        "file_name": "pubsub/topics/main.go",
        "code_diff": "@@ -14,6 +14,7 @@\nimport (\n \t// [START imports]\n \t\"golang.org/x/net/context\"\n \n+\t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"google.golang.org/api/iterator\"\n \t// [END imports]",
        "comments": [],
        "commit_messages": [
            "pubsub: add IAM and IAM policy samples"
        ],
        "last_commit_sha": "744bb51e5f460fc3384061a1bd371f2ef78a1d29"
    },
    {
        "pr_title": "pubsub: add IAM and IAM policy samples",
        "pr_number": 166,
        "file_name": "pubsub/topics/main_test.go",
        "code_diff": "@@ -9,6 +9,7 @@\nimport (\n \n \t\"golang.org/x/net/context\"\n \n+\t\"cloud.google.com/go/iam\"\n \t\"cloud.google.com/go/pubsub\"\n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_messages": [
            "pubsub: add IAM and IAM policy samples"
        ],
        "last_commit_sha": "744bb51e5f460fc3384061a1bd371f2ef78a1d29"
    },
    {
        "pr_title": "storage: add bucket listing samples",
        "pr_number": 153,
        "file_name": "storage/objects/main.go",
        "code_diff": "@@ -17,6 +17,8 @@\nimport (\n \t\"os\"\n \t\"strings\"\n \n+\t\"google.golang.org/api/iterator\"\n+\n \t\"golang.org/x/net/context\"\n \n \t\"cloud.google.com/go/storage\"",
        "comments": [],
        "commit_messages": [
            "storage: add bucket listing samples"
        ],
        "last_commit_sha": "127317f28472fb7df5dd2abec2cf923b0543a7a8"
    },
    {
        "pr_title": "logging: fix the broken build",
        "pr_number": 127,
        "file_name": "logging/simplelog/simplelog.go",
        "code_diff": "@@ -11,14 +11,13 @@\nimport (\n \t\"os\"\n \t\"time\"\n \n+\t// [START imports]\n \t\"golang.org/x/net/context\"\n \n-\t// [START imports]\n-\t// NOTE: This will become cloud.google.com/go/logging soon.\n-\t\"cloud.google.com/go/preview/logging\"\n+\t\"cloud.google.com/go/logging\"\n+\t\"cloud.google.com/go/logging/logadmin\"\n \n \t\"google.golang.org/api/iterator\"\n-\t\"google.golang.org/api/option\"\n \t// [END imports]\n )",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ff2a32523281d6f975d5b6e89362e36b32ab9fc6"
    },
    {
        "pr_title": "logging: fix the broken build",
        "pr_number": 127,
        "file_name": "logging/simplelog/simplelog.go",
        "code_diff": "@@ -35,13 +34,16 @@\nfunc main() {\n \n \t// [START setup]\n \tctx := context.Background()\n-\tclient, err := logging.NewClient(ctx, projID,\n-\t\t// Admin scope is required to delete logs.\n-\t\toption.WithScopes(logging.AdminScope))\n-\n+\tclient, err := logging.NewClient(ctx, projID)\n \tif err != nil {\n \t\tlog.Fatalf(\"Failed to create logging client: %v\", err)\n \t}\n+\n+\tadminClient, err := logadmin.NewClient(ctx, projID)\n+\tif err != nil {\n+\t\tlog.Fatalf(\"Failed to create logadmin client: %v\", err)\n+\t}\n+\n \tclient.OnError = func(err error) {\n \t\t// Print an error to the local log.\n \t\t// For example, if Flush() failed.",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ff2a32523281d6f975d5b6e89362e36b32ab9fc6"
    },
    {
        "pr_title": "logging: fix the broken build",
        "pr_number": 127,
        "file_name": "logging/simplelog/simplelog.go",
        "code_diff": "@@ -57,7 +59,7 @@\nfunc main() {\n \n \tcase \"read\":\n \t\tlog.Print(\"Fetching and printing log entries.\")\n-\t\tentries, err := getEntries(client, projID)\n+\t\tentries, err := getEntries(adminClient, projID)\n \t\tif err != nil {\n \t\t\tlog.Fatalf(\"Could not get entries: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "logging: fix the broken build"
        ],
        "last_commit_sha": "ff2a32523281d6f975d5b6e89362e36b32ab9fc6"
    },
    {
        "pr_title": "logging: fix the broken build",
        "pr_number": 127,
        "file_name": "logging/simplelog/simplelog.go",
        "code_diff": "@@ -71,7 +73,7 @@\nfunc main() {\n \n \tcase \"delete\":\n \t\tlog.Print(\"Deleting log.\")\n-\t\tif err := deleteLog(client); err != nil {\n+\t\tif err := deleteLog(adminClient); err != nil {\n \t\t\tlog.Fatalf(\"Could not delete log: %v\", err)\n \t\t}",
        "comments": [],
        "commit_messages": [
            "logging: fix the broken build"
        ],
        "last_commit_sha": "ff2a32523281d6f975d5b6e89362e36b32ab9fc6"
    },
    {
        "pr_title": "logging: fix the broken build",
        "pr_number": 127,
        "file_name": "logging/simplelog/simplelog_test.go",
        "code_diff": "@@ -10,9 +10,9 @@\nimport (\n \t\"testing\"\n \t\"time\"\n \n-\t\"cloud.google.com/go/preview/logging\"\n+\t\"cloud.google.com/go/logging\"\n+\t\"cloud.google.com/go/logging/logadmin\"\n \t\"golang.org/x/net/context\"\n-\t\"google.golang.org/api/option\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ff2a32523281d6f975d5b6e89362e36b32ab9fc6"
    },
    {
        "pr_title": "logging: fix the broken build",
        "pr_number": 127,
        "file_name": "logging/simplelog/simplelog_test.go",
        "code_diff": "@@ -21,9 +21,13 @@\nfunc TestSimplelog(t *testing.T) {\n \ttc := testutil.SystemTest(t)\n \tctx := context.Background()\n \n-\tclient, err := logging.NewClient(ctx, tc.ProjectID, option.WithScopes(logging.AdminScope))\n+\tclient, err := logging.NewClient(ctx, tc.ProjectID)\n \tif err != nil {\n-\t\tt.Fatalf(\"NewClient: %v\", err)\n+\t\tt.Fatalf(\"logging.NewClient: %v\", err)\n+\t}\n+\tadminClient, err := logadmin.NewClient(ctx, tc.ProjectID)\n+\tif err != nil {\n+\t\tt.Fatalf(\"logadmin.NewClient: %v\", err)\n \t}\n \tdefer func() {\n \t\tif err := client.Close(); err != nil {",
        "comments": [],
        "commit_messages": [],
        "last_commit_sha": "ff2a32523281d6f975d5b6e89362e36b32ab9fc6"
    },
    {
        "pr_title": "logging: fix the broken build",
        "pr_number": 127,
        "file_name": "logging/simplelog/simplelog_test.go",
        "code_diff": "@@ -32,7 +36,7 @@\nfunc TestSimplelog(t *testing.T) {\n \t}()\n \n \tdefer func() {\n-\t\tif err := deleteLog(client); err != nil {\n+\t\tif err := deleteLog(adminClient); err != nil {\n \t\t\tt.Errorf(\"deleteLog: %v\", err)\n \t\t}\n \t}()",
        "comments": [],
        "commit_messages": [
            "logging: fix the broken build"
        ],
        "last_commit_sha": "ff2a32523281d6f975d5b6e89362e36b32ab9fc6"
    },
    {
        "pr_title": "logging: fix the broken build",
        "pr_number": 127,
        "file_name": "speech/captionasync/captionasync.go",
        "code_diff": "@@ -7,7 +7,6 @@\npackage main\n \n import (\n-\t\"context\"\n \t\"errors\"\n \t\"fmt\"\n \t\"io/ioutil\"",
        "comments": [],
        "commit_messages": [
            "address review feedback"
        ],
        "last_commit_sha": "ff2a32523281d6f975d5b6e89362e36b32ab9fc6"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -7,32 +7,33 @@\npackage main\n \n import (\n-\t\"encoding/json\"\n \t\"fmt\"\n \t\"log\"\n \t\"os\"\n \t\"strings\"\n \n+\t\"github.com/golang/protobuf/proto\"\n+\n \t\"golang.org/x/net/context\"\n-\t\"golang.org/x/oauth2/google\"\n \n-\tlanguage \"google.golang.org/api/language/v1beta1\"\n+\t// [START imports]\n+\tlanguage \"cloud.google.com/go/language/apiv1beta1\"\n+\tlanguagepb \"google.golang.org/genproto/googleapis/cloud/language/v1beta1\"\n+\t// [END imports]\n )\n \n func main() {\n \tif len(os.Args) < 2 {\n \t\tusage(\"Missing command.\")\n \t}\n \n+\t// [START init]\n \tctx := context.Background()\n-\thc, err := google.DefaultClient(ctx, language.CloudPlatformScope)\n-\tif err != nil {\n-\t\tlog.Fatal(err)\n-\t}\n-\tclient, err := language.New(hc)\n+\tclient, err := language.NewClient(ctx)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n+\t// [END init]\n \n \ttext := strings.Join(os.Args[2:], \" \")\n \tif text == \"\" {",
        "comments": [],
        "commit_messages": [
            "language/analyze: use cloud.google.com/go/language/apiv1beta1"
        ],
        "last_commit_sha": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "language/analyze/analyze.go",
        "code_diff": "@@ -41,11 +42,11 @@\nfunc main() {\n \n \tswitch os.Args[1] {\n \tcase \"entities\":\n-\t\tprintResp(analyzeEntities(client, text))\n+\t\tprintResp(analyzeEntities(ctx, client, text))\n \tcase \"sentiment\":\n-\t\tprintResp(analyzeSentiment(client, text))\n+\t\tprintResp(analyzeSentiment(ctx, client, text))\n \tcase \"syntax\":\n-\t\tprintResp(analyzeSyntax(client, text))\n+\t\tprintResp(analyzeSyntax(ctx, client, text))\n \tdefault:\n \t\tusage(\"Unknown command.\")\n \t}",
        "comments": [],
        "commit_messages": [
            "language/analyze: use cloud.google.com/go/language/apiv1beta1"
        ],
        "last_commit_sha": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "language/analyze/analyze_test.go",
        "code_diff": "@@ -8,18 +8,18 @@\nimport (\n \t\"testing\"\n \n \t\"golang.org/x/net/context\"\n-\t\"golang.org/x/oauth2/google\"\n \n-\tlanguage \"google.golang.org/api/language/v1beta1\"\n+\tlanguage \"cloud.google.com/go/language/apiv1beta1\"\n+\tlanguagepb \"google.golang.org/genproto/googleapis/cloud/language/v1beta1\"\n \n \t\"github.com/GoogleCloudPlatform/golang-samples/internal/testutil\"\n )\n \n func TestSentiment(t *testing.T) {\n \ttestutil.SystemTest(t)\n-\tc := newClient(t)\n+\tctx, c := newClient(t)\n \n-\tres, err := analyzeSentiment(c, \"I am very happy.\")\n+\tres, err := analyzeSentiment(ctx, c, \"I am very happy.\")\n \tif err != nil {\n \t\tt.Fatalf(\"got %v, want nil err\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "language/analyze: use cloud.google.com/go/language/apiv1beta1"
        ],
        "last_commit_sha": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "language/analyze/analyze_test.go",
        "code_diff": "@@ -30,9 +30,9 @@\nfunc TestSentiment(t *testing.T) {\n \n func TestEntity(t *testing.T) {\n \ttestutil.SystemTest(t)\n-\tc := newClient(t)\n+\tctx, c := newClient(t)\n \n-\tres, err := analyzeEntities(c, \"Homer Simpson likes donuts.\")\n+\tres, err := analyzeEntities(ctx, c, \"Homer Simpson likes donuts.\")\n \tif err != nil {\n \t\tt.Fatalf(\"got %v, want nil err\", err)\n \t}",
        "comments": [],
        "commit_messages": [
            "language/analyze: use cloud.google.com/go/language/apiv1beta1"
        ],
        "last_commit_sha": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "language/analyze: use cloud.google.com/go/language/apiv1beta1",
        "pr_number": 121,
        "file_name": "language/analyze/analyze_test.go",
        "code_diff": "@@ -46,16 +46,16 @@\nfunc TestEntity(t *testing.T) {\n \n func TestSyntax(t *testing.T) {\n \ttestutil.SystemTest(t)\n-\tc := newClient(t)\n+\tctx, c := newClient(t)\n \n-\tres, err := analyzeSyntax(c, \"If you bend the gopher, his belly folds.\")\n+\tres, err := analyzeSyntax(ctx, c, \"If you bend the gopher, his belly folds.\")\n \tif err != nil {\n \t\tt.Fatalf(\"got %v, want nil err\", err)\n \t}\n \n \tfor _, tok := range res.Tokens {\n \t\tif tok.Lemma == \"gopher\" {\n-\t\t\tif tok.PartOfSpeech.Tag != \"NOUN\" {\n+\t\t\tif tok.PartOfSpeech.Tag != languagepb.PartOfSpeech_NOUN {\n \t\t\t\tt.Errorf(\"PartOfSpeech: got %+v, want NOUN\", tok.PartOfSpeech.Tag)\n \t\t\t}\n \t\t\treturn // found",
        "comments": [],
        "commit_messages": [
            "language/analyze: use cloud.google.com/go/language/apiv1beta1"
        ],
        "last_commit_sha": "01cbe94d515cb0b50628544827e95593b1c0bd1e"
    },
    {
        "pr_title": "speech/caption: use cloud.google.com/go/speech/apiv1beta1 package",
        "pr_number": 120,
        "file_name": "speech/caption/caption.go",
        "code_diff": "@@ -12,10 +12,12 @@\nimport (\n \t\"log\"\n \t\"os\"\n \n+\t// [START imports]\n \t\"golang.org/x/net/context\"\n-\t\"google.golang.org/api/option\"\n-\t\"google.golang.org/api/transport\"\n-\tspeech \"google.golang.org/genproto/googleapis/cloud/speech/v1beta1\"\n+\n+\tspeech \"cloud.google.com/go/speech/apiv1beta1\"\n+\tspeechpb \"google.golang.org/genproto/googleapis/cloud/speech/v1beta1\"\n+\t// [END imports]\n )\n \n const usage = `Usage: caption <audiofile>",
        "comments": [],
        "commit_messages": [
            "speech/caption: use cloud.google.com/go/speech/apiv1beta1 package"
        ],
        "last_commit_sha": "91e2123fb5be0bc08a23d10078db6c4f6a0e02a1"
    },
    {
        "pr_title": "all: add retry support for flaky tests",
        "pr_number": 116,
        "file_name": "pubsub/subscriptions/main_test.go",
        "code_diff": "@@ -23,7 +23,7 @@\nconst (\n \ttopicID = \"golang-samples-topic\"\n )\n \n-var once sync.Once // guards cleanup related operations that needs to be executed only for once.\n+var once sync.Once // guards cleanup related operations in setup.\n \n func setup(t *testing.T) *pubsub.Client {\n \tctx := context.Background()",
        "comments": [],
        "commit_messages": [
            "pubsub: use testutil.Flaky"
        ],
        "last_commit_sha": "523b907ea8d5225c293568a2995f23f27ae2d6ef"
    },
    {
        "pr_title": "all: add retry support for flaky tests",
        "pr_number": 116,
        "file_name": "pubsub/subscriptions/main_test.go",
        "code_diff": "@@ -36,7 +36,7 @@\nfunc setup(t *testing.T) *pubsub.Client {\n \n \t// Cleanup resources from the previous failed tests.\n \tonce.Do(func() {\n-\t\t// create a topic to subscribe to.\n+\t\t// Create a topic.\n \t\ttopic = client.Topic(topicID)\n \t\tok, err := topic.Exists(ctx)\n \t\tif err != nil {",
        "comments": [],
        "commit_messages": [
            "pubsub: use testutil.Flaky"
        ],
        "last_commit_sha": "523b907ea8d5225c293568a2995f23f27ae2d6ef"
    },
    {
        "pr_title": "all: add retry support for flaky tests",
        "pr_number": 116,
        "file_name": "pubsub/subscriptions/main_test.go",
        "code_diff": "@@ -48,7 +48,7 @@\nfunc setup(t *testing.T) *pubsub.Client {\n \t\t\t}\n \t\t}\n \n-\t\t// delete the sub if already exists\n+\t\t// Delete the sub if already exists.\n \t\tsub := client.Subscription(subID)\n \t\tok, err = sub.Exists(ctx)\n \t\tif err != nil {",
        "comments": [],
        "commit_messages": [
            "pubsub: use testutil.Flaky"
        ],
        "last_commit_sha": "523b907ea8d5225c293568a2995f23f27ae2d6ef"
    },
    {
        "pr_title": "all: add retry support for flaky tests",
        "pr_number": 116,
        "file_name": "pubsub/topics/main_test.go",
        "code_diff": "@@ -6,6 +6,7 @@\npackage main\n \n import (\n \t\"testing\"\n+\t\"time\"\n \n \t\"golang.org/x/net/context\"",
        "comments": [],
        "commit_messages": [
            "pubsub: use testutil.Flaky"
        ],
        "last_commit_sha": "523b907ea8d5225c293568a2995f23f27ae2d6ef"
    }
]